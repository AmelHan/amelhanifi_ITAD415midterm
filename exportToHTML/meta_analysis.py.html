<html>
<head>
<title>meta_analysis.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
meta_analysis.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Thu Apr  2 14:34:25 2020 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span>

<span class="s3">from </span><span class="s1">statsmodels.stats.base </span><span class="s3">import </span><span class="s1">HolderTuple</span>


<span class="s3">class </span><span class="s1">CombineResults:</span>
    <span class="s2">&quot;&quot;&quot;Results from combined estimate of means or effect sizes 
 
    This currently includes intermediate results that might be removed 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s1">self.__dict__.update(kwds)</span>
        <span class="s1">self._ini_keys = list(kwds.keys())</span>

        <span class="s1">self.df_resid = self.k - </span><span class="s4">1</span>

        <span class="s0"># TODO: move to property ?</span>
        <span class="s1">self.sd_eff_w_fe_hksj = np.sqrt(self.var_hksj_fe)</span>
        <span class="s1">self.sd_eff_w_re_hksj = np.sqrt(self.var_hksj_re)</span>

        <span class="s0"># explained variance measures</span>
        <span class="s1">self.h2 = self.q / (self.k - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">self.i2 = </span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1 </span><span class="s1">/ self.h2</span>

        <span class="s0"># memoize ci_samples</span>
        <span class="s1">self.cache_ci = {}</span>

    <span class="s3">def </span><span class="s1">conf_int_samples(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None, </span><span class="s1">nobs=</span><span class="s3">None,</span>
                         <span class="s1">ci_func=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;confidence intervals for the effect size estimate of samples 
 
        Additional information needs to be provided for confidence intervals 
        that are not based on normal distribution using available variance. 
        This is likely to change in future. 
 
        Parameters 
        ---------- 
        alpha : float in (0, 1) 
            Significance level for confidence interval. Nominal coverage is 
            ``1 - alpha``. 
        use_t : None or bool 
            If use_t is None, then the attribute `use_t` determines whether 
            normal or t-distribution is used for confidence intervals. 
            Specifying use_t overrides the attribute. 
            If use_t is false, then confidence intervals are based on the 
            normal distribution. If it is true, then the t-distribution is 
            used. 
        nobs : None or float 
            Number of observations used for degrees of freedom computation. 
            Only used if use_t is true. 
        ci_func : None or callable 
            User provided function to compute confidence intervals. 
            This is not used yet and will allow using non-standard confidence 
            intervals. 
 
        Returns 
        ------- 
        ci_eff : tuple of ndarrays 
            Tuple (ci_low, ci_upp) with confidence interval computed for each 
            sample. 
 
        Notes 
        ----- 
        CombineResults currently only has information from the combine_effects 
        function, which does not provide details about individual samples. 
        &quot;&quot;&quot;</span>
        <span class="s0"># this is a bit messy, we don't have enough information about</span>
        <span class="s0"># computing conf_int already in results for other than normal</span>
        <span class="s0"># TODO: maybe there is a better</span>
        <span class="s3">if </span><span class="s1">(alpha</span><span class="s3">, </span><span class="s1">use_t) </span><span class="s3">in </span><span class="s1">self.cache_ci:</span>
            <span class="s3">return </span><span class="s1">self.cache_ci[(alpha</span><span class="s3">, </span><span class="s1">use_t)]</span>

        <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">use_t = self.use_t</span>

        <span class="s3">if </span><span class="s1">ci_func </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">kwds = {</span><span class="s5">&quot;use_t&quot;</span><span class="s1">: use_t} </span><span class="s3">if </span><span class="s1">use_t </span><span class="s3">is not None else </span><span class="s1">{}</span>
            <span class="s1">ci_eff = ci_func(alpha=alpha</span><span class="s3">, </span><span class="s1">**kwds)</span>
            <span class="s1">self.ci_sample_distr = </span><span class="s5">&quot;ci_func&quot;</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is False</span><span class="s1">:</span>
                <span class="s1">crit = stats.norm.isf(alpha / </span><span class="s4">2</span><span class="s1">)</span>
                <span class="s1">self.ci_sample_distr = </span><span class="s5">&quot;normal&quot;</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">if </span><span class="s1">nobs </span><span class="s3">is not None</span><span class="s1">:</span>
                    <span class="s1">df_resid = nobs - </span><span class="s4">1</span>
                    <span class="s1">crit = stats.t.isf(alpha / </span><span class="s4">2</span><span class="s3">, </span><span class="s1">df_resid)</span>
                    <span class="s1">self.ci_sample_distr = </span><span class="s5">&quot;t&quot;</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">msg = (</span><span class="s5">&quot;`use_t=True` requires `nobs` for each sample &quot;</span>
                           <span class="s5">&quot;or `ci_func`. Using normal distribution for &quot;</span>
                           <span class="s5">&quot;confidence interval of individual samples.&quot;</span><span class="s1">)</span>
                    <span class="s3">import </span><span class="s1">warnings</span>
                    <span class="s1">warnings.warn(msg)</span>
                    <span class="s1">crit = stats.norm.isf(alpha / </span><span class="s4">2</span><span class="s1">)</span>
                    <span class="s1">self.ci_sample_distr = </span><span class="s5">&quot;normal&quot;</span>

            <span class="s0"># sgn = np.asarray([-1, 1])</span>
            <span class="s0"># ci_eff = self.eff + sgn * crit * self.sd_eff</span>
            <span class="s1">ci_low = self.eff - crit * self.sd_eff</span>
            <span class="s1">ci_upp = self.eff + crit * self.sd_eff</span>
            <span class="s1">ci_eff = (ci_low</span><span class="s3">, </span><span class="s1">ci_upp)</span>

        <span class="s0"># if (alpha, use_t) not in self.cache_ci:  # not needed</span>
        <span class="s1">self.cache_ci[(alpha</span><span class="s3">, </span><span class="s1">use_t)] = ci_eff</span>
        <span class="s3">return </span><span class="s1">ci_eff</span>

    <span class="s3">def </span><span class="s1">conf_int(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;confidence interval for the overall mean estimate 
 
        Parameters 
        ---------- 
        alpha : float in (0, 1) 
            Significance level for confidence interval. Nominal coverage is 
            ``1 - alpha``. 
        use_t : None or bool 
            If use_t is None, then the attribute `use_t` determines whether 
            normal or t-distribution is used for confidence intervals. 
            Specifying use_t overrides the attribute. 
            If use_t is false, then confidence intervals are based on the 
            normal distribution. If it is true, then the t-distribution is 
            used. 
 
        Returns 
        ------- 
        ci_eff_fe : tuple of floats 
            Confidence interval for mean effects size based on fixed effects 
            model with scale=1. 
        ci_eff_re : tuple of floats 
            Confidence interval for mean effects size based on random effects 
            model with scale=1 
        ci_eff_fe_wls : tuple of floats 
            Confidence interval for mean effects size based on fixed effects 
            model with estimated scale corresponding to WLS, ie. HKSJ. 
        ci_eff_re_wls : tuple of floats 
            Confidence interval for mean effects size based on random effects 
            model with estimated scale corresponding to WLS, ie. HKSJ. 
            If random effects method is fully iterated, i.e. Paule-Mandel, then 
            the estimated scale is 1. 
 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">use_t = self.use_t</span>

        <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is False</span><span class="s1">:</span>
            <span class="s1">crit = stats.norm.isf(alpha / </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">crit = stats.t.isf(alpha / </span><span class="s4">2</span><span class="s3">, </span><span class="s1">self.df_resid)</span>

        <span class="s1">sgn = np.asarray([-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">m_fe = self.mean_effect_fe</span>
        <span class="s1">m_re = self.mean_effect_re</span>
        <span class="s1">ci_eff_fe = m_fe + sgn * crit * self.sd_eff_w_fe</span>
        <span class="s1">ci_eff_re = m_re + sgn * crit * self.sd_eff_w_re</span>

        <span class="s1">ci_eff_fe_wls = m_fe + sgn * crit * np.sqrt(self.var_hksj_fe)</span>
        <span class="s1">ci_eff_re_wls = m_re + sgn * crit * np.sqrt(self.var_hksj_re)</span>

        <span class="s3">return </span><span class="s1">ci_eff_fe</span><span class="s3">, </span><span class="s1">ci_eff_re</span><span class="s3">, </span><span class="s1">ci_eff_fe_wls</span><span class="s3">, </span><span class="s1">ci_eff_re_wls</span>

    <span class="s3">def </span><span class="s1">test_homogeneity(self):</span>
        <span class="s2">&quot;&quot;&quot;Test whether the means of all samples are the same 
 
        currently no options, test uses chisquare distribution 
        default might change depending on `use_t` 
 
        Returns 
        ------- 
        res : HolderTuple instance 
            The results include the following attributes: 
 
            - statistic : float 
                Test statistic, ``q`` in meta-analysis, this is the 
                pearson_chi2 statistic for the fixed effects model. 
            - pvalue : float 
                P-value based on chisquare distribution. 
            - df : float 
                Degrees of freedom, equal to number of studies or samples 
                minus 1. 
        &quot;&quot;&quot;</span>
        <span class="s1">pvalue = stats.chi2.sf(self.q</span><span class="s3">, </span><span class="s1">self.k - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">res = HolderTuple(statistic=self.q</span><span class="s3">,</span>
                          <span class="s1">pvalue=pvalue</span><span class="s3">,</span>
                          <span class="s1">df=self.k - </span><span class="s4">1</span><span class="s3">,</span>
                          <span class="s1">distr=</span><span class="s5">&quot;chi2&quot;</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">summary_array(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Create array with sample statistics and mean estimates 
 
        Parameters 
        ---------- 
        alpha : float in (0, 1) 
            Significance level for confidence interval. Nominal coverage is 
            ``1 - alpha``. 
        use_t : None or bool 
            If use_t is None, then the attribute `use_t` determines whether 
            normal or t-distribution is used for confidence intervals. 
            Specifying use_t overrides the attribute. 
            If use_t is false, then confidence intervals are based on the 
            normal distribution. If it is true, then the t-distribution is 
            used. 
 
        Returns 
        ------- 
        res : ndarray 
            Array with columns 
            ['eff', &quot;sd_eff&quot;, &quot;ci_low&quot;, &quot;ci_upp&quot;, &quot;w_fe&quot;,&quot;w_re&quot;]. 
            Rows include statistics for samples and estimates of overall mean. 
        column_names : list of str 
            The names for the columns, used when creating summary DataFrame. 
        &quot;&quot;&quot;</span>

        <span class="s1">ci_low</span><span class="s3">, </span><span class="s1">ci_upp = self.conf_int_samples(alpha=alpha</span><span class="s3">, </span><span class="s1">use_t=use_t)</span>
        <span class="s1">res = np.column_stack([self.eff</span><span class="s3">, </span><span class="s1">self.sd_eff</span><span class="s3">,</span>
                               <span class="s1">ci_low</span><span class="s3">, </span><span class="s1">ci_upp</span><span class="s3">,</span>
                               <span class="s1">self.weights_rel_fe</span><span class="s3">, </span><span class="s1">self.weights_rel_re])</span>

        <span class="s1">ci = self.conf_int(alpha=alpha</span><span class="s3">, </span><span class="s1">use_t=use_t)</span>
        <span class="s1">res_fe = [[self.mean_effect_fe</span><span class="s3">, </span><span class="s1">self.sd_eff_w_fe</span><span class="s3">,</span>
                   <span class="s1">ci[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ci[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">np.nan]]</span>
        <span class="s1">res_re = [[self.mean_effect_re</span><span class="s3">, </span><span class="s1">self.sd_eff_w_re</span><span class="s3">,</span>
                   <span class="s1">ci[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ci[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">np.nan</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]]</span>
        <span class="s1">res_fe_wls = [[self.mean_effect_fe</span><span class="s3">, </span><span class="s1">self.sd_eff_w_fe_hksj</span><span class="s3">,</span>
                       <span class="s1">ci[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ci[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">np.nan]]</span>
        <span class="s1">res_re_wls = [[self.mean_effect_re</span><span class="s3">, </span><span class="s1">self.sd_eff_w_re_hksj</span><span class="s3">,</span>
                       <span class="s1">ci[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ci[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">np.nan</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]]</span>

        <span class="s1">res = np.concatenate([res</span><span class="s3">, </span><span class="s1">res_fe</span><span class="s3">, </span><span class="s1">res_re</span><span class="s3">, </span><span class="s1">res_fe_wls</span><span class="s3">, </span><span class="s1">res_re_wls]</span><span class="s3">,</span>
                             <span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">column_names = [</span><span class="s5">'eff'</span><span class="s3">, </span><span class="s5">&quot;sd_eff&quot;</span><span class="s3">, </span><span class="s5">&quot;ci_low&quot;</span><span class="s3">, </span><span class="s5">&quot;ci_upp&quot;</span><span class="s3">, </span><span class="s5">&quot;w_fe&quot;</span><span class="s3">, </span><span class="s5">&quot;w_re&quot;</span><span class="s1">]</span>
        <span class="s3">return </span><span class="s1">res</span><span class="s3">, </span><span class="s1">column_names</span>

    <span class="s3">def </span><span class="s1">summary_frame(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Create DataFrame with sample statistics and mean estimates 
 
        Parameters 
        ---------- 
        alpha : float in (0, 1) 
            Significance level for confidence interval. Nominal coverage is 
            ``1 - alpha``. 
        use_t : None or bool 
            If use_t is None, then the attribute `use_t` determines whether 
            normal or t-distribution is used for confidence intervals. 
            Specifying use_t overrides the attribute. 
            If use_t is false, then confidence intervals are based on the 
            normal distribution. If it is true, then the t-distribution is 
            used. 
 
        Returns 
        ------- 
        res : DataFrame 
            pandas DataFrame instance with columns 
            ['eff', &quot;sd_eff&quot;, &quot;ci_low&quot;, &quot;ci_upp&quot;, &quot;w_fe&quot;,&quot;w_re&quot;]. 
            Rows include statistics for samples and estimates of overall mean. 
 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">use_t = self.use_t</span>
        <span class="s1">labels = (list(self.row_names) +</span>
                  <span class="s1">[</span><span class="s5">&quot;fixed effect&quot;</span><span class="s3">, </span><span class="s5">&quot;random effect&quot;</span><span class="s3">,</span>
                   <span class="s5">&quot;fixed effect wls&quot;</span><span class="s3">, </span><span class="s5">&quot;random effect wls&quot;</span><span class="s1">])</span>
        <span class="s1">res</span><span class="s3">, </span><span class="s1">col_names = self.summary_array(alpha=alpha</span><span class="s3">, </span><span class="s1">use_t=use_t)</span>
        <span class="s1">results = pd.DataFrame(res</span><span class="s3">, </span><span class="s1">index=labels</span><span class="s3">, </span><span class="s1">columns=col_names)</span>
        <span class="s3">return </span><span class="s1">results</span>

    <span class="s3">def </span><span class="s1">plot_forest(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None, </span><span class="s1">use_exp=</span><span class="s3">False,</span>
                    <span class="s1">ax=</span><span class="s3">None, </span><span class="s1">**kwds):</span>
        <span class="s2">&quot;&quot;&quot;Forest plot with means and confidence intervals 
 
        Parameters 
        ---------- 
        ax : None or matplotlib axis instance 
            If ax is provided, then the plot will be added to it. 
        alpha : float in (0, 1) 
            Significance level for confidence interval. Nominal coverage is 
            ``1 - alpha``. 
        use_t : None or bool 
            If use_t is None, then the attribute `use_t` determines whether 
            normal or t-distribution is used for confidence intervals. 
            Specifying use_t overrides the attribute. 
            If use_t is false, then confidence intervals are based on the 
            normal distribution. If it is true, then the t-distribution is 
            used. 
        use_exp : bool 
            If `use_exp` is True, then the effect size and confidence limits 
            will be exponentiated. This transform log-odds-ration into 
            odds-ratio, and similarly for risk-ratio. 
        ax : AxesSubplot, optional 
            If given, this axes is used to plot in instead of a new figure 
            being created. 
        kwds : optional keyword arguments 
            Keywords are forwarded to the dot_plot function that creates the 
            plot. 
 
        Returns 
        ------- 
        fig : Matplotlib figure instance 
 
        See Also 
        -------- 
        dot_plot 
 
        &quot;&quot;&quot;</span>
        <span class="s3">from </span><span class="s1">statsmodels.graphics.dotplots </span><span class="s3">import </span><span class="s1">dot_plot</span>
        <span class="s1">res_df = self.summary_frame(alpha=alpha</span><span class="s3">, </span><span class="s1">use_t=use_t)</span>
        <span class="s3">if </span><span class="s1">use_exp:</span>
            <span class="s1">res_df = np.exp(res_df[[</span><span class="s5">&quot;eff&quot;</span><span class="s3">, </span><span class="s5">&quot;ci_low&quot;</span><span class="s3">, </span><span class="s5">&quot;ci_upp&quot;</span><span class="s1">]])</span>
        <span class="s1">hw = np.abs(res_df[[</span><span class="s5">&quot;ci_low&quot;</span><span class="s3">, </span><span class="s5">&quot;ci_upp&quot;</span><span class="s1">]] - res_df[[</span><span class="s5">&quot;eff&quot;</span><span class="s1">]].values)</span>
        <span class="s1">fig = dot_plot(points=res_df[</span><span class="s5">&quot;eff&quot;</span><span class="s1">]</span><span class="s3">, </span><span class="s1">intervals=hw</span><span class="s3">,</span>
                       <span class="s1">lines=res_df.index</span><span class="s3">, </span><span class="s1">line_order=res_df.index</span><span class="s3">, </span><span class="s1">**kwds)</span>
        <span class="s3">return </span><span class="s1">fig</span>


<span class="s3">def </span><span class="s1">effectsize_smd(mean1</span><span class="s3">, </span><span class="s1">sd1</span><span class="s3">, </span><span class="s1">nobs1</span><span class="s3">, </span><span class="s1">mean2</span><span class="s3">, </span><span class="s1">sd2</span><span class="s3">, </span><span class="s1">nobs2):</span>
    <span class="s2">&quot;&quot;&quot;effect sizes for mean difference for use in meta-analysis 
 
    mean1, sd1, nobs1 are for treatment 
    mean2, sd2, nobs2 are for control 
 
    Effect sizes are computed for the mean difference ``mean1 - mean2`` 
    standardized by an estimate of the within variance. 
 
    This does not have option yet. 
    It uses standardized mean difference with bias correction as effect size. 
 
    This currently does not use np.asarray, all computations are possible in 
    pandas. 
 
    Parameters 
    ---------- 
    mean1 : array 
        mean of second sample, treatment groups 
    sd1 : array 
        standard deviation of residuals in treatment groups, within 
    nobs1 : array 
        number of observations in treatment groups 
    mean2, sd2, nobs2 : arrays 
        mean, standard deviation and number of observations of control groups 
 
    Returns 
    ------- 
    smd_bc : array 
        bias corrected estimate of standardized mean difference 
    var_smdbc : array 
        estimate of variance of smd_bc 
 
    Notes 
    ----- 
    Status: API will still change. This is currently intended for support of 
    meta-analysis. 
 
    References 
    ---------- 
    Borenstein, Michael. 2009. Introduction to Meta-Analysis. 
        Chichester: Wiley. 
 
    Chen, Ding-Geng, and Karl E. Peace. 2013. Applied Meta-Analysis with R. 
        Chapman &amp; Hall/CRC Biostatistics Series. 
        Boca Raton: CRC Press/Taylor &amp; Francis Group. 
 
    &quot;&quot;&quot;</span>
    <span class="s0"># TODO: not used yet, design and options ?</span>
    <span class="s0"># k = len(mean1)</span>
    <span class="s0"># if row_names is None:</span>
    <span class="s0">#    row_names = list(range(k))</span>
    <span class="s0"># crit = stats.norm.isf(alpha / 2)</span>
    <span class="s0"># var_diff_uneq = sd1**2 / nobs1 + sd2**2 / nobs2</span>
    <span class="s1">var_diff = (sd1**</span><span class="s4">2 </span><span class="s1">* (nobs1 - </span><span class="s4">1</span><span class="s1">) +</span>
                <span class="s1">sd2**</span><span class="s4">2 </span><span class="s1">* (nobs2 - </span><span class="s4">1</span><span class="s1">)) / (nobs1 + nobs2 - </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">sd_diff = np.sqrt(var_diff)</span>
    <span class="s1">nobs = nobs1 + nobs2</span>
    <span class="s1">bias_correction = </span><span class="s4">1 </span><span class="s1">- </span><span class="s4">3 </span><span class="s1">/ (</span><span class="s4">4 </span><span class="s1">* nobs - </span><span class="s4">9</span><span class="s1">)</span>
    <span class="s1">smd = (mean1 - mean2) / sd_diff</span>
    <span class="s1">smd_bc = bias_correction * smd</span>
    <span class="s1">var_smdbc = nobs / nobs1 / nobs2 + smd_bc**</span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">2 </span><span class="s1">/ (nobs - </span><span class="s4">3.94</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">smd_bc</span><span class="s3">, </span><span class="s1">var_smdbc</span>


<span class="s3">def </span><span class="s1">effectsize_2proportions(count1</span><span class="s3">, </span><span class="s1">nobs1</span><span class="s3">, </span><span class="s1">count2</span><span class="s3">, </span><span class="s1">nobs2</span><span class="s3">, </span><span class="s1">statistic=</span><span class="s5">&quot;diff&quot;</span><span class="s3">,</span>
                            <span class="s1">zero_correction=</span><span class="s3">None, </span><span class="s1">zero_kwds=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Effects sizes for two sample binomial proportions 
 
    Parameters 
    ---------- 
    count1, nobs1, count2, nobs2 : array_like 
        data for two samples 
    statistic : {&quot;diff&quot;, &quot;odds-ratio&quot;, &quot;risk-ratio&quot;, &quot;arcsine&quot;} 
        statistic for the comparison of two proportions 
        Effect sizes for &quot;odds-ratio&quot; and &quot;risk-ratio&quot; are in logarithm. 
    zero_correction : {None, float, &quot;tac&quot;, &quot;clip&quot;} 
        Some statistics are not finite when zero counts are in the data. 
        The options to remove zeros are: 
 
        * float : if zero_correction is a single float, then it will be added 
          to all count (cells) if the sample has any zeros. 
        * &quot;tac&quot; : treatment arm continuity correction see Ruecker et al 2009, 
          section 3.2 
        * &quot;clip&quot; : clip proportions without adding a value to all cells 
          The clip bounds can be set with zero_kwds[&quot;clip_bounds&quot;] 
 
    zero_kwds : dict 
        additional options to handle zero counts 
        &quot;clip_bounds&quot; tuple, default (1e-6, 1 - 1e-6) if zero_correction=&quot;clip&quot; 
        other options not yet implemented 
 
    Returns 
    ------- 
    effect size : array 
        Effect size for each sample. 
    var_es : array 
        Estimate of variance of the effect size 
 
    Notes 
    ----- 
    Status: API is experimental, Options for zero handling is incomplete. 
 
    The names for ``statistics`` keyword can be shortened to &quot;rd&quot;, &quot;rr&quot;, &quot;or&quot; 
    and &quot;as&quot;. 
 
    The statistics are defined as: 
 
     - risk difference = p1 - p2 
     - log risk ratio = log(p1 / p2) 
     - log odds_ratio = log(p1 / (1 - p1) * (1 - p2) / p2) 
     - arcsine-sqrt = arcsin(sqrt(p1)) - arcsin(sqrt(p2)) 
 
    where p1 and p2 are the estimated proportions in sample 1 (treatment) and 
    sample 2 (control). 
 
    log-odds-ratio and log-risk-ratio can be transformed back to ``or`` and 
    `rr` using `exp` function. 
 
    See Also 
    -------- 
    statsmodels.stats.contingency_tables 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">zero_correction </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">cc1 = cc2 = </span><span class="s4">0</span>
    <span class="s3">elif </span><span class="s1">zero_correction == </span><span class="s5">&quot;tac&quot;</span><span class="s1">:</span>
        <span class="s0"># treatment arm continuity correction Ruecker et al 2009, section 3.2</span>
        <span class="s1">nobs_t = nobs1 + nobs2</span>
        <span class="s1">cc1 = nobs2 / nobs_t</span>
        <span class="s1">cc2 = nobs1 / nobs_t</span>
    <span class="s3">elif </span><span class="s1">zero_correction == </span><span class="s5">&quot;clip&quot;</span><span class="s1">:</span>
        <span class="s1">clip_bounds = zero_kwds.get(</span><span class="s5">&quot;clip_bounds&quot;</span><span class="s3">, </span><span class="s1">(</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-6</span><span class="s1">))</span>
        <span class="s1">cc1 = cc2 = </span><span class="s4">0</span>
    <span class="s3">elif </span><span class="s1">zero_correction:</span>
        <span class="s0"># TODO: check is float_like</span>
        <span class="s1">cc1 = cc2 = zero_correction</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s5">&quot;zero_correction not recognized or supported&quot;</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError(msg)</span>

    <span class="s1">zero_mask1 = (count1 == </span><span class="s4">0</span><span class="s1">) | (count1 == nobs1)</span>
    <span class="s1">zero_mask2 = (count2 == </span><span class="s4">0</span><span class="s1">) | (count2 == nobs2)</span>
    <span class="s1">zmask = np.logical_or(zero_mask1</span><span class="s3">, </span><span class="s1">zero_mask2)</span>
    <span class="s1">n1 = nobs1 + (cc1 + cc2) * zmask</span>
    <span class="s1">n2 = nobs2 + (cc1 + cc2) * zmask</span>
    <span class="s1">p1 = (count1 + cc1) / (n1)</span>
    <span class="s1">p2 = (count2 + cc2) / (n2)</span>

    <span class="s3">if </span><span class="s1">zero_correction == </span><span class="s5">&quot;clip&quot;</span><span class="s1">:</span>
        <span class="s1">p1 = np.clip(p1</span><span class="s3">, </span><span class="s1">*clip_bounds)</span>
        <span class="s1">p2 = np.clip(p2</span><span class="s3">, </span><span class="s1">*clip_bounds)</span>

    <span class="s3">if </span><span class="s1">statistic </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;diff&quot;</span><span class="s3">, </span><span class="s5">&quot;rd&quot;</span><span class="s1">]:</span>
        <span class="s1">rd = p1 - p2</span>
        <span class="s1">rd_var = p1 * (</span><span class="s4">1 </span><span class="s1">- p1) / n1 + p2 * (</span><span class="s4">1 </span><span class="s1">- p2) / n2</span>
        <span class="s1">eff = rd</span>
        <span class="s1">var_eff = rd_var</span>
    <span class="s3">elif </span><span class="s1">statistic </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;risk-ratio&quot;</span><span class="s3">, </span><span class="s5">&quot;rr&quot;</span><span class="s1">]:</span>
        <span class="s0"># rr = p1 / p2</span>
        <span class="s1">log_rr = np.log(p1) - np.log(p2)</span>
        <span class="s1">log_rr_var = (</span><span class="s4">1 </span><span class="s1">- p1) / p1 / n1 + (</span><span class="s4">1 </span><span class="s1">- p2) / p2 / n2</span>
        <span class="s1">eff = log_rr</span>
        <span class="s1">var_eff = log_rr_var</span>
    <span class="s3">elif </span><span class="s1">statistic </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;odds-ratio&quot;</span><span class="s3">, </span><span class="s5">&quot;or&quot;</span><span class="s1">]:</span>
        <span class="s0"># or_ = p1 / (1 - p1) * (1 - p2) / p2</span>
        <span class="s1">log_or = np.log(p1) - np.log(</span><span class="s4">1 </span><span class="s1">- p1) - np.log(p2) + np.log(</span><span class="s4">1 </span><span class="s1">- p2)</span>
        <span class="s1">log_or_var = </span><span class="s4">1 </span><span class="s1">/ (p1 * (</span><span class="s4">1 </span><span class="s1">- p1) * n1) + </span><span class="s4">1 </span><span class="s1">/ (p2 * (</span><span class="s4">1 </span><span class="s1">- p2) * n2)</span>
        <span class="s1">eff = log_or</span>
        <span class="s1">var_eff = log_or_var</span>
    <span class="s3">elif </span><span class="s1">statistic </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;arcsine&quot;</span><span class="s3">, </span><span class="s5">&quot;arcsin&quot;</span><span class="s3">, </span><span class="s5">&quot;as&quot;</span><span class="s1">]:</span>
        <span class="s1">as_ = np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2))</span>
        <span class="s1">as_var = (</span><span class="s4">1 </span><span class="s1">/ n1 + </span><span class="s4">1 </span><span class="s1">/ n2) / </span><span class="s4">4</span>
        <span class="s1">eff = as_</span>
        <span class="s1">var_eff = as_var</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s5">'statistic not recognized, use one of &quot;rd&quot;, &quot;rr&quot;, &quot;or&quot;, &quot;as&quot;'</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError(msg)</span>

    <span class="s3">return </span><span class="s1">eff</span><span class="s3">, </span><span class="s1">var_eff</span>


<span class="s3">def </span><span class="s1">combine_effects(effect</span><span class="s3">, </span><span class="s1">variance</span><span class="s3">, </span><span class="s1">method_re=</span><span class="s5">&quot;iterated&quot;</span><span class="s3">, </span><span class="s1">row_names=</span><span class="s3">None,</span>
                    <span class="s1">use_t=</span><span class="s3">False, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">**kwds):</span>
    <span class="s2">&quot;&quot;&quot;combining effect sizes for effect sizes using meta-analysis 
 
    This currently does not use np.asarray, all computations are possible in 
    pandas. 
 
    Parameters 
    ---------- 
    effect : array 
        mean of effect size measure for all samples 
    variance : array 
        variance of mean or effect size measure for all samples 
    method_re : {&quot;iterated&quot;, &quot;chi2&quot;} 
        method that is use to compute the between random effects variance 
        &quot;iterated&quot; or &quot;pm&quot; uses Paule and Mandel method to iteratively 
        estimate the random effects variance. Options for the iteration can 
        be provided in the ``kwds`` 
        &quot;chi2&quot; or &quot;dl&quot; uses DerSimonian and Laird one-step estimator. 
    row_names : list of strings (optional) 
        names for samples or studies, will be included in results summary and 
        table. 
    alpha : float in (0, 1) 
        significance level, default is 0.05, for the confidence intervals 
 
    Returns 
    ------- 
    results : CombineResults 
        Contains estimation results and intermediate statistics, and includes 
        a method to return a summary table. 
        Statistics from intermediate calculations might be removed at a later 
        time. 
 
    Notes 
    ----- 
    Status: Basic functionality is verified, mainly compared to R metafor 
    package. However, API might still change. 
 
    This computes both fixed effects and random effects estimates. The 
    random effects results depend on the method to estimate the RE variance. 
 
    Scale estimate 
    In fixed effects models and in random effects models without fully 
    iterated random effects variance, the model will in general not account 
    for all residual variance. Traditional meta-analysis uses a fixed 
    scale equal to 1, that might not produce test statistics and 
    confidence intervals with the correct size. Estimating the scale to account 
    for residual variance often improves the small sample properties of 
    inference and confidence intervals. 
    This adjustment to the standard errors is often referred to as HKSJ 
    method based attributed to Hartung and Knapp and Sidik and Jonkman. 
    However, this is equivalent to estimating the scale in WLS. 
    The results instance includes both, fixed scale and estimated scale 
    versions of standard errors and confidence intervals. 
 
    References 
    ---------- 
    Borenstein, Michael. 2009. Introduction to Meta-Analysis. 
        Chichester: Wiley. 
 
    Chen, Ding-Geng, and Karl E. Peace. 2013. Applied Meta-Analysis with R. 
        Chapman &amp; Hall/CRC Biostatistics Series. 
        Boca Raton: CRC Press/Taylor &amp; Francis Group. 
 
    &quot;&quot;&quot;</span>

    <span class="s1">k = len(effect)</span>
    <span class="s3">if </span><span class="s1">row_names </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">row_names = list(range(k))</span>
    <span class="s1">crit = stats.norm.isf(alpha / </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s0"># alias for initial version</span>
    <span class="s1">eff = effect</span>
    <span class="s1">var_eff = variance</span>
    <span class="s1">sd_eff = np.sqrt(var_eff)</span>

    <span class="s0"># fixed effects computation</span>

    <span class="s1">weights_fe = </span><span class="s4">1 </span><span class="s1">/ var_eff  </span><span class="s0"># no bias correction ?</span>
    <span class="s1">w_total_fe = weights_fe.sum(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">weights_rel_fe = weights_fe / w_total_fe</span>

    <span class="s1">eff_w_fe = weights_rel_fe * eff</span>
    <span class="s1">mean_effect_fe = eff_w_fe.sum()</span>
    <span class="s1">var_eff_w_fe = </span><span class="s4">1 </span><span class="s1">/ w_total_fe</span>
    <span class="s1">sd_eff_w_fe = np.sqrt(var_eff_w_fe)</span>

    <span class="s0"># random effects computation</span>

    <span class="s1">q = (weights_fe * eff**</span><span class="s4">2</span><span class="s1">).sum(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">q -= (weights_fe * eff).sum()**</span><span class="s4">2 </span><span class="s1">/ w_total_fe</span>
    <span class="s1">df = k - </span><span class="s4">1</span>

    <span class="s3">if </span><span class="s1">method_re.lower() </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;iterated&quot;</span><span class="s3">, </span><span class="s5">&quot;pm&quot;</span><span class="s1">]:</span>
        <span class="s1">tau2</span><span class="s3">, </span><span class="s1">_ = _fit_tau_iterative(eff</span><span class="s3">, </span><span class="s1">var_eff</span><span class="s3">, </span><span class="s1">**kwds)</span>
    <span class="s3">elif </span><span class="s1">method_re.lower() </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;chi2&quot;</span><span class="s3">, </span><span class="s5">&quot;dl&quot;</span><span class="s1">]:</span>
        <span class="s1">c = w_total_fe - (weights_fe**</span><span class="s4">2</span><span class="s1">).sum() / w_total_fe</span>
        <span class="s1">tau2 = (q - df) / c</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'method_re should be &quot;iterated&quot; or &quot;chi2&quot;'</span><span class="s1">)</span>

    <span class="s1">weights_re = </span><span class="s4">1 </span><span class="s1">/ (var_eff + tau2)  </span><span class="s0"># no  bias_correction ?</span>
    <span class="s1">w_total_re = weights_re.sum(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">weights_rel_re = weights_re / weights_re.sum(</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">eff_w_re = weights_rel_re * eff</span>
    <span class="s1">mean_effect_re = eff_w_re.sum()</span>
    <span class="s1">var_eff_w_re = </span><span class="s4">1 </span><span class="s1">/ w_total_re</span>
    <span class="s1">sd_eff_w_re = np.sqrt(var_eff_w_re)</span>
    <span class="s0"># ci_low_eff_re = mean_effect_re - crit * sd_eff_w_re</span>
    <span class="s0"># ci_upp_eff_re = mean_effect_re + crit * sd_eff_w_re</span>

    <span class="s1">scale_hksj_re = (weights_re * (eff - mean_effect_re)**</span><span class="s4">2</span><span class="s1">).sum() / df</span>
    <span class="s1">scale_hksj_fe = (weights_fe * (eff - mean_effect_fe)**</span><span class="s4">2</span><span class="s1">).sum() / df</span>
    <span class="s1">var_hksj_re = (weights_rel_re * (eff - mean_effect_re)**</span><span class="s4">2</span><span class="s1">).sum() / df</span>
    <span class="s1">var_hksj_fe = (weights_rel_fe * (eff - mean_effect_fe)**</span><span class="s4">2</span><span class="s1">).sum() / df</span>

    <span class="s1">res = CombineResults(**locals())</span>
    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">_fit_tau_iterative(eff</span><span class="s3">, </span><span class="s1">var_eff</span><span class="s3">, </span><span class="s1">tau2_start=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">50</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Paule-Mandel iterative estimate of between random effect variance 
 
    implementation follows DerSimonian and Kacker 2007 Appendix 8 
    see also Kacker 2004 
 
    Parameters 
    ---------- 
    eff : ndarray 
        effect sizes 
    var_eff : ndarray 
        variance of effect sizes 
    tau2_start : float 
        starting value for iteration 
    atol : float, default: 1e-5 
        convergence tolerance for absolute value of estimating equation 
    maxiter : int 
        maximum number of iterations 
 
    Returns 
    ------- 
    tau2 : float 
        estimate of random effects variance tau squared 
    converged : bool 
        True if iteration has converged. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">tau2 = tau2_start</span>
    <span class="s1">k = eff.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">converged = </span><span class="s3">False</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(maxiter):</span>
        <span class="s1">w = </span><span class="s4">1 </span><span class="s1">/ (var_eff + tau2)</span>
        <span class="s1">m = w.dot(eff) / w.sum(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">resid_sq = (eff - m)**</span><span class="s4">2</span>
        <span class="s1">q_w = w.dot(resid_sq)</span>
        <span class="s0"># estimating equation</span>
        <span class="s1">ee = q_w - (k - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">ee &lt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">tau2 = </span><span class="s4">0</span>
            <span class="s1">converged = </span><span class="s4">0</span>
            <span class="s3">break</span>
        <span class="s3">if </span><span class="s1">np.allclose(ee</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">atol=atol):</span>
            <span class="s1">converged = </span><span class="s3">True</span>
            <span class="s3">break</span>
        <span class="s0"># update tau2</span>
        <span class="s1">delta = ee / (w**</span><span class="s4">2</span><span class="s1">).dot(resid_sq)</span>
        <span class="s1">tau2 += delta</span>

    <span class="s3">return </span><span class="s1">tau2</span><span class="s3">, </span><span class="s1">converged</span>


<span class="s3">def </span><span class="s1">_fit_tau_mm(eff</span><span class="s3">, </span><span class="s1">var_eff</span><span class="s3">, </span><span class="s1">weights):</span>
    <span class="s2">&quot;&quot;&quot;one-step method of moment estimate of between random effect variance 
 
    implementation follows Kacker 2004 and DerSimonian and Kacker 2007 eq. 6 
 
    Parameters 
    ---------- 
    eff : ndarray 
        effect sizes 
    var_eff : ndarray 
        variance of effect sizes 
    weights : ndarray 
        weights for estimating overall weighted mean 
 
    Returns 
    ------- 
    tau2 : float 
        estimate of random effects variance tau squared 
 
    &quot;&quot;&quot;</span>
    <span class="s1">w = weights</span>

    <span class="s1">m = w.dot(eff) / w.sum(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">resid_sq = (eff - m)**</span><span class="s4">2</span>
    <span class="s1">q_w = w.dot(resid_sq)</span>
    <span class="s1">w_t = w.sum()</span>
    <span class="s1">expect = w.dot(var_eff) - (w**</span><span class="s4">2</span><span class="s1">).dot(var_eff) / w_t</span>
    <span class="s1">denom = w_t - (w**</span><span class="s4">2</span><span class="s1">).sum() / w_t</span>
    <span class="s0"># moment estimate from estimating equation</span>
    <span class="s1">tau2 = (q_w - expect) / denom</span>

    <span class="s3">return </span><span class="s1">tau2</span>


<span class="s3">def </span><span class="s1">_fit_tau_iter_mm(eff</span><span class="s3">, </span><span class="s1">var_eff</span><span class="s3">, </span><span class="s1">tau2_start=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">50</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;iterated method of moment estimate of between random effect variance 
 
    This repeatedly estimates tau, updating weights in each iteration 
    see two-step estimators in DerSimonian and Kacker 2007 
 
    Parameters 
    ---------- 
    eff : ndarray 
        effect sizes 
    var_eff : ndarray 
        variance of effect sizes 
    tau2_start : float 
        starting value for iteration 
    atol : float, default: 1e-5 
        convergence tolerance for change in tau2 estimate between iterations 
    maxiter : int 
        maximum number of iterations 
 
    Returns 
    ------- 
    tau2 : float 
        estimate of random effects variance tau squared 
    converged : bool 
        True if iteration has converged. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">tau2 = tau2_start</span>
    <span class="s1">converged = </span><span class="s3">False</span>
    <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range(maxiter):</span>
        <span class="s1">w = </span><span class="s4">1 </span><span class="s1">/ (var_eff + tau2)</span>

        <span class="s1">tau2_new = _fit_tau_mm(eff</span><span class="s3">, </span><span class="s1">var_eff</span><span class="s3">, </span><span class="s1">w)</span>
        <span class="s1">tau2_new = max(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tau2_new)</span>

        <span class="s1">delta = tau2_new - tau2</span>
        <span class="s3">if </span><span class="s1">np.allclose(delta</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">atol=atol):</span>
            <span class="s1">converged = </span><span class="s3">True</span>
            <span class="s3">break</span>

        <span class="s1">tau2 = tau2_new</span>

    <span class="s3">return </span><span class="s1">tau2</span><span class="s3">, </span><span class="s1">converged</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_unsupervised.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_unsupervised.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>
<span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">csc_matrix</span><span class="s0">, </span><span class="s1">csr_matrix</span><span class="s0">, </span><span class="s1">dok_matrix</span><span class="s0">, </span><span class="s1">issparse</span><span class="s0">, </span><span class="s1">lil_matrix</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">datasets</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">pairwise_distances</span>
<span class="s0">from </span><span class="s1">sklearn.metrics.cluster </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">calinski_harabasz_score</span><span class="s0">,</span>
    <span class="s1">davies_bouldin_score</span><span class="s0">,</span>
    <span class="s1">silhouette_samples</span><span class="s0">,</span>
    <span class="s1">silhouette_score</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.metrics.cluster._unsupervised </span><span class="s0">import </span><span class="s1">_silhouette_reduce</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">assert_array_equal</span>


<span class="s0">def </span><span class="s1">test_silhouette():</span>
    <span class="s2"># Tests the Silhouette Coefficient.</span>
    <span class="s1">dataset = datasets.load_iris()</span>
    <span class="s1">X_dense = dataset.data</span>
    <span class="s1">X_csr = csr_matrix(X_dense)</span>
    <span class="s1">X_csc = csc_matrix(X_dense)</span>
    <span class="s1">X_dok = dok_matrix(X_dense)</span>
    <span class="s1">X_lil = lil_matrix(X_dense)</span>
    <span class="s1">y = dataset.target</span>

    <span class="s0">for </span><span class="s1">X </span><span class="s0">in </span><span class="s1">[X_dense</span><span class="s0">, </span><span class="s1">X_csr</span><span class="s0">, </span><span class="s1">X_csc</span><span class="s0">, </span><span class="s1">X_dok</span><span class="s0">, </span><span class="s1">X_lil]:</span>
        <span class="s1">D = pairwise_distances(X</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;euclidean&quot;</span><span class="s1">)</span>
        <span class="s2"># Given that the actual labels are used, we can assume that S would be</span>
        <span class="s2"># positive.</span>
        <span class="s1">score_precomputed = silhouette_score(D</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_precomputed &gt; </span><span class="s4">0</span>
        <span class="s2"># Test without calculating D</span>
        <span class="s1">score_euclidean = silhouette_score(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;euclidean&quot;</span><span class="s1">)</span>
        <span class="s1">pytest.approx(score_precomputed</span><span class="s0">, </span><span class="s1">score_euclidean)</span>

        <span class="s0">if </span><span class="s1">X </span><span class="s0">is </span><span class="s1">X_dense:</span>
            <span class="s1">score_dense_without_sampling = score_precomputed</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">pytest.approx(score_euclidean</span><span class="s0">, </span><span class="s1">score_dense_without_sampling)</span>

        <span class="s2"># Test with sampling</span>
        <span class="s1">score_precomputed = silhouette_score(</span>
            <span class="s1">D</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s0">, </span><span class="s1">sample_size=int(X.shape[</span><span class="s4">0</span><span class="s1">] / </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span>
        <span class="s1">)</span>
        <span class="s1">score_euclidean = silhouette_score(</span>
            <span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;euclidean&quot;</span><span class="s0">, </span><span class="s1">sample_size=int(X.shape[</span><span class="s4">0</span><span class="s1">] / </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_precomputed &gt; </span><span class="s4">0</span>
        <span class="s0">assert </span><span class="s1">score_euclidean &gt; </span><span class="s4">0</span>
        <span class="s1">pytest.approx(score_euclidean</span><span class="s0">, </span><span class="s1">score_precomputed)</span>

        <span class="s0">if </span><span class="s1">X </span><span class="s0">is </span><span class="s1">X_dense:</span>
            <span class="s1">score_dense_with_sampling = score_precomputed</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">pytest.approx(score_euclidean</span><span class="s0">, </span><span class="s1">score_dense_with_sampling)</span>


<span class="s0">def </span><span class="s1">test_cluster_size_1():</span>
    <span class="s2"># Assert Silhouette Coefficient == 0 when there is 1 sample in a cluster</span>
    <span class="s2"># (cluster 0). We also test the case where there are identical samples</span>
    <span class="s2"># as the only members of a cluster (cluster 2). To our knowledge, this case</span>
    <span class="s2"># is not discussed in reference material, and we choose for it a sample</span>
    <span class="s2"># score of 1.</span>
    <span class="s1">X = [[</span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3.0</span><span class="s1">]]</span>
    <span class="s1">labels = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>

    <span class="s2"># Cluster 0: 1 sample -&gt; score of 0 by Rousseeuw's convention</span>
    <span class="s2"># Cluster 1: intra-cluster = [.5, .5, 1]</span>
    <span class="s2">#            inter-cluster = [1, 1, 1]</span>
    <span class="s2">#            silhouette    = [.5, .5, 0]</span>
    <span class="s2"># Cluster 2: intra-cluster = [0, 0]</span>
    <span class="s2">#            inter-cluster = [arbitrary, arbitrary]</span>
    <span class="s2">#            silhouette    = [1., 1.]</span>

    <span class="s1">silhouette = silhouette_score(X</span><span class="s0">, </span><span class="s1">labels)</span>
    <span class="s0">assert not </span><span class="s1">np.isnan(silhouette)</span>
    <span class="s1">ss = silhouette_samples(X</span><span class="s0">, </span><span class="s1">labels)</span>
    <span class="s1">assert_array_equal(ss</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_silhouette_paper_example():</span>
    <span class="s2"># Explicitly check per-sample results against Rousseeuw (1987)</span>
    <span class="s2"># Data from Table 1</span>
    <span class="s1">lower = [</span>
        <span class="s4">5.58</span><span class="s0">,</span>
        <span class="s4">7.00</span><span class="s0">,</span>
        <span class="s4">6.50</span><span class="s0">,</span>
        <span class="s4">7.08</span><span class="s0">,</span>
        <span class="s4">7.00</span><span class="s0">,</span>
        <span class="s4">3.83</span><span class="s0">,</span>
        <span class="s4">4.83</span><span class="s0">,</span>
        <span class="s4">5.08</span><span class="s0">,</span>
        <span class="s4">8.17</span><span class="s0">,</span>
        <span class="s4">5.83</span><span class="s0">,</span>
        <span class="s4">2.17</span><span class="s0">,</span>
        <span class="s4">5.75</span><span class="s0">,</span>
        <span class="s4">6.67</span><span class="s0">,</span>
        <span class="s4">6.92</span><span class="s0">,</span>
        <span class="s4">4.92</span><span class="s0">,</span>
        <span class="s4">6.42</span><span class="s0">,</span>
        <span class="s4">5.00</span><span class="s0">,</span>
        <span class="s4">5.58</span><span class="s0">,</span>
        <span class="s4">6.00</span><span class="s0">,</span>
        <span class="s4">4.67</span><span class="s0">,</span>
        <span class="s4">6.42</span><span class="s0">,</span>
        <span class="s4">3.42</span><span class="s0">,</span>
        <span class="s4">5.50</span><span class="s0">,</span>
        <span class="s4">6.42</span><span class="s0">,</span>
        <span class="s4">6.42</span><span class="s0">,</span>
        <span class="s4">5.00</span><span class="s0">,</span>
        <span class="s4">3.92</span><span class="s0">,</span>
        <span class="s4">6.17</span><span class="s0">,</span>
        <span class="s4">2.50</span><span class="s0">,</span>
        <span class="s4">4.92</span><span class="s0">,</span>
        <span class="s4">6.25</span><span class="s0">,</span>
        <span class="s4">7.33</span><span class="s0">,</span>
        <span class="s4">4.50</span><span class="s0">,</span>
        <span class="s4">2.25</span><span class="s0">,</span>
        <span class="s4">6.33</span><span class="s0">,</span>
        <span class="s4">2.75</span><span class="s0">,</span>
        <span class="s4">6.08</span><span class="s0">,</span>
        <span class="s4">6.67</span><span class="s0">,</span>
        <span class="s4">4.25</span><span class="s0">,</span>
        <span class="s4">2.67</span><span class="s0">,</span>
        <span class="s4">6.00</span><span class="s0">,</span>
        <span class="s4">6.17</span><span class="s0">,</span>
        <span class="s4">6.17</span><span class="s0">,</span>
        <span class="s4">6.92</span><span class="s0">,</span>
        <span class="s4">6.17</span><span class="s0">,</span>
        <span class="s4">5.25</span><span class="s0">,</span>
        <span class="s4">6.83</span><span class="s0">,</span>
        <span class="s4">4.50</span><span class="s0">,</span>
        <span class="s4">3.75</span><span class="s0">,</span>
        <span class="s4">5.75</span><span class="s0">,</span>
        <span class="s4">5.42</span><span class="s0">,</span>
        <span class="s4">6.08</span><span class="s0">,</span>
        <span class="s4">5.83</span><span class="s0">,</span>
        <span class="s4">6.67</span><span class="s0">,</span>
        <span class="s4">3.67</span><span class="s0">,</span>
        <span class="s4">4.75</span><span class="s0">,</span>
        <span class="s4">3.00</span><span class="s0">,</span>
        <span class="s4">6.08</span><span class="s0">,</span>
        <span class="s4">6.67</span><span class="s0">,</span>
        <span class="s4">5.00</span><span class="s0">,</span>
        <span class="s4">5.58</span><span class="s0">,</span>
        <span class="s4">4.83</span><span class="s0">,</span>
        <span class="s4">6.17</span><span class="s0">,</span>
        <span class="s4">5.67</span><span class="s0">,</span>
        <span class="s4">6.50</span><span class="s0">,</span>
        <span class="s4">6.92</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">D = np.zeros((</span><span class="s4">12</span><span class="s0">, </span><span class="s4">12</span><span class="s1">))</span>
    <span class="s1">D[np.tril_indices(</span><span class="s4">12</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)] = lower</span>
    <span class="s1">D += D.T</span>

    <span class="s1">names = [</span>
        <span class="s3">&quot;BEL&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;BRA&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;CHI&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;CUB&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;EGY&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;FRA&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;IND&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;ISR&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;USA&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;USS&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;YUG&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;ZAI&quot;</span><span class="s0">,</span>
    <span class="s1">]</span>

    <span class="s2"># Data from Figure 2</span>
    <span class="s1">labels1 = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">expected1 = {</span>
        <span class="s3">&quot;USA&quot;</span><span class="s1">: </span><span class="s4">0.43</span><span class="s0">,</span>
        <span class="s3">&quot;BEL&quot;</span><span class="s1">: </span><span class="s4">0.39</span><span class="s0">,</span>
        <span class="s3">&quot;FRA&quot;</span><span class="s1">: </span><span class="s4">0.35</span><span class="s0">,</span>
        <span class="s3">&quot;ISR&quot;</span><span class="s1">: </span><span class="s4">0.30</span><span class="s0">,</span>
        <span class="s3">&quot;BRA&quot;</span><span class="s1">: </span><span class="s4">0.22</span><span class="s0">,</span>
        <span class="s3">&quot;EGY&quot;</span><span class="s1">: </span><span class="s4">0.20</span><span class="s0">,</span>
        <span class="s3">&quot;ZAI&quot;</span><span class="s1">: </span><span class="s4">0.19</span><span class="s0">,</span>
        <span class="s3">&quot;CUB&quot;</span><span class="s1">: </span><span class="s4">0.40</span><span class="s0">,</span>
        <span class="s3">&quot;USS&quot;</span><span class="s1">: </span><span class="s4">0.34</span><span class="s0">,</span>
        <span class="s3">&quot;CHI&quot;</span><span class="s1">: </span><span class="s4">0.33</span><span class="s0">,</span>
        <span class="s3">&quot;YUG&quot;</span><span class="s1">: </span><span class="s4">0.26</span><span class="s0">,</span>
        <span class="s3">&quot;IND&quot;</span><span class="s1">: -</span><span class="s4">0.04</span><span class="s0">,</span>
    <span class="s1">}</span>
    <span class="s1">score1 = </span><span class="s4">0.28</span>

    <span class="s2"># Data from Figure 3</span>
    <span class="s1">labels2 = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">expected2 = {</span>
        <span class="s3">&quot;USA&quot;</span><span class="s1">: </span><span class="s4">0.47</span><span class="s0">,</span>
        <span class="s3">&quot;FRA&quot;</span><span class="s1">: </span><span class="s4">0.44</span><span class="s0">,</span>
        <span class="s3">&quot;BEL&quot;</span><span class="s1">: </span><span class="s4">0.42</span><span class="s0">,</span>
        <span class="s3">&quot;ISR&quot;</span><span class="s1">: </span><span class="s4">0.37</span><span class="s0">,</span>
        <span class="s3">&quot;EGY&quot;</span><span class="s1">: </span><span class="s4">0.02</span><span class="s0">,</span>
        <span class="s3">&quot;ZAI&quot;</span><span class="s1">: </span><span class="s4">0.28</span><span class="s0">,</span>
        <span class="s3">&quot;BRA&quot;</span><span class="s1">: </span><span class="s4">0.25</span><span class="s0">,</span>
        <span class="s3">&quot;IND&quot;</span><span class="s1">: </span><span class="s4">0.17</span><span class="s0">,</span>
        <span class="s3">&quot;CUB&quot;</span><span class="s1">: </span><span class="s4">0.48</span><span class="s0">,</span>
        <span class="s3">&quot;USS&quot;</span><span class="s1">: </span><span class="s4">0.44</span><span class="s0">,</span>
        <span class="s3">&quot;YUG&quot;</span><span class="s1">: </span><span class="s4">0.31</span><span class="s0">,</span>
        <span class="s3">&quot;CHI&quot;</span><span class="s1">: </span><span class="s4">0.31</span><span class="s0">,</span>
    <span class="s1">}</span>
    <span class="s1">score2 = </span><span class="s4">0.33</span>

    <span class="s0">for </span><span class="s1">labels</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">score </span><span class="s0">in </span><span class="s1">[</span>
        <span class="s1">(labels1</span><span class="s0">, </span><span class="s1">expected1</span><span class="s0">, </span><span class="s1">score1)</span><span class="s0">,</span>
        <span class="s1">(labels2</span><span class="s0">, </span><span class="s1">expected2</span><span class="s0">, </span><span class="s1">score2)</span><span class="s0">,</span>
    <span class="s1">]:</span>
        <span class="s1">expected = [expected[name] </span><span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">names]</span>
        <span class="s2"># we check to 2dp because that's what's in the paper</span>
        <span class="s1">pytest.approx(</span>
            <span class="s1">expected</span><span class="s0">,</span>
            <span class="s1">silhouette_samples(D</span><span class="s0">, </span><span class="s1">np.array(labels)</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span><span class="s0">,</span>
            <span class="s1">abs=</span><span class="s4">1e-2</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">pytest.approx(</span>
            <span class="s1">score</span><span class="s0">, </span><span class="s1">silhouette_score(D</span><span class="s0">, </span><span class="s1">np.array(labels)</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s1">abs=</span><span class="s4">1e-2</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_correct_labelsize():</span>
    <span class="s2"># Assert 1 &lt; n_labels &lt; n_samples</span>
    <span class="s1">dataset = datasets.load_iris()</span>
    <span class="s1">X = dataset.data</span>

    <span class="s2"># n_labels = n_samples</span>
    <span class="s1">y = np.arange(X.shape[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">err_msg = (</span>
        <span class="s3">r&quot;Number of labels is %d\. Valid values are 2 &quot;</span>
        <span class="s3">r&quot;to n_samples - 1 \(inclusive\)&quot; </span><span class="s1">% len(np.unique(y))</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">silhouette_score(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># n_labels = 1</span>
    <span class="s1">y = np.zeros(X.shape[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">err_msg = (</span>
        <span class="s3">r&quot;Number of labels is %d\. Valid values are 2 &quot;</span>
        <span class="s3">r&quot;to n_samples - 1 \(inclusive\)&quot; </span><span class="s1">% len(np.unique(y))</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">silhouette_score(X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s0">def </span><span class="s1">test_non_encoded_labels():</span>
    <span class="s1">dataset = datasets.load_iris()</span>
    <span class="s1">X = dataset.data</span>
    <span class="s1">labels = dataset.target</span>
    <span class="s0">assert </span><span class="s1">silhouette_score(X</span><span class="s0">, </span><span class="s1">labels * </span><span class="s4">2 </span><span class="s1">+ </span><span class="s4">10</span><span class="s1">) == silhouette_score(X</span><span class="s0">, </span><span class="s1">labels)</span>
    <span class="s1">assert_array_equal(</span>
        <span class="s1">silhouette_samples(X</span><span class="s0">, </span><span class="s1">labels * </span><span class="s4">2 </span><span class="s1">+ </span><span class="s4">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">silhouette_samples(X</span><span class="s0">, </span><span class="s1">labels)</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_non_numpy_labels():</span>
    <span class="s1">dataset = datasets.load_iris()</span>
    <span class="s1">X = dataset.data</span>
    <span class="s1">y = dataset.target</span>
    <span class="s0">assert </span><span class="s1">silhouette_score(list(X)</span><span class="s0">, </span><span class="s1">list(y)) == silhouette_score(X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float64))</span>
<span class="s0">def </span><span class="s1">test_silhouette_nonzero_diag(dtype):</span>
    <span class="s2"># Make sure silhouette_samples requires diagonal to be zero.</span>
    <span class="s2"># Non-regression test for #12178</span>

    <span class="s2"># Construct a zero-diagonal matrix</span>
    <span class="s1">dists = pairwise_distances(</span>
        <span class="s1">np.array([[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.12</span><span class="s0">, </span><span class="s4">1.34</span><span class="s0">, </span><span class="s4">1.11</span><span class="s0">, </span><span class="s4">1.6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=dtype).T</span>
    <span class="s1">)</span>
    <span class="s1">labels = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>

    <span class="s2"># small values on the diagonal are OK</span>
    <span class="s1">dists[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] = np.finfo(dists.dtype).eps * </span><span class="s4">10</span>
    <span class="s1">silhouette_samples(dists</span><span class="s0">, </span><span class="s1">labels</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span>

    <span class="s2"># values bigger than eps * 100 are not</span>
    <span class="s1">dists[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] = np.finfo(dists.dtype).eps * </span><span class="s4">1000</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;contains non-zero&quot;</span><span class="s1">):</span>
        <span class="s1">silhouette_samples(dists</span><span class="s0">, </span><span class="s1">labels</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;to_sparse&quot;</span><span class="s0">, </span><span class="s1">(csr_matrix</span><span class="s0">, </span><span class="s1">csc_matrix</span><span class="s0">, </span><span class="s1">dok_matrix</span><span class="s0">, </span><span class="s1">lil_matrix))</span>
<span class="s0">def </span><span class="s1">test_silhouette_samples_precomputed_sparse(to_sparse):</span>
    <span class="s5">&quot;&quot;&quot;Check that silhouette_samples works for sparse matrices correctly.&quot;&quot;&quot;</span>
    <span class="s1">X = np.array([[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">1.6</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float32).T</span>
    <span class="s1">y = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">pdist_dense = pairwise_distances(X)</span>
    <span class="s1">pdist_sparse = to_sparse(pdist_dense)</span>
    <span class="s0">assert </span><span class="s1">issparse(pdist_sparse)</span>
    <span class="s1">output_with_sparse_input = silhouette_samples(pdist_sparse</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span>
    <span class="s1">output_with_dense_input = silhouette_samples(pdist_dense</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span><span class="s1">)</span>
    <span class="s1">assert_allclose(output_with_sparse_input</span><span class="s0">, </span><span class="s1">output_with_dense_input)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;to_sparse&quot;</span><span class="s0">, </span><span class="s1">(csr_matrix</span><span class="s0">, </span><span class="s1">csc_matrix</span><span class="s0">, </span><span class="s1">dok_matrix</span><span class="s0">, </span><span class="s1">lil_matrix))</span>
<span class="s0">def </span><span class="s1">test_silhouette_samples_euclidean_sparse(to_sparse):</span>
    <span class="s5">&quot;&quot;&quot;Check that silhouette_samples works for sparse matrices correctly.&quot;&quot;&quot;</span>
    <span class="s1">X = np.array([[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">1.6</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float32).T</span>
    <span class="s1">y = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">pdist_dense = pairwise_distances(X)</span>
    <span class="s1">pdist_sparse = to_sparse(pdist_dense)</span>
    <span class="s0">assert </span><span class="s1">issparse(pdist_sparse)</span>
    <span class="s1">output_with_sparse_input = silhouette_samples(pdist_sparse</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">output_with_dense_input = silhouette_samples(pdist_dense</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_allclose(output_with_sparse_input</span><span class="s0">, </span><span class="s1">output_with_dense_input)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;to_non_csr_sparse&quot;</span><span class="s0">, </span><span class="s1">(csc_matrix</span><span class="s0">, </span><span class="s1">dok_matrix</span><span class="s0">, </span><span class="s1">lil_matrix))</span>
<span class="s0">def </span><span class="s1">test_silhouette_reduce(to_non_csr_sparse):</span>
    <span class="s5">&quot;&quot;&quot;Check for non-CSR input to private method `_silhouette_reduce`.&quot;&quot;&quot;</span>
    <span class="s1">X = np.array([[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">1.6</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float32).T</span>
    <span class="s1">pdist_dense = pairwise_distances(X)</span>
    <span class="s1">pdist_sparse = to_non_csr_sparse(pdist_dense)</span>
    <span class="s1">y = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">label_freqs = np.bincount(y)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(</span>
        <span class="s1">TypeError</span><span class="s0">,</span>
        <span class="s1">match=</span><span class="s3">&quot;Expected CSR matrix. Please pass sparse matrix in CSR format.&quot;</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">_silhouette_reduce(pdist_sparse</span><span class="s0">, </span><span class="s1">start=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">labels=y</span><span class="s0">, </span><span class="s1">label_freqs=label_freqs)</span>


<span class="s0">def </span><span class="s1">assert_raises_on_only_one_label(func):</span>
    <span class="s5">&quot;&quot;&quot;Assert message when there is only one label&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(seed=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;Number of labels is&quot;</span><span class="s1">):</span>
        <span class="s1">func(rng.rand(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.zeros(</span><span class="s4">10</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">assert_raises_on_all_points_same_cluster(func):</span>
    <span class="s5">&quot;&quot;&quot;Assert message when all point are in different clusters&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(seed=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;Number of labels is&quot;</span><span class="s1">):</span>
        <span class="s1">func(rng.rand(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.arange(</span><span class="s4">10</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">test_calinski_harabasz_score():</span>
    <span class="s1">assert_raises_on_only_one_label(calinski_harabasz_score)</span>

    <span class="s1">assert_raises_on_all_points_same_cluster(calinski_harabasz_score)</span>

    <span class="s2"># Assert the value is 1. when all samples are equals</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s1">== calinski_harabasz_score(np.ones((</span><span class="s4">10</span><span class="s0">, </span><span class="s4">2</span><span class="s1">))</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">5 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">5</span><span class="s1">)</span>

    <span class="s2"># Assert the value is 0. when all the mean cluster are equal</span>
    <span class="s0">assert </span><span class="s4">0.0 </span><span class="s1">== calinski_harabasz_score([[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]] * </span><span class="s4">10</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">10</span><span class="s1">)</span>

    <span class="s2"># General case (with non numpy arrays)</span>
    <span class="s1">X = (</span>
        <span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]] * </span><span class="s4">5</span>
    <span class="s1">)</span>
    <span class="s1">labels = [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">3</span><span class="s1">] * </span><span class="s4">10</span>
    <span class="s1">pytest.approx(calinski_harabasz_score(X</span><span class="s0">, </span><span class="s1">labels)</span><span class="s0">, </span><span class="s4">45 </span><span class="s1">* (</span><span class="s4">40 </span><span class="s1">- </span><span class="s4">4</span><span class="s1">) / (</span><span class="s4">5 </span><span class="s1">* (</span><span class="s4">4 </span><span class="s1">- </span><span class="s4">1</span><span class="s1">)))</span>


<span class="s0">def </span><span class="s1">test_davies_bouldin_score():</span>
    <span class="s1">assert_raises_on_only_one_label(davies_bouldin_score)</span>
    <span class="s1">assert_raises_on_all_points_same_cluster(davies_bouldin_score)</span>

    <span class="s2"># Assert the value is 0. when all samples are equals</span>
    <span class="s0">assert </span><span class="s1">davies_bouldin_score(np.ones((</span><span class="s4">10</span><span class="s0">, </span><span class="s4">2</span><span class="s1">))</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">5 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">5</span><span class="s1">) == pytest.approx(</span>
        <span class="s4">0.0</span>
    <span class="s1">)</span>

    <span class="s2"># Assert the value is 0. when all the mean cluster are equal</span>
    <span class="s0">assert </span><span class="s1">davies_bouldin_score(</span>
        <span class="s1">[[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]] * </span><span class="s4">10</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">10</span>
    <span class="s1">) == pytest.approx(</span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># General case (with non numpy arrays)</span>
    <span class="s1">X = (</span>
        <span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]] * </span><span class="s4">5</span>
        <span class="s1">+ [[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]] * </span><span class="s4">5</span>
    <span class="s1">)</span>
    <span class="s1">labels = [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">3</span><span class="s1">] * </span><span class="s4">10</span>
    <span class="s1">pytest.approx(davies_bouldin_score(X</span><span class="s0">, </span><span class="s1">labels)</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">* np.sqrt(</span><span class="s4">0.5</span><span class="s1">) / </span><span class="s4">3</span><span class="s1">)</span>

    <span class="s2"># Ensure divide by zero warning is not raised in general case</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;error&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s1">davies_bouldin_score(X</span><span class="s0">, </span><span class="s1">labels)</span>

    <span class="s2"># General case - cluster have one sample</span>
    <span class="s1">X = [[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">5</span><span class="s0">, </span><span class="s4">5</span><span class="s1">]]</span>
    <span class="s1">labels = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">pytest.approx(davies_bouldin_score(X</span><span class="s0">, </span><span class="s1">labels)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">5.0 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">) / </span><span class="s4">3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_silhouette_score_integer_precomputed():</span>
    <span class="s5">&quot;&quot;&quot;Check that silhouette_score works for precomputed metrics that are integers. 
 
    Non-regression test for #22107. 
    &quot;&quot;&quot;</span>
    <span class="s1">result = silhouette_score(</span>
        <span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">result == pytest.approx(</span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">6</span><span class="s1">)</span>

    <span class="s2"># non-zero on diagonal for ints raises an error</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;contains non-zero&quot;</span><span class="s1">):</span>
        <span class="s1">silhouette_score(</span>
            <span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">metric=</span><span class="s3">&quot;precomputed&quot;</span>
        <span class="s1">)</span>
</pre>
</body>
</html>
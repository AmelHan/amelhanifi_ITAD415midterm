<html>
<head>
<title>test_boost_ufuncs.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_boost_ufuncs.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>
<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">_boost</span>


<span class="s1">type_char_to_type_tol = {</span><span class="s2">'f'</span><span class="s1">: (np.float32</span><span class="s0">, </span><span class="s3">32</span><span class="s1">*np.finfo(np.float32).eps)</span><span class="s0">,</span>
                         <span class="s2">'d'</span><span class="s1">: (np.float64</span><span class="s0">, </span><span class="s3">32</span><span class="s1">*np.finfo(np.float64).eps)}</span>


<span class="s4"># Each item in this list is</span>
<span class="s4">#   (func, args, expected_value)</span>
<span class="s4"># All the values can be represented exactly, even with np.float32.</span>
<span class="s4">#</span>
<span class="s4"># This is not an exhaustive test data set of all the functions!</span>
<span class="s4"># It is a spot check of several functions, primarily for</span>
<span class="s4"># checking that the different data types are handled correctly.</span>
<span class="s1">test_data = [</span>
    <span class="s1">(_boost._beta_cdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.6875</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_ppf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.6875</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_pdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s3">1.5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_pdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span><span class="s0">, </span><span class="s3">5.0</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_pdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s3">5.0</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_sf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.75</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._beta_isf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.75</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._binom_cdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._binom_pdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.25</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._hypergeom_cdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._nbinom_cdf</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">0.25</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.015625</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(_boost._ncf_mean</span><span class="s0">, </span><span class="s1">(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">)</span><span class="s0">, </span><span class="s3">1.5</span><span class="s1">)</span><span class="s0">,</span>
<span class="s1">]</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">'func, args, expected'</span><span class="s0">, </span><span class="s1">test_data)</span>
<span class="s0">def </span><span class="s1">test_stats_boost_ufunc(func</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">expected):</span>
    <span class="s1">type_sigs = func.types</span>
    <span class="s1">type_chars = [sig.split(</span><span class="s2">'-&gt;'</span><span class="s1">)[-</span><span class="s3">1</span><span class="s1">] </span><span class="s0">for </span><span class="s1">sig </span><span class="s0">in </span><span class="s1">type_sigs]</span>
    <span class="s0">for </span><span class="s1">type_char </span><span class="s0">in </span><span class="s1">type_chars:</span>
        <span class="s1">typ</span><span class="s0">, </span><span class="s1">rtol = type_char_to_type_tol[type_char]</span>
        <span class="s1">args = [typ(arg) </span><span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args]</span>
        <span class="s4"># Harmless overflow warnings are a &quot;feature&quot; of some wrappers on some</span>
        <span class="s4"># plaforms. This test is about dtype and accuracy, so let's avoid false</span>
        <span class="s4"># test failures cause by these warnings. See gh-17432.</span>
        <span class="s0">with </span><span class="s1">np.errstate(over=</span><span class="s2">'ignore'</span><span class="s1">):</span>
            <span class="s1">value = func(*args)</span>
        <span class="s0">assert </span><span class="s1">isinstance(value</span><span class="s0">, </span><span class="s1">typ)</span>
        <span class="s1">assert_allclose(value</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
</pre>
</body>
</html>
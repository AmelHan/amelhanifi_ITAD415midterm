<html>
<head>
<title>class_weight.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
class_weight.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: Andreas Mueller</span>
<span class="s0">#          Manoj Kumar</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">sparse</span>


<span class="s2">def </span><span class="s1">compute_class_weight(class_weight</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">, </span><span class="s1">y):</span>
    <span class="s3">&quot;&quot;&quot;Estimate class weights for unbalanced datasets. 
 
    Parameters 
    ---------- 
    class_weight : dict, 'balanced' or None 
        If 'balanced', class weights will be given by 
        ``n_samples / (n_classes * np.bincount(y))``. 
        If a dictionary is given, keys are classes and values 
        are corresponding class weights. 
        If None is given, the class weights will be uniform. 
 
    classes : ndarray 
        Array of the classes occurring in the data, as given by 
        ``np.unique(y_org)`` with ``y_org`` the original class labels. 
 
    y : array-like of shape (n_samples,) 
        Array of original class labels per sample. 
 
    Returns 
    ------- 
    class_weight_vect : ndarray of shape (n_classes,) 
        Array with class_weight_vect[i] the weight for i-th class. 
 
    References 
    ---------- 
    The &quot;balanced&quot; heuristic is inspired by 
    Logistic Regression in Rare Events Data, King, Zen, 2001. 
    &quot;&quot;&quot;</span>
    <span class="s0"># Import error caused by circular imports.</span>
    <span class="s2">from </span><span class="s1">..preprocessing </span><span class="s2">import </span><span class="s1">LabelEncoder</span>

    <span class="s2">if </span><span class="s1">set(y) - set(classes):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;classes should include all valid labels that can be in y&quot;</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">class_weight </span><span class="s2">is None or </span><span class="s1">len(class_weight) == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s0"># uniform class weights</span>
        <span class="s1">weight = np.ones(classes.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=np.float64</span><span class="s2">, </span><span class="s1">order=</span><span class="s4">&quot;C&quot;</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">class_weight == </span><span class="s4">&quot;balanced&quot;</span><span class="s1">:</span>
        <span class="s0"># Find the weight of each class as present in y.</span>
        <span class="s1">le = LabelEncoder()</span>
        <span class="s1">y_ind = le.fit_transform(y)</span>
        <span class="s2">if not </span><span class="s1">all(np.isin(classes</span><span class="s2">, </span><span class="s1">le.classes_)):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;classes should have valid labels that are in y&quot;</span><span class="s1">)</span>

        <span class="s1">recip_freq = len(y) / (len(le.classes_) * np.bincount(y_ind).astype(np.float64))</span>
        <span class="s1">weight = recip_freq[le.transform(classes)]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s0"># user-defined dictionary</span>
        <span class="s1">weight = np.ones(classes.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=np.float64</span><span class="s2">, </span><span class="s1">order=</span><span class="s4">&quot;C&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">isinstance(class_weight</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;class_weight must be dict, 'balanced', or None, got: %r&quot; </span><span class="s1">% class_weight</span>
            <span class="s1">)</span>
        <span class="s1">unweighted_classes = []</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">c </span><span class="s2">in </span><span class="s1">enumerate(classes):</span>
            <span class="s2">if </span><span class="s1">c </span><span class="s2">in </span><span class="s1">class_weight:</span>
                <span class="s1">weight[i] = class_weight[c]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">unweighted_classes.append(c)</span>

        <span class="s1">n_weighted_classes = len(classes) - len(unweighted_classes)</span>
        <span class="s2">if </span><span class="s1">unweighted_classes </span><span class="s2">and </span><span class="s1">n_weighted_classes != len(class_weight):</span>
            <span class="s1">unweighted_classes_user_friendly_str = np.array(unweighted_classes).tolist()</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;The classes, </span><span class="s2">{</span><span class="s1">unweighted_classes_user_friendly_str</span><span class="s2">}</span><span class="s4">, are not in&quot;</span>
                <span class="s4">&quot; class_weight&quot;</span>
            <span class="s1">)</span>

    <span class="s2">return </span><span class="s1">weight</span>


<span class="s2">def </span><span class="s1">compute_sample_weight(class_weight</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">indices=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot;Estimate sample weights by class for unbalanced datasets. 
 
    Parameters 
    ---------- 
    class_weight : dict, list of dicts, &quot;balanced&quot;, or None 
        Weights associated with classes in the form ``{class_label: weight}``. 
        If not given, all classes are supposed to have weight one. For 
        multi-output problems, a list of dicts can be provided in the same 
        order as the columns of y. 
 
        Note that for multioutput (including multilabel) weights should be 
        defined for each class of every column in its own dict. For example, 
        for four-class multilabel classification weights should be 
        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of 
        [{1:1}, {2:5}, {3:1}, {4:1}]. 
 
        The &quot;balanced&quot; mode uses the values of y to automatically adjust 
        weights inversely proportional to class frequencies in the input data: 
        ``n_samples / (n_classes * np.bincount(y))``. 
 
        For multi-output, the weights of each column of y will be multiplied. 
 
    y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs) 
        Array of original class labels per sample. 
 
    indices : array-like of shape (n_subsample,), default=None 
        Array of indices to be used in a subsample. Can be of length less than 
        n_samples in the case of a subsample, or equal to n_samples in the 
        case of a bootstrap subsample with repeated indices. If None, the 
        sample weight will be calculated over the full sample. Only &quot;balanced&quot; 
        is supported for class_weight if this is provided. 
 
    Returns 
    ------- 
    sample_weight_vect : ndarray of shape (n_samples,) 
        Array with sample weights as applied to the original y. 
    &quot;&quot;&quot;</span>

    <span class="s0"># Ensure y is 2D. Sparse matrices are already 2D.</span>
    <span class="s2">if not </span><span class="s1">sparse.issparse(y):</span>
        <span class="s1">y = np.atleast_1d(y)</span>
        <span class="s2">if </span><span class="s1">y.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">y = np.reshape(y</span><span class="s2">, </span><span class="s1">(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">n_outputs = y.shape[</span><span class="s5">1</span><span class="s1">]</span>

    <span class="s2">if </span><span class="s1">isinstance(class_weight</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s2">if </span><span class="s1">class_weight </span><span class="s2">not in </span><span class="s1">[</span><span class="s4">&quot;balanced&quot;</span><span class="s1">]:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">'The only valid preset for class_weight is &quot;balanced&quot;. Given &quot;%s&quot;.'</span>
                <span class="s1">% class_weight</span>
            <span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">indices </span><span class="s2">is not None and not </span><span class="s1">isinstance(class_weight</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s4">'The only valid class_weight for subsampling is &quot;balanced&quot;. Given &quot;%s&quot;.'</span>
            <span class="s1">% class_weight</span>
        <span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">n_outputs &gt; </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s2">if not </span><span class="s1">hasattr(class_weight</span><span class="s2">, </span><span class="s4">&quot;__iter__&quot;</span><span class="s1">) </span><span class="s2">or </span><span class="s1">isinstance(class_weight</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;For multi-output, class_weight should be a &quot;</span>
                <span class="s4">&quot;list of dicts, or a valid string.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(class_weight) != n_outputs:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;For multi-output, number of elements in &quot;</span>
                <span class="s4">&quot;class_weight should match number of outputs.&quot;</span>
            <span class="s1">)</span>

    <span class="s1">expanded_class_weight = []</span>
    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(n_outputs):</span>
        <span class="s1">y_full = y[:</span><span class="s2">, </span><span class="s1">k]</span>
        <span class="s2">if </span><span class="s1">sparse.issparse(y_full):</span>
            <span class="s0"># Ok to densify a single column at a time</span>
            <span class="s1">y_full = y_full.toarray().flatten()</span>
        <span class="s1">classes_full = np.unique(y_full)</span>
        <span class="s1">classes_missing = </span><span class="s2">None</span>

        <span class="s2">if </span><span class="s1">class_weight == </span><span class="s4">&quot;balanced&quot; </span><span class="s2">or </span><span class="s1">n_outputs == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">class_weight_k = class_weight</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">class_weight_k = class_weight[k]</span>

        <span class="s2">if </span><span class="s1">indices </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># Get class weights for the subsample, covering all classes in</span>
            <span class="s0"># case some labels that were present in the original data are</span>
            <span class="s0"># missing from the sample.</span>
            <span class="s1">y_subsample = y_full[indices]</span>
            <span class="s1">classes_subsample = np.unique(y_subsample)</span>

            <span class="s1">weight_k = np.take(</span>
                <span class="s1">compute_class_weight(</span>
                    <span class="s1">class_weight_k</span><span class="s2">, </span><span class="s1">classes=classes_subsample</span><span class="s2">, </span><span class="s1">y=y_subsample</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">np.searchsorted(classes_subsample</span><span class="s2">, </span><span class="s1">classes_full)</span><span class="s2">,</span>
                <span class="s1">mode=</span><span class="s4">&quot;clip&quot;</span><span class="s2">,</span>
            <span class="s1">)</span>

            <span class="s1">classes_missing = set(classes_full) - set(classes_subsample)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">weight_k = compute_class_weight(</span>
                <span class="s1">class_weight_k</span><span class="s2">, </span><span class="s1">classes=classes_full</span><span class="s2">, </span><span class="s1">y=y_full</span>
            <span class="s1">)</span>

        <span class="s1">weight_k = weight_k[np.searchsorted(classes_full</span><span class="s2">, </span><span class="s1">y_full)]</span>

        <span class="s2">if </span><span class="s1">classes_missing:</span>
            <span class="s0"># Make missing classes' weight zero</span>
            <span class="s1">weight_k[np.isin(y_full</span><span class="s2">, </span><span class="s1">list(classes_missing))] = </span><span class="s5">0.0</span>

        <span class="s1">expanded_class_weight.append(weight_k)</span>

    <span class="s1">expanded_class_weight = np.prod(expanded_class_weight</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

    <span class="s2">return </span><span class="s1">expanded_class_weight</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_lobpcg.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_lobpcg.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; Test functions for the sparse.linalg._eigen.lobpcg module 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">itertools</span>
<span class="s2">import </span><span class="s1">platform</span>
<span class="s2">import </span><span class="s1">sys</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy </span><span class="s2">import </span><span class="s1">ones</span><span class="s2">, </span><span class="s1">r_</span><span class="s2">, </span><span class="s1">diag</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">(assert_almost_equal</span><span class="s2">, </span><span class="s1">assert_equal</span><span class="s2">,</span>
                           <span class="s1">assert_allclose</span><span class="s2">, </span><span class="s1">assert_array_less)</span>

<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">sparse</span>
<span class="s2">from </span><span class="s1">scipy.linalg </span><span class="s2">import </span><span class="s1">eig</span><span class="s2">, </span><span class="s1">eigh</span><span class="s2">, </span><span class="s1">toeplitz</span><span class="s2">, </span><span class="s1">orth</span>
<span class="s2">from </span><span class="s1">scipy.sparse </span><span class="s2">import </span><span class="s1">spdiags</span><span class="s2">, </span><span class="s1">diags</span><span class="s2">, </span><span class="s1">eye</span><span class="s2">, </span><span class="s1">csr_matrix</span>
<span class="s2">from </span><span class="s1">scipy.sparse.linalg </span><span class="s2">import </span><span class="s1">eigs</span><span class="s2">, </span><span class="s1">LinearOperator</span>
<span class="s2">from </span><span class="s1">scipy.sparse.linalg._eigen.lobpcg </span><span class="s2">import </span><span class="s1">lobpcg</span>
<span class="s2">from </span><span class="s1">scipy.sparse.linalg._eigen.lobpcg.lobpcg </span><span class="s2">import </span><span class="s1">_b_orthonormalize</span>

<span class="s1">_IS_32BIT = (sys.maxsize &lt; </span><span class="s3">2</span><span class="s1">**</span><span class="s3">32</span><span class="s1">)</span>

<span class="s1">INT_DTYPES = {np.intc</span><span class="s2">, </span><span class="s1">np.int_</span><span class="s2">, </span><span class="s1">np.longlong</span><span class="s2">, </span><span class="s1">np.uintc</span><span class="s2">, </span><span class="s1">np.uint</span><span class="s2">, </span><span class="s1">np.ulonglong}</span>
<span class="s4"># np.half is unsupported on many test systems so excluded</span>
<span class="s1">REAL_DTYPES = {np.single</span><span class="s2">, </span><span class="s1">np.double</span><span class="s2">, </span><span class="s1">np.longdouble}</span>
<span class="s1">COMPLEX_DTYPES = {np.csingle</span><span class="s2">, </span><span class="s1">np.cdouble</span><span class="s2">, </span><span class="s1">np.clongdouble}</span>
<span class="s4"># use sorted tuple to ensure fixed order of tests</span>
<span class="s1">VDTYPES = tuple(sorted(REAL_DTYPES ^ COMPLEX_DTYPES</span><span class="s2">, </span><span class="s1">key=str))</span>
<span class="s1">MDTYPES = tuple(sorted(INT_DTYPES ^ REAL_DTYPES ^ COMPLEX_DTYPES</span><span class="s2">, </span><span class="s1">key=str))</span>


<span class="s2">def </span><span class="s1">sign_align(A</span><span class="s2">, </span><span class="s1">B):</span>
    <span class="s0">&quot;&quot;&quot;Align signs of columns of A match those of B: column-wise remove 
    sign of A by multiplying with its sign then multiply in sign of B. 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">np.array([col_A * np.sign(col_A[</span><span class="s3">0</span><span class="s1">]) * np.sign(col_B[</span><span class="s3">0</span><span class="s1">])</span>
                     <span class="s2">for </span><span class="s1">col_A</span><span class="s2">, </span><span class="s1">col_B </span><span class="s2">in </span><span class="s1">zip(A.T</span><span class="s2">, </span><span class="s1">B.T)]).T</span>

<span class="s2">def </span><span class="s1">ElasticRod(n):</span>
    <span class="s0">&quot;&quot;&quot;Build the matrices for the generalized eigenvalue problem of the 
    fixed-free elastic rod vibration model. 
    &quot;&quot;&quot;</span>
    <span class="s1">L = </span><span class="s3">1.0</span>
    <span class="s1">le = L/n</span>
    <span class="s1">rho = </span><span class="s3">7.85e3</span>
    <span class="s1">S = </span><span class="s3">1.e-4</span>
    <span class="s1">E = </span><span class="s3">2.1e11</span>
    <span class="s1">mass = rho*S*le/</span><span class="s3">6.</span>
    <span class="s1">k = E*S/le</span>
    <span class="s1">A = k*(diag(r_[</span><span class="s3">2.</span><span class="s1">*ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s3">1</span><span class="s1">])-diag(ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)-diag(ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">B = mass*(diag(r_[</span><span class="s3">4.</span><span class="s1">*ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s3">2</span><span class="s1">])+diag(ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)+diag(ones(n-</span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">))</span>
    <span class="s2">return </span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span>


<span class="s2">def </span><span class="s1">MikotaPair(n):</span>
    <span class="s0">&quot;&quot;&quot;Build a pair of full diagonal matrices for the generalized eigenvalue 
    problem. The Mikota pair acts as a nice test since the eigenvalues are the 
    squares of the integers n, n=1,2,... 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">B = diag(</span><span class="s3">1.</span><span class="s1">/x)</span>
    <span class="s1">y = np.arange(n-</span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">z = np.arange(</span><span class="s3">2</span><span class="s1">*n-</span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s1">-</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">A = diag(z)-diag(y</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">)-diag(y</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span>


<span class="s2">def </span><span class="s1">compare_solutions(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">m):</span>
    <span class="s0">&quot;&quot;&quot;Check eig vs. lobpcg consistency. 
    &quot;&quot;&quot;</span>
    <span class="s1">n = A.shape[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">V = rnd.random((n</span><span class="s2">, </span><span class="s1">m))</span>
    <span class="s1">X = orth(V)</span>
    <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">B=B</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-2</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">50</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">eigvals.sort()</span>
    <span class="s1">w</span><span class="s2">, </span><span class="s1">_ = eig(A</span><span class="s2">, </span><span class="s1">b=B)</span>
    <span class="s1">w.sort()</span>
    <span class="s1">assert_almost_equal(w[:int(m/</span><span class="s3">2</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">eigvals[:int(m/</span><span class="s3">2</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_Small():</span>
    <span class="s1">A</span><span class="s2">, </span><span class="s1">B = ElasticRod(</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;The problem size&quot;</span><span class="s1">):</span>
        <span class="s1">compare_solutions(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">A</span><span class="s2">, </span><span class="s1">B = MikotaPair(</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;The problem size&quot;</span><span class="s1">):</span>
        <span class="s1">compare_solutions(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_ElasticRod():</span>
    <span class="s1">A</span><span class="s2">, </span><span class="s1">B = ElasticRod(</span><span class="s3">20</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Exited at iteration&quot;</span><span class="s1">):</span>
        <span class="s1">compare_solutions(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_MikotaPair():</span>
    <span class="s1">A</span><span class="s2">, </span><span class="s1">B = MikotaPair(</span><span class="s3">20</span><span class="s1">)</span>
    <span class="s1">compare_solutions(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">50</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;m&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span class="s3">10</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;Vdtype&quot;</span><span class="s2">, </span><span class="s1">REAL_DTYPES)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;Bdtype&quot;</span><span class="s2">, </span><span class="s1">REAL_DTYPES)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;BVdtype&quot;</span><span class="s2">, </span><span class="s1">REAL_DTYPES)</span>
<span class="s2">def </span><span class="s1">test_b_orthonormalize(n</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">Vdtype</span><span class="s2">, </span><span class="s1">Bdtype</span><span class="s2">, </span><span class="s1">BVdtype):</span>
    <span class="s0">&quot;&quot;&quot;Test B-orthonormalization by Cholesky with callable 'B'. 
    The function '_b_orthonormalize' is key in LOBPCG but may 
    lead to numerical instabilities. The input vectors are often 
    badly scaled, so the function needs scale-invariant Cholesky; 
    see https://netlib.org/lapack/lawnspdf/lawn14.pdf. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.standard_normal((n</span><span class="s2">, </span><span class="s1">m)).astype(Vdtype)</span>
    <span class="s1">Xcopy = np.copy(X)</span>
    <span class="s1">vals = np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s3">1</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s1">B = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n)).astype(Bdtype)</span>
    <span class="s1">BX = B @ X</span>
    <span class="s1">BX = BX.astype(BVdtype)</span>
    <span class="s1">dtype = min(X.dtype</span><span class="s2">, </span><span class="s1">B.dtype</span><span class="s2">, </span><span class="s1">BX.dtype)</span>
    <span class="s4"># np.longdouble tol cannot be achieved on most systems</span>
    <span class="s1">atol = m * n * max(np.finfo(dtype).eps</span><span class="s2">, </span><span class="s1">np.finfo(np.double).eps)</span>

    <span class="s1">Xo</span><span class="s2">, </span><span class="s1">BXo</span><span class="s2">, </span><span class="s1">_ = _b_orthonormalize(</span><span class="s2">lambda </span><span class="s1">v: B @ v</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">BX)</span>
    <span class="s4"># Check in-place.</span>
    <span class="s1">assert_equal(X</span><span class="s2">, </span><span class="s1">Xo)</span>
    <span class="s1">assert_equal(id(X)</span><span class="s2">, </span><span class="s1">id(Xo))</span>
    <span class="s1">assert_equal(BX</span><span class="s2">, </span><span class="s1">BXo)</span>
    <span class="s1">assert_equal(id(BX)</span><span class="s2">, </span><span class="s1">id(BXo))</span>
    <span class="s4"># Check BXo.</span>
    <span class="s1">assert_allclose(B @ Xo</span><span class="s2">, </span><span class="s1">BXo</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>
    <span class="s4"># Check B-orthonormality</span>
    <span class="s1">assert_allclose(Xo.T.conj() @ B @ Xo</span><span class="s2">, </span><span class="s1">np.identity(m)</span><span class="s2">,</span>
                    <span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>
    <span class="s4"># Repeat without BX in outputs</span>
    <span class="s1">X = np.copy(Xcopy)</span>
    <span class="s1">Xo1</span><span class="s2">, </span><span class="s1">BXo1</span><span class="s2">, </span><span class="s1">_ = _b_orthonormalize(</span><span class="s2">lambda </span><span class="s1">v: B @ v</span><span class="s2">, </span><span class="s1">X)</span>
    <span class="s1">assert_allclose(Xo</span><span class="s2">, </span><span class="s1">Xo1</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>
    <span class="s1">assert_allclose(BXo</span><span class="s2">, </span><span class="s1">BXo1</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>
    <span class="s4"># Check in-place.</span>
    <span class="s1">assert_equal(X</span><span class="s2">, </span><span class="s1">Xo1)</span>
    <span class="s1">assert_equal(id(X)</span><span class="s2">, </span><span class="s1">id(Xo1))</span>
    <span class="s4"># Check BXo1.</span>
    <span class="s1">assert_allclose(B @ Xo1</span><span class="s2">, </span><span class="s1">BXo1</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>

    <span class="s4"># Introduce column-scaling in X.</span>
    <span class="s1">scaling = </span><span class="s3">1.0 </span><span class="s1">/ np.geomspace(</span><span class="s3">10</span><span class="s2">, </span><span class="s3">1e10</span><span class="s2">, </span><span class="s1">num=m)</span>
    <span class="s1">X = Xcopy * scaling</span>
    <span class="s1">X = X.astype(Vdtype)</span>
    <span class="s1">BX = B @ X</span>
    <span class="s1">BX = BX.astype(BVdtype)</span>
    <span class="s4"># Check scaling-invariance of Cholesky-based orthonormalization</span>
    <span class="s1">Xo1</span><span class="s2">, </span><span class="s1">BXo1</span><span class="s2">, </span><span class="s1">_ = _b_orthonormalize(</span><span class="s2">lambda </span><span class="s1">v: B @ v</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">BX)</span>
    <span class="s4"># The output should be the same, up the signs of the columns.</span>
    <span class="s1">Xo1 =  sign_align(Xo1</span><span class="s2">, </span><span class="s1">Xo)</span>
    <span class="s1">assert_allclose(Xo</span><span class="s2">, </span><span class="s1">Xo1</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>
    <span class="s1">BXo1 =  sign_align(BXo1</span><span class="s2">, </span><span class="s1">BXo)</span>
    <span class="s1">assert_allclose(BXo</span><span class="s2">, </span><span class="s1">BXo1</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=atol)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited at iteration 0&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited postprocessing&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_nonhermitian_warning(capsys):</span>
    <span class="s0">&quot;&quot;&quot;Check the warning of a Ritz matrix being not Hermitian 
    by feeding a non-Hermitian input matrix. 
    Also check stdout since verbosityLevel=1 and lack of stderr. 
    &quot;&quot;&quot;</span>
    <span class="s1">n = </span><span class="s3">10</span>
    <span class="s1">X = np.arange(n * </span><span class="s3">2</span><span class="s1">).reshape(n</span><span class="s2">, </span><span class="s3">2</span><span class="s1">).astype(np.float32)</span>
    <span class="s1">A = np.arange(n * n).reshape(n</span><span class="s2">, </span><span class="s1">n).astype(np.float32)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Matrix gramA&quot;</span><span class="s1">):</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">out</span><span class="s2">, </span><span class="s1">err = capsys.readouterr()  </span><span class="s4"># Capture output</span>
    <span class="s2">assert </span><span class="s1">out.startswith(</span><span class="s5">&quot;Solving standard eigenvalue&quot;</span><span class="s1">)  </span><span class="s4"># Test stdout</span>
    <span class="s2">assert </span><span class="s1">err == </span><span class="s5">''  </span><span class="s4"># Test empty stderr</span>
    <span class="s4"># Make the matrix symmetric and the UserWarning dissappears.</span>
    <span class="s1">A += A.T</span>
    <span class="s1">_</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">out</span><span class="s2">, </span><span class="s1">err = capsys.readouterr()  </span><span class="s4"># Capture output</span>
    <span class="s2">assert </span><span class="s1">out.startswith(</span><span class="s5">&quot;Solving standard eigenvalue&quot;</span><span class="s1">)  </span><span class="s4"># Test stdout</span>
    <span class="s2">assert </span><span class="s1">err == </span><span class="s5">''  </span><span class="s4"># Test empty stderr</span>


<span class="s2">def </span><span class="s1">test_regression():</span>
    <span class="s0">&quot;&quot;&quot;Check the eigenvalue of the identity matrix is one. 
    &quot;&quot;&quot;</span>
    <span class="s4"># https://mail.python.org/pipermail/scipy-user/2010-October/026944.html</span>
    <span class="s1">n = </span><span class="s3">10</span>
    <span class="s1">X = np.ones((n</span><span class="s2">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">A = np.identity(n)</span>
    <span class="s1">w</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X)</span>
    <span class="s1">assert_allclose(w</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">])</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:The problem size&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">'n, m, m_excluded'</span><span class="s2">, </span><span class="s1">[(</span><span class="s3">30</span><span class="s2">, </span><span class="s3">4</span><span class="s2">, </span><span class="s3">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s3">4</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span class="s3">0</span><span class="s1">)])</span>
<span class="s2">def </span><span class="s1">test_diagonal(n</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">m_excluded):</span>
    <span class="s0">&quot;&quot;&quot;Test ``m - m_excluded`` eigenvalues and eigenvectors of 
    diagonal matrices of the size ``n`` varying matrix formats: 
    dense array, spare matrix, and ``LinearOperator`` for both 
    matrixes in the generalized eigenvalue problem ``Av = cBv`` 
    and for the preconditioner. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s4"># Define the generalized eigenvalue problem Av = cBv</span>
    <span class="s4"># where (c, v) is a generalized eigenpair,</span>
    <span class="s4"># A is the diagonal matrix whose entries are 1,...n,</span>
    <span class="s4"># B is the identity matrix.</span>
    <span class="s1">vals = np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s3">1</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s1">A_s = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n))</span>
    <span class="s1">A_a = A_s.toarray()</span>

    <span class="s2">def </span><span class="s1">A_f(x):</span>
        <span class="s2">return </span><span class="s1">A_s @ x</span>

    <span class="s1">A_lo = LinearOperator(matvec=A_f</span><span class="s2">,</span>
                          <span class="s1">matmat=A_f</span><span class="s2">,</span>
                          <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">dtype=float)</span>

    <span class="s1">B_a = eye(n)</span>
    <span class="s1">B_s = csr_matrix(B_a)</span>

    <span class="s2">def </span><span class="s1">B_f(x):</span>
        <span class="s2">return </span><span class="s1">B_a @ x</span>

    <span class="s1">B_lo = LinearOperator(matvec=B_f</span><span class="s2">,</span>
                          <span class="s1">matmat=B_f</span><span class="s2">,</span>
                          <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">dtype=float)</span>

    <span class="s4"># Let the preconditioner M be the inverse of A.</span>
    <span class="s1">M_s = diags([</span><span class="s3">1.</span><span class="s1">/vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n))</span>
    <span class="s1">M_a = M_s.toarray()</span>

    <span class="s2">def </span><span class="s1">M_f(x):</span>
        <span class="s2">return </span><span class="s1">M_s @ x</span>

    <span class="s1">M_lo = LinearOperator(matvec=M_f</span><span class="s2">,</span>
                          <span class="s1">matmat=M_f</span><span class="s2">,</span>
                          <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">dtype=float)</span>

    <span class="s4"># Pick random initial vectors.</span>
    <span class="s1">X = rnd.normal(size=(n</span><span class="s2">, </span><span class="s1">m))</span>

    <span class="s4"># Require that the returned eigenvectors be in the orthogonal complement</span>
    <span class="s4"># of the first few standard basis vectors.</span>
    <span class="s2">if </span><span class="s1">m_excluded &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s1">Y = np.eye(n</span><span class="s2">, </span><span class="s1">m_excluded)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">Y = </span><span class="s2">None</span>

    <span class="s2">for </span><span class="s1">A </span><span class="s2">in </span><span class="s1">[A_a</span><span class="s2">, </span><span class="s1">A_s</span><span class="s2">, </span><span class="s1">A_lo]:</span>
        <span class="s2">for </span><span class="s1">B </span><span class="s2">in </span><span class="s1">[B_a</span><span class="s2">, </span><span class="s1">B_s</span><span class="s2">, </span><span class="s1">B_lo]:</span>
            <span class="s2">for </span><span class="s1">M </span><span class="s2">in </span><span class="s1">[M_a</span><span class="s2">, </span><span class="s1">M_s</span><span class="s2">, </span><span class="s1">M_lo]:</span>
                <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">vecs = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">M=M</span><span class="s2">, </span><span class="s1">Y=Y</span><span class="s2">,</span>
                                       <span class="s1">maxiter=</span><span class="s3">40</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>

                <span class="s1">assert_allclose(eigvals</span><span class="s2">, </span><span class="s1">np.arange(</span><span class="s3">1</span><span class="s1">+m_excluded</span><span class="s2">,</span>
                                                   <span class="s3">1</span><span class="s1">+m_excluded+m))</span>
                <span class="s1">_check_eigen(A</span><span class="s2">, </span><span class="s1">eigvals</span><span class="s2">, </span><span class="s1">vecs</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-3</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-3</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_check_eigen(M</span><span class="s2">, </span><span class="s1">w</span><span class="s2">, </span><span class="s1">V</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-8</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-14</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Check if the eigenvalue residual is small. 
    &quot;&quot;&quot;</span>
    <span class="s1">mult_wV = np.multiply(w</span><span class="s2">, </span><span class="s1">V)</span>
    <span class="s1">dot_MV = M.dot(V)</span>
    <span class="s1">assert_allclose(mult_wV</span><span class="s2">, </span><span class="s1">dot_MV</span><span class="s2">, </span><span class="s1">rtol=rtol</span><span class="s2">, </span><span class="s1">atol=atol)</span>


<span class="s2">def </span><span class="s1">_check_fiedler(n</span><span class="s2">, </span><span class="s1">p):</span>
    <span class="s0">&quot;&quot;&quot;Check the Fiedler vector computation. 
    &quot;&quot;&quot;</span>
    <span class="s4"># This is not necessarily the recommended way to find the Fiedler vector.</span>
    <span class="s1">col = np.zeros(n)</span>
    <span class="s1">col[</span><span class="s3">1</span><span class="s1">] = </span><span class="s3">1</span>
    <span class="s1">A = toeplitz(col)</span>
    <span class="s1">D = np.diag(A.sum(axis=</span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">L = D - A</span>
    <span class="s4"># Compute the full eigendecomposition using tricks, e.g.</span>
    <span class="s4"># http://www.cs.yale.edu/homes/spielman/561/2009/lect02-09.pdf</span>
    <span class="s1">tmp = np.pi * np.arange(n) / n</span>
    <span class="s1">analytic_w = </span><span class="s3">2 </span><span class="s1">* (</span><span class="s3">1 </span><span class="s1">- np.cos(tmp))</span>
    <span class="s1">analytic_V = np.cos(np.outer(np.arange(n) + </span><span class="s3">1</span><span class="s1">/</span><span class="s3">2</span><span class="s2">, </span><span class="s1">tmp))</span>
    <span class="s1">_check_eigen(L</span><span class="s2">, </span><span class="s1">analytic_w</span><span class="s2">, </span><span class="s1">analytic_V)</span>
    <span class="s4"># Compute the full eigendecomposition using eigh.</span>
    <span class="s1">eigh_w</span><span class="s2">, </span><span class="s1">eigh_V = eigh(L)</span>
    <span class="s1">_check_eigen(L</span><span class="s2">, </span><span class="s1">eigh_w</span><span class="s2">, </span><span class="s1">eigh_V)</span>
    <span class="s4"># Check that the first eigenvalue is near zero and that the rest agree.</span>
    <span class="s1">assert_array_less(np.abs([eigh_w[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">analytic_w[</span><span class="s3">0</span><span class="s1">]])</span><span class="s2">, </span><span class="s3">1e-14</span><span class="s1">)</span>
    <span class="s1">assert_allclose(eigh_w[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">analytic_w[</span><span class="s3">1</span><span class="s1">:])</span>

    <span class="s4"># Check small lobpcg eigenvalues.</span>
    <span class="s1">X = analytic_V[:</span><span class="s2">, </span><span class="s1">:p]</span>
    <span class="s1">lobpcg_w</span><span class="s2">, </span><span class="s1">lobpcg_V = lobpcg(L</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_equal(lobpcg_w.shape</span><span class="s2">, </span><span class="s1">(p</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">assert_equal(lobpcg_V.shape</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">p))</span>
    <span class="s1">_check_eigen(L</span><span class="s2">, </span><span class="s1">lobpcg_w</span><span class="s2">, </span><span class="s1">lobpcg_V)</span>
    <span class="s1">assert_array_less(np.abs(np.min(lobpcg_w))</span><span class="s2">, </span><span class="s3">1e-14</span><span class="s1">)</span>
    <span class="s1">assert_allclose(np.sort(lobpcg_w)[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">analytic_w[</span><span class="s3">1</span><span class="s1">:p])</span>

    <span class="s4"># Check large lobpcg eigenvalues.</span>
    <span class="s1">X = analytic_V[:</span><span class="s2">, </span><span class="s1">-p:]</span>
    <span class="s1">lobpcg_w</span><span class="s2">, </span><span class="s1">lobpcg_V = lobpcg(L</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_equal(lobpcg_w.shape</span><span class="s2">, </span><span class="s1">(p</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">assert_equal(lobpcg_V.shape</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">p))</span>
    <span class="s1">_check_eigen(L</span><span class="s2">, </span><span class="s1">lobpcg_w</span><span class="s2">, </span><span class="s1">lobpcg_V)</span>
    <span class="s1">assert_allclose(np.sort(lobpcg_w)</span><span class="s2">, </span><span class="s1">analytic_w[-p:])</span>

    <span class="s4"># Look for the Fiedler vector using good but not exactly correct guesses.</span>
    <span class="s1">fiedler_guess = np.concatenate((np.ones(n//</span><span class="s3">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">-np.ones(n-n//</span><span class="s3">2</span><span class="s1">)))</span>
    <span class="s1">X = np.vstack((np.ones(n)</span><span class="s2">, </span><span class="s1">fiedler_guess)).T</span>
    <span class="s1">lobpcg_w</span><span class="s2">, </span><span class="s1">_ = lobpcg(L</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s4"># Mathematically, the smaller eigenvalue should be zero</span>
    <span class="s4"># and the larger should be the algebraic connectivity.</span>
    <span class="s1">lobpcg_w = np.sort(lobpcg_w)</span>
    <span class="s1">assert_allclose(lobpcg_w</span><span class="s2">, </span><span class="s1">analytic_w[:</span><span class="s3">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-14</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_fiedler_small_8():</span>
    <span class="s0">&quot;&quot;&quot;Check the dense workaround path for small matrices. 
    &quot;&quot;&quot;</span>
    <span class="s4"># This triggers the dense path because 8 &lt; 2*5.</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;The problem size&quot;</span><span class="s1">):</span>
        <span class="s1">_check_fiedler(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_fiedler_large_12():</span>
    <span class="s0">&quot;&quot;&quot;Check the dense workaround path avoided for non-small matrices. 
    &quot;&quot;&quot;</span>
    <span class="s4"># This does not trigger the dense path, because 2*5 &lt;= 12.</span>
    <span class="s1">_check_fiedler(</span><span class="s3">12</span><span class="s2">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Failed at iteration&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited at iteration&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited postprocessing&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_failure_to_run_iterations():</span>
    <span class="s0">&quot;&quot;&quot;Check that the code exits gracefully without breaking. Issue #10974. 
    The code may or not issue a warning, filtered out. Issue #15935, #17954. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.standard_normal((</span><span class="s3">100</span><span class="s2">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">A = X @ X.T</span>
    <span class="s1">Q = rnd.standard_normal((X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">4</span><span class="s1">))</span>
    <span class="s1">eigenvalues</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">Q</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">40</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-12</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">np.max(eigenvalues) &gt; </span><span class="s3">0</span>


<span class="s2">def </span><span class="s1">test_failure_to_run_iterations_nonsymmetric():</span>
    <span class="s0">&quot;&quot;&quot;Check that the code exists gracefully without breaking 
    if the matrix in not symmetric. 
    &quot;&quot;&quot;</span>
    <span class="s1">A = np.zeros((</span><span class="s3">10</span><span class="s2">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">A[</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s1">] = </span><span class="s3">1</span>
    <span class="s1">Q = np.ones((</span><span class="s3">10</span><span class="s2">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Exited at iteration 2&quot;</span><span class="s1">):</span>
        <span class="s1">eigenvalues</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">Q</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">20</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">np.max(eigenvalues) &gt; </span><span class="s3">0</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:The problem size&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_hermitian():</span>
    <span class="s0">&quot;&quot;&quot;Check complex-value Hermitian cases. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">sizes = [</span><span class="s3">3</span><span class="s2">, </span><span class="s3">12</span><span class="s1">]</span>
    <span class="s1">ks = [</span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s1">gens = [</span><span class="s2">True, False</span><span class="s1">]</span>

    <span class="s2">for </span><span class="s1">s</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">gen</span><span class="s2">, </span><span class="s1">dh</span><span class="s2">, </span><span class="s1">dx</span><span class="s2">, </span><span class="s1">db </span><span class="s2">in </span><span class="s1">(</span>
        <span class="s1">itertools.product(sizes</span><span class="s2">, </span><span class="s1">ks</span><span class="s2">, </span><span class="s1">gens</span><span class="s2">, </span><span class="s1">gens</span><span class="s2">, </span><span class="s1">gens</span><span class="s2">, </span><span class="s1">gens)</span>
    <span class="s1">):</span>
        <span class="s1">H = rnd.random((s</span><span class="s2">, </span><span class="s1">s)) + </span><span class="s3">1.j </span><span class="s1">* rnd.random((s</span><span class="s2">, </span><span class="s1">s))</span>
        <span class="s1">H = </span><span class="s3">10 </span><span class="s1">* np.eye(s) + H + H.T.conj()</span>
        <span class="s1">H = H.astype(np.complex128) </span><span class="s2">if </span><span class="s1">dh </span><span class="s2">else </span><span class="s1">H.astype(np.complex64)</span>

        <span class="s1">X = rnd.standard_normal((s</span><span class="s2">, </span><span class="s1">k))</span>
        <span class="s1">X = X + </span><span class="s3">1.j </span><span class="s1">* rnd.standard_normal((s</span><span class="s2">, </span><span class="s1">k))</span>
        <span class="s1">X = X.astype(np.complex128) </span><span class="s2">if </span><span class="s1">dx </span><span class="s2">else </span><span class="s1">X.astype(np.complex64)</span>

        <span class="s2">if not </span><span class="s1">gen:</span>
            <span class="s1">B = np.eye(s)</span>
            <span class="s1">w</span><span class="s2">, </span><span class="s1">v = lobpcg(H</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">99</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">0</span><span class="s1">)</span>
            <span class="s4"># Also test mixing complex H with real B.</span>
            <span class="s1">wb</span><span class="s2">, </span><span class="s1">_ = lobpcg(H</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">99</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">0</span><span class="s1">)</span>
            <span class="s1">assert_allclose(w</span><span class="s2">, </span><span class="s1">wb</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>
            <span class="s1">w0</span><span class="s2">, </span><span class="s1">_ = eigh(H)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">B = rnd.random((s</span><span class="s2">, </span><span class="s1">s)) + </span><span class="s3">1.j </span><span class="s1">* rnd.random((s</span><span class="s2">, </span><span class="s1">s))</span>
            <span class="s1">B = </span><span class="s3">10 </span><span class="s1">* np.eye(s) + B.dot(B.T.conj())</span>
            <span class="s1">B = B.astype(np.complex128) </span><span class="s2">if </span><span class="s1">db </span><span class="s2">else </span><span class="s1">B.astype(np.complex64)</span>
            <span class="s1">w</span><span class="s2">, </span><span class="s1">v = lobpcg(H</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">99</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">0</span><span class="s1">)</span>
            <span class="s1">w0</span><span class="s2">, </span><span class="s1">_ = eigh(H</span><span class="s2">, </span><span class="s1">B)</span>

        <span class="s2">for </span><span class="s1">wx</span><span class="s2">, </span><span class="s1">vx </span><span class="s2">in </span><span class="s1">zip(w</span><span class="s2">, </span><span class="s1">v.T):</span>
            <span class="s4"># Check eigenvector</span>
            <span class="s1">assert_allclose(np.linalg.norm(H.dot(vx) - B.dot(vx) * wx)</span>
                            <span class="s1">/ np.linalg.norm(H.dot(vx))</span><span class="s2">,</span>
                            <span class="s3">0</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">5e-2</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">0</span><span class="s1">)</span>

            <span class="s4"># Compare eigenvalues</span>
            <span class="s1">j = np.argmin(abs(w0 - wx))</span>
            <span class="s1">assert_allclose(wx</span><span class="s2">, </span><span class="s1">w0[j]</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-4</span><span class="s1">)</span>


<span class="s4"># The n=5 case tests the alternative small matrix code path that uses eigh().</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:The problem size&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">'n, atol'</span><span class="s2">, </span><span class="s1">[(</span><span class="s3">20</span><span class="s2">, </span><span class="s3">1e-3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s3">5</span><span class="s2">, </span><span class="s3">1e-8</span><span class="s1">)])</span>
<span class="s2">def </span><span class="s1">test_eigs_consistency(n</span><span class="s2">, </span><span class="s1">atol):</span>
    <span class="s0">&quot;&quot;&quot;Check eigs vs. lobpcg consistency. 
    &quot;&quot;&quot;</span>
    <span class="s1">vals = np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s3">1</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">A = spdiags(vals</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">n)</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.standard_normal((n</span><span class="s2">, </span><span class="s3">2</span><span class="s1">))</span>
    <span class="s1">lvals</span><span class="s2">, </span><span class="s1">lvecs = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">True, </span><span class="s1">maxiter=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">vals</span><span class="s2">, </span><span class="s1">_ = eigs(A</span><span class="s2">, </span><span class="s1">k=</span><span class="s3">2</span><span class="s1">)</span>

    <span class="s1">_check_eigen(A</span><span class="s2">, </span><span class="s1">lvals</span><span class="s2">, </span><span class="s1">lvecs</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(np.sort(vals)</span><span class="s2">, </span><span class="s1">np.sort(lvals)</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-14</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_verbosity():</span>
    <span class="s0">&quot;&quot;&quot;Check that nonzero verbosity level code runs. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.standard_normal((</span><span class="s3">10</span><span class="s2">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">A = X @ X.T</span>
    <span class="s1">Q = rnd.standard_normal((X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Exited at iteration&quot;</span><span class="s1">):</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">Q</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">9</span><span class="s1">)</span>


<span class="s1">@pytest.mark.xfail(_IS_32BIT </span><span class="s2">and </span><span class="s1">sys.platform == </span><span class="s5">'win32'</span><span class="s2">,</span>
                   <span class="s1">reason=</span><span class="s5">&quot;tolerance violation on windows&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.xfail(platform.machine() == </span><span class="s5">'ppc64le'</span><span class="s2">,</span>
                   <span class="s1">reason=</span><span class="s5">&quot;fails on ppc64le&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited postprocessing&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_tolerance_float32():</span>
    <span class="s0">&quot;&quot;&quot;Check lobpcg for attainable tolerance in float32. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">50</span>
    <span class="s1">m = </span><span class="s3">3</span>
    <span class="s1">vals = -np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">A = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n))</span>
    <span class="s1">A = A.astype(np.float32)</span>
    <span class="s1">X = rnd.standard_normal((n</span><span class="s2">, </span><span class="s1">m))</span>
    <span class="s1">X = X.astype(np.float32)</span>
    <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1.25e-5</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">50</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(eigvals</span><span class="s2">, </span><span class="s1">-np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1 </span><span class="s1">+ m)</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">2e-5</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-5</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;vdtype&quot;</span><span class="s2">, </span><span class="s1">VDTYPES)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;mdtype&quot;</span><span class="s2">, </span><span class="s1">MDTYPES)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;arr_type&quot;</span><span class="s2">, </span><span class="s1">[np.array</span><span class="s2">,</span>
                                      <span class="s1">sparse.csr_matrix</span><span class="s2">,</span>
                                      <span class="s1">sparse.coo_matrix])</span>
<span class="s2">def </span><span class="s1">test_dtypes(vdtype</span><span class="s2">, </span><span class="s1">mdtype</span><span class="s2">, </span><span class="s1">arr_type):</span>
    <span class="s0">&quot;&quot;&quot;Test lobpcg in various dtypes. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">12</span>
    <span class="s1">m = </span><span class="s3">2</span>
    <span class="s1">A = arr_type(np.diag(np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s3">1</span><span class="s1">)).astype(mdtype))</span>
    <span class="s1">X = rnd.random((n</span><span class="s2">, </span><span class="s1">m))</span>
    <span class="s1">X = X.astype(vdtype)</span>
    <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">eigvecs = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-2</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(eigvals</span><span class="s2">, </span><span class="s1">np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1 </span><span class="s1">+ m)</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-1</span><span class="s1">)</span>
    <span class="s4"># eigenvectors must be nearly real in any case</span>
    <span class="s1">assert_allclose(np.sum(np.abs(eigvecs - eigvecs.conj()))</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited at iteration&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited postprocessing&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_inplace_warning():</span>
    <span class="s0">&quot;&quot;&quot;Check lobpcg gives a warning in '_b_orthonormalize' 
    that in-place orthogonalization is impossible due to dtype mismatch. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">6</span>
    <span class="s1">m = </span><span class="s3">1</span>
    <span class="s1">vals = -np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">A = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n))</span>
    <span class="s1">A = A.astype(np.cdouble)</span>
    <span class="s1">X = rnd.standard_normal((n</span><span class="s2">, </span><span class="s1">m))</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Inplace update&quot;</span><span class="s1">):</span>
        <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s3">2</span><span class="s2">, </span><span class="s1">verbosityLevel=</span><span class="s3">1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_maxit():</span>
    <span class="s0">&quot;&quot;&quot;Check lobpcg if maxit=maxiter runs maxiter iterations and 
    if maxit=None runs 20 iterations (the default) 
    by checking the size of the iteration history output, which should 
    be the number of iterations plus 3 (initial, final, and postprocessing) 
    typically when maxiter is small and the choice of the best is passive. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">50</span>
    <span class="s1">m = </span><span class="s3">4</span>
    <span class="s1">vals = -np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">A = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n))</span>
    <span class="s1">A = A.astype(np.float32)</span>
    <span class="s1">X = rnd.standard_normal((n</span><span class="s2">, </span><span class="s1">m))</span>
    <span class="s1">X = X.astype(np.float64)</span>
    <span class="s2">for </span><span class="s1">maxiter </span><span class="s2">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span class="s3">4</span><span class="s1">):</span>
        <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Exited at iteration&quot;</span><span class="s1">):</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">l_h</span><span class="s2">, </span><span class="s1">r_h = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-8</span><span class="s2">, </span><span class="s1">maxiter=maxiter</span><span class="s2">,</span>
                                    <span class="s1">retLambdaHistory=</span><span class="s2">True,</span>
                                    <span class="s1">retResidualNormsHistory=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.shape(l_h)[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">maxiter+</span><span class="s3">3</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.shape(r_h)[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">maxiter+</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s5">&quot;Exited at iteration&quot;</span><span class="s1">):</span>
        <span class="s1">l</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">l_h</span><span class="s2">, </span><span class="s1">r_h = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-8</span><span class="s2">,</span>
                                <span class="s1">retLambdaHistory=</span><span class="s2">True,</span>
                                <span class="s1">retResidualNormsHistory=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(np.shape(l_h)[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">20</span><span class="s1">+</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_allclose(np.shape(r_h)[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">20</span><span class="s1">+</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s4"># Check that eigenvalue output is the last one in history</span>
    <span class="s1">assert_allclose(l</span><span class="s2">, </span><span class="s1">l_h[-</span><span class="s3">1</span><span class="s1">])</span>
    <span class="s4"># Make sure that both history outputs are lists</span>
    <span class="s2">assert </span><span class="s1">isinstance(l_h</span><span class="s2">, </span><span class="s1">list)</span>
    <span class="s2">assert </span><span class="s1">isinstance(r_h</span><span class="s2">, </span><span class="s1">list)</span>
    <span class="s4"># Make sure that both history lists are arrays-like</span>
    <span class="s1">assert_allclose(np.shape(l_h)</span><span class="s2">, </span><span class="s1">np.shape(np.asarray(l_h)))</span>
    <span class="s1">assert_allclose(np.shape(r_h)</span><span class="s2">, </span><span class="s1">np.shape(np.asarray(r_h)))</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">15</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;m&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited at iteration&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore:Exited postprocessing&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_diagonal_data_types(n</span><span class="s2">, </span><span class="s1">m):</span>
    <span class="s0">&quot;&quot;&quot;Check lobpcg for diagonal matrices for all matrix types. 
    Constraints are imposed, so a dense eigensolver eig cannot run. 
    &quot;&quot;&quot;</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s4"># Define the generalized eigenvalue problem Av = cBv</span>
    <span class="s4"># where (c, v) is a generalized eigenpair,</span>
    <span class="s4"># and where we choose A  and B to be diagonal.</span>
    <span class="s1">vals = np.arange(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s4"># list_sparse_format = ['bsr', 'coo', 'csc', 'csr', 'dia', 'dok', 'lil']</span>
    <span class="s1">list_sparse_format = [</span><span class="s5">'coo'</span><span class="s1">]</span>
    <span class="s1">sparse_formats = len(list_sparse_format)</span>
    <span class="s2">for </span><span class="s1">s_f_i</span><span class="s2">, </span><span class="s1">s_f </span><span class="s2">in </span><span class="s1">enumerate(list_sparse_format):</span>

        <span class="s1">As64 = diags([vals * vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">format=s_f)</span>
        <span class="s1">As32 = As64.astype(np.float32)</span>
        <span class="s1">Af64 = As64.toarray()</span>
        <span class="s1">Af32 = Af64.astype(np.float32)</span>

        <span class="s2">def </span><span class="s1">As32f(x):</span>
            <span class="s2">return </span><span class="s1">As32 @ x</span>
        <span class="s1">As32LO = LinearOperator(matvec=As32f</span><span class="s2">,</span>
                                <span class="s1">matmat=As32f</span><span class="s2">,</span>
                                <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                <span class="s1">dtype=As32.dtype)</span>

        <span class="s1">listA = [Af64</span><span class="s2">, </span><span class="s1">As64</span><span class="s2">, </span><span class="s1">Af32</span><span class="s2">, </span><span class="s1">As32</span><span class="s2">, </span><span class="s1">As32f</span><span class="s2">, </span><span class="s1">As32LO</span><span class="s2">, lambda </span><span class="s1">v: As32 @ v]</span>

        <span class="s1">Bs64 = diags([vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">format=s_f)</span>
        <span class="s1">Bf64 = Bs64.toarray()</span>
        <span class="s1">Bs32 = Bs64.astype(np.float32)</span>

        <span class="s2">def </span><span class="s1">Bs32f(x):</span>
            <span class="s2">return </span><span class="s1">Bs32 @ x</span>
        <span class="s1">Bs32LO = LinearOperator(matvec=Bs32f</span><span class="s2">,</span>
                                <span class="s1">matmat=Bs32f</span><span class="s2">,</span>
                                <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                <span class="s1">dtype=Bs32.dtype)</span>
        <span class="s1">listB = [Bf64</span><span class="s2">, </span><span class="s1">Bs64</span><span class="s2">, </span><span class="s1">Bs32</span><span class="s2">, </span><span class="s1">Bs32f</span><span class="s2">, </span><span class="s1">Bs32LO</span><span class="s2">, lambda </span><span class="s1">v: Bs32 @ v]</span>

        <span class="s4"># Define the preconditioner function as LinearOperator.</span>
        <span class="s1">Ms64 = diags([</span><span class="s3">1.</span><span class="s1">/vals]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">, </span><span class="s1">format=s_f)</span>

        <span class="s2">def </span><span class="s1">Ms64precond(x):</span>
            <span class="s2">return </span><span class="s1">Ms64 @ x</span>
        <span class="s1">Ms64precondLO = LinearOperator(matvec=Ms64precond</span><span class="s2">,</span>
                                       <span class="s1">matmat=Ms64precond</span><span class="s2">,</span>
                                       <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                       <span class="s1">dtype=Ms64.dtype)</span>
        <span class="s1">Mf64 = Ms64.toarray()</span>

        <span class="s2">def </span><span class="s1">Mf64precond(x):</span>
            <span class="s2">return </span><span class="s1">Mf64 @ x</span>
        <span class="s1">Mf64precondLO = LinearOperator(matvec=Mf64precond</span><span class="s2">,</span>
                                       <span class="s1">matmat=Mf64precond</span><span class="s2">,</span>
                                       <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                       <span class="s1">dtype=Mf64.dtype)</span>
        <span class="s1">Ms32 = Ms64.astype(np.float32)</span>

        <span class="s2">def </span><span class="s1">Ms32precond(x):</span>
            <span class="s2">return </span><span class="s1">Ms32 @ x</span>
        <span class="s1">Ms32precondLO = LinearOperator(matvec=Ms32precond</span><span class="s2">,</span>
                                       <span class="s1">matmat=Ms32precond</span><span class="s2">,</span>
                                       <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                       <span class="s1">dtype=Ms32.dtype)</span>
        <span class="s1">Mf32 = Ms32.toarray()</span>

        <span class="s2">def </span><span class="s1">Mf32precond(x):</span>
            <span class="s2">return </span><span class="s1">Mf32 @ x</span>
        <span class="s1">Mf32precondLO = LinearOperator(matvec=Mf32precond</span><span class="s2">,</span>
                                       <span class="s1">matmat=Mf32precond</span><span class="s2">,</span>
                                       <span class="s1">shape=(n</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                                       <span class="s1">dtype=Mf32.dtype)</span>
        <span class="s1">listM = [</span><span class="s2">None, </span><span class="s1">Ms64</span><span class="s2">, </span><span class="s1">Ms64precondLO</span><span class="s2">, </span><span class="s1">Mf64precondLO</span><span class="s2">, </span><span class="s1">Ms64precond</span><span class="s2">,</span>
                 <span class="s1">Ms32</span><span class="s2">, </span><span class="s1">Ms32precondLO</span><span class="s2">, </span><span class="s1">Mf32precondLO</span><span class="s2">, </span><span class="s1">Ms32precond]</span>

        <span class="s4"># Setup matrix of the initial approximation to the eigenvectors</span>
        <span class="s4"># (cannot be sparse array).</span>
        <span class="s1">Xf64 = rnd.random((n</span><span class="s2">, </span><span class="s1">m))</span>
        <span class="s1">Xf32 = Xf64.astype(np.float32)</span>
        <span class="s1">listX = [Xf64</span><span class="s2">, </span><span class="s1">Xf32]</span>

        <span class="s4"># Require that the returned eigenvectors be in the orthogonal complement</span>
        <span class="s4"># of the first few standard basis vectors (cannot be sparse array).</span>
        <span class="s1">m_excluded = </span><span class="s3">3</span>
        <span class="s1">Yf64 = np.eye(n</span><span class="s2">, </span><span class="s1">m_excluded</span><span class="s2">, </span><span class="s1">dtype=float)</span>
        <span class="s1">Yf32 = np.eye(n</span><span class="s2">, </span><span class="s1">m_excluded</span><span class="s2">, </span><span class="s1">dtype=np.float32)</span>
        <span class="s1">listY = [Yf64</span><span class="s2">, </span><span class="s1">Yf32]</span>

        <span class="s1">tests = list(itertools.product(listA</span><span class="s2">, </span><span class="s1">listB</span><span class="s2">, </span><span class="s1">listM</span><span class="s2">, </span><span class="s1">listX</span><span class="s2">, </span><span class="s1">listY))</span>
        <span class="s4"># This is one of the slower tests because there are &gt;1,000 configs</span>
        <span class="s4"># to test here, instead of checking product of all input, output types</span>
        <span class="s4"># test each configuration for the first sparse format, and then</span>
        <span class="s4"># for one additional sparse format. this takes 2/7=30% as long as</span>
        <span class="s4"># testing all configurations for all sparse formats.</span>
        <span class="s2">if </span><span class="s1">s_f_i &gt; </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">tests = tests[s_f_i - </span><span class="s3">1</span><span class="s1">::sparse_formats-</span><span class="s3">1</span><span class="s1">]</span>

        <span class="s2">for </span><span class="s1">A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">in </span><span class="s1">tests:</span>
            <span class="s1">eigvals</span><span class="s2">, </span><span class="s1">_ = lobpcg(A</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">B=B</span><span class="s2">, </span><span class="s1">M=M</span><span class="s2">, </span><span class="s1">Y=Y</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-4</span><span class="s2">,</span>
                                <span class="s1">maxiter=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">largest=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">assert_allclose(eigvals</span><span class="s2">,</span>
                            <span class="s1">np.arange(</span><span class="s3">1 </span><span class="s1">+ m_excluded</span><span class="s2">, </span><span class="s3">1 </span><span class="s1">+ m_excluded + m)</span><span class="s2">,</span>
                            <span class="s1">atol=</span><span class="s3">1e-5</span><span class="s1">)</span>
</pre>
</body>
</html>
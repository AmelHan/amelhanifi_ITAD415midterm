<html>
<head>
<title>test__basinhopping.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test__basinhopping.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Unit tests for the basin hopping global minimization algorithm. 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">copy</span>

<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">(assert_almost_equal</span><span class="s2">, </span><span class="s1">assert_equal</span><span class="s2">, </span><span class="s1">assert_</span><span class="s2">,</span>
                           <span class="s1">assert_allclose)</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">pytest </span><span class="s2">import </span><span class="s1">raises </span><span class="s2">as </span><span class="s1">assert_raises</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy </span><span class="s2">import </span><span class="s1">cos</span><span class="s2">, </span><span class="s1">sin</span>

<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">basinhopping</span><span class="s2">, </span><span class="s1">OptimizeResult</span>
<span class="s2">from </span><span class="s1">scipy.optimize._basinhopping </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Storage</span><span class="s2">, </span><span class="s1">RandomDisplacement</span><span class="s2">, </span><span class="s1">Metropolis</span><span class="s2">, </span><span class="s1">AdaptiveStepsize)</span>


<span class="s2">def </span><span class="s1">func1d(x):</span>
    <span class="s1">f = cos(</span><span class="s3">14.5 </span><span class="s1">* x - </span><span class="s3">0.3</span><span class="s1">) + (x + </span><span class="s3">0.2</span><span class="s1">) * x</span>
    <span class="s1">df = np.array(-</span><span class="s3">14.5 </span><span class="s1">* sin(</span><span class="s3">14.5 </span><span class="s1">* x - </span><span class="s3">0.3</span><span class="s1">) + </span><span class="s3">2. </span><span class="s1">* x + </span><span class="s3">0.2</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">f</span><span class="s2">, </span><span class="s1">df</span>


<span class="s2">def </span><span class="s1">func2d_nograd(x):</span>
    <span class="s1">f = cos(</span><span class="s3">14.5 </span><span class="s1">* x[</span><span class="s3">0</span><span class="s1">] - </span><span class="s3">0.3</span><span class="s1">) + (x[</span><span class="s3">1</span><span class="s1">] + </span><span class="s3">0.2</span><span class="s1">) * x[</span><span class="s3">1</span><span class="s1">] + (x[</span><span class="s3">0</span><span class="s1">] + </span><span class="s3">0.2</span><span class="s1">) * x[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s2">return </span><span class="s1">f</span>


<span class="s2">def </span><span class="s1">func2d(x):</span>
    <span class="s1">f = cos(</span><span class="s3">14.5 </span><span class="s1">* x[</span><span class="s3">0</span><span class="s1">] - </span><span class="s3">0.3</span><span class="s1">) + (x[</span><span class="s3">1</span><span class="s1">] + </span><span class="s3">0.2</span><span class="s1">) * x[</span><span class="s3">1</span><span class="s1">] + (x[</span><span class="s3">0</span><span class="s1">] + </span><span class="s3">0.2</span><span class="s1">) * x[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">df = np.zeros(</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">df[</span><span class="s3">0</span><span class="s1">] = -</span><span class="s3">14.5 </span><span class="s1">* sin(</span><span class="s3">14.5 </span><span class="s1">* x[</span><span class="s3">0</span><span class="s1">] - </span><span class="s3">0.3</span><span class="s1">) + </span><span class="s3">2. </span><span class="s1">* x[</span><span class="s3">0</span><span class="s1">] + </span><span class="s3">0.2</span>
    <span class="s1">df[</span><span class="s3">1</span><span class="s1">] = </span><span class="s3">2. </span><span class="s1">* x[</span><span class="s3">1</span><span class="s1">] + </span><span class="s3">0.2</span>
    <span class="s2">return </span><span class="s1">f</span><span class="s2">, </span><span class="s1">df</span>


<span class="s2">def </span><span class="s1">func2d_easyderiv(x):</span>
    <span class="s1">f = </span><span class="s3">2.0</span><span class="s1">*x[</span><span class="s3">0</span><span class="s1">]**</span><span class="s3">2 </span><span class="s1">+ </span><span class="s3">2.0</span><span class="s1">*x[</span><span class="s3">0</span><span class="s1">]*x[</span><span class="s3">1</span><span class="s1">] + </span><span class="s3">2.0</span><span class="s1">*x[</span><span class="s3">1</span><span class="s1">]**</span><span class="s3">2 </span><span class="s1">- </span><span class="s3">6.0</span><span class="s1">*x[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">df = np.zeros(</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">df[</span><span class="s3">0</span><span class="s1">] = </span><span class="s3">4.0</span><span class="s1">*x[</span><span class="s3">0</span><span class="s1">] + </span><span class="s3">2.0</span><span class="s1">*x[</span><span class="s3">1</span><span class="s1">] - </span><span class="s3">6.0</span>
    <span class="s1">df[</span><span class="s3">1</span><span class="s1">] = </span><span class="s3">2.0</span><span class="s1">*x[</span><span class="s3">0</span><span class="s1">] + </span><span class="s3">4.0</span><span class="s1">*x[</span><span class="s3">1</span><span class="s1">]</span>

    <span class="s2">return </span><span class="s1">f</span><span class="s2">, </span><span class="s1">df</span>


<span class="s2">class </span><span class="s1">MyTakeStep1(RandomDisplacement):</span>
    <span class="s0">&quot;&quot;&quot;use a copy of displace, but have it set a special parameter to 
    make sure it's actually being used.&quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self.been_called = </span><span class="s2">False</span>
        <span class="s1">super().__init__()</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">self.been_called = </span><span class="s2">True</span>
        <span class="s2">return </span><span class="s1">super().__call__(x)</span>


<span class="s2">def </span><span class="s1">myTakeStep2(x):</span>
    <span class="s0">&quot;&quot;&quot;redo RandomDisplacement in function form without the attribute stepsize 
    to make sure everything still works ok 
    &quot;&quot;&quot;</span>
    <span class="s1">s = </span><span class="s3">0.5</span>
    <span class="s1">x += np.random.uniform(-s</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">np.shape(x))</span>
    <span class="s2">return </span><span class="s1">x</span>


<span class="s2">class </span><span class="s1">MyAcceptTest:</span>
    <span class="s0">&quot;&quot;&quot;pass a custom accept test 
 
    This does nothing but make sure it's being used and ensure all the 
    possible return values are accepted 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self.been_called = </span><span class="s2">False</span>
        <span class="s1">self.ncalls = </span><span class="s3">0</span>
        <span class="s1">self.testres = [</span><span class="s2">False, </span><span class="s4">'force accept'</span><span class="s2">, True, </span><span class="s1">np.bool_(</span><span class="s2">True</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">np.bool_(</span><span class="s2">False</span><span class="s1">)</span><span class="s2">, </span><span class="s1">[]</span><span class="s2">, </span><span class="s1">{}</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">self.been_called = </span><span class="s2">True</span>
        <span class="s1">self.ncalls += </span><span class="s3">1</span>
        <span class="s2">if </span><span class="s1">self.ncalls - </span><span class="s3">1 </span><span class="s1">&lt; len(self.testres):</span>
            <span class="s2">return </span><span class="s1">self.testres[self.ncalls - </span><span class="s3">1</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return True</span>


<span class="s2">class </span><span class="s1">MyCallBack:</span>
    <span class="s0">&quot;&quot;&quot;pass a custom callback function 
 
    This makes sure it's being used. It also returns True after 10 
    steps to ensure that it's stopping early. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self.been_called = </span><span class="s2">False</span>
        <span class="s1">self.ncalls = </span><span class="s3">0</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">accepted):</span>
        <span class="s1">self.been_called = </span><span class="s2">True</span>
        <span class="s1">self.ncalls += </span><span class="s3">1</span>
        <span class="s2">if </span><span class="s1">self.ncalls == </span><span class="s3">10</span><span class="s1">:</span>
            <span class="s2">return True</span>


<span class="s2">class </span><span class="s1">TestBasinHopping:</span>

    <span class="s2">def </span><span class="s1">setup_method(self):</span>
        <span class="s0">&quot;&quot;&quot; Tests setup. 
 
        Run tests based on the 1-D and 2-D functions described above. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.x0 = (</span><span class="s3">1.0</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">1.0</span><span class="s1">])</span>
        <span class="s1">self.sol = (-</span><span class="s3">0.195</span><span class="s2">, </span><span class="s1">np.array([-</span><span class="s3">0.195</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.1</span><span class="s1">]))</span>

        <span class="s1">self.tol = </span><span class="s3">3  </span><span class="s5"># number of decimal places</span>

        <span class="s1">self.niter = </span><span class="s3">100</span>
        <span class="s1">self.disp = </span><span class="s2">False</span>

        <span class="s5"># fix random seed</span>
        <span class="s1">np.random.seed(</span><span class="s3">1234</span><span class="s1">)</span>

        <span class="s1">self.kwargs = {</span><span class="s4">&quot;method&quot;</span><span class="s1">: </span><span class="s4">&quot;L-BFGS-B&quot;</span><span class="s2">, </span><span class="s4">&quot;jac&quot;</span><span class="s1">: </span><span class="s2">True</span><span class="s1">}</span>
        <span class="s1">self.kwargs_nograd = {</span><span class="s4">&quot;method&quot;</span><span class="s1">: </span><span class="s4">&quot;L-BFGS-B&quot;</span><span class="s1">}</span>

    <span class="s2">def </span><span class="s1">test_TypeError(self):</span>
        <span class="s5"># test the TypeErrors are raised on bad input</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s5"># if take_step is passed, it must be callable</span>
        <span class="s1">assert_raises(TypeError</span><span class="s2">, </span><span class="s1">basinhopping</span><span class="s2">, </span><span class="s1">func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                      <span class="s1">take_step=</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s5"># if accept_test is passed, it must be callable</span>
        <span class="s1">assert_raises(TypeError</span><span class="s2">, </span><span class="s1">basinhopping</span><span class="s2">, </span><span class="s1">func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                      <span class="s1">accept_test=</span><span class="s3">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_input_validation(self):</span>
        <span class="s1">msg = </span><span class="s4">'target_accept_rate has to be in range </span><span class="s2">\\</span><span class="s4">(0, 1</span><span class="s2">\\</span><span class="s4">)'</span>
        <span class="s2">with </span><span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s1">basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">target_accept_rate=</span><span class="s3">0.</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s1">basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">target_accept_rate=</span><span class="s3">1.</span><span class="s1">)</span>

        <span class="s1">msg = </span><span class="s4">'stepwise_factor has to be in range </span><span class="s2">\\</span><span class="s4">(0, 1</span><span class="s2">\\</span><span class="s4">)'</span>
        <span class="s2">with </span><span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s1">basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">stepwise_factor=</span><span class="s3">0.</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s1">basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">stepwise_factor=</span><span class="s3">1.</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_1d_grad(self):</span>
        <span class="s5"># test 1-D minimizations with gradient</span>
        <span class="s1">i = </span><span class="s3">0</span>
        <span class="s1">res = basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>

    <span class="s2">def </span><span class="s1">test_2d(self):</span>
        <span class="s5"># test 2d minimizations with gradient</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>
        <span class="s1">assert_(res.nfev &gt; </span><span class="s3">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_njev(self):</span>
        <span class="s5"># test njev is returned correctly</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">minimizer_kwargs = self.kwargs.copy()</span>
        <span class="s5"># L-BFGS-B doesn't use njev, but BFGS does</span>
        <span class="s1">minimizer_kwargs[</span><span class="s4">&quot;method&quot;</span><span class="s1">] = </span><span class="s4">&quot;BFGS&quot;</span>
        <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                           <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">, </span><span class="s1">niter=self.niter</span><span class="s2">,</span>
                           <span class="s1">disp=self.disp)</span>
        <span class="s1">assert_(res.nfev &gt; </span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.nfev</span><span class="s2">, </span><span class="s1">res.njev)</span>

    <span class="s2">def </span><span class="s1">test_jac(self):</span>
        <span class="s5"># test Jacobian returned</span>
        <span class="s1">minimizer_kwargs = self.kwargs.copy()</span>
        <span class="s5"># BFGS returns a Jacobian</span>
        <span class="s1">minimizer_kwargs[</span><span class="s4">&quot;method&quot;</span><span class="s1">] = </span><span class="s4">&quot;BFGS&quot;</span>

        <span class="s1">res = basinhopping(func2d_easyderiv</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0.0</span><span class="s2">, </span><span class="s3">0.0</span><span class="s1">]</span><span class="s2">,</span>
                           <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">, </span><span class="s1">niter=self.niter</span><span class="s2">,</span>
                           <span class="s1">disp=self.disp)</span>

        <span class="s1">assert_(hasattr(res.lowest_optimization_result</span><span class="s2">, </span><span class="s4">&quot;jac&quot;</span><span class="s1">))</span>

        <span class="s5"># in this case, the Jacobian is just [df/dx, df/dy]</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">jacobian = func2d_easyderiv(res.x)</span>
        <span class="s1">assert_almost_equal(res.lowest_optimization_result.jac</span><span class="s2">, </span><span class="s1">jacobian</span><span class="s2">,</span>
                            <span class="s1">self.tol)</span>

    <span class="s2">def </span><span class="s1">test_2d_nograd(self):</span>
        <span class="s5"># test 2-D minimizations without gradient</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">res = basinhopping(func2d_nograd</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                           <span class="s1">minimizer_kwargs=self.kwargs_nograd</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>

    <span class="s2">def </span><span class="s1">test_all_minimizers(self):</span>
        <span class="s5"># Test 2-D minimizations with gradient. Nelder-Mead, Powell, and COBYLA</span>
        <span class="s5"># don't accept jac=True, so aren't included here.</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">methods = [</span><span class="s4">'CG'</span><span class="s2">, </span><span class="s4">'BFGS'</span><span class="s2">, </span><span class="s4">'Newton-CG'</span><span class="s2">, </span><span class="s4">'L-BFGS-B'</span><span class="s2">, </span><span class="s4">'TNC'</span><span class="s2">, </span><span class="s4">'SLSQP'</span><span class="s1">]</span>
        <span class="s1">minimizer_kwargs = copy.copy(self.kwargs)</span>
        <span class="s2">for </span><span class="s1">method </span><span class="s2">in </span><span class="s1">methods:</span>
            <span class="s1">minimizer_kwargs[</span><span class="s4">&quot;method&quot;</span><span class="s1">] = method</span>
            <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                               <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                               <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
            <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>

    <span class="s2">def </span><span class="s1">test_all_nograd_minimizers(self):</span>
        <span class="s5"># Test 2-D minimizations without gradient. Newton-CG requires jac=True,</span>
        <span class="s5"># so not included here.</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">methods = [</span><span class="s4">'CG'</span><span class="s2">, </span><span class="s4">'BFGS'</span><span class="s2">, </span><span class="s4">'L-BFGS-B'</span><span class="s2">, </span><span class="s4">'TNC'</span><span class="s2">, </span><span class="s4">'SLSQP'</span><span class="s2">,</span>
                   <span class="s4">'Nelder-Mead'</span><span class="s2">, </span><span class="s4">'Powell'</span><span class="s2">, </span><span class="s4">'COBYLA'</span><span class="s1">]</span>
        <span class="s1">minimizer_kwargs = copy.copy(self.kwargs_nograd)</span>
        <span class="s2">for </span><span class="s1">method </span><span class="s2">in </span><span class="s1">methods:</span>
            <span class="s1">minimizer_kwargs[</span><span class="s4">&quot;method&quot;</span><span class="s1">] = method</span>
            <span class="s1">res = basinhopping(func2d_nograd</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                               <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                               <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
            <span class="s1">tol = self.tol</span>
            <span class="s2">if </span><span class="s1">method == </span><span class="s4">'COBYLA'</span><span class="s1">:</span>
                <span class="s1">tol = </span><span class="s3">2</span>
            <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">decimal=tol)</span>

    <span class="s2">def </span><span class="s1">test_pass_takestep(self):</span>
        <span class="s5"># test that passing a custom takestep works</span>
        <span class="s5"># also test that the stepsize is being adjusted</span>
        <span class="s1">takestep = MyTakeStep1()</span>
        <span class="s1">initial_step_size = takestep.stepsize</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp</span><span class="s2">,</span>
                           <span class="s1">take_step=takestep)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>
        <span class="s1">assert_(takestep.been_called)</span>
        <span class="s5"># make sure that the build in adaptive step size has been used</span>
        <span class="s1">assert_(initial_step_size != takestep.stepsize)</span>

    <span class="s2">def </span><span class="s1">test_pass_simple_takestep(self):</span>
        <span class="s5"># test that passing a custom takestep without attribute stepsize</span>
        <span class="s1">takestep = myTakeStep2</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">res = basinhopping(func2d_nograd</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">,</span>
                           <span class="s1">minimizer_kwargs=self.kwargs_nograd</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp</span><span class="s2">,</span>
                           <span class="s1">take_step=takestep)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>

    <span class="s2">def </span><span class="s1">test_pass_accept_test(self):</span>
        <span class="s5"># test passing a custom accept test</span>
        <span class="s5"># makes sure it's being used and ensures all the possible return values</span>
        <span class="s5"># are accepted.</span>
        <span class="s1">accept_test = MyAcceptTest()</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s5"># there's no point in running it more than a few steps.</span>
        <span class="s1">basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                     <span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">disp=self.disp</span><span class="s2">, </span><span class="s1">accept_test=accept_test)</span>
        <span class="s1">assert_(accept_test.been_called)</span>

    <span class="s2">def </span><span class="s1">test_pass_callback(self):</span>
        <span class="s5"># test passing a custom callback function</span>
        <span class="s5"># This makes sure it's being used. It also returns True after 10 steps</span>
        <span class="s5"># to ensure that it's stopping early.</span>
        <span class="s1">callback = MyCallBack()</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s5"># there's no point in running it more than a few steps.</span>
        <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=</span><span class="s3">30</span><span class="s2">, </span><span class="s1">disp=self.disp</span><span class="s2">, </span><span class="s1">callback=callback)</span>
        <span class="s1">assert_(callback.been_called)</span>
        <span class="s1">assert_(</span><span class="s4">&quot;callback&quot; </span><span class="s2">in </span><span class="s1">res.message[</span><span class="s3">0</span><span class="s1">])</span>
        <span class="s5"># One of the calls of MyCallBack is during BasinHoppingRunner</span>
        <span class="s5"># construction, so there are only 9 remaining before MyCallBack stops</span>
        <span class="s5"># the minimization.</span>
        <span class="s1">assert_equal(res.nit</span><span class="s2">, </span><span class="s3">9</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_minimizer_fail(self):</span>
        <span class="s5"># test if a minimizer fails</span>
        <span class="s1">i = </span><span class="s3">1</span>
        <span class="s1">self.kwargs[</span><span class="s4">&quot;options&quot;</span><span class="s1">] = dict(maxiter=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">self.niter = </span><span class="s3">10</span>
        <span class="s1">res = basinhopping(func2d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>
        <span class="s5"># the number of failed minimizations should be the number of</span>
        <span class="s5"># iterations + 1</span>
        <span class="s1">assert_equal(res.nit + </span><span class="s3">1</span><span class="s2">, </span><span class="s1">res.minimization_failures)</span>

    <span class="s2">def </span><span class="s1">test_niter_zero(self):</span>
        <span class="s5"># gh5915, what happens if you call basinhopping with niter=0</span>
        <span class="s1">i = </span><span class="s3">0</span>
        <span class="s1">basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                     <span class="s1">niter=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">disp=self.disp)</span>

    <span class="s2">def </span><span class="s1">test_seed_reproducibility(self):</span>
        <span class="s5"># seed should ensure reproducibility between runs</span>
        <span class="s1">minimizer_kwargs = {</span><span class="s4">&quot;method&quot;</span><span class="s1">: </span><span class="s4">&quot;L-BFGS-B&quot;</span><span class="s2">, </span><span class="s4">&quot;jac&quot;</span><span class="s1">: </span><span class="s2">True</span><span class="s1">}</span>

        <span class="s1">f_1 = []</span>

        <span class="s2">def </span><span class="s1">callback(x</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">accepted):</span>
            <span class="s1">f_1.append(f)</span>

        <span class="s1">basinhopping(func2d</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">1.0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                     <span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">callback=callback</span><span class="s2">, </span><span class="s1">seed=</span><span class="s3">10</span><span class="s1">)</span>

        <span class="s1">f_2 = []</span>

        <span class="s2">def </span><span class="s1">callback2(x</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">accepted):</span>
            <span class="s1">f_2.append(f)</span>

        <span class="s1">basinhopping(func2d</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">1.0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                     <span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">callback=callback2</span><span class="s2">, </span><span class="s1">seed=</span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">assert_equal(np.array(f_1)</span><span class="s2">, </span><span class="s1">np.array(f_2))</span>

    <span class="s2">def </span><span class="s1">test_random_gen(self):</span>
        <span class="s5"># check that np.random.Generator can be used (numpy &gt;= 1.17)</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">minimizer_kwargs = {</span><span class="s4">&quot;method&quot;</span><span class="s1">: </span><span class="s4">&quot;L-BFGS-B&quot;</span><span class="s2">, </span><span class="s4">&quot;jac&quot;</span><span class="s1">: </span><span class="s2">True</span><span class="s1">}</span>

        <span class="s1">res1 = basinhopping(func2d</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">1.0</span><span class="s1">]</span><span class="s2">,</span>
                            <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                            <span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">seed=rng)</span>

        <span class="s1">rng = np.random.default_rng(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">res2 = basinhopping(func2d</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">1.0</span><span class="s1">]</span><span class="s2">,</span>
                            <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
                            <span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">seed=rng)</span>
        <span class="s1">assert_equal(res1.x</span><span class="s2">, </span><span class="s1">res2.x)</span>

    <span class="s2">def </span><span class="s1">test_monotonic_basin_hopping(self):</span>
        <span class="s5"># test 1-D minimizations with gradient and T=0</span>
        <span class="s1">i = </span><span class="s3">0</span>
        <span class="s1">res = basinhopping(func1d</span><span class="s2">, </span><span class="s1">self.x0[i]</span><span class="s2">, </span><span class="s1">minimizer_kwargs=self.kwargs</span><span class="s2">,</span>
                           <span class="s1">niter=self.niter</span><span class="s2">, </span><span class="s1">disp=self.disp</span><span class="s2">, </span><span class="s1">T=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.x</span><span class="s2">, </span><span class="s1">self.sol[i]</span><span class="s2">, </span><span class="s1">self.tol)</span>


<span class="s2">class </span><span class="s1">Test_Storage:</span>
    <span class="s2">def </span><span class="s1">setup_method(self):</span>
        <span class="s1">self.x0 = np.array(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">self.f0 = </span><span class="s3">0</span>

        <span class="s1">minres = OptimizeResult(success=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">minres.x = self.x0</span>
        <span class="s1">minres.fun = self.f0</span>

        <span class="s1">self.storage = Storage(minres)</span>

    <span class="s2">def </span><span class="s1">test_higher_f_rejected(self):</span>
        <span class="s1">new_minres = OptimizeResult(success=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">new_minres.x = self.x0 + </span><span class="s3">1</span>
        <span class="s1">new_minres.fun = self.f0 + </span><span class="s3">1</span>

        <span class="s1">ret = self.storage.update(new_minres)</span>
        <span class="s1">minres = self.storage.get_lowest()</span>
        <span class="s1">assert_equal(self.x0</span><span class="s2">, </span><span class="s1">minres.x)</span>
        <span class="s1">assert_equal(self.f0</span><span class="s2">, </span><span class="s1">minres.fun)</span>
        <span class="s1">assert_(</span><span class="s2">not </span><span class="s1">ret)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'success'</span><span class="s2">, </span><span class="s1">[</span><span class="s2">True, False</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">test_lower_f_accepted(self</span><span class="s2">, </span><span class="s1">success):</span>
        <span class="s1">new_minres = OptimizeResult(success=success)</span>
        <span class="s1">new_minres.x = self.x0 + </span><span class="s3">1</span>
        <span class="s1">new_minres.fun = self.f0 - </span><span class="s3">1</span>

        <span class="s1">ret = self.storage.update(new_minres)</span>
        <span class="s1">minres = self.storage.get_lowest()</span>
        <span class="s2">assert </span><span class="s1">(self.x0 != minres.x) == success  </span><span class="s5"># can't use `is`</span>
        <span class="s2">assert </span><span class="s1">(self.f0 != minres.fun) == success  </span><span class="s5"># left side is NumPy bool</span>
        <span class="s2">assert </span><span class="s1">ret </span><span class="s2">is </span><span class="s1">success</span>


<span class="s2">class </span><span class="s1">Test_RandomDisplacement:</span>
    <span class="s2">def </span><span class="s1">setup_method(self):</span>
        <span class="s1">self.stepsize = </span><span class="s3">1.0</span>
        <span class="s1">self.displace = RandomDisplacement(stepsize=self.stepsize)</span>
        <span class="s1">self.N = </span><span class="s3">300000</span>
        <span class="s1">self.x0 = np.zeros([self.N])</span>

    <span class="s2">def </span><span class="s1">test_random(self):</span>
        <span class="s5"># the mean should be 0</span>
        <span class="s5"># the variance should be (2*stepsize)**2 / 12</span>
        <span class="s5"># note these tests are random, they will fail from time to time</span>
        <span class="s1">x = self.displace(self.x0)</span>
        <span class="s1">v = (</span><span class="s3">2. </span><span class="s1">* self.stepsize) ** </span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">12</span>
        <span class="s1">assert_almost_equal(np.mean(x)</span><span class="s2">, </span><span class="s3">0.</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(np.var(x)</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">Test_Metropolis:</span>
    <span class="s2">def </span><span class="s1">setup_method(self):</span>
        <span class="s1">self.T = </span><span class="s3">2.</span>
        <span class="s1">self.met = Metropolis(self.T)</span>
        <span class="s1">self.res_new = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">0.</span><span class="s1">)</span>
        <span class="s1">self.res_old = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">1.</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_boolean_return(self):</span>
        <span class="s5"># the return must be a bool, else an error will be raised in</span>
        <span class="s5"># basinhopping</span>
        <span class="s1">ret = self.met(res_new=self.res_new</span><span class="s2">, </span><span class="s1">res_old=self.res_old)</span>
        <span class="s2">assert </span><span class="s1">isinstance(ret</span><span class="s2">, </span><span class="s1">bool)</span>

    <span class="s2">def </span><span class="s1">test_lower_f_accepted(self):</span>
        <span class="s1">assert_(self.met(res_new=self.res_new</span><span class="s2">, </span><span class="s1">res_old=self.res_old))</span>

    <span class="s2">def </span><span class="s1">test_accept(self):</span>
        <span class="s5"># test that steps are randomly accepted for f_new &gt; f_old</span>
        <span class="s1">one_accept = </span><span class="s2">False</span>
        <span class="s1">one_reject = </span><span class="s2">False</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s3">1000</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">one_accept </span><span class="s2">and </span><span class="s1">one_reject:</span>
                <span class="s2">break</span>
            <span class="s1">res_new = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">1.</span><span class="s1">)</span>
            <span class="s1">res_old = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">0.5</span><span class="s1">)</span>
            <span class="s1">ret = self.met(res_new=res_new</span><span class="s2">, </span><span class="s1">res_old=res_old)</span>
            <span class="s2">if </span><span class="s1">ret:</span>
                <span class="s1">one_accept = </span><span class="s2">True</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">one_reject = </span><span class="s2">True</span>
        <span class="s1">assert_(one_accept)</span>
        <span class="s1">assert_(one_reject)</span>

    <span class="s2">def </span><span class="s1">test_GH7495(self):</span>
        <span class="s5"># an overflow in exp was producing a RuntimeWarning</span>
        <span class="s5"># create own object here in case someone changes self.T</span>
        <span class="s1">met = Metropolis(</span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">res_new = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">0.</span><span class="s1">)</span>
        <span class="s1">res_old = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">2000</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'raise'</span><span class="s1">):</span>
            <span class="s1">met.accept_reject(res_new=res_new</span><span class="s2">, </span><span class="s1">res_old=res_old)</span>

    <span class="s2">def </span><span class="s1">test_gh7799(self):</span>
        <span class="s5"># gh-7799 reported a problem in which local search was successful but</span>
        <span class="s5"># basinhopping returned an invalid solution. Show that this is fixed.</span>
        <span class="s2">def </span><span class="s1">func(x):</span>
            <span class="s2">return </span><span class="s1">(x**</span><span class="s3">2</span><span class="s1">-</span><span class="s3">8</span><span class="s1">)**</span><span class="s3">2</span><span class="s1">+(x+</span><span class="s3">2</span><span class="s1">)**</span><span class="s3">2</span>

        <span class="s1">x0 = -</span><span class="s3">4</span>
        <span class="s1">limit = </span><span class="s3">50  </span><span class="s5"># Constrain to func value &gt;= 50</span>
        <span class="s1">con = {</span><span class="s4">'type'</span><span class="s1">: </span><span class="s4">'ineq'</span><span class="s2">, </span><span class="s4">'fun'</span><span class="s1">: </span><span class="s2">lambda </span><span class="s1">x: func(x) - limit}</span><span class="s2">,</span>
        <span class="s1">res = basinhopping(func</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s3">30</span><span class="s2">, </span><span class="s1">minimizer_kwargs={</span><span class="s4">'constraints'</span><span class="s1">: con})</span>
        <span class="s2">assert </span><span class="s1">res.success</span>
        <span class="s1">assert_allclose(res.fun</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_accept_gh7799(self):</span>
        <span class="s5"># Metropolis should not accept the result of an unsuccessful new local</span>
        <span class="s5"># search if the old local search was successful</span>

        <span class="s1">met = Metropolis(</span><span class="s3">0</span><span class="s1">)  </span><span class="s5"># monotonic basin hopping</span>
        <span class="s1">res_new = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">0.</span><span class="s1">)</span>
        <span class="s1">res_old = OptimizeResult(success=</span><span class="s2">True, </span><span class="s1">fun=</span><span class="s3">1.</span><span class="s1">)</span>

        <span class="s5"># if new local search was successful and energy is lower, accept</span>
        <span class="s2">assert </span><span class="s1">met(res_new=res_new</span><span class="s2">, </span><span class="s1">res_old=res_old)</span>
        <span class="s5"># if new res is unsuccessful, don't accept - even if energy is lower</span>
        <span class="s1">res_new.success = </span><span class="s2">False</span>
        <span class="s2">assert not </span><span class="s1">met(res_new=res_new</span><span class="s2">, </span><span class="s1">res_old=res_old)</span>
        <span class="s5"># ...unless the old res was unsuccessful, too. In that case, why not?</span>
        <span class="s1">res_old.success = </span><span class="s2">False</span>
        <span class="s2">assert </span><span class="s1">met(res_new=res_new</span><span class="s2">, </span><span class="s1">res_old=res_old)</span>

    <span class="s2">def </span><span class="s1">test_reject_all_gh7799(self):</span>
        <span class="s5"># Test the behavior when there is no feasible solution</span>
        <span class="s2">def </span><span class="s1">fun(x):</span>
            <span class="s2">return </span><span class="s1">x@x</span>

        <span class="s2">def </span><span class="s1">constraint(x):</span>
            <span class="s2">return </span><span class="s1">x + </span><span class="s3">1</span>

        <span class="s1">kwargs = {</span><span class="s4">'constraints'</span><span class="s1">: {</span><span class="s4">'type'</span><span class="s1">: </span><span class="s4">'eq'</span><span class="s2">, </span><span class="s4">'fun'</span><span class="s1">: constraint}</span><span class="s2">,</span>
                  <span class="s4">'bounds'</span><span class="s1">: [(</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)]</span><span class="s2">, </span><span class="s4">'method'</span><span class="s1">: </span><span class="s4">'slsqp'</span><span class="s1">}</span>
        <span class="s1">res = basinhopping(fun</span><span class="s2">, </span><span class="s1">x0=[</span><span class="s3">2</span><span class="s2">, </span><span class="s3">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">niter=</span><span class="s3">10</span><span class="s2">, </span><span class="s1">minimizer_kwargs=kwargs)</span>
        <span class="s2">assert not </span><span class="s1">res.success</span>


<span class="s2">class </span><span class="s1">Test_AdaptiveStepsize:</span>
    <span class="s2">def </span><span class="s1">setup_method(self):</span>
        <span class="s1">self.stepsize = </span><span class="s3">1.</span>
        <span class="s1">self.ts = RandomDisplacement(stepsize=self.stepsize)</span>
        <span class="s1">self.target_accept_rate = </span><span class="s3">0.5</span>
        <span class="s1">self.takestep = AdaptiveStepsize(takestep=self.ts</span><span class="s2">, </span><span class="s1">verbose=</span><span class="s2">False,</span>
                                         <span class="s1">accept_rate=self.target_accept_rate)</span>

    <span class="s2">def </span><span class="s1">test_adaptive_increase(self):</span>
        <span class="s5"># if few steps are rejected, the stepsize should increase</span>
        <span class="s1">x = </span><span class="s3">0.</span>
        <span class="s1">self.takestep(x)</span>
        <span class="s1">self.takestep.report(</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.takestep.interval):</span>
            <span class="s1">self.takestep(x)</span>
            <span class="s1">self.takestep.report(</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">assert_(self.ts.stepsize &gt; self.stepsize)</span>

    <span class="s2">def </span><span class="s1">test_adaptive_decrease(self):</span>
        <span class="s5"># if few steps are rejected, the stepsize should increase</span>
        <span class="s1">x = </span><span class="s3">0.</span>
        <span class="s1">self.takestep(x)</span>
        <span class="s1">self.takestep.report(</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.takestep.interval):</span>
            <span class="s1">self.takestep(x)</span>
            <span class="s1">self.takestep.report(</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">assert_(self.ts.stepsize &lt; self.stepsize)</span>

    <span class="s2">def </span><span class="s1">test_all_accepted(self):</span>
        <span class="s5"># test that everything works OK if all steps were accepted</span>
        <span class="s1">x = </span><span class="s3">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.takestep.interval + </span><span class="s3">1</span><span class="s1">):</span>
            <span class="s1">self.takestep(x)</span>
            <span class="s1">self.takestep.report(</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">assert_(self.ts.stepsize &gt; self.stepsize)</span>

    <span class="s2">def </span><span class="s1">test_all_rejected(self):</span>
        <span class="s5"># test that everything works OK if all steps were rejected</span>
        <span class="s1">x = </span><span class="s3">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.takestep.interval + </span><span class="s3">1</span><span class="s1">):</span>
            <span class="s1">self.takestep(x)</span>
            <span class="s1">self.takestep.report(</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">assert_(self.ts.stepsize &lt; self.stepsize)</span>
</pre>
</body>
</html>
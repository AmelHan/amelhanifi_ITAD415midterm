<html>
<head>
<title>test_poisson.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_poisson.py</font>
</center></td></tr></table>
<pre><span class="s0">'''Testing GenericLikelihoodModel variations on Poisson 
 
 
'''</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">assert_almost_equal</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>

<span class="s2">import </span><span class="s1">statsmodels.api </span><span class="s2">as </span><span class="s1">sm</span>
<span class="s2">from </span><span class="s1">statsmodels.miscmodels.count </span><span class="s2">import </span><span class="s1">PoissonGMLE</span><span class="s2">, </span><span class="s1">PoissonOffsetGMLE</span><span class="s2">, </span><span class="s1">\</span>
                        <span class="s1">PoissonZiGMLE</span>
<span class="s2">from </span><span class="s1">statsmodels.discrete.discrete_model </span><span class="s2">import </span><span class="s1">Poisson</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">ValueWarning</span>


<span class="s1">DEC = </span><span class="s3">4</span>
<span class="s1">DEC4 = </span><span class="s3">4</span>
<span class="s1">DEC5 = </span><span class="s3">5</span>

<span class="s2">class </span><span class="s1">CompareMixin:</span>

    <span class="s2">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(self.res.params</span><span class="s2">, </span><span class="s1">self.res_glm.params</span><span class="s2">, </span><span class="s1">DEC5)</span>
        <span class="s1">assert_almost_equal(self.res.params</span><span class="s2">, </span><span class="s1">self.res_discrete.params</span><span class="s2">, </span><span class="s1">DEC5)</span>

    <span class="s2">def </span><span class="s1">test_cov_params(self):</span>
        <span class="s1">assert_almost_equal(self.res.bse</span><span class="s2">, </span><span class="s1">self.res_glm.bse</span><span class="s2">, </span><span class="s1">DEC5)</span>
        <span class="s1">assert_almost_equal(self.res.bse</span><span class="s2">, </span><span class="s1">self.res_discrete.bse</span><span class="s2">, </span><span class="s1">DEC5)</span>
        <span class="s4">#TODO check problem with the following, precision is low,</span>
        <span class="s4">#dof error? last t-value is 22, 23, error is around 1% for PoissonMLE</span>
        <span class="s4">#this was with constant=1,</span>
        <span class="s4">#now changed constant=0.1 to make it less significant and test passes</span>
        <span class="s4">#overall precision for tstat looks like 1%</span>

        <span class="s4">#assert_almost_equal(self.res.tval, self.res_glm.t(), DEC)</span>
        <span class="s1">assert_almost_equal(self.res.tvalues</span><span class="s2">, </span><span class="s1">self.res_discrete.tvalues</span><span class="s2">, </span><span class="s1">DEC4)</span>
        <span class="s4">#assert_almost_equal(self.res.params, self.res_discrete.params)</span>
        <span class="s1">assert_almost_equal(self.res.pvalues</span><span class="s2">, </span><span class="s1">self.res_discrete.pvalues</span><span class="s2">, </span><span class="s1">DEC)</span>

    <span class="s2">def </span><span class="s1">test_ttest(self):</span>
        <span class="s1">tt = self.res.t_test(np.eye(len(self.res.params)))</span>
        <span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>
        <span class="s1">pvalue = stats.norm.sf(np.abs(tt.tvalue)) * </span><span class="s3">2</span>
        <span class="s1">assert_almost_equal(tt.tvalue</span><span class="s2">, </span><span class="s1">self.res.tvalues</span><span class="s2">, </span><span class="s1">DEC)</span>
        <span class="s1">assert_almost_equal(pvalue</span><span class="s2">, </span><span class="s1">self.res.pvalues</span><span class="s2">, </span><span class="s1">DEC)</span>

    <span class="s2">def </span><span class="s1">test_df(self):</span>
        <span class="s1">res = self.res</span>
        <span class="s1">k_extra = getattr(self</span><span class="s2">, </span><span class="s5">&quot;k_extra&quot;</span><span class="s2">, </span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">k_vars = res.model.exog.shape</span>
        <span class="s2">assert </span><span class="s1">res.df_resid == nobs - k_vars - k_extra</span>
        <span class="s2">assert </span><span class="s1">res.df_model == k_vars - </span><span class="s3">1  </span><span class="s4"># -1 for constant</span>
        <span class="s2">assert </span><span class="s1">len(res.params) == k_vars + k_extra</span>

    <span class="s1">@pytest.mark.smoke</span>
    <span class="s2">def </span><span class="s1">test_summary(self):</span>
        <span class="s1">self.res.summary()</span>


<span class="s2">class </span><span class="s1">TestPoissonMLE(CompareMixin):</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>

        <span class="s4"># generate artificial data</span>
        <span class="s1">np.random.seed(</span><span class="s3">98765678</span><span class="s1">)</span>
        <span class="s1">nobs = </span><span class="s3">200</span>
        <span class="s1">rvs = np.random.randn(nobs</span><span class="s2">,</span><span class="s3">6</span><span class="s1">)</span>
        <span class="s1">data_exog = rvs</span>
        <span class="s1">data_exog = sm.add_constant(data_exog</span><span class="s2">, </span><span class="s1">prepend=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">xbeta = </span><span class="s3">0.1 </span><span class="s1">+ </span><span class="s3">0.1</span><span class="s1">*rvs.sum(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">data_endog = np.random.poisson(np.exp(xbeta))</span>

        <span class="s4">#estimate discretemod.Poisson as benchmark</span>
        <span class="s1">cls.res_discrete = Poisson(data_endog</span><span class="s2">, </span><span class="s1">data_exog).fit(disp=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s1">mod_glm = sm.GLM(data_endog</span><span class="s2">, </span><span class="s1">data_exog</span><span class="s2">, </span><span class="s1">family=sm.families.Poisson())</span>
        <span class="s1">cls.res_glm = mod_glm.fit()</span>

        <span class="s4">#estimate generic MLE</span>
        <span class="s1">cls.mod = PoissonGMLE(data_endog</span><span class="s2">, </span><span class="s1">data_exog)</span>
        <span class="s1">cls.res = cls.mod.fit(start_params=</span><span class="s3">0.9 </span><span class="s1">* cls.res_discrete.params</span><span class="s2">,</span>
                                <span class="s1">method=</span><span class="s5">'bfgs'</span><span class="s2">, </span><span class="s1">disp=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_predict_distribution(self):</span>
        <span class="s1">res = self.res</span>
        <span class="s1">model = self.mod</span>

        <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s4"># No &quot;result&quot; attribute</span>
            <span class="s1">model.predict_distribution(model.exog)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">model.result = res</span>
            <span class="s1">dist = model.predict_distribution(model.exog)</span>
            <span class="s2">assert </span><span class="s1">isinstance(dist</span><span class="s2">, </span><span class="s1">stats._distn_infrastructure.rv_frozen)</span>
            <span class="s1">assert_almost_equal(dist.mean()</span><span class="s2">,</span>
                                <span class="s1">np.exp(model.exog.dot(res.params))</span><span class="s2">,</span>
                                <span class="s3">15</span><span class="s1">)</span>
        <span class="s2">finally</span><span class="s1">:</span>
            <span class="s4"># leave the model object how we found it</span>
            <span class="s1">model.__delattr__(</span><span class="s5">&quot;result&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestPoissonOffset(CompareMixin):</span>
    <span class="s4">#this uses the first exog to construct an offset variable</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s4"># generate artificial data</span>
        <span class="s1">np.random.seed(</span><span class="s3">98765678</span><span class="s1">)</span>
        <span class="s1">nobs = </span><span class="s3">200</span>
        <span class="s1">rvs = np.random.randn(nobs</span><span class="s2">,</span><span class="s3">6</span><span class="s1">)</span>
        <span class="s1">data_exog = rvs</span>
        <span class="s1">data_exog = sm.add_constant(data_exog</span><span class="s2">, </span><span class="s1">prepend=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">xbeta = </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">0.1</span><span class="s1">*rvs.sum(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">data_endog = np.random.poisson(np.exp(xbeta))</span>

        <span class="s1">mod_glm = sm.GLM(data_endog</span><span class="s2">, </span><span class="s1">data_exog</span><span class="s2">, </span><span class="s1">family=sm.families.Poisson())</span>
        <span class="s1">cls.res_glm = mod_glm.fit()</span>

        <span class="s4">#estimate generic MLE</span>
        <span class="s4">#cls.mod = PoissonGMLE(data_endog, data_exog)</span>
        <span class="s4">#res = cls.mod.fit()</span>

        <span class="s4">#create offset variable based on first exog</span>
        <span class="s1">cls.res_discrete = Poisson(data_endog</span><span class="s2">, </span><span class="s1">data_exog).fit(disp=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">offset = cls.res_discrete.params[</span><span class="s3">0</span><span class="s1">] * data_exog[:</span><span class="s2">,</span><span class="s3">0</span><span class="s1">]  </span><span class="s4">#1d ???</span>

        <span class="s4">#estimate discretemod.Poisson as benchmark, now has offset</span>
        <span class="s1">cls.res_discrete = Poisson(data_endog</span><span class="s2">, </span><span class="s1">data_exog[:</span><span class="s2">,</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">,</span>
                                    <span class="s1">offset=offset).fit(disp=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s1">mod_glm = sm.GLM(data_endog</span><span class="s2">, </span><span class="s1">data_exog</span><span class="s2">, </span><span class="s1">family=sm.families.Poisson())</span>
        <span class="s1">cls.res_glm = mod_glm.fit()</span>

        <span class="s4">#cls.res = PoissonOffsetGMLE(data_endog, data_exog[:,1:], offset=offset).fit(start_params = np.ones(6)/2., method='nm')</span>
        <span class="s1">modo = PoissonOffsetGMLE(data_endog</span><span class="s2">, </span><span class="s1">data_exog[:</span><span class="s2">,</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">offset=offset)</span>
        <span class="s1">cls.res = modo.fit(start_params = </span><span class="s3">0.9</span><span class="s1">*cls.res_discrete.params</span><span class="s2">,</span>
                            <span class="s1">method=</span><span class="s5">'bfgs'</span><span class="s2">, </span><span class="s1">disp=</span><span class="s3">0</span><span class="s1">)</span>



    <span class="s2">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(self.res.params</span><span class="s2">, </span><span class="s1">self.res_glm.params[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">DEC)</span>
        <span class="s1">assert_almost_equal(self.res.params</span><span class="s2">, </span><span class="s1">self.res_discrete.params</span><span class="s2">, </span><span class="s1">DEC)</span>

    <span class="s2">def </span><span class="s1">test_cov_params(self):</span>
        <span class="s1">assert_almost_equal(self.res.bse</span><span class="s2">, </span><span class="s1">self.res_glm.bse[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">DEC-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(self.res.bse</span><span class="s2">, </span><span class="s1">self.res_discrete.bse</span><span class="s2">, </span><span class="s1">DEC5)</span>
        <span class="s4">#precision of next is very low ???</span>
        <span class="s4">#assert_almost_equal(self.res.tval, self.res_glm.t()[1:], DEC)</span>
        <span class="s4">#assert_almost_equal(self.res.params, self.res_discrete.params)</span>


<span class="s4">#DEC = DEC - 1</span>
<span class="s2">class </span><span class="s1">TestPoissonZi(CompareMixin):</span>
    <span class="s4">#this uses the first exog to construct an offset variable</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>

        <span class="s4"># generate artificial data</span>
        <span class="s1">np.random.seed(</span><span class="s3">98765678</span><span class="s1">)</span>
        <span class="s1">nobs = </span><span class="s3">200</span>
        <span class="s1">rvs = np.random.randn(nobs</span><span class="s2">,</span><span class="s3">6</span><span class="s1">)</span>
        <span class="s1">data_exog = rvs</span>
        <span class="s1">data_exog = sm.add_constant(data_exog</span><span class="s2">, </span><span class="s1">prepend=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">xbeta = </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">0.1</span><span class="s1">*rvs.sum(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">data_endog = np.random.poisson(np.exp(xbeta))</span>
        <span class="s1">cls.k_extra = </span><span class="s3">1</span>

        <span class="s1">mod_glm = sm.GLM(data_endog</span><span class="s2">, </span><span class="s1">data_exog</span><span class="s2">, </span><span class="s1">family=sm.families.Poisson())</span>
        <span class="s1">cls.res_glm = mod_glm.fit()</span>

        <span class="s4">#estimate generic MLE</span>
        <span class="s4">#cls.mod = PoissonGMLE(data_endog, data_exog)</span>
        <span class="s4">#res = cls.mod.fit()</span>

        <span class="s4">#create offset variable based on first exog</span>
        <span class="s1">cls.res_discrete = Poisson(data_endog</span><span class="s2">, </span><span class="s1">data_exog).fit(disp=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">offset = cls.res_discrete.params[</span><span class="s3">0</span><span class="s1">] * data_exog[:</span><span class="s2">,</span><span class="s3">0</span><span class="s1">]  </span><span class="s4">#1d ???</span>

        <span class="s4">#estimate discretemod.Poisson as benchmark, now has offset</span>
        <span class="s1">cls.res_discrete = Poisson(data_endog</span><span class="s2">, </span><span class="s1">data_exog[:</span><span class="s2">,</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">offset=offset).fit(disp=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s4"># Note : ZI has one extra parameter</span>
        <span class="s1">cls.res = PoissonZiGMLE(data_endog</span><span class="s2">, </span><span class="s1">data_exog[:</span><span class="s2">,</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">offset=offset).fit(</span>
                            <span class="s1">start_params=np.r_[</span><span class="s3">0.9</span><span class="s1">*cls.res_discrete.params</span><span class="s2">,</span><span class="s3">10</span><span class="s1">]</span><span class="s2">,</span>
                            <span class="s1">method=</span><span class="s5">'bfgs'</span><span class="s2">, </span><span class="s1">disp=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s1">cls.decimal = </span><span class="s3">4</span>

    <span class="s2">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(self.res.params[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.res_glm.params[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">self.decimal)</span>
        <span class="s1">assert_almost_equal(self.res.params[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.res_discrete.params</span><span class="s2">, </span><span class="s1">self.decimal)</span>

    <span class="s2">def </span><span class="s1">test_cov_params(self):</span>
        <span class="s4">#skip until I have test with zero-inflated data</span>
        <span class="s4">#use bsejac for now since it seems to work</span>
        <span class="s1">assert_almost_equal(self.res.bsejac[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.res_glm.bse[</span><span class="s3">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">self.decimal-</span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(self.res.bsejac[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.res_discrete.bse</span><span class="s2">, </span><span class="s1">self.decimal-</span><span class="s3">2</span><span class="s1">)</span>
        <span class="s4">#assert_almost_equal(self.res.tval[:-1], self.res_glm.t()[1:], self.decimal)</span>


    <span class="s2">def </span><span class="s1">test_exog_names_warning(self):</span>
        <span class="s1">mod = self.res.model</span>
        <span class="s1">mod1 = PoissonOffsetGMLE(mod.endog</span><span class="s2">, </span><span class="s1">mod.exog</span><span class="s2">, </span><span class="s1">offset=mod.offset)</span>
        <span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">assert_warns</span>
        <span class="s1">mod1.data.xnames = mod1.data.xnames * </span><span class="s3">2</span>
        <span class="s1">assert_warns(ValueWarning</span><span class="s2">, </span><span class="s1">mod1.fit</span><span class="s2">, </span><span class="s1">disp=</span><span class="s3">0</span><span class="s1">)</span>
</pre>
</body>
</html>
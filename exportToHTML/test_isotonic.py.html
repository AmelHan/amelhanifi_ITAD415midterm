<html>
<head>
<title>test_isotonic.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_isotonic.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">copy</span>
<span class="s0">import </span><span class="s1">pickle</span>
<span class="s0">import </span><span class="s1">warnings</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy.special </span><span class="s0">import </span><span class="s1">expit</span>

<span class="s0">import </span><span class="s1">sklearn</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">make_regression</span>
<span class="s0">from </span><span class="s1">sklearn.isotonic </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">IsotonicRegression</span><span class="s0">,</span>
    <span class="s1">_make_unique</span><span class="s0">,</span>
    <span class="s1">check_increasing</span><span class="s0">,</span>
    <span class="s1">isotonic_regression</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">shuffle</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils.validation </span><span class="s0">import </span><span class="s1">check_array</span>


<span class="s0">def </span><span class="s1">test_permutation_invariance():</span>
    <span class="s2"># check that fit is permutation invariant.</span>
    <span class="s2"># regression test of missing sorting of sample-weights</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">41</span><span class="s0">, </span><span class="s3">51</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">24</span><span class="s1">]</span>
    <span class="s1">sample_weight = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span>
    <span class="s1">x_s</span><span class="s0">, </span><span class="s1">y_s</span><span class="s0">, </span><span class="s1">sample_weight_s = shuffle(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">y_transformed = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
    <span class="s1">y_transformed_s = ir.fit(x_s</span><span class="s0">, </span><span class="s1">y_s</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight_s).transform(x)</span>

    <span class="s1">assert_array_equal(y_transformed</span><span class="s0">, </span><span class="s1">y_transformed_s)</span>


<span class="s0">def </span><span class="s1">test_check_increasing_small_number_of_samples():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1.1</span><span class="s0">, </span><span class="s3">1.05</span><span class="s1">]</span>

    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_check_increasing_up():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2.77</span><span class="s0">, </span><span class="s3">8.99</span><span class="s0">, </span><span class="s3">8.99</span><span class="s0">, </span><span class="s3">50</span><span class="s1">]</span>

    <span class="s2"># Check that we got increasing=True and no warnings</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_check_increasing_up_extreme():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>

    <span class="s2"># Check that we got increasing=True and no warnings</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_check_increasing_down():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1.5</span><span class="s0">, </span><span class="s1">-</span><span class="s3">2.77</span><span class="s0">, </span><span class="s1">-</span><span class="s3">8.99</span><span class="s0">, </span><span class="s1">-</span><span class="s3">8.99</span><span class="s0">, </span><span class="s1">-</span><span class="s3">50</span><span class="s1">]</span>

    <span class="s2"># Check that we got increasing=False and no warnings</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert not </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_check_increasing_down_extreme():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">2</span><span class="s0">, </span><span class="s1">-</span><span class="s3">3</span><span class="s0">, </span><span class="s1">-</span><span class="s3">4</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s1">]</span>

    <span class="s2"># Check that we got increasing=False and no warnings</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert not </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_check_ci_warn():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s1">-</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s1">]</span>

    <span class="s2"># Check that we got increasing=False and CI interval warning</span>
    <span class="s1">msg = </span><span class="s4">&quot;interval&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">is_increasing = check_increasing(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert not </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression():</span>
    <span class="s1">y = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">y_ = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(y_</span><span class="s0">, </span><span class="s1">isotonic_regression(y))</span>

    <span class="s1">y = np.array([</span><span class="s3">10</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">y_ = np.array([</span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(y_</span><span class="s0">, </span><span class="s1">isotonic_regression(y))</span>

    <span class="s1">x = np.arange(len(y))</span>
    <span class="s1">ir = IsotonicRegression(y_min=</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(ir.fit(x</span><span class="s0">, </span><span class="s1">y).transform(x)</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s1">assert_array_equal(ir.transform(x)</span><span class="s0">, </span><span class="s1">ir.predict(x))</span>

    <span class="s2"># check that it is immune to permutation</span>
    <span class="s1">perm = np.random.permutation(len(y))</span>
    <span class="s1">ir = IsotonicRegression(y_min=</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(ir.fit_transform(x[perm]</span><span class="s0">, </span><span class="s1">y[perm])</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)[perm])</span>
    <span class="s1">assert_array_equal(ir.transform(x[perm])</span><span class="s0">, </span><span class="s1">ir.transform(x)[perm])</span>

    <span class="s2"># check we don't crash when all x are equal:</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">assert_array_equal(ir.fit_transform(np.ones(len(x))</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">np.mean(y))</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_ties_min():</span>
    <span class="s2"># Setup examples with ties on minimum</span>
    <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]</span>
    <span class="s1">y_true = [</span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]</span>

    <span class="s2"># Check that we get identical results for fit/transform and fit_transform</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(ir.fit(x</span><span class="s0">, </span><span class="s1">y).transform(x)</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s1">assert_array_equal(y_true</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_ties_max():</span>
    <span class="s2"># Setup examples with ties on maximum</span>
    <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]</span>
    <span class="s1">y_true = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5.5</span><span class="s0">, </span><span class="s3">5.5</span><span class="s1">]</span>

    <span class="s2"># Check that we get identical results for fit/transform and fit_transform</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(ir.fit(x</span><span class="s0">, </span><span class="s1">y).transform(x)</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s1">assert_array_equal(y_true</span><span class="s0">, </span><span class="s1">ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_ties_secondary_():</span>
    <span class="s5">&quot;&quot;&quot; 
    Test isotonic regression fit, transform  and fit_transform 
    against the &quot;secondary&quot; ties method and &quot;pituitary&quot; data from R 
     &quot;isotone&quot; package, as detailed in: J. d. Leeuw, K. Hornik, P. Mair, 
     Isotone Optimization in R: Pool-Adjacent-Violators Algorithm 
    (PAVA) and Active Set Methods 
 
    Set values based on pituitary example and 
     the following R command detailed in the paper above: 
    &gt; library(&quot;isotone&quot;) 
    &gt; data(&quot;pituitary&quot;) 
    &gt; res1 &lt;- gpava(pituitary$age, pituitary$size, ties=&quot;secondary&quot;) 
    &gt; res1$x 
 
    `isotone` version: 1.0-2, 2014-09-07 
    R version: R version 3.1.1 (2014-07-10) 
    &quot;&quot;&quot;</span>
    <span class="s1">x = [</span><span class="s3">8</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">14</span><span class="s0">, </span><span class="s3">14</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">21</span><span class="s0">, </span><span class="s3">23.5</span><span class="s0">, </span><span class="s3">23</span><span class="s0">, </span><span class="s3">24</span><span class="s0">, </span><span class="s3">21</span><span class="s0">, </span><span class="s3">25</span><span class="s0">, </span><span class="s3">21.5</span><span class="s0">, </span><span class="s3">22</span><span class="s0">, </span><span class="s3">19</span><span class="s0">, </span><span class="s3">23.5</span><span class="s0">, </span><span class="s3">25</span><span class="s1">]</span>
    <span class="s1">y_true = [</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">22.22222</span><span class="s0">,</span>
        <span class="s3">24.25</span><span class="s0">,</span>
        <span class="s3">24.25</span><span class="s0">,</span>
    <span class="s1">]</span>

    <span class="s2"># Check fit, transform and fit_transform</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_almost_equal(ir.transform(x)</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_with_ties_in_differently_sized_groups():</span>
    <span class="s5">&quot;&quot;&quot; 
    Non-regression test to handle issue 9432: 
    https://github.com/scikit-learn/scikit-learn/issues/9432 
 
    Compare against output in R: 
    &gt; library(&quot;isotone&quot;) 
    &gt; x &lt;- c(0, 1, 1, 2, 3, 4) 
    &gt; y &lt;- c(0, 0, 1, 0, 0, 1) 
    &gt; res1 &lt;- gpava(x, y, ties=&quot;secondary&quot;) 
    &gt; res1$x 
 
    `isotone` version: 1.1-0, 2015-07-24 
    R version: R version 3.3.2 (2016-10-31) 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">y_true = np.array([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_almost_equal(ir.transform(x)</span><span class="s0">, </span><span class="s1">y_true)</span>
    <span class="s1">assert_array_almost_equal(ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">y_true)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_reversed():</span>
    <span class="s1">y = np.array([</span><span class="s3">10</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">6.1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">])</span>
    <span class="s1">y_ = IsotonicRegression(increasing=</span><span class="s0">False</span><span class="s1">).fit_transform(np.arange(len(y))</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(np.ones(y_[:-</span><span class="s3">1</span><span class="s1">].shape)</span><span class="s0">, </span><span class="s1">((y_[:-</span><span class="s3">1</span><span class="s1">] - y_[</span><span class="s3">1</span><span class="s1">:]) &gt;= </span><span class="s3">0</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_auto_decreasing():</span>
    <span class="s2"># Set y and x for decreasing</span>
    <span class="s1">y = np.array([</span><span class="s3">10</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">6.1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit_transform</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">w:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">y_ = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)</span>
        <span class="s2"># work-around for pearson divide warnings in scipy &lt;= 0.17.0</span>
        <span class="s0">assert </span><span class="s1">all([</span><span class="s4">&quot;invalid value encountered in &quot; </span><span class="s0">in </span><span class="s1">str(warn.message) </span><span class="s0">for </span><span class="s1">warn </span><span class="s0">in </span><span class="s1">w])</span>

    <span class="s2"># Check that relationship decreases</span>
    <span class="s1">is_increasing = y_[</span><span class="s3">0</span><span class="s1">] &lt; y_[-</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s0">assert not </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_auto_increasing():</span>
    <span class="s2"># Set y and x for decreasing</span>
    <span class="s1">y = np.array([</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6.1</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit_transform</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">w:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">y_ = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)</span>
        <span class="s2"># work-around for pearson divide warnings in scipy &lt;= 0.17.0</span>
        <span class="s0">assert </span><span class="s1">all([</span><span class="s4">&quot;invalid value encountered in &quot; </span><span class="s0">in </span><span class="s1">str(warn.message) </span><span class="s0">for </span><span class="s1">warn </span><span class="s0">in </span><span class="s1">w])</span>

    <span class="s2"># Check that relationship increases</span>
    <span class="s1">is_increasing = y_[</span><span class="s3">0</span><span class="s1">] &lt; y_[-</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">is_increasing</span>


<span class="s0">def </span><span class="s1">test_assert_raises_exceptions():</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>

    <span class="s1">msg = </span><span class="s4">&quot;Found input variables with inconsistent numbers of samples&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">ir.fit([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">])</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">ir.fit([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">7</span><span class="s1">])</span>

    <span class="s1">msg = </span><span class="s4">&quot;X should be a 1d array&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">ir.fit(rng.randn(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>

    <span class="s1">msg = </span><span class="s4">&quot;Isotonic regression input X should be a 1d array&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">ir.transform(rng.randn(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">test_isotonic_sample_weight_parameter_default_value():</span>
    <span class="s2"># check if default value of sample_weight parameter is one</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s2"># random test data</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">100</span>
    <span class="s1">x = np.arange(n)</span>
    <span class="s1">y = rng.randint(-</span><span class="s3">50</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s1">size=(n</span><span class="s0">,</span><span class="s1">)) + </span><span class="s3">50.0 </span><span class="s1">* np.log(</span><span class="s3">1 </span><span class="s1">+ np.arange(n))</span>
    <span class="s2"># check if value is correctly used</span>
    <span class="s1">weights = np.ones(n)</span>
    <span class="s1">y_set_value = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=weights)</span>
    <span class="s1">y_default_value = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">assert_array_equal(y_set_value</span><span class="s0">, </span><span class="s1">y_default_value)</span>


<span class="s0">def </span><span class="s1">test_isotonic_min_max_boundaries():</span>
    <span class="s2"># check if min value is used correctly</span>
    <span class="s1">ir = IsotonicRegression(y_min=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">6</span>
    <span class="s1">x = np.arange(n)</span>
    <span class="s1">y = np.arange(n)</span>
    <span class="s1">y_test = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span>
    <span class="s1">y_result = np.round(ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s1">assert_array_equal(y_result</span><span class="s0">, </span><span class="s1">y_test)</span>


<span class="s0">def </span><span class="s1">test_isotonic_sample_weight():</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">41</span><span class="s0">, </span><span class="s3">51</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">24</span><span class="s1">]</span>
    <span class="s1">sample_weight = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span>
    <span class="s1">expected_y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">13.95</span><span class="s0">, </span><span class="s3">13.95</span><span class="s0">, </span><span class="s3">13.95</span><span class="s0">, </span><span class="s3">13.95</span><span class="s0">, </span><span class="s3">13.95</span><span class="s0">, </span><span class="s3">24</span><span class="s1">]</span>
    <span class="s1">received_y = ir.fit_transform(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>

    <span class="s1">assert_array_equal(expected_y</span><span class="s0">, </span><span class="s1">received_y)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_oob_raise():</span>
    <span class="s2"># Set y and x</span>
    <span class="s1">y = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;raise&quot;</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># Check that an exception is thrown</span>
    <span class="s1">msg = </span><span class="s4">&quot;in x_new is below the interpolation range&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">ir.predict([min(x) - </span><span class="s3">10</span><span class="s0">, </span><span class="s1">max(x) + </span><span class="s3">10</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_oob_clip():</span>
    <span class="s2"># Set y and x</span>
    <span class="s1">y = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;clip&quot;</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># Predict from  training and test x and check that min/max match.</span>
    <span class="s1">y1 = ir.predict([min(x) - </span><span class="s3">10</span><span class="s0">, </span><span class="s1">max(x) + </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">y2 = ir.predict(x)</span>
    <span class="s0">assert </span><span class="s1">max(y1) == max(y2)</span>
    <span class="s0">assert </span><span class="s1">min(y1) == min(y2)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_oob_nan():</span>
    <span class="s2"># Set y and x</span>
    <span class="s1">y = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;nan&quot;</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># Predict from  training and test x and check that we have two NaNs.</span>
    <span class="s1">y1 = ir.predict([min(x) - </span><span class="s3">10</span><span class="s0">, </span><span class="s1">max(x) + </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">sum(np.isnan(y1)) == </span><span class="s3">2</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_pickle():</span>
    <span class="s1">y = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">x = np.arange(len(y))</span>

    <span class="s2"># Create model and fit</span>
    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;clip&quot;</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">ir_ser = pickle.dumps(ir</span><span class="s0">, </span><span class="s1">pickle.HIGHEST_PROTOCOL)</span>
    <span class="s1">ir2 = pickle.loads(ir_ser)</span>
    <span class="s1">np.testing.assert_array_equal(ir.predict(x)</span><span class="s0">, </span><span class="s1">ir2.predict(x))</span>


<span class="s0">def </span><span class="s1">test_isotonic_duplicate_min_entry():</span>
    <span class="s1">x = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>

    <span class="s1">ir = IsotonicRegression(increasing=</span><span class="s0">True, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;clip&quot;</span><span class="s1">)</span>
    <span class="s1">ir.fit(x</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">all_predictions_finite = np.all(np.isfinite(ir.predict(x)))</span>
    <span class="s0">assert </span><span class="s1">all_predictions_finite</span>


<span class="s0">def </span><span class="s1">test_isotonic_ymin_ymax():</span>
    <span class="s2"># Test from @NelleV's issue:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/6921</span>
    <span class="s1">x = np.array(</span>
        <span class="s1">[</span>
            <span class="s3">1.263</span><span class="s0">,</span>
            <span class="s3">1.318</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.572</span><span class="s0">,</span>
            <span class="s3">0.307</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.707</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.176</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">1.599</span><span class="s0">,</span>
            <span class="s3">1.059</span><span class="s0">,</span>
            <span class="s3">1.396</span><span class="s0">,</span>
            <span class="s3">1.906</span><span class="s0">,</span>
            <span class="s3">0.210</span><span class="s0">,</span>
            <span class="s3">0.028</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.081</span><span class="s0">,</span>
            <span class="s3">0.444</span><span class="s0">,</span>
            <span class="s3">0.018</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.377</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.896</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">0.377</span><span class="s0">,</span>
            <span class="s1">-</span><span class="s3">1.327</span><span class="s0">,</span>
            <span class="s3">0.180</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">y = isotonic_regression(x</span><span class="s0">, </span><span class="s1">y_min=</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">0.1</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.all(y &gt;= </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.all(y &lt;= </span><span class="s3">0.1</span><span class="s1">)</span>

    <span class="s2"># Also test decreasing case since the logic there is different</span>
    <span class="s1">y = isotonic_regression(x</span><span class="s0">, </span><span class="s1">y_min=</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">increasing=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.all(y &gt;= </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.all(y &lt;= </span><span class="s3">0.1</span><span class="s1">)</span>

    <span class="s2"># Finally, test with only one bound</span>
    <span class="s1">y = isotonic_regression(x</span><span class="s0">, </span><span class="s1">y_min=</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">increasing=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.all(y &gt;= </span><span class="s3">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_isotonic_zero_weight_loop():</span>
    <span class="s2"># Test from @ogrisel's issue:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/4297</span>

    <span class="s2"># Get deterministic RNG with seed</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>

    <span class="s2"># Create regression and samples</span>
    <span class="s1">regression = IsotonicRegression()</span>
    <span class="s1">n_samples = </span><span class="s3">50</span>
    <span class="s1">x = np.linspace(-</span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">n_samples)</span>
    <span class="s1">y = x + rng.uniform(size=n_samples)</span>

    <span class="s2"># Get some random weights and zero out</span>
    <span class="s1">w = rng.uniform(size=n_samples)</span>
    <span class="s1">w[</span><span class="s3">5</span><span class="s1">:</span><span class="s3">8</span><span class="s1">] = </span><span class="s3">0</span>
    <span class="s1">regression.fit(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=w)</span>

    <span class="s2"># This will hang in failure case.</span>
    <span class="s1">regression.fit(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=w)</span>


<span class="s0">def </span><span class="s1">test_fast_predict():</span>
    <span class="s2"># test that the faster prediction change doesn't</span>
    <span class="s2"># affect out-of-sample predictions:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/pull/6206</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">123</span><span class="s1">)</span>
    <span class="s1">n_samples = </span><span class="s3">10</span><span class="s1">**</span><span class="s3">3</span>
    <span class="s2"># X values over the -10,10 range</span>
    <span class="s1">X_train = </span><span class="s3">20.0 </span><span class="s1">* rng.rand(n_samples) - </span><span class="s3">10</span>
    <span class="s1">y_train = (</span>
        <span class="s1">np.less(rng.rand(n_samples)</span><span class="s0">, </span><span class="s1">expit(X_train)).astype(</span><span class="s4">&quot;int64&quot;</span><span class="s1">).astype(</span><span class="s4">&quot;float64&quot;</span><span class="s1">)</span>
    <span class="s1">)</span>

    <span class="s1">weights = rng.rand(n_samples)</span>
    <span class="s2"># we also want to test that everything still works when some weights are 0</span>
    <span class="s1">weights[rng.rand(n_samples) &lt; </span><span class="s3">0.1</span><span class="s1">] = </span><span class="s3">0</span>

    <span class="s1">slow_model = IsotonicRegression(y_min=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;clip&quot;</span><span class="s1">)</span>
    <span class="s1">fast_model = IsotonicRegression(y_min=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">y_max=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">out_of_bounds=</span><span class="s4">&quot;clip&quot;</span><span class="s1">)</span>

    <span class="s2"># Build interpolation function with ALL input data, not just the</span>
    <span class="s2"># non-redundant subset. The following 2 lines are taken from the</span>
    <span class="s2"># .fit() method, without removing unnecessary points</span>
    <span class="s1">X_train_fit</span><span class="s0">, </span><span class="s1">y_train_fit = slow_model._build_y(</span>
        <span class="s1">X_train</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">sample_weight=weights</span><span class="s0">, </span><span class="s1">trim_duplicates=</span><span class="s0">False</span>
    <span class="s1">)</span>
    <span class="s1">slow_model._build_f(X_train_fit</span><span class="s0">, </span><span class="s1">y_train_fit)</span>

    <span class="s2"># fit with just the necessary data</span>
    <span class="s1">fast_model.fit(X_train</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">sample_weight=weights)</span>

    <span class="s1">X_test = </span><span class="s3">20.0 </span><span class="s1">* rng.rand(n_samples) - </span><span class="s3">10</span>
    <span class="s1">y_pred_slow = slow_model.predict(X_test)</span>
    <span class="s1">y_pred_fast = fast_model.predict(X_test)</span>

    <span class="s1">assert_array_equal(y_pred_slow</span><span class="s0">, </span><span class="s1">y_pred_fast)</span>


<span class="s0">def </span><span class="s1">test_isotonic_copy_before_fit():</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/6628</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s1">copy.copy(ir)</span>


<span class="s0">def </span><span class="s1">test_isotonic_dtype():</span>
    <span class="s1">y = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s1">weights = np.array([</span><span class="s3">0.9</span><span class="s0">, </span><span class="s3">0.9</span><span class="s0">, </span><span class="s3">0.9</span><span class="s0">, </span><span class="s3">0.9</span><span class="s0">, </span><span class="s3">0.9</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">reg = IsotonicRegression()</span>

    <span class="s0">for </span><span class="s1">dtype </span><span class="s0">in </span><span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.int64</span><span class="s0">, </span><span class="s1">np.float32</span><span class="s0">, </span><span class="s1">np.float64):</span>
        <span class="s0">for </span><span class="s1">sample_weight </span><span class="s0">in </span><span class="s1">(</span><span class="s0">None, </span><span class="s1">weights.astype(np.float32)</span><span class="s0">, </span><span class="s1">weights):</span>
            <span class="s1">y_np = np.array(y</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
            <span class="s1">expected_dtype = check_array(</span>
                <span class="s1">y_np</span><span class="s0">, </span><span class="s1">dtype=[np.float64</span><span class="s0">, </span><span class="s1">np.float32]</span><span class="s0">, </span><span class="s1">ensure_2d=</span><span class="s0">False</span>
            <span class="s1">).dtype</span>

            <span class="s1">res = isotonic_regression(y_np</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
            <span class="s0">assert </span><span class="s1">res.dtype == expected_dtype</span>

            <span class="s1">X = np.arange(len(y)).astype(dtype)</span>
            <span class="s1">reg.fit(X</span><span class="s0">, </span><span class="s1">y_np</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
            <span class="s1">res = reg.predict(X)</span>
            <span class="s0">assert </span><span class="s1">res.dtype == expected_dtype</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;y_dtype&quot;</span><span class="s0">, </span><span class="s1">[np.int32</span><span class="s0">, </span><span class="s1">np.int64</span><span class="s0">, </span><span class="s1">np.float32</span><span class="s0">, </span><span class="s1">np.float64])</span>
<span class="s0">def </span><span class="s1">test_isotonic_mismatched_dtype(y_dtype):</span>
    <span class="s2"># regression test for #15004</span>
    <span class="s2"># check that data are converted when X and y dtype differ</span>
    <span class="s1">reg = IsotonicRegression()</span>
    <span class="s1">y = np.array([</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=y_dtype)</span>
    <span class="s1">X = np.arange(len(y)</span><span class="s0">, </span><span class="s1">dtype=np.float32)</span>
    <span class="s1">reg.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">reg.predict(X).dtype == X.dtype</span>


<span class="s0">def </span><span class="s1">test_make_unique_dtype():</span>
    <span class="s1">x_list = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span>
    <span class="s0">for </span><span class="s1">dtype </span><span class="s0">in </span><span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float64):</span>
        <span class="s1">x = np.array(x_list</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
        <span class="s1">y = x.copy()</span>
        <span class="s1">w = np.ones_like(x)</span>
        <span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">w = _make_unique(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">w)</span>
        <span class="s1">assert_array_equal(x</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s1">])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">[np.float64</span><span class="s0">, </span><span class="s1">np.float32])</span>
<span class="s0">def </span><span class="s1">test_make_unique_tolerance(dtype):</span>
    <span class="s2"># Check that equality takes account of np.finfo tolerance</span>
    <span class="s1">x = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1e-16</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">1e-14</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">y = x.copy()</span>
    <span class="s1">w = np.ones_like(x)</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">w = _make_unique(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">w)</span>
    <span class="s0">if </span><span class="s1">dtype == np.float64:</span>
        <span class="s1">x_out = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">1e-14</span><span class="s1">])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">x_out = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(x</span><span class="s0">, </span><span class="s1">x_out)</span>


<span class="s0">def </span><span class="s1">test_isotonic_make_unique_tolerance():</span>
    <span class="s2"># Check that averaging of targets for duplicate X is done correctly,</span>
    <span class="s2"># taking into account tolerance</span>
    <span class="s1">X = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">1e-16</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">ireg = IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred = ireg.predict([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>

    <span class="s1">assert_array_equal(y_pred</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0.75</span><span class="s0">, </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2.25</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]))</span>
    <span class="s1">assert_array_equal(ireg.X_thresholds_</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]))</span>
    <span class="s1">assert_array_equal(ireg.y_thresholds_</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">3.0</span><span class="s1">]))</span>


<span class="s0">def </span><span class="s1">test_isotonic_non_regression_inf_slope():</span>
    <span class="s2"># Non-regression test to ensure that inf values are not returned</span>
    <span class="s2"># see: https://github.com/scikit-learn/scikit-learn/issues/10903</span>
    <span class="s1">X = np.array([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">4.1e-320</span><span class="s0">, </span><span class="s3">4.4e-314</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
    <span class="s1">y = np.array([</span><span class="s3">0.42</span><span class="s0">, </span><span class="s3">0.42</span><span class="s0">, </span><span class="s3">0.44</span><span class="s0">, </span><span class="s3">0.44</span><span class="s1">])</span>
    <span class="s1">ireg = IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred = ireg.predict(np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2.1e-319</span><span class="s0">, </span><span class="s3">5.4e-316</span><span class="s0">, </span><span class="s3">1e-10</span><span class="s1">]))</span>
    <span class="s0">assert </span><span class="s1">np.all(np.isfinite(y_pred))</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;increasing&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_isotonic_thresholds(increasing):</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_samples = </span><span class="s3">30</span>
    <span class="s1">X = rng.normal(size=n_samples)</span>
    <span class="s1">y = rng.normal(size=n_samples)</span>
    <span class="s1">ireg = IsotonicRegression(increasing=increasing).fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">X_thresholds</span><span class="s0">, </span><span class="s1">y_thresholds = ireg.X_thresholds_</span><span class="s0">, </span><span class="s1">ireg.y_thresholds_</span>
    <span class="s0">assert </span><span class="s1">X_thresholds.shape == y_thresholds.shape</span>

    <span class="s2"># Input thresholds are a strict subset of the training set (unless</span>
    <span class="s2"># the data is already strictly monotonic which is not the case with</span>
    <span class="s2"># this random data)</span>
    <span class="s0">assert </span><span class="s1">X_thresholds.shape[</span><span class="s3">0</span><span class="s1">] &lt; X.shape[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">np.isin(X_thresholds</span><span class="s0">, </span><span class="s1">X).all()</span>

    <span class="s2"># Output thresholds lie in the range of the training set:</span>
    <span class="s0">assert </span><span class="s1">y_thresholds.max() &lt;= y.max()</span>
    <span class="s0">assert </span><span class="s1">y_thresholds.min() &gt;= y.min()</span>

    <span class="s0">assert </span><span class="s1">all(np.diff(X_thresholds) &gt; </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">increasing:</span>
        <span class="s0">assert </span><span class="s1">all(np.diff(y_thresholds) &gt;= </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">all(np.diff(y_thresholds) &lt;= </span><span class="s3">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_input_shape_validation():</span>
    <span class="s2"># Test from #15012</span>
    <span class="s2"># Check that IsotonicRegression can handle 2darray with only 1 feature</span>
    <span class="s1">X = np.arange(</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">X_2d = X.reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">y = np.arange(</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s1">iso_reg = IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">iso_reg_2d = IsotonicRegression().fit(X_2d</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">assert </span><span class="s1">iso_reg.X_max_ == iso_reg_2d.X_max_</span>
    <span class="s0">assert </span><span class="s1">iso_reg.X_min_ == iso_reg_2d.X_min_</span>
    <span class="s0">assert </span><span class="s1">iso_reg.y_max == iso_reg_2d.y_max</span>
    <span class="s0">assert </span><span class="s1">iso_reg.y_min == iso_reg_2d.y_min</span>
    <span class="s1">assert_array_equal(iso_reg.X_thresholds_</span><span class="s0">, </span><span class="s1">iso_reg_2d.X_thresholds_)</span>
    <span class="s1">assert_array_equal(iso_reg.y_thresholds_</span><span class="s0">, </span><span class="s1">iso_reg_2d.y_thresholds_)</span>

    <span class="s1">y_pred1 = iso_reg.predict(X)</span>
    <span class="s1">y_pred2 = iso_reg_2d.predict(X_2d)</span>
    <span class="s1">assert_allclose(y_pred1</span><span class="s0">, </span><span class="s1">y_pred2)</span>


<span class="s0">def </span><span class="s1">test_isotonic_2darray_more_than_1_feature():</span>
    <span class="s2"># Ensure IsotonicRegression raises error if input has more than 1 feature</span>
    <span class="s1">X = np.arange(</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">X_2d = np.c_[X</span><span class="s0">, </span><span class="s1">X]</span>
    <span class="s1">y = np.arange(</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s1">msg = </span><span class="s4">&quot;should be a 1d array or 2d array with 1 feature&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">IsotonicRegression().fit(X_2d</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">iso_reg = IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">iso_reg.predict(X_2d)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">iso_reg.transform(X_2d)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_sample_weight_not_overwritten():</span>
    <span class="s5">&quot;&quot;&quot;Check that calling fitting function of isotonic regression will not 
    overwrite `sample_weight`. 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/20508 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">41</span><span class="s1">)</span>
    <span class="s1">sample_weight_original = np.ones_like(y)</span>
    <span class="s1">sample_weight_original[</span><span class="s3">0</span><span class="s1">] = </span><span class="s3">10</span>
    <span class="s1">sample_weight_fit = sample_weight_original.copy()</span>

    <span class="s1">isotonic_regression(y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight_fit)</span>
    <span class="s1">assert_allclose(sample_weight_fit</span><span class="s0">, </span><span class="s1">sample_weight_original)</span>

    <span class="s1">IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight_fit)</span>
    <span class="s1">assert_allclose(sample_weight_fit</span><span class="s0">, </span><span class="s1">sample_weight_original)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;shape&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">&quot;1d&quot;</span><span class="s0">, </span><span class="s4">&quot;2d&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_get_feature_names_out(shape):</span>
    <span class="s5">&quot;&quot;&quot;Check `get_feature_names_out` for `IsotonicRegression`.&quot;&quot;&quot;</span>
    <span class="s1">X = np.arange(</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">shape == </span><span class="s4">&quot;2d&quot;</span><span class="s1">:</span>
        <span class="s1">X = X.reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">y = np.arange(</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s1">iso = IsotonicRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">names = iso.get_feature_names_out()</span>
    <span class="s0">assert </span><span class="s1">isinstance(names</span><span class="s0">, </span><span class="s1">np.ndarray)</span>
    <span class="s0">assert </span><span class="s1">names.dtype == object</span>
    <span class="s1">assert_array_equal([</span><span class="s4">&quot;isotonicregression0&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">names)</span>


<span class="s0">def </span><span class="s1">test_isotonic_regression_output_predict():</span>
    <span class="s5">&quot;&quot;&quot;Check that `predict` does return the expected output type. 
 
    We need to check that `transform` will output a DataFrame and a NumPy array 
    when we set `transform_output` to `pandas`. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/25499 
    &quot;&quot;&quot;</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s4">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">regressor = IsotonicRegression()</span>
    <span class="s0">with </span><span class="s1">sklearn.config_context(transform_output=</span><span class="s4">&quot;pandas&quot;</span><span class="s1">):</span>
        <span class="s1">regressor.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
        <span class="s1">X_trans = regressor.transform(X)</span>
        <span class="s1">y_pred = regressor.predict(X)</span>

    <span class="s0">assert </span><span class="s1">isinstance(X_trans</span><span class="s0">, </span><span class="s1">pd.DataFrame)</span>
    <span class="s0">assert </span><span class="s1">isinstance(y_pred</span><span class="s0">, </span><span class="s1">np.ndarray)</span>
</pre>
</body>
</html>
<html>
<head>
<title>bdf.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
bdf.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">scipy.linalg </span><span class="s0">import </span><span class="s1">lu_factor</span><span class="s0">, </span><span class="s1">lu_solve</span>
<span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">issparse</span><span class="s0">, </span><span class="s1">csc_matrix</span><span class="s0">, </span><span class="s1">eye</span>
<span class="s0">from </span><span class="s1">scipy.sparse.linalg </span><span class="s0">import </span><span class="s1">splu</span>
<span class="s0">from </span><span class="s1">scipy.optimize._numdiff </span><span class="s0">import </span><span class="s1">group_columns</span>
<span class="s0">from </span><span class="s1">.common </span><span class="s0">import </span><span class="s1">(validate_max_step</span><span class="s0">, </span><span class="s1">validate_tol</span><span class="s0">, </span><span class="s1">select_initial_step</span><span class="s0">,</span>
                     <span class="s1">norm</span><span class="s0">, </span><span class="s1">EPS</span><span class="s0">, </span><span class="s1">num_jac</span><span class="s0">, </span><span class="s1">validate_first_step</span><span class="s0">,</span>
                     <span class="s1">warn_extraneous)</span>
<span class="s0">from </span><span class="s1">.base </span><span class="s0">import </span><span class="s1">OdeSolver</span><span class="s0">, </span><span class="s1">DenseOutput</span>


<span class="s1">MAX_ORDER = </span><span class="s2">5</span>
<span class="s1">NEWTON_MAXITER = </span><span class="s2">4</span>
<span class="s1">MIN_FACTOR = </span><span class="s2">0.2</span>
<span class="s1">MAX_FACTOR = </span><span class="s2">10</span>


<span class="s0">def </span><span class="s1">compute_R(order</span><span class="s0">, </span><span class="s1">factor):</span>
    <span class="s3">&quot;&quot;&quot;Compute the matrix for changing the differences array.&quot;&quot;&quot;</span>
    <span class="s1">I = np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">order + </span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, None</span><span class="s1">]</span>
    <span class="s1">J = np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">order + </span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">M = np.zeros((order + </span><span class="s2">1</span><span class="s0">, </span><span class="s1">order + </span><span class="s2">1</span><span class="s1">))</span>
    <span class="s1">M[</span><span class="s2">1</span><span class="s1">:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:] = (I - </span><span class="s2">1 </span><span class="s1">- factor * J) / I</span>
    <span class="s1">M[</span><span class="s2">0</span><span class="s1">] = </span><span class="s2">1</span>
    <span class="s0">return </span><span class="s1">np.cumprod(M</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">factor):</span>
    <span class="s3">&quot;&quot;&quot;Change differences array in-place when step size is changed.&quot;&quot;&quot;</span>
    <span class="s1">R = compute_R(order</span><span class="s0">, </span><span class="s1">factor)</span>
    <span class="s1">U = compute_R(order</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">RU = R.dot(U)</span>
    <span class="s1">D[:order + </span><span class="s2">1</span><span class="s1">] = np.dot(RU.T</span><span class="s0">, </span><span class="s1">D[:order + </span><span class="s2">1</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">solve_bdf_system(fun</span><span class="s0">, </span><span class="s1">t_new</span><span class="s0">, </span><span class="s1">y_predict</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">psi</span><span class="s0">, </span><span class="s1">LU</span><span class="s0">, </span><span class="s1">solve_lu</span><span class="s0">, </span><span class="s1">scale</span><span class="s0">, </span><span class="s1">tol):</span>
    <span class="s3">&quot;&quot;&quot;Solve the algebraic system resulting from BDF method.&quot;&quot;&quot;</span>
    <span class="s1">d = </span><span class="s2">0</span>
    <span class="s1">y = y_predict.copy()</span>
    <span class="s1">dy_norm_old = </span><span class="s0">None</span>
    <span class="s1">converged = </span><span class="s0">False</span>
    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(NEWTON_MAXITER):</span>
        <span class="s1">f = fun(t_new</span><span class="s0">, </span><span class="s1">y)</span>
        <span class="s0">if not </span><span class="s1">np.all(np.isfinite(f)):</span>
            <span class="s0">break</span>

        <span class="s1">dy = solve_lu(LU</span><span class="s0">, </span><span class="s1">c * f - psi - d)</span>
        <span class="s1">dy_norm = norm(dy / scale)</span>

        <span class="s0">if </span><span class="s1">dy_norm_old </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">rate = </span><span class="s0">None</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">rate = dy_norm / dy_norm_old</span>

        <span class="s0">if </span><span class="s1">(rate </span><span class="s0">is not None and </span><span class="s1">(rate &gt;= </span><span class="s2">1 </span><span class="s0">or</span>
                <span class="s1">rate ** (NEWTON_MAXITER - k) / (</span><span class="s2">1 </span><span class="s1">- rate) * dy_norm &gt; tol)):</span>
            <span class="s0">break</span>

        <span class="s1">y += dy</span>
        <span class="s1">d += dy</span>

        <span class="s0">if </span><span class="s1">(dy_norm == </span><span class="s2">0 </span><span class="s0">or</span>
                <span class="s1">rate </span><span class="s0">is not None and </span><span class="s1">rate / (</span><span class="s2">1 </span><span class="s1">- rate) * dy_norm &lt; tol):</span>
            <span class="s1">converged = </span><span class="s0">True</span>
            <span class="s0">break</span>

        <span class="s1">dy_norm_old = dy_norm</span>

    <span class="s0">return </span><span class="s1">converged</span><span class="s0">, </span><span class="s1">k + </span><span class="s2">1</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">d</span>


<span class="s0">class </span><span class="s1">BDF(OdeSolver):</span>
    <span class="s3">&quot;&quot;&quot;Implicit method based on backward-differentiation formulas. 
 
    This is a variable order method with the order varying automatically from 
    1 to 5. The general framework of the BDF algorithm is described in [1]_. 
    This class implements a quasi-constant step size as explained in [2]_. 
    The error estimation strategy for the constant-step BDF is derived in [3]_. 
    An accuracy enhancement using modified formulas (NDF) [2]_ is also implemented. 
 
    Can be applied in the complex domain. 
 
    Parameters 
    ---------- 
    fun : callable 
        Right-hand side of the system: the time derivative of the state ``y`` 
        at time ``t``. The calling signature is ``fun(t, y)``, where ``t`` is a 
        scalar and ``y`` is an ndarray with ``len(y) = len(y0)``. ``fun`` must 
        return an array of the same shape as ``y``. See `vectorized` for more 
        information. 
    t0 : float 
        Initial time. 
    y0 : array_like, shape (n,) 
        Initial state. 
    t_bound : float 
        Boundary time - the integration won't continue beyond it. It also 
        determines the direction of the integration. 
    first_step : float or None, optional 
        Initial step size. Default is ``None`` which means that the algorithm 
        should choose. 
    max_step : float, optional 
        Maximum allowed step size. Default is np.inf, i.e., the step size is not 
        bounded and determined solely by the solver. 
    rtol, atol : float and array_like, optional 
        Relative and absolute tolerances. The solver keeps the local error 
        estimates less than ``atol + rtol * abs(y)``. Here `rtol` controls a 
        relative accuracy (number of correct digits), while `atol` controls 
        absolute accuracy (number of correct decimal places). To achieve the 
        desired `rtol`, set `atol` to be smaller than the smallest value that 
        can be expected from ``rtol * abs(y)`` so that `rtol` dominates the 
        allowable error. If `atol` is larger than ``rtol * abs(y)`` the 
        number of correct digits is not guaranteed. Conversely, to achieve the 
        desired `atol` set `rtol` such that ``rtol * abs(y)`` is always smaller 
        than `atol`. If components of y have different scales, it might be 
        beneficial to set different `atol` values for different components by 
        passing array_like with shape (n,) for `atol`. Default values are 
        1e-3 for `rtol` and 1e-6 for `atol`. 
    jac : {None, array_like, sparse_matrix, callable}, optional 
        Jacobian matrix of the right-hand side of the system with respect to y, 
        required by this method. The Jacobian matrix has shape (n, n) and its 
        element (i, j) is equal to ``d f_i / d y_j``. 
        There are three ways to define the Jacobian: 
 
            * If array_like or sparse_matrix, the Jacobian is assumed to 
              be constant. 
            * If callable, the Jacobian is assumed to depend on both 
              t and y; it will be called as ``jac(t, y)`` as necessary. 
              For the 'Radau' and 'BDF' methods, the return value might be a 
              sparse matrix. 
            * If None (default), the Jacobian will be approximated by 
              finite differences. 
 
        It is generally recommended to provide the Jacobian rather than 
        relying on a finite-difference approximation. 
    jac_sparsity : {None, array_like, sparse matrix}, optional 
        Defines a sparsity structure of the Jacobian matrix for a 
        finite-difference approximation. Its shape must be (n, n). This argument 
        is ignored if `jac` is not `None`. If the Jacobian has only few non-zero 
        elements in *each* row, providing the sparsity structure will greatly 
        speed up the computations [4]_. A zero entry means that a corresponding 
        element in the Jacobian is always zero. If None (default), the Jacobian 
        is assumed to be dense. 
    vectorized : bool, optional 
        Whether `fun` can be called in a vectorized fashion. Default is False. 
 
        If ``vectorized`` is False, `fun` will always be called with ``y`` of 
        shape ``(n,)``, where ``n = len(y0)``. 
 
        If ``vectorized`` is True, `fun` may be called with ``y`` of shape 
        ``(n, k)``, where ``k`` is an integer. In this case, `fun` must behave 
        such that ``fun(t, y)[:, i] == fun(t, y[:, i])`` (i.e. each column of 
        the returned array is the time derivative of the state corresponding 
        with a column of ``y``). 
 
        Setting ``vectorized=True`` allows for faster finite difference 
        approximation of the Jacobian by this method, but may result in slower 
        execution overall in some circumstances (e.g. small ``len(y0)``). 
 
    Attributes 
    ---------- 
    n : int 
        Number of equations. 
    status : string 
        Current status of the solver: 'running', 'finished' or 'failed'. 
    t_bound : float 
        Boundary time. 
    direction : float 
        Integration direction: +1 or -1. 
    t : float 
        Current time. 
    y : ndarray 
        Current state. 
    t_old : float 
        Previous time. None if no steps were made yet. 
    step_size : float 
        Size of the last successful step. None if no steps were made yet. 
    nfev : int 
        Number of evaluations of the right-hand side. 
    njev : int 
        Number of evaluations of the Jacobian. 
    nlu : int 
        Number of LU decompositions. 
 
    References 
    ---------- 
    .. [1] G. D. Byrne, A. C. Hindmarsh, &quot;A Polyalgorithm for the Numerical 
           Solution of Ordinary Differential Equations&quot;, ACM Transactions on 
           Mathematical Software, Vol. 1, No. 1, pp. 71-96, March 1975. 
    .. [2] L. F. Shampine, M. W. Reichelt, &quot;THE MATLAB ODE SUITE&quot;, SIAM J. SCI. 
           COMPUTE., Vol. 18, No. 1, pp. 1-22, January 1997. 
    .. [3] E. Hairer, G. Wanner, &quot;Solving Ordinary Differential Equations I: 
           Nonstiff Problems&quot;, Sec. III.2. 
    .. [4] A. Curtis, M. J. D. Powell, and J. Reid, &quot;On the estimation of 
           sparse Jacobian matrices&quot;, Journal of the Institute of Mathematics 
           and its Applications, 13, pp. 117-120, 1974. 
    &quot;&quot;&quot;</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">fun</span><span class="s0">, </span><span class="s1">t0</span><span class="s0">, </span><span class="s1">y0</span><span class="s0">, </span><span class="s1">t_bound</span><span class="s0">, </span><span class="s1">max_step=np.inf</span><span class="s0">,</span>
                 <span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-6</span><span class="s0">, </span><span class="s1">jac=</span><span class="s0">None, </span><span class="s1">jac_sparsity=</span><span class="s0">None,</span>
                 <span class="s1">vectorized=</span><span class="s0">False, </span><span class="s1">first_step=</span><span class="s0">None, </span><span class="s1">**extraneous):</span>
        <span class="s1">warn_extraneous(extraneous)</span>
        <span class="s1">super().__init__(fun</span><span class="s0">, </span><span class="s1">t0</span><span class="s0">, </span><span class="s1">y0</span><span class="s0">, </span><span class="s1">t_bound</span><span class="s0">, </span><span class="s1">vectorized</span><span class="s0">,</span>
                         <span class="s1">support_complex=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">self.max_step = validate_max_step(max_step)</span>
        <span class="s1">self.rtol</span><span class="s0">, </span><span class="s1">self.atol = validate_tol(rtol</span><span class="s0">, </span><span class="s1">atol</span><span class="s0">, </span><span class="s1">self.n)</span>
        <span class="s1">f = self.fun(self.t</span><span class="s0">, </span><span class="s1">self.y)</span>
        <span class="s0">if </span><span class="s1">first_step </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">self.h_abs = select_initial_step(self.fun</span><span class="s0">, </span><span class="s1">self.t</span><span class="s0">, </span><span class="s1">self.y</span><span class="s0">, </span><span class="s1">f</span><span class="s0">,</span>
                                             <span class="s1">self.direction</span><span class="s0">, </span><span class="s2">1</span><span class="s0">,</span>
                                             <span class="s1">self.rtol</span><span class="s0">, </span><span class="s1">self.atol)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">self.h_abs = validate_first_step(first_step</span><span class="s0">, </span><span class="s1">t0</span><span class="s0">, </span><span class="s1">t_bound)</span>
        <span class="s1">self.h_abs_old = </span><span class="s0">None</span>
        <span class="s1">self.error_norm_old = </span><span class="s0">None</span>

        <span class="s1">self.newton_tol = max(</span><span class="s2">10 </span><span class="s1">* EPS / rtol</span><span class="s0">, </span><span class="s1">min(</span><span class="s2">0.03</span><span class="s0">, </span><span class="s1">rtol ** </span><span class="s2">0.5</span><span class="s1">))</span>

        <span class="s1">self.jac_factor = </span><span class="s0">None</span>
        <span class="s1">self.jac</span><span class="s0">, </span><span class="s1">self.J = self._validate_jac(jac</span><span class="s0">, </span><span class="s1">jac_sparsity)</span>
        <span class="s0">if </span><span class="s1">issparse(self.J):</span>
            <span class="s0">def </span><span class="s1">lu(A):</span>
                <span class="s1">self.nlu += </span><span class="s2">1</span>
                <span class="s0">return </span><span class="s1">splu(A)</span>

            <span class="s0">def </span><span class="s1">solve_lu(LU</span><span class="s0">, </span><span class="s1">b):</span>
                <span class="s0">return </span><span class="s1">LU.solve(b)</span>

            <span class="s1">I = eye(self.n</span><span class="s0">, </span><span class="s1">format=</span><span class="s4">'csc'</span><span class="s0">, </span><span class="s1">dtype=self.y.dtype)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">def </span><span class="s1">lu(A):</span>
                <span class="s1">self.nlu += </span><span class="s2">1</span>
                <span class="s0">return </span><span class="s1">lu_factor(A</span><span class="s0">, </span><span class="s1">overwrite_a=</span><span class="s0">True</span><span class="s1">)</span>

            <span class="s0">def </span><span class="s1">solve_lu(LU</span><span class="s0">, </span><span class="s1">b):</span>
                <span class="s0">return </span><span class="s1">lu_solve(LU</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">overwrite_b=</span><span class="s0">True</span><span class="s1">)</span>

            <span class="s1">I = np.identity(self.n</span><span class="s0">, </span><span class="s1">dtype=self.y.dtype)</span>

        <span class="s1">self.lu = lu</span>
        <span class="s1">self.solve_lu = solve_lu</span>
        <span class="s1">self.I = I</span>

        <span class="s1">kappa = np.array([</span><span class="s2">0</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.1850</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">/</span><span class="s2">9</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.0823</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.0415</span><span class="s0">, </span><span class="s2">0</span><span class="s1">])</span>
        <span class="s1">self.gamma = np.hstack((</span><span class="s2">0</span><span class="s0">, </span><span class="s1">np.cumsum(</span><span class="s2">1 </span><span class="s1">/ np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">MAX_ORDER + </span><span class="s2">1</span><span class="s1">))))</span>
        <span class="s1">self.alpha = (</span><span class="s2">1 </span><span class="s1">- kappa) * self.gamma</span>
        <span class="s1">self.error_const = kappa * self.gamma + </span><span class="s2">1 </span><span class="s1">/ np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">MAX_ORDER + </span><span class="s2">2</span><span class="s1">)</span>

        <span class="s1">D = np.empty((MAX_ORDER + </span><span class="s2">3</span><span class="s0">, </span><span class="s1">self.n)</span><span class="s0">, </span><span class="s1">dtype=self.y.dtype)</span>
        <span class="s1">D[</span><span class="s2">0</span><span class="s1">] = self.y</span>
        <span class="s1">D[</span><span class="s2">1</span><span class="s1">] = f * self.h_abs * self.direction</span>
        <span class="s1">self.D = D</span>

        <span class="s1">self.order = </span><span class="s2">1</span>
        <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
        <span class="s1">self.LU = </span><span class="s0">None</span>

    <span class="s0">def </span><span class="s1">_validate_jac(self</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">sparsity):</span>
        <span class="s1">t0 = self.t</span>
        <span class="s1">y0 = self.y</span>

        <span class="s0">if </span><span class="s1">jac </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">sparsity </span><span class="s0">is not None</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">issparse(sparsity):</span>
                    <span class="s1">sparsity = csc_matrix(sparsity)</span>
                <span class="s1">groups = group_columns(sparsity)</span>
                <span class="s1">sparsity = (sparsity</span><span class="s0">, </span><span class="s1">groups)</span>

            <span class="s0">def </span><span class="s1">jac_wrapped(t</span><span class="s0">, </span><span class="s1">y):</span>
                <span class="s1">self.njev += </span><span class="s2">1</span>
                <span class="s1">f = self.fun_single(t</span><span class="s0">, </span><span class="s1">y)</span>
                <span class="s1">J</span><span class="s0">, </span><span class="s1">self.jac_factor = num_jac(self.fun_vectorized</span><span class="s0">, </span><span class="s1">t</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">f</span><span class="s0">,</span>
                                             <span class="s1">self.atol</span><span class="s0">, </span><span class="s1">self.jac_factor</span><span class="s0">,</span>
                                             <span class="s1">sparsity)</span>
                <span class="s0">return </span><span class="s1">J</span>
            <span class="s1">J = jac_wrapped(t0</span><span class="s0">, </span><span class="s1">y0)</span>
        <span class="s0">elif </span><span class="s1">callable(jac):</span>
            <span class="s1">J = jac(t0</span><span class="s0">, </span><span class="s1">y0)</span>
            <span class="s1">self.njev += </span><span class="s2">1</span>
            <span class="s0">if </span><span class="s1">issparse(J):</span>
                <span class="s1">J = csc_matrix(J</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>

                <span class="s0">def </span><span class="s1">jac_wrapped(t</span><span class="s0">, </span><span class="s1">y):</span>
                    <span class="s1">self.njev += </span><span class="s2">1</span>
                    <span class="s0">return </span><span class="s1">csc_matrix(jac(t</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">J = np.asarray(J</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>

                <span class="s0">def </span><span class="s1">jac_wrapped(t</span><span class="s0">, </span><span class="s1">y):</span>
                    <span class="s1">self.njev += </span><span class="s2">1</span>
                    <span class="s0">return </span><span class="s1">np.asarray(jac(t</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>

            <span class="s0">if </span><span class="s1">J.shape != (self.n</span><span class="s0">, </span><span class="s1">self.n):</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;`jac` is expected to have shape {}, but &quot;</span>
                                 <span class="s4">&quot;actually has {}.&quot;</span>
                                 <span class="s1">.format((self.n</span><span class="s0">, </span><span class="s1">self.n)</span><span class="s0">, </span><span class="s1">J.shape))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">issparse(jac):</span>
                <span class="s1">J = csc_matrix(jac</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">J = np.asarray(jac</span><span class="s0">, </span><span class="s1">dtype=y0.dtype)</span>

            <span class="s0">if </span><span class="s1">J.shape != (self.n</span><span class="s0">, </span><span class="s1">self.n):</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;`jac` is expected to have shape {}, but &quot;</span>
                                 <span class="s4">&quot;actually has {}.&quot;</span>
                                 <span class="s1">.format((self.n</span><span class="s0">, </span><span class="s1">self.n)</span><span class="s0">, </span><span class="s1">J.shape))</span>
            <span class="s1">jac_wrapped = </span><span class="s0">None</span>

        <span class="s0">return </span><span class="s1">jac_wrapped</span><span class="s0">, </span><span class="s1">J</span>

    <span class="s0">def </span><span class="s1">_step_impl(self):</span>
        <span class="s1">t = self.t</span>
        <span class="s1">D = self.D</span>

        <span class="s1">max_step = self.max_step</span>
        <span class="s1">min_step = </span><span class="s2">10 </span><span class="s1">* np.abs(np.nextafter(t</span><span class="s0">, </span><span class="s1">self.direction * np.inf) - t)</span>
        <span class="s0">if </span><span class="s1">self.h_abs &gt; max_step:</span>
            <span class="s1">h_abs = max_step</span>
            <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">self.order</span><span class="s0">, </span><span class="s1">max_step / self.h_abs)</span>
            <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
        <span class="s0">elif </span><span class="s1">self.h_abs &lt; min_step:</span>
            <span class="s1">h_abs = min_step</span>
            <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">self.order</span><span class="s0">, </span><span class="s1">min_step / self.h_abs)</span>
            <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">h_abs = self.h_abs</span>

        <span class="s1">atol = self.atol</span>
        <span class="s1">rtol = self.rtol</span>
        <span class="s1">order = self.order</span>

        <span class="s1">alpha = self.alpha</span>
        <span class="s1">gamma = self.gamma</span>
        <span class="s1">error_const = self.error_const</span>

        <span class="s1">J = self.J</span>
        <span class="s1">LU = self.LU</span>
        <span class="s1">current_jac = self.jac </span><span class="s0">is None</span>

        <span class="s1">step_accepted = </span><span class="s0">False</span>
        <span class="s0">while not </span><span class="s1">step_accepted:</span>
            <span class="s0">if </span><span class="s1">h_abs &lt; min_step:</span>
                <span class="s0">return False, </span><span class="s1">self.TOO_SMALL_STEP</span>

            <span class="s1">h = h_abs * self.direction</span>
            <span class="s1">t_new = t + h</span>

            <span class="s0">if </span><span class="s1">self.direction * (t_new - self.t_bound) &gt; </span><span class="s2">0</span><span class="s1">:</span>
                <span class="s1">t_new = self.t_bound</span>
                <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">np.abs(t_new - t) / h_abs)</span>
                <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
                <span class="s1">LU = </span><span class="s0">None</span>

            <span class="s1">h = t_new - t</span>
            <span class="s1">h_abs = np.abs(h)</span>

            <span class="s1">y_predict = np.sum(D[:order + </span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>

            <span class="s1">scale = atol + rtol * np.abs(y_predict)</span>
            <span class="s1">psi = np.dot(D[</span><span class="s2">1</span><span class="s1">: order + </span><span class="s2">1</span><span class="s1">].T</span><span class="s0">, </span><span class="s1">gamma[</span><span class="s2">1</span><span class="s1">: order + </span><span class="s2">1</span><span class="s1">]) / alpha[order]</span>

            <span class="s1">converged = </span><span class="s0">False</span>
            <span class="s1">c = h / alpha[order]</span>
            <span class="s0">while not </span><span class="s1">converged:</span>
                <span class="s0">if </span><span class="s1">LU </span><span class="s0">is None</span><span class="s1">:</span>
                    <span class="s1">LU = self.lu(self.I - c * J)</span>

                <span class="s1">converged</span><span class="s0">, </span><span class="s1">n_iter</span><span class="s0">, </span><span class="s1">y_new</span><span class="s0">, </span><span class="s1">d = solve_bdf_system(</span>
                    <span class="s1">self.fun</span><span class="s0">, </span><span class="s1">t_new</span><span class="s0">, </span><span class="s1">y_predict</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">psi</span><span class="s0">, </span><span class="s1">LU</span><span class="s0">, </span><span class="s1">self.solve_lu</span><span class="s0">,</span>
                    <span class="s1">scale</span><span class="s0">, </span><span class="s1">self.newton_tol)</span>

                <span class="s0">if not </span><span class="s1">converged:</span>
                    <span class="s0">if </span><span class="s1">current_jac:</span>
                        <span class="s0">break</span>
                    <span class="s1">J = self.jac(t_new</span><span class="s0">, </span><span class="s1">y_predict)</span>
                    <span class="s1">LU = </span><span class="s0">None</span>
                    <span class="s1">current_jac = </span><span class="s0">True</span>

            <span class="s0">if not </span><span class="s1">converged:</span>
                <span class="s1">factor = </span><span class="s2">0.5</span>
                <span class="s1">h_abs *= factor</span>
                <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">factor)</span>
                <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
                <span class="s1">LU = </span><span class="s0">None</span>
                <span class="s0">continue</span>

            <span class="s1">safety = </span><span class="s2">0.9 </span><span class="s1">* (</span><span class="s2">2 </span><span class="s1">* NEWTON_MAXITER + </span><span class="s2">1</span><span class="s1">) / (</span><span class="s2">2 </span><span class="s1">* NEWTON_MAXITER</span>
                                                       <span class="s1">+ n_iter)</span>

            <span class="s1">scale = atol + rtol * np.abs(y_new)</span>
            <span class="s1">error = error_const[order] * d</span>
            <span class="s1">error_norm = norm(error / scale)</span>

            <span class="s0">if </span><span class="s1">error_norm &gt; </span><span class="s2">1</span><span class="s1">:</span>
                <span class="s1">factor = max(MIN_FACTOR</span><span class="s0">,</span>
                             <span class="s1">safety * error_norm ** (-</span><span class="s2">1 </span><span class="s1">/ (order + </span><span class="s2">1</span><span class="s1">)))</span>
                <span class="s1">h_abs *= factor</span>
                <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">factor)</span>
                <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
                <span class="s5"># As we didn't have problems with convergence, we don't</span>
                <span class="s5"># reset LU here.</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">step_accepted = </span><span class="s0">True</span>

        <span class="s1">self.n_equal_steps += </span><span class="s2">1</span>

        <span class="s1">self.t = t_new</span>
        <span class="s1">self.y = y_new</span>

        <span class="s1">self.h_abs = h_abs</span>
        <span class="s1">self.J = J</span>
        <span class="s1">self.LU = LU</span>

        <span class="s5"># Update differences. The principal relation here is</span>
        <span class="s5"># D^{j + 1} y_n = D^{j} y_n - D^{j} y_{n - 1}. Keep in mind that D</span>
        <span class="s5"># contained difference for previous interpolating polynomial and</span>
        <span class="s5"># d = D^{k + 1} y_n. Thus this elegant code follows.</span>
        <span class="s1">D[order + </span><span class="s2">2</span><span class="s1">] = d - D[order + </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">D[order + </span><span class="s2">1</span><span class="s1">] = d</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">reversed(range(order + </span><span class="s2">1</span><span class="s1">)):</span>
            <span class="s1">D[i] += D[i + </span><span class="s2">1</span><span class="s1">]</span>

        <span class="s0">if </span><span class="s1">self.n_equal_steps &lt; order + </span><span class="s2">1</span><span class="s1">:</span>
            <span class="s0">return True, None</span>

        <span class="s0">if </span><span class="s1">order &gt; </span><span class="s2">1</span><span class="s1">:</span>
            <span class="s1">error_m = error_const[order - </span><span class="s2">1</span><span class="s1">] * D[order]</span>
            <span class="s1">error_m_norm = norm(error_m / scale)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">error_m_norm = np.inf</span>

        <span class="s0">if </span><span class="s1">order &lt; MAX_ORDER:</span>
            <span class="s1">error_p = error_const[order + </span><span class="s2">1</span><span class="s1">] * D[order + </span><span class="s2">2</span><span class="s1">]</span>
            <span class="s1">error_p_norm = norm(error_p / scale)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">error_p_norm = np.inf</span>

        <span class="s1">error_norms = np.array([error_m_norm</span><span class="s0">, </span><span class="s1">error_norm</span><span class="s0">, </span><span class="s1">error_p_norm])</span>
        <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">factors = error_norms ** (-</span><span class="s2">1 </span><span class="s1">/ np.arange(order</span><span class="s0">, </span><span class="s1">order + </span><span class="s2">3</span><span class="s1">))</span>

        <span class="s1">delta_order = np.argmax(factors) - </span><span class="s2">1</span>
        <span class="s1">order += delta_order</span>
        <span class="s1">self.order = order</span>

        <span class="s1">factor = min(MAX_FACTOR</span><span class="s0">, </span><span class="s1">safety * np.max(factors))</span>
        <span class="s1">self.h_abs *= factor</span>
        <span class="s1">change_D(D</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">factor)</span>
        <span class="s1">self.n_equal_steps = </span><span class="s2">0</span>
        <span class="s1">self.LU = </span><span class="s0">None</span>

        <span class="s0">return True, None</span>

    <span class="s0">def </span><span class="s1">_dense_output_impl(self):</span>
        <span class="s0">return </span><span class="s1">BdfDenseOutput(self.t_old</span><span class="s0">, </span><span class="s1">self.t</span><span class="s0">, </span><span class="s1">self.h_abs * self.direction</span><span class="s0">,</span>
                              <span class="s1">self.order</span><span class="s0">, </span><span class="s1">self.D[:self.order + </span><span class="s2">1</span><span class="s1">].copy())</span>


<span class="s0">class </span><span class="s1">BdfDenseOutput(DenseOutput):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">t_old</span><span class="s0">, </span><span class="s1">t</span><span class="s0">, </span><span class="s1">h</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">D):</span>
        <span class="s1">super().__init__(t_old</span><span class="s0">, </span><span class="s1">t)</span>
        <span class="s1">self.order = order</span>
        <span class="s1">self.t_shift = self.t - h * np.arange(self.order)</span>
        <span class="s1">self.denom = h * (</span><span class="s2">1 </span><span class="s1">+ np.arange(self.order))</span>
        <span class="s1">self.D = D</span>

    <span class="s0">def </span><span class="s1">_call_impl(self</span><span class="s0">, </span><span class="s1">t):</span>
        <span class="s0">if </span><span class="s1">t.ndim == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">x = (t - self.t_shift) / self.denom</span>
            <span class="s1">p = np.cumprod(x)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">x = (t - self.t_shift[:</span><span class="s0">, None</span><span class="s1">]) / self.denom[:</span><span class="s0">, None</span><span class="s1">]</span>
            <span class="s1">p = np.cumprod(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>

        <span class="s1">y = np.dot(self.D[</span><span class="s2">1</span><span class="s1">:].T</span><span class="s0">, </span><span class="s1">p)</span>
        <span class="s0">if </span><span class="s1">y.ndim == </span><span class="s2">1</span><span class="s1">:</span>
            <span class="s1">y += self.D[</span><span class="s2">0</span><span class="s1">]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">y += self.D[</span><span class="s2">0</span><span class="s0">, </span><span class="s1">:</span><span class="s0">, None</span><span class="s1">]</span>

        <span class="s0">return </span><span class="s1">y</span>
</pre>
</body>
</html>
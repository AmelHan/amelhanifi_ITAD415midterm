<html>
<head>
<title>_mds.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_mds.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Multi-dimensional Scaling (MDS). 
&quot;&quot;&quot;</span>

<span class="s2"># author: Nelle Varoquaux &lt;nelle.varoquaux@gmail.com&gt;</span>
<span class="s2"># License: BSD</span>

<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s3">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">joblib </span><span class="s3">import </span><span class="s1">effective_n_jobs</span>

<span class="s3">from </span><span class="s1">..base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">_fit_context</span>
<span class="s3">from </span><span class="s1">..isotonic </span><span class="s3">import </span><span class="s1">IsotonicRegression</span>
<span class="s3">from </span><span class="s1">..metrics </span><span class="s3">import </span><span class="s1">euclidean_distances</span>
<span class="s3">from </span><span class="s1">..utils </span><span class="s3">import </span><span class="s1">check_array</span><span class="s3">, </span><span class="s1">check_random_state</span><span class="s3">, </span><span class="s1">check_symmetric</span>
<span class="s3">from </span><span class="s1">..utils._param_validation </span><span class="s3">import </span><span class="s1">Hidden</span><span class="s3">, </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s1">..utils.parallel </span><span class="s3">import </span><span class="s1">Parallel</span><span class="s3">, </span><span class="s1">delayed</span>


<span class="s3">def </span><span class="s1">_smacof_single(</span>
    <span class="s1">dissimilarities</span><span class="s3">,</span>
    <span class="s1">metric=</span><span class="s3">True,</span>
    <span class="s1">n_components=</span><span class="s4">2</span><span class="s3">,</span>
    <span class="s1">init=</span><span class="s3">None,</span>
    <span class="s1">max_iter=</span><span class="s4">300</span><span class="s3">,</span>
    <span class="s1">verbose=</span><span class="s4">0</span><span class="s3">,</span>
    <span class="s1">eps=</span><span class="s4">1e-3</span><span class="s3">,</span>
    <span class="s1">random_state=</span><span class="s3">None,</span>
    <span class="s1">normalized_stress=</span><span class="s3">False,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Computes multidimensional scaling using SMACOF algorithm. 
 
    Parameters 
    ---------- 
    dissimilarities : ndarray of shape (n_samples, n_samples) 
        Pairwise dissimilarities between the points. Must be symmetric. 
 
    metric : bool, default=True 
        Compute metric or nonmetric SMACOF algorithm. 
        When ``False`` (i.e. non-metric MDS), dissimilarities with 0 are considered as 
        missing values. 
 
    n_components : int, default=2 
        Number of dimensions in which to immerse the dissimilarities. If an 
        ``init`` array is provided, this option is overridden and the shape of 
        ``init`` is used to determine the dimensionality of the embedding 
        space. 
 
    init : ndarray of shape (n_samples, n_components), default=None 
        Starting configuration of the embedding to initialize the algorithm. By 
        default, the algorithm is initialized with a randomly chosen array. 
 
    max_iter : int, default=300 
        Maximum number of iterations of the SMACOF algorithm for a single run. 
 
    verbose : int, default=0 
        Level of verbosity. 
 
    eps : float, default=1e-3 
        Relative tolerance with respect to stress at which to declare 
        convergence. The value of `eps` should be tuned separately depending 
        on whether or not `normalized_stress` is being used. 
 
    random_state : int, RandomState instance or None, default=None 
        Determines the random number generator used to initialize the centers. 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    normalized_stress : bool, default=False 
        Whether use and return normed stress value (Stress-1) instead of raw 
        stress calculated by default. Only supported in non-metric MDS. The 
        caller must ensure that if `normalized_stress=True` then `metric=False` 
 
        .. versionadded:: 1.2 
 
    Returns 
    ------- 
    X : ndarray of shape (n_samples, n_components) 
        Coordinates of the points in a ``n_components``-space. 
 
    stress : float 
        The final value of the stress (sum of squared distance of the 
        disparities and the distances for all constrained points). 
        If `normalized_stress=True`, and `metric=False` returns Stress-1. 
        A value of 0 indicates &quot;perfect&quot; fit, 0.025 excellent, 0.05 good, 
        0.1 fair, and 0.2 poor [1]_. 
 
    n_iter : int 
        The number of iterations corresponding to the best stress. 
 
    References 
    ---------- 
    .. [1] &quot;Nonmetric multidimensional scaling: a numerical method&quot; Kruskal, J. 
           Psychometrika, 29 (1964) 
 
    .. [2] &quot;Multidimensional scaling by optimizing goodness of fit to a nonmetric 
           hypothesis&quot; Kruskal, J. Psychometrika, 29, (1964) 
 
    .. [3] &quot;Modern Multidimensional Scaling - Theory and Applications&quot; Borg, I.; 
           Groenen P. Springer Series in Statistics (1997) 
    &quot;&quot;&quot;</span>
    <span class="s1">dissimilarities = check_symmetric(dissimilarities</span><span class="s3">, </span><span class="s1">raise_exception=</span><span class="s3">True</span><span class="s1">)</span>

    <span class="s1">n_samples = dissimilarities.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">random_state = check_random_state(random_state)</span>

    <span class="s1">sim_flat = ((</span><span class="s4">1 </span><span class="s1">- np.tri(n_samples)) * dissimilarities).ravel()</span>
    <span class="s1">sim_flat_w = sim_flat[sim_flat != </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s3">if </span><span class="s1">init </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s2"># Randomly choose initial configuration</span>
        <span class="s1">X = random_state.uniform(size=n_samples * n_components)</span>
        <span class="s1">X = X.reshape((n_samples</span><span class="s3">, </span><span class="s1">n_components))</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s2"># overrides the parameter p</span>
        <span class="s1">n_components = init.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">n_samples != init.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;init matrix should be of shape (%d, %d)&quot; </span><span class="s1">% (n_samples</span><span class="s3">, </span><span class="s1">n_components)</span>
            <span class="s1">)</span>
        <span class="s1">X = init</span>

    <span class="s1">old_stress = </span><span class="s3">None</span>
    <span class="s1">ir = IsotonicRegression()</span>
    <span class="s3">for </span><span class="s1">it </span><span class="s3">in </span><span class="s1">range(max_iter):</span>
        <span class="s2"># Compute distance and monotonic regression</span>
        <span class="s1">dis = euclidean_distances(X)</span>

        <span class="s3">if </span><span class="s1">metric:</span>
            <span class="s1">disparities = dissimilarities</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">dis_flat = dis.ravel()</span>
            <span class="s2"># dissimilarities with 0 are considered as missing values</span>
            <span class="s1">dis_flat_w = dis_flat[sim_flat != </span><span class="s4">0</span><span class="s1">]</span>

            <span class="s2"># Compute the disparities using a monotonic regression</span>
            <span class="s1">disparities_flat = ir.fit_transform(sim_flat_w</span><span class="s3">, </span><span class="s1">dis_flat_w)</span>
            <span class="s1">disparities = dis_flat.copy()</span>
            <span class="s1">disparities[sim_flat != </span><span class="s4">0</span><span class="s1">] = disparities_flat</span>
            <span class="s1">disparities = disparities.reshape((n_samples</span><span class="s3">, </span><span class="s1">n_samples))</span>
            <span class="s1">disparities *= np.sqrt(</span>
                <span class="s1">(n_samples * (n_samples - </span><span class="s4">1</span><span class="s1">) / </span><span class="s4">2</span><span class="s1">) / (disparities**</span><span class="s4">2</span><span class="s1">).sum()</span>
            <span class="s1">)</span>

        <span class="s2"># Compute stress</span>
        <span class="s1">stress = ((dis.ravel() - disparities.ravel()) ** </span><span class="s4">2</span><span class="s1">).sum() / </span><span class="s4">2</span>
        <span class="s3">if </span><span class="s1">normalized_stress:</span>
            <span class="s1">stress = np.sqrt(stress / ((disparities.ravel() ** </span><span class="s4">2</span><span class="s1">).sum() / </span><span class="s4">2</span><span class="s1">))</span>
        <span class="s2"># Update X using the Guttman transform</span>
        <span class="s1">dis[dis == </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1e-5</span>
        <span class="s1">ratio = disparities / dis</span>
        <span class="s1">B = -ratio</span>
        <span class="s1">B[np.arange(len(B))</span><span class="s3">, </span><span class="s1">np.arange(len(B))] += ratio.sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">X = </span><span class="s4">1.0 </span><span class="s1">/ n_samples * np.dot(B</span><span class="s3">, </span><span class="s1">X)</span>

        <span class="s1">dis = np.sqrt((X**</span><span class="s4">2</span><span class="s1">).sum(axis=</span><span class="s4">1</span><span class="s1">)).sum()</span>
        <span class="s3">if </span><span class="s1">verbose &gt;= </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s1">print(</span><span class="s5">&quot;it: %d, stress %s&quot; </span><span class="s1">% (it</span><span class="s3">, </span><span class="s1">stress))</span>
        <span class="s3">if </span><span class="s1">old_stress </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">(old_stress - stress / dis) &lt; eps:</span>
                <span class="s3">if </span><span class="s1">verbose:</span>
                    <span class="s1">print(</span><span class="s5">&quot;breaking at iteration %d with stress %s&quot; </span><span class="s1">% (it</span><span class="s3">, </span><span class="s1">stress))</span>
                <span class="s3">break</span>
        <span class="s1">old_stress = stress / dis</span>

    <span class="s3">return </span><span class="s1">X</span><span class="s3">, </span><span class="s1">stress</span><span class="s3">, </span><span class="s1">it + </span><span class="s4">1</span>


<span class="s3">def </span><span class="s1">smacof(</span>
    <span class="s1">dissimilarities</span><span class="s3">,</span>
    <span class="s1">*</span><span class="s3">,</span>
    <span class="s1">metric=</span><span class="s3">True,</span>
    <span class="s1">n_components=</span><span class="s4">2</span><span class="s3">,</span>
    <span class="s1">init=</span><span class="s3">None,</span>
    <span class="s1">n_init=</span><span class="s4">8</span><span class="s3">,</span>
    <span class="s1">n_jobs=</span><span class="s3">None,</span>
    <span class="s1">max_iter=</span><span class="s4">300</span><span class="s3">,</span>
    <span class="s1">verbose=</span><span class="s4">0</span><span class="s3">,</span>
    <span class="s1">eps=</span><span class="s4">1e-3</span><span class="s3">,</span>
    <span class="s1">random_state=</span><span class="s3">None,</span>
    <span class="s1">return_n_iter=</span><span class="s3">False,</span>
    <span class="s1">normalized_stress=</span><span class="s5">&quot;warn&quot;</span><span class="s3">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Compute multidimensional scaling using the SMACOF algorithm. 
 
    The SMACOF (Scaling by MAjorizing a COmplicated Function) algorithm is a 
    multidimensional scaling algorithm which minimizes an objective function 
    (the *stress*) using a majorization technique. Stress majorization, also 
    known as the Guttman Transform, guarantees a monotone convergence of 
    stress, and is more powerful than traditional techniques such as gradient 
    descent. 
 
    The SMACOF algorithm for metric MDS can be summarized by the following 
    steps: 
 
    1. Set an initial start configuration, randomly or not. 
    2. Compute the stress 
    3. Compute the Guttman Transform 
    4. Iterate 2 and 3 until convergence. 
 
    The nonmetric algorithm adds a monotonic regression step before computing 
    the stress. 
 
    Parameters 
    ---------- 
    dissimilarities : ndarray of shape (n_samples, n_samples) 
        Pairwise dissimilarities between the points. Must be symmetric. 
 
    metric : bool, default=True 
        Compute metric or nonmetric SMACOF algorithm. 
        When ``False`` (i.e. non-metric MDS), dissimilarities with 0 are considered as 
        missing values. 
 
    n_components : int, default=2 
        Number of dimensions in which to immerse the dissimilarities. If an 
        ``init`` array is provided, this option is overridden and the shape of 
        ``init`` is used to determine the dimensionality of the embedding 
        space. 
 
    init : ndarray of shape (n_samples, n_components), default=None 
        Starting configuration of the embedding to initialize the algorithm. By 
        default, the algorithm is initialized with a randomly chosen array. 
 
    n_init : int, default=8 
        Number of times the SMACOF algorithm will be run with different 
        initializations. The final results will be the best output of the runs, 
        determined by the run with the smallest final stress. If ``init`` is 
        provided, this option is overridden and a single run is performed. 
 
    n_jobs : int, default=None 
        The number of jobs to use for the computation. If multiple 
        initializations are used (``n_init``), each run of the algorithm is 
        computed in parallel. 
 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    max_iter : int, default=300 
        Maximum number of iterations of the SMACOF algorithm for a single run. 
 
    verbose : int, default=0 
        Level of verbosity. 
 
    eps : float, default=1e-3 
        Relative tolerance with respect to stress at which to declare 
        convergence. The value of `eps` should be tuned separately depending 
        on whether or not `normalized_stress` is being used. 
 
    random_state : int, RandomState instance or None, default=None 
        Determines the random number generator used to initialize the centers. 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    return_n_iter : bool, default=False 
        Whether or not to return the number of iterations. 
 
    normalized_stress : bool or &quot;auto&quot; default=False 
        Whether use and return normed stress value (Stress-1) instead of raw 
        stress calculated by default. Only supported in non-metric MDS. 
 
        .. versionadded:: 1.2 
 
    Returns 
    ------- 
    X : ndarray of shape (n_samples, n_components) 
        Coordinates of the points in a ``n_components``-space. 
 
    stress : float 
        The final value of the stress (sum of squared distance of the 
        disparities and the distances for all constrained points). 
        If `normalized_stress=True`, and `metric=False` returns Stress-1. 
        A value of 0 indicates &quot;perfect&quot; fit, 0.025 excellent, 0.05 good, 
        0.1 fair, and 0.2 poor [1]_. 
 
    n_iter : int 
        The number of iterations corresponding to the best stress. Returned 
        only if ``return_n_iter`` is set to ``True``. 
 
    References 
    ---------- 
    .. [1] &quot;Nonmetric multidimensional scaling: a numerical method&quot; Kruskal, J. 
           Psychometrika, 29 (1964) 
 
    .. [2] &quot;Multidimensional scaling by optimizing goodness of fit to a nonmetric 
           hypothesis&quot; Kruskal, J. Psychometrika, 29, (1964) 
 
    .. [3] &quot;Modern Multidimensional Scaling - Theory and Applications&quot; Borg, I.; 
           Groenen P. Springer Series in Statistics (1997) 
    &quot;&quot;&quot;</span>

    <span class="s1">dissimilarities = check_array(dissimilarities)</span>
    <span class="s1">random_state = check_random_state(random_state)</span>

    <span class="s2"># TODO(1.4): Remove</span>
    <span class="s3">if </span><span class="s1">normalized_stress == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
        <span class="s1">warnings.warn(</span>
            <span class="s1">(</span>
                <span class="s5">&quot;The default value of `normalized_stress` will change to `'auto'` in&quot;</span>
                <span class="s5">&quot; version 1.4. To suppress this warning, manually set the value of&quot;</span>
                <span class="s5">&quot; `normalized_stress`.&quot;</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">FutureWarning</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s1">normalized_stress = </span><span class="s3">False</span>

    <span class="s3">if </span><span class="s1">normalized_stress == </span><span class="s5">&quot;auto&quot;</span><span class="s1">:</span>
        <span class="s1">normalized_stress = </span><span class="s3">not </span><span class="s1">metric</span>

    <span class="s3">if </span><span class="s1">normalized_stress </span><span class="s3">and </span><span class="s1">metric:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s5">&quot;Normalized stress is not supported for metric MDS. Either set&quot;</span>
            <span class="s5">&quot; `normalized_stress=False` or use `metric=False`.&quot;</span>
        <span class="s1">)</span>
    <span class="s3">if </span><span class="s1">hasattr(init</span><span class="s3">, </span><span class="s5">&quot;__array__&quot;</span><span class="s1">):</span>
        <span class="s1">init = np.asarray(init).copy()</span>
        <span class="s3">if not </span><span class="s1">n_init == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s5">&quot;Explicit initial positions passed: &quot;</span>
                <span class="s5">&quot;performing only one init of the MDS instead of %d&quot; </span><span class="s1">% n_init</span>
            <span class="s1">)</span>
            <span class="s1">n_init = </span><span class="s4">1</span>

    <span class="s1">best_pos</span><span class="s3">, </span><span class="s1">best_stress = </span><span class="s3">None, None</span>

    <span class="s3">if </span><span class="s1">effective_n_jobs(n_jobs) == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s3">for </span><span class="s1">it </span><span class="s3">in </span><span class="s1">range(n_init):</span>
            <span class="s1">pos</span><span class="s3">, </span><span class="s1">stress</span><span class="s3">, </span><span class="s1">n_iter_ = _smacof_single(</span>
                <span class="s1">dissimilarities</span><span class="s3">,</span>
                <span class="s1">metric=metric</span><span class="s3">,</span>
                <span class="s1">n_components=n_components</span><span class="s3">,</span>
                <span class="s1">init=init</span><span class="s3">,</span>
                <span class="s1">max_iter=max_iter</span><span class="s3">,</span>
                <span class="s1">verbose=verbose</span><span class="s3">,</span>
                <span class="s1">eps=eps</span><span class="s3">,</span>
                <span class="s1">random_state=random_state</span><span class="s3">,</span>
                <span class="s1">normalized_stress=normalized_stress</span><span class="s3">,</span>
            <span class="s1">)</span>
            <span class="s3">if </span><span class="s1">best_stress </span><span class="s3">is None or </span><span class="s1">stress &lt; best_stress:</span>
                <span class="s1">best_stress = stress</span>
                <span class="s1">best_pos = pos.copy()</span>
                <span class="s1">best_iter = n_iter_</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">seeds = random_state.randint(np.iinfo(np.int32).max</span><span class="s3">, </span><span class="s1">size=n_init)</span>
        <span class="s1">results = Parallel(n_jobs=n_jobs</span><span class="s3">, </span><span class="s1">verbose=max(verbose - </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">))(</span>
            <span class="s1">delayed(_smacof_single)(</span>
                <span class="s1">dissimilarities</span><span class="s3">,</span>
                <span class="s1">metric=metric</span><span class="s3">,</span>
                <span class="s1">n_components=n_components</span><span class="s3">,</span>
                <span class="s1">init=init</span><span class="s3">,</span>
                <span class="s1">max_iter=max_iter</span><span class="s3">,</span>
                <span class="s1">verbose=verbose</span><span class="s3">,</span>
                <span class="s1">eps=eps</span><span class="s3">,</span>
                <span class="s1">random_state=seed</span><span class="s3">,</span>
                <span class="s1">normalized_stress=normalized_stress</span><span class="s3">,</span>
            <span class="s1">)</span>
            <span class="s3">for </span><span class="s1">seed </span><span class="s3">in </span><span class="s1">seeds</span>
        <span class="s1">)</span>
        <span class="s1">positions</span><span class="s3">, </span><span class="s1">stress</span><span class="s3">, </span><span class="s1">n_iters = zip(*results)</span>
        <span class="s1">best = np.argmin(stress)</span>
        <span class="s1">best_stress = stress[best]</span>
        <span class="s1">best_pos = positions[best]</span>
        <span class="s1">best_iter = n_iters[best]</span>

    <span class="s3">if </span><span class="s1">return_n_iter:</span>
        <span class="s3">return </span><span class="s1">best_pos</span><span class="s3">, </span><span class="s1">best_stress</span><span class="s3">, </span><span class="s1">best_iter</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">return </span><span class="s1">best_pos</span><span class="s3">, </span><span class="s1">best_stress</span>


<span class="s3">class </span><span class="s1">MDS(BaseEstimator):</span>
    <span class="s0">&quot;&quot;&quot;Multidimensional scaling. 
 
    Read more in the :ref:`User Guide &lt;multidimensional_scaling&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, default=2 
        Number of dimensions in which to immerse the dissimilarities. 
 
    metric : bool, default=True 
        If ``True``, perform metric MDS; otherwise, perform nonmetric MDS. 
        When ``False`` (i.e. non-metric MDS), dissimilarities with 0 are considered as 
        missing values. 
 
    n_init : int, default=4 
        Number of times the SMACOF algorithm will be run with different 
        initializations. The final results will be the best output of the runs, 
        determined by the run with the smallest final stress. 
 
    max_iter : int, default=300 
        Maximum number of iterations of the SMACOF algorithm for a single run. 
 
    verbose : int, default=0 
        Level of verbosity. 
 
    eps : float, default=1e-3 
        Relative tolerance with respect to stress at which to declare 
        convergence. The value of `eps` should be tuned separately depending 
        on whether or not `normalized_stress` is being used. 
 
    n_jobs : int, default=None 
        The number of jobs to use for the computation. If multiple 
        initializations are used (``n_init``), each run of the algorithm is 
        computed in parallel. 
 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    random_state : int, RandomState instance or None, default=None 
        Determines the random number generator used to initialize the centers. 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    dissimilarity : {'euclidean', 'precomputed'}, default='euclidean' 
        Dissimilarity measure to use: 
 
        - 'euclidean': 
            Pairwise Euclidean distances between points in the dataset. 
 
        - 'precomputed': 
            Pre-computed dissimilarities are passed directly to ``fit`` and 
            ``fit_transform``. 
 
    normalized_stress : bool or &quot;auto&quot; default=False 
        Whether use and return normed stress value (Stress-1) instead of raw 
        stress calculated by default. Only supported in non-metric MDS. 
 
        .. versionadded:: 1.2 
 
    Attributes 
    ---------- 
    embedding_ : ndarray of shape (n_samples, n_components) 
        Stores the position of the dataset in the embedding space. 
 
    stress_ : float 
        The final value of the stress (sum of squared distance of the 
        disparities and the distances for all constrained points). 
        If `normalized_stress=True`, and `metric=False` returns Stress-1. 
        A value of 0 indicates &quot;perfect&quot; fit, 0.025 excellent, 0.05 good, 
        0.1 fair, and 0.2 poor [1]_. 
 
    dissimilarity_matrix_ : ndarray of shape (n_samples, n_samples) 
        Pairwise dissimilarities between the points. Symmetric matrix that: 
 
        - either uses a custom dissimilarity matrix by setting `dissimilarity` 
          to 'precomputed'; 
        - or constructs a dissimilarity matrix from data using 
          Euclidean distances. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        The number of iterations corresponding to the best stress. 
 
    See Also 
    -------- 
    sklearn.decomposition.PCA : Principal component analysis that is a linear 
        dimensionality reduction method. 
    sklearn.decomposition.KernelPCA : Non-linear dimensionality reduction using 
        kernels and PCA. 
    TSNE : T-distributed Stochastic Neighbor Embedding. 
    Isomap : Manifold learning based on Isometric Mapping. 
    LocallyLinearEmbedding : Manifold learning using Locally Linear Embedding. 
    SpectralEmbedding : Spectral embedding for non-linear dimensionality. 
 
    References 
    ---------- 
    .. [1] &quot;Nonmetric multidimensional scaling: a numerical method&quot; Kruskal, J. 
       Psychometrika, 29 (1964) 
 
    .. [2] &quot;Multidimensional scaling by optimizing goodness of fit to a nonmetric 
       hypothesis&quot; Kruskal, J. Psychometrika, 29, (1964) 
 
    .. [3] &quot;Modern Multidimensional Scaling - Theory and Applications&quot; Borg, I.; 
       Groenen P. Springer Series in Statistics (1997) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.datasets import load_digits 
    &gt;&gt;&gt; from sklearn.manifold import MDS 
    &gt;&gt;&gt; X, _ = load_digits(return_X_y=True) 
    &gt;&gt;&gt; X.shape 
    (1797, 64) 
    &gt;&gt;&gt; embedding = MDS(n_components=2, normalized_stress='auto') 
    &gt;&gt;&gt; X_transformed = embedding.fit_transform(X[:100]) 
    &gt;&gt;&gt; X_transformed.shape 
    (100, 2) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints: dict = {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;metric&quot;</span><span class="s1">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s5">&quot;n_init&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s1">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s5">&quot;eps&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s4">0.0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s1">: [</span><span class="s3">None, </span><span class="s1">Integral]</span><span class="s3">,</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s1">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s5">&quot;dissimilarity&quot;</span><span class="s1">: [StrOptions({</span><span class="s5">&quot;euclidean&quot;</span><span class="s3">, </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">})]</span><span class="s3">,</span>
        <span class="s5">&quot;normalized_stress&quot;</span><span class="s1">: [</span>
            <span class="s5">&quot;boolean&quot;</span><span class="s3">,</span>
            <span class="s1">StrOptions({</span><span class="s5">&quot;auto&quot;</span><span class="s1">})</span><span class="s3">,</span>
            <span class="s1">Hidden(StrOptions({</span><span class="s5">&quot;warn&quot;</span><span class="s1">}))</span><span class="s3">,</span>
        <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">}</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">n_components=</span><span class="s4">2</span><span class="s3">,</span>
        <span class="s1">*</span><span class="s3">,</span>
        <span class="s1">metric=</span><span class="s3">True,</span>
        <span class="s1">n_init=</span><span class="s4">4</span><span class="s3">,</span>
        <span class="s1">max_iter=</span><span class="s4">300</span><span class="s3">,</span>
        <span class="s1">verbose=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">eps=</span><span class="s4">1e-3</span><span class="s3">,</span>
        <span class="s1">n_jobs=</span><span class="s3">None,</span>
        <span class="s1">random_state=</span><span class="s3">None,</span>
        <span class="s1">dissimilarity=</span><span class="s5">&quot;euclidean&quot;</span><span class="s3">,</span>
        <span class="s1">normalized_stress=</span><span class="s5">&quot;warn&quot;</span><span class="s3">,</span>
    <span class="s1">):</span>
        <span class="s1">self.n_components = n_components</span>
        <span class="s1">self.dissimilarity = dissimilarity</span>
        <span class="s1">self.metric = metric</span>
        <span class="s1">self.n_init = n_init</span>
        <span class="s1">self.max_iter = max_iter</span>
        <span class="s1">self.eps = eps</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.n_jobs = n_jobs</span>
        <span class="s1">self.random_state = random_state</span>
        <span class="s1">self.normalized_stress = normalized_stress</span>

    <span class="s3">def </span><span class="s1">_more_tags(self):</span>
        <span class="s3">return </span><span class="s1">{</span><span class="s5">&quot;pairwise&quot;</span><span class="s1">: self.dissimilarity == </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">}</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y=</span><span class="s3">None, </span><span class="s1">init=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute the position of the points in the embedding space. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) or \ 
                (n_samples, n_samples) 
            Input data. If ``dissimilarity=='precomputed'``, the input should 
            be the dissimilarity matrix. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        init : ndarray of shape (n_samples, n_components), default=None 
            Starting configuration of the embedding to initialize the SMACOF 
            algorithm. By default, the algorithm is initialized with a randomly 
            chosen array. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.fit_transform(X</span><span class="s3">, </span><span class="s1">init=init)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">fit_transform(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y=</span><span class="s3">None, </span><span class="s1">init=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit the data from `X`, and returns the embedded coordinates. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) or \ 
                (n_samples, n_samples) 
            Input data. If ``dissimilarity=='precomputed'``, the input should 
            be the dissimilarity matrix. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        init : ndarray of shape (n_samples, n_components), default=None 
            Starting configuration of the embedding to initialize the SMACOF 
            algorithm. By default, the algorithm is initialized with a randomly 
            chosen array. 
 
        Returns 
        ------- 
        X_new : ndarray of shape (n_samples, n_components) 
            X transformed in the new space. 
        &quot;&quot;&quot;</span>
        <span class="s1">X = self._validate_data(X)</span>
        <span class="s3">if </span><span class="s1">X.shape[</span><span class="s4">0</span><span class="s1">] == X.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">and </span><span class="s1">self.dissimilarity != </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s5">&quot;The MDS API has changed. ``fit`` now constructs an&quot;</span>
                <span class="s5">&quot; dissimilarity matrix from data. To use a custom &quot;</span>
                <span class="s5">&quot;dissimilarity matrix, set &quot;</span>
                <span class="s5">&quot;``dissimilarity='precomputed'``.&quot;</span>
            <span class="s1">)</span>

        <span class="s3">if </span><span class="s1">self.dissimilarity == </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">:</span>
            <span class="s1">self.dissimilarity_matrix_ = X</span>
        <span class="s3">elif </span><span class="s1">self.dissimilarity == </span><span class="s5">&quot;euclidean&quot;</span><span class="s1">:</span>
            <span class="s1">self.dissimilarity_matrix_ = euclidean_distances(X)</span>

        <span class="s1">self.embedding_</span><span class="s3">, </span><span class="s1">self.stress_</span><span class="s3">, </span><span class="s1">self.n_iter_ = smacof(</span>
            <span class="s1">self.dissimilarity_matrix_</span><span class="s3">,</span>
            <span class="s1">metric=self.metric</span><span class="s3">,</span>
            <span class="s1">n_components=self.n_components</span><span class="s3">,</span>
            <span class="s1">init=init</span><span class="s3">,</span>
            <span class="s1">n_init=self.n_init</span><span class="s3">,</span>
            <span class="s1">n_jobs=self.n_jobs</span><span class="s3">,</span>
            <span class="s1">max_iter=self.max_iter</span><span class="s3">,</span>
            <span class="s1">verbose=self.verbose</span><span class="s3">,</span>
            <span class="s1">eps=self.eps</span><span class="s3">,</span>
            <span class="s1">random_state=self.random_state</span><span class="s3">,</span>
            <span class="s1">return_n_iter=</span><span class="s3">True,</span>
            <span class="s1">normalized_stress=self.normalized_stress</span><span class="s3">,</span>
        <span class="s1">)</span>

        <span class="s3">return </span><span class="s1">self.embedding_</span>
</pre>
</body>
</html>
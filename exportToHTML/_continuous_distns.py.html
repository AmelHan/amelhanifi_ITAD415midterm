<html>
<head>
<title>_continuous_distns.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_continuous_distns.py</font>
</center></td></tr></table>
<pre><span class="s0">#</span>
<span class="s0"># Author:  Travis Oliphant  2002-2011 with contributions from</span>
<span class="s0">#          SciPy Developers 2004-2011</span>
<span class="s0">#</span>
<span class="s2">import </span><span class="s1">warnings</span>
<span class="s2">from </span><span class="s1">collections.abc </span><span class="s2">import </span><span class="s1">Iterable</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">wraps</span><span class="s2">, </span><span class="s1">cached_property</span>
<span class="s2">import </span><span class="s1">ctypes</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy.polynomial </span><span class="s2">import </span><span class="s1">Polynomial</span>
<span class="s2">from </span><span class="s1">scipy._lib.doccer </span><span class="s2">import </span><span class="s1">(extend_notes_in_docstring</span><span class="s2">,</span>
                               <span class="s1">replace_notes_in_docstring</span><span class="s2">,</span>
                               <span class="s1">inherit_docstring_from)</span>
<span class="s2">from </span><span class="s1">scipy._lib._ccallback </span><span class="s2">import </span><span class="s1">LowLevelCallable</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">optimize</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">integrate</span>
<span class="s2">import </span><span class="s1">scipy.special </span><span class="s2">as </span><span class="s1">sc</span>

<span class="s2">import </span><span class="s1">scipy.special._ufuncs </span><span class="s2">as </span><span class="s1">scu</span>
<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">_lazyselect</span><span class="s2">, </span><span class="s1">_lazywhere</span>

<span class="s2">from </span><span class="s1">. </span><span class="s2">import </span><span class="s1">_stats</span>
<span class="s2">from </span><span class="s1">._tukeylambda_stats </span><span class="s2">import </span><span class="s1">(tukeylambda_variance </span><span class="s2">as </span><span class="s1">_tlvar</span><span class="s2">,</span>
                                 <span class="s1">tukeylambda_kurtosis </span><span class="s2">as </span><span class="s1">_tlkurt)</span>
<span class="s2">from </span><span class="s1">._distn_infrastructure </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">get_distribution_names</span><span class="s2">, </span><span class="s1">_kurtosis</span><span class="s2">,</span>
    <span class="s1">rv_continuous</span><span class="s2">, </span><span class="s1">_skew</span><span class="s2">, </span><span class="s1">_get_fixed_fit_value</span><span class="s2">, </span><span class="s1">_check_shape</span><span class="s2">, </span><span class="s1">_ShapeInfo)</span>
<span class="s2">from </span><span class="s1">._ksstats </span><span class="s2">import </span><span class="s1">kolmogn</span><span class="s2">, </span><span class="s1">kolmognp</span><span class="s2">, </span><span class="s1">kolmogni</span>
<span class="s2">from </span><span class="s1">._constants </span><span class="s2">import </span><span class="s1">(_XMIN</span><span class="s2">, </span><span class="s1">_LOGXMIN</span><span class="s2">, </span><span class="s1">_EULER</span><span class="s2">, </span><span class="s1">_ZETA3</span><span class="s2">, </span><span class="s1">_SQRT_PI</span><span class="s2">,</span>
                         <span class="s1">_SQRT_2_OVER_PI</span><span class="s2">, </span><span class="s1">_LOG_SQRT_2_OVER_PI)</span>
<span class="s2">from </span><span class="s1">._censored_data </span><span class="s2">import </span><span class="s1">CensoredData</span>
<span class="s2">import </span><span class="s1">scipy.stats._boost </span><span class="s2">as </span><span class="s1">_boost</span>
<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">root_scalar</span>
<span class="s2">from </span><span class="s1">scipy.stats._warnings_errors </span><span class="s2">import </span><span class="s1">FitError</span>
<span class="s2">import </span><span class="s1">scipy.stats </span><span class="s2">as </span><span class="s1">stats</span>


<span class="s2">def </span><span class="s1">_remove_optimizer_parameters(kwds):</span>
    <span class="s3">&quot;&quot;&quot; 
    Remove the optimizer-related keyword arguments 'loc', 'scale' and 
    'optimizer' from `kwds`.  Then check that `kwds` is empty, and 
    raise `TypeError(&quot;Unknown arguments: %s.&quot; % kwds)` if it is not. 
 
    This function is used in the fit method of distributions that override 
    the default method and do not use the default optimization code. 
 
    `kwds` is modified in-place. 
    &quot;&quot;&quot;</span>
    <span class="s1">kwds.pop(</span><span class="s4">'loc'</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">kwds.pop(</span><span class="s4">'scale'</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">kwds.pop(</span><span class="s4">'optimizer'</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">kwds.pop(</span><span class="s4">'method'</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">kwds:</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Unknown arguments: %s.&quot; </span><span class="s1">% kwds)</span>


<span class="s2">def </span><span class="s1">_call_super_mom(fun):</span>
    <span class="s0"># If fit method is overridden only for MLE and doesn't specify what to do</span>
    <span class="s0"># if method == 'mm' or with censored data, this decorator calls the generic</span>
    <span class="s0"># implementation.</span>
    <span class="s1">@wraps(fun)</span>
    <span class="s2">def </span><span class="s1">wrapper(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">method = kwds.get(</span><span class="s4">'method'</span><span class="s2">, </span><span class="s4">'mle'</span><span class="s1">).lower()</span>
        <span class="s1">censored = isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData)</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s4">'mm' </span><span class="s2">or </span><span class="s1">(censored </span><span class="s2">and </span><span class="s1">data.num_censored() &gt; </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super(type(self)</span><span class="s2">, </span><span class="s1">self).fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">censored:</span>
                <span class="s0"># data is an instance of CensoredData, but actually holds</span>
                <span class="s0"># no censored values, so replace it with the array of</span>
                <span class="s0"># uncensored values.</span>
                <span class="s1">data = data._uncensored</span>
            <span class="s2">return </span><span class="s1">fun(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

    <span class="s2">return </span><span class="s1">wrapper</span>


<span class="s2">def </span><span class="s1">_get_left_bracket(fun</span><span class="s2">, </span><span class="s1">rbrack</span><span class="s2">, </span><span class="s1">lbrack=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s0"># find left bracket for `root_scalar`. A guess for lbrack may be provided.</span>
    <span class="s1">lbrack = lbrack </span><span class="s2">or </span><span class="s1">rbrack - </span><span class="s5">1</span>
    <span class="s1">diff = rbrack - lbrack</span>

    <span class="s0"># if there is no sign change in `fun` between the brackets, expand</span>
    <span class="s0"># rbrack - lbrack until a sign change occurs</span>
    <span class="s2">def </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack):</span>
        <span class="s0"># return true if the signs disagree.</span>
        <span class="s2">return </span><span class="s1">np.sign(fun(lbrack)) != np.sign(fun(rbrack))</span>

    <span class="s2">while not </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack):</span>
        <span class="s1">diff *= </span><span class="s5">2</span>
        <span class="s1">lbrack = rbrack - diff</span>

        <span class="s1">msg = (</span><span class="s4">&quot;The solver could not find a bracket containing a &quot;</span>
               <span class="s4">&quot;root to an MLE first order condition.&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">np.isinf(lbrack):</span>
            <span class="s2">raise </span><span class="s1">FitSolverError(msg)</span>

    <span class="s2">return </span><span class="s1">lbrack</span>


<span class="s2">class </span><span class="s1">ksone_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Kolmogorov-Smirnov one-sided test statistic distribution. 
 
    This is the distribution of the one-sided Kolmogorov-Smirnov (KS) 
    statistics :math:`D_n^+` and :math:`D_n^-` 
    for a finite sample size ``n &gt;= 1`` (the shape parameter). 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    kstwobign, kstwo, kstest 
 
    Notes 
    ----- 
    :math:`D_n^+` and :math:`D_n^-` are given by 
 
    .. math:: 
 
        D_n^+ &amp;= \text{sup}_x (F_n(x) - F(x)),\\ 
        D_n^- &amp;= \text{sup}_x (F(x) - F_n(x)),\\ 
 
    where :math:`F` is a continuous CDF and :math:`F_n` is an empirical CDF. 
    `ksone` describes the distribution under the null hypothesis of the KS test 
    that the empirical CDF corresponds to :math:`n` i.i.d. random variates 
    with CDF :math:`F`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Birnbaum, Z. W. and Tingey, F.H. &quot;One-sided confidence contours 
       for probability distribution functions&quot;, The Annals of Mathematical 
       Statistics, 22(4), pp 592-596 (1951). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">(n &gt;= </span><span class="s5">1</span><span class="s1">) &amp; (n == np.round(n))</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">-scu._smirnovp(n</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">scu._smirnovc(n</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">sc.smirnov(n</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">scu._smirnovci(n</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">sc.smirnovi(n</span><span class="s2">, </span><span class="s1">q)</span>


<span class="s1">ksone = ksone_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'ksone'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">kstwo_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Kolmogorov-Smirnov two-sided test statistic distribution. 
 
    This is the distribution of the two-sided Kolmogorov-Smirnov (KS) 
    statistic :math:`D_n` for a finite sample size ``n &gt;= 1`` 
    (the shape parameter). 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    kstwobign, ksone, kstest 
 
    Notes 
    ----- 
    :math:`D_n` is given by 
 
    .. math:: 
 
        D_n = \text{sup}_x |F_n(x) - F(x)| 
 
    where :math:`F` is a (continuous) CDF and :math:`F_n` is an empirical CDF. 
    `kstwo` describes the distribution under the null hypothesis of the KS test 
    that the empirical CDF corresponds to :math:`n` i.i.d. random variates 
    with CDF :math:`F`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Simard, R., L'Ecuyer, P. &quot;Computing the Two-Sided 
       Kolmogorov-Smirnov Distribution&quot;,  Journal of Statistical Software, 
       Vol 39, 11, 1-18 (2011). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">(n &gt;= </span><span class="s5">1</span><span class="s1">) &amp; (n == np.round(n))</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">0.5</span><span class="s1">/(n </span><span class="s2">if not </span><span class="s1">isinstance(n</span><span class="s2">, </span><span class="s1">Iterable) </span><span class="s2">else </span><span class="s1">np.asanyarray(n))</span><span class="s2">,</span>
                <span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">kolmognp(n</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">kolmogn(n</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">kolmogn(n</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">cdf=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">kolmogni(n</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">cdf=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">kolmogni(n</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">cdf=</span><span class="s2">False</span><span class="s1">)</span>


<span class="s0"># Use the pdf, (not the ppf) to compute moments</span>
<span class="s1">kstwo = kstwo_gen(momtype=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'kstwo'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">kstwobign_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Limiting distribution of scaled Kolmogorov-Smirnov two-sided test statistic. 
 
    This is the asymptotic distribution of the two-sided Kolmogorov-Smirnov 
    statistic :math:`\sqrt{n} D_n` that measures the maximum absolute 
    distance of the theoretical (continuous) CDF from the empirical CDF. 
    (see `kstest`). 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    ksone, kstwo, kstest 
 
    Notes 
    ----- 
    :math:`\sqrt{n} D_n` is given by 
 
    .. math:: 
 
        D_n = \text{sup}_x |F_n(x) - F(x)| 
 
    where :math:`F` is a continuous CDF and :math:`F_n` is an empirical CDF. 
    `kstwobign`  describes the asymptotic distribution (i.e. the limit of 
    :math:`\sqrt{n} D_n`) under the null hypothesis of the KS test that the 
    empirical CDF corresponds to i.i.d. random variates with CDF :math:`F`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Feller, W. &quot;On the Kolmogorov-Smirnov Limit Theorems for Empirical 
       Distributions&quot;,  Ann. Math. Statist. Vol 19, 177-189 (1948). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-scu._kolmogp(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">scu._kolmogc(x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.kolmogorov(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">scu._kolmogci(q)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">sc.kolmogi(q)</span>


<span class="s1">kstwobign = kstwobign_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'kstwobign'</span><span class="s1">)</span>


<span class="s0">## Normal distribution</span>

<span class="s0"># loc = mu, scale = std</span>
<span class="s0"># Keep these implementations out of the class definition so they can be reused</span>
<span class="s0"># by other distributions.</span>
<span class="s1">_norm_pdf_C = np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi)</span>
<span class="s1">_norm_pdf_logC = np.log(_norm_pdf_C)</span>


<span class="s2">def </span><span class="s1">_norm_pdf(x):</span>
    <span class="s2">return </span><span class="s1">np.exp(-x**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2.0</span><span class="s1">) / _norm_pdf_C</span>


<span class="s2">def </span><span class="s1">_norm_logpdf(x):</span>
    <span class="s2">return </span><span class="s1">-x**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0 </span><span class="s1">- _norm_pdf_logC</span>


<span class="s2">def </span><span class="s1">_norm_cdf(x):</span>
    <span class="s2">return </span><span class="s1">sc.ndtr(x)</span>


<span class="s2">def </span><span class="s1">_norm_logcdf(x):</span>
    <span class="s2">return </span><span class="s1">sc.log_ndtr(x)</span>


<span class="s2">def </span><span class="s1">_norm_ppf(q):</span>
    <span class="s2">return </span><span class="s1">sc.ndtri(q)</span>


<span class="s2">def </span><span class="s1">_norm_sf(x):</span>
    <span class="s2">return </span><span class="s1">_norm_cdf(-x)</span>


<span class="s2">def </span><span class="s1">_norm_logsf(x):</span>
    <span class="s2">return </span><span class="s1">_norm_logcdf(-x)</span>


<span class="s2">def </span><span class="s1">_norm_isf(q):</span>
    <span class="s2">return </span><span class="s1">-_norm_ppf(q)</span>


<span class="s2">class </span><span class="s1">norm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A normal continuous random variable. 
 
    The location (``loc``) keyword specifies the mean. 
    The scale (``scale``) keyword specifies the standard deviation. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `norm` is: 
 
    .. math:: 
 
        f(x) = \frac{\exp(-x^2/2)}{\sqrt{2\pi}} 
 
    for a real number :math:`x`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.standard_normal(size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># norm.pdf(x) = exp(-x**2/2)/sqrt(2*pi)</span>
        <span class="s2">return </span><span class="s1">_norm_pdf(x)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_logpdf(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(x)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_logcdf(x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(x)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_logsf(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">_norm_ppf(q)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">_norm_isf(q)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">0.0</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">*(np.log(</span><span class="s5">2</span><span class="s1">*np.pi)+</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@replace_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">For the normal distribution, method of moments and maximum likelihood 
        estimation give identical fits, and explicit formulas for the estimates 
        are available. 
        This function uses these explicit formulas for the maximum likelihood 
        estimation of the normal distribution parameters, so the 
        `optimizer` and `method` arguments are ignored.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">floc = kwds.pop(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">fscale = kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">_remove_optimizer_parameters(kwds)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
            <span class="s0"># Without this check, this function would just return the</span>
            <span class="s0"># parameters that were given.</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                             <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

        <span class="s1">data = np.asarray(data)</span>

        <span class="s2">if not </span><span class="s1">np.isfinite(data).all():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">loc = data.mean()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">loc = floc</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">scale = np.sqrt(((data - loc)**</span><span class="s5">2</span><span class="s1">).mean())</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">scale = fscale</span>

        <span class="s2">return </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s3">&quot;&quot;&quot; 
        @returns Moments of standard normal distribution for integer n &gt;= 0 
 
        See eq. 16 of https://arxiv.org/abs/1209.4340v2 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">n % </span><span class="s5">2 </span><span class="s1">== </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">sc.factorial2(n - </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">0.</span>


<span class="s1">norm = norm_gen(name=</span><span class="s4">'norm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">alpha_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An alpha continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `alpha` ([1]_, [2]_) is: 
 
    .. math:: 
 
        f(x, a) = \frac{1}{x^2 \Phi(a) \sqrt{2\pi}} * 
                  \exp(-\frac{1}{2} (a-1/x)^2) 
 
    where :math:`\Phi` is the normal CDF, :math:`x &gt; 0`, and :math:`a &gt; 0`. 
 
    `alpha` takes ``a`` as a shape parameter. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Johnson, Kotz, and Balakrishnan, &quot;Continuous Univariate 
           Distributions, Volume 1&quot;, Second Edition, John Wiley and Sons, 
           p. 173 (1994). 
    .. [2] Anthony A. Salvia, &quot;Reliability applications of the Alpha 
           Distribution&quot;, IEEE Transactions on Reliability, Vol. R-34, 
           No. 3, pp. 251-252 (1985). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># alpha.pdf(x, a) = 1/(x**2*Phi(a)*sqrt(2*pi)) * exp(-1/2 * (a-1/x)**2)</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/(x**</span><span class="s5">2</span><span class="s1">)/_norm_cdf(a)*_norm_pdf(a-</span><span class="s5">1.0</span><span class="s1">/x)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">2</span><span class="s1">*np.log(x) + _norm_logpdf(a-</span><span class="s5">1.0</span><span class="s1">/x) - np.log(_norm_cdf(a))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(a-</span><span class="s5">1.0</span><span class="s1">/x) / _norm_cdf(a)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.asarray(a - _norm_ppf(q*_norm_cdf(a)))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">[np.inf]*</span><span class="s5">2 </span><span class="s1">+ [np.nan]*</span><span class="s5">2</span>


<span class="s1">alpha = alpha_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'alpha'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">anglit_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An anglit continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `anglit` is: 
 
    .. math:: 
 
        f(x) = \sin(2x + \pi/2) = \cos(2x) 
 
    for :math:`-\pi/4 \le x \le \pi/4`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># anglit.pdf(x) = sin(2*x + \pi/2) = cos(2*x)</span>
        <span class="s2">return </span><span class="s1">np.cos(</span><span class="s5">2</span><span class="s1">*x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.sin(x+np.pi/</span><span class="s5">4</span><span class="s1">)**</span><span class="s5">2.0</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.cos(x + np.pi / </span><span class="s5">4</span><span class="s1">) ** </span><span class="s5">2.0</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.arcsin(np.sqrt(q))-np.pi/</span><span class="s5">4</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">16</span><span class="s1">-</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">*(np.pi**</span><span class="s5">4 </span><span class="s1">- </span><span class="s5">96</span><span class="s1">)/(np.pi*np.pi-</span><span class="s5">8</span><span class="s1">)**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s1">-np.log(</span><span class="s5">2</span><span class="s1">)</span>


<span class="s1">anglit = anglit_gen(a=-np.pi/</span><span class="s5">4</span><span class="s2">, </span><span class="s1">b=np.pi/</span><span class="s5">4</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'anglit'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">arcsine_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An arcsine continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `arcsine` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{\pi \sqrt{x (1-x)}} 
 
    for :math:`0 &lt; x &lt; 1`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># arcsine.pdf(x) = 1/(pi*sqrt(x*(1-x)))</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.pi/np.sqrt(x*(</span><span class="s5">1</span><span class="s1">-x))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi*np.arcsin(np.sqrt(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.sin(np.pi/</span><span class="s5">2.0</span><span class="s1">*q)**</span><span class="s5">2.0</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s1">mu = </span><span class="s5">0.5</span>
        <span class="s1">mu2 = </span><span class="s5">1.0</span><span class="s1">/</span><span class="s5">8</span>
        <span class="s1">g1 = </span><span class="s5">0</span>
        <span class="s1">g2 = -</span><span class="s5">3.0</span><span class="s1">/</span><span class="s5">2.0</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">0.24156447527049044468</span>


<span class="s1">arcsine = arcsine_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'arcsine'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">FitDataError(ValueError):</span>
    <span class="s3">&quot;&quot;&quot;Raised when input data is inconsistent with fixed parameters.&quot;&quot;&quot;</span>
    <span class="s0"># This exception is raised by, for example, beta_gen.fit when both floc</span>
    <span class="s0"># and fscale are fixed and there are values in the data not in the open</span>
    <span class="s0"># interval (floc, floc+fscale).</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">distr</span><span class="s2">, </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper):</span>
        <span class="s1">self.args = (</span>
            <span class="s4">&quot;Invalid values in `data`.  Maximum likelihood &quot;</span>
            <span class="s4">&quot;estimation with {distr!r} requires that {lower!r} &lt; &quot;</span>
            <span class="s4">&quot;(x - loc)/scale  &lt; {upper!r} for each x in `data`.&quot;</span><span class="s1">.format(</span>
                <span class="s1">distr=distr</span><span class="s2">, </span><span class="s1">lower=lower</span><span class="s2">, </span><span class="s1">upper=upper)</span><span class="s2">,</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">FitSolverError(FitError):</span>
    <span class="s3">&quot;&quot;&quot; 
    Raised when a solver fails to converge while fitting a distribution. 
    &quot;&quot;&quot;</span>
    <span class="s0"># This exception is raised by, for example, beta_gen.fit when</span>
    <span class="s0"># optimize.fsolve returns with ier != 1.</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">mesg):</span>
        <span class="s1">emsg = </span><span class="s4">&quot;Solver for the MLE equations failed to converge: &quot;</span>
        <span class="s1">emsg += mesg.replace(</span><span class="s4">'</span><span class="s2">\n</span><span class="s4">'</span><span class="s2">, </span><span class="s4">''</span><span class="s1">)</span>
        <span class="s1">self.args = (emsg</span><span class="s2">,</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_beta_mle_a(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">s1):</span>
    <span class="s0"># The zeros of this function give the MLE for `a`, with</span>
    <span class="s0"># `b`, `n` and `s1` given.  `s1` is the sum of the logs of</span>
    <span class="s0"># the data. `n` is the number of data points.</span>
    <span class="s1">psiab = sc.psi(a + b)</span>
    <span class="s1">func = s1 - n * (-psiab + sc.psi(a))</span>
    <span class="s2">return </span><span class="s1">func</span>


<span class="s2">def </span><span class="s1">_beta_mle_ab(theta</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">s1</span><span class="s2">, </span><span class="s1">s2):</span>
    <span class="s0"># Zeros of this function are critical points of</span>
    <span class="s0"># the maximum likelihood function.  Solving this system</span>
    <span class="s0"># for theta (which contains a and b) gives the MLE for a and b</span>
    <span class="s0"># given `n`, `s1` and `s2`.  `s1` is the sum of the logs of the data,</span>
    <span class="s0"># and `s2` is the sum of the logs of 1 - data.  `n` is the number</span>
    <span class="s0"># of data points.</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">b = theta</span>
    <span class="s1">psiab = sc.psi(a + b)</span>
    <span class="s1">func = [s1 - n * (-psiab + sc.psi(a))</span><span class="s2">,</span>
            <span class="s1">s2 - n * (-psiab + sc.psi(b))]</span>
    <span class="s2">return </span><span class="s1">func</span>


<span class="s2">class </span><span class="s1">beta_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A beta continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `beta` is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{\Gamma(a+b) x^{a-1} (1-x)^{b-1}} 
                          {\Gamma(a) \Gamma(b)} 
 
    for :math:`0 &lt;= x &lt;= 1`, :math:`a &gt; 0`, :math:`b &gt; 0`, where 
    :math:`\Gamma` is the gamma function (`scipy.special.gamma`). 
 
    `beta` takes :math:`a` and :math:`b` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.beta(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0">#                     gamma(a+b) * x**(a-1) * (1-x)**(b-1)</span>
        <span class="s0"># beta.pdf(x, a, b) = ------------------------------------</span>
        <span class="s0">#                              gamma(a)*gamma(b)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">_boost._beta_pdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">lPx = sc.xlog1py(b - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-x) + sc.xlogy(a - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x)</span>
        <span class="s1">lPx -= sc.betaln(a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s2">return </span><span class="s1">lPx</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_boost._beta_cdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_boost._beta_sf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._beta_isf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._beta_ppf(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(</span>
            <span class="s1">_boost._beta_mean(a</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
            <span class="s1">_boost._beta_variance(a</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
            <span class="s1">_boost._beta_skewness(a</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
            <span class="s1">_boost._beta_kurtosis_excess(a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>

        <span class="s1">g1 = _skew(data)</span>
        <span class="s1">g2 = _kurtosis(data)</span>

        <span class="s2">def </span><span class="s1">func(x):</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = x</span>
            <span class="s1">sk = </span><span class="s5">2</span><span class="s1">*(b-a)*np.sqrt(a + b + </span><span class="s5">1</span><span class="s1">) / (a + b + </span><span class="s5">2</span><span class="s1">) / np.sqrt(a*b)</span>
            <span class="s1">ku = a**</span><span class="s5">3 </span><span class="s1">- a**</span><span class="s5">2</span><span class="s1">*(</span><span class="s5">2</span><span class="s1">*b-</span><span class="s5">1</span><span class="s1">) + b**</span><span class="s5">2</span><span class="s1">*(b+</span><span class="s5">1</span><span class="s1">) - </span><span class="s5">2</span><span class="s1">*a*b*(b+</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">ku /= a*b*(a+b+</span><span class="s5">2</span><span class="s1">)*(a+b+</span><span class="s5">3</span><span class="s1">)</span>
            <span class="s1">ku *= </span><span class="s5">6</span>
            <span class="s2">return </span><span class="s1">[sk-g1</span><span class="s2">, </span><span class="s1">ku-g2]</span>
        <span class="s1">a</span><span class="s2">, </span><span class="s1">b = optimize.fsolve(func</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">In the special case where `method=&quot;MLE&quot;` and 
        both `floc` and `fscale` are given, a 
        `ValueError` is raised if any value `x` in `data` does not satisfy 
        `floc &lt; x &lt; floc + fscale`.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s0"># Override rv_continuous.fit, so we can more efficiently handle the</span>
        <span class="s0"># case where floc and fscale are given.</span>

        <span class="s1">floc = kwds.get(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">fscale = kwds.get(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None or </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># do general fit</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># We already got these from kwds, so just pop them.</span>
        <span class="s1">kwds.pop(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">f0 = _get_fixed_fit_value(kwds</span><span class="s2">, </span><span class="s1">[</span><span class="s4">'f0'</span><span class="s2">, </span><span class="s4">'fa'</span><span class="s2">, </span><span class="s4">'fix_a'</span><span class="s1">])</span>
        <span class="s1">f1 = _get_fixed_fit_value(kwds</span><span class="s2">, </span><span class="s1">[</span><span class="s4">'f1'</span><span class="s2">, </span><span class="s4">'fb'</span><span class="s2">, </span><span class="s4">'fix_b'</span><span class="s1">])</span>

        <span class="s1">_remove_optimizer_parameters(kwds)</span>

        <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None and </span><span class="s1">f1 </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                             <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

        <span class="s0"># Special case: loc and scale are constrained, so we are fitting</span>
        <span class="s0"># just the shape parameters.  This can be done much more efficiently</span>
        <span class="s0"># than the method used in `rv_continuous.fit`.  (See the subsection</span>
        <span class="s0"># &quot;Two unknown parameters&quot; in the section &quot;Maximum likelihood&quot; of</span>
        <span class="s0"># the Wikipedia article on the Beta distribution for the formulas.)</span>

        <span class="s2">if not </span><span class="s1">np.isfinite(data).all():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

        <span class="s0"># Normalize the data to the interval [0, 1].</span>
        <span class="s1">data = (np.ravel(data) - floc) / fscale</span>
        <span class="s2">if </span><span class="s1">np.any(data &lt;= </span><span class="s5">0</span><span class="s1">) </span><span class="s2">or </span><span class="s1">np.any(data &gt;= </span><span class="s5">1</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;beta&quot;</span><span class="s2">, </span><span class="s1">lower=floc</span><span class="s2">, </span><span class="s1">upper=floc + fscale)</span>

        <span class="s1">xbar = data.mean()</span>

        <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None or </span><span class="s1">f1 </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># One of the shape parameters is fixed.</span>

            <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s0"># The shape parameter a is fixed, so swap the parameters</span>
                <span class="s0"># and flip the data.  We always solve for `a`.  The result</span>
                <span class="s0"># will be swapped back before returning.</span>
                <span class="s1">b = f0</span>
                <span class="s1">data = </span><span class="s5">1 </span><span class="s1">- data</span>
                <span class="s1">xbar = </span><span class="s5">1 </span><span class="s1">- xbar</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">b = f1</span>

            <span class="s0"># Initial guess for a.  Use the formula for the mean of the beta</span>
            <span class="s0"># distribution, E[x] = a / (a + b), to generate a reasonable</span>
            <span class="s0"># starting point based on the mean of the data and the given</span>
            <span class="s0"># value of b.</span>
            <span class="s1">a = b * xbar / (</span><span class="s5">1 </span><span class="s1">- xbar)</span>

            <span class="s0"># Compute the MLE for `a` by solving _beta_mle_a.</span>
            <span class="s1">theta</span><span class="s2">, </span><span class="s1">info</span><span class="s2">, </span><span class="s1">ier</span><span class="s2">, </span><span class="s1">mesg = optimize.fsolve(</span>
                <span class="s1">_beta_mle_a</span><span class="s2">, </span><span class="s1">a</span><span class="s2">,</span>
                <span class="s1">args=(b</span><span class="s2">, </span><span class="s1">len(data)</span><span class="s2">, </span><span class="s1">np.log(data).sum())</span><span class="s2">,</span>
                <span class="s1">full_output=</span><span class="s2">True</span>
            <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">ier != </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">FitSolverError(mesg=mesg)</span>
            <span class="s1">a = theta[</span><span class="s5">0</span><span class="s1">]</span>

            <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s0"># The shape parameter a was fixed, so swap back the</span>
                <span class="s0"># parameters.</span>
                <span class="s1">a</span><span class="s2">, </span><span class="s1">b = b</span><span class="s2">, </span><span class="s1">a</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># Neither of the shape parameters is fixed.</span>

            <span class="s0"># s1 and s2 are used in the extra arguments passed to _beta_mle_ab</span>
            <span class="s0"># by optimize.fsolve.</span>
            <span class="s1">s1 = np.log(data).sum()</span>
            <span class="s1">s2 = sc.log1p(-data).sum()</span>

            <span class="s0"># Use the &quot;method of moments&quot; to estimate the initial</span>
            <span class="s0"># guess for a and b.</span>
            <span class="s1">fac = xbar * (</span><span class="s5">1 </span><span class="s1">- xbar) / data.var(ddof=</span><span class="s5">0</span><span class="s1">) - </span><span class="s5">1</span>
            <span class="s1">a = xbar * fac</span>
            <span class="s1">b = (</span><span class="s5">1 </span><span class="s1">- xbar) * fac</span>

            <span class="s0"># Compute the MLE for a and b by solving _beta_mle_ab.</span>
            <span class="s1">theta</span><span class="s2">, </span><span class="s1">info</span><span class="s2">, </span><span class="s1">ier</span><span class="s2">, </span><span class="s1">mesg = optimize.fsolve(</span>
                <span class="s1">_beta_mle_ab</span><span class="s2">, </span><span class="s1">[a</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">,</span>
                <span class="s1">args=(len(data)</span><span class="s2">, </span><span class="s1">s1</span><span class="s2">, </span><span class="s1">s2)</span><span class="s2">,</span>
                <span class="s1">full_output=</span><span class="s2">True</span>
            <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">ier != </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">FitSolverError(mesg=mesg)</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = theta</span>

        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(sc.betaln(a</span><span class="s2">, </span><span class="s1">b) - (a - </span><span class="s5">1</span><span class="s1">) * sc.psi(a) -</span>
                <span class="s1">(b - </span><span class="s5">1</span><span class="s1">) * sc.psi(b) + (a + b - </span><span class="s5">2</span><span class="s1">) * sc.psi(a + b))</span>


<span class="s1">beta = beta_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'beta'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">betaprime_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A beta prime continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `betaprime` is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{x^{a-1} (1+x)^{-a-b}}{\beta(a, b)} 
 
    for :math:`x &gt;= 0`, :math:`a &gt; 0`, :math:`b &gt; 0`, where 
    :math:`\beta(a, b)` is the beta function (see `scipy.special.beta`). 
 
    `betaprime` takes ``a`` and ``b`` as shape parameters. 
 
    The distribution is related to the `beta` distribution as follows: 
    If :math:`X` follows a beta distribution with parameters :math:`a, b`, 
    then :math:`Y = X/(1-X)` has a beta prime distribution with 
    parameters :math:`a, b` ([1]_). 
 
    The beta prime distribution is a reparametrized version of the 
    F distribution.  The beta prime distribution with shape parameters 
    ``a`` and ``b`` and ``scale = s`` is equivalent to the F distribution 
    with parameters ``d1 = 2*a``, ``d2 = 2*b`` and ``scale = (a/b)*s``. 
    For example, 
 
    &gt;&gt;&gt; from scipy.stats import betaprime, f 
    &gt;&gt;&gt; x = [1, 2, 5, 10] 
    &gt;&gt;&gt; a = 12 
    &gt;&gt;&gt; b = 5 
    &gt;&gt;&gt; betaprime.pdf(x, a, b, scale=2) 
    array([0.00541179, 0.08331299, 0.14669185, 0.03150079]) 
    &gt;&gt;&gt; f.pdf(x, 2*a, 2*b, scale=(a/b)*2) 
    array([0.00541179, 0.08331299, 0.14669185, 0.03150079]) 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Beta prime distribution, Wikipedia, 
           https://en.wikipedia.org/wiki/Beta_prime_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">u1 = gamma.rvs(a</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s1">u2 = gamma.rvs(b</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">u1 / u2</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># betaprime.pdf(x, a, b) = x**(a-1) * (1+x)**(-a-b) / beta(a, b)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">sc.xlogy(a - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x) - sc.xlog1py(a + b</span><span class="s2">, </span><span class="s1">x) - sc.betaln(a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># note: f2 is the direct way to compute the cdf if the relationship</span>
        <span class="s0"># to the beta distribution is used.</span>
        <span class="s0"># however, for very large x, x/(1+x) == 1. since the distribution</span>
        <span class="s0"># has very fat tails if b is small, this can cause inaccurate results</span>
        <span class="s0"># use the following relationship of the incomplete beta function:</span>
        <span class="s0"># betainc(x, a, b) = 1 - betainc(1-x, b, a)</span>
        <span class="s0"># see gh-17631</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">x &gt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">[x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_: beta._sf(</span><span class="s5">1</span><span class="s1">/(</span><span class="s5">1</span><span class="s1">+x_)</span><span class="s2">, </span><span class="s1">b_</span><span class="s2">, </span><span class="s1">a_)</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_: beta._cdf(x_/(</span><span class="s5">1</span><span class="s1">+x_)</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">x &gt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">[x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_: beta._cdf(</span><span class="s5">1</span><span class="s1">/(</span><span class="s5">1</span><span class="s1">+x_)</span><span class="s2">, </span><span class="s1">b_</span><span class="s2">, </span><span class="s1">a_)</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_: beta._sf(x_/(</span><span class="s5">1</span><span class="s1">+x_)</span><span class="s2">, </span><span class="s1">a_</span><span class="s2">, </span><span class="s1">b_)</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s0"># by default, compute compute the ppf by solving the following:</span>
        <span class="s0"># p = beta._cdf(x/(1+x), a, b). This implies x = r/(1-r) with</span>
        <span class="s0"># r = beta._ppf(p, a, b). This can cause numerical issues if r is</span>
        <span class="s0"># very close to 1. in that case, invert the alternative expression of</span>
        <span class="s0"># the cdf: p = beta._sf(1/(1+x), b, a).</span>
        <span class="s1">r = stats.beta._ppf(p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">out = r / (</span><span class="s5">1 </span><span class="s1">- r)</span>
        <span class="s1">i = (r &gt; </span><span class="s5">0.9999</span><span class="s1">)</span>
        <span class="s1">out[i] = </span><span class="s5">1</span><span class="s1">/stats.beta._isf(p[i]</span><span class="s2">, </span><span class="s1">b[i]</span><span class="s2">, </span><span class="s1">a[i]) - </span><span class="s5">1</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">b &gt; n</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b: np.prod([(a+i-</span><span class="s5">1</span><span class="s1">)/(b-i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s5">1</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">fillvalue=np.inf)</span>


<span class="s1">betaprime = betaprime_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'betaprime'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">bradford_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Bradford continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `bradford` is: 
 
    .. math:: 
 
        f(x, c) = \frac{c}{\log(1+c) (1+cx)} 
 
    for :math:`0 &lt;= x &lt;= 1` and :math:`c &gt; 0`. 
 
    `bradford` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># bradford.pdf(x, c) = c / (k * (1+c*x))</span>
        <span class="s2">return </span><span class="s1">c / (c*x + </span><span class="s5">1.0</span><span class="s1">) / sc.log1p(c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.log1p(c*x) / sc.log1p(c)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.expm1(q * sc.log1p(c)) / c</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">k = np.log(</span><span class="s5">1.0</span><span class="s1">+c)</span>
        <span class="s1">mu = (c-k)/(c*k)</span>
        <span class="s1">mu2 = ((c+</span><span class="s5">2.0</span><span class="s1">)*k-</span><span class="s5">2.0</span><span class="s1">*c)/(</span><span class="s5">2</span><span class="s1">*c*k*k)</span>
        <span class="s1">g1 = </span><span class="s2">None</span>
        <span class="s1">g2 = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g1 = np.sqrt(</span><span class="s5">2</span><span class="s1">)*(</span><span class="s5">12</span><span class="s1">*c*c-</span><span class="s5">9</span><span class="s1">*c*k*(c+</span><span class="s5">2</span><span class="s1">)+</span><span class="s5">2</span><span class="s1">*k*k*(c*(c+</span><span class="s5">3</span><span class="s1">)+</span><span class="s5">3</span><span class="s1">))</span>
            <span class="s1">g1 /= np.sqrt(c*(c*(k-</span><span class="s5">2</span><span class="s1">)+</span><span class="s5">2</span><span class="s1">*k))*(</span><span class="s5">3</span><span class="s1">*c*(k-</span><span class="s5">2</span><span class="s1">)+</span><span class="s5">6</span><span class="s1">*k)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g2 = (c**</span><span class="s5">3</span><span class="s1">*(k-</span><span class="s5">3</span><span class="s1">)*(k*(</span><span class="s5">3</span><span class="s1">*k-</span><span class="s5">16</span><span class="s1">)+</span><span class="s5">24</span><span class="s1">)+</span><span class="s5">12</span><span class="s1">*k*c*c*(k-</span><span class="s5">4</span><span class="s1">)*(k-</span><span class="s5">3</span><span class="s1">) +</span>
                  <span class="s5">6</span><span class="s1">*c*k*k*(</span><span class="s5">3</span><span class="s1">*k-</span><span class="s5">14</span><span class="s1">) + </span><span class="s5">12</span><span class="s1">*k**</span><span class="s5">3</span><span class="s1">)</span>
            <span class="s1">g2 /= </span><span class="s5">3</span><span class="s1">*c*(c*(k-</span><span class="s5">2</span><span class="s1">)+</span><span class="s5">2</span><span class="s1">*k)**</span><span class="s5">2</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">k = np.log(</span><span class="s5">1</span><span class="s1">+c)</span>
        <span class="s2">return </span><span class="s1">k/</span><span class="s5">2.0 </span><span class="s1">- np.log(c/k)</span>


<span class="s1">bradford = bradford_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'bradford'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">burr_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Burr (Type III) continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    fisk : a special case of either `burr` or `burr12` with ``d=1`` 
    burr12 : Burr Type XII distribution 
    mielke : Mielke Beta-Kappa / Dagum distribution 
 
    Notes 
    ----- 
    The probability density function for `burr` is: 
 
    .. math:: 
 
        f(x; c, d) = c d \frac{x^{-c - 1}} 
                              {{(1 + x^{-c})}^{d + 1}} 
 
    for :math:`x &gt;= 0` and :math:`c, d &gt; 0`. 
 
    `burr` takes ``c`` and ``d`` as shape parameters for :math:`c` and 
    :math:`d`. 
 
    This is the PDF corresponding to the third CDF given in Burr's list; 
    specifically, it is equation (11) in Burr's paper [1]_. The distribution 
    is also commonly referred to as the Dagum distribution [2]_. If the 
    parameter :math:`c &lt; 1` then the mean of the distribution does not 
    exist and if :math:`c &lt; 2` the variance does not exist [2]_. 
    The PDF is finite at the left endpoint :math:`x = 0` if :math:`c * d &gt;= 1`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Burr, I. W. &quot;Cumulative frequency functions&quot;, Annals of 
       Mathematical Statistics, 13(2), pp 215-232 (1942). 
    .. [2] https://en.wikipedia.org/wiki/Dagum_distribution 
    .. [3] Kleiber, Christian. &quot;A guide to the Dagum distributions.&quot; 
       Modeling Income Distributions and Lorenz Curves  pp 97-117 (2008). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s0"># Do not set _support_mask to rv_continuous._open_support_mask</span>
    <span class="s0"># Whether the left-hand endpoint is suitable for pdf evaluation is dependent</span>
    <span class="s0"># on the values of c and d: if c*d &gt;= 1, the pdf is finite, otherwise infinite.</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">id = _ShapeInfo(</span><span class="s4">&quot;d&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ic</span><span class="s2">, </span><span class="s1">id]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s0"># burr.pdf(x, c, d) = c * d * x**(-c-1) * (1+x**(-c))**(-d-1)</span>
        <span class="s1">output = _lazywhere(</span>
            <span class="s1">x == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">[x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d]</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">c_</span><span class="s2">, </span><span class="s1">d_: c_ * d_ * (x_**(c_*d_-</span><span class="s5">1</span><span class="s1">)) / (</span><span class="s5">1 </span><span class="s1">+ x_**c_)</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">c_</span><span class="s2">, </span><span class="s1">d_: (c_ * d_ * (x_ ** (-c_ - </span><span class="s5">1.0</span><span class="s1">)) /</span>
                                   <span class="s1">((</span><span class="s5">1 </span><span class="s1">+ x_ ** (-c_)) ** (d_ + </span><span class="s5">1.0</span><span class="s1">))))</span>
        <span class="s2">if </span><span class="s1">output.ndim == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">output[()]</span>
        <span class="s2">return </span><span class="s1">output</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s1">output = _lazywhere(</span>
            <span class="s1">x == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">[x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d]</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">c_</span><span class="s2">, </span><span class="s1">d_: (np.log(c_) + np.log(d_) + sc.xlogy(c_*d_ - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x_)</span>
                                <span class="s1">- (d_+</span><span class="s5">1</span><span class="s1">) * sc.log1p(x_**(c_)))</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x_</span><span class="s2">, </span><span class="s1">c_</span><span class="s2">, </span><span class="s1">d_: (np.log(c_) + np.log(d_)</span>
                                   <span class="s1">+ sc.xlogy(-c_ - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x_)</span>
                                   <span class="s1">- sc.xlog1py(d_+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x_**(-c_))))</span>
        <span class="s2">if </span><span class="s1">output.ndim == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">output[()]</span>
        <span class="s2">return </span><span class="s1">output</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1 </span><span class="s1">+ x**(-c))**(-d)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">sc.log1p(x**(-c)) * (-d)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">np.log1p(- (</span><span class="s5">1 </span><span class="s1">+ x**(-c))**(-d))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">(q**(-</span><span class="s5">1.0</span><span class="s1">/d) - </span><span class="s5">1</span><span class="s1">)**(-</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s1">nc = np.arange(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">5</span><span class="s1">).reshape(</span><span class="s5">4</span><span class="s2">,</span><span class="s5">1</span><span class="s1">) / c</span>
        <span class="s0"># ek is the kth raw moment, e1 is the mean e2-e1**2 variance etc.</span>
        <span class="s1">e1</span><span class="s2">, </span><span class="s1">e2</span><span class="s2">, </span><span class="s1">e3</span><span class="s2">, </span><span class="s1">e4 = sc.beta(d + nc</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">- nc) * d</span>
        <span class="s1">mu = np.where(c &gt; </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">e1</span><span class="s2">, </span><span class="s1">np.nan)</span>
        <span class="s1">mu2_if_c = e2 - mu**</span><span class="s5">2</span>
        <span class="s1">mu2 = np.where(c &gt; </span><span class="s5">2.0</span><span class="s2">, </span><span class="s1">mu2_if_c</span><span class="s2">, </span><span class="s1">np.nan)</span>
        <span class="s1">g1 = _lazywhere(</span>
            <span class="s1">c &gt; </span><span class="s5">3.0</span><span class="s2">,</span>
            <span class="s1">(c</span><span class="s2">, </span><span class="s1">e1</span><span class="s2">, </span><span class="s1">e2</span><span class="s2">, </span><span class="s1">e3</span><span class="s2">, </span><span class="s1">mu2_if_c)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">c</span><span class="s2">, </span><span class="s1">e1</span><span class="s2">, </span><span class="s1">e2</span><span class="s2">, </span><span class="s1">e3</span><span class="s2">, </span><span class="s1">mu2_if_c: (e3 - </span><span class="s5">3</span><span class="s1">*e2*e1 + </span><span class="s5">2</span><span class="s1">*e1**</span><span class="s5">3</span><span class="s1">) / np.sqrt((mu2_if_c)**</span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">fillvalue=np.nan)</span>
        <span class="s1">g2 = _lazywhere(</span>
            <span class="s1">c &gt; </span><span class="s5">4.0</span><span class="s2">,</span>
            <span class="s1">(c</span><span class="s2">, </span><span class="s1">e1</span><span class="s2">, </span><span class="s1">e2</span><span class="s2">, </span><span class="s1">e3</span><span class="s2">, </span><span class="s1">e4</span><span class="s2">, </span><span class="s1">mu2_if_c)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">c</span><span class="s2">, </span><span class="s1">e1</span><span class="s2">, </span><span class="s1">e2</span><span class="s2">, </span><span class="s1">e3</span><span class="s2">, </span><span class="s1">e4</span><span class="s2">, </span><span class="s1">mu2_if_c: (</span>
                <span class="s1">((e4 - </span><span class="s5">4</span><span class="s1">*e3*e1 + </span><span class="s5">6</span><span class="s1">*e2*e1**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">3</span><span class="s1">*e1**</span><span class="s5">4</span><span class="s1">) / mu2_if_c**</span><span class="s5">2</span><span class="s1">) - </span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">fillvalue=np.nan)</span>
        <span class="s2">if </span><span class="s1">np.ndim(c) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">mu.item()</span><span class="s2">, </span><span class="s1">mu2.item()</span><span class="s2">, </span><span class="s1">g1.item()</span><span class="s2">, </span><span class="s1">g2.item()</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">def </span><span class="s1">__munp(n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
            <span class="s1">nc = </span><span class="s5">1. </span><span class="s1">* n / c</span>
            <span class="s2">return </span><span class="s1">d * sc.beta(</span><span class="s5">1.0 </span><span class="s1">- nc</span><span class="s2">, </span><span class="s1">d + nc)</span>
        <span class="s1">n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d = np.asarray(n)</span><span class="s2">, </span><span class="s1">np.asarray(c)</span><span class="s2">, </span><span class="s1">np.asarray(d)</span>
        <span class="s2">return </span><span class="s1">_lazywhere((c &gt; n) &amp; (n == n) &amp; (d == d)</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">n: __munp(n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d)</span><span class="s2">,</span>
                          <span class="s1">np.nan)</span>


<span class="s1">burr = burr_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'burr'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">burr12_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Burr (Type XII) continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    fisk : a special case of either `burr` or `burr12` with ``d=1`` 
    burr : Burr Type III distribution 
 
    Notes 
    ----- 
    The probability density function for `burr12` is: 
 
    .. math:: 
 
        f(x; c, d) = c d \frac{x^{c-1}} 
                              {(1 + x^c)^{d + 1}} 
 
    for :math:`x &gt;= 0` and :math:`c, d &gt; 0`. 
 
    `burr12` takes ``c`` and ``d`` as shape parameters for :math:`c` 
    and :math:`d`. 
 
    This is the PDF corresponding to the twelfth CDF given in Burr's list; 
    specifically, it is equation (20) in Burr's paper [1]_. 
 
    %(after_notes)s 
 
    The Burr type 12 distribution is also sometimes referred to as 
    the Singh-Maddala distribution from NIST [2]_. 
 
    References 
    ---------- 
    .. [1] Burr, I. W. &quot;Cumulative frequency functions&quot;, Annals of 
       Mathematical Statistics, 13(2), pp 215-232 (1942). 
 
    .. [2] https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/b12pdf.htm 
 
    .. [3] &quot;Burr distribution&quot;, 
       https://en.wikipedia.org/wiki/Burr_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">id = _ShapeInfo(</span><span class="s4">&quot;d&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ic</span><span class="s2">, </span><span class="s1">id]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s0"># burr12.pdf(x, c, d) = c * d * x**(c-1) * (1+x**(c))**(-d-1)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">np.log(c) + np.log(d) + sc.xlogy(c - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x) + sc.xlog1py(-d-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x**c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(self._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">sc.log1p(-(</span><span class="s5">1 </span><span class="s1">+ x**c)**(-d))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">sc.xlog1py(-d</span><span class="s2">, </span><span class="s1">x**c)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s0"># The following is an implementation of</span>
        <span class="s0">#   ((1 - q)**(-1.0/d) - 1)**(1.0/c)</span>
        <span class="s0"># that does a better job handling small values of q.</span>
        <span class="s2">return </span><span class="s1">sc.expm1(-</span><span class="s5">1</span><span class="s1">/d * sc.log1p(-q))**(</span><span class="s5">1</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s1">nc = </span><span class="s5">1. </span><span class="s1">* n / c</span>
        <span class="s2">return </span><span class="s1">d * sc.beta(</span><span class="s5">1.0 </span><span class="s1">+ nc</span><span class="s2">, </span><span class="s1">d - nc)</span>


<span class="s1">burr12 = burr12_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'burr12'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">fisk_gen(burr_gen):</span>
    <span class="s3">r&quot;&quot;&quot;A Fisk continuous random variable. 
 
    The Fisk distribution is also known as the log-logistic distribution. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    burr 
 
    Notes 
    ----- 
    The probability density function for `fisk` is: 
 
    .. math:: 
 
        f(x, c) = \frac{c x^{c-1}} 
                       {(1 + x^c)^2} 
 
    for :math:`x &gt;= 0` and :math:`c &gt; 0`. 
 
    Please note that the above expression can be transformed into the following 
    one, which is also commonly used: 
 
    .. math:: 
 
        f(x, c) = \frac{c x^{-c-1}} 
                       {(1 + x^{-c})^2} 
 
    `fisk` takes ``c`` as a shape parameter for :math:`c`. 
 
    `fisk` is a special case of `burr` or `burr12` with ``d=1``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># fisk.pdf(x, c) = c * x**(-c-1) * (1 + x**(-c))**(-2)</span>
        <span class="s2">return </span><span class="s1">burr._pdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._cdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._sf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># fisk.pdf(x, c) = c * x**(-c-1) * (1 + x**(-c))**(-2)</span>
        <span class="s2">return </span><span class="s1">burr._logpdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._logcdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._ppf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._munp(n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">burr._stats(c</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">- np.log(c)</span>


<span class="s1">fisk = fisk_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'fisk'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">cauchy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Cauchy continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `cauchy` is 
 
    .. math:: 
 
        f(x) = \frac{1}{\pi (1 + x^2)} 
 
    for a real number :math:`x`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># cauchy.pdf(x) = 1 / (pi * (1 + x**2))</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.pi/(</span><span class="s5">1.0</span><span class="s1">+x*x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">+ </span><span class="s5">1.0</span><span class="s1">/np.pi*np.arctan(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.tan(np.pi*q-np.pi/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">- </span><span class="s5">1.0</span><span class="s1">/np.pi*np.arctan(x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.tan(np.pi/</span><span class="s5">2.0</span><span class="s1">-np.pi*q)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">4</span><span class="s1">*np.pi)</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># Initialize ML guesses using quartiles instead of moments.</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s1">p25</span><span class="s2">, </span><span class="s1">p50</span><span class="s2">, </span><span class="s1">p75 = np.percentile(data</span><span class="s2">, </span><span class="s1">[</span><span class="s5">25</span><span class="s2">, </span><span class="s5">50</span><span class="s2">, </span><span class="s5">75</span><span class="s1">])</span>
        <span class="s2">return </span><span class="s1">p50</span><span class="s2">, </span><span class="s1">(p75 - p25)/</span><span class="s5">2</span>


<span class="s1">cauchy = cauchy_gen(name=</span><span class="s4">'cauchy'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">chi_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A chi continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `chi` is: 
 
    .. math:: 
 
        f(x, k) = \frac{1}{2^{k/2-1} \Gamma \left( k/2 \right)} 
                   x^{k-1} \exp \left( -x^2/2 \right) 
 
    for :math:`x &gt;= 0` and :math:`k &gt; 0` (degrees of freedom, denoted ``df`` 
    in the implementation). :math:`\Gamma` is the gamma function 
    (`scipy.special.gamma`). 
 
    Special cases of `chi` are: 
 
        - ``chi(1, loc, scale)`` is equivalent to `halfnorm` 
        - ``chi(2, 0, scale)`` is equivalent to `rayleigh` 
        - ``chi(3, 0, scale)`` is equivalent to `maxwell` 
 
    `chi` takes ``df`` as a shape parameter. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(chi2.rvs(df</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s0">#                   x**(df-1) * exp(-x**2/2)</span>
        <span class="s0"># chi.pdf(x, df) =  -------------------------</span>
        <span class="s0">#                   2**(df/2-1) * gamma(df/2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s1">l = np.log(</span><span class="s5">2</span><span class="s1">) - </span><span class="s5">.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">)*df - sc.gammaln(</span><span class="s5">.5</span><span class="s1">*df)</span>
        <span class="s2">return </span><span class="s1">l + sc.xlogy(df - </span><span class="s5">1.</span><span class="s2">, </span><span class="s1">x) - </span><span class="s5">.5</span><span class="s1">*x**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(</span><span class="s5">.5</span><span class="s1">*df</span><span class="s2">, </span><span class="s5">.5</span><span class="s1">*x**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(</span><span class="s5">.5</span><span class="s1">*df</span><span class="s2">, </span><span class="s5">.5</span><span class="s1">*x**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">*sc.gammaincinv(</span><span class="s5">.5</span><span class="s1">*df</span><span class="s2">, </span><span class="s1">q))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">*sc.gammainccinv(</span><span class="s5">.5</span><span class="s1">*df</span><span class="s2">, </span><span class="s1">q))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s1">mu = np.sqrt(</span><span class="s5">2</span><span class="s1">)*np.exp(sc.gammaln(df/</span><span class="s5">2.0</span><span class="s1">+</span><span class="s5">0.5</span><span class="s1">)-sc.gammaln(df/</span><span class="s5">2.0</span><span class="s1">))</span>
        <span class="s1">mu2 = df - mu*mu</span>
        <span class="s1">g1 = (</span><span class="s5">2</span><span class="s1">*mu**</span><span class="s5">3.0 </span><span class="s1">+ mu*(</span><span class="s5">1</span><span class="s1">-</span><span class="s5">2</span><span class="s1">*df))/np.asarray(np.power(mu2</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">))</span>
        <span class="s1">g2 = </span><span class="s5">2</span><span class="s1">*df*(</span><span class="s5">1.0</span><span class="s1">-df)-</span><span class="s5">6</span><span class="s1">*mu**</span><span class="s5">4 </span><span class="s1">+ </span><span class="s5">4</span><span class="s1">*mu**</span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">2</span><span class="s1">*df-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g2 /= np.asarray(mu2**</span><span class="s5">2.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">df):</span>

        <span class="s2">def </span><span class="s1">regular_formula(df):</span>
            <span class="s2">return </span><span class="s1">(sc.gammaln(</span><span class="s5">.5 </span><span class="s1">* df)</span>
                    <span class="s1">+ </span><span class="s5">0.5 </span><span class="s1">* (df - np.log(</span><span class="s5">2</span><span class="s1">) - (df - </span><span class="s5">1</span><span class="s1">) * sc.digamma(</span><span class="s5">0.5 </span><span class="s1">* df)))</span>

        <span class="s2">def </span><span class="s1">asymptotic_formula(df):</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">0.5 </span><span class="s1">+ np.log(np.pi)/</span><span class="s5">2 </span><span class="s1">- (df**-</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">6 </span><span class="s1">- (df**-</span><span class="s5">2</span><span class="s1">)/</span><span class="s5">6</span>
                    <span class="s1">- </span><span class="s5">4</span><span class="s1">/</span><span class="s5">45</span><span class="s1">*(df**-</span><span class="s5">3</span><span class="s1">) + (df**-</span><span class="s5">4</span><span class="s1">)/</span><span class="s5">15</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">_lazywhere(df &lt; </span><span class="s5">3e2</span><span class="s2">, </span><span class="s1">(df</span><span class="s2">, </span><span class="s1">)</span><span class="s2">, </span><span class="s1">regular_formula</span><span class="s2">,</span>
                          <span class="s1">f2=asymptotic_formula)</span>


<span class="s1">chi = chi_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'chi'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">chi2_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A chi-squared continuous random variable. 
 
    For the noncentral chi-square distribution, see `ncx2`. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    ncx2 
 
    Notes 
    ----- 
    The probability density function for `chi2` is: 
 
    .. math:: 
 
        f(x, k) = \frac{1}{2^{k/2} \Gamma \left( k/2 \right)} 
                   x^{k/2-1} \exp \left( -x/2 \right) 
 
    for :math:`x &gt; 0`  and :math:`k &gt; 0` (degrees of freedom, denoted ``df`` 
    in the implementation). 
 
    `chi2` takes ``df`` as a shape parameter. 
 
    The chi-squared distribution is a special case of the gamma 
    distribution, with gamma parameters ``a = df/2``, ``loc = 0`` and 
    ``scale = 2``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.chisquare(df</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s0"># chi2.pdf(x, df) = 1 / (2*gamma(df/2)) * (x/2)**(df/2-1) * exp(-x/2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.xlogy(df/</span><span class="s5">2.</span><span class="s1">-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x) - x/</span><span class="s5">2. </span><span class="s1">- sc.gammaln(df/</span><span class="s5">2.</span><span class="s1">) - (np.log(</span><span class="s5">2</span><span class="s1">)*df)/</span><span class="s5">2.</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.chdtr(df</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.chdtrc(df</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.chdtri(df</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">*sc.gammaincinv(df/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s1">mu = df</span>
        <span class="s1">mu2 = </span><span class="s5">2</span><span class="s1">*df</span>
        <span class="s1">g1 = </span><span class="s5">2</span><span class="s1">*np.sqrt(</span><span class="s5">2.0</span><span class="s1">/df)</span>
        <span class="s1">g2 = </span><span class="s5">12.0</span><span class="s1">/df</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s1">half_df = </span><span class="s5">0.5 </span><span class="s1">* df</span>

        <span class="s2">def </span><span class="s1">regular_formula(half_df):</span>
            <span class="s2">return </span><span class="s1">(half_df + np.log(</span><span class="s5">2</span><span class="s1">) + sc.gammaln(half_df) +</span>
                    <span class="s1">(</span><span class="s5">1 </span><span class="s1">- half_df) * sc.psi(half_df))</span>

        <span class="s2">def </span><span class="s1">asymptotic_formula(half_df):</span>
            <span class="s0"># plug in the above formula the following asymptotic</span>
            <span class="s0"># expansions:</span>
            <span class="s0"># ln(gamma(a)) ~ (a - 0.5) * ln(a) - a + 0.5 * ln(2 * pi) +</span>
            <span class="s0">#                 1/(12 * a) - 1/(360 * a**3)</span>
            <span class="s0"># psi(a) ~ ln(a) - 1/(2 * a) - 1/(3 * a**2) + 1/120 * a**4)</span>
            <span class="s1">c = np.log(</span><span class="s5">2</span><span class="s1">) + </span><span class="s5">0.5</span><span class="s1">*(</span><span class="s5">1 </span><span class="s1">+ np.log(</span><span class="s5">2</span><span class="s1">*np.pi))</span>
            <span class="s1">h = </span><span class="s5">0.5</span><span class="s1">/half_df</span>
            <span class="s2">return </span><span class="s1">(h*(-</span><span class="s5">2</span><span class="s1">/</span><span class="s5">3 </span><span class="s1">+ h*(-</span><span class="s5">1</span><span class="s1">/</span><span class="s5">3 </span><span class="s1">+ h*(-</span><span class="s5">4</span><span class="s1">/</span><span class="s5">45 </span><span class="s1">+ h/</span><span class="s5">7.5</span><span class="s1">))) +</span>
                    <span class="s5">0.5</span><span class="s1">*np.log(half_df) + c)</span>

        <span class="s2">return </span><span class="s1">_lazywhere(half_df &lt; </span><span class="s5">125</span><span class="s2">, </span><span class="s1">(half_df</span><span class="s2">, </span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s1">regular_formula</span><span class="s2">,</span>
                          <span class="s1">f2=asymptotic_formula)</span>


<span class="s1">chi2 = chi2_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'chi2'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">cosine_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A cosine continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The cosine distribution is an approximation to the normal distribution. 
    The probability density function for `cosine` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{2\pi} (1+\cos(x)) 
 
    for :math:`-\pi \le x \le \pi`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># cosine.pdf(x) = 1/(2*pi) * (1+cos(x))</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/</span><span class="s5">2</span><span class="s1">/np.pi*(</span><span class="s5">1</span><span class="s1">+np.cos(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">c = np.cos(x)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(c != -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">c: np.log1p(c) - np.log(</span><span class="s5">2</span><span class="s1">*np.pi)</span><span class="s2">,</span>
                          <span class="s1">fillvalue=-np.inf)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">scu._cosine_cdf(x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">scu._cosine_cdf(-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">scu._cosine_invcdf(p)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">-scu._cosine_invcdf(p)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">3.0</span><span class="s1">-</span><span class="s5">2.0</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6.0</span><span class="s1">*(np.pi**</span><span class="s5">4</span><span class="s1">-</span><span class="s5">90</span><span class="s1">)/(</span><span class="s5">5.0</span><span class="s1">*(np.pi*np.pi-</span><span class="s5">6</span><span class="s1">)**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">4</span><span class="s1">*np.pi)-</span><span class="s5">1.0</span>


<span class="s1">cosine = cosine_gen(a=-np.pi</span><span class="s2">, </span><span class="s1">b=np.pi</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'cosine'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">dgamma_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A double gamma continuous random variable. 
 
    The double gamma distribution is also known as the reflected gamma 
    distribution [1]_. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `dgamma` is: 
 
    .. math:: 
 
        f(x, a) = \frac{1}{2\Gamma(a)} |x|^{a-1} \exp(-|x|) 
 
    for a real number :math:`x` and :math:`a &gt; 0`. :math:`\Gamma` is the 
    gamma function (`scipy.special.gamma`). 
 
    `dgamma` takes ``a`` as a shape parameter for :math:`a`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Johnson, Kotz, and Balakrishnan, &quot;Continuous Univariate 
           Distributions, Volume 1&quot;, Second Edition, John Wiley and Sons 
           (1994). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">u = random_state.uniform(size=size)</span>
        <span class="s1">gm = gamma.rvs(a</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">gm * np.where(u &gt;= </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># dgamma.pdf(x, a) = 1 / (2*gamma(a)) * abs(x)**(a-1) * exp(-abs(x))</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*sc.gamma(a))*ax**(a-</span><span class="s5">1.0</span><span class="s1">) * np.exp(-ax)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s1">sc.xlogy(a - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">ax) - ax - np.log(</span><span class="s5">2</span><span class="s1">) - sc.gammaln(a)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt; </span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s5">0.5 </span><span class="s1">+ </span><span class="s5">0.5</span><span class="s1">*sc.gammainc(a</span><span class="s2">, </span><span class="s1">x)</span><span class="s2">,</span>
                        <span class="s5">0.5</span><span class="s1">*sc.gammaincc(a</span><span class="s2">, </span><span class="s1">-x))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt; </span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s5">0.5</span><span class="s1">*sc.gammaincc(a</span><span class="s2">, </span><span class="s1">x)</span><span class="s2">,</span>
                        <span class="s5">0.5 </span><span class="s1">+ </span><span class="s5">0.5</span><span class="s1">*sc.gammainc(a</span><span class="s2">, </span><span class="s1">-x))</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">stats.gamma._entropy(a) - np.log(</span><span class="s5">0.5</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt; </span><span class="s5">0.5</span><span class="s2">,</span>
                        <span class="s1">sc.gammaincinv(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*q - </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">-sc.gammainccinv(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*q))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt; </span><span class="s5">0.5</span><span class="s2">,</span>
                        <span class="s1">-sc.gammaincinv(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*q - </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">sc.gammainccinv(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*q))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">mu2 = a*(a+</span><span class="s5">1.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">(a+</span><span class="s5">2.0</span><span class="s1">)*(a+</span><span class="s5">3.0</span><span class="s1">)/mu2-</span><span class="s5">3.0</span>


<span class="s1">dgamma = dgamma_gen(name=</span><span class="s4">'dgamma'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">dweibull_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A double Weibull continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `dweibull` is given by 
 
    .. math:: 
 
        f(x, c) = c / 2 |x|^{c-1} \exp(-|x|^c) 
 
    for a real number :math:`x` and :math:`c &gt; 0`. 
 
    `dweibull` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">u = random_state.uniform(size=size)</span>
        <span class="s1">w = weibull_min.rvs(c</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">w * (np.where(u &gt;= </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># dweibull.pdf(x, c) = c / 2 * abs(x)**(c-1) * exp(-abs(x)**c)</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s1">Px = c / </span><span class="s5">2.0 </span><span class="s1">* ax**(c-</span><span class="s5">1.0</span><span class="s1">) * np.exp(-ax**c)</span>
        <span class="s2">return </span><span class="s1">Px</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s1">np.log(c) - np.log(</span><span class="s5">2.0</span><span class="s1">) + sc.xlogy(c - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">ax) - ax**c</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">Cx1 = </span><span class="s5">0.5 </span><span class="s1">* np.exp(-abs(x)**c)</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">- Cx1</span><span class="s2">, </span><span class="s1">Cx1)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">fac = </span><span class="s5">2. </span><span class="s1">* np.where(q &lt;= </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">- q)</span>
        <span class="s1">fac = np.power(-np.log(fac)</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ c)</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt; </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">fac</span><span class="s2">, </span><span class="s1">-fac)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">half_weibull_min_sf = </span><span class="s5">0.5 </span><span class="s1">* stats.weibull_min._sf(np.abs(x)</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">half_weibull_min_sf</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">- half_weibull_min_sf)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">double_q = </span><span class="s5">2. </span><span class="s1">* np.where(q &lt;= </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">- q)</span>
        <span class="s1">weibull_min_isf = stats.weibull_min._isf(double_q</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt; </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">-weibull_min_isf</span><span class="s2">, </span><span class="s1">weibull_min_isf)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1 </span><span class="s1">- (n % </span><span class="s5">2</span><span class="s1">)) * sc.gamma(</span><span class="s5">1.0 </span><span class="s1">+ </span><span class="s5">1.0 </span><span class="s1">* n / c)</span>

    <span class="s0"># since we know that all odd moments are zeros, return them at once.</span>
    <span class="s0"># returning Nones from _stats makes the public stats call _munp</span>
    <span class="s0"># so overall we're saving one or two gamma function evaluations here.</span>
    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, None, </span><span class="s5">0</span><span class="s2">, None</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">h = stats.weibull_min._entropy(c) - np.log(</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">h</span>


<span class="s1">dweibull = dweibull_gen(name=</span><span class="s4">'dweibull'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">expon_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An exponential continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `expon` is: 
 
    .. math:: 
 
        f(x) = \exp(-x) 
 
    for :math:`x \ge 0`. 
 
    %(after_notes)s 
 
    A common parameterization for `expon` is in terms of the rate parameter 
    ``lambda``, such that ``pdf = lambda * exp(-lambda * x)``. This 
    parameterization corresponds to using ``scale = 1 / lambda``. 
 
    The exponential distribution is a special case of the gamma 
    distributions, with gamma shape parameter ``a = 1``. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.standard_exponential(size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># expon.pdf(x) = exp(-x)</span>
        <span class="s2">return </span><span class="s1">np.exp(-x)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-x</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">-sc.log1p(-q)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(-x)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-x</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">-np.log(q)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">2.0</span><span class="s2">, </span><span class="s5">6.0</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">1.0</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@replace_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">When `method='MLE'`, 
        this function uses explicit formulas for the maximum likelihood 
        estimation of the exponential distribution parameters, so the 
        `optimizer`, `loc` and `scale` keyword arguments are 
        ignored.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">len(args) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Too many arguments.&quot;</span><span class="s1">)</span>

        <span class="s1">floc = kwds.pop(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">fscale = kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">_remove_optimizer_parameters(kwds)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                             <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

        <span class="s1">data = np.asarray(data)</span>

        <span class="s2">if not </span><span class="s1">np.isfinite(data).all():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

        <span class="s1">data_min = data.min()</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># ML estimate of the location is the minimum of the data.</span>
            <span class="s1">loc = data_min</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">loc = floc</span>
            <span class="s2">if </span><span class="s1">data_min &lt; loc:</span>
                <span class="s0"># There are values that are less than the specified loc.</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;expon&quot;</span><span class="s2">, </span><span class="s1">lower=floc</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># ML estimate of the scale is the shifted mean.</span>
            <span class="s1">scale = data.mean() - loc</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">scale = fscale</span>

        <span class="s0"># We expect the return values to be floating point, so ensure it</span>
        <span class="s0"># by explicitly converting to float.</span>
        <span class="s2">return </span><span class="s1">float(loc)</span><span class="s2">, </span><span class="s1">float(scale)</span>


<span class="s1">expon = expon_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'expon'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">exponnorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An exponentially modified Normal continuous random variable. 
 
    Also known as the exponentially modified Gaussian distribution [1]_. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `exponnorm` is: 
 
    .. math:: 
 
        f(x, K) = \frac{1}{2K} \exp\left(\frac{1}{2 K^2} - x / K \right) 
                  \text{erfc}\left(-\frac{x - 1/K}{\sqrt{2}}\right) 
 
    where :math:`x` is a real number and :math:`K &gt; 0`. 
 
    It can be thought of as the sum of a standard normal random variable 
    and an independent exponentially distributed random variable with rate 
    ``1/K``. 
 
    %(after_notes)s 
 
    An alternative parameterization of this distribution (for example, in 
    the Wikpedia article [1]_) involves three parameters, :math:`\mu`, 
    :math:`\lambda` and :math:`\sigma`. 
 
    In the present parameterization this corresponds to having ``loc`` and 
    ``scale`` equal to :math:`\mu` and :math:`\sigma`, respectively, and 
    shape parameter :math:`K = 1/(\sigma\lambda)`. 
 
    .. versionadded:: 0.16.0 
 
    References 
    ---------- 
    .. [1] Exponentially modified Gaussian distribution, Wikipedia, 
           https://en.wikipedia.org/wiki/Exponentially_modified_Gaussian_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;K&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">K</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">expval = random_state.standard_exponential(size) * K</span>
        <span class="s1">gval = random_state.standard_normal(size)</span>
        <span class="s2">return </span><span class="s1">expval + gval</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">K):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">K))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">K):</span>
        <span class="s1">invK = </span><span class="s5">1.0 </span><span class="s1">/ K</span>
        <span class="s1">exparg = invK * (</span><span class="s5">0.5 </span><span class="s1">* invK - x)</span>
        <span class="s2">return </span><span class="s1">exparg + _norm_logcdf(x - invK) - np.log(K)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">K):</span>
        <span class="s1">invK = </span><span class="s5">1.0 </span><span class="s1">/ K</span>
        <span class="s1">expval = invK * (</span><span class="s5">0.5 </span><span class="s1">* invK - x)</span>
        <span class="s1">logprod = expval + _norm_logcdf(x - invK)</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(x) - np.exp(logprod)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">K):</span>
        <span class="s1">invK = </span><span class="s5">1.0 </span><span class="s1">/ K</span>
        <span class="s1">expval = invK * (</span><span class="s5">0.5 </span><span class="s1">* invK - x)</span>
        <span class="s1">logprod = expval + _norm_logcdf(x - invK)</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(-x) + np.exp(logprod)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">K):</span>
        <span class="s1">K2 = K * K</span>
        <span class="s1">opK2 = </span><span class="s5">1.0 </span><span class="s1">+ K2</span>
        <span class="s1">skw = </span><span class="s5">2 </span><span class="s1">* K**</span><span class="s5">3 </span><span class="s1">* opK2**(-</span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">krt = </span><span class="s5">6.0 </span><span class="s1">* K2 * K2 * opK2**(-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">K</span><span class="s2">, </span><span class="s1">opK2</span><span class="s2">, </span><span class="s1">skw</span><span class="s2">, </span><span class="s1">krt</span>


<span class="s1">exponnorm = exponnorm_gen(name=</span><span class="s4">'exponnorm'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_pow1pm1(x</span><span class="s2">, </span><span class="s1">y):</span>
    <span class="s3">&quot;&quot;&quot; 
    Compute (1 + x)**y - 1. 
 
    Uses expm1 and xlog1py to avoid loss of precision when 
    (1 + x)**y is close to 1. 
 
    Note that the inverse of this function with respect to x is 
    ``_pow1pm1(x, 1/y)``.  That is, if 
 
        t = _pow1pm1(x, y) 
 
    then 
 
        x = _pow1pm1(t, 1/y) 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">np.expm1(sc.xlog1py(y</span><span class="s2">, </span><span class="s1">x))</span>


<span class="s2">class </span><span class="s1">exponweib_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An exponentiated Weibull continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    weibull_min, numpy.random.Generator.weibull 
 
    Notes 
    ----- 
    The probability density function for `exponweib` is: 
 
    .. math:: 
 
        f(x, a, c) = a c [1-\exp(-x^c)]^{a-1} \exp(-x^c) x^{c-1} 
 
    and its cumulative distribution function is: 
 
    .. math:: 
 
        F(x, a, c) = [1-\exp(-x^c)]^a 
 
    for :math:`x &gt; 0`, :math:`a &gt; 0`, :math:`c &gt; 0`. 
 
    `exponweib` takes :math:`a` and :math:`c` as shape parameters: 
 
    * :math:`a` is the exponentiation parameter, 
      with the special case :math:`a=1` corresponding to the 
      (non-exponentiated) Weibull distribution `weibull_min`. 
    * :math:`c` is the shape parameter of the non-exponentiated Weibull law. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    https://en.wikipedia.org/wiki/Exponentiated_Weibull_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ic]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># exponweib.pdf(x, a, c) =</span>
        <span class="s0">#     a * c * (1-exp(-x**c))**(a-1) * exp(-x**c)*x**(c-1)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">negxc = -x**c</span>
        <span class="s1">exm1c = -sc.expm1(negxc)</span>
        <span class="s1">logp = (np.log(a) + np.log(c) + sc.xlogy(a - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">exm1c) +</span>
                <span class="s1">negxc + sc.xlogy(c - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x))</span>
        <span class="s2">return </span><span class="s1">logp</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">exm1c = -sc.expm1(-x**c)</span>
        <span class="s2">return </span><span class="s1">exm1c**a</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(-sc.log1p(-q**(</span><span class="s5">1.0</span><span class="s1">/a)))**np.asarray(</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-_pow1pm1(-np.exp(-x**c)</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(-np.log(-_pow1pm1(-p</span><span class="s2">, </span><span class="s5">1</span><span class="s1">/a)))**(</span><span class="s5">1</span><span class="s1">/c)</span>


<span class="s1">exponweib = exponweib_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'exponweib'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">exponpow_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An exponential power continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `exponpow` is: 
 
    .. math:: 
 
        f(x, b) = b x^{b-1} \exp(1 + x^b - \exp(x^b)) 
 
    for :math:`x \ge 0`, :math:`b &gt; 0`.  Note that this is a different 
    distribution from the exponential power distribution that is also known 
    under the names &quot;generalized normal&quot; or &quot;generalized Gaussian&quot;. 
 
    `exponpow` takes ``b`` as a shape parameter for :math:`b`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Exponentialpower.pdf 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># exponpow.pdf(x, b) = b * x**(b-1) * exp(1 + x**b - exp(x**b))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">xb = x**b</span>
        <span class="s1">f = </span><span class="s5">1 </span><span class="s1">+ np.log(b) + sc.xlogy(b - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x) + xb - np.exp(xb)</span>
        <span class="s2">return </span><span class="s1">f</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-sc.expm1(x**b))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.exp(-sc.expm1(x**b))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(sc.log1p(-np.log(x)))**(</span><span class="s5">1.</span><span class="s1">/b)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">pow(sc.log1p(-sc.log1p(-q))</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/b)</span>


<span class="s1">exponpow = exponpow_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'exponpow'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">fatiguelife_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A fatigue-life (Birnbaum-Saunders) continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `fatiguelife` is: 
 
    .. math:: 
 
        f(x, c) = \frac{x+1}{2c\sqrt{2\pi x^3}} \exp(-\frac{(x-1)^2}{2x c^2}) 
 
    for :math:`x &gt;= 0` and :math:`c &gt; 0`. 
 
    `fatiguelife` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Birnbaum-Saunders distribution&quot;, 
           https://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">z = random_state.standard_normal(size)</span>
        <span class="s1">x = </span><span class="s5">0.5</span><span class="s1">*c*z</span>
        <span class="s1">x2 = x*x</span>
        <span class="s1">t = </span><span class="s5">1.0 </span><span class="s1">+ </span><span class="s5">2</span><span class="s1">*x2 + </span><span class="s5">2</span><span class="s1">*x*np.sqrt(</span><span class="s5">1 </span><span class="s1">+ x2)</span>
        <span class="s2">return </span><span class="s1">t</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># fatiguelife.pdf(x, c) =</span>
        <span class="s0">#     (x+1) / (2*c*sqrt(2*pi*x**3)) * exp(-(x-1)**2/(2*x*c**2))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(np.log(x+</span><span class="s5">1</span><span class="s1">) - (x-</span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">/ (</span><span class="s5">2.0</span><span class="s1">*x*c**</span><span class="s5">2</span><span class="s1">) - np.log(</span><span class="s5">2</span><span class="s1">*c) -</span>
                <span class="s5">0.5</span><span class="s1">*(np.log(</span><span class="s5">2</span><span class="s1">*np.pi) + </span><span class="s5">3</span><span class="s1">*np.log(x)))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(</span><span class="s5">1.0 </span><span class="s1">/ c * (np.sqrt(x) - </span><span class="s5">1.0</span><span class="s1">/np.sqrt(x)))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">tmp = c * _norm_ppf(q)</span>
        <span class="s2">return </span><span class="s5">0.25 </span><span class="s1">* (tmp + np.sqrt(tmp**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">4</span><span class="s1">))**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(</span><span class="s5">1.0 </span><span class="s1">/ c * (np.sqrt(x) - </span><span class="s5">1.0</span><span class="s1">/np.sqrt(x)))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">tmp = -c * _norm_ppf(q)</span>
        <span class="s2">return </span><span class="s5">0.25 </span><span class="s1">* (tmp + np.sqrt(tmp**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">4</span><span class="s1">))**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># NB: the formula for kurtosis in wikipedia seems to have an error:</span>
        <span class="s0"># it's 40, not 41. At least it disagrees with the one from Wolfram</span>
        <span class="s0"># Alpha.  And the latter one, below, passes the tests, while the wiki</span>
        <span class="s0"># one doesn't So far I didn't have the guts to actually check the</span>
        <span class="s0"># coefficients from the expressions for the raw moments.</span>
        <span class="s1">c2 = c*c</span>
        <span class="s1">mu = c2 / </span><span class="s5">2.0 </span><span class="s1">+ </span><span class="s5">1.0</span>
        <span class="s1">den = </span><span class="s5">5.0 </span><span class="s1">* c2 + </span><span class="s5">4.0</span>
        <span class="s1">mu2 = c2*den / </span><span class="s5">4.0</span>
        <span class="s1">g1 = </span><span class="s5">4 </span><span class="s1">* c * (</span><span class="s5">11</span><span class="s1">*c2 + </span><span class="s5">6.0</span><span class="s1">) / np.power(den</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">g2 = </span><span class="s5">6 </span><span class="s1">* c2 * (</span><span class="s5">93</span><span class="s1">*c2 + </span><span class="s5">40.0</span><span class="s1">) / den**</span><span class="s5">2.0</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">fatiguelife = fatiguelife_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'fatiguelife'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">foldcauchy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A folded Cauchy continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `foldcauchy` is: 
 
    .. math:: 
 
        f(x, c) = \frac{1}{\pi (1+(x-c)^2)} + \frac{1}{\pi (1+(x+c)^2)} 
 
    for :math:`x \ge 0` and :math:`c \ge 0`. 
 
    `foldcauchy` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">c &gt;= </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">abs(cauchy.rvs(loc=c</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">,</span>
                              <span class="s1">random_state=random_state))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># foldcauchy.pdf(x, c) = 1/(pi*(1+(x-c)**2)) + 1/(pi*(1+(x+c)**2))</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.pi*(</span><span class="s5">1.0</span><span class="s1">/(</span><span class="s5">1</span><span class="s1">+(x-c)**</span><span class="s5">2</span><span class="s1">) + </span><span class="s5">1.0</span><span class="s1">/(</span><span class="s5">1</span><span class="s1">+(x+c)**</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.pi*(np.arctan(x-c) + np.arctan(x+c))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># 1 - CDF(x, c) = 1 - (atan(x - c) + atan(x + c))/pi</span>
        <span class="s0">#               = ((pi/2 - atan(x - c)) + (pi/2 - atan(x + c)))/pi</span>
        <span class="s0">#               = (acot(x - c) + acot(x + c))/pi</span>
        <span class="s0">#               = (atan2(1, x - c) + atan2(1, x + c))/pi</span>
        <span class="s2">return </span><span class="s1">(np.arctan2(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x - c) + np.arctan2(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x + c))/np.pi</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>


<span class="s1">foldcauchy = foldcauchy_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'foldcauchy'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">f_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An F continuous random variable. 
 
    For the noncentral F distribution, see `ncf`. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    ncf 
 
    Notes 
    ----- 
    The probability density function for `f` is: 
 
    .. math:: 
 
        f(x, df_1, df_2) = \frac{df_2^{df_2/2} df_1^{df_1/2} x^{df_1 / 2-1}} 
                                {(df_2+df_1 x)^{(df_1+df_2)/2} 
                                 B(df_1/2, df_2/2)} 
 
    for :math:`x &gt; 0` and parameters :math:`df_1, df_2 &gt; 0` . 
 
    `f` takes ``dfn`` and ``dfd`` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">idfn = _ShapeInfo(</span><span class="s4">&quot;dfn&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">idfd = _ShapeInfo(</span><span class="s4">&quot;dfd&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[idfn</span><span class="s2">, </span><span class="s1">idfd]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.f(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s0">#                      df2**(df2/2) * df1**(df1/2) * x**(df1/2-1)</span>
        <span class="s0"># F.pdf(x, df1, df2) = --------------------------------------------</span>
        <span class="s0">#                      (df2+df1*x)**((df1+df2)/2) * B(df1/2, df2/2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s1">n = </span><span class="s5">1.0 </span><span class="s1">* dfn</span>
        <span class="s1">m = </span><span class="s5">1.0 </span><span class="s1">* dfd</span>
        <span class="s1">lPx = (m/</span><span class="s5">2 </span><span class="s1">* np.log(m) + n/</span><span class="s5">2 </span><span class="s1">* np.log(n) + sc.xlogy(n/</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x)</span>
               <span class="s1">- (((n+m)/</span><span class="s5">2</span><span class="s1">) * np.log(m + n*x) + sc.betaln(n/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">m/</span><span class="s5">2</span><span class="s1">)))</span>
        <span class="s2">return </span><span class="s1">lPx</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s2">return </span><span class="s1">sc.fdtr(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s2">return </span><span class="s1">sc.fdtrc(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s2">return </span><span class="s1">sc.fdtri(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s1">v1</span><span class="s2">, </span><span class="s1">v2 = </span><span class="s5">1. </span><span class="s1">* dfn</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">* dfd</span>
        <span class="s1">v2_2</span><span class="s2">, </span><span class="s1">v2_4</span><span class="s2">, </span><span class="s1">v2_6</span><span class="s2">, </span><span class="s1">v2_8 = v2 - </span><span class="s5">2.</span><span class="s2">, </span><span class="s1">v2 - </span><span class="s5">4.</span><span class="s2">, </span><span class="s1">v2 - </span><span class="s5">6.</span><span class="s2">, </span><span class="s1">v2 - </span><span class="s5">8.</span>

        <span class="s1">mu = _lazywhere(</span>
            <span class="s1">v2 &gt; </span><span class="s5">2</span><span class="s2">, </span><span class="s1">(v2</span><span class="s2">, </span><span class="s1">v2_2)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">v2</span><span class="s2">, </span><span class="s1">v2_2: v2 / v2_2</span><span class="s2">,</span>
            <span class="s1">np.inf)</span>

        <span class="s1">mu2 = _lazywhere(</span>
            <span class="s1">v2 &gt; </span><span class="s5">4</span><span class="s2">, </span><span class="s1">(v1</span><span class="s2">, </span><span class="s1">v2</span><span class="s2">, </span><span class="s1">v2_2</span><span class="s2">, </span><span class="s1">v2_4)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">v1</span><span class="s2">, </span><span class="s1">v2</span><span class="s2">, </span><span class="s1">v2_2</span><span class="s2">, </span><span class="s1">v2_4:</span>
            <span class="s5">2 </span><span class="s1">* v2 * v2 * (v1 + v2_2) / (v1 * v2_2**</span><span class="s5">2 </span><span class="s1">* v2_4)</span><span class="s2">,</span>
            <span class="s1">np.inf)</span>

        <span class="s1">g1 = _lazywhere(</span>
            <span class="s1">v2 &gt; </span><span class="s5">6</span><span class="s2">, </span><span class="s1">(v1</span><span class="s2">, </span><span class="s1">v2_2</span><span class="s2">, </span><span class="s1">v2_4</span><span class="s2">, </span><span class="s1">v2_6)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">v1</span><span class="s2">, </span><span class="s1">v2_2</span><span class="s2">, </span><span class="s1">v2_4</span><span class="s2">, </span><span class="s1">v2_6:</span>
            <span class="s1">(</span><span class="s5">2 </span><span class="s1">* v1 + v2_2) / v2_6 * np.sqrt(v2_4 / (v1 * (v1 + v2_2)))</span><span class="s2">,</span>
            <span class="s1">np.nan)</span>
        <span class="s1">g1 *= np.sqrt(</span><span class="s5">8.</span><span class="s1">)</span>

        <span class="s1">g2 = _lazywhere(</span>
            <span class="s1">v2 &gt; </span><span class="s5">8</span><span class="s2">, </span><span class="s1">(g1</span><span class="s2">, </span><span class="s1">v2_6</span><span class="s2">, </span><span class="s1">v2_8)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">v2_6</span><span class="s2">, </span><span class="s1">v2_8: (</span><span class="s5">8 </span><span class="s1">+ g1 * g1 * v2_6) / v2_8</span><span class="s2">,</span>
            <span class="s1">np.nan)</span>
        <span class="s1">g2 *= </span><span class="s5">3. </span><span class="s1">/ </span><span class="s5">2.</span>

        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd):</span>
        <span class="s0"># the formula found in literature is incorrect. This one yields the</span>
        <span class="s0"># same result as numerical integration using the generic entropy</span>
        <span class="s0"># definition. This is also tested in tests/test_conntinous_basic</span>
        <span class="s1">half_dfn = </span><span class="s5">0.5 </span><span class="s1">* dfn</span>
        <span class="s1">half_dfd = </span><span class="s5">0.5 </span><span class="s1">* dfd</span>
        <span class="s1">half_sum = </span><span class="s5">0.5 </span><span class="s1">* (dfn + dfd)</span>

        <span class="s2">return </span><span class="s1">(np.log(dfd) - np.log(dfn) + sc.betaln(half_dfn</span><span class="s2">, </span><span class="s1">half_dfd) +</span>
                <span class="s1">(</span><span class="s5">1 </span><span class="s1">- half_dfn) * sc.psi(half_dfn) - (</span><span class="s5">1 </span><span class="s1">+ half_dfd) *</span>
                <span class="s1">sc.psi(half_dfd) + half_sum * sc.psi(half_sum))</span>


<span class="s1">f = f_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'f'</span><span class="s1">)</span>


<span class="s0">## Folded Normal</span>
<span class="s0">##   abs(Z) where (Z is normal with mu=L and std=S so that c=abs(L)/S)</span>
<span class="s0">##</span>
<span class="s0">##  note: regress docs have scale parameter correct, but first parameter</span>
<span class="s0">##    he gives is a shape parameter A = c * scale</span>

<span class="s0">##  Half-normal is folded normal with shape-parameter c=0.</span>

<span class="s2">class </span><span class="s1">foldnorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A folded normal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `foldnorm` is: 
 
    .. math:: 
 
        f(x, c) = \sqrt{2/\pi} cosh(c x) \exp(-\frac{x^2+c^2}{2}) 
 
    for :math:`x \ge 0` and :math:`c \ge 0`. 
 
    `foldnorm` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">c &gt;= </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">abs(random_state.standard_normal(size) + c)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># foldnormal.pdf(x, c) = sqrt(2/pi) * cosh(c*x) * exp(-(x**2+c**2)/2)</span>
        <span class="s2">return </span><span class="s1">_norm_pdf(x + c) + _norm_pdf(x-c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">sqrt_two = np.sqrt(</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* (sc.erf((x - c)/sqrt_two) + sc.erf((x + c)/sqrt_two))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(x - c) + _norm_sf(x + c)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># Regina C. Elandt, Technometrics 3, 551 (1961)</span>
        <span class="s0"># https://www.jstor.org/stable/1266561</span>
        <span class="s0">#</span>
        <span class="s1">c2 = c*c</span>
        <span class="s1">expfac = np.exp(-</span><span class="s5">0.5</span><span class="s1">*c2) / np.sqrt(</span><span class="s5">2.</span><span class="s1">*np.pi)</span>

        <span class="s1">mu = </span><span class="s5">2.</span><span class="s1">*expfac + c * sc.erf(c/np.sqrt(</span><span class="s5">2</span><span class="s1">))</span>
        <span class="s1">mu2 = c2 + </span><span class="s5">1 </span><span class="s1">- mu*mu</span>

        <span class="s1">g1 = </span><span class="s5">2. </span><span class="s1">* (mu*mu*mu - c2*mu - expfac)</span>
        <span class="s1">g1 /= np.power(mu2</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>

        <span class="s1">g2 = c2 * (c2 + </span><span class="s5">6.</span><span class="s1">) + </span><span class="s5">3 </span><span class="s1">+ </span><span class="s5">8.</span><span class="s1">*expfac*mu</span>
        <span class="s1">g2 += (</span><span class="s5">2. </span><span class="s1">* (c2 - </span><span class="s5">3.</span><span class="s1">) - </span><span class="s5">3. </span><span class="s1">* mu**</span><span class="s5">2</span><span class="s1">) * mu**</span><span class="s5">2</span>
        <span class="s1">g2 = g2 / mu2**</span><span class="s5">2.0 </span><span class="s1">- </span><span class="s5">3.</span>

        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">foldnorm = foldnorm_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'foldnorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">weibull_min_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Weibull minimum continuous random variable. 
 
    The Weibull Minimum Extreme Value distribution, from extreme value theory 
    (Fisher-Gnedenko theorem), is also often simply called the Weibull 
    distribution. It arises as the limiting distribution of the rescaled 
    minimum of iid random variables. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    weibull_max, numpy.random.Generator.weibull, exponweib 
 
    Notes 
    ----- 
    The probability density function for `weibull_min` is: 
 
    .. math:: 
 
        f(x, c) = c x^{c-1} \exp(-x^c) 
 
    for :math:`x &gt; 0`, :math:`c &gt; 0`. 
 
    `weibull_min` takes ``c`` as a shape parameter for :math:`c`. 
    (named :math:`k` in Wikipedia article and :math:`a` in 
    ``numpy.random.weibull``).  Special shape values are :math:`c=1` and 
    :math:`c=2` where Weibull distribution reduces to the `expon` and 
    `rayleigh` distributions respectively. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    https://en.wikipedia.org/wiki/Weibull_distribution 
 
    https://en.wikipedia.org/wiki/Fisher-Tippett-Gnedenko_theorem 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># weibull_min.pdf(x, c) = c * x**(c-1) * exp(-x**c)</span>
        <span class="s2">return </span><span class="s1">c*pow(x</span><span class="s2">, </span><span class="s1">c-</span><span class="s5">1</span><span class="s1">)*np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(c) + sc.xlogy(c - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x) - pow(x</span><span class="s2">, </span><span class="s1">c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-pow(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">pow(-sc.log1p(-q)</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-pow(x</span><span class="s2">, </span><span class="s1">c)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(-np.log(q))**(</span><span class="s5">1</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.gamma(</span><span class="s5">1.0</span><span class="s1">+n*</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-_EULER / c - np.log(c) + _EULER + </span><span class="s5">1</span>

    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">If ``method='mm'``, parameters fixed by the user are respected, and the 
        remaining parameters are used to match distribution and sample moments 
        where possible. For example, if the user fixes the location with 
        ``floc``, the parameters will only match the distribution skewness and 
        variance to the sample skewness and variance; no attempt will be made 
        to match the means or minimize a norm of the errors. 
        </span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>

        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s2">if </span><span class="s1">data.num_censored() == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">data = data._uncensor()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># this extracts fixed shape, location, and scale however they</span>
        <span class="s0"># are specified, and also leaves them in `kwds`</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">fc</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                             <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">method = kwds.get(</span><span class="s4">&quot;method&quot;</span><span class="s2">, </span><span class="s4">&quot;mle&quot;</span><span class="s1">).lower()</span>

        <span class="s0"># See https://en.wikipedia.org/wiki/Weibull_distribution#Moments for</span>
        <span class="s0"># moment formulas.</span>
        <span class="s2">def </span><span class="s1">skew(c):</span>
            <span class="s1">gamma1 = sc.gamma(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">1</span><span class="s1">/c)</span>
            <span class="s1">gamma2 = sc.gamma(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">2</span><span class="s1">/c)</span>
            <span class="s1">gamma3 = sc.gamma(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">3</span><span class="s1">/c)</span>
            <span class="s1">num = </span><span class="s5">2 </span><span class="s1">* gamma1**</span><span class="s5">3 </span><span class="s1">- </span><span class="s5">3</span><span class="s1">*gamma1*gamma2 + gamma3</span>
            <span class="s1">den = (gamma2 - gamma1**</span><span class="s5">2</span><span class="s1">)**(</span><span class="s5">3</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">num/den</span>

        <span class="s0"># For c in [1e2, 3e4], population skewness appears to approach</span>
        <span class="s0"># asymptote near -1.139, but past c &gt; 3e4, skewness begins to vary</span>
        <span class="s0"># wildly, and MoM won't provide a good guess. Get out early.</span>
        <span class="s1">s = stats.skew(data)</span>
        <span class="s1">max_c = </span><span class="s5">1e4</span>
        <span class="s1">s_min = skew(max_c)</span>
        <span class="s2">if </span><span class="s1">s &lt; s_min </span><span class="s2">and </span><span class="s1">method != </span><span class="s4">&quot;mm&quot; </span><span class="s2">and </span><span class="s1">fc </span><span class="s2">is None and not </span><span class="s1">args:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># If method is method of moments, we don't need the user's guesses.</span>
        <span class="s0"># Otherwise, extract the guesses from args and kwds.</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;mm&quot;</span><span class="s1">:</span>
            <span class="s1">c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = </span><span class="s2">None, None, None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">c = args[</span><span class="s5">0</span><span class="s1">] </span><span class="s2">if </span><span class="s1">len(args) </span><span class="s2">else None</span>
            <span class="s1">loc = kwds.pop(</span><span class="s4">'loc'</span><span class="s2">, None</span><span class="s1">)</span>
            <span class="s1">scale = kwds.pop(</span><span class="s4">'scale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">fc </span><span class="s2">is None and </span><span class="s1">c </span><span class="s2">is None</span><span class="s1">:  </span><span class="s0"># not fixed and no guess: use MoM</span>
            <span class="s0"># Solve for c that matches sample distribution skewness to sample</span>
            <span class="s0"># skewness.</span>
            <span class="s0"># we start having numerical issues with `weibull_min` with</span>
            <span class="s0"># parameters outside this range - and not just in this method.</span>
            <span class="s0"># We could probably improve the situation by doing everything</span>
            <span class="s0"># in the log space, but that is for another time.</span>
            <span class="s1">c = root_scalar(</span><span class="s2">lambda </span><span class="s1">c: skew(c) - s</span><span class="s2">, </span><span class="s1">bracket=[</span><span class="s5">0.02</span><span class="s2">, </span><span class="s1">max_c]</span><span class="s2">,</span>
                            <span class="s1">method=</span><span class="s4">'bisect'</span><span class="s1">).root</span>
        <span class="s2">elif </span><span class="s1">fc </span><span class="s2">is not None</span><span class="s1">:  </span><span class="s0"># fixed: use it</span>
            <span class="s1">c = fc</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None and </span><span class="s1">scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">v = np.var(data)</span>
            <span class="s1">scale = np.sqrt(v / (sc.gamma(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">2</span><span class="s1">/c) - sc.gamma(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">1</span><span class="s1">/c)**</span><span class="s5">2</span><span class="s1">))</span>
        <span class="s2">elif </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">scale = fscale</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None and </span><span class="s1">loc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">m = np.mean(data)</span>
            <span class="s1">loc = m - scale*sc.gamma(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/c)</span>
        <span class="s2">elif </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">loc = floc</span>

        <span class="s2">if </span><span class="s1">method == </span><span class="s4">'mm'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># At this point, parameter &quot;guesses&quot; may equal the fixed parameters</span>
            <span class="s0"># in kwds. No harm in passing them as guesses, too.</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">loc=loc</span><span class="s2">, </span><span class="s1">scale=scale</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">weibull_min = weibull_min_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'weibull_min'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">truncweibull_min_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A doubly truncated Weibull minimum continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    weibull_min, truncexpon 
 
    Notes 
    ----- 
    The probability density function for `truncweibull_min` is: 
 
    .. math:: 
 
        f(x, a, b, c) = \frac{c x^{c-1} \exp(-x^c)}{\exp(-a^c) - \exp(-b^c)} 
 
    for :math:`a &lt; x &lt;= b`, :math:`0 \le a &lt; b` and :math:`c &gt; 0`. 
 
    `truncweibull_min` takes :math:`a`, :math:`b`, and :math:`c` as shape 
    parameters. 
 
    Notice that the truncation values, :math:`a` and :math:`b`, are defined in 
    standardized form: 
 
    .. math:: 
 
        a = (u_l - loc)/scale 
        b = (u_r - loc)/scale 
 
    where :math:`u_l` and :math:`u_r` are the specific left and right 
    truncation values, respectively. In other words, the support of the 
    distribution becomes :math:`(a*scale + loc) &lt; x &lt;= (b*scale + loc)` when 
    :math:`loc` and/or :math:`scale` are provided. 
 
    %(after_notes)s 
 
    References 
    ---------- 
 
    .. [1] Rinne, H. &quot;The Weibull Distribution: A Handbook&quot;. CRC Press (2009). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(a &gt;= </span><span class="s5">0.</span><span class="s1">) &amp; (b &gt; a) &amp; (c &gt; </span><span class="s5">0.</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ic</span><span class="s2">, </span><span class="s1">ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Arbitrary, but default a=b=c=1 is not valid</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">denum = (np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">(c * pow(x</span><span class="s2">, </span><span class="s1">c-</span><span class="s5">1</span><span class="s1">) * np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c))) / denum</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">logdenum = np.log(np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">np.log(c) + sc.xlogy(c - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x) - pow(x</span><span class="s2">, </span><span class="s1">c) - logdenum</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">num = (np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s1">denum = (np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">num / denum</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">lognum = np.log(np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s1">logdenum = np.log(np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">lognum - logdenum</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">num = (np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s1">denum = (np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">num / denum</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">lognum = np.log(np.exp(-pow(x</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s1">logdenum = np.log(np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">lognum - logdenum</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">pow(</span>
            <span class="s1">-np.log((</span><span class="s5">1 </span><span class="s1">- q) * np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)) + q * np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)))</span><span class="s2">, </span><span class="s5">1</span><span class="s1">/c</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">pow(</span>
            <span class="s1">-np.log((</span><span class="s5">1 </span><span class="s1">- q) * np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) + q * np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span><span class="s2">, </span><span class="s5">1</span><span class="s1">/c</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">gamma_fun = sc.gamma(n/c + </span><span class="s5">1.</span><span class="s1">) * (</span>
            <span class="s1">sc.gammainc(n/c + </span><span class="s5">1.</span><span class="s2">, </span><span class="s1">pow(b</span><span class="s2">, </span><span class="s1">c)) - sc.gammainc(n/c + </span><span class="s5">1.</span><span class="s2">, </span><span class="s1">pow(a</span><span class="s2">, </span><span class="s1">c))</span>
            <span class="s1">)</span>
        <span class="s1">denum = (np.exp(-pow(a</span><span class="s2">, </span><span class="s1">c)) - np.exp(-pow(b</span><span class="s2">, </span><span class="s1">c)))</span>
        <span class="s2">return </span><span class="s1">gamma_fun / denum</span>


<span class="s1">truncweibull_min = truncweibull_min_gen(name=</span><span class="s4">'truncweibull_min'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">weibull_max_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Weibull maximum continuous random variable. 
 
    The Weibull Maximum Extreme Value distribution, from extreme value theory 
    (Fisher-Gnedenko theorem), is the limiting distribution of rescaled 
    maximum of iid random variables. This is the distribution of -X 
    if X is from the `weibull_min` function. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    weibull_min 
 
    Notes 
    ----- 
    The probability density function for `weibull_max` is: 
 
    .. math:: 
 
        f(x, c) = c (-x)^{c-1} \exp(-(-x)^c) 
 
    for :math:`x &lt; 0`, :math:`c &gt; 0`. 
 
    `weibull_max` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    https://en.wikipedia.org/wiki/Weibull_distribution 
 
    https://en.wikipedia.org/wiki/Fisher-Tippett-Gnedenko_theorem 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># weibull_max.pdf(x, c) = c * (-x)**(c-1) * exp(-(-x)**c)</span>
        <span class="s2">return </span><span class="s1">c*pow(-x</span><span class="s2">, </span><span class="s1">c-</span><span class="s5">1</span><span class="s1">)*np.exp(-pow(-x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(c) + sc.xlogy(c-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-x) - pow(-x</span><span class="s2">, </span><span class="s1">c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(-pow(-x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-pow(-x</span><span class="s2">, </span><span class="s1">c)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-pow(-x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-pow(-np.log(q)</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">val = sc.gamma(</span><span class="s5">1.0</span><span class="s1">+n*</span><span class="s5">1.0</span><span class="s1">/c)</span>
        <span class="s2">if </span><span class="s1">int(n) % </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">sgn = -</span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sgn = </span><span class="s5">1</span>
        <span class="s2">return </span><span class="s1">sgn * val</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-_EULER / c - np.log(c) + _EULER + </span><span class="s5">1</span>


<span class="s1">weibull_max = weibull_max_gen(b=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'weibull_max'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genlogistic_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized logistic continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `genlogistic` is: 
 
    .. math:: 
 
        f(x, c) = c \frac{\exp(-x)} 
                         {(1 + \exp(-x))^{c+1}} 
 
    for real :math:`x` and :math:`c &gt; 0`. 
 
    `genlogistic` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># genlogistic.pdf(x, c) = c * exp(-x) / (1 + exp(-x))**(c+1)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># Two mathematically equivalent expressions for log(pdf(x, c)):</span>
        <span class="s0">#     log(pdf(x, c)) = log(c) - x - (c + 1)*log(1 + exp(-x))</span>
        <span class="s0">#                    = log(c) + c*x - (c + 1)*log(1 + exp(x))</span>
        <span class="s1">mult = -(c - </span><span class="s5">1</span><span class="s1">) * (x &lt; </span><span class="s5">0</span><span class="s1">) - </span><span class="s5">1</span>
        <span class="s1">absx = np.abs(x)</span>
        <span class="s2">return </span><span class="s1">np.log(c) + mult*absx - (c+</span><span class="s5">1</span><span class="s1">) * sc.log1p(np.exp(-absx))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">Cx = (</span><span class="s5">1</span><span class="s1">+np.exp(-x))**(-c)</span>
        <span class="s2">return </span><span class="s1">Cx</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-c * np.log1p(np.exp(-x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-np.log(sc.powm1(q</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1.0</span><span class="s1">/c))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(self._logcdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">self._ppf(</span><span class="s5">1 </span><span class="s1">- q</span><span class="s2">, </span><span class="s1">c)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">mu = _EULER + sc.psi(c)</span>
        <span class="s1">mu2 = np.pi*np.pi/</span><span class="s5">6.0 </span><span class="s1">+ sc.zeta(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s1">g1 = -</span><span class="s5">2</span><span class="s1">*sc.zeta(</span><span class="s5">3</span><span class="s2">, </span><span class="s1">c) + </span><span class="s5">2</span><span class="s1">*_ZETA3</span>
        <span class="s1">g1 /= np.power(mu2</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">g2 = np.pi**</span><span class="s5">4</span><span class="s1">/</span><span class="s5">15.0 </span><span class="s1">+ </span><span class="s5">6</span><span class="s1">*sc.zeta(</span><span class="s5">4</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s1">g2 /= mu2**</span><span class="s5">2.0</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(c &lt; </span><span class="s5">8e6</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">, </span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">c: -np.log(c) + sc.psi(c + </span><span class="s5">1</span><span class="s1">) + _EULER + </span><span class="s5">1</span><span class="s2">,</span>
                          <span class="s0"># asymptotic expansion: psi(c) ~ log(c) - 1/(2 * c)</span>
                          <span class="s0"># a = -log(c) + psi(c + 1)</span>
                          <span class="s0">#   = -log(c) + psi(c) + 1/c</span>
                          <span class="s0">#   ~ -log(c) + log(c) - 1/(2 * c) + 1/c</span>
                          <span class="s0">#   = 1/(2 * c)</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">c: </span><span class="s5">1</span><span class="s1">/(</span><span class="s5">2 </span><span class="s1">* c) + _EULER + </span><span class="s5">1</span><span class="s1">)</span>


<span class="s1">genlogistic = genlogistic_gen(name=</span><span class="s4">'genlogistic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genpareto_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized Pareto continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `genpareto` is: 
 
    .. math:: 
 
        f(x, c) = (1 + c x)^{-1 - 1/c} 
 
    defined for :math:`x \ge 0` if :math:`c \ge 0`, and for 
    :math:`0 \le x \le -1/c` if :math:`c &lt; 0`. 
 
    `genpareto` takes ``c`` as a shape parameter for :math:`c`. 
 
    For :math:`c=0`, `genpareto` reduces to the exponential 
    distribution, `expon`: 
 
    .. math:: 
 
        f(x, 0) = \exp(-x) 
 
    For :math:`c=-1`, `genpareto` is uniform on ``[0, 1]``: 
 
    .. math:: 
 
        f(x, -1) = 1 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.isfinite(c)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">c = np.asarray(c)</span>
        <span class="s1">b = _lazywhere(c &lt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                       <span class="s2">lambda </span><span class="s1">c: -</span><span class="s5">1. </span><span class="s1">/ c</span><span class="s2">,</span>
                       <span class="s1">np.inf)</span>
        <span class="s1">a = np.where(c &gt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">self.a)</span>
        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># genpareto.pdf(x, c) = (1 + c * x)**(-1 - 1/c)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: -sc.xlog1py(c + </span><span class="s5">1.</span><span class="s2">, </span><span class="s1">c*x) / c</span><span class="s2">,</span>
                          <span class="s1">-x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.inv_boxcox1p(-x</span><span class="s2">, </span><span class="s1">-c)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.inv_boxcox(-x</span><span class="s2">, </span><span class="s1">-c)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: -sc.log1p(c*x) / c</span><span class="s2">,</span>
                          <span class="s1">-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.boxcox1p(-q</span><span class="s2">, </span><span class="s1">-c)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.boxcox(q</span><span class="s2">, </span><span class="s1">-c)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s4">'m' </span><span class="s2">not in </span><span class="s1">moments:</span>
            <span class="s1">m = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">m = _lazywhere(c &lt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                           <span class="s2">lambda </span><span class="s1">xi: </span><span class="s5">1</span><span class="s1">/(</span><span class="s5">1 </span><span class="s1">- xi)</span><span class="s2">,</span>
                           <span class="s1">np.inf)</span>
        <span class="s2">if </span><span class="s4">'v' </span><span class="s2">not in </span><span class="s1">moments:</span>
            <span class="s1">v = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">v = _lazywhere(c &lt; </span><span class="s5">1</span><span class="s1">/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                           <span class="s2">lambda </span><span class="s1">xi: </span><span class="s5">1 </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">- xi)**</span><span class="s5">2 </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2</span><span class="s1">*xi)</span><span class="s2">,</span>
                           <span class="s1">np.nan)</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">not in </span><span class="s1">moments:</span>
            <span class="s1">s = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">s = _lazywhere(c &lt; </span><span class="s5">1</span><span class="s1">/</span><span class="s5">3</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                           <span class="s2">lambda </span><span class="s1">xi: (</span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ xi) * np.sqrt(</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2</span><span class="s1">*xi) /</span>
                                       <span class="s1">(</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">3</span><span class="s1">*xi))</span><span class="s2">,</span>
                           <span class="s1">np.nan)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">not in </span><span class="s1">moments:</span>
            <span class="s1">k = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">k = _lazywhere(c &lt; </span><span class="s5">1</span><span class="s1">/</span><span class="s5">4</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                           <span class="s2">lambda </span><span class="s1">xi: (</span><span class="s5">3 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2</span><span class="s1">*xi) * (</span><span class="s5">2</span><span class="s1">*xi**</span><span class="s5">2 </span><span class="s1">+ xi + </span><span class="s5">3</span><span class="s1">) /</span>
                                       <span class="s1">(</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">3</span><span class="s1">*xi) / (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">4</span><span class="s1">*xi) - </span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
                           <span class="s1">np.nan)</span>
        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">k</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">def </span><span class="s1">__munp(n</span><span class="s2">, </span><span class="s1">c):</span>
            <span class="s1">val = </span><span class="s5">0.0</span>
            <span class="s1">k = np.arange(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n + </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">ki</span><span class="s2">, </span><span class="s1">cnk </span><span class="s2">in </span><span class="s1">zip(k</span><span class="s2">, </span><span class="s1">sc.comb(n</span><span class="s2">, </span><span class="s1">k)):</span>
                <span class="s1">val = val + cnk * (-</span><span class="s5">1</span><span class="s1">) ** ki / (</span><span class="s5">1.0 </span><span class="s1">- c * ki)</span>
            <span class="s2">return </span><span class="s1">np.where(c * n &lt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">val * (-</span><span class="s5">1.0 </span><span class="s1">/ c) ** n</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(c != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(c</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">c: __munp(n</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s1">sc.gamma(n + </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1. </span><span class="s1">+ c</span>


<span class="s1">genpareto = genpareto_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'genpareto'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genexpon_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized exponential continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `genexpon` is: 
 
    .. math:: 
 
        f(x, a, b, c) = (a + b (1 - \exp(-c x))) 
                        \exp(-a x - b x + \frac{b}{c}  (1-\exp(-c x))) 
 
    for :math:`x \ge 0`, :math:`a, b, c &gt; 0`. 
 
    `genexpon` takes :math:`a`, :math:`b` and :math:`c` as shape parameters. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    H.K. Ryu, &quot;An Extension of Marshall and Olkin's Bivariate Exponential 
    Distribution&quot;, Journal of the American Statistical Association, 1993. 
 
    N. Balakrishnan, Asit P. Basu (editors), *The Exponential Distribution: 
    Theory, Methods and Applications*, Gordon and Breach, 1995. 
    ISBN 10: 2884491929 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib</span><span class="s2">, </span><span class="s1">ic]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># genexpon.pdf(x, a, b, c) = (a + b * (1 - exp(-c*x))) * \</span>
        <span class="s0">#                            exp(-a*x - b*x + b/c * (1-exp(-c*x)))</span>
        <span class="s2">return </span><span class="s1">(a + b*(-sc.expm1(-c*x)))*np.exp((-a-b)*x +</span>
                                                <span class="s1">b*(-sc.expm1(-c*x))/c)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(a+b*(-sc.expm1(-c*x))) + (-a-b)*x+b*(-sc.expm1(-c*x))/c</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1((-a-b)*x + b*(-sc.expm1(-c*x))/c)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">s = a + b</span>
        <span class="s1">t = (b - c*np.log1p(-p))/s</span>
        <span class="s2">return </span><span class="s1">(t + sc.lambertw(-b/s * np.exp(-t)).real)/c</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp((-a-b)*x + b*(-sc.expm1(-c*x))/c)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">s = a + b</span>
        <span class="s1">t = (b - c*np.log(p))/s</span>
        <span class="s2">return </span><span class="s1">(t + sc.lambertw(-b/s * np.exp(-t)).real)/c</span>


<span class="s1">genexpon = genexpon_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'genexpon'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genextreme_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized extreme value continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gumbel_r 
 
    Notes 
    ----- 
    For :math:`c=0`, `genextreme` is equal to `gumbel_r` with 
    probability density function 
 
    .. math:: 
 
        f(x) = \exp(-\exp(-x)) \exp(-x), 
 
    where :math:`-\infty &lt; x &lt; \infty`. 
 
    For :math:`c \ne 0`, the probability density function for `genextreme` is: 
 
    .. math:: 
 
        f(x, c) = \exp(-(1-c x)^{1/c}) (1-c x)^{1/c-1}, 
 
    where :math:`-\infty &lt; x \le 1/c` if :math:`c &gt; 0` and 
    :math:`1/c \le x &lt; \infty` if :math:`c &lt; 0`. 
 
    Note that several sources and software packages use the opposite 
    convention for the sign of the shape parameter :math:`c`. 
 
    `genextreme` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.isfinite(c)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">_b = np.where(c &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ np.maximum(c</span><span class="s2">, </span><span class="s1">_XMIN)</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">_a = np.where(c &lt; </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ np.minimum(c</span><span class="s2">, </span><span class="s1">-_XMIN)</span><span class="s2">, </span><span class="s1">-np.inf)</span>
        <span class="s2">return </span><span class="s1">_a</span><span class="s2">, </span><span class="s1">_b</span>

    <span class="s2">def </span><span class="s1">_loglogcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># Returns log(-log(cdf(x, c)))</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: sc.log1p(-c*x)/c</span><span class="s2">, </span><span class="s1">-x)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># genextreme.pdf(x, c) =</span>
        <span class="s0">#     exp(-exp(-x))*exp(-x),                    for c==0</span>
        <span class="s0">#     exp(-(1-c*x)**(1/c))*(1-c*x)**(1/c-1),    for x \le 1/c, c &gt; 0</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">cx = _lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: c*x</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">)</span>
        <span class="s1">logex2 = sc.log1p(-cx)</span>
        <span class="s1">logpex2 = self._loglogcdf(x</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s1">pex2 = np.exp(logpex2)</span>
        <span class="s0"># Handle special cases</span>
        <span class="s1">np.putmask(logpex2</span><span class="s2">, </span><span class="s1">(c == </span><span class="s5">0</span><span class="s1">) &amp; (x == -np.inf)</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">)</span>
        <span class="s1">logpdf = _lazywhere(~((cx == </span><span class="s5">1</span><span class="s1">) | (cx == -np.inf))</span><span class="s2">,</span>
                            <span class="s1">(pex2</span><span class="s2">, </span><span class="s1">logpex2</span><span class="s2">, </span><span class="s1">logex2)</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">pex2</span><span class="s2">, </span><span class="s1">lpex2</span><span class="s2">, </span><span class="s1">lex2: -pex2 + lpex2 - lex2</span><span class="s2">,</span>
                            <span class="s1">fillvalue=-np.inf)</span>
        <span class="s1">np.putmask(logpdf</span><span class="s2">, </span><span class="s1">(c == </span><span class="s5">1</span><span class="s1">) &amp; (x == </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">logpdf</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-np.exp(self._loglogcdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logcdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(self._logcdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">x = -np.log(-np.log(q))</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: -sc.expm1(-c * x) / c</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">x = -np.log(-sc.log1p(-q))</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x == x) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: -sc.expm1(-c * x) / c</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">def </span><span class="s1">g(n):</span>
            <span class="s2">return </span><span class="s1">sc.gamma(n * c + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g1 = g(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g2 = g(</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">g3 = g(</span><span class="s5">3</span><span class="s1">)</span>
        <span class="s1">g4 = g(</span><span class="s5">4</span><span class="s1">)</span>
        <span class="s1">g2mg12 = np.where(abs(c) &lt; </span><span class="s5">1e-7</span><span class="s2">, </span><span class="s1">(c*np.pi)**</span><span class="s5">2.0</span><span class="s1">/</span><span class="s5">6.0</span><span class="s2">, </span><span class="s1">g2-g1**</span><span class="s5">2.0</span><span class="s1">)</span>
        <span class="s1">gam2k = np.where(abs(c) &lt; </span><span class="s5">1e-7</span><span class="s2">, </span><span class="s1">np.pi**</span><span class="s5">2.0</span><span class="s1">/</span><span class="s5">6.0</span><span class="s2">,</span>
                         <span class="s1">sc.expm1(sc.gammaln(</span><span class="s5">2.0</span><span class="s1">*c+</span><span class="s5">1.0</span><span class="s1">)-</span><span class="s5">2</span><span class="s1">*sc.gammaln(c + </span><span class="s5">1.0</span><span class="s1">))/c**</span><span class="s5">2.0</span><span class="s1">)</span>
        <span class="s1">eps = </span><span class="s5">1e-14</span>
        <span class="s1">gamk = np.where(abs(c) &lt; eps</span><span class="s2">, </span><span class="s1">-_EULER</span><span class="s2">, </span><span class="s1">sc.expm1(sc.gammaln(c + </span><span class="s5">1</span><span class="s1">))/c)</span>

        <span class="s1">m = np.where(c &lt; -</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">-gamk)</span>
        <span class="s1">v = np.where(c &lt; -</span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">g1**</span><span class="s5">2.0</span><span class="s1">*gam2k)</span>

        <span class="s0"># skewness</span>
        <span class="s1">sk1 = _lazywhere(c &gt;= -</span><span class="s5">1.</span><span class="s1">/</span><span class="s5">3</span><span class="s2">,</span>
                         <span class="s1">(c</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span><span class="s2">, </span><span class="s1">g3</span><span class="s2">, </span><span class="s1">g2mg12)</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">c</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span><span class="s2">, </span><span class="s1">g3</span><span class="s2">, </span><span class="s1">g2gm12:</span>
                             <span class="s1">np.sign(c)*(-g3 + (g2 + </span><span class="s5">2</span><span class="s1">*g2mg12)*g1)/g2mg12**</span><span class="s5">1.5</span><span class="s2">,</span>
                         <span class="s1">fillvalue=np.nan)</span>
        <span class="s1">sk = np.where(abs(c) &lt;= eps**</span><span class="s5">0.29</span><span class="s2">, </span><span class="s5">12</span><span class="s1">*np.sqrt(</span><span class="s5">6</span><span class="s1">)*_ZETA3/np.pi**</span><span class="s5">3</span><span class="s2">, </span><span class="s1">sk1)</span>

        <span class="s0"># kurtosis</span>
        <span class="s1">ku1 = _lazywhere(c &gt;= -</span><span class="s5">1.</span><span class="s1">/</span><span class="s5">4</span><span class="s2">,</span>
                         <span class="s1">(g1</span><span class="s2">, </span><span class="s1">g2</span><span class="s2">, </span><span class="s1">g3</span><span class="s2">, </span><span class="s1">g4</span><span class="s2">, </span><span class="s1">g2mg12)</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span><span class="s2">, </span><span class="s1">g3</span><span class="s2">, </span><span class="s1">g4</span><span class="s2">, </span><span class="s1">g2mg12:</span>
                             <span class="s1">(g4 + (-</span><span class="s5">4</span><span class="s1">*g3 + </span><span class="s5">3</span><span class="s1">*(g2 + g2mg12)*g1)*g1)/g2mg12**</span><span class="s5">2</span><span class="s2">,</span>
                         <span class="s1">fillvalue=np.nan)</span>
        <span class="s1">ku = np.where(abs(c) &lt;= (eps)**</span><span class="s5">0.23</span><span class="s2">, </span><span class="s5">12.0</span><span class="s1">/</span><span class="s5">5.0</span><span class="s2">, </span><span class="s1">ku1-</span><span class="s5">3.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">sk</span><span class="s2">, </span><span class="s1">ku</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s0"># This is better than the default shape of (1,).</span>
        <span class="s1">g = _skew(data)</span>
        <span class="s2">if </span><span class="s1">g &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">a = </span><span class="s5">0.5</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a = -</span><span class="s5">0.5</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">,</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">k = np.arange(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n+</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">vals = </span><span class="s5">1.0</span><span class="s1">/c**n * np.sum(</span>
            <span class="s1">sc.comb(n</span><span class="s2">, </span><span class="s1">k) * (-</span><span class="s5">1</span><span class="s1">)**k * sc.gamma(c*k + </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.where(c*n &gt; -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">vals</span><span class="s2">, </span><span class="s1">np.inf)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_EULER*(</span><span class="s5">1 </span><span class="s1">- c) + </span><span class="s5">1</span>


<span class="s1">genextreme = genextreme_gen(name=</span><span class="s4">'genextreme'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_digammainv(y):</span>
    <span class="s3">&quot;&quot;&quot;Inverse of the digamma function (real positive arguments only). 
 
    This function is used in the `fit` method of `gamma_gen`. 
    The function uses either optimize.fsolve or optimize.newton 
    to solve `sc.digamma(x) - y = 0`.  There is probably room for 
    improvement, but currently it works over a wide range of y: 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; y = 64*rng.standard_normal(1000000) 
    &gt;&gt;&gt; y.min(), y.max() 
    (-311.43592651416662, 351.77388222276869) 
    &gt;&gt;&gt; x = [_digammainv(t) for t in y] 
    &gt;&gt;&gt; np.abs(sc.digamma(x) - y).max() 
    1.1368683772161603e-13 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_em = </span><span class="s5">0.5772156649015328606065120</span>

    <span class="s2">def </span><span class="s1">func(x):</span>
        <span class="s2">return </span><span class="s1">sc.digamma(x) - y</span>

    <span class="s2">if </span><span class="s1">y &gt; -</span><span class="s5">0.125</span><span class="s1">:</span>
        <span class="s1">x0 = np.exp(y) + </span><span class="s5">0.5</span>
        <span class="s2">if </span><span class="s1">y &lt; </span><span class="s5">10</span><span class="s1">:</span>
            <span class="s0"># Some experimentation shows that newton reliably converges</span>
            <span class="s0"># must faster than fsolve in this y range.  For larger y,</span>
            <span class="s0"># newton sometimes fails to converge.</span>
            <span class="s1">value = optimize.newton(func</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s1">tol=</span><span class="s5">1e-10</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">value</span>
    <span class="s2">elif </span><span class="s1">y &gt; -</span><span class="s5">3</span><span class="s1">:</span>
        <span class="s1">x0 = np.exp(y/</span><span class="s5">2.332</span><span class="s1">) + </span><span class="s5">0.08661</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">x0 = </span><span class="s5">1.0 </span><span class="s1">/ (-y - _em)</span>

    <span class="s1">value</span><span class="s2">, </span><span class="s1">info</span><span class="s2">, </span><span class="s1">ier</span><span class="s2">, </span><span class="s1">mesg = optimize.fsolve(func</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s1">xtol=</span><span class="s5">1e-11</span><span class="s2">,</span>
                                             <span class="s1">full_output=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">ier != </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s4">&quot;_digammainv: fsolve failed, y = %r&quot; </span><span class="s1">% y)</span>

    <span class="s2">return </span><span class="s1">value[</span><span class="s5">0</span><span class="s1">]</span>


<span class="s0">## Gamma (Use MATLAB and MATHEMATICA (b=theta=scale, a=alpha=shape) definition)</span>

<span class="s0">## gamma(a, loc, scale)  with a an integer is the Erlang distribution</span>
<span class="s0">## gamma(1, loc, scale)  is the Exponential distribution</span>
<span class="s0">## gamma(df/2, 0, 2) is the chi2 distribution with df degrees of freedom.</span>

<span class="s2">class </span><span class="s1">gamma_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A gamma continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    erlang, expon 
 
    Notes 
    ----- 
    The probability density function for `gamma` is: 
 
    .. math:: 
 
        f(x, a) = \frac{x^{a-1} e^{-x}}{\Gamma(a)} 
 
    for :math:`x \ge 0`, :math:`a &gt; 0`. Here :math:`\Gamma(a)` refers to the 
    gamma function. 
 
    `gamma` takes ``a`` as a shape parameter for :math:`a`. 
 
    When :math:`a` is an integer, `gamma` reduces to the Erlang 
    distribution, and when :math:`a=1` to the exponential distribution. 
 
    Gamma distributions are sometimes parameterized with two variables, 
    with a probability density function of: 
 
    .. math:: 
 
        f(x, \alpha, \beta) = \frac{\beta^\alpha x^{\alpha - 1} e^{-\beta x }}{\Gamma(\alpha)} 
 
    Note that this parameterization is equivalent to the above, with 
    ``scale = 1 / beta``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.standard_gamma(a</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># gamma.pdf(x, a) = x**(a-1) * exp(-x) / gamma(a)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.xlogy(a-</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x) - x - sc.gammaln(a)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(a</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(a</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincinv(a</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammainccinv(a</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s5">2.0</span><span class="s1">/np.sqrt(a)</span><span class="s2">, </span><span class="s5">6.0</span><span class="s1">/a</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a):</span>

        <span class="s2">def </span><span class="s1">regular_formula(a):</span>
            <span class="s2">return </span><span class="s1">sc.psi(a) * (</span><span class="s5">1</span><span class="s1">-a) + a + sc.gammaln(a)</span>

        <span class="s2">def </span><span class="s1">asymptotic_formula(a):</span>
            <span class="s0"># plug in above formula the expansions:</span>
            <span class="s0"># psi(a) ~ ln(a) - 1/2a - 1/12a^2 + 1/120a^4</span>
            <span class="s0"># gammaln(a) ~ a * ln(a) - a - 1/2 * ln(a) + 1/2 ln(2 * pi) +</span>
            <span class="s0">#              1/12a - 1/360a^3</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">1. </span><span class="s1">+ np.log(</span><span class="s5">2</span><span class="s1">*np.pi) + np.log(a)) - </span><span class="s5">1</span><span class="s1">/(</span><span class="s5">3 </span><span class="s1">* a)</span>
                    <span class="s1">- (a**-</span><span class="s5">2.</span><span class="s1">)/</span><span class="s5">12 </span><span class="s1">- (a**-</span><span class="s5">3.</span><span class="s1">)/</span><span class="s5">90 </span><span class="s1">+ (a**-</span><span class="s5">4.</span><span class="s1">)/</span><span class="s5">120</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">_lazywhere(a &lt; </span><span class="s5">250</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">, </span><span class="s1">)</span><span class="s2">, </span><span class="s1">regular_formula</span><span class="s2">,</span>
                          <span class="s1">f2=asymptotic_formula)</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># The skewness of the gamma distribution is `2 / np.sqrt(a)`.</span>
        <span class="s0"># We invert that to estimate the shape `a` using the skewness</span>
        <span class="s0"># of the data.  The formula is regularized with 1e-8 in the</span>
        <span class="s0"># denominator to allow for degenerate data where the skewness</span>
        <span class="s0"># is close to 0.</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s1">sk = _skew(data)</span>
        <span class="s1">a = </span><span class="s5">4 </span><span class="s1">/ (</span><span class="s5">1e-8 </span><span class="s1">+ sk**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">,</span><span class="s1">))</span>

    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">When the location is fixed by using the argument `floc` 
        and `method='MLE'`, this 
        function uses explicit formulas or solves a simpler numerical 
        problem than the full ML optimization problem.  So in that case, 
        the `optimizer`, `loc` and `scale` arguments are ignored. 
        </span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">floc = kwds.get(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">method = kwds.get(</span><span class="s4">'method'</span><span class="s2">, </span><span class="s4">'mle'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">(isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData) </span><span class="s2">or </span><span class="s1">floc </span><span class="s2">is None</span>
                <span class="s2">or </span><span class="s1">method.lower() == </span><span class="s4">'mm'</span><span class="s1">):</span>
            <span class="s0"># loc is not fixed or we're not doing standard MLE.</span>
            <span class="s0"># Use the default fit method.</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># We already have this value, so just pop it from kwds.</span>
        <span class="s1">kwds.pop(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">f0 = _get_fixed_fit_value(kwds</span><span class="s2">, </span><span class="s1">[</span><span class="s4">'f0'</span><span class="s2">, </span><span class="s4">'fa'</span><span class="s2">, </span><span class="s4">'fix_a'</span><span class="s1">])</span>
        <span class="s1">fscale = kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">_remove_optimizer_parameters(kwds)</span>

        <span class="s0"># Special case: loc is fixed.</span>

        <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None and </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
            <span class="s0"># Without this check, this function would just return the</span>
            <span class="s0"># parameters that were given.</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                             <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

        <span class="s0"># Fixed location is handled by shifting the data.</span>
        <span class="s1">data = np.asarray(data)</span>

        <span class="s2">if not </span><span class="s1">np.isfinite(data).all():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">np.any(data &lt;= floc):</span>
            <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;gamma&quot;</span><span class="s2">, </span><span class="s1">lower=floc</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>

        <span class="s2">if </span><span class="s1">floc != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s0"># Don't do the subtraction in-place, because `data` might be a</span>
            <span class="s0"># view of the input array.</span>
            <span class="s1">data = data - floc</span>
        <span class="s1">xbar = data.mean()</span>

        <span class="s0"># Three cases to handle:</span>
        <span class="s0"># * shape and scale both free</span>
        <span class="s0"># * shape fixed, scale free</span>
        <span class="s0"># * shape free, scale fixed</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># scale is free</span>
            <span class="s2">if </span><span class="s1">f0 </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s0"># shape is fixed</span>
                <span class="s1">a = f0</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># shape and scale are both free.</span>
                <span class="s0"># The MLE for the shape parameter `a` is the solution to:</span>
                <span class="s0"># np.log(a) - sc.digamma(a) - np.log(xbar) +</span>
                <span class="s0">#                             np.log(data).mean() = 0</span>
                <span class="s1">s = np.log(xbar) - np.log(data).mean()</span>
                <span class="s1">aest = (</span><span class="s5">3</span><span class="s1">-s + np.sqrt((s-</span><span class="s5">3</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">24</span><span class="s1">*s)) / (</span><span class="s5">12</span><span class="s1">*s)</span>
                <span class="s1">xa = aest*(</span><span class="s5">1</span><span class="s1">-</span><span class="s5">0.4</span><span class="s1">)</span>
                <span class="s1">xb = aest*(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">0.4</span><span class="s1">)</span>
                <span class="s1">a = optimize.brentq(</span><span class="s2">lambda </span><span class="s1">a: np.log(a) - sc.digamma(a) - s</span><span class="s2">,</span>
                                    <span class="s1">xa</span><span class="s2">, </span><span class="s1">xb</span><span class="s2">, </span><span class="s1">disp=</span><span class="s5">0</span><span class="s1">)</span>

            <span class="s0"># The MLE for the scale parameter is just the data mean</span>
            <span class="s0"># divided by the shape parameter.</span>
            <span class="s1">scale = xbar / a</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># scale is fixed, shape is free</span>
            <span class="s0"># The MLE for the shape parameter `a` is the solution to:</span>
            <span class="s0"># sc.digamma(a) - np.log(data).mean() + np.log(fscale) = 0</span>
            <span class="s1">c = np.log(data).mean() - np.log(fscale)</span>
            <span class="s1">a = _digammainv(c)</span>
            <span class="s1">scale = fscale</span>

        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">scale</span>


<span class="s1">gamma = gamma_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'gamma'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">erlang_gen(gamma_gen):</span>
    <span class="s3">&quot;&quot;&quot;An Erlang continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gamma 
 
    Notes 
    ----- 
    The Erlang distribution is a special case of the Gamma distribution, with 
    the shape parameter `a` an integer.  Note that this restriction is not 
    enforced by `erlang`. It will, however, generate a warning the first time 
    a non-integer value is used for the shape parameter. 
 
    Refer to `gamma` for examples. 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">allint = np.all(np.floor(a) == a)</span>
        <span class="s2">if not </span><span class="s1">allint:</span>
            <span class="s0"># An Erlang distribution shouldn't really have a non-integer</span>
            <span class="s0"># shape parameter, so warn the user.</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">'The shape parameter of the erlang distribution '</span>
                <span class="s4">'has been given a non-integer value {!r}.'</span><span class="s1">.format(a)</span><span class="s2">,</span>
                <span class="s1">RuntimeWarning)</span>
        <span class="s2">return </span><span class="s1">a &gt; </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Override gamma_gen_fitstart so that an integer initial value is</span>
        <span class="s0"># used.  (Also regularize the division, to avoid issues when</span>
        <span class="s0"># _skew(data) is 0 or close to 0.)</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s1">a = int(</span><span class="s5">4.0 </span><span class="s1">/ (</span><span class="s5">1e-8 </span><span class="s1">+ _skew(data)**</span><span class="s5">2</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">super(gamma_gen</span><span class="s2">, </span><span class="s1">self)._fitstart(data</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">,</span><span class="s1">))</span>

    <span class="s0"># Trivial override of the fit method, so we can monkey-patch its</span>
    <span class="s0"># docstring.</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">The Erlang distribution is generally defined to have integer values 
        for the shape parameter.  This is not enforced by the `erlang` class. 
        When fitting the distribution, it will generally return a non-integer 
        value for the shape parameter.  By using the keyword argument 
        `f0=&lt;integer&gt;`, the fit method can be constrained to fit the data to 
        a specific integer shape parameter.&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">erlang = erlang_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'erlang'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gengamma_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized gamma continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gamma, invgamma, weibull_min 
 
    Notes 
    ----- 
    The probability density function for `gengamma` is ([1]_): 
 
    .. math:: 
 
        f(x, a, c) = \frac{|c| x^{c a-1} \exp(-x^c)}{\Gamma(a)} 
 
    for :math:`x \ge 0`, :math:`a &gt; 0`, and :math:`c \ne 0`. 
    :math:`\Gamma` is the gamma function (`scipy.special.gamma`). 
 
    `gengamma` takes :math:`a` and :math:`c` as shape parameters. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] E.W. Stacy, &quot;A Generalization of the Gamma Distribution&quot;, 
       Annals of Mathematical Statistics, Vol 33(3), pp. 1187--1192. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(a &gt; </span><span class="s5">0</span><span class="s1">) &amp; (c != </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ic]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">_lazywhere((x != </span><span class="s5">0</span><span class="s1">) | (c &gt; </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: (np.log(abs(c)) + sc.xlogy(c*a - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x)</span>
                                        <span class="s1">- x**c - sc.gammaln(a))</span><span class="s2">,</span>
                          <span class="s1">fillvalue=-np.inf)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">xc = x**c</span>
        <span class="s1">val1 = sc.gammainc(a</span><span class="s2">, </span><span class="s1">xc)</span>
        <span class="s1">val2 = sc.gammaincc(a</span><span class="s2">, </span><span class="s1">xc)</span>
        <span class="s2">return </span><span class="s1">np.where(c &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">val1</span><span class="s2">, </span><span class="s1">val2)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">r = random_state.standard_gamma(a</span><span class="s2">, </span><span class="s1">size=size)</span>
        <span class="s2">return </span><span class="s1">r**(</span><span class="s5">1.</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">xc = x**c</span>
        <span class="s1">val1 = sc.gammainc(a</span><span class="s2">, </span><span class="s1">xc)</span>
        <span class="s1">val2 = sc.gammaincc(a</span><span class="s2">, </span><span class="s1">xc)</span>
        <span class="s2">return </span><span class="s1">np.where(c &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">val2</span><span class="s2">, </span><span class="s1">val1)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">val1 = sc.gammaincinv(a</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s1">val2 = sc.gammainccinv(a</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s2">return </span><span class="s1">np.where(c &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">val1</span><span class="s2">, </span><span class="s1">val2)**(</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">val1 = sc.gammaincinv(a</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s1">val2 = sc.gammainccinv(a</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s2">return </span><span class="s1">np.where(c &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">val2</span><span class="s2">, </span><span class="s1">val1)**(</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># Pochhammer symbol: sc.pocha,n) = gamma(a+n)/gamma(a)</span>
        <span class="s2">return </span><span class="s1">sc.poch(a</span><span class="s2">, </span><span class="s1">n*</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">def </span><span class="s1">regular(a</span><span class="s2">, </span><span class="s1">c):</span>
            <span class="s1">val = sc.psi(a)</span>
            <span class="s1">A = a * (</span><span class="s5">1 </span><span class="s1">- val) + val / c</span>
            <span class="s1">B = sc.gammaln(a) - np.log(abs(c))</span>
            <span class="s1">h = A + B</span>
            <span class="s2">return </span><span class="s1">h</span>

        <span class="s2">def </span><span class="s1">asymptotic(a</span><span class="s2">, </span><span class="s1">c):</span>
            <span class="s0"># using asymptotic expansions for gammaln and psi (see gh-18093)</span>
            <span class="s2">return </span><span class="s1">(norm._entropy() - np.log(a)/</span><span class="s5">2</span>
                    <span class="s1">- np.log(np.abs(c)) + (a**-</span><span class="s5">1.</span><span class="s1">)/</span><span class="s5">6 </span><span class="s1">- (a**-</span><span class="s5">3.</span><span class="s1">)/</span><span class="s5">90</span>
                    <span class="s1">+ (np.log(a) - (a**-</span><span class="s5">1.</span><span class="s1">)/</span><span class="s5">2 </span><span class="s1">- (a**-</span><span class="s5">2.</span><span class="s1">)/</span><span class="s5">12 </span><span class="s1">+ (a**-</span><span class="s5">4.</span><span class="s1">)/</span><span class="s5">120</span><span class="s1">)/c)</span>

        <span class="s1">h = _lazywhere(a &gt;= </span><span class="s5">2e2</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">, </span><span class="s1">f=asymptotic</span><span class="s2">, </span><span class="s1">f2=regular)</span>
        <span class="s2">return </span><span class="s1">h</span>


<span class="s1">gengamma = gengamma_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'gengamma'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genhalflogistic_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized half-logistic continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `genhalflogistic` is: 
 
    .. math:: 
 
        f(x, c) = \frac{2 (1 - c x)^{1/(c-1)}}{[1 + (1 - c x)^{1/c}]^2} 
 
    for :math:`0 \le x \le 1/c`, and :math:`c &gt; 0`. 
 
    `genhalflogistic` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/c</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># genhalflogistic.pdf(x, c) =</span>
        <span class="s0">#    2 * (1-c*x)**(1/c-1) / (1+(1-c*x)**(1/c))**2</span>
        <span class="s1">limit = </span><span class="s5">1.0</span><span class="s1">/c</span>
        <span class="s1">tmp = np.asarray(</span><span class="s5">1</span><span class="s1">-c*x)</span>
        <span class="s1">tmp0 = tmp**(limit-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">tmp2 = tmp0*tmp</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">*tmp0 / (</span><span class="s5">1</span><span class="s1">+tmp2)**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">limit = </span><span class="s5">1.0</span><span class="s1">/c</span>
        <span class="s1">tmp = np.asarray(</span><span class="s5">1</span><span class="s1">-c*x)</span>
        <span class="s1">tmp2 = tmp**(limit)</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1.0</span><span class="s1">-tmp2) / (</span><span class="s5">1</span><span class="s1">+tmp2)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/c*(</span><span class="s5">1</span><span class="s1">-((</span><span class="s5">1.0</span><span class="s1">-q)/(</span><span class="s5">1.0</span><span class="s1">+q))**c)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">- (</span><span class="s5">2</span><span class="s1">*c+</span><span class="s5">1</span><span class="s1">)*np.log(</span><span class="s5">2</span><span class="s1">)</span>


<span class="s1">genhalflogistic = genhalflogistic_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'genhalflogistic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">genhyperbolic_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized hyperbolic continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    t, norminvgauss, geninvgauss, laplace, cauchy 
 
    Notes 
    ----- 
    The probability density function for `genhyperbolic` is: 
 
    .. math:: 
 
        f(x, p, a, b) = 
            \frac{(a^2 - b^2)^{p/2}} 
            {\sqrt{2\pi}a^{p-1/2} 
            K_p\Big(\sqrt{a^2 - b^2}\Big)} 
            e^{bx} \times \frac{K_{p - 1/2} 
            (a \sqrt{1 + x^2})} 
            {(\sqrt{1 + x^2})^{1/2 - p}} 
 
    for :math:`x, p \in ( - \infty; \infty)`, 
    :math:`|b| &lt; a` if :math:`p \ge 0`, 
    :math:`|b| \le a` if :math:`p &lt; 0`. 
    :math:`K_{p}(.)` denotes the modified Bessel function of the second 
    kind and order :math:`p` (`scipy.special.kv`) 
 
    `genhyperbolic` takes ``p`` as a tail parameter, 
    ``a`` as a shape parameter, 
    ``b`` as a skewness parameter. 
 
    %(after_notes)s 
 
    The original parameterization of the Generalized Hyperbolic Distribution 
    is found in [1]_ as follows 
 
    .. math:: 
 
        f(x, \lambda, \alpha, \beta, \delta, \mu) = 
           \frac{(\gamma/\delta)^\lambda}{\sqrt{2\pi}K_\lambda(\delta \gamma)} 
           e^{\beta (x - \mu)} \times \frac{K_{\lambda - 1/2} 
           (\alpha \sqrt{\delta^2 + (x - \mu)^2})} 
           {(\sqrt{\delta^2 + (x - \mu)^2} / \alpha)^{1/2 - \lambda}} 
 
    for :math:`x \in ( - \infty; \infty)`, 
    :math:`\gamma := \sqrt{\alpha^2 - \beta^2}`, 
    :math:`\lambda, \mu \in ( - \infty; \infty)`, 
    :math:`\delta \ge 0, |\beta| &lt; \alpha` if :math:`\lambda \ge 0`, 
    :math:`\delta &gt; 0, |\beta| \le \alpha` if :math:`\lambda &lt; 0`. 
 
    The location-scale-based parameterization implemented in 
    SciPy is based on [2]_, where :math:`a = \alpha\delta`, 
    :math:`b = \beta\delta`, :math:`p = \lambda`, 
    :math:`scale=\delta` and :math:`loc=\mu` 
 
    Moments are implemented based on [3]_ and [4]_. 
 
    For the distributions that are a special case such as Student's t, 
    it is not recommended to rely on the implementation of genhyperbolic. 
    To avoid potential numerical problems and for performance reasons, 
    the methods of the specific distributions should be used. 
 
    References 
    ---------- 
    .. [1] O. Barndorff-Nielsen, &quot;Hyperbolic Distributions and Distributions 
       on Hyperbolae&quot;, Scandinavian Journal of Statistics, Vol. 5(3), 
       pp. 151-157, 1978. https://www.jstor.org/stable/4615705 
 
    .. [2] Eberlein E., Prause K. (2002) The Generalized Hyperbolic Model: 
        Financial Derivatives and Risk Measures. In: Geman H., Madan D., 
        Pliska S.R., Vorst T. (eds) Mathematical Finance - Bachelier 
        Congress 2000. Springer Finance. Springer, Berlin, Heidelberg. 
        :doi:`10.1007/978-3-662-12429-1_12` 
 
    .. [3] Scott, David J, Wrtz, Diethelm, Dong, Christine and Tran, 
       Thanh Tam, (2009), Moments of the generalized hyperbolic 
       distribution, MPRA Paper, University Library of Munich, Germany, 
       https://EconPapers.repec.org/RePEc:pra:mprapa:19081. 
 
    .. [4] E. Eberlein and E. A. von Hammerstein. Generalized hyperbolic 
       and inverse Gaussian distributions: Limiting cases and approximation 
       of processes. FDM Preprint 80, April 2003. University of Freiburg. 
       https://freidok.uni-freiburg.de/fedora/objects/freidok:7974/datastreams/FILE1/content 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(np.logical_and(np.abs(b) &lt; a</span><span class="s2">, </span><span class="s1">p &gt;= </span><span class="s5">0</span><span class="s1">)</span>
                <span class="s1">| np.logical_and(np.abs(b) &lt;= a</span><span class="s2">, </span><span class="s1">p &lt; </span><span class="s5">0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ip = _ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ip</span><span class="s2">, </span><span class="s1">ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Arbitrary, but the default p = a = b = 1 is not valid; the</span>
        <span class="s0"># distribution requires |b| &lt; a if p &gt;= 0.</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># kve instead of kv works better for large values of p</span>
        <span class="s0"># and smaller values of sqrt(a^2  - b^2)</span>
        <span class="s1">@np.vectorize</span>
        <span class="s2">def </span><span class="s1">_logpdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s2">return </span><span class="s1">_stats.genhyperbolic_logpdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s2">return </span><span class="s1">_logpdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># kve instead of kv works better for large values of p</span>
        <span class="s0"># and smaller values of sqrt(a^2  - b^2)</span>
        <span class="s1">@np.vectorize</span>
        <span class="s2">def </span><span class="s1">_pdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s2">return </span><span class="s1">_stats.genhyperbolic_pdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s2">return </span><span class="s1">_pdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s0"># np.vectorize isn't currently designed to be used as a decorator,</span>
    <span class="s0"># so use a lambda instead.  This allows us to decorate the function</span>
    <span class="s0"># with `np.vectorize` and still provide the `otypes` parameter.</span>
    <span class="s0"># The first argument to `vectorize` is `func.__get__(object)` for</span>
    <span class="s0"># compatibility with Python 3.9.  In Python 3.10, this can be</span>
    <span class="s0"># simplified to just `func`.</span>
    <span class="s1">@</span><span class="s2">lambda </span><span class="s1">func: np.vectorize(func.__get__(object)</span><span class="s2">, </span><span class="s1">otypes=[np.float64])</span>
    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">_integrate_pdf(x0</span><span class="s2">, </span><span class="s1">x1</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s3">&quot;&quot;&quot; 
        Integrate the pdf of the genhyberbolic distribution from x0 to x1. 
        This is a private function used by _cdf() and _sf() only; either x0 
        will be -inf or x1 will be inf. 
        &quot;&quot;&quot;</span>
        <span class="s1">user_data = np.array([p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
        <span class="s1">llc = LowLevelCallable.from_cython(_stats</span><span class="s2">, </span><span class="s4">'_genhyperbolic_pdf'</span><span class="s2">,</span>
                                           <span class="s1">user_data)</span>
        <span class="s1">d = np.sqrt((a + b)*(a - b))</span>
        <span class="s1">mean = b/d * sc.kv(p + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">d) / sc.kv(p</span><span class="s2">, </span><span class="s1">d)</span>
        <span class="s1">epsrel = </span><span class="s5">1e-10</span>
        <span class="s1">epsabs = </span><span class="s5">0</span>
        <span class="s2">if </span><span class="s1">x0 &lt; mean &lt; x1:</span>
            <span class="s0"># If the interval includes the mean, integrate over the two</span>
            <span class="s0"># intervals [x0, mean] and [mean, x1] and add. If we try to do</span>
            <span class="s0"># the integral in one call of quad and the non-infinite endpoint</span>
            <span class="s0"># is far in the tail, quad might return an incorrect result</span>
            <span class="s0"># because it does not &quot;see&quot; the peak of the PDF.</span>
            <span class="s1">intgrl = (integrate.quad(llc</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">,</span>
                                     <span class="s1">epsrel=epsrel</span><span class="s2">, </span><span class="s1">epsabs=epsabs)[</span><span class="s5">0</span><span class="s1">]</span>
                      <span class="s1">+ integrate.quad(llc</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">x1</span><span class="s2">,</span>
                                       <span class="s1">epsrel=epsrel</span><span class="s2">, </span><span class="s1">epsabs=epsabs)[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">intgrl = integrate.quad(llc</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s1">x1</span><span class="s2">,</span>
                                    <span class="s1">epsrel=epsrel</span><span class="s2">, </span><span class="s1">epsabs=epsabs)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">np.isnan(intgrl):</span>
            <span class="s1">msg = (</span><span class="s4">&quot;Infinite values encountered in scipy.special.kve. &quot;</span>
                   <span class="s4">&quot;Values replaced by NaN to avoid incorrect results.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s2">return </span><span class="s1">max(</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">min(</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">intgrl))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">self._integrate_pdf(-np.inf</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">self._integrate_pdf(x</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># note: X = b * V + sqrt(V) * X  has a</span>
        <span class="s0"># generalized hyperbolic distribution</span>
        <span class="s0"># if X is standard normal and V is</span>
        <span class="s0"># geninvgauss(p = p, b = t2, loc = loc, scale = t3)</span>
        <span class="s1">t1 = np.float_power(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) - np.float_power(b</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s0"># b in the GIG</span>
        <span class="s1">t2 = np.float_power(t1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s0"># scale in the GIG</span>
        <span class="s1">t3 = np.float_power(t1</span><span class="s2">, </span><span class="s1">- </span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s1">gig = geninvgauss.rvs(</span>
            <span class="s1">p=p</span><span class="s2">,</span>
            <span class="s1">b=t2</span><span class="s2">,</span>
            <span class="s1">scale=t3</span><span class="s2">,</span>
            <span class="s1">size=size</span><span class="s2">,</span>
            <span class="s1">random_state=random_state</span>
            <span class="s1">)</span>
        <span class="s1">normst = norm.rvs(size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

        <span class="s2">return </span><span class="s1">b * gig + np.sqrt(gig) * normst</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># https://mpra.ub.uni-muenchen.de/19081/1/MPRA_paper_19081.pdf</span>
        <span class="s0"># https://freidok.uni-freiburg.de/fedora/objects/freidok:7974/datastreams/FILE1/content</span>
        <span class="s0"># standardized moments</span>
        <span class="s1">p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(p</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">t1 = np.float_power(a</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) - np.float_power(b</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">t1 = np.float_power(t1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s1">t2 = np.float_power(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) * np.float_power(t1</span><span class="s2">, </span><span class="s1">- </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">integers = np.linspace(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span>
        <span class="s0"># make integers perpendicular to existing dimensions</span>
        <span class="s1">integers = integers.reshape(integers.shape + (</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) * p.ndim)</span>
        <span class="s1">b0</span><span class="s2">, </span><span class="s1">b1</span><span class="s2">, </span><span class="s1">b2</span><span class="s2">, </span><span class="s1">b3</span><span class="s2">, </span><span class="s1">b4 = sc.kv(p + integers</span><span class="s2">, </span><span class="s1">t1)</span>
        <span class="s1">r1</span><span class="s2">, </span><span class="s1">r2</span><span class="s2">, </span><span class="s1">r3</span><span class="s2">, </span><span class="s1">r4 = (b / b0 </span><span class="s2">for </span><span class="s1">b </span><span class="s2">in </span><span class="s1">(b1</span><span class="s2">, </span><span class="s1">b2</span><span class="s2">, </span><span class="s1">b3</span><span class="s2">, </span><span class="s1">b4))</span>

        <span class="s1">m = b * t2 * r1</span>
        <span class="s1">v = (</span>
            <span class="s1">t2 * r1 + np.float_power(b</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) * np.float_power(t2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) *</span>
            <span class="s1">(r2 - np.float_power(r1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
        <span class="s1">)</span>
        <span class="s1">m3e = (</span>
            <span class="s1">np.float_power(b</span><span class="s2">, </span><span class="s5">3</span><span class="s1">) * np.float_power(t2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">) *</span>
            <span class="s1">(r3 - </span><span class="s5">3 </span><span class="s1">* b2 * b1 * np.float_power(b0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">) +</span>
             <span class="s5">2 </span><span class="s1">* np.float_power(r1</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)) +</span>
            <span class="s5">3 </span><span class="s1">* b * np.float_power(t2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) *</span>
            <span class="s1">(r2 - np.float_power(r1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
        <span class="s1">)</span>
        <span class="s1">s = m3e * np.float_power(v</span><span class="s2">, </span><span class="s1">- </span><span class="s5">3 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">m4e = (</span>
            <span class="s1">np.float_power(b</span><span class="s2">, </span><span class="s5">4</span><span class="s1">) * np.float_power(t2</span><span class="s2">, </span><span class="s5">4</span><span class="s1">) *</span>
            <span class="s1">(r4 - </span><span class="s5">4 </span><span class="s1">* b3 * b1 * np.float_power(b0</span><span class="s2">, </span><span class="s1">- </span><span class="s5">2</span><span class="s1">) +</span>
             <span class="s5">6 </span><span class="s1">* b2 * np.float_power(b1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) * np.float_power(b0</span><span class="s2">, </span><span class="s1">- </span><span class="s5">3</span><span class="s1">) -</span>
             <span class="s5">3 </span><span class="s1">* np.float_power(r1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">)) +</span>
            <span class="s1">np.float_power(b</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) * np.float_power(t2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">) *</span>
            <span class="s1">(</span><span class="s5">6 </span><span class="s1">* r3 - </span><span class="s5">12 </span><span class="s1">* b2 * b1 * np.float_power(b0</span><span class="s2">, </span><span class="s1">- </span><span class="s5">2</span><span class="s1">) +</span>
             <span class="s5">6 </span><span class="s1">* np.float_power(r1</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)) +</span>
            <span class="s5">3 </span><span class="s1">* np.float_power(t2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">) * r2</span>
        <span class="s1">)</span>
        <span class="s1">k = m4e * np.float_power(v</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">) - </span><span class="s5">3</span>

        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">k</span>


<span class="s1">genhyperbolic = genhyperbolic_gen(name=</span><span class="s4">'genhyperbolic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gompertz_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Gompertz (or truncated Gumbel) continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `gompertz` is: 
 
    .. math:: 
 
        f(x, c) = c \exp(x) \exp(-c (e^x-1)) 
 
    for :math:`x \ge 0`, :math:`c &gt; 0`. 
 
    `gompertz` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># gompertz.pdf(x, c) = c * exp(x) * exp(-c*(exp(x)-1))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(c) + x - c * sc.expm1(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-c * sc.expm1(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.log1p(-</span><span class="s5">1.0 </span><span class="s1">/ c * sc.log1p(-q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(-c * sc.expm1(x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.log1p(-np.log(p)/c)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">- np.log(c) - sc._ufuncs._scaled_exp1(c)/c</span>


<span class="s1">gompertz = gompertz_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'gompertz'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_average_with_log_weights(x</span><span class="s2">, </span><span class="s1">logweights):</span>
    <span class="s1">x = np.asarray(x)</span>
    <span class="s1">logweights = np.asarray(logweights)</span>
    <span class="s1">maxlogw = logweights.max()</span>
    <span class="s1">weights = np.exp(logweights - maxlogw)</span>
    <span class="s2">return </span><span class="s1">np.average(x</span><span class="s2">, </span><span class="s1">weights=weights)</span>


<span class="s2">class </span><span class="s1">gumbel_r_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A right-skewed Gumbel continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gumbel_l, gompertz, genextreme 
 
    Notes 
    ----- 
    The probability density function for `gumbel_r` is: 
 
    .. math:: 
 
        f(x) = \exp(-(x + e^{-x})) 
 
    The Gumbel distribution is sometimes referred to as a type I Fisher-Tippett 
    distribution.  It is also related to the extreme value distribution, 
    log-Weibull and Gompertz distributions. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># gumbel_r.pdf(x) = exp(-(x + exp(-x)))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-x - np.exp(-x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(-np.exp(-x))</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-np.exp(-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">-np.log(-np.log(q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-np.exp(-x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">-np.log(-np.log1p(-p))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">_EULER</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">6.0</span><span class="s2">, </span><span class="s5">12</span><span class="s1">*np.sqrt(</span><span class="s5">6</span><span class="s1">)/np.pi**</span><span class="s5">3 </span><span class="s1">* _ZETA3</span><span class="s2">, </span><span class="s5">12.0</span><span class="s1">/</span><span class="s5">5</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s0"># https://en.wikipedia.org/wiki/Gumbel_distribution</span>
        <span class="s2">return </span><span class="s1">_EULER + </span><span class="s5">1.</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                         <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>

        <span class="s0"># By the method of maximum likelihood, the estimators of the</span>
        <span class="s0"># location and scale are the roots of the equations defined in</span>
        <span class="s0"># `func` and the value of the expression for `loc` that follows.</span>
        <span class="s0"># The first `func` is a first order derivative of the log-likelihood</span>
        <span class="s0"># equation and the second is from Source: Statistical Distributions,</span>
        <span class="s0"># 3rd Edition. Evans, Hastings, and Peacock (2000), Page 101.</span>

        <span class="s2">def </span><span class="s1">get_loc_from_scale(scale):</span>
            <span class="s2">return </span><span class="s1">-scale * (sc.logsumexp(-data / scale) - np.log(len(data)))</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># if the scale is fixed, the location can be analytically</span>
            <span class="s0"># determined.</span>
            <span class="s1">scale = fscale</span>
            <span class="s1">loc = get_loc_from_scale(scale)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># A different function is solved depending on whether the location</span>
            <span class="s0"># is fixed.</span>
            <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">loc = floc</span>

                <span class="s0"># equation to use if the location is fixed.</span>
                <span class="s0"># note that one cannot use the equation in Evans, Hastings,</span>
                <span class="s0"># and Peacock (2000) (since it assumes that the derivative</span>
                <span class="s0"># w.r.t. the log-likelihood is zero). however, it is easy to</span>
                <span class="s0"># derive the MLE condition directly if loc is fixed</span>
                <span class="s2">def </span><span class="s1">func(scale):</span>
                    <span class="s1">term1 = (loc - data) * np.exp((loc - data) / scale) + data</span>
                    <span class="s1">term2 = len(data) * (loc + scale)</span>
                    <span class="s2">return </span><span class="s1">term1.sum() - term2</span>
            <span class="s2">else</span><span class="s1">:</span>

                <span class="s0"># equation to use if both location and scale are free</span>
                <span class="s2">def </span><span class="s1">func(scale):</span>
                    <span class="s1">sdata = -data / scale</span>
                    <span class="s1">wavg = _average_with_log_weights(data</span><span class="s2">, </span><span class="s1">logweights=sdata)</span>
                    <span class="s2">return </span><span class="s1">data.mean() - wavg - scale</span>

            <span class="s0"># set brackets for `root_scalar` to use when optimizing over the</span>
            <span class="s0"># scale such that a root is likely between them. Use user supplied</span>
            <span class="s0"># guess or default 1.</span>
            <span class="s1">brack_start = kwds.get(</span><span class="s4">'scale'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">lbrack</span><span class="s2">, </span><span class="s1">rbrack = brack_start / </span><span class="s5">2</span><span class="s2">, </span><span class="s1">brack_start * </span><span class="s5">2</span>

            <span class="s0"># if a root is not between the brackets, iteratively expand them</span>
            <span class="s0"># until they include a sign change, checking after each bracket is</span>
            <span class="s0"># modified.</span>
            <span class="s2">def </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack):</span>
                <span class="s0"># return true if the signs disagree.</span>
                <span class="s2">return </span><span class="s1">(np.sign(func(lbrack)) !=</span>
                        <span class="s1">np.sign(func(rbrack)))</span>
            <span class="s2">while </span><span class="s1">(</span><span class="s2">not </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack)</span>
                   <span class="s2">and </span><span class="s1">(lbrack &gt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">rbrack &lt; np.inf)):</span>
                <span class="s1">lbrack /= </span><span class="s5">2</span>
                <span class="s1">rbrack *= </span><span class="s5">2</span>

            <span class="s1">res = optimize.root_scalar(func</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack)</span><span class="s2">,</span>
                                       <span class="s1">rtol=</span><span class="s5">1e-14</span><span class="s2">, </span><span class="s1">xtol=</span><span class="s5">1e-14</span><span class="s1">)</span>
            <span class="s1">scale = res.root</span>
            <span class="s1">loc = floc </span><span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None else </span><span class="s1">get_loc_from_scale(scale)</span>
        <span class="s2">return </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>


<span class="s1">gumbel_r = gumbel_r_gen(name=</span><span class="s4">'gumbel_r'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gumbel_l_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A left-skewed Gumbel continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gumbel_r, gompertz, genextreme 
 
    Notes 
    ----- 
    The probability density function for `gumbel_l` is: 
 
    .. math:: 
 
        f(x) = \exp(x - e^x) 
 
    The Gumbel distribution is sometimes referred to as a type I Fisher-Tippett 
    distribution.  It is also related to the extreme value distribution, 
    log-Weibull and Gompertz distributions. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># gumbel_l.pdf(x) = exp(x - exp(x))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">x - np.exp(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-np.exp(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.log(-sc.log1p(-q))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-np.exp(x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(-np.exp(x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.log(-np.log(x))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">-_EULER</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">6.0</span><span class="s2">, </span><span class="s1">\</span>
               <span class="s1">-</span><span class="s5">12</span><span class="s1">*np.sqrt(</span><span class="s5">6</span><span class="s1">)/np.pi**</span><span class="s5">3 </span><span class="s1">* _ZETA3</span><span class="s2">, </span><span class="s5">12.0</span><span class="s1">/</span><span class="s5">5</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">_EULER + </span><span class="s5">1.</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s0"># The fit method of `gumbel_r` can be used for this distribution with</span>
        <span class="s0"># small modifications. The process to do this is</span>
        <span class="s0"># 1. pass the sign negated data into `gumbel_r.fit`</span>
        <span class="s0">#    - if the location is fixed, it should also be negated.</span>
        <span class="s0"># 2. negate the sign of the resulting location, leaving the scale</span>
        <span class="s0">#    unmodified.</span>
        <span class="s0"># `gumbel_r.fit` holds necessary input checks.</span>

        <span class="s2">if </span><span class="s1">kwds.get(</span><span class="s4">'floc'</span><span class="s1">) </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">kwds[</span><span class="s4">'floc'</span><span class="s1">] = -kwds[</span><span class="s4">'floc'</span><span class="s1">]</span>
        <span class="s1">loc_r</span><span class="s2">, </span><span class="s1">scale_r</span><span class="s2">, </span><span class="s1">= gumbel_r.fit(-np.asarray(data)</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">return </span><span class="s1">-loc_r</span><span class="s2">, </span><span class="s1">scale_r</span>


<span class="s1">gumbel_l = gumbel_l_gen(name=</span><span class="s4">'gumbel_l'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">halfcauchy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Half-Cauchy continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `halfcauchy` is: 
 
    .. math:: 
 
        f(x) = \frac{2}{\pi (1 + x^2)} 
 
    for :math:`x \ge 0`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># halfcauchy.pdf(x) = 2 / (pi * (1 + x**2))</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi/(</span><span class="s5">1.0</span><span class="s1">+x*x)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2.0</span><span class="s1">/np.pi) - sc.log1p(x*x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi*np.arctan(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.tan(np.pi/</span><span class="s5">2</span><span class="s1">*q)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi * np.arctan2(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.tan(np.pi*p/</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">*np.pi)</span>


<span class="s1">halfcauchy = halfcauchy_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'halfcauchy'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">halflogistic_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A half-logistic continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `halflogistic` is: 
 
    .. math:: 
 
        f(x) = \frac{ 2 e^{-x} }{ (1+e^{-x})^2 } 
             = \frac{1}{2} \text{sech}(x/2)^2 
 
    for :math:`x \ge 0`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># halflogistic.pdf(x) = 2 * exp(-x) / (1+exp(-x))**2</span>
        <span class="s0">#                     = 1/2 * sech(x/2)**2</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">) - x - </span><span class="s5">2. </span><span class="s1">* sc.log1p(np.exp(-x))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.tanh(x/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">*np.arctanh(q)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">* sc.expit(-x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(q &lt; </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">(q</span><span class="s2">, </span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">q: -sc.logit(</span><span class="s5">0.5 </span><span class="s1">* q)</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">q: </span><span class="s5">2</span><span class="s1">*np.arctanh(</span><span class="s5">1 </span><span class="s1">- q))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">2</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.pi*np.pi/</span><span class="s5">3.0</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">9</span><span class="s1">*_ZETA3</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">4</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">7</span><span class="s1">*np.pi**</span><span class="s5">4 </span><span class="s1">/ </span><span class="s5">15.0</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">-pow(</span><span class="s5">2.0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">-n))*sc.gamma(n+</span><span class="s5">1</span><span class="s1">)*sc.zeta(n</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">-np.log(</span><span class="s5">2</span><span class="s1">)</span>


<span class="s1">halflogistic = halflogistic_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'halflogistic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">halfnorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A half-normal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `halfnorm` is: 
 
    .. math:: 
 
        f(x) = \sqrt{2/\pi} \exp(-x^2 / 2) 
 
    for :math:`x &gt;= 0`. 
 
    `halfnorm` is a special case of `chi` with ``df=1``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">abs(random_state.standard_normal(size=size))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># halfnorm.pdf(x) = sqrt(2/pi) * exp(-x**2/2)</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">2.0</span><span class="s1">/np.pi)*np.exp(-x*x/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* np.log(</span><span class="s5">2.0</span><span class="s1">/np.pi) - x*x/</span><span class="s5">2.0</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.erf(x / np.sqrt(</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">_norm_ppf((</span><span class="s5">1</span><span class="s1">+q)/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">* _norm_sf(x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">_norm_isf(p/</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">(np.sqrt(</span><span class="s5">2.0</span><span class="s1">/np.pi)</span><span class="s2">,</span>
                <span class="s5">1</span><span class="s1">-</span><span class="s5">2.0</span><span class="s1">/np.pi</span><span class="s2">,</span>
                <span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">)*(</span><span class="s5">4</span><span class="s1">-np.pi)/(np.pi-</span><span class="s5">2</span><span class="s1">)**</span><span class="s5">1.5</span><span class="s2">,</span>
                <span class="s5">8</span><span class="s1">*(np.pi-</span><span class="s5">3</span><span class="s1">)/(np.pi-</span><span class="s5">2</span><span class="s1">)**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">*np.log(np.pi/</span><span class="s5">2.0</span><span class="s1">)+</span><span class="s5">0.5</span>


<span class="s1">halfnorm = halfnorm_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'halfnorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">hypsecant_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A hyperbolic secant continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `hypsecant` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{\pi} \text{sech}(x) 
 
    for a real number :math:`x`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># hypsecant.pdf(x) = 1/pi * sech(x)</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/(np.pi*np.cosh(x))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi*np.arctan(np.exp(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.log(np.tan(np.pi*q/</span><span class="s5">2.0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">4</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">*np.pi)</span>


<span class="s1">hypsecant = hypsecant_gen(name=</span><span class="s4">'hypsecant'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gausshyper_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Gauss hypergeometric continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `gausshyper` is: 
 
    .. math:: 
 
        f(x, a, b, c, z) = C x^{a-1} (1-x)^{b-1} (1+zx)^{-c} 
 
    for :math:`0 \le x \le 1`, :math:`a,b &gt; 0`, :math:`c` a real number, 
    :math:`z &gt; -1`, and :math:`C = \frac{1}{B(a, b) F[2, 1](c, a; a+b; -z)}`. 
    :math:`F[2, 1]` is the Gauss hypergeometric function 
    `scipy.special.hyp2f1`. 
 
    `gausshyper` takes :math:`a`, :math:`b`, :math:`c` and :math:`z` as shape 
    parameters. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Armero, C., and M. J. Bayarri. &quot;Prior Assessments for Prediction in 
           Queues.&quot; *Journal of the Royal Statistical Society*. Series D (The 
           Statistician) 43, no. 1 (1994): 139-53. doi:10.2307/2348939 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">z):</span>
        <span class="s0"># z &gt; -1 per gh-10134</span>
        <span class="s2">return </span><span class="s1">(a &gt; </span><span class="s5">0</span><span class="s1">) &amp; (b &gt; </span><span class="s5">0</span><span class="s1">) &amp; (c == c) &amp; (z &gt; -</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">iz = _ShapeInfo(</span><span class="s4">&quot;z&quot;</span><span class="s2">, False, </span><span class="s1">(-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib</span><span class="s2">, </span><span class="s1">ic</span><span class="s2">, </span><span class="s1">iz]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">z):</span>
        <span class="s0"># gausshyper.pdf(x, a, b, c, z) =</span>
        <span class="s0">#   C * x**(a-1) * (1-x)**(b-1) * (1+z*x)**(-c)</span>
        <span class="s1">Cinv = sc.gamma(a)*sc.gamma(b)/sc.gamma(a+b)*sc.hyp2f1(c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">a+b</span><span class="s2">, </span><span class="s1">-z)</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/Cinv * x**(a-</span><span class="s5">1.0</span><span class="s1">) * (</span><span class="s5">1.0</span><span class="s1">-x)**(b-</span><span class="s5">1.0</span><span class="s1">) / (</span><span class="s5">1.0</span><span class="s1">+z*x)**c</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">z):</span>
        <span class="s1">fac = sc.beta(n+a</span><span class="s2">, </span><span class="s1">b) / sc.beta(a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">num = sc.hyp2f1(c</span><span class="s2">, </span><span class="s1">a+n</span><span class="s2">, </span><span class="s1">a+b+n</span><span class="s2">, </span><span class="s1">-z)</span>
        <span class="s1">den = sc.hyp2f1(c</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">a+b</span><span class="s2">, </span><span class="s1">-z)</span>
        <span class="s2">return </span><span class="s1">fac*num / den</span>


<span class="s1">gausshyper = gausshyper_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'gausshyper'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">invgamma_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An inverted gamma continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `invgamma` is: 
 
    .. math:: 
 
        f(x, a) = \frac{x^{-a-1}}{\Gamma(a)} \exp(-\frac{1}{x}) 
 
    for :math:`x &gt;= 0`, :math:`a &gt; 0`. :math:`\Gamma` is the gamma function 
    (`scipy.special.gamma`). 
 
    `invgamma` takes ``a`` as a shape parameter for :math:`a`. 
 
    `invgamma` is a special case of `gengamma` with ``c=-1``, and it is a 
    different parameterization of the scaled inverse chi-squared distribution. 
    Specifically, if the scaled inverse chi-squared distribution is 
    parameterized with degrees of freedom :math:`\nu` and scaling parameter 
    :math:`\tau^2`, then it can be modeled using `invgamma` with 
    ``a=`` :math:`\nu/2` and ``scale=`` :math:`\nu \tau^2/2`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># invgamma.pdf(x, a) = x**(-a-1) / gamma(a) * exp(-1/x)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">-(a+</span><span class="s5">1</span><span class="s1">) * np.log(x) - sc.gammaln(a) - </span><span class="s5">1.0</span><span class="s1">/x</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(a</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">/ sc.gammainccinv(a</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(a</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">/ sc.gammaincinv(a</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mvsk'</span><span class="s1">):</span>
        <span class="s1">m1 = _lazywhere(a &gt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, lambda </span><span class="s1">x: </span><span class="s5">1. </span><span class="s1">/ (x - </span><span class="s5">1.</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">m2 = _lazywhere(a &gt; </span><span class="s5">2</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, lambda </span><span class="s1">x: </span><span class="s5">1. </span><span class="s1">/ (x - </span><span class="s5">1.</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">/ (x - </span><span class="s5">2.</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">np.inf)</span>

        <span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g1 = _lazywhere(</span>
                <span class="s1">a &gt; </span><span class="s5">3</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s2">lambda </span><span class="s1">x: </span><span class="s5">4. </span><span class="s1">* np.sqrt(x - </span><span class="s5">2.</span><span class="s1">) / (x - </span><span class="s5">3.</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.nan)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g2 = _lazywhere(</span>
                <span class="s1">a &gt; </span><span class="s5">4</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s2">lambda </span><span class="s1">x: </span><span class="s5">6. </span><span class="s1">* (</span><span class="s5">5. </span><span class="s1">* x - </span><span class="s5">11.</span><span class="s1">) / (x - </span><span class="s5">3.</span><span class="s1">) / (x - </span><span class="s5">4.</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.nan)</span>
        <span class="s2">return </span><span class="s1">m1</span><span class="s2">, </span><span class="s1">m2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">def </span><span class="s1">regular(a):</span>
            <span class="s1">h = a - (a + </span><span class="s5">1.0</span><span class="s1">) * sc.psi(a) + sc.gammaln(a)</span>
            <span class="s2">return </span><span class="s1">h</span>

        <span class="s2">def </span><span class="s1">asymptotic(a):</span>
            <span class="s0"># gammaln(a) ~ a * ln(a) - a - 0.5 * ln(a) + 0.5 * ln(2 * pi)</span>
            <span class="s0"># psi(a) ~ ln(a) - 1 / (2 * a)</span>
            <span class="s1">h = ((</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">3</span><span class="s1">*np.log(a) + np.log(</span><span class="s5">2</span><span class="s1">) + np.log(np.pi))/</span><span class="s5">2</span>
                 <span class="s1">+ </span><span class="s5">2</span><span class="s1">/</span><span class="s5">3</span><span class="s1">*a**-</span><span class="s5">1 </span><span class="s1">+ a**-</span><span class="s5">2</span><span class="s1">/</span><span class="s5">12 </span><span class="s1">- a**-</span><span class="s5">3</span><span class="s1">/</span><span class="s5">90 </span><span class="s1">- a**-</span><span class="s5">4</span><span class="s1">/</span><span class="s5">120</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">h</span>

        <span class="s1">h = _lazywhere(a &gt;= </span><span class="s5">2e2</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">f=asymptotic</span><span class="s2">, </span><span class="s1">f2=regular)</span>
        <span class="s2">return </span><span class="s1">h</span>


<span class="s1">invgamma = invgamma_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'invgamma'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">invgauss_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An inverse Gaussian continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `invgauss` is: 
 
    .. math:: 
 
        f(x, \mu) = \frac{1}{\sqrt{2 \pi x^3}} 
                    \exp(-\frac{(x-\mu)^2}{2 x \mu^2}) 
 
    for :math:`x &gt;= 0` and :math:`\mu &gt; 0`. 
 
    `invgauss` takes ``mu`` as a shape parameter for :math:`\mu`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;mu&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.wald(mu</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s0"># invgauss.pdf(x, mu) =</span>
        <span class="s0">#                  1 / sqrt(2*pi*x**3) * exp(-(x-mu)**2/(2*x*mu**2))</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi*x**</span><span class="s5">3.0</span><span class="s1">)*np.exp(-</span><span class="s5">1.0</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*x)*((x-mu)/mu)**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">0.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">*np.pi) - </span><span class="s5">1.5</span><span class="s1">*np.log(x) - ((x-mu)/mu)**</span><span class="s5">2</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*x)</span>

    <span class="s0"># approach adapted from equations in</span>
    <span class="s0"># https://journal.r-project.org/archive/2016-1/giner-smyth.pdf,</span>
    <span class="s0"># not R code. see gh-13616</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">fac = </span><span class="s5">1 </span><span class="s1">/ np.sqrt(x)</span>
        <span class="s1">a = _norm_logcdf(fac * ((x / mu) - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">b = </span><span class="s5">2 </span><span class="s1">/ mu + _norm_logcdf(-fac * ((x / mu) + </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">a + np.log1p(np.exp(b - a))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">fac = </span><span class="s5">1 </span><span class="s1">/ np.sqrt(x)</span>
        <span class="s1">a = _norm_logsf(fac * ((x / mu) - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">b = </span><span class="s5">2 </span><span class="s1">/ mu + _norm_logcdf(-fac * (x + mu) / mu)</span>
        <span class="s2">return </span><span class="s1">a + np.log1p(-np.exp(b - a))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">mu))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logcdf(x</span><span class="s2">, </span><span class="s1">mu))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s2">, </span><span class="s1">over=</span><span class="s4">'ignore'</span><span class="s2">, </span><span class="s1">invalid=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">x</span><span class="s2">, </span><span class="s1">mu = np.broadcast_arrays(x</span><span class="s2">, </span><span class="s1">mu)</span>
            <span class="s1">ppf = _boost._invgauss_ppf(x</span><span class="s2">, </span><span class="s1">mu</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">i_wt = x &gt; </span><span class="s5">0.5  </span><span class="s0"># &quot;wrong tail&quot; - sometimes too inaccurate</span>
            <span class="s1">ppf[i_wt] = _boost._invgauss_isf(</span><span class="s5">1</span><span class="s1">-x[i_wt]</span><span class="s2">, </span><span class="s1">mu[i_wt]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">i_nan = np.isnan(ppf)</span>
            <span class="s1">ppf[i_nan] = super()._ppf(x[i_nan]</span><span class="s2">, </span><span class="s1">mu[i_nan])</span>
        <span class="s2">return </span><span class="s1">ppf</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s2">, </span><span class="s1">over=</span><span class="s4">'ignore'</span><span class="s2">, </span><span class="s1">invalid=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">x</span><span class="s2">, </span><span class="s1">mu = np.broadcast_arrays(x</span><span class="s2">, </span><span class="s1">mu)</span>
            <span class="s1">isf = _boost._invgauss_isf(x</span><span class="s2">, </span><span class="s1">mu</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">i_wt = x &gt; </span><span class="s5">0.5  </span><span class="s0"># &quot;wrong tail&quot; - sometimes too inaccurate</span>
            <span class="s1">isf[i_wt] = _boost._invgauss_ppf(</span><span class="s5">1</span><span class="s1">-x[i_wt]</span><span class="s2">, </span><span class="s1">mu[i_wt]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">i_nan = np.isnan(isf)</span>
            <span class="s1">isf[i_nan] = super()._isf(x[i_nan]</span><span class="s2">, </span><span class="s1">mu[i_nan])</span>
        <span class="s2">return </span><span class="s1">isf</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu**</span><span class="s5">3.0</span><span class="s2">, </span><span class="s5">3</span><span class="s1">*np.sqrt(mu)</span><span class="s2">, </span><span class="s5">15</span><span class="s1">*mu</span>

    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">method = kwds.get(</span><span class="s4">'method'</span><span class="s2">, </span><span class="s4">'mle'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">(isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData) </span><span class="s2">or </span><span class="s1">type(self) == wald_gen</span>
                <span class="s2">or </span><span class="s1">method.lower() == </span><span class="s4">'mm'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">data</span><span class="s2">, </span><span class="s1">fshape_s</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                                   <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s4">''' 
        Source: Statistical Distributions, 3rd Edition. Evans, Hastings, 
        and Peacock (2000), Page 121. Their shape parameter is equivilent to 
        SciPy's with the conversion `fshape_s = fshape / scale`. 
 
        MLE formulas are not used in 3 condtions: 
        - `loc` is not fixed 
        - `mu` is fixed 
        These cases fall back on the superclass fit method. 
        - `loc` is fixed but translation results in negative data raises 
          a `FitDataError`. 
        '''</span>
        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None or </span><span class="s1">fshape_s </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">elif </span><span class="s1">np.any(data - floc &lt; </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;invgauss&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">data = data - floc</span>
            <span class="s1">fshape_n = np.mean(data)</span>
            <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">fscale = len(data) / (np.sum(data ** -</span><span class="s5">1 </span><span class="s1">- fshape_n ** -</span><span class="s5">1</span><span class="s1">))</span>
            <span class="s1">fshape_s = fshape_n / fscale</span>
        <span class="s2">return </span><span class="s1">fshape_s</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s3">&quot;&quot;&quot; 
        Ref.: https://moser-isi.ethz.ch/docs/papers/smos-2012-10.pdf (eq. 9) 
        &quot;&quot;&quot;</span>
        <span class="s0"># a = log(2*pi*e*mu**3)</span>
        <span class="s0">#   = 1 + log(2*pi) + 3 * log(mu)</span>
        <span class="s1">a = </span><span class="s5">1. </span><span class="s1">+ np.log(</span><span class="s5">2 </span><span class="s1">* np.pi) + </span><span class="s5">3 </span><span class="s1">* np.log(mu)</span>
        <span class="s0"># b = exp(2/mu) * exp1(2/mu)</span>
        <span class="s0">#   = _scaled_exp1(2/mu) / (2/mu)</span>
        <span class="s1">r = </span><span class="s5">2</span><span class="s1">/mu</span>
        <span class="s1">b = sc._ufuncs._scaled_exp1(r)/r</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* a - </span><span class="s5">1.5 </span><span class="s1">* b</span>


<span class="s1">invgauss = invgauss_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'invgauss'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">geninvgauss_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Generalized Inverse Gaussian continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `geninvgauss` is: 
 
    .. math:: 
 
        f(x, p, b) = x^{p-1} \exp(-b (x + 1/x) / 2) / (2 K_p(b)) 
 
    where `x &gt; 0`, `p` is a real number and `b &gt; 0`([1]_). 
    :math:`K_p` is the modified Bessel function of second kind of order `p` 
    (`scipy.special.kv`). 
 
    %(after_notes)s 
 
    The inverse Gaussian distribution `stats.invgauss(mu)` is a special case of 
    `geninvgauss` with `p = -1/2`, `b = 1 / mu` and `scale = mu`. 
 
    Generating random variates is challenging for this distribution. The 
    implementation is based on [2]_. 
 
    References 
    ---------- 
    .. [1] O. Barndorff-Nielsen, P. Blaesild, C. Halgreen, &quot;First hitting time 
       models for the generalized inverse gaussian distribution&quot;, 
       Stochastic Processes and their Applications 7, pp. 49--54, 1978. 
 
    .. [2] W. Hoermann and J. Leydold, &quot;Generating generalized inverse Gaussian 
       random variates&quot;, Statistics and Computing, 24(4), p. 547--557, 2014. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(p == p) &amp; (b &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ip = _ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ip</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># kve instead of kv works better for large values of b</span>
        <span class="s0"># warn if kve produces infinite values and replace by nan</span>
        <span class="s0"># otherwise c = -inf and the results are often incorrect</span>
        <span class="s2">def </span><span class="s1">logpdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s2">return </span><span class="s1">_stats.geninvgauss_logpdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s1">logpdf_single = np.vectorize(logpdf_single</span><span class="s2">, </span><span class="s1">otypes=[np.float64])</span>

        <span class="s1">z = logpdf_single(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s2">if </span><span class="s1">np.isnan(z).any():</span>
            <span class="s1">msg = (</span><span class="s4">&quot;Infinite values encountered in scipy.special.kve(p, b). &quot;</span>
                   <span class="s4">&quot;Values replaced by NaN to avoid incorrect results.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s2">return </span><span class="s1">z</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># relying on logpdf avoids overflow of x**(p-1) for large x and p</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*args):</span>
        <span class="s1">_a</span><span class="s2">, </span><span class="s1">_b = self._get_support(*args)</span>

        <span class="s2">def </span><span class="s1">_cdf_single(x</span><span class="s2">, </span><span class="s1">*args):</span>
            <span class="s1">p</span><span class="s2">, </span><span class="s1">b = args</span>
            <span class="s1">user_data = np.array([p</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
            <span class="s1">llc = LowLevelCallable.from_cython(_stats</span><span class="s2">, </span><span class="s4">'_geninvgauss_pdf'</span><span class="s2">,</span>
                                               <span class="s1">user_data)</span>

            <span class="s2">return </span><span class="s1">integrate.quad(llc</span><span class="s2">, </span><span class="s1">_a</span><span class="s2">, </span><span class="s1">x)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">_cdf_single = np.vectorize(_cdf_single</span><span class="s2">, </span><span class="s1">otypes=[np.float64])</span>

        <span class="s2">return </span><span class="s1">_cdf_single(x</span><span class="s2">, </span><span class="s1">*args)</span>

    <span class="s2">def </span><span class="s1">_logquasipdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># log of the quasi-density (w/o normalizing constant) used in _rvs</span>
        <span class="s2">return </span><span class="s1">_lazywhere(x &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b: (p - </span><span class="s5">1</span><span class="s1">)*np.log(x) - b*(x + </span><span class="s5">1</span><span class="s1">/x)/</span><span class="s5">2</span><span class="s2">,</span>
                          <span class="s1">-np.inf)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># if p and b are scalar, use _rvs_scalar, otherwise need to create</span>
        <span class="s0"># output by iterating over parameters</span>
        <span class="s2">if </span><span class="s1">np.isscalar(p) </span><span class="s2">and </span><span class="s1">np.isscalar(b):</span>
            <span class="s1">out = self._rvs_scalar(p</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state)</span>
        <span class="s2">elif </span><span class="s1">p.size == </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">b.size == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">out = self._rvs_scalar(p.item()</span><span class="s2">, </span><span class="s1">b.item()</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># When this method is called, size will be a (possibly empty)</span>
            <span class="s0"># tuple of integers.  It will not be None; if `size=None` is passed</span>
            <span class="s0"># to `rvs()`, size will be the empty tuple ().</span>

            <span class="s1">p</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(p</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s0"># p and b now have the same shape.</span>

            <span class="s0"># `shp` is the shape of the blocks of random variates that are</span>
            <span class="s0"># generated for each combination of parameters associated with</span>
            <span class="s0"># broadcasting p and b.</span>
            <span class="s0"># bc is a tuple the same lenth as size.  The values</span>
            <span class="s0"># in bc are bools.  If bc[j] is True, it means that</span>
            <span class="s0"># entire axis is filled in for a given combination of the</span>
            <span class="s0"># broadcast arguments.</span>
            <span class="s1">shp</span><span class="s2">, </span><span class="s1">bc = _check_shape(p.shape</span><span class="s2">, </span><span class="s1">size)</span>

            <span class="s0"># `numsamples` is the total number of variates to be generated</span>
            <span class="s0"># for each combination of the input arguments.</span>
            <span class="s1">numsamples = int(np.prod(shp))</span>

            <span class="s0"># `out` is the array to be returned.  It is filled in the</span>
            <span class="s0"># loop below.</span>
            <span class="s1">out = np.empty(size)</span>

            <span class="s1">it = np.nditer([p</span><span class="s2">, </span><span class="s1">b]</span><span class="s2">,</span>
                           <span class="s1">flags=[</span><span class="s4">'multi_index'</span><span class="s1">]</span><span class="s2">,</span>
                           <span class="s1">op_flags=[[</span><span class="s4">'readonly'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s4">'readonly'</span><span class="s1">]])</span>
            <span class="s2">while not </span><span class="s1">it.finished:</span>
                <span class="s0"># Convert the iterator's multi_index into an index into the</span>
                <span class="s0"># `out` array where the call to _rvs_scalar() will be stored.</span>
                <span class="s0"># Where bc is True, we use a full slice; otherwise we use the</span>
                <span class="s0"># index value from it.multi_index.  len(it.multi_index) might</span>
                <span class="s0"># be less than len(bc), and in that case we want to align these</span>
                <span class="s0"># two sequences to the right, so the loop variable j runs from</span>
                <span class="s0"># -len(size) to 0.  This doesn't cause an IndexError, as</span>
                <span class="s0"># bc[j] will be True in those cases where it.multi_index[j]</span>
                <span class="s0"># would cause an IndexError.</span>
                <span class="s1">idx = tuple((it.multi_index[j] </span><span class="s2">if not </span><span class="s1">bc[j] </span><span class="s2">else </span><span class="s1">slice(</span><span class="s2">None</span><span class="s1">))</span>
                            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(-len(size)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
                <span class="s1">out[idx] = self._rvs_scalar(it[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">it[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">numsamples</span><span class="s2">,</span>
                                            <span class="s1">random_state).reshape(shp)</span>
                <span class="s1">it.iternext()</span>

        <span class="s2">if </span><span class="s1">size == ():</span>
            <span class="s1">out = out.item()</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_rvs_scalar(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">numsamples</span><span class="s2">, </span><span class="s1">random_state):</span>
        <span class="s0"># following [2], the quasi-pdf is used instead of the pdf for the</span>
        <span class="s0"># generation of rvs</span>
        <span class="s1">invert_res = </span><span class="s2">False</span>
        <span class="s2">if not </span><span class="s1">numsamples:</span>
            <span class="s1">numsamples = </span><span class="s5">1</span>
        <span class="s2">if </span><span class="s1">p &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s0"># note: if X is geninvgauss(p, b), then 1/X is geninvgauss(-p, b)</span>
            <span class="s1">p = -p</span>
            <span class="s1">invert_res = </span><span class="s2">True</span>
        <span class="s1">m = self._mode(p</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s0"># determine method to be used following [2]</span>
        <span class="s1">ratio_unif = </span><span class="s2">True</span>
        <span class="s2">if </span><span class="s1">p &gt;= </span><span class="s5">1 </span><span class="s2">or </span><span class="s1">b &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s0"># ratio of uniforms with mode shift below</span>
            <span class="s1">mode_shift = </span><span class="s2">True</span>
        <span class="s2">elif </span><span class="s1">b &gt;= min(</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">2 </span><span class="s1">* np.sqrt(</span><span class="s5">1 </span><span class="s1">- p) / </span><span class="s5">3</span><span class="s1">):</span>
            <span class="s0"># ratio of uniforms without mode shift below</span>
            <span class="s1">mode_shift = </span><span class="s2">False</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># new algorithm in [2]</span>
            <span class="s1">ratio_unif = </span><span class="s2">False</span>

        <span class="s0"># prepare sampling of rvs</span>
        <span class="s1">size1d = tuple(np.atleast_1d(numsamples))</span>
        <span class="s1">N = np.prod(size1d)  </span><span class="s0"># number of rvs needed, reshape upon return</span>
        <span class="s1">x = np.zeros(N)</span>
        <span class="s1">simulated = </span><span class="s5">0</span>

        <span class="s2">if </span><span class="s1">ratio_unif:</span>
            <span class="s0"># use ratio of uniforms method</span>
            <span class="s2">if </span><span class="s1">mode_shift:</span>
                <span class="s1">a2 = -</span><span class="s5">2 </span><span class="s1">* (p + </span><span class="s5">1</span><span class="s1">) / b - m</span>
                <span class="s1">a1 = </span><span class="s5">2 </span><span class="s1">* m * (p - </span><span class="s5">1</span><span class="s1">) / b - </span><span class="s5">1</span>
                <span class="s0"># find roots of x**3 + a2*x**2 + a1*x + m (Cardano's formula)</span>
                <span class="s1">p1 = a1 - a2**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">3</span>
                <span class="s1">q1 = </span><span class="s5">2 </span><span class="s1">* a2**</span><span class="s5">3 </span><span class="s1">/ </span><span class="s5">27 </span><span class="s1">- a2 * a1 / </span><span class="s5">3 </span><span class="s1">+ m</span>
                <span class="s1">phi = np.arccos(-q1 * np.sqrt(-</span><span class="s5">27 </span><span class="s1">/ p1**</span><span class="s5">3</span><span class="s1">) / </span><span class="s5">2</span><span class="s1">)</span>
                <span class="s1">s1 = -np.sqrt(-</span><span class="s5">4 </span><span class="s1">* p1 / </span><span class="s5">3</span><span class="s1">)</span>
                <span class="s1">root1 = s1 * np.cos(phi / </span><span class="s5">3 </span><span class="s1">+ np.pi / </span><span class="s5">3</span><span class="s1">) - a2 / </span><span class="s5">3</span>
                <span class="s1">root2 = -s1 * np.cos(phi / </span><span class="s5">3</span><span class="s1">) - a2 / </span><span class="s5">3</span>
                <span class="s0"># root3 = s1 * np.cos(phi / 3 - np.pi / 3) - a2 / 3</span>

                <span class="s0"># if g is the quasipdf, rescale: g(x) / g(m) which we can write</span>
                <span class="s0"># as exp(log(g(x)) - log(g(m))). This is important</span>
                <span class="s0"># since for large values of p and b, g cannot be evaluated.</span>
                <span class="s0"># denote the rescaled quasipdf by h</span>
                <span class="s1">lm = self._logquasipdf(m</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b)</span>
                <span class="s1">d1 = self._logquasipdf(root1</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b) - lm</span>
                <span class="s1">d2 = self._logquasipdf(root2</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b) - lm</span>
                <span class="s0"># compute the bounding rectangle w.r.t. h. Note that</span>
                <span class="s0"># np.exp(0.5*d1) = np.sqrt(g(root1)/g(m)) = np.sqrt(h(root1))</span>
                <span class="s1">vmin = (root1 - m) * np.exp(</span><span class="s5">0.5 </span><span class="s1">* d1)</span>
                <span class="s1">vmax = (root2 - m) * np.exp(</span><span class="s5">0.5 </span><span class="s1">* d2)</span>
                <span class="s1">umax = </span><span class="s5">1  </span><span class="s0"># umax = sqrt(h(m)) = 1</span>

                <span class="s2">def </span><span class="s1">logqpdf(x):</span>
                    <span class="s2">return </span><span class="s1">self._logquasipdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b) - lm</span>

                <span class="s1">c = m</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># ratio of uniforms without mode shift</span>
                <span class="s0"># compute np.sqrt(quasipdf(m))</span>
                <span class="s1">umax = np.exp(</span><span class="s5">0.5</span><span class="s1">*self._logquasipdf(m</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b))</span>
                <span class="s1">xplus = ((</span><span class="s5">1 </span><span class="s1">+ p) + np.sqrt((</span><span class="s5">1 </span><span class="s1">+ p)**</span><span class="s5">2 </span><span class="s1">+ b**</span><span class="s5">2</span><span class="s1">))/b</span>
                <span class="s1">vmin = </span><span class="s5">0</span>
                <span class="s0"># compute xplus * np.sqrt(quasipdf(xplus))</span>
                <span class="s1">vmax = xplus * np.exp(</span><span class="s5">0.5 </span><span class="s1">* self._logquasipdf(xplus</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b))</span>
                <span class="s1">c = </span><span class="s5">0</span>

                <span class="s2">def </span><span class="s1">logqpdf(x):</span>
                    <span class="s2">return </span><span class="s1">self._logquasipdf(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b)</span>

            <span class="s2">if </span><span class="s1">vmin &gt;= vmax:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;vmin must be smaller than vmax.&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">umax &lt;= </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;umax must be positive.&quot;</span><span class="s1">)</span>

            <span class="s1">i = </span><span class="s5">1</span>
            <span class="s2">while </span><span class="s1">simulated &lt; N:</span>
                <span class="s1">k = N - simulated</span>
                <span class="s0"># simulate uniform rvs on [0, umax] and [vmin, vmax]</span>
                <span class="s1">u = umax * random_state.uniform(size=k)</span>
                <span class="s1">v = random_state.uniform(size=k)</span>
                <span class="s1">v = vmin + (vmax - vmin) * v</span>
                <span class="s1">rvs = v / u + c</span>
                <span class="s0"># rewrite acceptance condition u**2 &lt;= pdf(rvs) by taking logs</span>
                <span class="s1">accept = (</span><span class="s5">2</span><span class="s1">*np.log(u) &lt;= logqpdf(rvs))</span>
                <span class="s1">num_accept = np.sum(accept)</span>
                <span class="s2">if </span><span class="s1">num_accept &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">x[simulated:(simulated + num_accept)] = rvs[accept]</span>
                    <span class="s1">simulated += num_accept</span>

                <span class="s2">if </span><span class="s1">(simulated == </span><span class="s5">0</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(i*N &gt;= </span><span class="s5">50000</span><span class="s1">):</span>
                    <span class="s1">msg = (</span><span class="s4">&quot;Not a single random variate could be generated &quot;</span>
                           <span class="s4">&quot;in {} attempts. Sampling does not appear to &quot;</span>
                           <span class="s4">&quot;work for the provided parameters.&quot;</span><span class="s1">.format(i*N))</span>
                    <span class="s2">raise </span><span class="s1">RuntimeError(msg)</span>
                <span class="s1">i += </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># use new algorithm in [2]</span>
            <span class="s1">x0 = b / (</span><span class="s5">1 </span><span class="s1">- p)</span>
            <span class="s1">xs = np.max((x0</span><span class="s2">, </span><span class="s5">2 </span><span class="s1">/ b))</span>
            <span class="s1">k1 = np.exp(self._logquasipdf(m</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s1">A1 = k1 * x0</span>
            <span class="s2">if </span><span class="s1">x0 &lt; </span><span class="s5">2 </span><span class="s1">/ b:</span>
                <span class="s1">k2 = np.exp(-b)</span>
                <span class="s2">if </span><span class="s1">p &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">A2 = k2 * ((</span><span class="s5">2 </span><span class="s1">/ b)**p - x0**p) / p</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">A2 = k2 * np.log(</span><span class="s5">2 </span><span class="s1">/ b**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">k2</span><span class="s2">, </span><span class="s1">A2 = </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span>
            <span class="s1">k3 = xs**(p - </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">A3 = </span><span class="s5">2 </span><span class="s1">* k3 * np.exp(-xs * b / </span><span class="s5">2</span><span class="s1">) / b</span>
            <span class="s1">A = A1 + A2 + A3</span>

            <span class="s0"># [2]: rejection constant is &lt; 2.73; so expected runtime is finite</span>
            <span class="s2">while </span><span class="s1">simulated &lt; N:</span>
                <span class="s1">k = N - simulated</span>
                <span class="s1">h</span><span class="s2">, </span><span class="s1">rvs = np.zeros(k)</span><span class="s2">, </span><span class="s1">np.zeros(k)</span>
                <span class="s0"># simulate uniform rvs on [x1, x2] and [0, y2]</span>
                <span class="s1">u = random_state.uniform(size=k)</span>
                <span class="s1">v = A * random_state.uniform(size=k)</span>
                <span class="s1">cond1 = v &lt;= A1</span>
                <span class="s1">cond2 = np.logical_not(cond1) &amp; (v &lt;= A1 + A2)</span>
                <span class="s1">cond3 = np.logical_not(cond1 | cond2)</span>
                <span class="s0"># subdomain (0, x0)</span>
                <span class="s1">rvs[cond1] = x0 * v[cond1] / A1</span>
                <span class="s1">h[cond1] = k1</span>
                <span class="s0"># subdomain (x0, 2 / b)</span>
                <span class="s2">if </span><span class="s1">p &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">rvs[cond2] = (x0**p + (v[cond2] - A1) * p / k2)**(</span><span class="s5">1 </span><span class="s1">/ p)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">rvs[cond2] = b * np.exp((v[cond2] - A1) * np.exp(b))</span>
                <span class="s1">h[cond2] = k2 * rvs[cond2]**(p - </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s0"># subdomain (xs, infinity)</span>
                <span class="s1">z = np.exp(-xs * b / </span><span class="s5">2</span><span class="s1">) - b * (v[cond3] - A1 - A2) / (</span><span class="s5">2 </span><span class="s1">* k3)</span>
                <span class="s1">rvs[cond3] = -</span><span class="s5">2 </span><span class="s1">/ b * np.log(z)</span>
                <span class="s1">h[cond3] = k3 * np.exp(-rvs[cond3] * b / </span><span class="s5">2</span><span class="s1">)</span>
                <span class="s0"># apply rejection method</span>
                <span class="s1">accept = (np.log(u * h) &lt;= self._logquasipdf(rvs</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b))</span>
                <span class="s1">num_accept = sum(accept)</span>
                <span class="s2">if </span><span class="s1">num_accept &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">x[simulated:(simulated + num_accept)] = rvs[accept]</span>
                    <span class="s1">simulated += num_accept</span>

        <span class="s1">rvs = np.reshape(x</span><span class="s2">, </span><span class="s1">size1d)</span>
        <span class="s2">if </span><span class="s1">invert_res:</span>
            <span class="s1">rvs = </span><span class="s5">1 </span><span class="s1">/ rvs</span>
        <span class="s2">return </span><span class="s1">rvs</span>

    <span class="s2">def </span><span class="s1">_mode(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># distinguish cases to avoid catastrophic cancellation (see [2])</span>
        <span class="s2">if </span><span class="s1">p &lt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">b / (np.sqrt((p - </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">+ b**</span><span class="s5">2</span><span class="s1">) + </span><span class="s5">1 </span><span class="s1">- p)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">(np.sqrt((</span><span class="s5">1 </span><span class="s1">- p)**</span><span class="s5">2 </span><span class="s1">+ b**</span><span class="s5">2</span><span class="s1">) - (</span><span class="s5">1 </span><span class="s1">- p)) / b</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">num = sc.kve(p + n</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">denom = sc.kve(p</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">inf_vals = np.isinf(num) | np.isinf(denom)</span>
        <span class="s2">if </span><span class="s1">inf_vals.any():</span>
            <span class="s1">msg = (</span><span class="s4">&quot;Infinite values encountered in the moment calculation &quot;</span>
                   <span class="s4">&quot;involving scipy.special.kve. Values replaced by NaN to &quot;</span>
                   <span class="s4">&quot;avoid incorrect results.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">RuntimeWarning)</span>
            <span class="s1">m = np.full_like(num</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">dtype=np.double)</span>
            <span class="s1">m[~inf_vals] = num[~inf_vals] / denom[~inf_vals]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">m = num / denom</span>
        <span class="s2">return </span><span class="s1">m</span>


<span class="s1">geninvgauss = geninvgauss_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;geninvgauss&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">norminvgauss_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Normal Inverse Gaussian continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `norminvgauss` is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{a \, K_1(a \sqrt{1 + x^2})}{\pi \sqrt{1 + x^2}} \, 
                     \exp(\sqrt{a^2 - b^2} + b x) 
 
    where :math:`x` is a real number, the parameter :math:`a` is the tail 
    heaviness and :math:`b` is the asymmetry parameter satisfying 
    :math:`a &gt; 0` and :math:`|b| &lt;= a`. 
    :math:`K_1` is the modified Bessel function of second kind 
    (`scipy.special.k1`). 
 
    %(after_notes)s 
 
    A normal inverse Gaussian random variable `Y` with parameters `a` and `b` 
    can be expressed as a normal mean-variance mixture: 
    `Y = b * V + sqrt(V) * X` where `X` is `norm(0,1)` and `V` is 
    `invgauss(mu=1/sqrt(a**2 - b**2))`. This representation is used 
    to generate random variates. 
 
    Another common parametrization of the distribution (see Equation 2.1 in 
    [2]_) is given by the following expression of the pdf: 
 
    .. math:: 
 
        g(x, \alpha, \beta, \delta, \mu) = 
        \frac{\alpha\delta K_1\left(\alpha\sqrt{\delta^2 + (x - \mu)^2}\right)} 
        {\pi \sqrt{\delta^2 + (x - \mu)^2}} \, 
        e^{\delta \sqrt{\alpha^2 - \beta^2} + \beta (x - \mu)} 
 
    In SciPy, this corresponds to 
    `a = alpha * delta, b = beta * delta, loc = mu, scale=delta`. 
 
    References 
    ---------- 
    .. [1] O. Barndorff-Nielsen, &quot;Hyperbolic Distributions and Distributions on 
           Hyperbolae&quot;, Scandinavian Journal of Statistics, Vol. 5(3), 
           pp. 151-157, 1978. 
 
    .. [2] O. Barndorff-Nielsen, &quot;Normal Inverse Gaussian Distributions and 
           Stochastic Volatility Modelling&quot;, Scandinavian Journal of 
           Statistics, Vol. 24, pp. 1-13, 1997. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(a &gt; </span><span class="s5">0</span><span class="s1">) &amp; (np.absolute(b) &lt; a)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Arbitrary, but the default a = b = 1 is not valid; the distribution</span>
        <span class="s0"># requires |b| &lt; a.</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">gamma = np.sqrt(a**</span><span class="s5">2 </span><span class="s1">- b**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">fac1 = a / np.pi * np.exp(gamma)</span>
        <span class="s1">sq = np.hypot(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x)  </span><span class="s0"># reduce overflows</span>
        <span class="s2">return </span><span class="s1">fac1 * sc.k1e(a * sq) * np.exp(b*x - a*sq) / sq</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">if </span><span class="s1">np.isscalar(x):</span>
            <span class="s0"># If x is a scalar, then so are a and b.</span>
            <span class="s2">return </span><span class="s1">integrate.quad(self._pdf</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">, </span><span class="s1">b))[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a = np.atleast_1d(a)</span>
            <span class="s1">b = np.atleast_1d(b)</span>
            <span class="s1">result = []</span>
            <span class="s2">for </span><span class="s1">(x0</span><span class="s2">, </span><span class="s1">a0</span><span class="s2">, </span><span class="s1">b0) </span><span class="s2">in </span><span class="s1">zip(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
                <span class="s1">result.append(integrate.quad(self._pdf</span><span class="s2">, </span><span class="s1">x0</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">,</span>
                                             <span class="s1">args=(a0</span><span class="s2">, </span><span class="s1">b0))[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s2">return </span><span class="s1">np.array(result)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">def </span><span class="s1">_isf_scalar(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>

            <span class="s2">def </span><span class="s1">eq(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">q):</span>
                <span class="s0"># Solve eq(x, a, b, q) = 0 to obtain isf(x, a, b) = q.</span>
                <span class="s2">return </span><span class="s1">self._sf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b) - q</span>

            <span class="s0"># Find a bracketing interval for the root.</span>
            <span class="s0"># Start at the mean, and grow the length of the interval</span>
            <span class="s0"># by 2 each iteration until there is a sign change in eq.</span>
            <span class="s1">xm = self.mean(a</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">em = eq(xm</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">q)</span>
            <span class="s2">if </span><span class="s1">em == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s0"># Unlikely, but might as well check.</span>
                <span class="s2">return </span><span class="s1">xm</span>
            <span class="s2">if </span><span class="s1">em &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">delta = </span><span class="s5">1</span>
                <span class="s1">left = xm</span>
                <span class="s1">right = xm + delta</span>
                <span class="s2">while </span><span class="s1">eq(right</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">q) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">delta = </span><span class="s5">2</span><span class="s1">*delta</span>
                    <span class="s1">right = xm + delta</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># em &lt; 0</span>
                <span class="s1">delta = </span><span class="s5">1</span>
                <span class="s1">right = xm</span>
                <span class="s1">left = xm - delta</span>
                <span class="s2">while </span><span class="s1">eq(left</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">q) &lt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">delta = </span><span class="s5">2</span><span class="s1">*delta</span>
                    <span class="s1">left = xm - delta</span>
            <span class="s1">result = optimize.brentq(eq</span><span class="s2">, </span><span class="s1">left</span><span class="s2">, </span><span class="s1">right</span><span class="s2">, </span><span class="s1">args=(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">q)</span><span class="s2">,</span>
                                     <span class="s1">xtol=self.xtol)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">if </span><span class="s1">np.isscalar(q):</span>
            <span class="s2">return </span><span class="s1">_isf_scalar(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = []</span>
            <span class="s2">for </span><span class="s1">(q0</span><span class="s2">, </span><span class="s1">a0</span><span class="s2">, </span><span class="s1">b0) </span><span class="s2">in </span><span class="s1">zip(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
                <span class="s1">result.append(_isf_scalar(q0</span><span class="s2">, </span><span class="s1">a0</span><span class="s2">, </span><span class="s1">b0))</span>
            <span class="s2">return </span><span class="s1">np.array(result)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># note: X = b * V + sqrt(V) * X is norminvgaus(a,b) if X is standard</span>
        <span class="s0"># normal and V is invgauss(mu=1/sqrt(a**2 - b**2))</span>
        <span class="s1">gamma = np.sqrt(a**</span><span class="s5">2 </span><span class="s1">- b**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">ig = invgauss.rvs(mu=</span><span class="s5">1</span><span class="s1">/gamma</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">b * ig + np.sqrt(ig) * norm.rvs(size=size</span><span class="s2">,</span>
                                               <span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">gamma = np.sqrt(a**</span><span class="s5">2 </span><span class="s1">- b**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">mean = b / gamma</span>
        <span class="s1">variance = a**</span><span class="s5">2 </span><span class="s1">/ gamma**</span><span class="s5">3</span>
        <span class="s1">skewness = </span><span class="s5">3.0 </span><span class="s1">* b / (a * np.sqrt(gamma))</span>
        <span class="s1">kurtosis = </span><span class="s5">3.0 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">4 </span><span class="s1">* b**</span><span class="s5">2 </span><span class="s1">/ a**</span><span class="s5">2</span><span class="s1">) / gamma</span>
        <span class="s2">return </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">variance</span><span class="s2">, </span><span class="s1">skewness</span><span class="s2">, </span><span class="s1">kurtosis</span>


<span class="s1">norminvgauss = norminvgauss_gen(name=</span><span class="s4">&quot;norminvgauss&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">invweibull_gen(rv_continuous):</span>
    <span class="s3">&quot;&quot;&quot;An inverted Weibull continuous random variable. 
 
    This distribution is also known as the Frchet distribution or the 
    type II extreme value distribution. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `invweibull` is: 
 
    .. math:: 
 
        f(x, c) = c x^{-c-1} \\exp(-x^{-c}) 
 
    for :math:`x &gt; 0`, :math:`c &gt; 0`. 
 
    `invweibull` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    F.R.S. de Gusmao, E.M.M Ortega and G.M. Cordeiro, &quot;The generalized inverse 
    Weibull distribution&quot;, Stat. Papers, vol. 52, pp. 591-619, 2011. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># invweibull.pdf(x, c) = c * x**(-c-1) * exp(-x**(-c))</span>
        <span class="s1">xc1 = np.power(x</span><span class="s2">, </span><span class="s1">-c - </span><span class="s5">1.0</span><span class="s1">)</span>
        <span class="s1">xc2 = np.power(x</span><span class="s2">, </span><span class="s1">-c)</span>
        <span class="s1">xc2 = np.exp(-xc2)</span>
        <span class="s2">return </span><span class="s1">c * xc1 * xc2</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">xc1 = np.power(x</span><span class="s2">, </span><span class="s1">-c)</span>
        <span class="s2">return </span><span class="s1">np.exp(-xc1)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-np.expm1(-x**-c)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.power(-np.log(q)</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1.0</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(-np.log1p(-p))**(-</span><span class="s5">1</span><span class="s1">/c)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.gamma(</span><span class="s5">1 </span><span class="s1">- n / c)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s1">+_EULER + _EULER / c - np.log(c)</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># invweibull requires c &gt; 1 for the first moment to exist, so use 2.0</span>
        <span class="s1">args = (</span><span class="s5">2.0</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if </span><span class="s1">args </span><span class="s2">is None else </span><span class="s1">args</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=args)</span>


<span class="s1">invweibull = invweibull_gen(a=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'invweibull'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">johnsonsb_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Johnson SB continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    johnsonsu 
 
    Notes 
    ----- 
    The probability density function for `johnsonsb` is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{b}{x(1-x)}  \phi(a + b \log \frac{x}{1-x} ) 
 
    where :math:`x`, :math:`a`, and :math:`b` are real scalars; :math:`b &gt; 0` 
    and :math:`x \in [0,1]`.  :math:`\phi` is the pdf of the normal 
    distribution. 
 
    `johnsonsb` takes :math:`a` and :math:`b` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(b &gt; </span><span class="s5">0</span><span class="s1">) &amp; (a == a)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># johnsonsb.pdf(x, a, b) = b / (x*(1-x)) * phi(a + b * log(x/(1-x)))</span>
        <span class="s1">trm = _norm_pdf(a + b*sc.logit(x))</span>
        <span class="s2">return </span><span class="s1">b*</span><span class="s5">1.0</span><span class="s1">/(x*(</span><span class="s5">1</span><span class="s1">-x))*trm</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(a + b*sc.logit(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">sc.expit(</span><span class="s5">1.0 </span><span class="s1">/ b * (_norm_ppf(q) - a))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(a + b*sc.logit(x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">sc.expit(</span><span class="s5">1.0 </span><span class="s1">/ b * (_norm_isf(q) - a))</span>


<span class="s1">johnsonsb = johnsonsb_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'johnsonsb'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">johnsonsu_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Johnson SU continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    johnsonsb 
 
    Notes 
    ----- 
    The probability density function for `johnsonsu` is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{b}{\sqrt{x^2 + 1}} 
                     \phi(a + b \log(x + \sqrt{x^2 + 1})) 
 
    where :math:`x`, :math:`a`, and :math:`b` are real scalars; :math:`b &gt; 0`. 
    :math:`\phi` is the pdf of the normal distribution. 
 
    `johnsonsu` takes :math:`a` and :math:`b` as shape parameters. 
 
    The first four central moments are calculated according to the formulas 
    in [1]_. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Taylor Enterprises. &quot;Johnson Family of Distributions&quot;. 
       https://variation.com/wp-content/distribution_analyzer_help/hs126.htm 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(b &gt; </span><span class="s5">0</span><span class="s1">) &amp; (a == a)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># johnsonsu.pdf(x, a, b) = b / sqrt(x**2 + 1) *</span>
        <span class="s0">#                          phi(a + b * log(x + sqrt(x**2 + 1)))</span>
        <span class="s1">x2 = x*x</span>
        <span class="s1">trm = _norm_pdf(a + b * np.arcsinh(x))</span>
        <span class="s2">return </span><span class="s1">b*</span><span class="s5">1.0</span><span class="s1">/np.sqrt(x2+</span><span class="s5">1.0</span><span class="s1">)*trm</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(a + b * np.arcsinh(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.sinh((_norm_ppf(q) - a) / b)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(a + b * np.arcsinh(x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.sinh((_norm_isf(x) - a) / b)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s0"># Naive implementation of first and second moment to address gh-18071.</span>
        <span class="s0"># https://variation.com/wp-content/distribution_analyzer_help/hs126.htm</span>
        <span class="s0"># Numerical improvements left to future enhancements.</span>
        <span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None, None, None</span>

        <span class="s1">bn2 = b**-</span><span class="s5">2.</span>
        <span class="s1">expbn2 = np.exp(bn2)</span>
        <span class="s1">a_b = a / b</span>

        <span class="s2">if </span><span class="s4">'m' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mu = -expbn2**</span><span class="s5">0.5 </span><span class="s1">* np.sinh(a_b)</span>
        <span class="s2">if </span><span class="s4">'v' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mu2 = </span><span class="s5">0.5</span><span class="s1">*sc.expm1(bn2)*(expbn2*np.cosh(</span><span class="s5">2</span><span class="s1">*a_b) + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">t1 = expbn2**</span><span class="s5">.5 </span><span class="s1">* sc.expm1(bn2)**</span><span class="s5">0.5</span>
            <span class="s1">t2 = </span><span class="s5">3</span><span class="s1">*np.sinh(a_b)</span>
            <span class="s1">t3 = expbn2 * (expbn2 + </span><span class="s5">2</span><span class="s1">) * np.sinh(</span><span class="s5">3</span><span class="s1">*a_b)</span>
            <span class="s1">denom = np.sqrt(</span><span class="s5">2</span><span class="s1">) * (</span><span class="s5">1 </span><span class="s1">+ expbn2 * np.cosh(</span><span class="s5">2</span><span class="s1">*a_b))**(</span><span class="s5">3</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">g1 = -t1 * (t2 + t3) / denom</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">t1 = </span><span class="s5">3 </span><span class="s1">+ </span><span class="s5">6</span><span class="s1">*expbn2</span>
            <span class="s1">t2 = </span><span class="s5">4</span><span class="s1">*expbn2**</span><span class="s5">2 </span><span class="s1">* (expbn2 + </span><span class="s5">2</span><span class="s1">) * np.cosh(</span><span class="s5">2</span><span class="s1">*a_b)</span>
            <span class="s1">t3 = expbn2**</span><span class="s5">2 </span><span class="s1">* np.cosh(</span><span class="s5">4</span><span class="s1">*a_b)</span>
            <span class="s1">t4 = -</span><span class="s5">3 </span><span class="s1">+ </span><span class="s5">3</span><span class="s1">*expbn2**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">2</span><span class="s1">*expbn2**</span><span class="s5">3 </span><span class="s1">+ expbn2**</span><span class="s5">4</span>
            <span class="s1">denom = </span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1 </span><span class="s1">+ expbn2*np.cosh(</span><span class="s5">2</span><span class="s1">*a_b))**</span><span class="s5">2</span>
            <span class="s1">g2 = (t1 + t2 + t3*t4) / denom - </span><span class="s5">3</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">johnsonsu = johnsonsu_gen(name=</span><span class="s4">'johnsonsu'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">laplace_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Laplace continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `laplace` is 
 
    .. math:: 
 
        f(x) = \frac{1}{2} \exp(-|x|) 
 
    for a real number :math:`x`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.laplace(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># laplace.pdf(x) = 1/2 * exp(-abs(x))</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">*np.exp(-abs(x))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">np.where(x &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">- </span><span class="s5">0.5</span><span class="s1">*np.exp(-x)</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">*np.exp(x))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># By symmetry...</span>
        <span class="s2">return </span><span class="s1">self._cdf(-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt; </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">-np.log(</span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">-q))</span><span class="s2">, </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">*q))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s0"># By symmetry...</span>
        <span class="s2">return </span><span class="s1">-self._ppf(q)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">3</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">)+</span><span class="s5">1</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@replace_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">This function uses explicit formulas for the maximum likelihood 
        estimation of the Laplace distribution parameters, so the keyword 
        arguments `loc`, `scale`, and `optimizer` are ignored.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                         <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>

        <span class="s0"># Source: Statistical Distributions, 3rd Edition. Evans, Hastings,</span>
        <span class="s0"># and Peacock (2000), Page 124</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">floc = np.median(data)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">fscale = (np.sum(np.abs(data - floc))) / len(data)</span>

        <span class="s2">return </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale</span>


<span class="s1">laplace = laplace_gen(name=</span><span class="s4">'laplace'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">laplace_asymmetric_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An asymmetric Laplace continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    laplace : Laplace distribution 
 
    Notes 
    ----- 
    The probability density function for `laplace_asymmetric` is 
 
    .. math:: 
 
       f(x, \kappa) &amp;= \frac{1}{\kappa+\kappa^{-1}}\exp(-x\kappa),\quad x\ge0\\ 
                    &amp;= \frac{1}{\kappa+\kappa^{-1}}\exp(x/\kappa),\quad x&lt;0\\ 
 
    for :math:`-\infty &lt; x &lt; \infty`, :math:`\kappa &gt; 0`. 
 
    `laplace_asymmetric` takes ``kappa`` as a shape parameter for 
    :math:`\kappa`. For :math:`\kappa = 1`, it is identical to a 
    Laplace distribution. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Asymmetric Laplace distribution&quot;, Wikipedia 
            https://en.wikipedia.org/wiki/Asymmetric_Laplace_distribution 
 
    .. [2] Kozubowski TJ and Podgrski K. A Multivariate and 
           Asymmetric Generalization of Laplace Distribution, 
           Computational Statistics 15, 531--540 (2000). 
           :doi:`10.1007/PL00022717` 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;kappa&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">kappa))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">lPx = x * np.where(x &gt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-kappa</span><span class="s2">, </span><span class="s1">kapinv)</span>
        <span class="s1">lPx -= np.log(kappa+kapinv)</span>
        <span class="s2">return </span><span class="s1">lPx</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">kappkapinv = kappa+kapinv</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt;= </span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s5">1 </span><span class="s1">- np.exp(-x*kappa)*(kapinv/kappkapinv)</span><span class="s2">,</span>
                        <span class="s1">np.exp(x*kapinv)*(kappa/kappkapinv))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">kappkapinv = kappa+kapinv</span>
        <span class="s2">return </span><span class="s1">np.where(x &gt;= </span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s1">np.exp(-x*kappa)*(kapinv/kappkapinv)</span><span class="s2">,</span>
                        <span class="s5">1 </span><span class="s1">- np.exp(x*kapinv)*(kappa/kappkapinv))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">kappkapinv = kappa+kapinv</span>
        <span class="s2">return </span><span class="s1">np.where(q &gt;= kappa/kappkapinv</span><span class="s2">,</span>
                        <span class="s1">-np.log((</span><span class="s5">1 </span><span class="s1">- q)*kappkapinv*kappa)*kapinv</span><span class="s2">,</span>
                        <span class="s1">np.log(q*kappkapinv/kappa)*kappa)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">kappkapinv = kappa+kapinv</span>
        <span class="s2">return </span><span class="s1">np.where(q &lt;= kapinv/kappkapinv</span><span class="s2">,</span>
                        <span class="s1">-np.log(q*kappkapinv*kappa)*kapinv</span><span class="s2">,</span>
                        <span class="s1">np.log((</span><span class="s5">1 </span><span class="s1">- q)*kappkapinv/kappa)*kappa)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s1">kapinv = </span><span class="s5">1</span><span class="s1">/kappa</span>
        <span class="s1">mn = kapinv - kappa</span>
        <span class="s1">var = kapinv*kapinv + kappa*kappa</span>
        <span class="s1">g1 = </span><span class="s5">2.0</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">-np.power(kappa</span><span class="s2">, </span><span class="s5">6</span><span class="s1">))/np.power(</span><span class="s5">1</span><span class="s1">+np.power(kappa</span><span class="s2">, </span><span class="s5">4</span><span class="s1">)</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">g2 = </span><span class="s5">6.0</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">+np.power(kappa</span><span class="s2">, </span><span class="s5">8</span><span class="s1">))/np.power(</span><span class="s5">1</span><span class="s1">+np.power(kappa</span><span class="s2">, </span><span class="s5">4</span><span class="s1">)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">mn</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">+ np.log(kappa+</span><span class="s5">1</span><span class="s1">/kappa)</span>


<span class="s1">laplace_asymmetric = laplace_asymmetric_gen(name=</span><span class="s4">'laplace_asymmetric'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_check_fit_input_parameters(dist</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwds):</span>
    <span class="s2">if not </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
        <span class="s1">data = np.asarray(data)</span>

    <span class="s1">floc = kwds.get(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">fscale = kwds.get(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

    <span class="s1">num_shapes = len(dist.shapes.split(</span><span class="s4">&quot;,&quot;</span><span class="s1">)) </span><span class="s2">if </span><span class="s1">dist.shapes </span><span class="s2">else </span><span class="s5">0</span>
    <span class="s1">fshape_keys = []</span>
    <span class="s1">fshapes = []</span>

    <span class="s0"># user has many options for fixing the shape, so here we standardize it</span>
    <span class="s0"># into 'f' + the number of the shape.</span>
    <span class="s0"># Adapted from `_reduce_func` in `_distn_infrastructure.py`:</span>
    <span class="s2">if </span><span class="s1">dist.shapes:</span>
        <span class="s1">shapes = dist.shapes.replace(</span><span class="s4">','</span><span class="s2">, </span><span class="s4">' '</span><span class="s1">).split()</span>
        <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">s </span><span class="s2">in </span><span class="s1">enumerate(shapes):</span>
            <span class="s1">key = </span><span class="s4">'f' </span><span class="s1">+ str(j)</span>
            <span class="s1">names = [key</span><span class="s2">, </span><span class="s4">'f' </span><span class="s1">+ s</span><span class="s2">, </span><span class="s4">'fix_' </span><span class="s1">+ s]</span>
            <span class="s1">val = _get_fixed_fit_value(kwds</span><span class="s2">, </span><span class="s1">names)</span>
            <span class="s1">fshape_keys.append(key)</span>
            <span class="s1">fshapes.append(val)</span>
            <span class="s2">if </span><span class="s1">val </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">kwds[key] = val</span>

    <span class="s0"># determine if there are any unknown arguments in kwds</span>
    <span class="s1">known_keys = {</span><span class="s4">'loc'</span><span class="s2">, </span><span class="s4">'scale'</span><span class="s2">, </span><span class="s4">'optimizer'</span><span class="s2">, </span><span class="s4">'method'</span><span class="s2">,</span>
                  <span class="s4">'floc'</span><span class="s2">, </span><span class="s4">'fscale'</span><span class="s2">, </span><span class="s1">*fshape_keys}</span>
    <span class="s1">unknown_keys = set(kwds).difference(known_keys)</span>
    <span class="s2">if </span><span class="s1">unknown_keys:</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Unknown keyword arguments: </span><span class="s2">{</span><span class="s1">unknown_keys</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">len(args) &gt; num_shapes:</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Too many positional arguments.&quot;</span><span class="s1">)</span>

    <span class="s2">if None not in </span><span class="s1">{floc</span><span class="s2">, </span><span class="s1">fscale</span><span class="s2">, </span><span class="s1">*fshapes}:</span>
        <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
        <span class="s0"># Without this check, this function would just return the</span>
        <span class="s0"># parameters that were given.</span>
        <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                           <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

    <span class="s1">uncensored = data._uncensor() </span><span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData) </span><span class="s2">else </span><span class="s1">data</span>
    <span class="s2">if not </span><span class="s1">np.isfinite(uncensored).all():</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">(data</span><span class="s2">, </span><span class="s1">*fshapes</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale)</span>


<span class="s2">class </span><span class="s1">levy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Levy continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    levy_stable, levy_l 
 
    Notes 
    ----- 
    The probability density function for `levy` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{\sqrt{2\pi x^3}} \exp\left(-\frac{1}{2x}\right) 
 
    for :math:`x &gt; 0`. 
 
    This is the same as the Levy-stable distribution with :math:`a=1/2` and 
    :math:`b=1`. 
 
    %(after_notes)s 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import levy 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
 
    Calculate the first four moments: 
 
    &gt;&gt;&gt; mean, var, skew, kurt = levy.stats(moments='mvsk') 
 
    Display the probability density function (``pdf``): 
 
    &gt;&gt;&gt; # `levy` is very heavy-tailed. 
    &gt;&gt;&gt; # To show a nice plot, let's cut off the upper 40 percent. 
    &gt;&gt;&gt; a, b = levy.ppf(0), levy.ppf(0.6) 
    &gt;&gt;&gt; x = np.linspace(a, b, 100) 
    &gt;&gt;&gt; ax.plot(x, levy.pdf(x), 
    ...        'r-', lw=5, alpha=0.6, label='levy pdf') 
 
    Alternatively, the distribution object can be called (as a function) 
    to fix the shape, location and scale parameters. This returns a &quot;frozen&quot; 
    RV object holding the given parameters fixed. 
 
    Freeze the distribution and display the frozen ``pdf``: 
 
    &gt;&gt;&gt; rv = levy() 
    &gt;&gt;&gt; ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf') 
 
    Check accuracy of ``cdf`` and ``ppf``: 
 
    &gt;&gt;&gt; vals = levy.ppf([0.001, 0.5, 0.999]) 
    &gt;&gt;&gt; np.allclose([0.001, 0.5, 0.999], levy.cdf(vals)) 
    True 
 
    Generate random numbers: 
 
    &gt;&gt;&gt; r = levy.rvs(size=1000) 
 
    And compare the histogram: 
 
    &gt;&gt;&gt; # manual binning to ignore the tail 
    &gt;&gt;&gt; bins = np.concatenate((np.linspace(a, b, 20), [np.max(r)])) 
    &gt;&gt;&gt; ax.hist(r, bins=bins, density=True, histtype='stepfilled', alpha=0.2) 
    &gt;&gt;&gt; ax.set_xlim([x[0], x[-1]]) 
    &gt;&gt;&gt; ax.legend(loc='best', frameon=False) 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># levy.pdf(x) = 1 / (x * sqrt(2*pi*x)) * exp(-1/(2*x))</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">/ np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi*x) / x * np.exp(-</span><span class="s5">1</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*x))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># Equivalent to 2*norm.sf(np.sqrt(1/x))</span>
        <span class="s2">return </span><span class="s1">sc.erfc(np.sqrt(</span><span class="s5">0.5 </span><span class="s1">/ x))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.erf(np.sqrt(</span><span class="s5">0.5 </span><span class="s1">/ x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s0"># Equivalent to 1.0/(norm.isf(q/2)**2) or 0.5/(erfcinv(q)**2)</span>
        <span class="s1">val = _norm_isf(q/</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">/ (val * val)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*sc.erfinv(p)**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>


<span class="s1">levy = levy_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;levy&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">levy_l_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A left-skewed Levy continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    levy, levy_stable 
 
    Notes 
    ----- 
    The probability density function for `levy_l` is: 
 
    .. math:: 
        f(x) = \frac{1}{|x| \sqrt{2\pi |x|}} \exp{ \left(-\frac{1}{2|x|} \right)} 
 
    for :math:`x &lt; 0`. 
 
    This is the same as the Levy-stable distribution with :math:`a=1/2` and 
    :math:`b=-1`. 
 
    %(after_notes)s 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import levy_l 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
 
    Calculate the first four moments: 
 
    &gt;&gt;&gt; mean, var, skew, kurt = levy_l.stats(moments='mvsk') 
 
    Display the probability density function (``pdf``): 
 
    &gt;&gt;&gt; # `levy_l` is very heavy-tailed. 
    &gt;&gt;&gt; # To show a nice plot, let's cut off the lower 40 percent. 
    &gt;&gt;&gt; a, b = levy_l.ppf(0.4), levy_l.ppf(1) 
    &gt;&gt;&gt; x = np.linspace(a, b, 100) 
    &gt;&gt;&gt; ax.plot(x, levy_l.pdf(x), 
    ...        'r-', lw=5, alpha=0.6, label='levy_l pdf') 
 
    Alternatively, the distribution object can be called (as a function) 
    to fix the shape, location and scale parameters. This returns a &quot;frozen&quot; 
    RV object holding the given parameters fixed. 
 
    Freeze the distribution and display the frozen ``pdf``: 
 
    &gt;&gt;&gt; rv = levy_l() 
    &gt;&gt;&gt; ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf') 
 
    Check accuracy of ``cdf`` and ``ppf``: 
 
    &gt;&gt;&gt; vals = levy_l.ppf([0.001, 0.5, 0.999]) 
    &gt;&gt;&gt; np.allclose([0.001, 0.5, 0.999], levy_l.cdf(vals)) 
    True 
 
    Generate random numbers: 
 
    &gt;&gt;&gt; r = levy_l.rvs(size=1000) 
 
    And compare the histogram: 
 
    &gt;&gt;&gt; # manual binning to ignore the tail 
    &gt;&gt;&gt; bins = np.concatenate(([np.min(r)], np.linspace(a, b, 20))) 
    &gt;&gt;&gt; ax.hist(r, bins=bins, density=True, histtype='stepfilled', alpha=0.2) 
    &gt;&gt;&gt; ax.set_xlim([x[0], x[-1]]) 
    &gt;&gt;&gt; ax.legend(loc='best', frameon=False) 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># levy_l.pdf(x) = 1 / (abs(x) * sqrt(2*pi*abs(x))) * exp(-1/(2*abs(x)))</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s1">/np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi*ax)/ax*np.exp(-</span><span class="s5">1</span><span class="s1">/(</span><span class="s5">2</span><span class="s1">*ax))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">* _norm_cdf(</span><span class="s5">1 </span><span class="s1">/ np.sqrt(ax)) - </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">ax = abs(x)</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">* _norm_sf(</span><span class="s5">1 </span><span class="s1">/ np.sqrt(ax))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s1">val = _norm_ppf((q + </span><span class="s5">1.0</span><span class="s1">) / </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">1.0 </span><span class="s1">/ (val * val)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">1</span><span class="s1">/_norm_isf(p/</span><span class="s5">2</span><span class="s1">)**</span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>


<span class="s1">levy_l = levy_l_gen(b=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;levy_l&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">logistic_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A logistic (or Sech-squared) continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `logistic` is: 
 
    .. math:: 
 
        f(x) = \frac{\exp(-x)} 
                    {(1+\exp(-x))^2} 
 
    `logistic` is a special case of `genlogistic` with ``c=1``. 
 
    Remark that the survival function (``logistic.sf``) is equal to the 
    Fermi-Dirac distribution describing fermionic statistics. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.logistic(size=size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># logistic.pdf(x) = exp(-x) / (1+exp(-x))**2</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">y = -np.abs(x)</span>
        <span class="s2">return </span><span class="s1">y - </span><span class="s5">2. </span><span class="s1">* sc.log1p(np.exp(y))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.expit(x)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.log_expit(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">sc.logit(q)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.expit(-x)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.log_expit(-x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">-sc.logit(q)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.pi*np.pi/</span><span class="s5">3.0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">6.0</span><span class="s1">/</span><span class="s5">5.0</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s0"># https://en.wikipedia.org/wiki/Logistic_distribution</span>
        <span class="s2">return </span><span class="s5">2.0</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                         <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">n = len(data)</span>

        <span class="s0"># rv_continuous provided guesses</span>
        <span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = self._fitstart(data)</span>
        <span class="s0"># these are trumped by user-provided guesses</span>
        <span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = kwds.get(</span><span class="s4">'loc'</span><span class="s2">, </span><span class="s1">loc)</span><span class="s2">, </span><span class="s1">kwds.get(</span><span class="s4">'scale'</span><span class="s2">, </span><span class="s1">scale)</span>

        <span class="s0"># the maximum likelihood estimators `a` and `b` of the location and</span>
        <span class="s0"># scale parameters are roots of the two equations described in `func`.</span>
        <span class="s0"># Source: Statistical Distributions, 3rd Edition. Evans, Hastings, and</span>
        <span class="s0"># Peacock (2000), Page 130</span>

        <span class="s2">def </span><span class="s1">dl_dloc(loc</span><span class="s2">, </span><span class="s1">scale=fscale):</span>
            <span class="s1">c = (data - loc) / scale</span>
            <span class="s2">return </span><span class="s1">np.sum(sc.expit(c)) - n/</span><span class="s5">2</span>

        <span class="s2">def </span><span class="s1">dl_dscale(scale</span><span class="s2">, </span><span class="s1">loc=floc):</span>
            <span class="s1">c = (data - loc) / scale</span>
            <span class="s2">return </span><span class="s1">np.sum(c*np.tanh(c/</span><span class="s5">2</span><span class="s1">)) - n</span>

        <span class="s2">def </span><span class="s1">func(params):</span>
            <span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = params</span>
            <span class="s2">return </span><span class="s1">dl_dloc(loc</span><span class="s2">, </span><span class="s1">scale)</span><span class="s2">, </span><span class="s1">dl_dscale(scale</span><span class="s2">, </span><span class="s1">loc)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None and </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">res = optimize.root(dl_dloc</span><span class="s2">, </span><span class="s1">(loc</span><span class="s2">,</span><span class="s1">))</span>
            <span class="s1">loc = res.x[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">scale = fscale</span>
        <span class="s2">elif </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">res = optimize.root(dl_dscale</span><span class="s2">, </span><span class="s1">(scale</span><span class="s2">,</span><span class="s1">))</span>
            <span class="s1">scale = res.x[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">loc = floc</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res = optimize.root(func</span><span class="s2">, </span><span class="s1">(loc</span><span class="s2">, </span><span class="s1">scale))</span>
            <span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = res.x</span>

        <span class="s0"># Note: gh-18176 reported data for which the reported MLE had</span>
        <span class="s0"># `scale &lt; 0`. To fix the bug, we return abs(scale). This is OK because</span>
        <span class="s0"># `dl_dscale` and `dl_dloc` are even and odd functions of `scale`,</span>
        <span class="s0"># respectively, so if `-scale` is a solution, so is `scale`.</span>
        <span class="s1">scale = abs(scale)</span>
        <span class="s2">return </span><span class="s1">((loc</span><span class="s2">, </span><span class="s1">scale) </span><span class="s2">if </span><span class="s1">res.success</span>
                <span class="s2">else </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds))</span>


<span class="s1">logistic = logistic_gen(name=</span><span class="s4">'logistic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">loggamma_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A log gamma continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `loggamma` is: 
 
    .. math:: 
 
        f(x, c) = \frac{\exp(c x - \exp(x))} 
                       {\Gamma(c)} 
 
    for all :math:`x, c &gt; 0`. Here, :math:`\Gamma` is the 
    gamma function (`scipy.special.gamma`). 
 
    `loggamma` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># Use the property of the gamma distribution Gamma(c)</span>
        <span class="s0">#    Gamma(c) ~ Gamma(c + 1)*U**(1/c),</span>
        <span class="s0"># where U is uniform on [0, 1]. (See, e.g.,</span>
        <span class="s0"># G. Marsaglia and W.W. Tsang, &quot;A simple method for generating gamma</span>
        <span class="s0"># variables&quot;, https://doi.org/10.1145/358407.358414)</span>
        <span class="s0"># So</span>
        <span class="s0">#    log(Gamma(c)) ~ log(Gamma(c + 1)) + log(U)/c</span>
        <span class="s0"># Generating a sample with this formulation is a bit slower</span>
        <span class="s0"># than the more obvious log(Gamma(c)), but it avoids loss</span>
        <span class="s0"># of precision when c &lt;&lt; 1.</span>
        <span class="s2">return </span><span class="s1">(np.log(random_state.gamma(c + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">size=size))</span>
                <span class="s1">+ np.log(random_state.uniform(size=size))/c)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># loggamma.pdf(x, c) = exp(c*x-exp(x)) / gamma(c)</span>
        <span class="s2">return </span><span class="s1">np.exp(c*x-np.exp(x)-sc.gammaln(c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">c*x - np.exp(x) - sc.gammaln(c)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># This function is gammainc(c, exp(x)), where gammainc(c, z) is</span>
        <span class="s0"># the regularized incomplete gamma function.</span>
        <span class="s0"># The first term in a series expansion of gamminc(c, z) is</span>
        <span class="s0"># z**c/Gamma(c+1); see 6.5.29 of Abramowitz &amp; Stegun (and refer</span>
        <span class="s0"># back to 6.5.1, 6.5.2 and 6.5.4 for the relevant notation).</span>
        <span class="s0"># This can also be found in the wikipedia article</span>
        <span class="s0"># https://en.wikipedia.org/wiki/Incomplete_gamma_function.</span>
        <span class="s0"># Here we use that formula when x is sufficiently negative that</span>
        <span class="s0"># exp(x) will result in subnormal numbers and lose precision.</span>
        <span class="s0"># We evaluate the log of the expression first to allow the possible</span>
        <span class="s0"># cancellation of the terms in the division, and then exponentiate.</span>
        <span class="s0"># That is,</span>
        <span class="s0">#     exp(x)**c/Gamma(c+1) = exp(log(exp(x)**c/Gamma(c+1)))</span>
        <span class="s0">#                          = exp(c*x - gammaln(c+1))</span>
        <span class="s2">return </span><span class="s1">_lazywhere(x &lt; _LOGXMIN</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: np.exp(c*x - sc.gammaln(c+</span><span class="s5">1</span><span class="s1">))</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: sc.gammainc(c</span><span class="s2">, </span><span class="s1">np.exp(x)))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># The expression used when g &lt; _XMIN inverts the one term expansion</span>
        <span class="s0"># given in the comments of _cdf().</span>
        <span class="s1">g = sc.gammaincinv(c</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(g &lt; _XMIN</span><span class="s2">, </span><span class="s1">(g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c: (np.log(q) + sc.gammaln(c+</span><span class="s5">1</span><span class="s1">))/c</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c: np.log(g))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># See the comments for _cdf() for how x &lt; _LOGXMIN is handled.</span>
        <span class="s2">return </span><span class="s1">_lazywhere(x &lt; _LOGXMIN</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: -np.expm1(c*x - sc.gammaln(c+</span><span class="s5">1</span><span class="s1">))</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: sc.gammaincc(c</span><span class="s2">, </span><span class="s1">np.exp(x)))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># The expression used when g &lt; _XMIN inverts the complement of</span>
        <span class="s0"># the one term expansion given in the comments of _cdf().</span>
        <span class="s1">g = sc.gammainccinv(c</span><span class="s2">, </span><span class="s1">q)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(g &lt; _XMIN</span><span class="s2">, </span><span class="s1">(g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c: (np.log1p(-q) + sc.gammaln(c+</span><span class="s5">1</span><span class="s1">))/c</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">g</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c: np.log(g))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># See, for example, &quot;A Statistical Study of Log-Gamma Distribution&quot;, by</span>
        <span class="s0"># Ping Shing Chan (thesis, McMaster University, 1993).</span>
        <span class="s1">mean = sc.digamma(c)</span>
        <span class="s1">var = sc.polygamma(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s1">skewness = sc.polygamma(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c) / np.power(var</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">excess_kurtosis = sc.polygamma(</span><span class="s5">3</span><span class="s2">, </span><span class="s1">c) / (var*var)</span>
        <span class="s2">return </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">skewness</span><span class="s2">, </span><span class="s1">excess_kurtosis</span>


<span class="s1">loggamma = loggamma_gen(name=</span><span class="s4">'loggamma'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">loglaplace_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A log-Laplace continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `loglaplace` is: 
 
    .. math:: 
 
        f(x, c) = \begin{cases}\frac{c}{2} x^{ c-1}  &amp;\text{for } 0 &lt; x &lt; 1\\ 
                               \frac{c}{2} x^{-c-1}  &amp;\text{for } x \ge 1 
                  \end{cases} 
 
    for :math:`c &gt; 0`. 
 
    `loglaplace` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    T.J. Kozubowski and K. Podgorski, &quot;A log-Laplace growth rate model&quot;, 
    The Mathematical Scientist, vol. 28, pp. 49-60, 2003. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># loglaplace.pdf(x, c) = c / 2 * x**(c-1),   for 0 &lt; x &lt; 1</span>
        <span class="s0">#                      = c / 2 * x**(-c-1),  for x &gt;= 1</span>
        <span class="s1">cd2 = c/</span><span class="s5">2.0</span>
        <span class="s1">c = np.where(x &lt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">-c)</span>
        <span class="s2">return </span><span class="s1">cd2*x**(c-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.where(x &lt; </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">*x**c</span><span class="s2">, </span><span class="s5">1</span><span class="s1">-</span><span class="s5">0.5</span><span class="s1">*x**(-c))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.where(q &lt; </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2.0</span><span class="s1">*q)**(</span><span class="s5">1.0</span><span class="s1">/c)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1.0</span><span class="s1">-q))**(-</span><span class="s5">1.0</span><span class="s1">/c))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">c**</span><span class="s5">2 </span><span class="s1">/ (c**</span><span class="s5">2 </span><span class="s1">- n**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2.0</span><span class="s1">/c) + </span><span class="s5">1.0</span>


<span class="s1">loglaplace = loglaplace_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'loglaplace'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_lognorm_logpdf(x</span><span class="s2">, </span><span class="s1">s):</span>
    <span class="s2">return </span><span class="s1">_lazywhere(x != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">s)</span><span class="s2">,</span>
                      <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s: -np.log(x)**</span><span class="s5">2 </span><span class="s1">/ (</span><span class="s5">2</span><span class="s1">*s**</span><span class="s5">2</span><span class="s1">) - np.log(s*x*np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi))</span><span class="s2">,</span>
                      <span class="s1">-np.inf)</span>


<span class="s2">class </span><span class="s1">lognorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A lognormal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `lognorm` is: 
 
    .. math:: 
 
        f(x, s) = \frac{1}{s x \sqrt{2\pi}} 
                  \exp\left(-\frac{\log^2(x)}{2s^2}\right) 
 
    for :math:`x &gt; 0`, :math:`s &gt; 0`. 
 
    `lognorm` takes ``s`` as a shape parameter for :math:`s`. 
 
    %(after_notes)s 
 
    Suppose a normally distributed random variable ``X`` has  mean ``mu`` and 
    standard deviation ``sigma``. Then ``Y = exp(X)`` is lognormally 
    distributed with ``s = sigma`` and ``scale = exp(mu)``. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;s&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">np.exp(s * random_state.standard_normal(size))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s0"># lognorm.pdf(x, s) = 1 / (s*x*sqrt(2*pi)) * exp(-1/2*(log(x)/s)**2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">s))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_lognorm_logpdf(x</span><span class="s2">, </span><span class="s1">s)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(np.log(x) / s)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_norm_logcdf(np.log(x) / s)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">np.exp(s * _norm_ppf(q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(np.log(x) / s)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_norm_logsf(np.log(x) / s)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s1">p = np.exp(s*s)</span>
        <span class="s1">mu = np.sqrt(p)</span>
        <span class="s1">mu2 = p*(p-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g1 = np.sqrt(p-</span><span class="s5">1</span><span class="s1">)*(</span><span class="s5">2</span><span class="s1">+p)</span>
        <span class="s1">g2 = np.polyval([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6.0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ np.log(</span><span class="s5">2</span><span class="s1">*np.pi) + </span><span class="s5">2 </span><span class="s1">* np.log(s))</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">When `method='MLE'` and 
        the location parameter is fixed by using the `floc` argument, 
        this function uses explicit formulas for the maximum likelihood 
        estimation of the log-normal shape and scale parameters, so the 
        `optimizer`, `loc` and `scale` keyword arguments are ignored. 
        If the location is free, a likelihood maximum is found by 
        setting its partial derivative wrt to location to 0, and 
        solving by substituting the analytical expressions of shape 
        and scale (or provided parameters). 
        See, e.g., equation 3.1 in 
        A. Clifford Cohen &amp; Betty Jones Whitten (1980) 
        Estimation in the Three-Parameter Lognormal Distribution, 
        Journal of the American Statistical Association, 75:370, 399-404 
        https://doi.org/10.2307/2287466 
        </span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">parameters = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">fshape</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = parameters</span>
        <span class="s1">data_min = np.min(data)</span>

        <span class="s2">def </span><span class="s1">get_shape_scale(loc):</span>
            <span class="s0"># Calculate maximum likelihood scale and shape with analytical</span>
            <span class="s0"># formulas unless provided by the user</span>
            <span class="s2">if </span><span class="s1">fshape </span><span class="s2">is None or </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">lndata = np.log(data - loc)</span>
            <span class="s1">scale = fscale </span><span class="s2">or </span><span class="s1">np.exp(lndata.mean())</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">np.sqrt(np.mean((lndata - np.log(scale))**</span><span class="s5">2</span><span class="s1">))</span>
            <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">scale</span>

        <span class="s2">def </span><span class="s1">dL_dLoc(loc):</span>
            <span class="s0"># Derivative of (positive) LL w.r.t. loc</span>
            <span class="s1">shape</span><span class="s2">, </span><span class="s1">scale = get_shape_scale(loc)</span>
            <span class="s1">shifted = data - loc</span>
            <span class="s2">return </span><span class="s1">np.sum((</span><span class="s5">1 </span><span class="s1">+ np.log(shifted/scale)/shape**</span><span class="s5">2</span><span class="s1">)/shifted)</span>

        <span class="s2">def </span><span class="s1">ll(loc):</span>
            <span class="s0"># (Positive) log-likelihood</span>
            <span class="s1">shape</span><span class="s2">, </span><span class="s1">scale = get_shape_scale(loc)</span>
            <span class="s2">return </span><span class="s1">-self.nnlf((shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span><span class="s2">, </span><span class="s1">data)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># The location must be less than the minimum of the data.</span>
            <span class="s0"># Back off a bit to avoid numerical issues.</span>
            <span class="s1">spacing = np.spacing(data_min)</span>
            <span class="s1">rbrack = data_min - spacing</span>

            <span class="s0"># Find the right end of the bracket by successive doubling of the</span>
            <span class="s0"># distance to data_min. We're interested in a maximum LL, so the</span>
            <span class="s0"># slope dL_dLoc_rbrack should be negative at the right end.</span>
            <span class="s0"># optimization for later: share shape, scale</span>
            <span class="s1">dL_dLoc_rbrack = dL_dLoc(rbrack)</span>
            <span class="s1">ll_rbrack = ll(rbrack)</span>
            <span class="s1">delta = </span><span class="s5">2 </span><span class="s1">* spacing  </span><span class="s0"># 2 * (data_min - rbrack)</span>
            <span class="s2">while </span><span class="s1">dL_dLoc_rbrack &gt;= -</span><span class="s5">1e-6</span><span class="s1">:</span>
                <span class="s1">rbrack = data_min - delta</span>
                <span class="s1">dL_dLoc_rbrack = dL_dLoc(rbrack)</span>
                <span class="s1">delta *= </span><span class="s5">2</span>

            <span class="s2">if not </span><span class="s1">np.isfinite(rbrack) </span><span class="s2">or not </span><span class="s1">np.isfinite(dL_dLoc_rbrack):</span>
                <span class="s0"># If we never find a negative slope, either we missed it or the</span>
                <span class="s0"># slope is always positive. It's usually the latter,</span>
                <span class="s0"># which means</span>
                <span class="s0"># loc = data_min - spacing</span>
                <span class="s0"># But sometimes when shape and/or scale are fixed there are</span>
                <span class="s0"># other issues, so be cautious.</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

            <span class="s0"># Now find the left end of the bracket. Guess is `rbrack-1`</span>
            <span class="s0"># unless that is too small of a difference to resolve. Double</span>
            <span class="s0"># the size of the interval until the left end is found.</span>
            <span class="s1">lbrack = np.minimum(np.nextafter(rbrack</span><span class="s2">, </span><span class="s1">-np.inf)</span><span class="s2">, </span><span class="s1">rbrack-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">dL_dLoc_lbrack = dL_dLoc(lbrack)</span>
            <span class="s1">delta = </span><span class="s5">2 </span><span class="s1">* (rbrack - lbrack)</span>
            <span class="s2">while </span><span class="s1">(np.isfinite(lbrack) </span><span class="s2">and </span><span class="s1">np.isfinite(dL_dLoc_lbrack)</span>
                   <span class="s2">and </span><span class="s1">np.sign(dL_dLoc_lbrack) == np.sign(dL_dLoc_rbrack)):</span>
                <span class="s1">lbrack = rbrack - delta</span>
                <span class="s1">dL_dLoc_lbrack = dL_dLoc(lbrack)</span>
                <span class="s1">delta *= </span><span class="s5">2</span>

            <span class="s0"># I don't recall observing this, but just in case...</span>
            <span class="s2">if not </span><span class="s1">np.isfinite(lbrack) </span><span class="s2">or not </span><span class="s1">np.isfinite(dL_dLoc_lbrack):</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

            <span class="s0"># If we have a valid bracket, find the root</span>
            <span class="s1">res = root_scalar(dL_dLoc</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
            <span class="s2">if not </span><span class="s1">res.converged:</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

            <span class="s0"># If the slope was positive near the minimum of the data,</span>
            <span class="s0"># the maximum LL could be there instead of at the root. Compare</span>
            <span class="s0"># the LL of the two points to decide.</span>
            <span class="s1">ll_root = ll(res.root)</span>
            <span class="s1">loc = res.root </span><span class="s2">if </span><span class="s1">ll_root &gt; ll_rbrack </span><span class="s2">else </span><span class="s1">data_min-spacing</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">floc &gt;= data_min:</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;lognorm&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">0.</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>
            <span class="s1">loc = floc</span>

        <span class="s1">shape</span><span class="s2">, </span><span class="s1">scale = get_shape_scale(loc)</span>
        <span class="s2">if not </span><span class="s1">(self._argcheck(shape) </span><span class="s2">and </span><span class="s1">scale &gt; </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>


<span class="s1">lognorm = lognorm_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'lognorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gibrat_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Gibrat continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `gibrat` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{x \sqrt{2\pi}} \exp(-\frac{1}{2} (\log(x))^2) 
 
    `gibrat` is a special case of `lognorm` with ``s=1``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">np.exp(random_state.standard_normal(size))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># gibrat.pdf(x) = 1/(x*sqrt(2*pi)) * exp(-1/2*(log(x))**2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_lognorm_logpdf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(np.log(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.exp(_norm_ppf(q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">_norm_sf(np.log(x))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">np.exp(_norm_isf(p))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s1">p = np.e</span>
        <span class="s1">mu = np.sqrt(p)</span>
        <span class="s1">mu2 = p * (p - </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g1 = np.sqrt(p - </span><span class="s5">1</span><span class="s1">) * (</span><span class="s5">2 </span><span class="s1">+ p)</span>
        <span class="s1">g2 = np.polyval([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6.0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* np.log(</span><span class="s5">2 </span><span class="s1">* np.pi) + </span><span class="s5">0.5</span>


<span class="s1">gibrat = gibrat_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'gibrat'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">maxwell_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Maxwell continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    A special case of a `chi` distribution,  with ``df=3``, ``loc=0.0``, 
    and given ``scale = a``, where ``a`` is the parameter used in the 
    Mathworld description [1]_. 
 
    The probability density function for `maxwell` is: 
 
    .. math:: 
 
        f(x) = \sqrt{2/\pi}x^2 \exp(-x^2/2) 
 
    for :math:`x &gt;= 0`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] http://mathworld.wolfram.com/MaxwellDistribution.html 
 
    %(example)s 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">chi.rvs(</span><span class="s5">3.0</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># maxwell.pdf(x) = sqrt(2/pi)x**2 * exp(-x**2/2)</span>
        <span class="s2">return </span><span class="s1">_SQRT_2_OVER_PI*x*x*np.exp(-x*x/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># Allow x=0 without 'divide by zero' warnings</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">_LOG_SQRT_2_OVER_PI + </span><span class="s5">2</span><span class="s1">*np.log(x) - </span><span class="s5">0.5</span><span class="s1">*x*x</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">x*x/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">*sc.gammaincinv(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">x*x/</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">*sc.gammainccinv(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">q))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s1">val = </span><span class="s5">3</span><span class="s1">*np.pi-</span><span class="s5">8</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">2</span><span class="s1">*np.sqrt(</span><span class="s5">2.0</span><span class="s1">/np.pi)</span><span class="s2">,</span>
                <span class="s5">3</span><span class="s1">-</span><span class="s5">8</span><span class="s1">/np.pi</span><span class="s2">,</span>
                <span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">)*(</span><span class="s5">32</span><span class="s1">-</span><span class="s5">10</span><span class="s1">*np.pi)/val**</span><span class="s5">1.5</span><span class="s2">,</span>
                <span class="s1">(-</span><span class="s5">12</span><span class="s1">*np.pi*np.pi + </span><span class="s5">160</span><span class="s1">*np.pi - </span><span class="s5">384</span><span class="s1">) / val**</span><span class="s5">2.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">_EULER + </span><span class="s5">0.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">*np.pi)-</span><span class="s5">0.5</span>


<span class="s1">maxwell = maxwell_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'maxwell'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">mielke_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Mielke Beta-Kappa / Dagum continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `mielke` is: 
 
    .. math:: 
 
        f(x, k, s) = \frac{k x^{k-1}}{(1+x^s)^{1+k/s}} 
 
    for :math:`x &gt; 0` and :math:`k, s &gt; 0`. The distribution is sometimes 
    called Dagum distribution ([2]_). It was already defined in [3]_, called 
    a Burr Type III distribution (`burr` with parameters ``c=s`` and 
    ``d=k/s``). 
 
    `mielke` takes ``k`` and ``s`` as shape parameters. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Mielke, P.W., 1973 &quot;Another Family of Distributions for Describing 
           and Analyzing Precipitation Data.&quot; J. Appl. Meteor., 12, 275-280 
    .. [2] Dagum, C., 1977 &quot;A new model for personal income distribution.&quot; 
           Economie Appliquee, 33, 327-367. 
    .. [3] Burr, I. W. &quot;Cumulative frequency functions&quot;, Annals of 
           Mathematical Statistics, 13(2), pp 215-232 (1942). 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ik = _ShapeInfo(</span><span class="s4">&quot;k&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">i_s = _ShapeInfo(</span><span class="s4">&quot;s&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ik</span><span class="s2">, </span><span class="s1">i_s]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">k*x**(k-</span><span class="s5">1.0</span><span class="s1">) / (</span><span class="s5">1.0</span><span class="s1">+x**s)**(</span><span class="s5">1.0</span><span class="s1">+k*</span><span class="s5">1.0</span><span class="s1">/s)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s0"># Allow x=0 without 'divide by zero' warnings.</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">np.log(k) + np.log(x)*(k - </span><span class="s5">1</span><span class="s1">) - np.log1p(x**s)*(</span><span class="s5">1 </span><span class="s1">+ k/s)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">x**k / (</span><span class="s5">1.0</span><span class="s1">+x**s)**(k*</span><span class="s5">1.0</span><span class="s1">/s)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s1">qsk = pow(q</span><span class="s2">, </span><span class="s1">s*</span><span class="s5">1.0</span><span class="s1">/k)</span>
        <span class="s2">return </span><span class="s1">pow(qsk/(</span><span class="s5">1.0</span><span class="s1">-qsk)</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/s)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">def </span><span class="s1">nth_moment(n</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s):</span>
            <span class="s0"># n-th moment is defined for -k &lt; n &lt; s</span>
            <span class="s2">return </span><span class="s1">sc.gamma((k+n)/s)*sc.gamma(</span><span class="s5">1</span><span class="s1">-n/s)/sc.gamma(k/s)</span>

        <span class="s2">return </span><span class="s1">_lazywhere(n &lt; s</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s)</span><span class="s2">, </span><span class="s1">nth_moment</span><span class="s2">, </span><span class="s1">np.inf)</span>


<span class="s1">mielke = mielke_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'mielke'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">kappa4_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Kappa 4 parameter distribution. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for kappa4 is: 
 
    .. math:: 
 
        f(x, h, k) = (1 - k x)^{1/k - 1} (1 - h (1 - k x)^{1/k})^{1/h-1} 
 
    if :math:`h` and :math:`k` are not equal to 0. 
 
    If :math:`h` or :math:`k` are zero then the pdf can be simplified: 
 
    h = 0 and k != 0:: 
 
        kappa4.pdf(x, h, k) = (1.0 - k*x)**(1.0/k - 1.0)* 
                              exp(-(1.0 - k*x)**(1.0/k)) 
 
    h != 0 and k = 0:: 
 
        kappa4.pdf(x, h, k) = exp(-x)*(1.0 - h*exp(-x))**(1.0/h - 1.0) 
 
    h = 0 and k = 0:: 
 
        kappa4.pdf(x, h, k) = exp(-x)*exp(-exp(-x)) 
 
    kappa4 takes :math:`h` and :math:`k` as shape parameters. 
 
    The kappa4 distribution returns other distributions when certain 
    :math:`h` and :math:`k` values are used. 
 
    +------+-------------+----------------+------------------+ 
    | h    | k=0.0       | k=1.0          | -inf&lt;=k&lt;=inf     | 
    +======+=============+================+==================+ 
    | -1.0 | Logistic    |                | Generalized      | 
    |      |             |                | Logistic(1)      | 
    |      |             |                |                  | 
    |      | logistic(x) |                |                  | 
    +------+-------------+----------------+------------------+ 
    |  0.0 | Gumbel      | Reverse        | Generalized      | 
    |      |             | Exponential(2) | Extreme Value    | 
    |      |             |                |                  | 
    |      | gumbel_r(x) |                | genextreme(x, k) | 
    +------+-------------+----------------+------------------+ 
    |  1.0 | Exponential | Uniform        | Generalized      | 
    |      |             |                | Pareto           | 
    |      |             |                |                  | 
    |      | expon(x)    | uniform(x)     | genpareto(x, -k) | 
    +------+-------------+----------------+------------------+ 
 
    (1) There are at least five generalized logistic distributions. 
        Four are described here: 
        https://en.wikipedia.org/wiki/Generalized_logistic_distribution 
        The &quot;fifth&quot; one is the one kappa4 should match which currently 
        isn't implemented in scipy: 
        https://en.wikipedia.org/wiki/Talk:Generalized_logistic_distribution 
        https://www.mathwave.com/help/easyfit/html/analyses/distributions/gen_logistic.html 
    (2) This distribution is currently not in scipy. 
 
    References 
    ---------- 
    J.C. Finney, &quot;Optimization of a Skewed Logistic Distribution With Respect 
    to the Kolmogorov-Smirnov Test&quot;, A Dissertation Submitted to the Graduate 
    Faculty of the Louisiana State University and Agricultural and Mechanical 
    College, (August, 2004), 
    https://digitalcommons.lsu.edu/gradschool_dissertations/3672 
 
    J.R.M. Hosking, &quot;The four-parameter kappa distribution&quot;. IBM J. Res. 
    Develop. 38 (3), 25 1-258 (1994). 
 
    B. Kumphon, A. Kaew-Man, P. Seenoi, &quot;A Rainfall Distribution for the Lampao 
    Site in the Chi River Basin, Thailand&quot;, Journal of Water Resource and 
    Protection, vol. 4, 866-869, (2012). 
    :doi:`10.4236/jwarp.2012.410101` 
 
    C. Winchester, &quot;On Estimation of the Four-Parameter Kappa Distribution&quot;, A 
    Thesis Submitted to Dalhousie University, Halifax, Nova Scotia, (March 
    2000). 
    http://www.nlc-bnc.ca/obj/s4/f2/dsk2/ftp01/MQ57336.pdf 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">shape = np.broadcast_arrays(h</span><span class="s2">, </span><span class="s1">k)[</span><span class="s5">0</span><span class="s1">].shape</span>
        <span class="s2">return </span><span class="s1">np.full(shape</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ih = _ShapeInfo(</span><span class="s4">&quot;h&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ik = _ShapeInfo(</span><span class="s4">&quot;k&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ih</span><span class="s2">, </span><span class="s1">ik]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">condlist = [np.logical_and(h &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k &gt; </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k &lt; </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h &lt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k &gt; </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h &lt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h &lt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k &lt; </span><span class="s5">0</span><span class="s1">)]</span>

        <span class="s2">def </span><span class="s1">f0(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">1.0 </span><span class="s1">- np.float_power(h</span><span class="s2">, </span><span class="s1">-k))/k</span>

        <span class="s2">def </span><span class="s1">f1(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s1">np.log(h)</span>

        <span class="s2">def </span><span class="s1">f3(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s1">a = np.empty(np.shape(h))</span>
            <span class="s1">a[:] = -np.inf</span>
            <span class="s2">return </span><span class="s1">a</span>

        <span class="s2">def </span><span class="s1">f5(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/k</span>

        <span class="s1">_a = _lazyselect(condlist</span><span class="s2">,</span>
                         <span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f0</span><span class="s2">, </span><span class="s1">f3</span><span class="s2">, </span><span class="s1">f3</span><span class="s2">, </span><span class="s1">f5]</span><span class="s2">,</span>
                         <span class="s1">[h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">,</span>
                         <span class="s1">default=np.nan)</span>

        <span class="s2">def </span><span class="s1">f0(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/k</span>

        <span class="s2">def </span><span class="s1">f1(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s1">a = np.empty(np.shape(h))</span>
            <span class="s1">a[:] = np.inf</span>
            <span class="s2">return </span><span class="s1">a</span>

        <span class="s1">_b = _lazyselect(condlist</span><span class="s2">,</span>
                         <span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f1]</span><span class="s2">,</span>
                         <span class="s1">[h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">,</span>
                         <span class="s1">default=np.nan)</span>
        <span class="s2">return </span><span class="s1">_a</span><span class="s2">, </span><span class="s1">_b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s0"># kappa4.pdf(x, h, k) = (1.0 - k*x)**(1.0/k - 1.0)*</span>
        <span class="s0">#                       (1.0 - h*(1.0 - k*x)**(1.0/k))**(1.0/h-1)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">condlist = [np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)]</span>

        <span class="s2">def </span><span class="s1">f0(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''pdf = (1.0 - k*x)**(1.0/k - 1.0)*( 
                      1.0 - h*(1.0 - k*x)**(1.0/k))**(1.0/h-1.0) 
               logpdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">(sc.xlog1py(</span><span class="s5">1.0</span><span class="s1">/k - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-k*x) +</span>
                    <span class="s1">sc.xlog1py(</span><span class="s5">1.0</span><span class="s1">/h - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-h*(</span><span class="s5">1.0 </span><span class="s1">- k*x)**(</span><span class="s5">1.0</span><span class="s1">/k)))</span>

        <span class="s2">def </span><span class="s1">f1(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''pdf = (1.0 - k*x)**(1.0/k - 1.0)*np.exp(-( 
                      1.0 - k*x)**(1.0/k)) 
               logpdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">sc.xlog1py(</span><span class="s5">1.0</span><span class="s1">/k - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-k*x) - (</span><span class="s5">1.0 </span><span class="s1">- k*x)**(</span><span class="s5">1.0</span><span class="s1">/k)</span>

        <span class="s2">def </span><span class="s1">f2(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''pdf = np.exp(-x)*(1.0 - h*np.exp(-x))**(1.0/h - 1.0) 
               logpdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">-x + sc.xlog1py(</span><span class="s5">1.0</span><span class="s1">/h - </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-h*np.exp(-x))</span>

        <span class="s2">def </span><span class="s1">f3(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''pdf = np.exp(-x-np.exp(-x)) 
               logpdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">-x - np.exp(-x)</span>

        <span class="s2">return </span><span class="s1">_lazyselect(condlist</span><span class="s2">,</span>
                           <span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f2</span><span class="s2">, </span><span class="s1">f3]</span><span class="s2">,</span>
                           <span class="s1">[x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">,</span>
                           <span class="s1">default=np.nan)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logcdf(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k))</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">condlist = [np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)]</span>

        <span class="s2">def </span><span class="s1">f0(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''cdf = (1.0 - h*(1.0 - k*x)**(1.0/k))**(1.0/h) 
               logcdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">1.0</span><span class="s1">/h)*sc.log1p(-h*(</span><span class="s5">1.0 </span><span class="s1">- k*x)**(</span><span class="s5">1.0</span><span class="s1">/k))</span>

        <span class="s2">def </span><span class="s1">f1(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''cdf = np.exp(-(1.0 - k*x)**(1.0/k)) 
               logcdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">-(</span><span class="s5">1.0 </span><span class="s1">- k*x)**(</span><span class="s5">1.0</span><span class="s1">/k)</span>

        <span class="s2">def </span><span class="s1">f2(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''cdf = (1.0 - h*np.exp(-x))**(1.0/h) 
               logcdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">1.0</span><span class="s1">/h)*sc.log1p(-h*np.exp(-x))</span>

        <span class="s2">def </span><span class="s1">f3(x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''cdf = np.exp(-np.exp(-x)) 
               logcdf = ... 
            '''</span>
            <span class="s2">return </span><span class="s1">-np.exp(-x)</span>

        <span class="s2">return </span><span class="s1">_lazyselect(condlist</span><span class="s2">,</span>
                           <span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f2</span><span class="s2">, </span><span class="s1">f3]</span><span class="s2">,</span>
                           <span class="s1">[x</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">,</span>
                           <span class="s1">default=np.nan)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">condlist = [np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k != </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h != </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">np.logical_and(h == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k == </span><span class="s5">0</span><span class="s1">)]</span>

        <span class="s2">def </span><span class="s1">f0(q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/k*(</span><span class="s5">1.0 </span><span class="s1">- ((</span><span class="s5">1.0 </span><span class="s1">- (q**h))/h)**k)</span>

        <span class="s2">def </span><span class="s1">f1(q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/k*(</span><span class="s5">1.0 </span><span class="s1">- (-np.log(q))**k)</span>

        <span class="s2">def </span><span class="s1">f2(q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s3">'''ppf = -np.log((1.0 - (q**h))/h) 
            '''</span>
            <span class="s2">return </span><span class="s1">-sc.log1p(-(q**h)) + np.log(h)</span>

        <span class="s2">def </span><span class="s1">f3(q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s1">-np.log(-np.log(q))</span>

        <span class="s2">return </span><span class="s1">_lazyselect(condlist</span><span class="s2">,</span>
                           <span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1</span><span class="s2">, </span><span class="s1">f2</span><span class="s2">, </span><span class="s1">f3]</span><span class="s2">,</span>
                           <span class="s1">[q</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">,</span>
                           <span class="s1">default=np.nan)</span>

    <span class="s2">def </span><span class="s1">_get_stats_info(self</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">condlist = [</span>
            <span class="s1">np.logical_and(h &lt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">k &gt;= </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">k &lt; </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">]</span>

        <span class="s2">def </span><span class="s1">f0(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s1">(-</span><span class="s5">1.0</span><span class="s1">/h*k).astype(int)</span>

        <span class="s2">def </span><span class="s1">f1(h</span><span class="s2">, </span><span class="s1">k):</span>
            <span class="s2">return </span><span class="s1">(-</span><span class="s5">1.0</span><span class="s1">/k).astype(int)</span>

        <span class="s2">return </span><span class="s1">_lazyselect(condlist</span><span class="s2">, </span><span class="s1">[f0</span><span class="s2">, </span><span class="s1">f1]</span><span class="s2">, </span><span class="s1">[h</span><span class="s2">, </span><span class="s1">k]</span><span class="s2">, </span><span class="s1">default=</span><span class="s5">5</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">h</span><span class="s2">, </span><span class="s1">k):</span>
        <span class="s1">maxr = self._get_stats_info(h</span><span class="s2">, </span><span class="s1">k)</span>
        <span class="s1">outputs = [</span><span class="s2">None if </span><span class="s1">np.any(r &lt; maxr) </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)]</span>
        <span class="s2">return </span><span class="s1">outputs[:]</span>

    <span class="s2">def </span><span class="s1">_mom1_sc(self</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">*args):</span>
        <span class="s1">maxr = self._get_stats_info(args[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">args[</span><span class="s5">1</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">m &gt;= maxr:</span>
            <span class="s2">return </span><span class="s1">np.nan</span>
        <span class="s2">return </span><span class="s1">integrate.quad(self._mom_integ1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">args=(m</span><span class="s2">,</span><span class="s1">)+args)[</span><span class="s5">0</span><span class="s1">]</span>


<span class="s1">kappa4 = kappa4_gen(name=</span><span class="s4">'kappa4'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">kappa3_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;Kappa 3 parameter distribution. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `kappa3` is: 
 
    .. math:: 
 
        f(x, a) = a (a + x^a)^{-(a + 1)/a} 
 
    for :math:`x &gt; 0` and :math:`a &gt; 0`. 
 
    `kappa3` takes ``a`` as a shape parameter for :math:`a`. 
 
    References 
    ---------- 
    P.W. Mielke and E.S. Johnson, &quot;Three-Parameter Kappa Distribution Maximum 
    Likelihood and Likelihood Ratio Tests&quot;, Methods in Weather Research, 
    701-707, (September, 1973), 
    :doi:`10.1175/1520-0493(1973)101&lt;0701:TKDMLE&gt;2.3.CO;2` 
 
    B. Kumphon, &quot;Maximum Entropy and Maximum Likelihood Estimation for the 
    Three-Parameter Kappa Distribution&quot;, Open Journal of Statistics, vol 2, 
    415-419 (2012), :doi:`10.4236/ojs.2012.24050` 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># kappa3.pdf(x, a) = a*(a + x**a)**(-(a + 1)/a),     for x &gt; 0</span>
        <span class="s2">return </span><span class="s1">a*(a + x**a)**(-</span><span class="s5">1.0</span><span class="s1">/a-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">x*(a + x**a)**(-</span><span class="s5">1.0</span><span class="s1">/a)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">(a/(q**-a - </span><span class="s5">1.0</span><span class="s1">))**(</span><span class="s5">1.0</span><span class="s1">/a)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">outputs = [</span><span class="s2">None if </span><span class="s1">np.any(i &lt; a) </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)]</span>
        <span class="s2">return </span><span class="s1">outputs[:]</span>

    <span class="s2">def </span><span class="s1">_mom1_sc(self</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">*args):</span>
        <span class="s2">if </span><span class="s1">np.any(m &gt;= args[</span><span class="s5">0</span><span class="s1">]):</span>
            <span class="s2">return </span><span class="s1">np.nan</span>
        <span class="s2">return </span><span class="s1">integrate.quad(self._mom_integ1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">args=(m</span><span class="s2">,</span><span class="s1">)+args)[</span><span class="s5">0</span><span class="s1">]</span>


<span class="s1">kappa3 = kappa3_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'kappa3'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">moyal_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Moyal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `moyal` is: 
 
    .. math:: 
 
        f(x) = \exp(-(x + \exp(-x))/2) / \sqrt{2\pi} 
 
    for a real number :math:`x`. 
 
    %(after_notes)s 
 
    This distribution has utility in high-energy physics and radiation 
    detection. It describes the energy loss of a charged relativistic 
    particle due to ionization of the medium [1]_. It also provides an 
    approximation for the Landau distribution. For an in depth description 
    see [2]_. For additional description, see [3]_. 
 
    References 
    ---------- 
    .. [1] J.E. Moyal, &quot;XXX. Theory of ionization fluctuations&quot;, 
           The London, Edinburgh, and Dublin Philosophical Magazine 
           and Journal of Science, vol 46, 263-280, (1955). 
           :doi:`10.1080/14786440308521076` (gated) 
    .. [2] G. Cordeiro et al., &quot;The beta Moyal: a useful skew distribution&quot;, 
           International Journal of Research and Reviews in Applied Sciences, 
           vol 10, 171-192, (2012). 
           http://www.arpapress.com/Volumes/Vol10Issue2/IJRRAS_10_2_02.pdf 
    .. [3] C. Walck, &quot;Handbook on Statistical Distributions for 
           Experimentalists; International Report SUF-PFY/96-01&quot;, Chapter 26, 
           University of Stockholm: Stockholm, Sweden, (2007). 
           http://www.stat.rice.edu/~dobelman/textfiles/DistributionsHandbook.pdf 
 
    .. versionadded:: 1.1.0 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">u1 = gamma.rvs(a=</span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">scale=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">,</span>
                       <span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">-np.log(u1)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(-</span><span class="s5">0.5 </span><span class="s1">* (x + np.exp(-x))) / np.sqrt(</span><span class="s5">2</span><span class="s1">*np.pi)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.erfc(np.exp(-</span><span class="s5">0.5 </span><span class="s1">* x) / np.sqrt(</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">sc.erf(np.exp(-</span><span class="s5">0.5 </span><span class="s1">* x) / np.sqrt(</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">-np.log(</span><span class="s5">2 </span><span class="s1">* sc.erfcinv(x)**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s1">mu = np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma</span>
        <span class="s1">mu2 = np.pi**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2</span>
        <span class="s1">g1 = </span><span class="s5">28 </span><span class="s1">* np.sqrt(</span><span class="s5">2</span><span class="s1">) * sc.zeta(</span><span class="s5">3</span><span class="s1">) / np.pi**</span><span class="s5">3</span>
        <span class="s1">g2 = </span><span class="s5">4.</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">1.0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma</span>
        <span class="s2">elif </span><span class="s1">n == </span><span class="s5">2.0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.pi**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2 </span><span class="s1">+ (np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma)**</span><span class="s5">2</span>
        <span class="s2">elif </span><span class="s1">n == </span><span class="s5">3.0</span><span class="s1">:</span>
            <span class="s1">tmp1 = </span><span class="s5">1.5 </span><span class="s1">* np.pi**</span><span class="s5">2 </span><span class="s1">* (np.log(</span><span class="s5">2</span><span class="s1">)+np.euler_gamma)</span>
            <span class="s1">tmp2 = (np.log(</span><span class="s5">2</span><span class="s1">)+np.euler_gamma)**</span><span class="s5">3</span>
            <span class="s1">tmp3 = </span><span class="s5">14 </span><span class="s1">* sc.zeta(</span><span class="s5">3</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">tmp1 + tmp2 + tmp3</span>
        <span class="s2">elif </span><span class="s1">n == </span><span class="s5">4.0</span><span class="s1">:</span>
            <span class="s1">tmp1 = </span><span class="s5">4 </span><span class="s1">* </span><span class="s5">14 </span><span class="s1">* sc.zeta(</span><span class="s5">3</span><span class="s1">) * (np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma)</span>
            <span class="s1">tmp2 = </span><span class="s5">3 </span><span class="s1">* np.pi**</span><span class="s5">2 </span><span class="s1">* (np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma)**</span><span class="s5">2</span>
            <span class="s1">tmp3 = (np.log(</span><span class="s5">2</span><span class="s1">) + np.euler_gamma)**</span><span class="s5">4</span>
            <span class="s1">tmp4 = </span><span class="s5">7 </span><span class="s1">* np.pi**</span><span class="s5">4 </span><span class="s1">/ </span><span class="s5">4</span>
            <span class="s2">return </span><span class="s1">tmp1 + tmp2 + tmp3 + tmp4</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># return generic for higher moments</span>
            <span class="s0"># return rv_continuous._mom1_sc(self, n, b)</span>
            <span class="s2">return </span><span class="s1">self._mom1_sc(n)</span>


<span class="s1">moyal = moyal_gen(name=</span><span class="s4">&quot;moyal&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">nakagami_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Nakagami continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `nakagami` is: 
 
    .. math:: 
 
        f(x, \nu) = \frac{2 \nu^\nu}{\Gamma(\nu)} x^{2\nu-1} \exp(-\nu x^2) 
 
    for :math:`x &gt;= 0`, :math:`\nu &gt; 0`. The distribution was introduced in 
    [2]_, see also [1]_ for further information. 
 
    `nakagami` takes ``nu`` as a shape parameter for :math:`\nu`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Nakagami distribution&quot;, Wikipedia 
           https://en.wikipedia.org/wiki/Nakagami_distribution 
    .. [2] M. Nakagami, &quot;The m-distribution - A general formula of intensity 
           distribution of rapid fading&quot;, Statistical methods in radio wave 
           propagation, Pergamon Press, 1960, 3-36. 
           :doi:`10.1016/B978-0-08-009306-2.50005-4` 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">nu &gt; </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;nu&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">nu))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s0"># nakagami.pdf(x, nu) = 2 * nu**nu / gamma(nu) *</span>
        <span class="s0">#                       x**(2*nu-1) * exp(-nu*x**2)</span>
        <span class="s2">return </span><span class="s1">(np.log(</span><span class="s5">2</span><span class="s1">) + sc.xlogy(nu</span><span class="s2">, </span><span class="s1">nu) - sc.gammaln(nu) +</span>
                <span class="s1">sc.xlogy(</span><span class="s5">2</span><span class="s1">*nu - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x) - nu*x**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(nu</span><span class="s2">, </span><span class="s1">nu*x*x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">1.0</span><span class="s1">/nu*sc.gammaincinv(nu</span><span class="s2">, </span><span class="s1">q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(nu</span><span class="s2">, </span><span class="s1">nu*x*x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(</span><span class="s5">1</span><span class="s1">/nu * sc.gammainccinv(nu</span><span class="s2">, </span><span class="s1">p))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s1">mu = sc.gamma(nu+</span><span class="s5">0.5</span><span class="s1">)/sc.gamma(nu)/np.sqrt(nu)</span>
        <span class="s1">mu2 = </span><span class="s5">1.0</span><span class="s1">-mu*mu</span>
        <span class="s1">g1 = mu * (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">4</span><span class="s1">*nu*mu2) / </span><span class="s5">2.0 </span><span class="s1">/ nu / np.power(mu2</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">g2 = -</span><span class="s5">6</span><span class="s1">*mu**</span><span class="s5">4</span><span class="s1">*nu + (</span><span class="s5">8</span><span class="s1">*nu-</span><span class="s5">2</span><span class="s1">)*mu**</span><span class="s5">2</span><span class="s1">-</span><span class="s5">2</span><span class="s1">*nu + </span><span class="s5">1</span>
        <span class="s1">g2 /= nu*mu2**</span><span class="s5">2.0</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">nu):</span>
        <span class="s1">shape = np.shape(nu)</span>
        <span class="s0"># because somehow this isn't taken care of by the infrastructure...</span>
        <span class="s1">nu = np.atleast_1d(nu)</span>
        <span class="s1">A = sc.gammaln(nu)</span>
        <span class="s1">B = nu - (nu - </span><span class="s5">0.5</span><span class="s1">) * sc.digamma(nu)</span>
        <span class="s1">C = -</span><span class="s5">0.5 </span><span class="s1">* np.log(nu) - np.log(</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">h = A + B + C</span>
        <span class="s0"># This is the asymptotic sum of A and B (see gh-17868)</span>
        <span class="s1">norm_entropy = stats.norm._entropy()</span>
        <span class="s0"># Above, this is lost to rounding error for large nu, so use the</span>
        <span class="s0"># asymptotic sum when the approximation becomes accurate</span>
        <span class="s1">i = nu &gt; </span><span class="s5">5e4  </span><span class="s0"># roundoff error ~ approximation error</span>
        <span class="s0"># -1 / (12 * nu) is the O(1/nu) term; see gh-17929</span>
        <span class="s1">h[i] = C[i] + norm_entropy - </span><span class="s5">1</span><span class="s1">/(</span><span class="s5">12</span><span class="s1">*nu[i])</span>
        <span class="s2">return </span><span class="s1">h.reshape(shape)[()]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># this relationship can be found in [1] or by a direct calculation</span>
        <span class="s2">return </span><span class="s1">np.sqrt(random_state.standard_gamma(nu</span><span class="s2">, </span><span class="s1">size=size) / nu)</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s2">if </span><span class="s1">args </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">args = (</span><span class="s5">1.0</span><span class="s2">,</span><span class="s1">) * self.numargs</span>
        <span class="s0"># Analytical justified estimates</span>
        <span class="s0"># see: https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous_nakagami.html</span>
        <span class="s1">loc = np.min(data)</span>
        <span class="s1">scale = np.sqrt(np.sum((data - loc)**</span><span class="s5">2</span><span class="s1">) / len(data))</span>
        <span class="s2">return </span><span class="s1">args + (loc</span><span class="s2">, </span><span class="s1">scale)</span>


<span class="s1">nakagami = nakagami_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;nakagami&quot;</span><span class="s1">)</span>


<span class="s0"># The function name ncx2 is an abbreviation for noncentral chi squared.</span>
<span class="s2">def </span><span class="s1">_ncx2_log_pdf(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
    <span class="s0"># We use (xs**2 + ns**2)/2 = (xs - ns)**2/2  + xs*ns, and include the</span>
    <span class="s0"># factor of exp(-xs*ns) into the ive function to improve numerical</span>
    <span class="s0"># stability at large values of xs. See also `rice.pdf`.</span>
    <span class="s1">df2 = df/</span><span class="s5">2.0 </span><span class="s1">- </span><span class="s5">1.0</span>
    <span class="s1">xs</span><span class="s2">, </span><span class="s1">ns = np.sqrt(x)</span><span class="s2">, </span><span class="s1">np.sqrt(nc)</span>
    <span class="s1">res = sc.xlogy(df2/</span><span class="s5">2.0</span><span class="s2">, </span><span class="s1">x/nc) - </span><span class="s5">0.5</span><span class="s1">*(xs - ns)**</span><span class="s5">2</span>
    <span class="s1">corr = sc.ive(df2</span><span class="s2">, </span><span class="s1">xs*ns) / </span><span class="s5">2.0</span>
    <span class="s0"># Return res + np.log(corr) avoiding np.log(0)</span>
    <span class="s2">return </span><span class="s1">_lazywhere(</span>
        <span class="s1">corr &gt; </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">(res</span><span class="s2">, </span><span class="s1">corr)</span><span class="s2">,</span>
        <span class="s1">f=</span><span class="s2">lambda </span><span class="s1">r</span><span class="s2">, </span><span class="s1">c: r + np.log(c)</span><span class="s2">,</span>
        <span class="s1">fillvalue=-np.inf)</span>


<span class="s2">class </span><span class="s1">ncx2_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A non-central chi-squared continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `ncx2` is: 
 
    .. math:: 
 
        f(x, k, \lambda) = \frac{1}{2} \exp(-(\lambda+x)/2) 
            (x/\lambda)^{(k-2)/4}  I_{(k-2)/2}(\sqrt{\lambda x}) 
 
    for :math:`x &gt;= 0`, :math:`k &gt; 0` and :math:`\lambda \ge 0`. 
    :math:`k` specifies the degrees of freedom (denoted ``df`` in the 
    implementation) and :math:`\lambda` is the non-centrality parameter 
    (denoted ``nc`` in the implementation). :math:`I_\nu` denotes the 
    modified Bessel function of first order of degree :math:`\nu` 
    (`scipy.special.iv`). 
 
    `ncx2` takes ``df`` and ``nc`` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">(df &gt; </span><span class="s5">0</span><span class="s1">) &amp; np.isfinite(df) &amp; (nc &gt;= </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">idf = _ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">inc = _ShapeInfo(</span><span class="s4">&quot;nc&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[idf</span><span class="s2">, </span><span class="s1">inc]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.noncentral_chisquare(df</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(x</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_ncx2_log_pdf</span><span class="s2">,</span>
                          <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._logpdf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(x</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_boost._ncx2_pdf</span><span class="s2">,</span>
                              <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._pdf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(x</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_boost._ncx2_cdf</span><span class="s2">,</span>
                              <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._cdf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(q</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(q</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_boost._ncx2_ppf</span><span class="s2">,</span>
                              <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._ppf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(x</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_boost._ncx2_sf</span><span class="s2">,</span>
                              <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._sf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">cond = np.ones_like(x</span><span class="s2">, </span><span class="s1">dtype=bool) &amp; (nc != </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_lazywhere(cond</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s1">f=_boost._ncx2_isf</span><span class="s2">,</span>
                              <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">_: chi2._isf(x</span><span class="s2">, </span><span class="s1">df))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">(</span>
            <span class="s1">_boost._ncx2_mean(df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">,</span>
            <span class="s1">_boost._ncx2_variance(df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">,</span>
            <span class="s1">_boost._ncx2_skewness(df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">,</span>
            <span class="s1">_boost._ncx2_kurtosis_excess(df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">,</span>
        <span class="s1">)</span>


<span class="s1">ncx2 = ncx2_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'ncx2'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">ncf_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A non-central F distribution continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    scipy.stats.f : Fisher distribution 
 
    Notes 
    ----- 
    The probability density function for `ncf` is: 
 
    .. math:: 
 
        f(x, n_1, n_2, \lambda) = 
            \exp\left(\frac{\lambda}{2} + 
                      \lambda n_1 \frac{x}{2(n_1 x + n_2)} 
                \right) 
            n_1^{n_1/2} n_2^{n_2/2} x^{n_1/2 - 1} \\ 
            (n_2 + n_1 x)^{-(n_1 + n_2)/2} 
            \gamma(n_1/2) \gamma(1 + n_2/2) \\ 
            \frac{L^{\frac{n_1}{2}-1}_{n_2/2} 
                \left(-\lambda n_1 \frac{x}{2(n_1 x + n_2)}\right)} 
            {B(n_1/2, n_2/2) 
                \gamma\left(\frac{n_1 + n_2}{2}\right)} 
 
    for :math:`n_1, n_2 &gt; 0`, :math:`\lambda \ge 0`.  Here :math:`n_1` is the 
    degrees of freedom in the numerator, :math:`n_2` the degrees of freedom in 
    the denominator, :math:`\lambda` the non-centrality parameter, 
    :math:`\gamma` is the logarithm of the Gamma function, :math:`L_n^k` is a 
    generalized Laguerre polynomial and :math:`B` is the beta function. 
 
    `ncf` takes ``df1``, ``df2`` and ``nc`` as shape parameters. If ``nc=0``, 
    the distribution becomes equivalent to the Fisher distribution. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">df1</span><span class="s2">, </span><span class="s1">df2</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">(df1 &gt; </span><span class="s5">0</span><span class="s1">) &amp; (df2 &gt; </span><span class="s5">0</span><span class="s1">) &amp; (nc &gt;= </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">idf1 = _ShapeInfo(</span><span class="s4">&quot;df1&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">idf2 = _ShapeInfo(</span><span class="s4">&quot;df2&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">inc = _ShapeInfo(</span><span class="s4">&quot;nc&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[idf1</span><span class="s2">, </span><span class="s1">idf2</span><span class="s2">, </span><span class="s1">inc]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.noncentral_f(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s0"># ncf.pdf(x, df1, df2, nc) = exp(nc/2 + nc*df1*x/(2*(df1*x+df2))) *</span>
        <span class="s0">#             df1**(df1/2) * df2**(df2/2) * x**(df1/2-1) *</span>
        <span class="s0">#             (df2+df1*x)**(-(df1+df2)/2) *</span>
        <span class="s0">#             gamma(df1/2)*gamma(1+df2/2) *</span>
        <span class="s0">#             L^{v1/2-1}^{v2/2}(-nc*v1*x/(2*(v1*x+v2))) /</span>
        <span class="s0">#             (B(v1/2, v2/2) * gamma((v1+v2)/2))</span>
        <span class="s2">return </span><span class="s1">_boost._ncf_pdf(x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">_boost._ncf_cdf(x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._ncf_ppf(q</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">_boost._ncf_sf(x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._ncf_isf(x</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s1">val = (dfn * </span><span class="s5">1.0</span><span class="s1">/dfd)**n</span>
        <span class="s1">term = sc.gammaln(n+</span><span class="s5">0.5</span><span class="s1">*dfn) + sc.gammaln(</span><span class="s5">0.5</span><span class="s1">*dfd-n) - sc.gammaln(dfd*</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s1">val *= np.exp(-nc / </span><span class="s5">2.0</span><span class="s1">+term)</span>
        <span class="s1">val *= sc.hyp1f1(n+</span><span class="s5">0.5</span><span class="s1">*dfn</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">*dfn</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">*nc)</span>
        <span class="s2">return </span><span class="s1">val</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">mu = _boost._ncf_mean(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>
        <span class="s1">mu2 = _boost._ncf_variance(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc)</span>
        <span class="s1">g1 = _boost._ncf_skewness(dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc) </span><span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments </span><span class="s2">else None</span>
        <span class="s1">g2 = _boost._ncf_kurtosis_excess(</span>
            <span class="s1">dfn</span><span class="s2">, </span><span class="s1">dfd</span><span class="s2">, </span><span class="s1">nc) </span><span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments </span><span class="s2">else None</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">ncf = ncf_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'ncf'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">t_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Student's t continuous random variable. 
 
    For the noncentral t distribution, see `nct`. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    nct 
 
    Notes 
    ----- 
    The probability density function for `t` is: 
 
    .. math:: 
 
        f(x, \nu) = \frac{\Gamma((\nu+1)/2)} 
                        {\sqrt{\pi \nu} \Gamma(\nu/2)} 
                    (1+x^2/\nu)^{-(\nu+1)/2} 
 
    where :math:`x` is a real number and the degrees of freedom parameter 
    :math:`\nu` (denoted ``df`` in the implementation) satisfies 
    :math:`\nu &gt; 0`. :math:`\Gamma` is the gamma function 
    (`scipy.special.gamma`). 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.standard_t(df</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">df == np.inf</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">,</span>
            <span class="s1">f=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df: norm._pdf(x)</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df: (</span>
                <span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">df))</span>
            <span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>

        <span class="s2">def </span><span class="s1">regular_formula(x</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s2">return </span><span class="s1">(sc.gammaln((df + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s1">) - sc.gammaln(df/</span><span class="s5">2</span><span class="s1">)</span>
                    <span class="s1">- (</span><span class="s5">0.5 </span><span class="s1">* np.log(df*np.pi))</span>
                    <span class="s1">- (df + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s1">*np.log1p(x * x/df))</span>

        <span class="s2">def </span><span class="s1">asymptotic_formula(x</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s2">return </span><span class="s1">(- </span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ np.log(</span><span class="s5">2 </span><span class="s1">* np.pi)) + df/</span><span class="s5">2 </span><span class="s1">* np.log1p(</span><span class="s5">1</span><span class="s1">/df)</span>
                    <span class="s1">+ </span><span class="s5">1</span><span class="s1">/</span><span class="s5">6 </span><span class="s1">* (df + </span><span class="s5">1</span><span class="s1">)**-</span><span class="s5">1. </span><span class="s1">- </span><span class="s5">1</span><span class="s1">/</span><span class="s5">45</span><span class="s1">*(df + </span><span class="s5">1</span><span class="s1">)**-</span><span class="s5">3.</span>
                    <span class="s1">- </span><span class="s5">1</span><span class="s1">/</span><span class="s5">6 </span><span class="s1">* df**-</span><span class="s5">1. </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/</span><span class="s5">45</span><span class="s1">*df**-</span><span class="s5">3.</span>
                    <span class="s1">- (df + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2 </span><span class="s1">* np.log1p(x*x/df))</span>

        <span class="s2">def </span><span class="s1">norm_logpdf(x</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s2">return </span><span class="s1">norm._logpdf(x)</span>

        <span class="s2">return </span><span class="s1">_lazyselect(</span>
            <span class="s1">((df == np.inf)</span><span class="s2">,</span>
             <span class="s1">(df &gt;= </span><span class="s5">200</span><span class="s1">) &amp; np.isfinite(df)</span><span class="s2">,</span>
             <span class="s1">(df &lt; </span><span class="s5">200</span><span class="s1">))</span><span class="s2">,</span>
            <span class="s1">(norm_logpdf</span><span class="s2">,</span>
             <span class="s1">asymptotic_formula</span><span class="s2">,</span>
             <span class="s1">regular_formula)</span><span class="s2">,</span>
            <span class="s1">(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.stdtr(df</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.stdtr(df</span><span class="s2">, </span><span class="s1">-x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">sc.stdtrit(df</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">-sc.stdtrit(df</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s0"># infinite df -&gt; normal distribution (0.0, 1.0, 0.0, 0.0)</span>
        <span class="s1">infinite_df = np.isposinf(df)</span>

        <span class="s1">mu = np.where(df &gt; </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.inf)</span>

        <span class="s1">condlist = ((df &gt; </span><span class="s5">1</span><span class="s1">) &amp; (df &lt;= </span><span class="s5">2</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(df &gt; </span><span class="s5">2</span><span class="s1">) &amp; np.isfinite(df)</span><span class="s2">,</span>
                    <span class="s1">infinite_df)</span>
        <span class="s1">choicelist = (</span><span class="s2">lambda </span><span class="s1">df: np.broadcast_to(np.inf</span><span class="s2">, </span><span class="s1">df.shape)</span><span class="s2">,</span>
                      <span class="s2">lambda </span><span class="s1">df: df / (df-</span><span class="s5">2.0</span><span class="s1">)</span><span class="s2">,</span>
                      <span class="s2">lambda </span><span class="s1">df: np.broadcast_to(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">df.shape))</span>
        <span class="s1">mu2 = _lazyselect(condlist</span><span class="s2">, </span><span class="s1">choicelist</span><span class="s2">, </span><span class="s1">(df</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.nan)</span>

        <span class="s1">g1 = np.where(df &gt; </span><span class="s5">3</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.nan)</span>

        <span class="s1">condlist = ((df &gt; </span><span class="s5">2</span><span class="s1">) &amp; (df &lt;= </span><span class="s5">4</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(df &gt; </span><span class="s5">4</span><span class="s1">) &amp; np.isfinite(df)</span><span class="s2">,</span>
                    <span class="s1">infinite_df)</span>
        <span class="s1">choicelist = (</span><span class="s2">lambda </span><span class="s1">df: np.broadcast_to(np.inf</span><span class="s2">, </span><span class="s1">df.shape)</span><span class="s2">,</span>
                      <span class="s2">lambda </span><span class="s1">df: </span><span class="s5">6.0 </span><span class="s1">/ (df-</span><span class="s5">4.0</span><span class="s1">)</span><span class="s2">,</span>
                      <span class="s2">lambda </span><span class="s1">df: np.broadcast_to(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">df.shape))</span>
        <span class="s1">g2 = _lazyselect(condlist</span><span class="s2">, </span><span class="s1">choicelist</span><span class="s2">, </span><span class="s1">(df</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.nan)</span>

        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">if </span><span class="s1">df == np.inf:</span>
            <span class="s2">return </span><span class="s1">norm._entropy()</span>

        <span class="s2">def </span><span class="s1">regular(df):</span>
            <span class="s1">half = df/</span><span class="s5">2</span>
            <span class="s1">half1 = (df + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span>
            <span class="s2">return </span><span class="s1">(half1*(sc.digamma(half1) - sc.digamma(half))</span>
                    <span class="s1">+ np.log(np.sqrt(df)*sc.beta(half</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">)))</span>

        <span class="s2">def </span><span class="s1">asymptotic(df):</span>
            <span class="s0"># Formula from Wolfram Alpha:</span>
            <span class="s0"># &quot;asymptotic expansion (d+1)/2 * (digamma((d+1)/2) - digamma(d/2))</span>
            <span class="s0">#  + log(sqrt(d) * beta(d/2, 1/2))&quot;</span>
            <span class="s1">h = (norm._entropy() + </span><span class="s5">1</span><span class="s1">/df + (df**-</span><span class="s5">2.</span><span class="s1">)/</span><span class="s5">4 </span><span class="s1">- (df**-</span><span class="s5">3.</span><span class="s1">)/</span><span class="s5">6</span>
                 <span class="s1">- (df**-</span><span class="s5">4.</span><span class="s1">)/</span><span class="s5">8 </span><span class="s1">+ </span><span class="s5">3</span><span class="s1">/</span><span class="s5">10</span><span class="s1">*(df**-</span><span class="s5">5.</span><span class="s1">) + (df**-</span><span class="s5">6.</span><span class="s1">)/</span><span class="s5">4</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">h</span>

        <span class="s1">h = _lazywhere(df &gt;= </span><span class="s5">100</span><span class="s2">, </span><span class="s1">(df</span><span class="s2">, </span><span class="s1">)</span><span class="s2">, </span><span class="s1">f=asymptotic</span><span class="s2">, </span><span class="s1">f2=regular)</span>
        <span class="s2">return </span><span class="s1">h</span>


<span class="s1">t = t_gen(name=</span><span class="s4">'t'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">nct_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A non-central Student's t continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    If :math:`Y` is a standard normal random variable and :math:`V` is 
    an independent chi-square random variable (`chi2`) with :math:`k` degrees 
    of freedom, then 
 
    .. math:: 
 
        X = \frac{Y + c}{\sqrt{V/k}} 
 
    has a non-central Student's t distribution on the real line. 
    The degrees of freedom parameter :math:`k` (denoted ``df`` in the 
    implementation) satisfies :math:`k &gt; 0` and the noncentrality parameter 
    :math:`c` (denoted ``nc`` in the implementation) is a real number. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">return </span><span class="s1">(df &gt; </span><span class="s5">0</span><span class="s1">) &amp; (nc == nc)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">idf = _ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">inc = _ShapeInfo(</span><span class="s4">&quot;nc&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[idf</span><span class="s2">, </span><span class="s1">inc]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">n = norm.rvs(loc=nc</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s1">c2 = chi2.rvs(df</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>
        <span class="s2">return </span><span class="s1">n * np.sqrt(df) / np.sqrt(c2)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s0"># Boost version has accuracy issues in left tail; see gh-16591</span>
        <span class="s1">n = df*</span><span class="s5">1.0</span>
        <span class="s1">nc = nc*</span><span class="s5">1.0</span>
        <span class="s1">x2 = x*x</span>
        <span class="s1">ncx2 = nc*nc*x2</span>
        <span class="s1">fac1 = n + x2</span>
        <span class="s1">trm1 = (n/</span><span class="s5">2.</span><span class="s1">*np.log(n) + sc.gammaln(n+</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">- (n*np.log(</span><span class="s5">2</span><span class="s1">) + nc*nc/</span><span class="s5">2 </span><span class="s1">+ (n/</span><span class="s5">2</span><span class="s1">)*np.log(fac1)</span>
                   <span class="s1">+ sc.gammaln(n/</span><span class="s5">2</span><span class="s1">)))</span>
        <span class="s1">Px = np.exp(trm1)</span>
        <span class="s1">valF = ncx2 / (</span><span class="s5">2</span><span class="s1">*fac1)</span>
        <span class="s1">trm1 = (np.sqrt(</span><span class="s5">2</span><span class="s1">)*nc*x*sc.hyp1f1(n/</span><span class="s5">2</span><span class="s1">+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">valF)</span>
                <span class="s1">/ np.asarray(fac1*sc.gamma((n+</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s1">)))</span>
        <span class="s1">trm2 = (sc.hyp1f1((n+</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">valF)</span>
                <span class="s1">/ np.asarray(np.sqrt(fac1)*sc.gamma(n/</span><span class="s5">2</span><span class="s1">+</span><span class="s5">1</span><span class="s1">)))</span>
        <span class="s1">Px *= trm1+trm2</span>
        <span class="s2">return </span><span class="s1">np.clip(Px</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, None</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">np.clip(_boost._nct_cdf(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._nct_ppf(q</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">np.clip(_boost._nct_sf(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._nct_isf(x</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">nc</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">mu = _boost._nct_mean(df</span><span class="s2">, </span><span class="s1">nc)</span>
        <span class="s1">mu2 = _boost._nct_variance(df</span><span class="s2">, </span><span class="s1">nc)</span>
        <span class="s1">g1 = _boost._nct_skewness(df</span><span class="s2">, </span><span class="s1">nc) </span><span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments </span><span class="s2">else None</span>
        <span class="s1">g2 = _boost._nct_kurtosis_excess(df</span><span class="s2">, </span><span class="s1">nc) </span><span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments </span><span class="s2">else None</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">nct = nct_gen(name=</span><span class="s4">&quot;nct&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">pareto_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Pareto continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `pareto` is: 
 
    .. math:: 
 
        f(x, b) = \frac{b}{x^{b+1}} 
 
    for :math:`x \ge 1`, :math:`b &gt; 0`. 
 
    `pareto` takes ``b`` as a shape parameter for :math:`b`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># pareto.pdf(x, b) = b / x**(b+1)</span>
        <span class="s2">return </span><span class="s1">b * x**(-b-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">- x**(-b)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">pow(</span><span class="s5">1</span><span class="s1">-q</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1.0</span><span class="s1">/b)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">x**(-b)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None, None, None</span>
        <span class="s2">if </span><span class="s4">'m' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mask = b &gt; </span><span class="s5">1</span>
            <span class="s1">bt = np.extract(mask</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">mu = np.full(np.shape(b)</span><span class="s2">, </span><span class="s1">fill_value=np.inf)</span>
            <span class="s1">np.place(mu</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">bt / (bt-</span><span class="s5">1.0</span><span class="s1">))</span>
        <span class="s2">if </span><span class="s4">'v' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mask = b &gt; </span><span class="s5">2</span>
            <span class="s1">bt = np.extract(mask</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">mu2 = np.full(np.shape(b)</span><span class="s2">, </span><span class="s1">fill_value=np.inf)</span>
            <span class="s1">np.place(mu2</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">bt / (bt-</span><span class="s5">2.0</span><span class="s1">) / (bt-</span><span class="s5">1.0</span><span class="s1">)**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mask = b &gt; </span><span class="s5">3</span>
            <span class="s1">bt = np.extract(mask</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">g1 = np.full(np.shape(b)</span><span class="s2">, </span><span class="s1">fill_value=np.nan)</span>
            <span class="s1">vals = </span><span class="s5">2 </span><span class="s1">* (bt + </span><span class="s5">1.0</span><span class="s1">) * np.sqrt(bt - </span><span class="s5">2.0</span><span class="s1">) / ((bt - </span><span class="s5">3.0</span><span class="s1">) * np.sqrt(bt))</span>
            <span class="s1">np.place(g1</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">vals)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">mask = b &gt; </span><span class="s5">4</span>
            <span class="s1">bt = np.extract(mask</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">g2 = np.full(np.shape(b)</span><span class="s2">, </span><span class="s1">fill_value=np.nan)</span>
            <span class="s1">vals = (</span><span class="s5">6.0</span><span class="s1">*np.polyval([</span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bt) /</span>
                    <span class="s1">np.polyval([</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">7.0</span><span class="s2">, </span><span class="s5">12.0</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bt))</span>
            <span class="s1">np.place(g2</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">vals)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1.0</span><span class="s1">/c - np.log(c)</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">parameters = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">fshape</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = parameters</span>

        <span class="s0"># ensure that any fixed parameters don't violate constraints of the</span>
        <span class="s0"># distribution before continuing.</span>
        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">np.min(data) - floc &lt; (fscale </span><span class="s2">or </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;pareto&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>

        <span class="s1">ndata = data.shape[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s2">def </span><span class="s1">get_shape(scale</span><span class="s2">, </span><span class="s1">location):</span>
            <span class="s0"># The first-order necessary condition on `shape` can be solved in</span>
            <span class="s0"># closed form</span>
            <span class="s2">return </span><span class="s1">ndata / np.sum(np.log((data - location) / scale))</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># The support of the distribution is `(x - loc)/scale &gt; 0`.</span>
            <span class="s0"># The method of Lagrange multipliers turns this constraint</span>
            <span class="s0"># into an equation that can be solved numerically.</span>
            <span class="s0"># See gh-12545 for details.</span>

            <span class="s2">def </span><span class="s1">dL_dScale(shape</span><span class="s2">, </span><span class="s1">scale):</span>
                <span class="s0"># The partial derivative of the log-likelihood function w.r.t.</span>
                <span class="s0"># the scale.</span>
                <span class="s2">return </span><span class="s1">ndata * shape / scale</span>

            <span class="s2">def </span><span class="s1">dL_dLocation(shape</span><span class="s2">, </span><span class="s1">location):</span>
                <span class="s0"># The partial derivative of the log-likelihood function w.r.t.</span>
                <span class="s0"># the location.</span>
                <span class="s2">return </span><span class="s1">(shape + </span><span class="s5">1</span><span class="s1">) * np.sum(</span><span class="s5">1 </span><span class="s1">/ (data - location))</span>

            <span class="s2">def </span><span class="s1">fun_to_solve(scale):</span>
                <span class="s0"># optimize the scale by setting the partial derivatives</span>
                <span class="s0"># w.r.t. to location and scale equal and solving.</span>
                <span class="s1">location = np.min(data) - scale</span>
                <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(scale</span><span class="s2">, </span><span class="s1">location)</span>
                <span class="s2">return </span><span class="s1">dL_dLocation(shape</span><span class="s2">, </span><span class="s1">location) - dL_dScale(shape</span><span class="s2">, </span><span class="s1">scale)</span>

            <span class="s2">def </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack):</span>
                <span class="s0"># return true if the signs disagree.</span>
                <span class="s2">return </span><span class="s1">(np.sign(fun_to_solve(lbrack)) !=</span>
                        <span class="s1">np.sign(fun_to_solve(rbrack)))</span>

            <span class="s0"># set brackets for `root_scalar` to use when optimizing over the</span>
            <span class="s0"># scale such that a root is likely between them. Use user supplied</span>
            <span class="s0"># guess or default 1.</span>
            <span class="s1">brack_start = float(kwds.get(</span><span class="s4">'scale'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
            <span class="s1">lbrack</span><span class="s2">, </span><span class="s1">rbrack = brack_start / </span><span class="s5">2</span><span class="s2">, </span><span class="s1">brack_start * </span><span class="s5">2</span>
            <span class="s0"># if a root is not between the brackets, iteratively expand them</span>
            <span class="s0"># until they include a sign change, checking after each bracket is</span>
            <span class="s0"># modified.</span>
            <span class="s2">while </span><span class="s1">(</span><span class="s2">not </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack)</span>
                   <span class="s2">and </span><span class="s1">(lbrack &gt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">rbrack &lt; np.inf)):</span>
                <span class="s1">lbrack /= </span><span class="s5">2</span>
                <span class="s1">rbrack *= </span><span class="s5">2</span>
            <span class="s1">res = root_scalar(fun_to_solve</span><span class="s2">, </span><span class="s1">bracket=[lbrack</span><span class="s2">, </span><span class="s1">rbrack])</span>
            <span class="s2">if </span><span class="s1">res.converged:</span>
                <span class="s1">scale = res.root</span>
                <span class="s1">loc = np.min(data) - scale</span>
                <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(scale</span><span class="s2">, </span><span class="s1">loc)</span>

                <span class="s0"># The Pareto distribution requires that its parameters satisfy</span>
                <span class="s0"># the condition `fscale + floc &lt;= min(data)`. However, to</span>
                <span class="s0"># avoid numerical issues, we require that `fscale + floc`</span>
                <span class="s0"># is strictly less than `min(data)`. If this condition</span>
                <span class="s0"># is not satisfied, reduce the scale with `np.nextafter` to</span>
                <span class="s0"># ensure that data does not fall outside of the support.</span>
                <span class="s2">if not </span><span class="s1">(scale + loc) &lt; np.min(data):</span>
                    <span class="s1">scale = np.min(data) - loc</span>
                    <span class="s1">scale = np.nextafter(scale</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
                <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">elif </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">loc = np.min(data) - fscale</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">loc = floc</span>
        <span class="s0"># Source: Evans, Hastings, and Peacock (2000), Statistical</span>
        <span class="s0"># Distributions, 3rd. Ed., John Wiley and Sons. Page 149.</span>
        <span class="s1">scale = fscale </span><span class="s2">or </span><span class="s1">np.min(data) - loc</span>
        <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(scale</span><span class="s2">, </span><span class="s1">loc)</span>
        <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>


<span class="s1">pareto = pareto_gen(a=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;pareto&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">lomax_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Lomax (Pareto of the second kind) continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `lomax` is: 
 
    .. math:: 
 
        f(x, c) = \frac{c}{(1+x)^{c+1}} 
 
    for :math:`x \ge 0`, :math:`c &gt; 0`. 
 
    `lomax` takes ``c`` as a shape parameter for :math:`c`. 
 
    `lomax` is a special case of `pareto` with ``loc=-1.0``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># lomax.pdf(x, c) = c / (1+x)**(c+1)</span>
        <span class="s2">return </span><span class="s1">c*</span><span class="s5">1.0</span><span class="s1">/(</span><span class="s5">1.0</span><span class="s1">+x)**(c+</span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(c) - (c+</span><span class="s5">1</span><span class="s1">)*sc.log1p(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-c*sc.log1p(x))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(-c*sc.log1p(x))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-c*sc.log1p(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">sc.expm1(-sc.log1p(-q)/c)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = pareto.stats(c</span><span class="s2">, </span><span class="s1">loc=-</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mvsk'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s1">+</span><span class="s5">1.0</span><span class="s1">/c-np.log(c)</span>


<span class="s1">lomax = lomax_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;lomax&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">pearson3_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A pearson type III continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `pearson3` is: 
 
    .. math:: 
 
        f(x, \kappa) = \frac{|\beta|}{\Gamma(\alpha)} 
                       (\beta (x - \zeta))^{\alpha - 1} 
                       \exp(-\beta (x - \zeta)) 
 
    where: 
 
    .. math:: 
 
            \beta = \frac{2}{\kappa} 
 
            \alpha = \beta^2 = \frac{4}{\kappa^2} 
 
            \zeta = -\frac{\alpha}{\beta} = -\beta 
 
    :math:`\Gamma` is the gamma function (`scipy.special.gamma`). 
    Pass the skew :math:`\kappa` into `pearson3` as the shape parameter 
    ``skew``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    References 
    ---------- 
    R.W. Vogel and D.E. McMartin, &quot;Probability Plot Goodness-of-Fit and 
    Skewness Estimation Procedures for the Pearson Type 3 Distribution&quot;, Water 
    Resources Research, Vol.27, 3149-3158 (1991). 
 
    L.R. Salvosa, &quot;Tables of Pearson's Type III Function&quot;, Ann. Math. Statist., 
    Vol.1, 191-198 (1930). 
 
    &quot;Using Modern Computing Tools to Fit the Pearson Type III Distribution to 
    Aviation Loads Data&quot;, Office of Aviation Research (2003). 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_preprocess(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s0"># The real 'loc' and 'scale' are handled in the calling pdf(...). The</span>
        <span class="s0"># local variables 'loc' and 'scale' within pearson3._pdf are set to</span>
        <span class="s0"># the defaults just to keep them as part of the equations for</span>
        <span class="s0"># documentation.</span>
        <span class="s1">loc = </span><span class="s5">0.0</span>
        <span class="s1">scale = </span><span class="s5">1.0</span>

        <span class="s0"># If skew is small, return _norm_pdf. The divide between pearson3</span>
        <span class="s0"># and norm was found by brute force and is approximately a skew of</span>
        <span class="s0"># 0.000016.  No one, I hope, would actually use a skew value even</span>
        <span class="s0"># close to this small.</span>
        <span class="s1">norm2pearson_transition = </span><span class="s5">0.000016</span>

        <span class="s1">ans</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew = np.broadcast_arrays(</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew)</span>
        <span class="s1">ans = ans.copy()</span>

        <span class="s0"># mask is True where skew is small enough to use the normal approx.</span>
        <span class="s1">mask = np.absolute(skew) &lt; norm2pearson_transition</span>
        <span class="s1">invmask = ~mask</span>

        <span class="s1">beta = </span><span class="s5">2.0 </span><span class="s1">/ (skew[invmask] * scale)</span>
        <span class="s1">alpha = (scale * beta)**</span><span class="s5">2</span>
        <span class="s1">zeta = loc - alpha / beta</span>

        <span class="s1">transx = beta * (x[invmask] - zeta)</span>
        <span class="s2">return </span><span class="s1">ans</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">transx</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">invmask</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">zeta</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s0"># The _argcheck function in rv_continuous only allows positive</span>
        <span class="s0"># arguments.  The skew argument for pearson3 can be zero (which I want</span>
        <span class="s0"># to handle inside pearson3._pdf) or negative.  So just return True</span>
        <span class="s0"># for all skew args.</span>
        <span class="s2">return </span><span class="s1">np.isfinite(skew)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;skew&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s1">m = </span><span class="s5">0.0</span>
        <span class="s1">v = </span><span class="s5">1.0</span>
        <span class="s1">s = skew</span>
        <span class="s1">k = </span><span class="s5">1.5</span><span class="s1">*skew**</span><span class="s5">2</span>
        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">k</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s0"># pearson3.pdf(x, skew) = abs(beta) / gamma(alpha) *</span>
        <span class="s0">#     (beta * (x - zeta))**(alpha - 1) * exp(-beta*(x - zeta))</span>
        <span class="s0"># Do the calculation in _logpdf since helps to limit</span>
        <span class="s0"># overflow/underflow problems</span>
        <span class="s1">ans = np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">skew))</span>
        <span class="s2">if </span><span class="s1">ans.ndim == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">np.isnan(ans):</span>
                <span class="s2">return </span><span class="s5">0.0</span>
            <span class="s2">return </span><span class="s1">ans</span>
        <span class="s1">ans[np.isnan(ans)] = </span><span class="s5">0.0</span>
        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s0">#   PEARSON3 logpdf                           GAMMA logpdf</span>
        <span class="s0">#   np.log(abs(beta))</span>
        <span class="s0"># + (alpha - 1)*np.log(beta*(x - zeta))          + (a - 1)*np.log(x)</span>
        <span class="s0"># - beta*(x - zeta)                           - x</span>
        <span class="s0"># - sc.gammalnalpha)                              - sc.gammalna)</span>
        <span class="s1">ans</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">transx</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">invmask</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">_ = (</span>
            <span class="s1">self._preprocess(x</span><span class="s2">, </span><span class="s1">skew))</span>

        <span class="s1">ans[mask] = np.log(_norm_pdf(x[mask]))</span>
        <span class="s0"># use logpdf instead of _logpdf to fix issue mentioned in gh-12640</span>
        <span class="s0"># (_logpdf does not return correct result for alpha = 1)</span>
        <span class="s1">ans[invmask] = np.log(abs(beta)) + gamma.logpdf(transx</span><span class="s2">, </span><span class="s1">alpha)</span>
        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s1">ans</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">transx</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">invmask</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">_ = (</span>
            <span class="s1">self._preprocess(x</span><span class="s2">, </span><span class="s1">skew))</span>

        <span class="s1">ans[mask] = _norm_cdf(x[mask])</span>

        <span class="s1">skew = np.broadcast_to(skew</span><span class="s2">, </span><span class="s1">invmask.shape)</span>
        <span class="s1">invmask1a = np.logical_and(invmask</span><span class="s2">, </span><span class="s1">skew &gt; </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">invmask1b = skew[invmask] &gt; </span><span class="s5">0</span>
        <span class="s0"># use cdf instead of _cdf to fix issue mentioned in gh-12640</span>
        <span class="s0"># (_cdf produces NaNs for inputs outside support)</span>
        <span class="s1">ans[invmask1a] = gamma.cdf(transx[invmask1b]</span><span class="s2">, </span><span class="s1">alpha[invmask1b])</span>

        <span class="s0"># The gamma._cdf approach wasn't working with negative skew.</span>
        <span class="s0"># Note that multiplying the skew by -1 reflects about x=0.</span>
        <span class="s0"># So instead of evaluating the CDF with negative skew at x,</span>
        <span class="s0"># evaluate the SF with positive skew at -x.</span>
        <span class="s1">invmask2a = np.logical_and(invmask</span><span class="s2">, </span><span class="s1">skew &lt; </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">invmask2b = skew[invmask] &lt; </span><span class="s5">0</span>
        <span class="s0"># gamma._sf produces NaNs when transx &lt; 0, so use gamma.sf</span>
        <span class="s1">ans[invmask2a] = gamma.sf(transx[invmask2b]</span><span class="s2">, </span><span class="s1">alpha[invmask2b])</span>

        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">skew</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">skew = np.broadcast_to(skew</span><span class="s2">, </span><span class="s1">size)</span>
        <span class="s1">ans</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">invmask</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">zeta = (</span>
            <span class="s1">self._preprocess([</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">skew))</span>

        <span class="s1">nsmall = mask.sum()</span>
        <span class="s1">nbig = mask.size - nsmall</span>
        <span class="s1">ans[mask] = random_state.standard_normal(nsmall)</span>
        <span class="s1">ans[invmask] = random_state.standard_gamma(alpha</span><span class="s2">, </span><span class="s1">nbig)/beta + zeta</span>

        <span class="s2">if </span><span class="s1">size == ():</span>
            <span class="s1">ans = ans[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">skew):</span>
        <span class="s1">ans</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">invmask</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">zeta = (</span>
            <span class="s1">self._preprocess(q</span><span class="s2">, </span><span class="s1">skew))</span>
        <span class="s1">ans[mask] = _norm_ppf(q[mask])</span>
        <span class="s1">q = q[invmask]</span>
        <span class="s1">q[beta &lt; </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1 </span><span class="s1">- q[beta &lt; </span><span class="s5">0</span><span class="s1">]  </span><span class="s0"># for negative skew; see gh-17050</span>
        <span class="s1">ans[invmask] = sc.gammaincinv(alpha</span><span class="s2">, </span><span class="s1">q)/beta + zeta</span>
        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">Note that method of moments (`method='MM'`) is not 
        available for this distribution.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.get(</span><span class="s4">&quot;method&quot;</span><span class="s2">, None</span><span class="s1">) == </span><span class="s4">'MM'</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s4">&quot;Fit `method='MM'` is not available for &quot;</span>
                                      <span class="s4">&quot;the Pearson3 distribution. Please try &quot;</span>
                                      <span class="s4">&quot;the default `method='MLE'`.&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">super(type(self)</span><span class="s2">, </span><span class="s1">self).fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">pearson3 = pearson3_gen(name=</span><span class="s4">&quot;pearson3&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">powerlaw_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A power-function continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    pareto 
 
    Notes 
    ----- 
    The probability density function for `powerlaw` is: 
 
    .. math:: 
 
        f(x, a) = a x^{a-1} 
 
    for :math:`0 \le x \le 1`, :math:`a &gt; 0`. 
 
    `powerlaw` takes ``a`` as a shape parameter for :math:`a`. 
 
    %(after_notes)s 
 
    For example, the support of `powerlaw` can be adjusted from the default 
    interval ``[0, 1]`` to the interval ``[c, c+d]`` by setting ``loc=c`` and 
    ``scale=d``. For a power-law distribution with infinite support, see 
    `pareto`. 
 
    `powerlaw` is a special case of `beta` with ``b=1``. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># powerlaw.pdf(x, a) = a * x**(a-1)</span>
        <span class="s2">return </span><span class="s1">a*x**(a-</span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.log(a) + sc.xlogy(a - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">x**(a*</span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">a*np.log(x)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">pow(q</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/a)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">-sc.powm1(p</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">(a / (a + </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s1">a / (a + </span><span class="s5">2.0</span><span class="s1">) / (a + </span><span class="s5">1.0</span><span class="s1">) ** </span><span class="s5">2</span><span class="s2">,</span>
                <span class="s1">-</span><span class="s5">2.0 </span><span class="s1">* ((a - </span><span class="s5">1.0</span><span class="s1">) / (a + </span><span class="s5">3.0</span><span class="s1">)) * np.sqrt((a + </span><span class="s5">2.0</span><span class="s1">) / a)</span><span class="s2">,</span>
                <span class="s5">6 </span><span class="s1">* np.polyval([</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">a) / (a * (a + </span><span class="s5">3.0</span><span class="s1">) * (a + </span><span class="s5">4</span><span class="s1">)))</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1.0</span><span class="s1">/a - np.log(a)</span>

    <span class="s2">def </span><span class="s1">_support_mask(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">(super()._support_mask(x</span><span class="s2">, </span><span class="s1">a)</span>
                <span class="s1">&amp; ((x != </span><span class="s5">0</span><span class="s1">) | (a &gt;= </span><span class="s5">1</span><span class="s1">)))</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">Notes specifically for ``powerlaw.fit``: If the location is a free 
        parameter and the value returned for the shape parameter is less than 
        one, the true maximum likelihood approaches infinity. This causes 
        numerical difficulties, and the resulting estimates are approximate. 
        </span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s0"># Summary of the strategy:</span>
        <span class="s0">#</span>
        <span class="s0"># 1) If the scale and location are fixed, return the shape according</span>
        <span class="s0">#    to a formula.</span>
        <span class="s0">#</span>
        <span class="s0"># 2) If the scale is fixed, there are two possibilities for the other</span>
        <span class="s0">#    parameters - one corresponding with shape less than one, and</span>
        <span class="s0">#    another with shape greater than one. Calculate both, and return</span>
        <span class="s0">#    whichever has the better log-likelihood.</span>
        <span class="s0">#</span>
        <span class="s0"># At this point, the scale is known to be free.</span>
        <span class="s0">#</span>
        <span class="s0"># 3) If the location is fixed, return the scale and shape according to</span>
        <span class="s0">#    formulas (or, if the shape is fixed, the fixed shape).</span>
        <span class="s0">#</span>
        <span class="s0"># At this point, the location and scale are both free. There are</span>
        <span class="s0"># separate equations depending on whether the shape is less than one or</span>
        <span class="s0"># greater than one.</span>
        <span class="s0">#</span>
        <span class="s0"># 4a) If the shape is less than one, there are formulas for shape,</span>
        <span class="s0">#     location, and scale.</span>
        <span class="s0"># 4b) If the shape is greater than one, there are formulas for shape</span>
        <span class="s0">#     and scale, but there is a condition for location to be solved</span>
        <span class="s0">#     numerically.</span>
        <span class="s0">#</span>
        <span class="s0"># If the shape is fixed and less than one, we use 4a.</span>
        <span class="s0"># If the shape is fixed and greater than one, we use 4b.</span>
        <span class="s0"># If the shape is also free, we calculate fits using both 4a and 4b</span>
        <span class="s0"># and choose the one that results a better log-likelihood.</span>
        <span class="s0">#</span>
        <span class="s0"># In many cases, the use of `np.nextafter` is used to avoid numerical</span>
        <span class="s0"># issues.</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">if </span><span class="s1">len(np.unique(data)) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">data</span><span class="s2">, </span><span class="s1">fshape</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                                 <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">penalized_nllf_args = [data</span><span class="s2">, </span><span class="s1">(self._fitstart(data)</span><span class="s2">,</span><span class="s1">)]</span>
        <span class="s1">penalized_nllf = self._reduce_func(penalized_nllf_args</span><span class="s2">, </span><span class="s1">{})[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s0"># ensure that any fixed parameters don't violate constraints of the</span>
        <span class="s0"># distribution before continuing. The support of the distribution</span>
        <span class="s0"># is `0 &lt; (x - loc)/scale &lt; 1`.</span>
        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">data.min() &gt; floc:</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">'powerlaw'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None and not </span><span class="s1">data.max() &lt;= floc + fscale:</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">'powerlaw'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">fscale &lt;= </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Negative or zero `fscale` is outside the &quot;</span>
                                 <span class="s4">&quot;range allowed by the distribution.&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">fscale &lt;= data.ptp():</span>
                <span class="s1">msg = </span><span class="s4">&quot;`fscale` must be greater than the range of data.&quot;</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">def </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale):</span>
            <span class="s0"># The first-order necessary condition on `shape` can be solved in</span>
            <span class="s0"># closed form. It can be used no matter the assumption of the</span>
            <span class="s0"># value of the shape.</span>
            <span class="s1">N = len(data)</span>
            <span class="s2">return </span><span class="s1">- N / (np.sum(np.log(data - loc)) - N*np.log(scale))</span>

        <span class="s2">def </span><span class="s1">get_scale(data</span><span class="s2">, </span><span class="s1">loc):</span>
            <span class="s0"># analytical solution for `scale` based on the location.</span>
            <span class="s0"># It can be used no matter the assumption of the value of the</span>
            <span class="s0"># shape.</span>
            <span class="s2">return </span><span class="s1">data.max() - loc</span>

        <span class="s0"># 1) The location and scale are both fixed. Analytically determine the</span>
        <span class="s0"># shape.</span>
        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None and </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale)</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale</span>

        <span class="s0"># 2) The scale is fixed. There are two possibilities for the other</span>
        <span class="s0"># parameters. Choose the option with better log-likelihood.</span>
        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># using `data.min()` as the optimal location</span>
            <span class="s1">loc_lt1 = np.nextafter(data.min()</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s1">shape_lt1 = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc_lt1</span><span class="s2">, </span><span class="s1">fscale)</span>
            <span class="s1">ll_lt1 = penalized_nllf((shape_lt1</span><span class="s2">, </span><span class="s1">loc_lt1</span><span class="s2">, </span><span class="s1">fscale)</span><span class="s2">, </span><span class="s1">data)</span>

            <span class="s0"># using `data.max() - scale` as the optimal location</span>
            <span class="s1">loc_gt1 = np.nextafter(data.max() - fscale</span><span class="s2">, </span><span class="s1">np.inf)</span>
            <span class="s1">shape_gt1 = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc_gt1</span><span class="s2">, </span><span class="s1">fscale)</span>
            <span class="s1">ll_gt1 = penalized_nllf((shape_gt1</span><span class="s2">, </span><span class="s1">loc_gt1</span><span class="s2">, </span><span class="s1">fscale)</span><span class="s2">, </span><span class="s1">data)</span>

            <span class="s2">if </span><span class="s1">ll_lt1 &lt; ll_gt1:</span>
                <span class="s2">return </span><span class="s1">shape_lt1</span><span class="s2">, </span><span class="s1">loc_lt1</span><span class="s2">, </span><span class="s1">fscale</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">shape_gt1</span><span class="s2">, </span><span class="s1">loc_gt1</span><span class="s2">, </span><span class="s1">fscale</span>

        <span class="s0"># 3) The location is fixed. Return the analytical scale and the</span>
        <span class="s0"># analytical (or fixed) shape.</span>
        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">scale = get_scale(data</span><span class="s2">, </span><span class="s1">floc)</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">scale</span>

        <span class="s0"># 4) Location and scale are both free</span>
        <span class="s0"># 4a) Use formulas that assume `shape &lt;= 1`.</span>

        <span class="s2">def </span><span class="s1">fit_loc_scale_w_shape_lt_1():</span>
            <span class="s1">loc = np.nextafter(data.min()</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s2">if </span><span class="s1">np.abs(loc) &lt; np.finfo(loc.dtype).tiny:</span>
                <span class="s1">loc = np.sign(loc) * np.finfo(loc.dtype).tiny</span>
            <span class="s1">scale = np.nextafter(get_scale(data</span><span class="s2">, </span><span class="s1">loc)</span><span class="s2">, </span><span class="s1">np.inf)</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>

        <span class="s0"># 4b) Fit under the assumption that `shape &gt; 1`. The support</span>
        <span class="s0"># of the distribution is `(x - loc)/scale &lt;= 1`. The method of Lagrange</span>
        <span class="s0"># multipliers turns this constraint into the condition that</span>
        <span class="s0"># dL_dScale - dL_dLocation must be zero, which is solved numerically.</span>
        <span class="s0"># (Alternatively, substitute the constraint into the objective</span>
        <span class="s0"># function before deriving the likelihood equation for location.)</span>

        <span class="s2">def </span><span class="s1">dL_dScale(data</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">scale):</span>
            <span class="s0"># The partial derivative of the log-likelihood function w.r.t.</span>
            <span class="s0"># the scale.</span>
            <span class="s2">return </span><span class="s1">-data.shape[</span><span class="s5">0</span><span class="s1">] * shape / scale</span>

        <span class="s2">def </span><span class="s1">dL_dLocation(data</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc):</span>
            <span class="s0"># The partial derivative of the log-likelihood function w.r.t.</span>
            <span class="s0"># the location.</span>
            <span class="s2">return </span><span class="s1">(shape - </span><span class="s5">1</span><span class="s1">) * np.sum(</span><span class="s5">1 </span><span class="s1">/ (loc - data))  </span><span class="s0"># -1/(data-loc)</span>

        <span class="s2">def </span><span class="s1">dL_dLocation_star(loc):</span>
            <span class="s0"># The derivative of the log-likelihood function w.r.t.</span>
            <span class="s0"># the location, given optimal shape and scale</span>
            <span class="s1">scale = np.nextafter(get_scale(data</span><span class="s2">, </span><span class="s1">loc)</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s2">return </span><span class="s1">dL_dLocation(data</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc)</span>

        <span class="s2">def </span><span class="s1">fun_to_solve(loc):</span>
            <span class="s0"># optimize the location by setting the partial derivatives</span>
            <span class="s0"># w.r.t. to location and scale equal and solving.</span>
            <span class="s1">scale = np.nextafter(get_scale(data</span><span class="s2">, </span><span class="s1">loc)</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s2">return </span><span class="s1">(dL_dScale(data</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">scale)</span>
                    <span class="s1">- dL_dLocation(data</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc))</span>

        <span class="s2">def </span><span class="s1">fit_loc_scale_w_shape_gt_1():</span>
            <span class="s0"># set brackets for `root_scalar` to use when optimizing over the</span>
            <span class="s0"># location such that a root is likely between them.</span>
            <span class="s1">rbrack = np.nextafter(data.min()</span><span class="s2">, </span><span class="s1">-np.inf)</span>

            <span class="s0"># if the sign of `dL_dLocation_star` is positive at rbrack,</span>
            <span class="s0"># we're not going to find the root we're looking for</span>
            <span class="s1">delta = (data.min() - rbrack)</span>
            <span class="s2">while </span><span class="s1">dL_dLocation_star(rbrack) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">rbrack = data.min() - delta</span>
                <span class="s1">delta *= </span><span class="s5">2</span>

            <span class="s2">def </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack):</span>
                <span class="s0"># Check if the interval (lbrack, rbrack) contains the root.</span>
                <span class="s2">return </span><span class="s1">(np.sign(fun_to_solve(lbrack))</span>
                        <span class="s1">!= np.sign(fun_to_solve(rbrack)))</span>

            <span class="s1">lbrack = rbrack - </span><span class="s5">1</span>

            <span class="s0"># if the sign doesn't change between the brackets, move the left</span>
            <span class="s0"># bracket until it does. (The right bracket remains fixed at the</span>
            <span class="s0"># maximum permissible value.)</span>
            <span class="s1">i = </span><span class="s5">1.0</span>
            <span class="s2">while </span><span class="s1">(</span><span class="s2">not </span><span class="s1">interval_contains_root(lbrack</span><span class="s2">, </span><span class="s1">rbrack)</span>
                   <span class="s2">and </span><span class="s1">lbrack != -np.inf):</span>
                <span class="s1">lbrack = (data.min() - i)</span>
                <span class="s1">i *= </span><span class="s5">2</span>

            <span class="s1">root = optimize.root_scalar(fun_to_solve</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>

            <span class="s1">loc = np.nextafter(root.root</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s1">scale = np.nextafter(get_scale(data</span><span class="s2">, </span><span class="s1">loc)</span><span class="s2">, </span><span class="s1">np.inf)</span>
            <span class="s1">shape = fshape </span><span class="s2">or </span><span class="s1">get_shape(data</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>

        <span class="s0"># Shape is fixed - choose 4a or 4b accordingly.</span>
        <span class="s2">if </span><span class="s1">fshape </span><span class="s2">is not None and </span><span class="s1">fshape &lt;= </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">fit_loc_scale_w_shape_lt_1()</span>
        <span class="s2">elif </span><span class="s1">fshape </span><span class="s2">is not None and </span><span class="s1">fshape &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">fit_loc_scale_w_shape_gt_1()</span>

        <span class="s0"># Shape is free</span>
        <span class="s1">fit_shape_lt1 = fit_loc_scale_w_shape_lt_1()</span>
        <span class="s1">ll_lt1 = self.nnlf(fit_shape_lt1</span><span class="s2">, </span><span class="s1">data)</span>

        <span class="s1">fit_shape_gt1 = fit_loc_scale_w_shape_gt_1()</span>
        <span class="s1">ll_gt1 = self.nnlf(fit_shape_gt1</span><span class="s2">, </span><span class="s1">data)</span>

        <span class="s2">if </span><span class="s1">ll_lt1 &lt;= ll_gt1 </span><span class="s2">and </span><span class="s1">fit_shape_lt1[</span><span class="s5">0</span><span class="s1">] &lt;= </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">fit_shape_lt1</span>
        <span class="s2">elif </span><span class="s1">ll_lt1 &gt; ll_gt1 </span><span class="s2">and </span><span class="s1">fit_shape_gt1[</span><span class="s5">0</span><span class="s1">] &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">fit_shape_gt1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">powerlaw = powerlaw_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;powerlaw&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">powerlognorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A power log-normal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `powerlognorm` is: 
 
    .. math:: 
 
        f(x, c, s) = \frac{c}{x s} \phi(\log(x)/s) 
                     (\Phi(-\log(x)/s))^{c-1} 
 
    where :math:`\phi` is the normal pdf, and :math:`\Phi` is the normal cdf, 
    and :math:`x &gt; 0`, :math:`s, c &gt; 0`. 
 
    `powerlognorm` takes :math:`c` and :math:`s` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">i_s = _ShapeInfo(</span><span class="s4">&quot;s&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ic</span><span class="s2">, </span><span class="s1">i_s]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">(np.log(c) - np.log(x) - np.log(s) +</span>
                <span class="s1">_norm_logpdf(np.log(x) / s) +</span>
                <span class="s1">_norm_logcdf(-np.log(x) / s) * (c - </span><span class="s5">1.</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(self._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">self._isf(</span><span class="s5">1 </span><span class="s1">- q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">_norm_logcdf(-np.log(x) / s) * c</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">s):</span>
        <span class="s2">return </span><span class="s1">np.exp(-_norm_ppf(q**(</span><span class="s5">1</span><span class="s1">/c)) * s)</span>


<span class="s1">powerlognorm = powerlognorm_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;powerlognorm&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">powernorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A power normal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `powernorm` is: 
 
    .. math:: 
 
        f(x, c) = c \phi(x) (\Phi(-x))^{c-1} 
 
    where :math:`\phi` is the normal pdf, :math:`\Phi` is the normal cdf, 
    :math:`x` is any real, and :math:`c &gt; 0` [1]_. 
 
    `powernorm` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] NIST Engineering Statistics Handbook, Section 1.3.6.6.13, 
           https://www.itl.nist.gov/div898/handbook//eda/section3/eda366d.htm 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># powernorm.pdf(x, c) = c * phi(x) * (Phi(-x))**(c-1)</span>
        <span class="s2">return </span><span class="s1">c*_norm_pdf(x) * (_norm_cdf(-x)**(c-</span><span class="s5">1.0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(c) + _norm_logpdf(x) + (c-</span><span class="s5">1</span><span class="s1">)*_norm_logcdf(-x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(self._logsf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-_norm_ppf(pow(</span><span class="s5">1.0 </span><span class="s1">- q</span><span class="s2">, </span><span class="s5">1.0 </span><span class="s1">/ c))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">c * _norm_logcdf(-x)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-_norm_ppf(np.exp(np.log(q) / c))</span>


<span class="s1">powernorm = powernorm_gen(name=</span><span class="s4">'powernorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">rdist_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An R-distributed (symmetric beta) continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `rdist` is: 
 
    .. math:: 
 
        f(x, c) = \frac{(1-x^2)^{c/2-1}}{B(1/2, c/2)} 
 
    for :math:`-1 \le x \le 1`, :math:`c &gt; 0`. `rdist` is also called the 
    symmetric beta distribution: if B has a `beta` distribution with 
    parameters (c/2, c/2), then X = 2*B - 1 follows a R-distribution with 
    parameter c. 
 
    `rdist` takes ``c`` as a shape parameter for :math:`c`. 
 
    This distribution includes the following distribution kernels as 
    special cases:: 
 
        c = 2:  uniform 
        c = 3:  `semicircular` 
        c = 4:  Epanechnikov (parabolic) 
        c = 6:  quartic (biweight) 
        c = 8:  triweight 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s0"># use relation to the beta distribution for pdf, cdf, etc</span>
    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">c))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-np.log(</span><span class="s5">2</span><span class="s1">) + beta._logpdf((x + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">beta._cdf((x + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">2</span><span class="s1">*beta._ppf(q</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s1">) - </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s5">2 </span><span class="s1">* random_state.beta(c/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">c/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">size) - </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">numerator = (</span><span class="s5">1 </span><span class="s1">- (n % </span><span class="s5">2</span><span class="s1">)) * sc.beta((n + </span><span class="s5">1.0</span><span class="s1">) / </span><span class="s5">2</span><span class="s2">, </span><span class="s1">c / </span><span class="s5">2.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">numerator / sc.beta(</span><span class="s5">1. </span><span class="s1">/ </span><span class="s5">2</span><span class="s2">, </span><span class="s1">c / </span><span class="s5">2.</span><span class="s1">)</span>


<span class="s1">rdist = rdist_gen(a=-</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;rdist&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">rayleigh_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Rayleigh continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `rayleigh` is: 
 
    .. math:: 
 
        f(x) = x \exp(-x^2/2) 
 
    for :math:`x \ge 0`. 
 
    `rayleigh` is a special case of `chi` with ``df=2``. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">chi.rvs(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s0"># rayleigh.pdf(r) = r * exp(-r**2/2)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(r))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s2">return </span><span class="s1">np.log(r) - </span><span class="s5">0.5 </span><span class="s1">* r * r</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s2">return </span><span class="s1">-sc.expm1(-</span><span class="s5">0.5 </span><span class="s1">* r**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(-</span><span class="s5">2 </span><span class="s1">* sc.log1p(-q))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(r))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">0.5 </span><span class="s1">* r * r</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(-</span><span class="s5">2 </span><span class="s1">* np.log(q))</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s1">val = </span><span class="s5">4 </span><span class="s1">- np.pi</span>
        <span class="s2">return </span><span class="s1">(np.sqrt(np.pi/</span><span class="s5">2</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s1">val/</span><span class="s5">2</span><span class="s2">,</span>
                <span class="s5">2</span><span class="s1">*(np.pi-</span><span class="s5">3</span><span class="s1">)*np.sqrt(np.pi)/val**</span><span class="s5">1.5</span><span class="s2">,</span>
                <span class="s5">6</span><span class="s1">*np.pi/val-</span><span class="s5">16</span><span class="s1">/val**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">_EULER/</span><span class="s5">2.0 </span><span class="s1">+ </span><span class="s5">1 </span><span class="s1">- </span><span class="s5">0.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">Notes specifically for ``rayleigh.fit``: If the location is fixed with 
        the `floc` parameter, this method uses an analytical formula to find 
        the scale.  Otherwise, this function uses a numerical root finder on 
        the first order conditions of the log-likelihood function to find the 
        MLE.  Only the (optional) `loc` parameter is used as the initial guess 
        for the root finder; the `scale` parameter and any other parameters 
        for the optimizer are ignored.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                         <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>

        <span class="s2">def </span><span class="s1">scale_mle(loc):</span>
            <span class="s0"># Source: Statistical Distributions, 3rd Edition. Evans, Hastings,</span>
            <span class="s0"># and Peacock (2000), Page 175</span>
            <span class="s2">return </span><span class="s1">(np.sum((data - loc) ** </span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">2 </span><span class="s1">* len(data))) ** </span><span class="s5">.5</span>

        <span class="s2">def </span><span class="s1">loc_mle(loc):</span>
            <span class="s0"># This implicit equation for `loc` is used when</span>
            <span class="s0"># both `loc` and `scale` are free.</span>
            <span class="s1">xm = data - loc</span>
            <span class="s1">s1 = xm.sum()</span>
            <span class="s1">s2 = (xm**</span><span class="s5">2</span><span class="s1">).sum()</span>
            <span class="s1">s3 = (</span><span class="s5">1</span><span class="s1">/xm).sum()</span>
            <span class="s2">return </span><span class="s1">s1 - s2/(</span><span class="s5">2</span><span class="s1">*len(data))*s3</span>

        <span class="s2">def </span><span class="s1">loc_mle_scale_fixed(loc</span><span class="s2">, </span><span class="s1">scale=fscale):</span>
            <span class="s0"># This implicit equation for `loc` is used when</span>
            <span class="s0"># `scale` is fixed but `loc` is not.</span>
            <span class="s1">xm = data - loc</span>
            <span class="s2">return </span><span class="s1">xm.sum() - scale**</span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">1</span><span class="s1">/xm).sum()</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># `loc` is fixed, analytically determine `scale`.</span>
            <span class="s2">if </span><span class="s1">np.any(data - floc &lt;= </span><span class="s5">0</span><span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;rayleigh&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">upper=np.inf)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">scale_mle(floc)</span>

        <span class="s0"># Account for user provided guess of `loc`.</span>
        <span class="s1">loc0 = kwds.get(</span><span class="s4">'loc'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">loc0 </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># Use _fitstart to estimate loc; ignore the returned scale.</span>
            <span class="s1">loc0 = self._fitstart(data)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">fun = loc_mle </span><span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None else </span><span class="s1">loc_mle_scale_fixed</span>
        <span class="s1">rbrack = np.nextafter(np.min(data)</span><span class="s2">, </span><span class="s1">-np.inf)</span>
        <span class="s1">lbrack = _get_left_bracket(fun</span><span class="s2">, </span><span class="s1">rbrack)</span>
        <span class="s1">res = optimize.root_scalar(fun</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
        <span class="s2">if not </span><span class="s1">res.converged:</span>
            <span class="s2">raise </span><span class="s1">FitSolverError(res.flag)</span>
        <span class="s1">loc = res.root</span>
        <span class="s1">scale = fscale </span><span class="s2">or </span><span class="s1">scale_mle(loc)</span>
        <span class="s2">return </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>


<span class="s1">rayleigh = rayleigh_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;rayleigh&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">reciprocal_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A loguniform or reciprocal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for this class is: 
 
    .. math:: 
 
        f(x, a, b) = \frac{1}{x \log(b/a)} 
 
    for :math:`a \le x \le b`, :math:`b &gt; a &gt; 0`. This class takes 
    :math:`a` and :math:`b` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    This doesn't show the equal probability of ``0.01``, ``0.1`` and 
    ``1``. This is best when the x-axis is log-scaled: 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
    &gt;&gt;&gt; ax.hist(np.log10(r)) 
    &gt;&gt;&gt; ax.set_ylabel(&quot;Frequency&quot;) 
    &gt;&gt;&gt; ax.set_xlabel(&quot;Value of random variable&quot;) 
    &gt;&gt;&gt; ax.xaxis.set_major_locator(plt.FixedLocator([-2, -1, 0])) 
    &gt;&gt;&gt; ticks = [&quot;$10^{{ {} }}$&quot;.format(i) for i in [-2, -1, 0]] 
    &gt;&gt;&gt; ax.set_xticklabels(ticks)  # doctest: +SKIP 
    &gt;&gt;&gt; plt.show() 
 
    This random variable will be log-uniform regardless of the base chosen for 
    ``a`` and ``b``. Let's specify with base ``2`` instead: 
 
    &gt;&gt;&gt; rvs = %(name)s(2**-2, 2**0).rvs(size=1000) 
 
    Values of ``1/4``, ``1/2`` and ``1`` are equally likely with this random 
    variable.  Here's the histogram: 
 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
    &gt;&gt;&gt; ax.hist(np.log2(rvs)) 
    &gt;&gt;&gt; ax.set_ylabel(&quot;Frequency&quot;) 
    &gt;&gt;&gt; ax.set_xlabel(&quot;Value of random variable&quot;) 
    &gt;&gt;&gt; ax.xaxis.set_major_locator(plt.FixedLocator([-2, -1, 0])) 
    &gt;&gt;&gt; ticks = [&quot;$2^{{ {} }}$&quot;.format(i) for i in [-2, -1, 0]] 
    &gt;&gt;&gt; ax.set_xticklabels(ticks)  # doctest: +SKIP 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(a &gt; </span><span class="s5">0</span><span class="s1">) &amp; (b &gt; a)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s0"># Reasonable, since support is [a, b]</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(np.min(data)</span><span class="s2">, </span><span class="s1">np.max(data)))</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># reciprocal.pdf(x, a, b) = 1 / (x*(log(b) - log(a)))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">-np.log(x) - np.log(np.log(b) - np.log(a))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(np.log(x)-np.log(a)) / (np.log(b) - np.log(a))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.exp(np.log(a) + q*(np.log(b) - np.log(a)))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">t1 = </span><span class="s5">1 </span><span class="s1">/ (np.log(b) - np.log(a)) / n</span>
        <span class="s1">t2 = np.real(np.exp(_log_diff(n * np.log(b)</span><span class="s2">, </span><span class="s1">n*np.log(a))))</span>
        <span class="s2">return </span><span class="s1">t1 * t2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">*(np.log(a) + np.log(b)) + np.log(np.log(b) - np.log(a))</span>

    <span class="s1">fit_note = </span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">`loguniform`/`reciprocal` is over-parameterized. `fit` automatically 
         fixes `scale` to 1 unless `fscale` is provided by the user.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span>

    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=fit_note)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">fscale = kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">fscale=fscale</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">loguniform = reciprocal_gen(name=</span><span class="s4">&quot;loguniform&quot;</span><span class="s1">)</span>
<span class="s1">reciprocal = reciprocal_gen(name=</span><span class="s4">&quot;reciprocal&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">rice_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Rice continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `rice` is: 
 
    .. math:: 
 
        f(x, b) = x \exp(- \frac{x^2 + b^2}{2}) I_0(x b) 
 
    for :math:`x &gt;= 0`, :math:`b &gt; 0`. :math:`I_0` is the modified Bessel 
    function of order zero (`scipy.special.i0`). 
 
    `rice` takes ``b`` as a shape parameter for :math:`b`. 
 
    %(after_notes)s 
 
    The Rice distribution describes the length, :math:`r`, of a 2-D vector with 
    components :math:`(U+u, V+v)`, where :math:`U, V` are constant, :math:`u, 
    v` are independent Gaussian random variables with standard deviation 
    :math:`s`.  Let :math:`R = \sqrt{U^2 + V^2}`. Then the pdf of :math:`r` is 
    ``rice.pdf(x, R/s, scale=s)``. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">b &gt;= </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># https://en.wikipedia.org/wiki/Rice_distribution</span>
        <span class="s1">t = b/np.sqrt(</span><span class="s5">2</span><span class="s1">) + random_state.standard_normal(size=(</span><span class="s5">2</span><span class="s2">,</span><span class="s1">) + size)</span>
        <span class="s2">return </span><span class="s1">np.sqrt((t*t).sum(axis=</span><span class="s5">0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">sc.chndtr(np.square(x)</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s1">np.square(b))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.sqrt(sc.chndtrix(q</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s1">np.square(b)))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># rice.pdf(x, b) = x * exp(-(x**2+b**2)/2) * I[0](x*b)</span>
        <span class="s0">#</span>
        <span class="s0"># We use (x**2 + b**2)/2 = ((x-b)**2)/2 + xb.</span>
        <span class="s0"># The factor of np.exp(-xb) is then included in the i0e function</span>
        <span class="s0"># in place of the modified Bessel function, i0, improving</span>
        <span class="s0"># numerical stability for large values of xb.</span>
        <span class="s2">return </span><span class="s1">x * np.exp(-(x-b)*(x-b)/</span><span class="s5">2.0</span><span class="s1">) * sc.i0e(x*b)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">nd2 = n/</span><span class="s5">2.0</span>
        <span class="s1">n1 = </span><span class="s5">1 </span><span class="s1">+ nd2</span>
        <span class="s1">b2 = b*b/</span><span class="s5">2.0</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">2.0</span><span class="s1">**(nd2) * np.exp(-b2) * sc.gamma(n1) *</span>
                <span class="s1">sc.hyp1f1(n1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">b2))</span>


<span class="s1">rice = rice_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;rice&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">recipinvgauss_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A reciprocal inverse Gaussian continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `recipinvgauss` is: 
 
    .. math:: 
 
        f(x, \mu) = \frac{1}{\sqrt{2\pi x}} 
                    \exp\left(\frac{-(1-\mu x)^2}{2\mu^2x}\right) 
 
    for :math:`x \ge 0`. 
 
    `recipinvgauss` takes ``mu`` as a shape parameter for :math:`\mu`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;mu&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s0"># recipinvgauss.pdf(x, mu) =</span>
        <span class="s0">#                     1/sqrt(2*pi*x) * exp(-(1-mu*x)**2/(2*x*mu**2))</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">mu))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(x &gt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">mu)</span><span class="s2">,</span>
                          <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu: (-(</span><span class="s5">1 </span><span class="s1">- mu*x)**</span><span class="s5">2.0 </span><span class="s1">/ (</span><span class="s5">2</span><span class="s1">*x*mu**</span><span class="s5">2.0</span><span class="s1">)</span>
                                         <span class="s1">- </span><span class="s5">0.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">*np.pi*x))</span><span class="s2">,</span>
                          <span class="s1">fillvalue=-np.inf)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">trm1 = </span><span class="s5">1.0</span><span class="s1">/mu - x</span>
        <span class="s1">trm2 = </span><span class="s5">1.0</span><span class="s1">/mu + x</span>
        <span class="s1">isqx = </span><span class="s5">1.0</span><span class="s1">/np.sqrt(x)</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(-isqx*trm1) - np.exp(</span><span class="s5">2.0</span><span class="s1">/mu)*_norm_cdf(-isqx*trm2)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">trm1 = </span><span class="s5">1.0</span><span class="s1">/mu - x</span>
        <span class="s1">trm2 = </span><span class="s5">1.0</span><span class="s1">/mu + x</span>
        <span class="s1">isqx = </span><span class="s5">1.0</span><span class="s1">/np.sqrt(x)</span>
        <span class="s2">return </span><span class="s1">_norm_cdf(isqx*trm1) + np.exp(</span><span class="s5">2.0</span><span class="s1">/mu)*_norm_cdf(-isqx*trm2)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/random_state.wald(mu</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">size=size)</span>


<span class="s1">recipinvgauss = recipinvgauss_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'recipinvgauss'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">semicircular_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A semicircular continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    rdist 
 
    Notes 
    ----- 
    The probability density function for `semicircular` is: 
 
    .. math:: 
 
        f(x) = \frac{2}{\pi} \sqrt{1-x^2} 
 
    for :math:`-1 \le x \le 1`. 
 
    The distribution is a special case of `rdist` with `c = 3`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Wigner semicircle distribution&quot;, 
           https://en.wikipedia.org/wiki/Wigner_semicircle_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">2.0</span><span class="s1">/np.pi*np.sqrt(</span><span class="s5">1</span><span class="s1">-x*x)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">/np.pi) + </span><span class="s5">0.5</span><span class="s1">*sc.log1p(-x*x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">+</span><span class="s5">1.0</span><span class="s1">/np.pi*(x*np.sqrt(</span><span class="s5">1</span><span class="s1">-x*x) + np.arcsin(x))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">rdist._ppf(q</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># generate values uniformly distributed on the area under the pdf</span>
        <span class="s0"># (semi-circle) by randomly generating the radius and angle</span>
        <span class="s1">r = np.sqrt(random_state.uniform(size=size))</span>
        <span class="s1">a = np.cos(np.pi * random_state.uniform(size=size))</span>
        <span class="s2">return </span><span class="s1">r * a</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0.25</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1.0</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">0.64472988584940017414</span>


<span class="s1">semicircular = semicircular_gen(a=-</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;semicircular&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">skewcauchy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A skewed Cauchy random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    cauchy : Cauchy distribution 
 
    Notes 
    ----- 
 
    The probability density function for `skewcauchy` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{\pi \left(\frac{x^2}{\left(a\, \text{sign}(x) + 1 
                                                   \right)^2} + 1 \right)} 
 
    for a real number :math:`x` and skewness parameter :math:`-1 &lt; a &lt; 1`. 
 
    When :math:`a=0`, the distribution reduces to the usual Cauchy 
    distribution. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Skewed generalized *t* distribution&quot;, Wikipedia 
       https://en.wikipedia.org/wiki/Skewed_generalized_t_distribution#Skewed_Cauchy_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.abs(a) &lt; </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(-</span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">/ (np.pi * (x**</span><span class="s5">2 </span><span class="s1">/ (a * np.sign(x) + </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.where(x &lt;= </span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s1">(</span><span class="s5">1 </span><span class="s1">- a) / </span><span class="s5">2 </span><span class="s1">+ (</span><span class="s5">1 </span><span class="s1">- a) / np.pi * np.arctan(x / (</span><span class="s5">1 </span><span class="s1">- a))</span><span class="s2">,</span>
                        <span class="s1">(</span><span class="s5">1 </span><span class="s1">- a) / </span><span class="s5">2 </span><span class="s1">+ (</span><span class="s5">1 </span><span class="s1">+ a) / np.pi * np.arctan(x / (</span><span class="s5">1 </span><span class="s1">+ a)))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">i = x &lt; self._cdf(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">a)</span>
        <span class="s2">return </span><span class="s1">np.where(i</span><span class="s2">,</span>
                        <span class="s1">np.tan(np.pi / (</span><span class="s5">1 </span><span class="s1">- a) * (x - (</span><span class="s5">1 </span><span class="s1">- a) / </span><span class="s5">2</span><span class="s1">)) * (</span><span class="s5">1 </span><span class="s1">- a)</span><span class="s2">,</span>
                        <span class="s1">np.tan(np.pi / (</span><span class="s5">1 </span><span class="s1">+ a) * (x - (</span><span class="s5">1 </span><span class="s1">- a) / </span><span class="s5">2</span><span class="s1">)) * (</span><span class="s5">1 </span><span class="s1">+ a))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mvsk'</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Use 0 as the initial guess of the skewness shape parameter.</span>
        <span class="s0"># For the location and scale, estimate using the median and</span>
        <span class="s0"># quartiles.</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s1">p25</span><span class="s2">, </span><span class="s1">p50</span><span class="s2">, </span><span class="s1">p75 = np.percentile(data</span><span class="s2">, </span><span class="s1">[</span><span class="s5">25</span><span class="s2">, </span><span class="s5">50</span><span class="s2">, </span><span class="s5">75</span><span class="s1">])</span>
        <span class="s2">return </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">p50</span><span class="s2">, </span><span class="s1">(p75 - p25)/</span><span class="s5">2</span>


<span class="s1">skewcauchy = skewcauchy_gen(name=</span><span class="s4">'skewcauchy'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">skewnorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A skew-normal random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The pdf is:: 
 
        skewnorm.pdf(x, a) = 2 * norm.pdf(x) * norm.cdf(a*x) 
 
    `skewnorm` takes a real number :math:`a` as a skewness parameter 
    When ``a = 0`` the distribution is identical to a normal distribution 
    (`norm`). `rvs` implements the method of [1]_. 
 
    %(after_notes)s 
 
    %(example)s 
 
    References 
    ---------- 
    .. [1] A. Azzalini and A. Capitanio (1999). Statistical applications of 
        the multivariate skew-normal distribution. J. Roy. Statist. Soc., 
        B 61, 579-602. :arxiv:`0911.2093` 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">np.isfinite(a)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">a == </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">a)</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a: _norm_pdf(x)</span><span class="s2">,</span>
            <span class="s1">f2=</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a: </span><span class="s5">2.</span><span class="s1">*_norm_pdf(x)*_norm_cdf(a*x)</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">a = np.atleast_1d(a)</span>
        <span class="s1">cdf = _boost._skewnorm_cdf(x</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">a)</span>
        <span class="s0"># for some reason, a isn't broadcasted if some of x are invalid</span>
        <span class="s1">a = np.broadcast_to(a</span><span class="s2">, </span><span class="s1">cdf.shape)</span>
        <span class="s0"># Boost is not accurate in left tail when a &gt; 0</span>
        <span class="s1">i_small_cdf = (cdf &lt; </span><span class="s5">1e-6</span><span class="s1">) &amp; (a &gt; </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cdf[i_small_cdf] = super()._cdf(x[i_small_cdf]</span><span class="s2">, </span><span class="s1">a[i_small_cdf])</span>
        <span class="s2">return </span><span class="s1">np.clip(cdf</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">_boost._skewnorm_ppf(x</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># Boost's SF is implemented this way. Use whatever customizations</span>
        <span class="s0"># we made in the _cdf.</span>
        <span class="s2">return </span><span class="s1">self._cdf(-x</span><span class="s2">, </span><span class="s1">-a)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">_boost._skewnorm_isf(x</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">u0 = random_state.normal(size=size)</span>
        <span class="s1">v = random_state.normal(size=size)</span>
        <span class="s1">d = a/np.sqrt(</span><span class="s5">1 </span><span class="s1">+ a**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">u1 = d*u0 + v*np.sqrt(</span><span class="s5">1 </span><span class="s1">- d**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.where(u0 &gt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">u1</span><span class="s2">, </span><span class="s1">-u1)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mvsk'</span><span class="s1">):</span>
        <span class="s1">output = [</span><span class="s2">None, None, None, None</span><span class="s1">]</span>
        <span class="s1">const = np.sqrt(</span><span class="s5">2</span><span class="s1">/np.pi) * a/np.sqrt(</span><span class="s5">1 </span><span class="s1">+ a**</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s4">'m' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">output[</span><span class="s5">0</span><span class="s1">] = const</span>
        <span class="s2">if </span><span class="s4">'v' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">output[</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1 </span><span class="s1">- const**</span><span class="s5">2</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">output[</span><span class="s5">2</span><span class="s1">] = ((</span><span class="s5">4 </span><span class="s1">- np.pi)/</span><span class="s5">2</span><span class="s1">) * (const/np.sqrt(</span><span class="s5">1 </span><span class="s1">- const**</span><span class="s5">2</span><span class="s1">))**</span><span class="s5">3</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">output[</span><span class="s5">3</span><span class="s1">] = (</span><span class="s5">2</span><span class="s1">*(np.pi - </span><span class="s5">3</span><span class="s1">)) * (const**</span><span class="s5">4</span><span class="s1">/(</span><span class="s5">1 </span><span class="s1">- const**</span><span class="s5">2</span><span class="s1">)**</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">output</span>

    <span class="s0"># For odd order, the each noncentral moment of the skew-normal distribution</span>
    <span class="s0"># with location 0 and scale 1 can be expressed as a polynomial in delta,</span>
    <span class="s0"># where delta = a/sqrt(1 + a**2) and `a` is the skew-normal shape</span>
    <span class="s0"># parameter.  The dictionary _skewnorm_odd_moments defines those</span>
    <span class="s0"># polynomials for orders up to 19.  The dict is implemented as a cached</span>
    <span class="s0"># property to reduce the impact of the creation of the dict on import time.</span>
    <span class="s1">@cached_property</span>
    <span class="s2">def </span><span class="s1">_skewnorm_odd_moments(self):</span>
        <span class="s1">skewnorm_odd_moments = {</span>
            <span class="s5">1</span><span class="s1">: Polynomial([</span><span class="s5">1</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">3</span><span class="s1">: Polynomial([</span><span class="s5">3</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">5</span><span class="s1">: Polynomial([</span><span class="s5">15</span><span class="s2">, </span><span class="s1">-</span><span class="s5">10</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">7</span><span class="s1">: Polynomial([</span><span class="s5">105</span><span class="s2">, </span><span class="s1">-</span><span class="s5">105</span><span class="s2">, </span><span class="s5">63</span><span class="s2">, </span><span class="s1">-</span><span class="s5">15</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">9</span><span class="s1">: Polynomial([</span><span class="s5">945</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1260</span><span class="s2">, </span><span class="s5">1134</span><span class="s2">, </span><span class="s1">-</span><span class="s5">540</span><span class="s2">, </span><span class="s5">105</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">11</span><span class="s1">: Polynomial([</span><span class="s5">10395</span><span class="s2">, </span><span class="s1">-</span><span class="s5">17325</span><span class="s2">, </span><span class="s5">20790</span><span class="s2">, </span><span class="s1">-</span><span class="s5">14850</span><span class="s2">, </span><span class="s5">5775</span><span class="s2">, </span><span class="s1">-</span><span class="s5">945</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">13</span><span class="s1">: Polynomial([</span><span class="s5">135135</span><span class="s2">, </span><span class="s1">-</span><span class="s5">270270</span><span class="s2">, </span><span class="s5">405405</span><span class="s2">, </span><span class="s1">-</span><span class="s5">386100</span><span class="s2">, </span><span class="s5">225225</span><span class="s2">, </span><span class="s1">-</span><span class="s5">73710</span><span class="s2">,</span>
                            <span class="s5">10395</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">15</span><span class="s1">: Polynomial([</span><span class="s5">2027025</span><span class="s2">, </span><span class="s1">-</span><span class="s5">4729725</span><span class="s2">, </span><span class="s5">8513505</span><span class="s2">, </span><span class="s1">-</span><span class="s5">10135125</span><span class="s2">, </span><span class="s5">7882875</span><span class="s2">,</span>
                            <span class="s1">-</span><span class="s5">3869775</span><span class="s2">, </span><span class="s5">1091475</span><span class="s2">, </span><span class="s1">-</span><span class="s5">135135</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">17</span><span class="s1">: Polynomial([</span><span class="s5">34459425</span><span class="s2">, </span><span class="s1">-</span><span class="s5">91891800</span><span class="s2">, </span><span class="s5">192972780</span><span class="s2">, </span><span class="s1">-</span><span class="s5">275675400</span><span class="s2">,</span>
                            <span class="s5">268017750</span><span class="s2">, </span><span class="s1">-</span><span class="s5">175429800</span><span class="s2">, </span><span class="s5">74220300</span><span class="s2">, </span><span class="s1">-</span><span class="s5">18378360</span><span class="s2">,</span>
                            <span class="s5">2027025</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">19</span><span class="s1">: Polynomial([</span><span class="s5">654729075</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1964187225</span><span class="s2">, </span><span class="s5">4714049340</span><span class="s2">, </span><span class="s1">-</span><span class="s5">7856748900</span><span class="s2">,</span>
                            <span class="s5">9166207050</span><span class="s2">, </span><span class="s1">-</span><span class="s5">7499623950</span><span class="s2">, </span><span class="s5">4230557100</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1571349780</span><span class="s2">,</span>
                            <span class="s5">346621275</span><span class="s2">, </span><span class="s1">-</span><span class="s5">34459425</span><span class="s1">])</span><span class="s2">,</span>
        <span class="s1">}</span>
        <span class="s2">return </span><span class="s1">skewnorm_odd_moments</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">order</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">if </span><span class="s1">order &amp; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">order &gt; </span><span class="s5">19</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s4">&quot;skewnorm noncentral moments not &quot;</span>
                                          <span class="s4">&quot;implemented for odd orders greater &quot;</span>
                                          <span class="s4">&quot;than 19.&quot;</span><span class="s1">)</span>
            <span class="s0"># Use the precomputed polynomials that were derived from the</span>
            <span class="s0"># moment generating function.</span>
            <span class="s1">delta = a/np.sqrt(</span><span class="s5">1 </span><span class="s1">+ a**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">(delta * self._skewnorm_odd_moments[order](delta**</span><span class="s5">2</span><span class="s1">)</span>
                    <span class="s1">* _SQRT_2_OVER_PI)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># For even order, the moment is just (order-1)!!, where !! is the</span>
            <span class="s0"># notation for the double factorial; for an odd integer m, m!! is</span>
            <span class="s0"># m*(m-2)*...*3*1.</span>
            <span class="s0"># We could use special.factorial2, but we know the argument is odd,</span>
            <span class="s0"># so avoid the overhead of that function and compute the result</span>
            <span class="s0"># directly here.</span>
            <span class="s2">return </span><span class="s1">sc.gamma((order + </span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">2</span><span class="s1">**(order/</span><span class="s5">2</span><span class="s1">) / _SQRT_PI</span>

    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">If ``method='mm'``, parameters fixed by the user are respected, and the 
        remaining parameters are used to match distribution and sample moments 
        where possible. For example, if the user fixes the location with 
        ``floc``, the parameters will only match the distribution skewness and 
        variance to the sample skewness and variance; no attempt will be made 
        to match the means or minimize a norm of the errors. 
        Note that the maximum possible skewness magnitude of a 
        `scipy.stats.skewnorm` distribution is approximately 0.9952717; if the 
        magnitude of the data's sample skewness exceeds this, the returned 
        shape parameter ``a`` will be infinite. 
        </span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s2">if </span><span class="s1">data.num_censored() == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">data = data._uncensor()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># this extracts fixed shape, location, and scale however they</span>
        <span class="s0"># are specified, and also leaves them in `kwds`</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">fa</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                             <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">method = kwds.get(</span><span class="s4">&quot;method&quot;</span><span class="s2">, </span><span class="s4">&quot;mle&quot;</span><span class="s1">).lower()</span>

        <span class="s0"># See https://en.wikipedia.org/wiki/Skew_normal_distribution for</span>
        <span class="s0"># moment formulas.</span>
        <span class="s2">def </span><span class="s1">skew_d(d):  </span><span class="s0"># skewness in terms of delta</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">4</span><span class="s1">-np.pi)/</span><span class="s5">2 </span><span class="s1">* ((d * np.sqrt(</span><span class="s5">2 </span><span class="s1">/ np.pi))**</span><span class="s5">3</span>
                                  <span class="s1">/ (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2</span><span class="s1">*d**</span><span class="s5">2 </span><span class="s1">/ np.pi)**(</span><span class="s5">3</span><span class="s1">/</span><span class="s5">2</span><span class="s1">))</span>

        <span class="s0"># If skewness of data is greater than max possible population skewness,</span>
        <span class="s0"># MoM won't provide a good guess. Get out early.</span>
        <span class="s1">s = stats.skew(data)</span>
        <span class="s1">s_max = skew_d(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">abs(s) &gt;= s_max </span><span class="s2">and </span><span class="s1">method != </span><span class="s4">&quot;mm&quot; </span><span class="s2">and </span><span class="s1">fa </span><span class="s2">is None and not </span><span class="s1">args:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># If method is method of moments, we don't need the user's guesses.</span>
        <span class="s0"># Otherwise, extract the guesses from args and kwds.</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;mm&quot;</span><span class="s1">:</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = </span><span class="s2">None, None, None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a = args[</span><span class="s5">0</span><span class="s1">] </span><span class="s2">if </span><span class="s1">len(args) </span><span class="s2">else None</span>
            <span class="s1">loc = kwds.pop(</span><span class="s4">'loc'</span><span class="s2">, None</span><span class="s1">)</span>
            <span class="s1">scale = kwds.pop(</span><span class="s4">'scale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">fa </span><span class="s2">is None and </span><span class="s1">a </span><span class="s2">is None</span><span class="s1">:  </span><span class="s0"># not fixed and no guess: use MoM</span>
            <span class="s0"># Solve for a that matches sample distribution skewness to sample</span>
            <span class="s0"># skewness.</span>
            <span class="s1">s = np.clip(s</span><span class="s2">, </span><span class="s1">-s_max</span><span class="s2">, </span><span class="s1">s_max)</span>
            <span class="s1">d = root_scalar(</span><span class="s2">lambda </span><span class="s1">d: skew_d(d) - s</span><span class="s2">, </span><span class="s1">bracket=[-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]).root</span>
            <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
                <span class="s1">a = np.sqrt(np.divide(d**</span><span class="s5">2</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s1">-d**</span><span class="s5">2</span><span class="s1">)))*np.sign(s)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a = fa </span><span class="s2">if </span><span class="s1">fa </span><span class="s2">is not None else </span><span class="s1">a</span>
            <span class="s1">d = a / np.sqrt(</span><span class="s5">1 </span><span class="s1">+ a**</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None and </span><span class="s1">scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">v = np.var(data)</span>
            <span class="s1">scale = np.sqrt(v / (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2</span><span class="s1">*d**</span><span class="s5">2</span><span class="s1">/np.pi))</span>
        <span class="s2">elif </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">scale = fscale</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None and </span><span class="s1">loc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">m = np.mean(data)</span>
            <span class="s1">loc = m - scale*d*np.sqrt(</span><span class="s5">2</span><span class="s1">/np.pi)</span>
        <span class="s2">elif </span><span class="s1">floc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">loc = floc</span>

        <span class="s2">if </span><span class="s1">method == </span><span class="s4">'mm'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># At this point, parameter &quot;guesses&quot; may equal the fixed parameters</span>
            <span class="s0"># in kwds. No harm in passing them as guesses, too.</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">loc=loc</span><span class="s2">, </span><span class="s1">scale=scale</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">skewnorm = skewnorm_gen(name=</span><span class="s4">'skewnorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">trapezoid_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A trapezoidal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The trapezoidal distribution can be represented with an up-sloping line 
    from ``loc`` to ``(loc + c*scale)``, then constant to ``(loc + d*scale)`` 
    and then downsloping from ``(loc + d*scale)`` to ``(loc+scale)``.  This 
    defines the trapezoid base from ``loc`` to ``(loc+scale)`` and the flat 
    top from ``c`` to ``d`` proportional to the position along the base 
    with ``0 &lt;= c &lt;= d &lt;= 1``.  When ``c=d``, this is equivalent to `triang` 
    with the same values for `loc`, `scale` and `c`. 
    The method of [1]_ is used for computing moments. 
 
    `trapezoid` takes :math:`c` and :math:`d` as shape parameters. 
 
    %(after_notes)s 
 
    The standard form is in the range [0, 1] with c the mode. 
    The location parameter shifts the start to `loc`. 
    The scale parameter changes the width from 1 to `scale`. 
 
    %(example)s 
 
    References 
    ---------- 
    .. [1] Kacker, R.N. and Lawrence, J.F. (2007). Trapezoidal and triangular 
       distributions for Type B evaluation of standard uncertainty. 
       Metrologia 44, 117-127. :doi:`10.1088/0026-1394/44/2/003` 
 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">(c &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (c &lt;= </span><span class="s5">1</span><span class="s1">) &amp; (d &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (d &lt;= </span><span class="s5">1</span><span class="s1">) &amp; (d &gt;= c)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))</span>
        <span class="s1">id = _ShapeInfo(</span><span class="s4">&quot;d&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ic</span><span class="s2">, </span><span class="s1">id]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s1">u = </span><span class="s5">2 </span><span class="s1">/ (d-c+</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">_lazyselect([x &lt; c</span><span class="s2">,</span>
                            <span class="s1">(c &lt;= x) &amp; (x &lt;= d)</span><span class="s2">,</span>
                            <span class="s1">x &gt; d]</span><span class="s2">,</span>
                           <span class="s1">[</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">u: u * x / c</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">u: u</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">u: u * (</span><span class="s5">1</span><span class="s1">-x) / (</span><span class="s5">1</span><span class="s1">-d)]</span><span class="s2">,</span>
                           <span class="s1">(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">u))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s2">return </span><span class="s1">_lazyselect([x &lt; c</span><span class="s2">,</span>
                            <span class="s1">(c &lt;= x) &amp; (x &lt;= d)</span><span class="s2">,</span>
                            <span class="s1">x &gt; d]</span><span class="s2">,</span>
                           <span class="s1">[</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d: x**</span><span class="s5">2 </span><span class="s1">/ c / (d-c+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d: (c + </span><span class="s5">2 </span><span class="s1">* (x-c)) / (d-c+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d: </span><span class="s5">1</span><span class="s1">-((</span><span class="s5">1</span><span class="s1">-x) ** </span><span class="s5">2</span>
                                               <span class="s1">/ (d-c+</span><span class="s5">1</span><span class="s1">) / (</span><span class="s5">1</span><span class="s1">-d))]</span><span class="s2">,</span>
                           <span class="s1">(x</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s1">qc</span><span class="s2">, </span><span class="s1">qd = self._cdf(c</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d)</span><span class="s2">, </span><span class="s1">self._cdf(d</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d)</span>
        <span class="s1">condlist = [q &lt; qc</span><span class="s2">, </span><span class="s1">q &lt;= qd</span><span class="s2">, </span><span class="s1">q &gt; qd]</span>
        <span class="s1">choicelist = [np.sqrt(q * c * (</span><span class="s5">1 </span><span class="s1">+ d - c))</span><span class="s2">,</span>
                      <span class="s5">0.5 </span><span class="s1">* q * (</span><span class="s5">1 </span><span class="s1">+ d - c) + </span><span class="s5">0.5 </span><span class="s1">* c</span><span class="s2">,</span>
                      <span class="s5">1 </span><span class="s1">- np.sqrt((</span><span class="s5">1 </span><span class="s1">- q) * (d - c + </span><span class="s5">1</span><span class="s1">) * (</span><span class="s5">1 </span><span class="s1">- d))]</span>
        <span class="s2">return </span><span class="s1">np.select(condlist</span><span class="s2">, </span><span class="s1">choicelist)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s0"># Using the parameterization from Kacker, 2007, with</span>
        <span class="s0"># a=bottom left, c=top left, d=top right, b=bottom right, then</span>
        <span class="s0">#     E[X^n] = h/(n+1)/(n+2) [(b^{n+2}-d^{n+2})/(b-d)</span>
        <span class="s0">#                             - ((c^{n+2} - a^{n+2})/(c-a)]</span>
        <span class="s0"># with h = 2/((b-a) - (d-c)). The corresponding parameterization</span>
        <span class="s0"># in scipy, has a'=loc, c'=loc+c*scale, d'=loc+d*scale, b'=loc+scale,</span>
        <span class="s0"># which for standard form reduces to a'=0, b'=1, c'=c, d'=d.</span>
        <span class="s0"># Substituting into E[X^n] gives the bd' term as (1 - d^{n+2})/(1 - d)</span>
        <span class="s0"># and the ac' term as c^{n-1} for the standard form. The bd' term has</span>
        <span class="s0"># numerical difficulties near d=1, so replace (1 - d^{n+2})/(1-d)</span>
        <span class="s0"># with expm1((n+2)*log(d))/(d-1).</span>
        <span class="s0"># Testing with n=18 for c=(1e-30,1-eps) shows that this is stable.</span>
        <span class="s0"># We still require an explicit test for d=1 to prevent divide by zero,</span>
        <span class="s0"># and now a test for d=0 to prevent log(0).</span>
        <span class="s1">ab_term = c**(n+</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">dc_term = _lazyselect(</span>
            <span class="s1">[d == </span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">(</span><span class="s5">0.0 </span><span class="s1">&lt; d) &amp; (d &lt; </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">d == </span><span class="s5">1.0</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s2">lambda </span><span class="s1">d: </span><span class="s5">1.0</span><span class="s2">,</span>
             <span class="s2">lambda </span><span class="s1">d: np.expm1((n+</span><span class="s5">2</span><span class="s1">) * np.log(d)) / (d-</span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">,</span>
             <span class="s2">lambda </span><span class="s1">d: n+</span><span class="s5">2</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[d])</span>
        <span class="s1">val = </span><span class="s5">2.0 </span><span class="s1">/ (</span><span class="s5">1.0</span><span class="s1">+d-c) * (dc_term - ab_term) / ((n+</span><span class="s5">1</span><span class="s1">) * (n+</span><span class="s5">2</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">val</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">d):</span>
        <span class="s0"># Using the parameterization from Wikipedia (van Dorp, 2003)</span>
        <span class="s0"># with a=bottom left, c=top left, d=top right, b=bottom right</span>
        <span class="s0"># gives a'=loc, b'=loc+c*scale, c'=loc+d*scale, d'=loc+scale,</span>
        <span class="s0"># which for loc=0, scale=1 is a'=0, b'=c, c'=d, d'=1.</span>
        <span class="s0"># Substituting into the entropy formula from Wikipedia gives</span>
        <span class="s0"># the following result.</span>
        <span class="s2">return </span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">1.0</span><span class="s1">-d+c) / (</span><span class="s5">1.0</span><span class="s1">+d-c) + np.log(</span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">1.0</span><span class="s1">+d-c))</span>


<span class="s1">trapezoid = trapezoid_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;trapezoid&quot;</span><span class="s1">)</span>
<span class="s0"># Note: alias kept for backwards compatibility. Rename was done</span>
<span class="s0"># because trapz is a slur in colloquial English (see gh-12924).</span>
<span class="s1">trapz = trapezoid_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;trapz&quot;</span><span class="s1">)</span>
<span class="s2">if </span><span class="s1">trapz.__doc__:</span>
    <span class="s1">trapz.__doc__ = </span><span class="s4">&quot;trapz is an alias for `trapezoid`&quot;</span>


<span class="s2">class </span><span class="s1">triang_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A triangular continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The triangular distribution can be represented with an up-sloping line from 
    ``loc`` to ``(loc + c*scale)`` and then downsloping for ``(loc + c*scale)`` 
    to ``(loc + scale)``. 
 
    `triang` takes ``c`` as a shape parameter for :math:`0 \le c \le 1`. 
 
    %(after_notes)s 
 
    The standard form is in the range [0, 1] with c the mode. 
    The location parameter shifts the start to `loc`. 
    The scale parameter changes the width from 1 to `scale`. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.triangular(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(c &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (c &lt;= </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># 0: edge case where c=0</span>
        <span class="s0"># 1: generalised case for x &lt; c, don't use x &lt;= c, as it doesn't cope</span>
        <span class="s0">#    with c = 0.</span>
        <span class="s0"># 2: generalised case for x &gt;= c, but doesn't cope with c = 1</span>
        <span class="s0"># 3: edge case where c=1</span>
        <span class="s1">r = _lazyselect([c == </span><span class="s5">0</span><span class="s2">,</span>
                         <span class="s1">x &lt; c</span><span class="s2">,</span>
                         <span class="s1">(x &gt;= c) &amp; (c != </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s1">c == </span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
                        <span class="s1">[</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: </span><span class="s5">2 </span><span class="s1">- </span><span class="s5">2 </span><span class="s1">* x</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: </span><span class="s5">2 </span><span class="s1">* x / c</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: </span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">- x) / (</span><span class="s5">1 </span><span class="s1">- c)</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: </span><span class="s5">2 </span><span class="s1">* x]</span><span class="s2">,</span>
                        <span class="s1">(x</span><span class="s2">, </span><span class="s1">c))</span>
        <span class="s2">return </span><span class="s1">r</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">r = _lazyselect([c == </span><span class="s5">0</span><span class="s2">,</span>
                         <span class="s1">x &lt; c</span><span class="s2">,</span>
                         <span class="s1">(x &gt;= c) &amp; (c != </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s1">c == </span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
                        <span class="s1">[</span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: </span><span class="s5">2</span><span class="s1">*x - x*x</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: x * x / c</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: (x*x - </span><span class="s5">2</span><span class="s1">*x + c) / (c-</span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c: x * x]</span><span class="s2">,</span>
                        <span class="s1">(x</span><span class="s2">, </span><span class="s1">c))</span>
        <span class="s2">return </span><span class="s1">r</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.where(q &lt; c</span><span class="s2">, </span><span class="s1">np.sqrt(c * q)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">-np.sqrt((</span><span class="s5">1</span><span class="s1">-c) * (</span><span class="s5">1</span><span class="s1">-q)))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">((c+</span><span class="s5">1.0</span><span class="s1">)/</span><span class="s5">3.0</span><span class="s2">,</span>
                <span class="s1">(</span><span class="s5">1.0</span><span class="s1">-c+c*c)/</span><span class="s5">18</span><span class="s2">,</span>
                <span class="s1">np.sqrt(</span><span class="s5">2</span><span class="s1">)*(</span><span class="s5">2</span><span class="s1">*c-</span><span class="s5">1</span><span class="s1">)*(c+</span><span class="s5">1</span><span class="s1">)*(c-</span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">5</span><span class="s1">*np.power((</span><span class="s5">1.0</span><span class="s1">-c+c*c)</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">-</span><span class="s5">3.0</span><span class="s1">/</span><span class="s5">5.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s1">-np.log(</span><span class="s5">2</span><span class="s1">)</span>


<span class="s1">triang = triang_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;triang&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">truncexpon_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A truncated exponential continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `truncexpon` is: 
 
    .. math:: 
 
        f(x, b) = \frac{\exp(-x)}{1 - \exp(-b)} 
 
    for :math:`0 &lt;= x &lt;= b`. 
 
    `truncexpon` takes ``b`` as a shape parameter for :math:`b`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># truncexpon.pdf(x, b) = exp(-x) / (1-exp(-b))</span>
        <span class="s2">return </span><span class="s1">np.exp(-x)/(-sc.expm1(-b))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">-x - np.log(-sc.expm1(-b))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">sc.expm1(-x)/sc.expm1(-b)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">-sc.log1p(q*sc.expm1(-b))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(np.exp(-b) - np.exp(-x))/sc.expm1(-b)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">-np.log(np.exp(-b) - q * sc.expm1(-b))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># wrong answer with formula, same as in continuous.pdf</span>
        <span class="s0"># return sc.gamman+1)-sc.gammainc1+n, b)</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">1</span><span class="s1">-(b+</span><span class="s5">1</span><span class="s1">)*np.exp(-b))/(-sc.expm1(-b))</span>
        <span class="s2">elif </span><span class="s1">n == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">-</span><span class="s5">0.5</span><span class="s1">*(b*b+</span><span class="s5">2</span><span class="s1">*b+</span><span class="s5">2</span><span class="s1">)*np.exp(-b))/(-sc.expm1(-b))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># return generic for higher moments</span>
            <span class="s2">return </span><span class="s1">super()._munp(n</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">eB = np.exp(b)</span>
        <span class="s2">return </span><span class="s1">np.log(eB-</span><span class="s5">1</span><span class="s1">)+(</span><span class="s5">1</span><span class="s1">+eB*(b-</span><span class="s5">1.0</span><span class="s1">))/(</span><span class="s5">1.0</span><span class="s1">-eB)</span>


<span class="s1">truncexpon = truncexpon_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'truncexpon'</span><span class="s1">)</span>


<span class="s0"># logsumexp trick for log(p + q) with only log(p) and log(q)</span>
<span class="s2">def </span><span class="s1">_log_sum(log_p</span><span class="s2">, </span><span class="s1">log_q):</span>
    <span class="s2">return </span><span class="s1">sc.logsumexp([log_p</span><span class="s2">, </span><span class="s1">log_q]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>


<span class="s0"># same as above, but using -exp(x) = exp(x + i)</span>
<span class="s2">def </span><span class="s1">_log_diff(log_p</span><span class="s2">, </span><span class="s1">log_q):</span>
    <span class="s2">return </span><span class="s1">sc.logsumexp([log_p</span><span class="s2">, </span><span class="s1">log_q+np.pi*</span><span class="s5">1j</span><span class="s1">]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b):</span>
    <span class="s3">&quot;&quot;&quot;Log of Gaussian probability mass within an interval&quot;&quot;&quot;</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s0"># Calculations in right tail are inaccurate, so we'll exploit the</span>
    <span class="s0"># symmetry and work only in the left tail</span>
    <span class="s1">case_left = b &lt;= </span><span class="s5">0</span>
    <span class="s1">case_right = a &gt; </span><span class="s5">0</span>
    <span class="s1">case_central = ~(case_left | case_right)</span>

    <span class="s2">def </span><span class="s1">mass_case_left(a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_log_diff(_norm_logcdf(b)</span><span class="s2">, </span><span class="s1">_norm_logcdf(a))</span>

    <span class="s2">def </span><span class="s1">mass_case_right(a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">mass_case_left(-b</span><span class="s2">, </span><span class="s1">-a)</span>

    <span class="s2">def </span><span class="s1">mass_case_central(a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># Previously, this was implemented as:</span>
        <span class="s0"># left_mass = mass_case_left(a, 0)</span>
        <span class="s0"># right_mass = mass_case_right(0, b)</span>
        <span class="s0"># return _log_sum(left_mass, right_mass)</span>
        <span class="s0"># Catastrophic cancellation occurs as np.exp(log_mass) approaches 1.</span>
        <span class="s0"># Correct for this with an alternative formulation.</span>
        <span class="s0"># We're not concerned with underflow here: if only one term</span>
        <span class="s0"># underflows, it was insignificant; if both terms underflow,</span>
        <span class="s0"># the result can't accurately be represented in logspace anyway</span>
        <span class="s0"># because sc.log1p(x) ~ x for small x.</span>
        <span class="s2">return </span><span class="s1">sc.log1p(-_norm_cdf(a) - _norm_cdf(-b))</span>

    <span class="s0"># _lazyselect not working; don't care to debug it</span>
    <span class="s1">out = np.full_like(a</span><span class="s2">, </span><span class="s1">fill_value=np.nan</span><span class="s2">, </span><span class="s1">dtype=np.complex128)</span>
    <span class="s2">if </span><span class="s1">a[case_left].size:</span>
        <span class="s1">out[case_left] = mass_case_left(a[case_left]</span><span class="s2">, </span><span class="s1">b[case_left])</span>
    <span class="s2">if </span><span class="s1">a[case_right].size:</span>
        <span class="s1">out[case_right] = mass_case_right(a[case_right]</span><span class="s2">, </span><span class="s1">b[case_right])</span>
    <span class="s2">if </span><span class="s1">a[case_central].size:</span>
        <span class="s1">out[case_central] = mass_case_central(a[case_central]</span><span class="s2">, </span><span class="s1">b[case_central])</span>
    <span class="s2">return </span><span class="s1">np.real(out)  </span><span class="s0"># discard ~0j</span>


<span class="s2">class </span><span class="s1">truncnorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A truncated normal continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    This distribution is the normal distribution centered on ``loc`` (default 
    0), with standard deviation ``scale`` (default 1), and clipped at ``a``, 
    ``b`` standard deviations to the left, right (respectively) from ``loc``. 
    If ``myclip_a`` and ``myclip_b`` are clip values in the sample space (as 
    opposed to the number of standard deviations) then they can be converted 
    to the required form according to:: 
 
        a, b = (myclip_a - loc) / scale, (myclip_b - loc) / scale 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">a &lt; b</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ia = _ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, True</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ia</span><span class="s2">, </span><span class="s1">ib]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Reasonable, since support is [a, b]</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(np.min(data)</span><span class="s2">, </span><span class="s1">np.max(data)))</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">_norm_logpdf(x) - _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logcdf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">logcdf = np.asarray(_log_gauss_mass(a</span><span class="s2">, </span><span class="s1">x) - _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
        <span class="s1">i = logcdf &gt; -</span><span class="s5">0.1  </span><span class="s0"># avoid catastrophic cancellation</span>
        <span class="s2">if </span><span class="s1">np.any(i):</span>
            <span class="s1">logcdf[i] = np.log1p(-np.exp(self._logsf(x[i]</span><span class="s2">, </span><span class="s1">a[i]</span><span class="s2">, </span><span class="s1">b[i])))</span>
        <span class="s2">return </span><span class="s1">logcdf</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">logsf = np.asarray(_log_gauss_mass(x</span><span class="s2">, </span><span class="s1">b) - _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
        <span class="s1">i = logsf &gt; -</span><span class="s5">0.1  </span><span class="s0"># avoid catastrophic cancellation</span>
        <span class="s2">if </span><span class="s1">np.any(i):</span>
            <span class="s1">logsf[i] = np.log1p(-np.exp(self._logcdf(x[i]</span><span class="s2">, </span><span class="s1">a[i]</span><span class="s2">, </span><span class="s1">b[i])))</span>
        <span class="s2">return </span><span class="s1">logsf</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">A = _norm_cdf(a)</span>
        <span class="s1">B = _norm_cdf(b)</span>
        <span class="s1">Z = B - A</span>
        <span class="s1">C = np.log(np.sqrt(</span><span class="s5">2 </span><span class="s1">* np.pi * np.e) * Z)</span>
        <span class="s1">D = (a * _norm_pdf(a) - b * _norm_pdf(b)) / (</span><span class="s5">2 </span><span class="s1">* Z)</span>
        <span class="s1">h = C + D</span>
        <span class="s2">return </span><span class="s1">h</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s1">case_left = a &lt; </span><span class="s5">0</span>
        <span class="s1">case_right = ~case_left</span>

        <span class="s2">def </span><span class="s1">ppf_left(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s1">log_Phi_x = _log_sum(_norm_logcdf(a)</span><span class="s2">,</span>
                                 <span class="s1">np.log(q) + _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s2">return </span><span class="s1">sc.ndtri_exp(log_Phi_x)</span>

        <span class="s2">def </span><span class="s1">ppf_right(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s1">log_Phi_x = _log_sum(_norm_logcdf(-b)</span><span class="s2">,</span>
                                 <span class="s1">np.log1p(-q) + _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s2">return </span><span class="s1">-sc.ndtri_exp(log_Phi_x)</span>

        <span class="s1">out = np.empty_like(q)</span>

        <span class="s1">q_left = q[case_left]</span>
        <span class="s1">q_right = q[case_right]</span>

        <span class="s2">if </span><span class="s1">q_left.size:</span>
            <span class="s1">out[case_left] = ppf_left(q_left</span><span class="s2">, </span><span class="s1">a[case_left]</span><span class="s2">, </span><span class="s1">b[case_left])</span>
        <span class="s2">if </span><span class="s1">q_right.size:</span>
            <span class="s1">out[case_right] = ppf_right(q_right</span><span class="s2">, </span><span class="s1">a[case_right]</span><span class="s2">, </span><span class="s1">b[case_right])</span>

        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s0"># Mostly copy-paste of _ppf, but I think this is simpler than combining</span>
        <span class="s1">q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b = np.broadcast_arrays(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s1">case_left = b &lt; </span><span class="s5">0</span>
        <span class="s1">case_right = ~case_left</span>

        <span class="s2">def </span><span class="s1">isf_left(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s1">log_Phi_x = _log_diff(_norm_logcdf(b)</span><span class="s2">,</span>
                                  <span class="s1">np.log(q) + _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s2">return </span><span class="s1">sc.ndtri_exp(np.real(log_Phi_x))</span>

        <span class="s2">def </span><span class="s1">isf_right(q</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s1">log_Phi_x = _log_diff(_norm_logcdf(-a)</span><span class="s2">,</span>
                                  <span class="s1">np.log1p(-q) + _log_gauss_mass(a</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s2">return </span><span class="s1">-sc.ndtri_exp(np.real(log_Phi_x))</span>

        <span class="s1">out = np.empty_like(q)</span>

        <span class="s1">q_left = q[case_left]</span>
        <span class="s1">q_right = q[case_right]</span>

        <span class="s2">if </span><span class="s1">q_left.size:</span>
            <span class="s1">out[case_left] = isf_left(q_left</span><span class="s2">, </span><span class="s1">a[case_left]</span><span class="s2">, </span><span class="s1">b[case_left])</span>
        <span class="s2">if </span><span class="s1">q_right.size:</span>
            <span class="s1">out[case_right] = isf_right(q_right</span><span class="s2">, </span><span class="s1">a[case_right]</span><span class="s2">, </span><span class="s1">b[case_right])</span>

        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">def </span><span class="s1">n_th_moment(n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
            <span class="s3">&quot;&quot;&quot; 
            Returns n-th moment. Defined only if n &gt;= 0. 
            Function cannot broadcast due to the loop over n 
            &quot;&quot;&quot;</span>
            <span class="s1">pA</span><span class="s2">, </span><span class="s1">pB = self._pdf(np.asarray([a</span><span class="s2">, </span><span class="s1">b])</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>
            <span class="s1">probs = [pA</span><span class="s2">, </span><span class="s1">-pB]</span>
            <span class="s1">moments = [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n+</span><span class="s5">1</span><span class="s1">):</span>
                <span class="s0"># a or b might be infinite, and the corresponding pdf value</span>
                <span class="s0"># is 0 in that case, but nan is returned for the</span>
                <span class="s0"># multiplication.  However, as b-&gt;infinity,  pdf(b)*b**k -&gt; 0.</span>
                <span class="s0"># So it is safe to use _lazywhere to avoid the nan.</span>
                <span class="s1">vals = _lazywhere(probs</span><span class="s2">, </span><span class="s1">[probs</span><span class="s2">, </span><span class="s1">[a</span><span class="s2">, </span><span class="s1">b]]</span><span class="s2">,</span>
                                  <span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x * y**(k-</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">fillvalue=</span><span class="s5">0</span><span class="s1">)</span>
                <span class="s1">mk = np.sum(vals) + (k-</span><span class="s5">1</span><span class="s1">) * moments[-</span><span class="s5">2</span><span class="s1">]</span>
                <span class="s1">moments.append(mk)</span>
            <span class="s2">return </span><span class="s1">moments[-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">return </span><span class="s1">_lazywhere((n &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (a == a) &amp; (b == b)</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span><span class="s2">,</span>
                          <span class="s1">np.vectorize(n_th_moment</span><span class="s2">, </span><span class="s1">otypes=[np.float64])</span><span class="s2">,</span>
                          <span class="s1">np.nan)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">pA</span><span class="s2">, </span><span class="s1">pB = self.pdf(np.array([a</span><span class="s2">, </span><span class="s1">b])</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b)</span>

        <span class="s2">def </span><span class="s1">_truncnorm_stats_scalar(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">pA</span><span class="s2">, </span><span class="s1">pB</span><span class="s2">, </span><span class="s1">moments):</span>
            <span class="s1">m1 = pA - pB</span>
            <span class="s1">mu = m1</span>
            <span class="s0"># use _lazywhere to avoid nan (See detailed comment in _munp)</span>
            <span class="s1">probs = [pA</span><span class="s2">, </span><span class="s1">-pB]</span>
            <span class="s1">vals = _lazywhere(probs</span><span class="s2">, </span><span class="s1">[probs</span><span class="s2">, </span><span class="s1">[a</span><span class="s2">, </span><span class="s1">b]]</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x*y</span><span class="s2">,</span>
                              <span class="s1">fillvalue=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">m2 = </span><span class="s5">1 </span><span class="s1">+ np.sum(vals)</span>
            <span class="s1">vals = _lazywhere(probs</span><span class="s2">, </span><span class="s1">[probs</span><span class="s2">, </span><span class="s1">[a-mu</span><span class="s2">, </span><span class="s1">b-mu]]</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x*y</span><span class="s2">,</span>
                              <span class="s1">fillvalue=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s0"># mu2 = m2 - mu**2, but not as numerically stable as:</span>
            <span class="s0"># mu2 = (a-mu)*pA - (b-mu)*pB + 1</span>
            <span class="s1">mu2 = </span><span class="s5">1 </span><span class="s1">+ np.sum(vals)</span>
            <span class="s1">vals = _lazywhere(probs</span><span class="s2">, </span><span class="s1">[probs</span><span class="s2">, </span><span class="s1">[a</span><span class="s2">, </span><span class="s1">b]]</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x*y**</span><span class="s5">2</span><span class="s2">,</span>
                              <span class="s1">fillvalue=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">m3 = </span><span class="s5">2</span><span class="s1">*m1 + np.sum(vals)</span>
            <span class="s1">vals = _lazywhere(probs</span><span class="s2">, </span><span class="s1">[probs</span><span class="s2">, </span><span class="s1">[a</span><span class="s2">, </span><span class="s1">b]]</span><span class="s2">, lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x*y**</span><span class="s5">3</span><span class="s2">,</span>
                              <span class="s1">fillvalue=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">m4 = </span><span class="s5">3</span><span class="s1">*m2 + np.sum(vals)</span>

            <span class="s1">mu3 = m3 + m1 * (-</span><span class="s5">3</span><span class="s1">*m2 + </span><span class="s5">2</span><span class="s1">*m1**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">g1 = mu3 / np.power(mu2</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>
            <span class="s1">mu4 = m4 + m1*(-</span><span class="s5">4</span><span class="s1">*m3 + </span><span class="s5">3</span><span class="s1">*m1*(</span><span class="s5">2</span><span class="s1">*m2 - m1**</span><span class="s5">2</span><span class="s1">))</span>
            <span class="s1">g2 = mu4 / mu2**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">3</span>
            <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

        <span class="s1">_truncnorm_stats = np.vectorize(_truncnorm_stats_scalar</span><span class="s2">,</span>
                                        <span class="s1">excluded=(</span><span class="s4">'moments'</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">_truncnorm_stats(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">pA</span><span class="s2">, </span><span class="s1">pB</span><span class="s2">, </span><span class="s1">moments)</span>


<span class="s1">truncnorm = truncnorm_gen(name=</span><span class="s4">'truncnorm'</span><span class="s2">, </span><span class="s1">momtype=</span><span class="s5">1</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">truncpareto_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;An upper truncated Pareto continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    pareto : Pareto distribution 
 
    Notes 
    ----- 
    The probability density function for `truncpareto` is: 
 
    .. math:: 
 
        f(x, b, c) = \frac{b}{1 - c^{-b}} \frac{1}{x^{b+1}} 
 
    for :math:`b &gt; 0`, :math:`c &gt; 1` and :math:`1 \le x \le c`. 
 
    `truncpareto` takes `b` and `c` as shape parameters for :math:`b` and 
    :math:`c`. 
 
    Notice that the upper truncation value :math:`c` is defined in 
    standardized form so that random values of an unscaled, unshifted variable 
    are within the range ``[1, c]``. 
    If ``u_r`` is the upper bound to a scaled and/or shifted variable, 
    then ``c = (u_r - loc) / scale``. In other words, the support of the 
    distribution becomes ``(scale + loc) &lt;= x &lt;= (c*scale + loc)`` when 
    `scale` and/or `loc` are provided. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Burroughs, S. M., and Tebbens S. F. 
        &quot;Upper-truncated power laws in natural systems.&quot; 
        Pure and Applied Geophysics 158.4 (2001): 741-757. 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ib = _ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">ic = _ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ib</span><span class="s2">, </span><span class="s1">ic]</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(b &gt; </span><span class="s5">0.</span><span class="s1">) &amp; (c &gt; </span><span class="s5">1.</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">c</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">b * x**-(b+</span><span class="s5">1</span><span class="s1">) / (</span><span class="s5">1 </span><span class="s1">- c**-b)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># return np.log(b) - np.log1p(-c**-b) - (b+1)*np.log(x)</span>
        <span class="s2">return </span><span class="s1">np.log(b) - np.log(-np.expm1(-b*np.log(c))) - (b+</span><span class="s5">1</span><span class="s1">)*np.log(x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1 </span><span class="s1">- x**-b) / (</span><span class="s5">1 </span><span class="s1">- c**-b)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log1p(-x**-b) - np.log1p(-c**-b)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">pow(</span><span class="s5">1 </span><span class="s1">- (</span><span class="s5">1 </span><span class="s1">- c**-b)*q</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">/b)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(x**-b - c**-b) / (</span><span class="s5">1 </span><span class="s1">- c**-b)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(x**-b - c**-b) - np.log1p(-c**-b)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">pow(c**-b + (</span><span class="s5">1 </span><span class="s1">- c**-b)*q</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">/b)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">-(np.log(b/(</span><span class="s5">1 </span><span class="s1">- c**-b))</span>
                 <span class="s1">+ (b+</span><span class="s5">1</span><span class="s1">)*(np.log(c)/(c**b - </span><span class="s5">1</span><span class="s1">) - </span><span class="s5">1</span><span class="s1">/b))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">if </span><span class="s1">(n == b).all():</span>
            <span class="s2">return </span><span class="s1">b*np.log(c) / (</span><span class="s5">1 </span><span class="s1">- c**-b)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">b / (b-n) * (c**b - c**n) / (c**b - </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s1">b</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale = pareto.fit(data)</span>
        <span class="s1">c = (max(data) - loc)/scale</span>
        <span class="s2">return </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">&quot;superfit&quot;</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">def </span><span class="s1">log_mean(x):</span>
            <span class="s2">return </span><span class="s1">np.mean(np.log(x))</span>

        <span class="s2">def </span><span class="s1">harm_mean(x):</span>
            <span class="s2">return </span><span class="s5">1</span><span class="s1">/np.mean(</span><span class="s5">1</span><span class="s1">/x)</span>

        <span class="s2">def </span><span class="s1">get_b(c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale):</span>
            <span class="s1">u = (data-loc)/scale</span>
            <span class="s1">harm_m = harm_mean(u)</span>
            <span class="s1">log_m = log_mean(u)</span>
            <span class="s1">quot = (harm_m-</span><span class="s5">1</span><span class="s1">)/log_m</span>
            <span class="s2">return </span><span class="s1">(</span><span class="s5">1 </span><span class="s1">- (quot-</span><span class="s5">1</span><span class="s1">) / (quot - (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1</span><span class="s1">/c)*harm_m/np.log(c)))/log_m</span>

        <span class="s2">def </span><span class="s1">get_c(loc</span><span class="s2">, </span><span class="s1">scale):</span>
            <span class="s2">return </span><span class="s1">(mx - loc)/scale</span>

        <span class="s2">def </span><span class="s1">get_loc(fc</span><span class="s2">, </span><span class="s1">fscale):</span>
            <span class="s2">if </span><span class="s1">fscale:  </span><span class="s0"># (fscale and fc) or (fscale and not fc)</span>
                <span class="s1">loc = mn - fscale</span>
                <span class="s2">return </span><span class="s1">loc</span>
            <span class="s2">if </span><span class="s1">fc:</span>
                <span class="s1">loc = (fc*mn - mx)/(fc - </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s2">return </span><span class="s1">loc</span>

        <span class="s2">def </span><span class="s1">get_scale(loc):</span>
            <span class="s2">return </span><span class="s1">mn - loc</span>

        <span class="s0"># Functions used for optimisation; partial derivatives of</span>
        <span class="s0"># the Lagrangian, set to equal 0.</span>

        <span class="s2">def </span><span class="s1">dL_dLoc(loc</span><span class="s2">, </span><span class="s1">b_=</span><span class="s2">None</span><span class="s1">):</span>
            <span class="s0"># Partial derivative wrt location.</span>
            <span class="s0"># Optimised upon when no parameters, or only b, are fixed.</span>
            <span class="s1">scale = get_scale(loc)</span>
            <span class="s1">c = get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s1">b = get_b(c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale) </span><span class="s2">if </span><span class="s1">b_ </span><span class="s2">is None else </span><span class="s1">b_</span>
            <span class="s1">harm_m = harm_mean((data - loc)/scale)</span>
            <span class="s2">return </span><span class="s5">1 </span><span class="s1">- (</span><span class="s5">1 </span><span class="s1">+ (c - </span><span class="s5">1</span><span class="s1">)/(c**(b+</span><span class="s5">1</span><span class="s1">) - c)) * (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1</span><span class="s1">/(b+</span><span class="s5">1</span><span class="s1">)) * harm_m</span>

        <span class="s2">def </span><span class="s1">dL_dB(b</span><span class="s2">, </span><span class="s1">logc</span><span class="s2">, </span><span class="s1">logm):</span>
            <span class="s0"># Partial derivative wrt b.</span>
            <span class="s0"># Optimised upon whenever at least one parameter but b is fixed,</span>
            <span class="s0"># and b is free.</span>
            <span class="s2">return </span><span class="s1">b - np.log1p(b*logc / (</span><span class="s5">1 </span><span class="s1">- b*logm)) / logc</span>

        <span class="s2">def </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
            <span class="s0"># Should any issue arise, default to the general fit method.</span>
            <span class="s2">return </span><span class="s1">super(truncpareto_gen</span><span class="s2">, </span><span class="s1">self).fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s1">parameters = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">fb</span><span class="s2">, </span><span class="s1">fc</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = parameters</span>
        <span class="s1">mn</span><span class="s2">, </span><span class="s1">mx = data.min()</span><span class="s2">, </span><span class="s1">data.max()</span>
        <span class="s1">mn_inf = np.nextafter(mn</span><span class="s2">, </span><span class="s1">-np.inf)</span>

        <span class="s2">if </span><span class="s1">(fb </span><span class="s2">is not None</span>
                <span class="s2">and </span><span class="s1">fc </span><span class="s2">is not None</span>
                <span class="s2">and </span><span class="s1">floc </span><span class="s2">is not None</span>
                <span class="s2">and </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed.&quot;</span>
                             <span class="s4">&quot;There is nothing to optimize.&quot;</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">fc </span><span class="s2">is None and </span><span class="s1">floc </span><span class="s2">is None and </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">fb </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">def </span><span class="s1">cond_b(loc):</span>
                    <span class="s0"># b is positive only if this function is positive</span>
                    <span class="s1">scale = get_scale(loc)</span>
                    <span class="s1">c = get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>
                    <span class="s1">harm_m = harm_mean((data - loc)/scale)</span>
                    <span class="s2">return </span><span class="s1">(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/(c-</span><span class="s5">1</span><span class="s1">)) * np.log(c) / harm_m - </span><span class="s5">1</span>

                <span class="s0"># This gives an upper bound on loc allowing for a positive b.</span>
                <span class="s0"># Iteratively look for a bracket for root_scalar.</span>
                <span class="s1">mn_inf = np.nextafter(mn</span><span class="s2">, </span><span class="s1">-np.inf)</span>
                <span class="s1">rbrack = mn_inf</span>
                <span class="s1">i = </span><span class="s5">0</span>
                <span class="s1">lbrack = rbrack - </span><span class="s5">1</span>
                <span class="s2">while </span><span class="s1">((lbrack &gt; -np.inf)</span>
                       <span class="s2">and </span><span class="s1">(cond_b(lbrack)*cond_b(rbrack) &gt;= </span><span class="s5">0</span><span class="s1">)):</span>
                    <span class="s1">i += </span><span class="s5">1</span>
                    <span class="s1">lbrack = rbrack - np.power(</span><span class="s5">2.</span><span class="s2">, </span><span class="s1">i)</span>
                <span class="s2">if not </span><span class="s1">lbrack &gt; -np.inf:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s1">res = root_scalar(cond_b</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
                <span class="s2">if not </span><span class="s1">res.converged:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

                <span class="s0"># Determine the MLE for loc.</span>
                <span class="s0"># Iteratively look for a bracket for root_scalar.</span>
                <span class="s1">rbrack = res.root - </span><span class="s5">1e-3  </span><span class="s0"># grad_loc is numerically ill-behaved</span>
                <span class="s1">lbrack = rbrack - </span><span class="s5">1</span>
                <span class="s1">i = </span><span class="s5">0</span>
                <span class="s2">while </span><span class="s1">((lbrack &gt; -np.inf)</span>
                       <span class="s2">and </span><span class="s1">(dL_dLoc(lbrack)*dL_dLoc(rbrack) &gt;= </span><span class="s5">0</span><span class="s1">)):</span>
                    <span class="s1">i += </span><span class="s5">1</span>
                    <span class="s1">lbrack = rbrack - np.power(</span><span class="s5">2.</span><span class="s2">, </span><span class="s1">i)</span>
                <span class="s2">if not </span><span class="s1">lbrack &gt; -np.inf:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s1">res = root_scalar(dL_dLoc</span><span class="s2">, </span><span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
                <span class="s2">if not </span><span class="s1">res.converged:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s1">loc = res.root</span>
                <span class="s1">scale = get_scale(loc)</span>
                <span class="s1">c = get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>
                <span class="s1">b = get_b(c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale)</span>

                <span class="s1">std_data = (data - loc)/scale</span>
                <span class="s0"># The expression of b relies on b being bounded above.</span>
                <span class="s1">up_bound_b = min(</span><span class="s5">1</span><span class="s1">/log_mean(std_data)</span><span class="s2">,</span>
                                 <span class="s5">1</span><span class="s1">/(harm_mean(std_data)-</span><span class="s5">1</span><span class="s1">))</span>
                <span class="s2">if not </span><span class="s1">(b &lt; up_bound_b):</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># We know b is positive (or a FitError will be triggered)</span>
                <span class="s0"># so we let loc get close to min(data).</span>
                <span class="s1">rbrack = mn_inf</span>
                <span class="s1">lbrack = mn_inf - </span><span class="s5">1</span>
                <span class="s1">i = </span><span class="s5">0</span>
                <span class="s0"># Iteratively look for a bracket for root_scalar.</span>
                <span class="s2">while </span><span class="s1">(lbrack &gt; -np.inf</span>
                       <span class="s2">and </span><span class="s1">(dL_dLoc(lbrack</span><span class="s2">, </span><span class="s1">fb)</span>
                            <span class="s1">* dL_dLoc(rbrack</span><span class="s2">, </span><span class="s1">fb) &gt;= </span><span class="s5">0</span><span class="s1">)):</span>
                    <span class="s1">i += </span><span class="s5">1</span>
                    <span class="s1">lbrack = rbrack - </span><span class="s5">2</span><span class="s1">**i</span>
                <span class="s2">if not </span><span class="s1">lbrack &gt; -np.inf:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s1">res = root_scalar(dL_dLoc</span><span class="s2">, </span><span class="s1">(fb</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                                  <span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
                <span class="s2">if not </span><span class="s1">res.converged:</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s1">loc = res.root</span>
                <span class="s1">scale = get_scale(loc)</span>
                <span class="s1">c = get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>
                <span class="s1">b = fb</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># At least one of the parameters determining the support is fixed;</span>
            <span class="s0"># the others then have analytical expressions from the constraints.</span>
            <span class="s0"># The completely determined case (fixed c, loc and scale)</span>
            <span class="s0"># has to be checked for not overflowing the support.</span>
            <span class="s0"># If not fixed, b has to be determined numerically.</span>
            <span class="s1">loc = floc </span><span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None else </span><span class="s1">get_loc(fc</span><span class="s2">, </span><span class="s1">fscale)</span>
            <span class="s1">scale = fscale </span><span class="s2">or </span><span class="s1">get_scale(loc)</span>
            <span class="s1">c = fc </span><span class="s2">or </span><span class="s1">get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>

            <span class="s0"># Unscaled, translated values should be positive when the location</span>
            <span class="s0"># is fixed. If it is not the case, we end up with negative `scale`</span>
            <span class="s0"># and `c`, which would trigger a FitError before exiting the</span>
            <span class="s0"># method.</span>
            <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">data.min() - floc &lt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;truncpareto&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">upper=c)</span>

            <span class="s0"># Standardised values should be within the distribution support</span>
            <span class="s0"># when all parameters controlling it are fixed. If it not the case,</span>
            <span class="s0"># `fc` is overidden by `c` determined from `floc` and `fscale` when</span>
            <span class="s0"># raising the exception.</span>
            <span class="s2">if </span><span class="s1">fc </span><span class="s2">and </span><span class="s1">(floc </span><span class="s2">is not None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">fscale:</span>
                <span class="s2">if </span><span class="s1">data.max() &gt; fc*fscale + floc:</span>
                    <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;truncpareto&quot;</span><span class="s2">, </span><span class="s1">lower=</span><span class="s5">1</span><span class="s2">,</span>
                                       <span class="s1">upper=get_c(loc</span><span class="s2">, </span><span class="s1">scale))</span>

            <span class="s0"># The other constraints should be automatically satisfied</span>
            <span class="s0"># from the analytical expressions of the parameters.</span>
            <span class="s0"># If fc or fscale are respectively less than one or less than 0,</span>
            <span class="s0"># a FitError is triggered before exiting the method.</span>

            <span class="s2">if </span><span class="s1">fb </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">std_data = (data - loc)/scale</span>
                <span class="s1">logm = log_mean(std_data)</span>
                <span class="s1">logc = np.log(c)</span>
                <span class="s0"># Condition for a positive root to exist.</span>
                <span class="s2">if not </span><span class="s1">(</span><span class="s5">2</span><span class="s1">*logm &lt; logc):</span>
                    <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

                <span class="s1">lbrack = </span><span class="s5">1</span><span class="s1">/logm + </span><span class="s5">1</span><span class="s1">/(logm - logc)</span>
                <span class="s1">rbrack = np.nextafter(</span><span class="s5">1</span><span class="s1">/logm</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">res = root_scalar(dL_dB</span><span class="s2">, </span><span class="s1">(logc</span><span class="s2">, </span><span class="s1">logm)</span><span class="s2">,</span>
                                      <span class="s1">bracket=(lbrack</span><span class="s2">, </span><span class="s1">rbrack))</span>
                    <span class="s0"># we should then never get there</span>
                    <span class="s2">if not </span><span class="s1">res.converged:</span>
                        <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
                    <span class="s1">b = res.root</span>
                <span class="s2">except </span><span class="s1">ValueError:</span>
                    <span class="s1">b = rbrack</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">b = fb</span>

        <span class="s0"># The distribution requires that `scale+loc &lt;= data &lt;= c*scale+loc`.</span>
        <span class="s0"># To avoid numerical issues, some tuning may be necessary.</span>
        <span class="s0"># We adjust `scale` to satisfy the lower bound, and we adjust</span>
        <span class="s0"># `c` to satisfy the upper bound.</span>
        <span class="s2">if not </span><span class="s1">(scale+loc) &lt; mn:</span>
            <span class="s2">if </span><span class="s1">fscale:</span>
                <span class="s1">loc = np.nextafter(loc</span><span class="s2">, </span><span class="s1">-np.inf)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">scale = get_scale(loc)</span>
                <span class="s1">scale = np.nextafter(scale</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">(c*scale+loc) &gt; mx:</span>
            <span class="s1">c = get_c(loc</span><span class="s2">, </span><span class="s1">scale)</span>
            <span class="s1">c = np.nextafter(c</span><span class="s2">, </span><span class="s1">np.inf)</span>

        <span class="s2">if not </span><span class="s1">(np.all(self._argcheck(b</span><span class="s2">, </span><span class="s1">c)) </span><span class="s2">and </span><span class="s1">(scale &gt; </span><span class="s5">0</span><span class="s1">)):</span>
            <span class="s2">return </span><span class="s1">fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">params_override = b</span><span class="s2">, </span><span class="s1">c</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">scale</span>
        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None and </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># Based on testing in gh-16782, the following methods are only</span>
            <span class="s0"># reliable if either `floc` or `fscale` are provided. They are</span>
            <span class="s0"># fast, though, so might as well see if they are better than the</span>
            <span class="s0"># generic method.</span>
            <span class="s1">params_super = fallback(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
            <span class="s1">nllf_override = self.nnlf(params_override</span><span class="s2">, </span><span class="s1">data)</span>
            <span class="s1">nllf_super = self.nnlf(params_super</span><span class="s2">, </span><span class="s1">data)</span>
            <span class="s2">if </span><span class="s1">nllf_super &lt; nllf_override:</span>
                <span class="s2">return </span><span class="s1">params_super</span>

        <span class="s2">return </span><span class="s1">params_override</span>


<span class="s1">truncpareto = truncpareto_gen(a=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'truncpareto'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">tukeylambda_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Tukey-Lamdba continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    A flexible distribution, able to represent and interpolate between the 
    following distributions: 
 
    - Cauchy                (:math:`lambda = -1`) 
    - logistic              (:math:`lambda = 0`) 
    - approx Normal         (:math:`lambda = 0.14`) 
    - uniform from -1 to 1  (:math:`lambda = 1`) 
 
    `tukeylambda` takes a real number :math:`lambda` (denoted ``lam`` 
    in the implementation) as a shape parameter. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s2">return </span><span class="s1">np.isfinite(lam)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;lam&quot;</span><span class="s2">, False, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s1">Fx = np.asarray(sc.tklmbda(x</span><span class="s2">, </span><span class="s1">lam))</span>
        <span class="s1">Px = Fx**(lam-</span><span class="s5">1.0</span><span class="s1">) + (np.asarray(</span><span class="s5">1</span><span class="s1">-Fx))**(lam-</span><span class="s5">1.0</span><span class="s1">)</span>
        <span class="s1">Px = </span><span class="s5">1.0</span><span class="s1">/np.asarray(Px)</span>
        <span class="s2">return </span><span class="s1">np.where((lam &lt;= </span><span class="s5">0</span><span class="s1">) | (abs(x) &lt; </span><span class="s5">1.0</span><span class="s1">/np.asarray(lam))</span><span class="s2">, </span><span class="s1">Px</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s2">return </span><span class="s1">sc.tklmbda(x</span><span class="s2">, </span><span class="s1">lam)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s2">return </span><span class="s1">sc.boxcox(q</span><span class="s2">, </span><span class="s1">lam) - sc.boxcox1p(-q</span><span class="s2">, </span><span class="s1">lam)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s1">_tlvar(lam)</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">_tlkurt(lam)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">lam):</span>
        <span class="s2">def </span><span class="s1">integ(p):</span>
            <span class="s2">return </span><span class="s1">np.log(pow(p</span><span class="s2">, </span><span class="s1">lam-</span><span class="s5">1</span><span class="s1">)+pow(</span><span class="s5">1</span><span class="s1">-p</span><span class="s2">, </span><span class="s1">lam-</span><span class="s5">1</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">integrate.quad(integ</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>


<span class="s1">tukeylambda = tukeylambda_gen(name=</span><span class="s4">'tukeylambda'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">FitUniformFixedScaleDataError(FitDataError):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">ptp</span><span class="s2">, </span><span class="s1">fscale):</span>
        <span class="s1">self.args = (</span>
            <span class="s4">&quot;Invalid values in `data`.  Maximum likelihood estimation with &quot;</span>
            <span class="s4">&quot;the uniform distribution and fixed scale requires that &quot;</span>
            <span class="s4">f&quot;data.ptp() &lt;= fscale, but data.ptp() = </span><span class="s2">{</span><span class="s1">ptp</span><span class="s2">} </span><span class="s4">and &quot;</span>
            <span class="s4">f&quot;fscale = </span><span class="s2">{</span><span class="s1">fscale</span><span class="s2">}</span><span class="s4">.&quot;</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">uniform_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A uniform continuous random variable. 
 
    In the standard form, the distribution is uniform on ``[0, 1]``. Using 
    the parameters ``loc`` and ``scale``, one obtains the uniform distribution 
    on ``[loc, loc + scale]``. 
 
    %(before_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.uniform(</span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">*(x == x)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q):</span>
        <span class="s2">return </span><span class="s1">q</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">/</span><span class="s5">12</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1.2</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s5">0.0</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s3">&quot;&quot;&quot; 
        Maximum likelihood estimate for the location and scale parameters. 
 
        `uniform.fit` uses only the following parameters.  Because exact 
        formulas are used, the parameters related to optimization that are 
        available in the `fit` method of other distributions are ignored 
        here.  The only positional argument accepted is `data`. 
 
        Parameters 
        ---------- 
        data : array_like 
            Data to use in calculating the maximum likelihood estimate. 
        floc : float, optional 
            Hold the location parameter fixed to the specified value. 
        fscale : float, optional 
            Hold the scale parameter fixed to the specified value. 
 
        Returns 
        ------- 
        loc, scale : float 
            Maximum likelihood estimates for the location and scale. 
 
        Notes 
        ----- 
        An error is raised if `floc` is given and any values in `data` are 
        less than `floc`, or if `fscale` is given and `fscale` is less 
        than ``data.max() - data.min()``.  An error is also raised if both 
        `floc` and `fscale` are given. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; import numpy as np 
        &gt;&gt;&gt; from scipy.stats import uniform 
 
        We'll fit the uniform distribution to `x`: 
 
        &gt;&gt;&gt; x = np.array([2, 2.5, 3.1, 9.5, 13.0]) 
 
        For a uniform distribution MLE, the location is the minimum of the 
        data, and the scale is the maximum minus the minimum. 
 
        &gt;&gt;&gt; loc, scale = uniform.fit(x) 
        &gt;&gt;&gt; loc 
        2.0 
        &gt;&gt;&gt; scale 
        11.0 
 
        If we know the data comes from a uniform distribution where the support 
        starts at 0, we can use `floc=0`: 
 
        &gt;&gt;&gt; loc, scale = uniform.fit(x, floc=0) 
        &gt;&gt;&gt; loc 
        0.0 
        &gt;&gt;&gt; scale 
        13.0 
 
        Alternatively, if we know the length of the support is 12, we can use 
        `fscale=12`: 
 
        &gt;&gt;&gt; loc, scale = uniform.fit(x, fscale=12) 
        &gt;&gt;&gt; loc 
        1.5 
        &gt;&gt;&gt; scale 
        12.0 
 
        In that last example, the support interval is [1.5, 13.5].  This 
        solution is not unique.  For example, the distribution with ``loc=2`` 
        and ``scale=12`` has the same likelihood as the one above.  When 
        `fscale` is given and it is larger than ``data.max() - data.min()``, 
        the parameters returned by the `fit` method center the support over 
        the interval ``[data.min(), data.max()]``. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">len(args) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Too many arguments.&quot;</span><span class="s1">)</span>

        <span class="s1">floc = kwds.pop(</span><span class="s4">'floc'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">fscale = kwds.pop(</span><span class="s4">'fscale'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">_remove_optimizer_parameters(kwds)</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None and </span><span class="s1">fscale </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># This check is for consistency with `rv_continuous.fit`.</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All parameters fixed. There is nothing to &quot;</span>
                             <span class="s4">&quot;optimize.&quot;</span><span class="s1">)</span>

        <span class="s1">data = np.asarray(data)</span>

        <span class="s2">if not </span><span class="s1">np.isfinite(data).all():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The data contains non-finite values.&quot;</span><span class="s1">)</span>

        <span class="s0"># MLE for the uniform distribution</span>
        <span class="s0"># --------------------------------</span>
        <span class="s0"># The PDF is</span>
        <span class="s0">#</span>
        <span class="s0">#     f(x, loc, scale) = {1/scale  for loc &lt;= x &lt;= loc + scale</span>
        <span class="s0">#                        {0        otherwise}</span>
        <span class="s0">#</span>
        <span class="s0"># The likelihood function is</span>
        <span class="s0">#     L(x, loc, scale) = (1/scale)**n</span>
        <span class="s0"># where n is len(x), assuming loc &lt;= x &lt;= loc + scale for all x.</span>
        <span class="s0"># The log-likelihood is</span>
        <span class="s0">#     l(x, loc, scale) = -n*log(scale)</span>
        <span class="s0"># The log-likelihood is maximized by making scale as small as possible,</span>
        <span class="s0"># while keeping loc &lt;= x &lt;= loc + scale.   So if neither loc nor scale</span>
        <span class="s0"># are fixed, the log-likelihood is maximized by choosing</span>
        <span class="s0">#     loc = x.min()</span>
        <span class="s0">#     scale = x.ptp()</span>
        <span class="s0"># If loc is fixed, it must be less than or equal to x.min(), and then</span>
        <span class="s0"># the scale is</span>
        <span class="s0">#     scale = x.max() - loc</span>
        <span class="s0"># If scale is fixed, it must not be less than x.ptp().  If scale is</span>
        <span class="s0"># greater than x.ptp(), the solution is not unique.  Note that the</span>
        <span class="s0"># likelihood does not depend on loc, except for the requirement that</span>
        <span class="s0"># loc &lt;= x &lt;= loc + scale.  All choices of loc for which</span>
        <span class="s0">#     x.max() - scale &lt;= loc &lt;= x.min()</span>
        <span class="s0"># have the same log-likelihood.  In this case, we choose loc such that</span>
        <span class="s0"># the support is centered over the interval [data.min(), data.max()]:</span>
        <span class="s0">#     loc = x.min() = 0.5*(scale - x.ptp())</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># scale is not fixed.</span>
            <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s0"># loc is not fixed, scale is not fixed.</span>
                <span class="s1">loc = data.min()</span>
                <span class="s1">scale = data.ptp()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># loc is fixed, scale is not fixed.</span>
                <span class="s1">loc = floc</span>
                <span class="s1">scale = data.max() - loc</span>
                <span class="s2">if </span><span class="s1">data.min() &lt; loc:</span>
                    <span class="s2">raise </span><span class="s1">FitDataError(</span><span class="s4">&quot;uniform&quot;</span><span class="s2">, </span><span class="s1">lower=loc</span><span class="s2">, </span><span class="s1">upper=loc + scale)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># loc is not fixed, scale is fixed.</span>
            <span class="s1">ptp = data.ptp()</span>
            <span class="s2">if </span><span class="s1">ptp &gt; fscale:</span>
                <span class="s2">raise </span><span class="s1">FitUniformFixedScaleDataError(ptp=ptp</span><span class="s2">, </span><span class="s1">fscale=fscale)</span>
            <span class="s0"># If ptp &lt; fscale, the ML estimate is not unique; see the comments</span>
            <span class="s0"># above.  We choose the distribution for which the support is</span>
            <span class="s0"># centered over the interval [data.min(), data.max()].</span>
            <span class="s1">loc = data.min() - </span><span class="s5">0.5</span><span class="s1">*(fscale - ptp)</span>
            <span class="s1">scale = fscale</span>

        <span class="s0"># We expect the return values to be floating point, so ensure it</span>
        <span class="s0"># by explicitly converting to float.</span>
        <span class="s2">return </span><span class="s1">float(loc)</span><span class="s2">, </span><span class="s1">float(scale)</span>


<span class="s1">uniform = uniform_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'uniform'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">vonmises_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A Von Mises continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    scipy.stats.vonmises_fisher : Von-Mises Fisher distribution on a 
                                  hypersphere 
 
    Notes 
    ----- 
    The probability density function for `vonmises` and `vonmises_line` is: 
 
    .. math:: 
 
        f(x, \kappa) = \frac{ \exp(\kappa \cos(x)) }{ 2 \pi I_0(\kappa) } 
 
    for :math:`-\pi \le x \le \pi`, :math:`\kappa &gt; 0`. :math:`I_0` is the 
    modified Bessel function of order zero (`scipy.special.i0`). 
 
    `vonmises` is a circular distribution which does not restrict the 
    distribution to a fixed interval. Currently, there is no circular 
    distribution framework in SciPy. The ``cdf`` is implemented such that 
    ``cdf(x + 2*np.pi) == cdf(x) + 1``. 
 
    `vonmises_line` is the same distribution, defined on :math:`[-\pi, \pi]` 
    on the real line. This is a regular (i.e. non-circular) distribution. 
 
    Note about distribution parameters: `vonmises` and `vonmises_line` take 
    ``kappa`` as a shape parameter (concentration) and ``loc`` as the location 
    (circular mean). A ``scale`` parameter is accepted but does not have any 
    effect. 
 
    Examples 
    -------- 
    Import the necessary modules. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.stats import vonmises 
 
    Define distribution parameters. 
 
    &gt;&gt;&gt; loc = 0.5 * np.pi  # circular mean 
    &gt;&gt;&gt; kappa = 1  # concentration 
 
    Compute the probability density at ``x=0`` via the ``pdf`` method. 
 
    &gt;&gt;&gt; vonmises.pdf(loc, kappa, 0) 
    0.12570826359722018 
 
    Verify that the percentile function ``ppf`` inverts the cumulative 
    distribution function ``cdf`` up to floating point accuracy. 
 
    &gt;&gt;&gt; x = 1 
    &gt;&gt;&gt; cdf_value = vonmises.cdf(loc=loc, kappa=kappa, x=x) 
    &gt;&gt;&gt; ppf_value = vonmises.ppf(cdf_value, loc=loc, kappa=kappa) 
    &gt;&gt;&gt; x, cdf_value, ppf_value 
    (1, 0.31489339900904967, 1.0000000000000004) 
 
    Draw 1000 random variates by calling the ``rvs`` method. 
 
    &gt;&gt;&gt; number_of_samples = 1000 
    &gt;&gt;&gt; samples = vonmises(loc=loc, kappa=kappa).rvs(number_of_samples) 
 
    Plot the von Mises density on a Cartesian and polar grid to emphasize 
    that is is a circular distribution. 
 
    &gt;&gt;&gt; fig = plt.figure(figsize=(12, 6)) 
    &gt;&gt;&gt; left = plt.subplot(121) 
    &gt;&gt;&gt; right = plt.subplot(122, projection='polar') 
    &gt;&gt;&gt; x = np.linspace(-np.pi, np.pi, 500) 
    &gt;&gt;&gt; vonmises_pdf = vonmises.pdf(loc, kappa, x) 
    &gt;&gt;&gt; ticks = [0, 0.15, 0.3] 
 
    The left image contains the Cartesian plot. 
 
    &gt;&gt;&gt; left.plot(x, vonmises_pdf) 
    &gt;&gt;&gt; left.set_yticks(ticks) 
    &gt;&gt;&gt; number_of_bins = int(np.sqrt(number_of_samples)) 
    &gt;&gt;&gt; left.hist(samples, density=True, bins=number_of_bins) 
    &gt;&gt;&gt; left.set_title(&quot;Cartesian plot&quot;) 
    &gt;&gt;&gt; left.set_xlim(-np.pi, np.pi) 
    &gt;&gt;&gt; left.grid(True) 
 
    The right image contains the polar plot. 
 
    &gt;&gt;&gt; right.plot(x, vonmises_pdf, label=&quot;PDF&quot;) 
    &gt;&gt;&gt; right.set_yticks(ticks) 
    &gt;&gt;&gt; right.hist(samples, density=True, bins=number_of_bins, 
    ...            label=&quot;Histogram&quot;) 
    &gt;&gt;&gt; right.set_title(&quot;Polar plot&quot;) 
    &gt;&gt;&gt; right.legend(bbox_to_anchor=(0.15, 1.06)) 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;kappa&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">kappa</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.vonmises(</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">kappa</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">rvs = super().rvs(*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s2">return </span><span class="s1">np.mod(rvs + np.pi</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*np.pi) - np.pi</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s0"># vonmises.pdf(x, kappa) = exp(kappa * cos(x)) / (2*pi*I[0](kappa))</span>
        <span class="s0">#                        = exp(kappa * (cos(x) - 1)) /</span>
        <span class="s0">#                          (2*pi*exp(-kappa)*I[0](kappa))</span>
        <span class="s0">#                        = exp(kappa * cosm1(x)) / (2*pi*i0e(kappa))</span>
        <span class="s2">return </span><span class="s1">np.exp(kappa*sc.cosm1(x)) / (</span><span class="s5">2</span><span class="s1">*np.pi*sc.i0e(kappa))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s0"># vonmises.pdf(x, kappa) = exp(kappa * cosm1(x)) / (2*pi*i0e(kappa))</span>
        <span class="s2">return </span><span class="s1">kappa * sc.cosm1(x) - np.log(</span><span class="s5">2</span><span class="s1">*np.pi) - np.log(sc.i0e(kappa))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s2">return </span><span class="s1">_stats.von_mises_cdf(kappa</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s2">def </span><span class="s1">_stats_skip(self</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, None, </span><span class="s5">0</span><span class="s2">, None</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">kappa):</span>
        <span class="s0"># vonmises.entropy(kappa) = -kappa * I[1](kappa) / I[0](kappa) +</span>
        <span class="s0">#                           log(2 * np.pi * I[0](kappa))</span>
        <span class="s0">#                         = -kappa * I[1](kappa) * exp(-kappa) /</span>
        <span class="s0">#                           (I[0](kappa) * exp(-kappa)) +</span>
        <span class="s0">#                           log(2 * np.pi *</span>
        <span class="s0">#                           I[0](kappa) * exp(-kappa) / exp(-kappa))</span>
        <span class="s0">#                         = -kappa * sc.i1e(kappa) / sc.i0e(kappa) +</span>
        <span class="s0">#                           log(2 * np.pi * i0e(kappa)) + kappa</span>
        <span class="s2">return </span><span class="s1">(-kappa * sc.i1e(kappa) / sc.i0e(kappa) +</span>
                <span class="s1">np.log(</span><span class="s5">2 </span><span class="s1">* np.pi * sc.i0e(kappa)) + kappa)</span>

    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">The default limits of integration are endpoints of the interval 
        of width ``2*pi`` centered at `loc` (e.g. ``[-pi, pi]`` when 
        ``loc=0``).</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">expect(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">loc=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">scale=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">lb=</span><span class="s2">None, </span><span class="s1">ub=</span><span class="s2">None,</span>
               <span class="s1">conditional=</span><span class="s2">False, </span><span class="s1">**kwds):</span>
        <span class="s1">_a</span><span class="s2">, </span><span class="s1">_b = -np.pi</span><span class="s2">, </span><span class="s1">np.pi</span>

        <span class="s2">if </span><span class="s1">lb </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lb = loc + _a</span>
        <span class="s2">if </span><span class="s1">ub </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">ub = loc + _b</span>

        <span class="s2">return </span><span class="s1">super().expect(func</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">,</span>
                              <span class="s1">scale</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">conditional</span><span class="s2">, </span><span class="s1">**kwds)</span>

    <span class="s1">@_call_super_mom</span>
    <span class="s1">@extend_notes_in_docstring(rv_continuous</span><span class="s2">, </span><span class="s1">notes=</span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">Fit data is assumed to represent angles and will be wrapped onto the 
        unit circle. `f0` and `fscale` are ignored; the returned shape is 
        always the maximum likelihood estimate and the scale is always 
        1. Initial guesses are ignored.</span><span class="s2">\n\n</span><span class="s4">&quot;&quot;&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s2">if </span><span class="s1">kwds.pop(</span><span class="s4">'superfit'</span><span class="s2">, False</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s1">data</span><span class="s2">, </span><span class="s1">fshape</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                                                 <span class="s1">args</span><span class="s2">, </span><span class="s1">kwds)</span>
        <span class="s2">if </span><span class="s1">self.a == -np.pi:</span>
            <span class="s0"># vonmises line case, here the default fit method will be used</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s0"># wrap data to interval [0, 2*pi]</span>
        <span class="s1">data = np.mod(data</span><span class="s2">, </span><span class="s5">2 </span><span class="s1">* np.pi)</span>

        <span class="s2">def </span><span class="s1">find_mu(data):</span>
            <span class="s2">return </span><span class="s1">stats.circmean(data)</span>

        <span class="s2">def </span><span class="s1">find_kappa(data</span><span class="s2">, </span><span class="s1">loc):</span>
            <span class="s0"># Usually, sources list the following as the equation to solve for</span>
            <span class="s0"># the MLE of the shape parameter:</span>
            <span class="s0"># r = I[1](kappa)/I[0](kappa), where r = mean resultant length</span>
            <span class="s0"># This is valid when the location is the MLE of location.</span>
            <span class="s0"># More generally, when the location may be fixed at an arbitrary</span>
            <span class="s0"># value, r should be defined as follows:</span>
            <span class="s1">r = np.sum(np.cos(loc - data))/len(data)</span>
            <span class="s0"># See gh-18128 for more information.</span>

            <span class="s2">if </span><span class="s1">r &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">def </span><span class="s1">solve_for_kappa(kappa):</span>
                    <span class="s2">return </span><span class="s1">sc.i1e(kappa)/sc.i0e(kappa) - r</span>

                <span class="s1">root_res = root_scalar(solve_for_kappa</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;brentq&quot;</span><span class="s2">,</span>
                                       <span class="s1">bracket=(np.finfo(float).tiny</span><span class="s2">, </span><span class="s5">1e16</span><span class="s1">))</span>
                <span class="s2">return </span><span class="s1">root_res.root</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># if the provided floc is very far from the circular mean,</span>
                <span class="s0"># the mean resultant length r can become negative.</span>
                <span class="s0"># In that case, the equation</span>
                <span class="s0"># I[1](kappa)/I[0](kappa) = r does not have a solution.</span>
                <span class="s0"># The maximum likelihood kappa is then 0 which practically</span>
                <span class="s0"># results in the uniform distribution on the circle. As</span>
                <span class="s0"># vonmises is defined for kappa &gt; 0, return instead the</span>
                <span class="s0"># smallest floating point value.</span>
                <span class="s0"># See gh-18190 for more information</span>
                <span class="s2">return </span><span class="s1">np.finfo(float).tiny</span>

        <span class="s0"># location likelihood equation has a solution independent of kappa</span>
        <span class="s1">loc = floc </span><span class="s2">if </span><span class="s1">floc </span><span class="s2">is not None else </span><span class="s1">find_mu(data)</span>
        <span class="s0"># shape likelihood equation depends on location</span>
        <span class="s1">shape = fshape </span><span class="s2">if </span><span class="s1">fshape </span><span class="s2">is not None else </span><span class="s1">find_kappa(data</span><span class="s2">, </span><span class="s1">loc)</span>

        <span class="s1">loc = np.mod(loc + np.pi</span><span class="s2">, </span><span class="s5">2 </span><span class="s1">* np.pi) - np.pi  </span><span class="s0"># ensure in [-pi, pi]</span>
        <span class="s2">return </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s5">1  </span><span class="s0"># scale is not handled</span>


<span class="s1">vonmises = vonmises_gen(name=</span><span class="s4">'vonmises'</span><span class="s1">)</span>
<span class="s1">vonmises_line = vonmises_gen(a=-np.pi</span><span class="s2">, </span><span class="s1">b=np.pi</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'vonmises_line'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">wald_gen(invgauss_gen):</span>
    <span class="s3">r&quot;&quot;&quot;A Wald continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `wald` is: 
 
    .. math:: 
 
        f(x) = \frac{1}{\sqrt{2\pi x^3}} \exp(- \frac{ (x-1)^2 }{ 2x }) 
 
    for :math:`x &gt;= 0`. 
 
    `wald` is a special case of `invgauss` with ``mu=1``. 
 
    %(after_notes)s 
 
    %(example)s 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._open_support_mask</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.wald(</span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0"># wald.pdf(x) = 1/sqrt(2*pi*x**3) * exp(-(x-1)**2/(2*x))</span>
        <span class="s2">return </span><span class="s1">invgauss._pdf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._cdf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._sf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._ppf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._isf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._logpdf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._logcdf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">invgauss._logsf(x</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">3.0</span><span class="s2">, </span><span class="s5">15.0</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s2">return </span><span class="s1">invgauss._entropy(</span><span class="s5">1.0</span><span class="s1">)</span>


<span class="s1">wald = wald_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;wald&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">wrapcauchy_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A wrapped Cauchy continuous random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `wrapcauchy` is: 
 
    .. math:: 
 
        f(x, c) = \frac{1-c^2}{2\pi (1+c^2 - 2c \cos(x))} 
 
    for :math:`0 \le x \le 2\pi`, :math:`0 &lt; c &lt; 1`. 
 
    `wrapcauchy` takes ``c`` as a shape parameter for :math:`c`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">(c &gt; </span><span class="s5">0</span><span class="s1">) &amp; (c &lt; </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;c&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s0"># wrapcauchy.pdf(x, c) = (1-c**2) / (2*pi*(1+c**2-2*c*cos(x)))</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1.0</span><span class="s1">-c*c)/(</span><span class="s5">2</span><span class="s1">*np.pi*(</span><span class="s5">1</span><span class="s1">+c*c-</span><span class="s5">2</span><span class="s1">*c*np.cos(x)))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">c):</span>

        <span class="s2">def </span><span class="s1">f1(x</span><span class="s2">, </span><span class="s1">cr):</span>
            <span class="s0"># CDF for 0 &lt;= x &lt; pi</span>
            <span class="s2">return </span><span class="s5">1</span><span class="s1">/np.pi * np.arctan(cr*np.tan(x/</span><span class="s5">2</span><span class="s1">))</span>

        <span class="s2">def </span><span class="s1">f2(x</span><span class="s2">, </span><span class="s1">cr):</span>
            <span class="s0"># CDF for pi &lt;= x &lt;= 2*pi</span>
            <span class="s2">return </span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1</span><span class="s1">/np.pi * np.arctan(cr*np.tan((</span><span class="s5">2</span><span class="s1">*np.pi - x)/</span><span class="s5">2</span><span class="s1">))</span>

        <span class="s1">cr = (</span><span class="s5">1 </span><span class="s1">+ c)/(</span><span class="s5">1 </span><span class="s1">- c)</span>
        <span class="s2">return </span><span class="s1">_lazywhere(x &lt; np.pi</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">cr)</span><span class="s2">, </span><span class="s1">f=f1</span><span class="s2">, </span><span class="s1">f2=f2)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s1">val = (</span><span class="s5">1.0</span><span class="s1">-c)/(</span><span class="s5">1.0</span><span class="s1">+c)</span>
        <span class="s1">rcq = </span><span class="s5">2</span><span class="s1">*np.arctan(val*np.tan(np.pi*q))</span>
        <span class="s1">rcmq = </span><span class="s5">2</span><span class="s1">*np.pi-</span><span class="s5">2</span><span class="s1">*np.arctan(val*np.tan(np.pi*(</span><span class="s5">1</span><span class="s1">-q)))</span>
        <span class="s2">return </span><span class="s1">np.where(q &lt; </span><span class="s5">1.0</span><span class="s1">/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">rcq</span><span class="s2">, </span><span class="s1">rcmq)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">c):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">2</span><span class="s1">*np.pi*(</span><span class="s5">1</span><span class="s1">-c*c))</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Use 0.5 as the initial guess of the shape parameter.</span>
        <span class="s0"># For the location and scale, use the minimum and</span>
        <span class="s0"># peak-to-peak/(2*pi), respectively.</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData):</span>
            <span class="s1">data = data._uncensor()</span>
        <span class="s2">return </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">np.min(data)</span><span class="s2">, </span><span class="s1">np.ptp(data)/(</span><span class="s5">2</span><span class="s1">*np.pi)</span>


<span class="s1">wrapcauchy = wrapcauchy_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">2</span><span class="s1">*np.pi</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'wrapcauchy'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">gennorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A generalized normal continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    laplace : Laplace distribution 
    norm : normal distribution 
 
    Notes 
    ----- 
    The probability density function for `gennorm` is [1]_: 
 
    .. math:: 
 
        f(x, \beta) = \frac{\beta}{2 \Gamma(1/\beta)} \exp(-|x|^\beta), 
 
    where :math:`x` is a real number, :math:`\beta &gt; 0` and 
    :math:`\Gamma` is the gamma function (`scipy.special.gamma`). 
 
    `gennorm` takes ``beta`` as a shape parameter for :math:`\beta`. 
    For :math:`\beta = 1`, it is identical to a Laplace distribution. 
    For :math:`\beta = 2`, it is identical to a normal distribution 
    (with ``scale=1/sqrt(2)``). 
 
    References 
    ---------- 
 
    .. [1] &quot;Generalized normal distribution, Version 1&quot;, 
           https://en.wikipedia.org/wiki/Generalized_normal_distribution#Version_1 
 
    .. [2] Nardon, Martina, and Paolo Pianca. &quot;Simulation techniques for 
           generalized Gaussian densities.&quot; Journal of Statistical 
           Computation and Simulation 79.11 (2009): 1317-1329 
 
    .. [3] Wicklin, Rick. &quot;Simulate data from a generalized Gaussian 
           distribution&quot; in The DO Loop blog, September 21, 2016, 
           https://blogs.sas.com/content/iml/2016/09/21/simulate-generalized-gaussian-sas.html 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;beta&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">beta))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">np.log(</span><span class="s5">0.5</span><span class="s1">*beta) - sc.gammaln(</span><span class="s5">1.0</span><span class="s1">/beta) - abs(x)**beta</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s1">c = </span><span class="s5">0.5 </span><span class="s1">* np.sign(x)</span>
        <span class="s0"># evaluating (.5 + c) first prevents numerical cancellation</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">0.5 </span><span class="s1">+ c) - c * sc.gammaincc(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">abs(x)**beta)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s1">c = np.sign(x - </span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s0"># evaluating (1. + c) first prevents numerical cancellation</span>
        <span class="s2">return </span><span class="s1">c * sc.gammainccinv(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1.0 </span><span class="s1">+ c) - </span><span class="s5">2.0</span><span class="s1">*c*x)**(</span><span class="s5">1.0</span><span class="s1">/beta)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">self._cdf(-x</span><span class="s2">, </span><span class="s1">beta)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">-self._ppf(x</span><span class="s2">, </span><span class="s1">beta)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s1">c1</span><span class="s2">, </span><span class="s1">c3</span><span class="s2">, </span><span class="s1">c5 = sc.gammaln([</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s5">3.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s5">5.0</span><span class="s1">/beta])</span>
        <span class="s2">return </span><span class="s5">0.</span><span class="s2">, </span><span class="s1">np.exp(c3 - c1)</span><span class="s2">, </span><span class="s5">0.</span><span class="s2">, </span><span class="s1">np.exp(c5 + c1 - </span><span class="s5">2.0</span><span class="s1">*c3) - </span><span class="s5">3.</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s5">1. </span><span class="s1">/ beta - np.log(</span><span class="s5">.5 </span><span class="s1">* beta) + sc.gammaln(</span><span class="s5">1. </span><span class="s1">/ beta)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># see [2]_ for the algorithm</span>
        <span class="s0"># see [3]_ for reference implementation in SAS</span>
        <span class="s1">z = random_state.gamma(</span><span class="s5">1</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">size=size)</span>
        <span class="s1">y = z ** (</span><span class="s5">1</span><span class="s1">/beta)</span>
        <span class="s0"># convert y to array to ensure masking support</span>
        <span class="s1">y = np.asarray(y)</span>
        <span class="s1">mask = random_state.random(size=y.shape) &lt; </span><span class="s5">0.5</span>
        <span class="s1">y[mask] = -y[mask]</span>
        <span class="s2">return </span><span class="s1">y</span>


<span class="s1">gennorm = gennorm_gen(name=</span><span class="s4">'gennorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">halfgennorm_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;The upper half of a generalized normal continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    gennorm : generalized normal distribution 
    expon : exponential distribution 
    halfnorm : half normal distribution 
 
    Notes 
    ----- 
    The probability density function for `halfgennorm` is: 
 
    .. math:: 
 
        f(x, \beta) = \frac{\beta}{\Gamma(1/\beta)} \exp(-|x|^\beta) 
 
    for :math:`x, \beta &gt; 0`. :math:`\Gamma` is the gamma function 
    (`scipy.special.gamma`). 
 
    `halfgennorm` takes ``beta`` as a shape parameter for :math:`\beta`. 
    For :math:`\beta = 1`, it is identical to an exponential distribution. 
    For :math:`\beta = 2`, it is identical to a half normal distribution 
    (with ``scale=1/sqrt(2)``). 
 
    References 
    ---------- 
 
    .. [1] &quot;Generalized normal distribution, Version 1&quot;, 
           https://en.wikipedia.org/wiki/Generalized_normal_distribution#Version_1 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;beta&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s0">#                                 beta</span>
        <span class="s0"># halfgennorm.pdf(x, beta) =  -------------  exp(-|x|**beta)</span>
        <span class="s0">#                             gamma(1/beta)</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">beta))</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">np.log(beta) - sc.gammaln(</span><span class="s5">1.0</span><span class="s1">/beta) - x**beta</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">sc.gammainc(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">x**beta)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincinv(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">x)**(</span><span class="s5">1.0</span><span class="s1">/beta)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">sc.gammaincc(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">x**beta)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s1">sc.gammainccinv(</span><span class="s5">1.0</span><span class="s1">/beta</span><span class="s2">, </span><span class="s1">x)**(</span><span class="s5">1.0</span><span class="s1">/beta)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">beta):</span>
        <span class="s2">return </span><span class="s5">1.0</span><span class="s1">/beta - np.log(beta) + sc.gammaln(</span><span class="s5">1.0</span><span class="s1">/beta)</span>


<span class="s1">halfgennorm = halfgennorm_gen(a=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'halfgennorm'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">crystalball_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot; 
    Crystalball distribution 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `crystalball` is: 
 
    .. math:: 
 
        f(x, \beta, m) =  \begin{cases} 
                            N \exp(-x^2 / 2),  &amp;\text{for } x &gt; -\beta\\ 
                            N A (B - x)^{-m}  &amp;\text{for } x \le -\beta 
                          \end{cases} 
 
    where :math:`A = (m / |\beta|)^m  \exp(-\beta^2 / 2)`, 
    :math:`B = m/|\beta| - |\beta|` and :math:`N` is a normalisation constant. 
 
    `crystalball` takes :math:`\beta &gt; 0` and :math:`m &gt; 1` as shape 
    parameters.  :math:`\beta` defines the point where the pdf changes 
    from a power-law to a Gaussian distribution.  :math:`m` is the power 
    of the power-law tail. 
 
    References 
    ---------- 
    .. [1] &quot;Crystal Ball Function&quot;, 
           https://en.wikipedia.org/wiki/Crystal_Ball_function 
 
    %(after_notes)s 
 
    .. versionadded:: 0.19.0 
 
    %(example)s 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s3">&quot;&quot;&quot; 
        Shape parameter bounds are m &gt; 1 and beta &gt; 0. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">(m &gt; </span><span class="s5">1</span><span class="s1">) &amp; (beta &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ibeta = _ShapeInfo(</span><span class="s4">&quot;beta&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">im = _ShapeInfo(</span><span class="s4">&quot;m&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ibeta</span><span class="s2">, </span><span class="s1">im]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Arbitrary, but the default m=1 is not valid</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s3">&quot;&quot;&quot; 
        Return PDF of the crystalball function. 
 
                                            -- 
                                           | exp(-x**2 / 2),  for x &gt; -beta 
        crystalball.pdf(x, beta, m) =  N * | 
                                           | A * (B - x)**(-m), for x &lt;= -beta 
                                            -- 
        &quot;&quot;&quot;</span>
        <span class="s1">N = </span><span class="s5">1.0 </span><span class="s1">/ (m/beta / (m-</span><span class="s5">1</span><span class="s1">) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) +</span>
                   <span class="s1">_norm_pdf_C * _norm_cdf(beta))</span>

        <span class="s2">def </span><span class="s1">rhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">np.exp(-x**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">lhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">((m/beta)**m * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) *</span>
                    <span class="s1">(m/beta - beta - x)**(-m))</span>

        <span class="s2">return </span><span class="s1">N * _lazywhere(x &gt; -beta</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m)</span><span class="s2">, </span><span class="s1">f=rhs</span><span class="s2">, </span><span class="s1">f2=lhs)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s3">&quot;&quot;&quot; 
        Return the log of the PDF of the crystalball function. 
        &quot;&quot;&quot;</span>
        <span class="s1">N = </span><span class="s5">1.0 </span><span class="s1">/ (m/beta / (m-</span><span class="s5">1</span><span class="s1">) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) +</span>
                   <span class="s1">_norm_pdf_C * _norm_cdf(beta))</span>

        <span class="s2">def </span><span class="s1">rhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">-x**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2</span>

        <span class="s2">def </span><span class="s1">lhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">m*np.log(m/beta) - beta**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2 </span><span class="s1">- m*np.log(m/beta - beta - x)</span>

        <span class="s2">return </span><span class="s1">np.log(N) + _lazywhere(x &gt; -beta</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m)</span><span class="s2">, </span><span class="s1">f=rhs</span><span class="s2">, </span><span class="s1">f2=lhs)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s3">&quot;&quot;&quot; 
        Return CDF of the crystalball function 
        &quot;&quot;&quot;</span>
        <span class="s1">N = </span><span class="s5">1.0 </span><span class="s1">/ (m/beta / (m-</span><span class="s5">1</span><span class="s1">) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) +</span>
                   <span class="s1">_norm_pdf_C * _norm_cdf(beta))</span>

        <span class="s2">def </span><span class="s1">rhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">((m/beta) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) / (m-</span><span class="s5">1</span><span class="s1">) +</span>
                    <span class="s1">_norm_pdf_C * (_norm_cdf(x) - _norm_cdf(-beta)))</span>

        <span class="s2">def </span><span class="s1">lhs(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s2">return </span><span class="s1">((m/beta)**m * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) *</span>
                    <span class="s1">(m/beta - beta - x)**(-m+</span><span class="s5">1</span><span class="s1">) / (m-</span><span class="s5">1</span><span class="s1">))</span>

        <span class="s2">return </span><span class="s1">N * _lazywhere(x &gt; -beta</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m)</span><span class="s2">, </span><span class="s1">f=rhs</span><span class="s2">, </span><span class="s1">f2=lhs)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s1">N = </span><span class="s5">1.0 </span><span class="s1">/ (m/beta / (m-</span><span class="s5">1</span><span class="s1">) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) +</span>
                   <span class="s1">_norm_pdf_C * _norm_cdf(beta))</span>
        <span class="s1">pbeta = N * (m/beta) * np.exp(-beta**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2</span><span class="s1">) / (m - </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">ppf_less(p</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s1">eb2 = np.exp(-beta**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">C = (m/beta) * eb2 / (m-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">N = </span><span class="s5">1</span><span class="s1">/(C + _norm_pdf_C * _norm_cdf(beta))</span>
            <span class="s2">return </span><span class="s1">(m/beta - beta -</span>
                    <span class="s1">((m - </span><span class="s5">1</span><span class="s1">)*(m/beta)**(-m)/eb2*p/N)**(</span><span class="s5">1</span><span class="s1">/(</span><span class="s5">1</span><span class="s1">-m)))</span>

        <span class="s2">def </span><span class="s1">ppf_greater(p</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s1">eb2 = np.exp(-beta**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">C = (m/beta) * eb2 / (m-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">N = </span><span class="s5">1</span><span class="s1">/(C + _norm_pdf_C * _norm_cdf(beta))</span>
            <span class="s2">return </span><span class="s1">_norm_ppf(_norm_cdf(-beta) + (</span><span class="s5">1</span><span class="s1">/_norm_pdf_C)*(p/N - C))</span>

        <span class="s2">return </span><span class="s1">_lazywhere(p &lt; pbeta</span><span class="s2">, </span><span class="s1">(p</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m)</span><span class="s2">, </span><span class="s1">f=ppf_less</span><span class="s2">, </span><span class="s1">f2=ppf_greater)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
        <span class="s3">&quot;&quot;&quot; 
        Returns the n-th non-central moment of the crystalball function. 
        &quot;&quot;&quot;</span>
        <span class="s1">N = </span><span class="s5">1.0 </span><span class="s1">/ (m/beta / (m-</span><span class="s5">1</span><span class="s1">) * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">) +</span>
                   <span class="s1">_norm_pdf_C * _norm_cdf(beta))</span>

        <span class="s2">def </span><span class="s1">n_th_moment(n</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m):</span>
            <span class="s3">&quot;&quot;&quot; 
            Returns n-th moment. Defined only if n+1 &lt; m 
            Function cannot broadcast due to the loop over n 
            &quot;&quot;&quot;</span>
            <span class="s1">A = (m/beta)**m * np.exp(-beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2.0</span><span class="s1">)</span>
            <span class="s1">B = m/beta - beta</span>
            <span class="s1">rhs = (</span><span class="s5">2</span><span class="s1">**((n-</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2.0</span><span class="s1">) * sc.gamma((n+</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s1">) *</span>
                   <span class="s1">(</span><span class="s5">1.0 </span><span class="s1">+ (-</span><span class="s5">1</span><span class="s1">)**n * sc.gammainc((n+</span><span class="s5">1</span><span class="s1">)/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">beta**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">)))</span>
            <span class="s1">lhs = np.zeros(rhs.shape)</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(n + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s1">lhs += (sc.binom(n</span><span class="s2">, </span><span class="s1">k) * B**(n-k) * (-</span><span class="s5">1</span><span class="s1">)**k / (m - k - </span><span class="s5">1</span><span class="s1">) *</span>
                        <span class="s1">(m/beta)**(-m + k + </span><span class="s5">1</span><span class="s1">))</span>
            <span class="s2">return </span><span class="s1">A * lhs + rhs</span>

        <span class="s2">return </span><span class="s1">N * _lazywhere(n + </span><span class="s5">1 </span><span class="s1">&lt; m</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">, </span><span class="s1">m)</span><span class="s2">,</span>
                              <span class="s1">np.vectorize(n_th_moment</span><span class="s2">, </span><span class="s1">otypes=[np.float64])</span><span class="s2">,</span>
                              <span class="s1">np.inf)</span>


<span class="s1">crystalball = crystalball_gen(name=</span><span class="s4">'crystalball'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">&quot;A Crystalball Function&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_argus_phi(chi):</span>
    <span class="s3">&quot;&quot;&quot; 
    Utility function for the argus distribution used in the pdf, sf and 
    moment calculation. 
    Note that for all x &gt; 0: 
    gammainc(1.5, x**2/2) = 2 * (_norm_cdf(x) - x * _norm_pdf(x) - 0.5). 
    This can be verified directly by noting that the cdf of Gamma(1.5) can 
    be written as erf(sqrt(x)) - 2*sqrt(x)*exp(-x)/sqrt(Pi). 
    We use gammainc instead of the usual definition because it is more precise 
    for small chi. 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">sc.gammainc(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">chi**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">2</span><span class="s1">) / </span><span class="s5">2</span>


<span class="s2">class </span><span class="s1">argus_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot; 
    Argus distribution 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability density function for `argus` is: 
 
    .. math:: 
 
        f(x, \chi) = \frac{\chi^3}{\sqrt{2\pi} \Psi(\chi)} x \sqrt{1-x^2} 
                     \exp(-\chi^2 (1 - x^2)/2) 
 
    for :math:`0 &lt; x &lt; 1` and :math:`\chi &gt; 0`, where 
 
    .. math:: 
 
        \Psi(\chi) = \Phi(\chi) - \chi \phi(\chi) - 1/2 
 
    with :math:`\Phi` and :math:`\phi` being the CDF and PDF of a standard 
    normal distribution, respectively. 
 
    `argus` takes :math:`\chi` as shape a parameter. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;ARGUS distribution&quot;, 
           https://en.wikipedia.org/wiki/ARGUS_distribution 
 
    .. versionadded:: 0.19.0 
 
    %(example)s 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;chi&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">chi):</span>
        <span class="s0"># for x = 0 or 1, logpdf returns -np.inf</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">y = </span><span class="s5">1.0 </span><span class="s1">- x*x</span>
            <span class="s1">A = </span><span class="s5">3</span><span class="s1">*np.log(chi) - _norm_pdf_logC - np.log(_argus_phi(chi))</span>
            <span class="s2">return </span><span class="s1">A + np.log(x) + </span><span class="s5">0.5</span><span class="s1">*np.log1p(-x*x) - chi**</span><span class="s5">2 </span><span class="s1">* y / </span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">chi):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">chi))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">chi):</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">- self._sf(x</span><span class="s2">, </span><span class="s1">chi)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">chi):</span>
        <span class="s2">return </span><span class="s1">_argus_phi(chi * np.sqrt(</span><span class="s5">1 </span><span class="s1">- x**</span><span class="s5">2</span><span class="s1">)) / _argus_phi(chi)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">chi</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">chi = np.asarray(chi)</span>
        <span class="s2">if </span><span class="s1">chi.size == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">out = self._rvs_scalar(chi</span><span class="s2">, </span><span class="s1">numsamples=size</span><span class="s2">,</span>
                                   <span class="s1">random_state=random_state)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">shp</span><span class="s2">, </span><span class="s1">bc = _check_shape(chi.shape</span><span class="s2">, </span><span class="s1">size)</span>
            <span class="s1">numsamples = int(np.prod(shp))</span>
            <span class="s1">out = np.empty(size)</span>
            <span class="s1">it = np.nditer([chi]</span><span class="s2">,</span>
                           <span class="s1">flags=[</span><span class="s4">'multi_index'</span><span class="s1">]</span><span class="s2">,</span>
                           <span class="s1">op_flags=[[</span><span class="s4">'readonly'</span><span class="s1">]])</span>
            <span class="s2">while not </span><span class="s1">it.finished:</span>
                <span class="s1">idx = tuple((it.multi_index[j] </span><span class="s2">if not </span><span class="s1">bc[j] </span><span class="s2">else </span><span class="s1">slice(</span><span class="s2">None</span><span class="s1">))</span>
                            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(-len(size)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
                <span class="s1">r = self._rvs_scalar(it[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">numsamples=numsamples</span><span class="s2">,</span>
                                     <span class="s1">random_state=random_state)</span>
                <span class="s1">out[idx] = r.reshape(shp)</span>
                <span class="s1">it.iternext()</span>

        <span class="s2">if </span><span class="s1">size == ():</span>
            <span class="s1">out = out[()]</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_rvs_scalar(self</span><span class="s2">, </span><span class="s1">chi</span><span class="s2">, </span><span class="s1">numsamples=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># if chi &lt;= 1.8:</span>
        <span class="s0"># use rejection method, see Devroye:</span>
        <span class="s0"># Non-Uniform Random Variate Generation, 1986, section II.3.2.</span>
        <span class="s0"># write: PDF f(x) = c * g(x) * h(x), where</span>
        <span class="s0"># h is [0,1]-valued and g is a density</span>
        <span class="s0"># we use two ways to write f</span>
        <span class="s0">#</span>
        <span class="s0"># Case 1:</span>
        <span class="s0"># write g(x) = 3*x*sqrt(1-x**2), h(x) = exp(-chi**2 (1-x**2) / 2)</span>
        <span class="s0"># If X has a distribution with density g its ppf G_inv is given by:</span>
        <span class="s0"># G_inv(u) = np.sqrt(1 - u**(2/3))</span>
        <span class="s0">#</span>
        <span class="s0"># Case 2:</span>
        <span class="s0"># g(x) = chi**2 * x * exp(-chi**2 * (1-x**2)/2) / (1 - exp(-chi**2 /2))</span>
        <span class="s0"># h(x) = sqrt(1 - x**2), 0 &lt;= x &lt;= 1</span>
        <span class="s0"># one can show that</span>
        <span class="s0"># G_inv(u) = np.sqrt(2*np.log(u*(np.exp(chi**2/2)-1)+1))/chi</span>
        <span class="s0">#          = np.sqrt(1 + 2*np.log(np.exp(-chi**2/2)*(1-u)+u)/chi**2)</span>
        <span class="s0"># the latter expression is used for precision with small chi</span>
        <span class="s0">#</span>
        <span class="s0"># In both cases, the inverse cdf of g can be written analytically, and</span>
        <span class="s0"># we can apply the rejection method:</span>
        <span class="s0">#</span>
        <span class="s0"># REPEAT</span>
        <span class="s0">#    Generate U uniformly distributed on [0, 1]</span>
        <span class="s0">#    Generate X with density g (e.g. via inverse transform sampling:</span>
        <span class="s0">#    X = G_inv(V) with V uniformly distributed on [0, 1])</span>
        <span class="s0"># UNTIL X &lt;= h(X)</span>
        <span class="s0"># RETURN X</span>
        <span class="s0">#</span>
        <span class="s0"># We use case 1 for chi &lt;= 0.5 as it maintains precision for small chi</span>
        <span class="s0"># and case 2 for 0.5 &lt; chi &lt;= 1.8 due to its speed for moderate chi.</span>
        <span class="s0">#</span>
        <span class="s0"># if chi &gt; 1.8:</span>
        <span class="s0"># use relation to the Gamma distribution: if X is ARGUS with parameter</span>
        <span class="s0"># chi), then Y = chi**2 * (1 - X**2) / 2 has density proportional to</span>
        <span class="s0"># sqrt(u) * exp(-u) on [0, chi**2 / 2], i.e. a Gamma(3/2) distribution</span>
        <span class="s0"># conditioned on [0, chi**2 / 2]). Therefore, to sample X from the</span>
        <span class="s0"># ARGUS distribution, we sample Y from the gamma distribution, keeping</span>
        <span class="s0"># only samples on [0, chi**2 / 2], and apply the inverse</span>
        <span class="s0"># transformation X = (1 - 2*Y/chi**2)**(1/2). Since we only</span>
        <span class="s0"># look at chi &gt; 1.8, gamma(1.5).cdf(chi**2/2) is large enough such</span>
        <span class="s0"># Y falls in the inteval [0, chi**2 / 2] with a high probability:</span>
        <span class="s0"># stats.gamma(1.5).cdf(1.8**2/2) = 0.644...</span>
        <span class="s0">#</span>
        <span class="s0"># The points to switch between the different methods are determined</span>
        <span class="s0"># by a comparison of the runtime of the different methods. However,</span>
        <span class="s0"># the runtime is platform-dependent. The implemented values should</span>
        <span class="s0"># ensure a good overall performance and are supported by an analysis</span>
        <span class="s0"># of the rejection constants of different methods.</span>

        <span class="s1">size1d = tuple(np.atleast_1d(numsamples))</span>
        <span class="s1">N = int(np.prod(size1d))</span>
        <span class="s1">x = np.zeros(N)</span>
        <span class="s1">simulated = </span><span class="s5">0</span>
        <span class="s1">chi2 = chi * chi</span>
        <span class="s2">if </span><span class="s1">chi &lt;= </span><span class="s5">0.5</span><span class="s1">:</span>
            <span class="s1">d = -chi2 / </span><span class="s5">2</span>
            <span class="s2">while </span><span class="s1">simulated &lt; N:</span>
                <span class="s1">k = N - simulated</span>
                <span class="s1">u = random_state.uniform(size=k)</span>
                <span class="s1">v = random_state.uniform(size=k)</span>
                <span class="s1">z = v**(</span><span class="s5">2</span><span class="s1">/</span><span class="s5">3</span><span class="s1">)</span>
                <span class="s0"># acceptance condition: u &lt;= h(G_inv(v)). This simplifies to</span>
                <span class="s1">accept = (np.log(u) &lt;= d * z)</span>
                <span class="s1">num_accept = np.sum(accept)</span>
                <span class="s2">if </span><span class="s1">num_accept &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s0"># we still need to transform z=v**(2/3) to X = G_inv(v)</span>
                    <span class="s1">rvs = np.sqrt(</span><span class="s5">1 </span><span class="s1">- z[accept])</span>
                    <span class="s1">x[simulated:(simulated + num_accept)] = rvs</span>
                    <span class="s1">simulated += num_accept</span>
        <span class="s2">elif </span><span class="s1">chi &lt;= </span><span class="s5">1.8</span><span class="s1">:</span>
            <span class="s1">echi = np.exp(-chi2 / </span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">while </span><span class="s1">simulated &lt; N:</span>
                <span class="s1">k = N - simulated</span>
                <span class="s1">u = random_state.uniform(size=k)</span>
                <span class="s1">v = random_state.uniform(size=k)</span>
                <span class="s1">z = </span><span class="s5">2 </span><span class="s1">* np.log(echi * (</span><span class="s5">1 </span><span class="s1">- v) + v) / chi2</span>
                <span class="s0"># as in case one, simplify u &lt;= h(G_inv(v)) and then transform</span>
                <span class="s0"># z to the target distribution X = G_inv(v)</span>
                <span class="s1">accept = (u**</span><span class="s5">2 </span><span class="s1">+ z &lt;= </span><span class="s5">0</span><span class="s1">)</span>
                <span class="s1">num_accept = np.sum(accept)</span>
                <span class="s2">if </span><span class="s1">num_accept &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">rvs = np.sqrt(</span><span class="s5">1 </span><span class="s1">+ z[accept])</span>
                    <span class="s1">x[simulated:(simulated + num_accept)] = rvs</span>
                    <span class="s1">simulated += num_accept</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># conditional Gamma for chi &gt; 1.8</span>
            <span class="s2">while </span><span class="s1">simulated &lt; N:</span>
                <span class="s1">k = N - simulated</span>
                <span class="s1">g = random_state.standard_gamma(</span><span class="s5">1.5</span><span class="s2">, </span><span class="s1">size=k)</span>
                <span class="s1">accept = (g &lt;= chi2 / </span><span class="s5">2</span><span class="s1">)</span>
                <span class="s1">num_accept = np.sum(accept)</span>
                <span class="s2">if </span><span class="s1">num_accept &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">x[simulated:(simulated + num_accept)] = g[accept]</span>
                    <span class="s1">simulated += num_accept</span>
            <span class="s1">x = np.sqrt(</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">2 </span><span class="s1">* x / chi2)</span>

        <span class="s2">return </span><span class="s1">np.reshape(x</span><span class="s2">, </span><span class="s1">size1d)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">chi):</span>
        <span class="s0"># need to ensure that dtype is float</span>
        <span class="s0"># otherwise the mask below does not work for integers</span>
        <span class="s1">chi = np.asarray(chi</span><span class="s2">, </span><span class="s1">dtype=float)</span>
        <span class="s1">phi = _argus_phi(chi)</span>
        <span class="s1">m = np.sqrt(np.pi/</span><span class="s5">8</span><span class="s1">) * chi * sc.ive(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">chi**</span><span class="s5">2</span><span class="s1">/</span><span class="s5">4</span><span class="s1">) / phi</span>
        <span class="s0"># compute second moment, use Taylor expansion for small chi (&lt;= 0.1)</span>
        <span class="s1">mu2 = np.empty_like(chi)</span>
        <span class="s1">mask = chi &gt; </span><span class="s5">0.1</span>
        <span class="s1">c = chi[mask]</span>
        <span class="s1">mu2[mask] = </span><span class="s5">1 </span><span class="s1">- </span><span class="s5">3 </span><span class="s1">/ c**</span><span class="s5">2 </span><span class="s1">+ c * _norm_pdf(c) / phi[mask]</span>
        <span class="s1">c = chi[~mask]</span>
        <span class="s1">coef = [-</span><span class="s5">358</span><span class="s1">/</span><span class="s5">65690625</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">94</span><span class="s1">/</span><span class="s5">1010625</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">2</span><span class="s1">/</span><span class="s5">2625</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">6</span><span class="s1">/</span><span class="s5">175</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0.4</span><span class="s1">]</span>
        <span class="s1">mu2[~mask] = np.polyval(coef</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">mu2 - m**</span><span class="s5">2</span><span class="s2">, None, None</span>


<span class="s1">argus = argus_gen(name=</span><span class="s4">'argus'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">&quot;An Argus Function&quot;</span><span class="s2">, </span><span class="s1">a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">b=</span><span class="s5">1.0</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">rv_histogram(rv_continuous):</span>
    <span class="s3">&quot;&quot;&quot; 
    Generates a distribution given by a histogram. 
    This is useful to generate a template distribution from a binned 
    datasample. 
 
    As a subclass of the `rv_continuous` class, `rv_histogram` inherits from it 
    a collection of generic methods (see `rv_continuous` for the full list), 
    and implements them based on the properties of the provided binned 
    datasample. 
 
    Parameters 
    ---------- 
    histogram : tuple of array_like 
        Tuple containing two array_like objects. 
        The first containing the content of n bins, 
        the second containing the (n+1) bin boundaries. 
        In particular, the return value of `numpy.histogram` is accepted. 
 
    density : bool, optional 
        If False, assumes the histogram is proportional to counts per bin; 
        otherwise, assumes it is proportional to a density. 
        For constant bin widths, these are equivalent, but the distinction 
        is important when bin widths vary (see Notes). 
        If None (default), sets ``density=True`` for backwards compatibility, 
        but warns if the bin widths are variable. Set `density` explicitly 
        to silence the warning. 
 
        .. versionadded:: 1.10.0 
 
    Notes 
    ----- 
    When a histogram has unequal bin widths, there is a distinction between 
    histograms that are proportional to counts per bin and histograms that are 
    proportional to probability density over a bin. If `numpy.histogram` is 
    called with its default ``density=False``, the resulting histogram is the 
    number of counts per bin, so ``density=False`` should be passed to 
    `rv_histogram`. If `numpy.histogram` is called with ``density=True``, the 
    resulting histogram is in terms of probability density, so ``density=True`` 
    should be passed to `rv_histogram`. To avoid warnings, always pass 
    ``density`` explicitly when the input histogram has unequal bin widths. 
 
    There are no additional shape parameters except for the loc and scale. 
    The pdf is defined as a stepwise function from the provided histogram. 
    The cdf is a linear interpolation of the pdf. 
 
    .. versionadded:: 0.19.0 
 
    Examples 
    -------- 
 
    Create a scipy.stats distribution from a numpy histogram 
 
    &gt;&gt;&gt; import scipy.stats 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; data = scipy.stats.norm.rvs(size=100000, loc=0, scale=1.5, 
    ...                             random_state=123) 
    &gt;&gt;&gt; hist = np.histogram(data, bins=100) 
    &gt;&gt;&gt; hist_dist = scipy.stats.rv_histogram(hist, density=False) 
 
    Behaves like an ordinary scipy rv_continuous distribution 
 
    &gt;&gt;&gt; hist_dist.pdf(1.0) 
    0.20538577847618705 
    &gt;&gt;&gt; hist_dist.cdf(2.0) 
    0.90818568543056499 
 
    PDF is zero above (below) the highest (lowest) bin of the histogram, 
    defined by the max (min) of the original dataset 
 
    &gt;&gt;&gt; hist_dist.pdf(np.max(data)) 
    0.0 
    &gt;&gt;&gt; hist_dist.cdf(np.max(data)) 
    1.0 
    &gt;&gt;&gt; hist_dist.pdf(np.min(data)) 
    7.7591907244498314e-05 
    &gt;&gt;&gt; hist_dist.cdf(np.min(data)) 
    0.0 
 
    PDF and CDF follow the histogram 
 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; X = np.linspace(-5.0, 5.0, 100) 
    &gt;&gt;&gt; fig, ax = plt.subplots() 
    &gt;&gt;&gt; ax.set_title(&quot;PDF from Template&quot;) 
    &gt;&gt;&gt; ax.hist(data, density=True, bins=100) 
    &gt;&gt;&gt; ax.plot(X, hist_dist.pdf(X), label='PDF') 
    &gt;&gt;&gt; ax.plot(X, hist_dist.cdf(X), label='CDF') 
    &gt;&gt;&gt; ax.legend() 
    &gt;&gt;&gt; fig.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_support_mask = rv_continuous._support_mask</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">histogram</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">density=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s3">&quot;&quot;&quot; 
        Create a new distribution using the given histogram 
 
        Parameters 
        ---------- 
        histogram : tuple of array_like 
            Tuple containing two array_like objects. 
            The first containing the content of n bins, 
            the second containing the (n+1) bin boundaries. 
            In particular, the return value of np.histogram is accepted. 
        density : bool, optional 
            If False, assumes the histogram is proportional to counts per bin; 
            otherwise, assumes it is proportional to a density. 
            For constant bin widths, these are equivalent. 
            If None (default), sets ``density=True`` for backward 
            compatibility, but warns if the bin widths are variable. Set 
            `density` explicitly to silence the warning. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._histogram = histogram</span>
        <span class="s1">self._density = density</span>
        <span class="s2">if </span><span class="s1">len(histogram) != </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Expected length 2 for parameter histogram&quot;</span><span class="s1">)</span>
        <span class="s1">self._hpdf = np.asarray(histogram[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">self._hbins = np.asarray(histogram[</span><span class="s5">1</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">len(self._hpdf) + </span><span class="s5">1 </span><span class="s1">!= len(self._hbins):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Number of elements in histogram content &quot;</span>
                             <span class="s4">&quot;and histogram boundaries do not match, &quot;</span>
                             <span class="s4">&quot;expected n and n+1.&quot;</span><span class="s1">)</span>
        <span class="s1">self._hbin_widths = self._hbins[</span><span class="s5">1</span><span class="s1">:] - self._hbins[:-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">bins_vary = </span><span class="s2">not </span><span class="s1">np.allclose(self._hbin_widths</span><span class="s2">, </span><span class="s1">self._hbin_widths[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">density </span><span class="s2">is None and </span><span class="s1">bins_vary:</span>
            <span class="s1">message = (</span><span class="s4">&quot;Bin widths are not constant. Assuming `density=True`.&quot;</span>
                       <span class="s4">&quot;Specify `density` explicitly to silence this warning.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(message</span><span class="s2">, </span><span class="s1">RuntimeWarning</span><span class="s2">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">density = </span><span class="s2">True</span>
        <span class="s2">elif not </span><span class="s1">density:</span>
            <span class="s1">self._hpdf = self._hpdf / self._hbin_widths</span>

        <span class="s1">self._hpdf = self._hpdf / float(np.sum(self._hpdf * self._hbin_widths))</span>
        <span class="s1">self._hcdf = np.cumsum(self._hpdf * self._hbin_widths)</span>
        <span class="s1">self._hpdf = np.hstack([</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">self._hpdf</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">])</span>
        <span class="s1">self._hcdf = np.hstack([</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">self._hcdf])</span>
        <span class="s0"># Set support</span>
        <span class="s1">kwargs[</span><span class="s4">'a'</span><span class="s1">] = self.a = self._hbins[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">kwargs[</span><span class="s4">'b'</span><span class="s1">] = self.b = self._hbins[-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">super().__init__(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s3">&quot;&quot;&quot; 
        PDF of the histogram 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._hpdf[np.searchsorted(self._hbins</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">side=</span><span class="s4">'right'</span><span class="s1">)]</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s3">&quot;&quot;&quot; 
        CDF calculated from the histogram 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.interp(x</span><span class="s2">, </span><span class="s1">self._hbins</span><span class="s2">, </span><span class="s1">self._hcdf)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s3">&quot;&quot;&quot; 
        Percentile function calculated from the histogram 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.interp(x</span><span class="s2">, </span><span class="s1">self._hcdf</span><span class="s2">, </span><span class="s1">self._hbins)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s3">&quot;&quot;&quot;Compute the n-th non-central moment.&quot;&quot;&quot;</span>
        <span class="s1">integrals = (self._hbins[</span><span class="s5">1</span><span class="s1">:]**(n+</span><span class="s5">1</span><span class="s1">) - self._hbins[:-</span><span class="s5">1</span><span class="s1">]**(n+</span><span class="s5">1</span><span class="s1">)) / (n+</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.sum(self._hpdf[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">] * integrals)</span>

    <span class="s2">def </span><span class="s1">_entropy(self):</span>
        <span class="s3">&quot;&quot;&quot;Compute entropy of distribution&quot;&quot;&quot;</span>
        <span class="s1">res = _lazywhere(self._hpdf[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">0.0</span><span class="s2">,</span>
                         <span class="s1">(self._hpdf[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s1">np.log</span><span class="s2">,</span>
                         <span class="s5">0.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">-np.sum(self._hpdf[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">] * res * self._hbin_widths)</span>

    <span class="s2">def </span><span class="s1">_updated_ctor_param(self):</span>
        <span class="s3">&quot;&quot;&quot; 
        Set the histogram as additional constructor argument 
        &quot;&quot;&quot;</span>
        <span class="s1">dct = super()._updated_ctor_param()</span>
        <span class="s1">dct[</span><span class="s4">'histogram'</span><span class="s1">] = self._histogram</span>
        <span class="s1">dct[</span><span class="s4">'density'</span><span class="s1">] = self._density</span>
        <span class="s2">return </span><span class="s1">dct</span>


<span class="s2">class </span><span class="s1">studentized_range_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A studentized range continuous random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    t: Student's t distribution 
 
    Notes 
    ----- 
    The probability density function for `studentized_range` is: 
 
    .. math:: 
 
         f(x; k, \nu) = \frac{k(k-1)\nu^{\nu/2}}{\Gamma(\nu/2) 
                        2^{\nu/2-1}} \int_{0}^{\infty} \int_{-\infty}^{\infty} 
                        s^{\nu} e^{-\nu s^2/2} \phi(z) \phi(sx + z) 
                        [\Phi(sx + z) - \Phi(z)]^{k-2} \,dz \,ds 
 
    for :math:`x  0`, :math:`k &gt; 1`, and :math:`\nu &gt; 0`. 
 
    `studentized_range` takes ``k`` for :math:`k` and ``df`` for :math:`\nu` 
    as shape parameters. 
 
    When :math:`\nu` exceeds 100,000, an asymptotic approximation (infinite 
    degrees of freedom) is used to compute the cumulative distribution 
    function [4]_ and probability distribution function. 
 
    %(after_notes)s 
 
    References 
    ---------- 
 
    .. [1] &quot;Studentized range distribution&quot;, 
           https://en.wikipedia.org/wiki/Studentized_range_distribution 
    .. [2] Batista, Ben Divide, et al. &quot;Externally Studentized Normal Midrange 
           Distribution.&quot; Cincia e Agrotecnologia, vol. 41, no. 4, 2017, pp. 
           378-389., doi:10.1590/1413-70542017414047716. 
    .. [3] Harter, H. Leon. &quot;Tables of Range and Studentized Range.&quot; The Annals 
           of Mathematical Statistics, vol. 31, no. 4, 1960, pp. 1122-1147. 
           JSTOR, www.jstor.org/stable/2237810. Accessed 18 Feb. 2021. 
    .. [4] Lund, R. E., and J. R. Lund. &quot;Algorithm AS 190: Probabilities and 
           Upper Quantiles for the Studentized Range.&quot; Journal of the Royal 
           Statistical Society. Series C (Applied Statistics), vol. 32, no. 2, 
           1983, pp. 204-210. JSTOR, www.jstor.org/stable/2347300. Accessed 18 
           Feb. 2021. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import studentized_range 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
 
    Calculate the first four moments: 
 
    &gt;&gt;&gt; k, df = 3, 10 
    &gt;&gt;&gt; mean, var, skew, kurt = studentized_range.stats(k, df, moments='mvsk') 
 
    Display the probability density function (``pdf``): 
 
    &gt;&gt;&gt; x = np.linspace(studentized_range.ppf(0.01, k, df), 
    ...                 studentized_range.ppf(0.99, k, df), 100) 
    &gt;&gt;&gt; ax.plot(x, studentized_range.pdf(x, k, df), 
    ...         'r-', lw=5, alpha=0.6, label='studentized_range pdf') 
 
    Alternatively, the distribution object can be called (as a function) 
    to fix the shape, location and scale parameters. This returns a &quot;frozen&quot; 
    RV object holding the given parameters fixed. 
 
    Freeze the distribution and display the frozen ``pdf``: 
 
    &gt;&gt;&gt; rv = studentized_range(k, df) 
    &gt;&gt;&gt; ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf') 
 
    Check accuracy of ``cdf`` and ``ppf``: 
 
    &gt;&gt;&gt; vals = studentized_range.ppf([0.001, 0.5, 0.999], k, df) 
    &gt;&gt;&gt; np.allclose([0.001, 0.5, 0.999], studentized_range.cdf(vals, k, df)) 
    True 
 
    Rather than using (``studentized_range.rvs``) to generate random variates, 
    which is very slow for this distribution, we can approximate the inverse 
    CDF using an interpolator, and then perform inverse transform sampling 
    with this approximate inverse CDF. 
 
    This distribution has an infinite but thin right tail, so we focus our 
    attention on the leftmost 99.9 percent. 
 
    &gt;&gt;&gt; a, b = studentized_range.ppf([0, .999], k, df) 
    &gt;&gt;&gt; a, b 
    0, 7.41058083802274 
 
    &gt;&gt;&gt; from scipy.interpolate import interp1d 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; xs = np.linspace(a, b, 50) 
    &gt;&gt;&gt; cdf = studentized_range.cdf(xs, k, df) 
    # Create an interpolant of the inverse CDF 
    &gt;&gt;&gt; ppf = interp1d(cdf, xs, fill_value='extrapolate') 
    # Perform inverse transform sampling using the interpolant 
    &gt;&gt;&gt; r = ppf(rng.uniform(size=1000)) 
 
    And compare the histogram: 
 
    &gt;&gt;&gt; ax.hist(r, density=True, histtype='stepfilled', alpha=0.2) 
    &gt;&gt;&gt; ax.legend(loc='best', frameon=False) 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s2">return </span><span class="s1">(k &gt; </span><span class="s5">1</span><span class="s1">) &amp; (df &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s1">ik = _ShapeInfo(</span><span class="s4">&quot;k&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s1">idf = _ShapeInfo(</span><span class="s4">&quot;df&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">[ik</span><span class="s2">, </span><span class="s1">idf]</span>

    <span class="s2">def </span><span class="s1">_fitstart(self</span><span class="s2">, </span><span class="s1">data):</span>
        <span class="s0"># Default is k=1, but that is not a valid value of the parameter.</span>
        <span class="s2">return </span><span class="s1">super()._fitstart(data</span><span class="s2">, </span><span class="s1">args=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">K</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s1">cython_symbol = </span><span class="s4">'_studentized_range_moment'</span>
        <span class="s1">_a</span><span class="s2">, </span><span class="s1">_b = self._get_support()</span>
        <span class="s0"># all three of these are used to create a numpy array so they must</span>
        <span class="s0"># be the same shape.</span>

        <span class="s2">def </span><span class="s1">_single_moment(K</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s1">log_const = _stats._studentized_range_pdf_logconst(k</span><span class="s2">, </span><span class="s1">df)</span>
            <span class="s1">arg = [K</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">log_const]</span>
            <span class="s1">usr_data = np.array(arg</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>

            <span class="s1">llc = LowLevelCallable.from_cython(_stats</span><span class="s2">, </span><span class="s1">cython_symbol</span><span class="s2">, </span><span class="s1">usr_data)</span>

            <span class="s1">ranges = [(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(_a</span><span class="s2">, </span><span class="s1">_b)]</span>
            <span class="s1">opts = dict(epsabs=</span><span class="s5">1e-11</span><span class="s2">, </span><span class="s1">epsrel=</span><span class="s5">1e-12</span><span class="s1">)</span>

            <span class="s2">return </span><span class="s1">integrate.nquad(llc</span><span class="s2">, </span><span class="s1">ranges=ranges</span><span class="s2">, </span><span class="s1">opts=opts)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">ufunc = np.frompyfunc(_single_moment</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.asarray(ufunc(K</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">, </span><span class="s1">dtype=np.float64)[()]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>

        <span class="s2">def </span><span class="s1">_single_pdf(q</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s0"># The infinite form of the PDF is derived from the infinite</span>
            <span class="s0"># CDF.</span>
            <span class="s2">if </span><span class="s1">df &lt; </span><span class="s5">100000</span><span class="s1">:</span>
                <span class="s1">cython_symbol = </span><span class="s4">'_studentized_range_pdf'</span>
                <span class="s1">log_const = _stats._studentized_range_pdf_logconst(k</span><span class="s2">, </span><span class="s1">df)</span>
                <span class="s1">arg = [q</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">log_const]</span>
                <span class="s1">usr_data = np.array(arg</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
                <span class="s1">ranges = [(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)]</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">cython_symbol = </span><span class="s4">'_studentized_range_pdf_asymptotic'</span>
                <span class="s1">arg = [q</span><span class="s2">, </span><span class="s1">k]</span>
                <span class="s1">usr_data = np.array(arg</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
                <span class="s1">ranges = [(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)]</span>

            <span class="s1">llc = LowLevelCallable.from_cython(_stats</span><span class="s2">, </span><span class="s1">cython_symbol</span><span class="s2">, </span><span class="s1">usr_data)</span>
            <span class="s1">opts = dict(epsabs=</span><span class="s5">1e-11</span><span class="s2">, </span><span class="s1">epsrel=</span><span class="s5">1e-12</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">integrate.nquad(llc</span><span class="s2">, </span><span class="s1">ranges=ranges</span><span class="s2">, </span><span class="s1">opts=opts)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">ufunc = np.frompyfunc(_single_pdf</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.asarray(ufunc(x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">, </span><span class="s1">dtype=np.float64)[()]</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>

        <span class="s2">def </span><span class="s1">_single_cdf(q</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df):</span>
            <span class="s0"># &quot;When the degrees of freedom V are infinite the probability</span>
            <span class="s0"># integral takes [on a] simpler form,&quot; and a single asymptotic</span>
            <span class="s0"># integral is evaluated rather than the standard double integral.</span>
            <span class="s0"># (Lund, Lund, page 205)</span>
            <span class="s2">if </span><span class="s1">df &lt; </span><span class="s5">100000</span><span class="s1">:</span>
                <span class="s1">cython_symbol = </span><span class="s4">'_studentized_range_cdf'</span>
                <span class="s1">log_const = _stats._studentized_range_cdf_logconst(k</span><span class="s2">, </span><span class="s1">df)</span>
                <span class="s1">arg = [q</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">log_const]</span>
                <span class="s1">usr_data = np.array(arg</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
                <span class="s1">ranges = [(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)]</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">cython_symbol = </span><span class="s4">'_studentized_range_cdf_asymptotic'</span>
                <span class="s1">arg = [q</span><span class="s2">, </span><span class="s1">k]</span>
                <span class="s1">usr_data = np.array(arg</span><span class="s2">, </span><span class="s1">float).ctypes.data_as(ctypes.c_void_p)</span>
                <span class="s1">ranges = [(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)]</span>

            <span class="s1">llc = LowLevelCallable.from_cython(_stats</span><span class="s2">, </span><span class="s1">cython_symbol</span><span class="s2">, </span><span class="s1">usr_data)</span>
            <span class="s1">opts = dict(epsabs=</span><span class="s5">1e-11</span><span class="s2">, </span><span class="s1">epsrel=</span><span class="s5">1e-12</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">integrate.nquad(llc</span><span class="s2">, </span><span class="s1">ranges=ranges</span><span class="s2">, </span><span class="s1">opts=opts)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">ufunc = np.frompyfunc(_single_cdf</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s0"># clip p-values to ensure they are in [0, 1].</span>
        <span class="s2">return </span><span class="s1">np.clip(np.asarray(ufunc(x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">, </span><span class="s1">dtype=np.float64)[()]</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>


<span class="s1">studentized_range = studentized_range_gen(name=</span><span class="s4">'studentized_range'</span><span class="s2">, </span><span class="s1">a=</span><span class="s5">0</span><span class="s2">,</span>
                                          <span class="s1">b=np.inf)</span>


<span class="s2">class </span><span class="s1">rel_breitwigner_gen(rv_continuous):</span>
    <span class="s3">r&quot;&quot;&quot;A relativistic Breit-Wigner random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    cauchy: Cauchy distribution, also known as the Breit-Wigner distribution. 
 
    Notes 
    ----- 
 
    The probability density function for `rel_breitwigner` is 
 
    .. math:: 
 
        f(x, \rho) = \frac{k}{(x^2 - \rho^2)^2 + \rho^2} 
 
    where 
 
    .. math:: 
        k = \frac{2\sqrt{2}\rho^2\sqrt{\rho^2 + 1}} 
            {\pi\sqrt{\rho^2 + \rho\sqrt{\rho^2 + 1}}} 
 
    The relativistic Breit-Wigner distribution is used in high energy physics 
    to model resonances [1]_. It gives the uncertainty in the invariant mass, 
    :math:`M` [2]_, of a resonance with characteristic mass :math:`M_0` and 
    decay-width :math:`\Gamma`, where :math:`M`, :math:`M_0` and :math:`\Gamma` 
    are expressed in natural units. In SciPy's parametrization, the shape 
    parameter :math:`\rho` is equal to :math:`M_0/\Gamma` and takes values in 
    :math:`(0, \infty)`. 
 
    Equivalently, the relativistic Breit-Wigner distribution is said to give 
    the uncertainty in the center-of-mass energy :math:`E_{\text{cm}}`. In 
    natural units, the speed of light :math:`c` is equal to 1 and the invariant 
    mass :math:`M` is equal to the rest energy :math:`Mc^2`. In the 
    center-of-mass frame, the rest energy is equal to the total energy [3]_. 
 
    %(after_notes)s 
 
    :math:`\rho = M/\Gamma` and :math:`\Gamma` is the scale parameter. For 
    example, if one seeks to model the :math:`Z^0` boson with :math:`M_0 
    \approx 91.1876 \text{ GeV}` and :math:`\Gamma \approx 2.4952\text{ GeV}` 
    [4]_ one can set ``rho=91.1876/2.4952`` and ``scale=2.4952``. 
 
    To ensure a physically meaningful result when using the `fit` method, one 
    should set ``floc=0`` to fix the location parameter to 0. 
 
    References 
    ---------- 
    .. [1] Relativistic Breit-Wigner distribution, Wikipedia, 
           https://en.wikipedia.org/wiki/Relativistic_Breit-Wigner_distribution 
    .. [2] Invariant mass, Wikipedia, 
           https://en.wikipedia.org/wiki/Invariant_mass 
    .. [3] Center-of-momentum frame, Wikipedia, 
           https://en.wikipedia.org/wiki/Center-of-momentum_frame 
    .. [4] M. Tanabashi et al. (Particle Data Group) Phys. Rev. D 98, 030001 - 
           Published 17 August 2018 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">rho):</span>
        <span class="s2">return </span><span class="s1">rho &gt; </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;rho&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">rho):</span>
        <span class="s0"># C = k / rho**2</span>
        <span class="s1">C = np.sqrt(</span>
            <span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">1 </span><span class="s1">+ np.sqrt(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">))</span>
        <span class="s1">) * </span><span class="s5">2 </span><span class="s1">/ np.pi</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">C / (((x - rho)*(x + rho)/rho)**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">rho):</span>
        <span class="s0"># C = k / (2 * rho**2) / np.sqrt(1 + 1/rho**2)</span>
        <span class="s1">C = np.sqrt(</span><span class="s5">2</span><span class="s1">/(</span><span class="s5">1 </span><span class="s1">+ np.sqrt(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">)))/np.pi</span>
        <span class="s1">result = (</span>
            <span class="s1">np.sqrt(-</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1j</span><span class="s1">/rho)</span>
            <span class="s1">* np.arctan(x/np.sqrt(-rho*(rho + </span><span class="s5">1j</span><span class="s1">)))</span>
        <span class="s1">)</span>
        <span class="s1">result = C * </span><span class="s5">2 </span><span class="s1">* np.imag(result)</span>
        <span class="s0"># Sometimes above formula produces values greater than 1.</span>
        <span class="s2">return </span><span class="s1">np.clip(result</span><span class="s2">, None, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">rho):</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s0"># C = k / (2 * rho)</span>
            <span class="s1">C = np.sqrt(</span>
                <span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">1 </span><span class="s1">+ np.sqrt(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">))</span>
            <span class="s1">) / np.pi * rho</span>
            <span class="s2">return </span><span class="s1">C * (np.pi/</span><span class="s5">2 </span><span class="s1">+ np.arctan(rho))</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s0"># C = pi * k / (4 * rho)</span>
            <span class="s1">C = np.sqrt(</span>
                <span class="s1">(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ np.sqrt(</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">/rho**</span><span class="s5">2</span><span class="s1">)))</span>
            <span class="s1">) * rho</span>
            <span class="s1">result = (</span><span class="s5">1 </span><span class="s1">- rho * </span><span class="s5">1j</span><span class="s1">) / np.sqrt(-</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1j</span><span class="s1">/rho)</span>
            <span class="s2">return </span><span class="s5">2 </span><span class="s1">* C * np.real(result)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.inf</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">rho):</span>
        <span class="s0"># Returning None from stats makes public stats use _munp.</span>
        <span class="s0"># nan values will be omitted from public stats. Skew and</span>
        <span class="s0"># kurtosis are actually infinite.</span>
        <span class="s2">return None, None, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">np.nan</span>

    <span class="s1">@inherit_docstring_from(rv_continuous)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s0"># Override rv_continuous.fit to better handle case where floc is set.</span>
        <span class="s1">data</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">floc</span><span class="s2">, </span><span class="s1">fscale = _check_fit_input_parameters(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwds</span>
        <span class="s1">)</span>

        <span class="s1">censored = isinstance(data</span><span class="s2">, </span><span class="s1">CensoredData)</span>
        <span class="s2">if </span><span class="s1">censored:</span>
            <span class="s2">if </span><span class="s1">data.num_censored() == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s0"># There are no censored values in data, so replace the</span>
                <span class="s0"># CensoredData instance with a regular array.</span>
                <span class="s1">data = data._uncensored</span>
                <span class="s1">censored = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">floc </span><span class="s2">is None or </span><span class="s1">censored:</span>
            <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">if </span><span class="s1">fscale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s0"># The interquartile range approximates the scale parameter gamma.</span>
            <span class="s0"># The median approximates rho * gamma.</span>
            <span class="s1">p25</span><span class="s2">, </span><span class="s1">p50</span><span class="s2">, </span><span class="s1">p75 = np.quantile(data - floc</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.25</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.75</span><span class="s1">])</span>
            <span class="s1">scale_0 = p75 - p25</span>
            <span class="s1">rho_0 = p50 / scale_0</span>
            <span class="s2">if not </span><span class="s1">args:</span>
                <span class="s1">args = [rho_0]</span>
            <span class="s2">if </span><span class="s4">&quot;scale&quot; </span><span class="s2">not in </span><span class="s1">kwds:</span>
                <span class="s1">kwds[</span><span class="s4">&quot;scale&quot;</span><span class="s1">] = scale_0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">M_0 = np.median(data - floc)</span>
            <span class="s1">rho_0 = M_0 / fscale</span>
            <span class="s2">if not </span><span class="s1">args:</span>
                <span class="s1">args = [rho_0]</span>
        <span class="s2">return </span><span class="s1">super().fit(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds)</span>


<span class="s1">rel_breitwigner = rel_breitwigner_gen(a=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;rel_breitwigner&quot;</span><span class="s1">)</span>


<span class="s0"># Collect names of classes and objects in this module.</span>
<span class="s1">pairs = list(globals().copy().items())</span>
<span class="s1">_distn_names</span><span class="s2">, </span><span class="s1">_distn_gen_names = get_distribution_names(pairs</span><span class="s2">, </span><span class="s1">rv_continuous)</span>

<span class="s1">__all__ = _distn_names + _distn_gen_names + [</span><span class="s4">'rv_histogram'</span><span class="s1">]</span>
</pre>
</body>
</html>
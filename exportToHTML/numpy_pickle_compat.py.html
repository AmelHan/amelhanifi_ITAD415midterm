<html>
<head>
<title>numpy_pickle_compat.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
.s6 { color: #a5c261;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
numpy_pickle_compat.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Numpy pickle compatibility functions.&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">pickle</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">zlib</span>
<span class="s2">import </span><span class="s1">inspect</span>

<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">BytesIO</span>

<span class="s2">from </span><span class="s1">.numpy_pickle_utils </span><span class="s2">import </span><span class="s1">_ZFILE_PREFIX</span>
<span class="s2">from </span><span class="s1">.numpy_pickle_utils </span><span class="s2">import </span><span class="s1">Unpickler</span>
<span class="s2">from </span><span class="s1">.numpy_pickle_utils </span><span class="s2">import </span><span class="s1">_ensure_native_byte_order</span>


<span class="s2">def </span><span class="s1">hex_str(an_int):</span>
    <span class="s0">&quot;&quot;&quot;Convert an int to an hexadecimal string.&quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s3">'{:#x}'</span><span class="s1">.format(an_int)</span>


<span class="s2">def </span><span class="s1">asbytes(s):</span>
    <span class="s2">if </span><span class="s1">isinstance(s</span><span class="s2">, </span><span class="s1">bytes):</span>
        <span class="s2">return </span><span class="s1">s</span>
    <span class="s2">return </span><span class="s1">s.encode(</span><span class="s3">'latin1'</span><span class="s1">)</span>


<span class="s1">_MAX_LEN = len(hex_str(</span><span class="s4">2 </span><span class="s1">** </span><span class="s4">64</span><span class="s1">))</span>
<span class="s1">_CHUNK_SIZE = </span><span class="s4">64 </span><span class="s1">* </span><span class="s4">1024</span>


<span class="s2">def </span><span class="s1">read_zfile(file_handle):</span>
    <span class="s0">&quot;&quot;&quot;Read the z-file and return the content as a string. 
 
    Z-files are raw data compressed with zlib used internally by joblib 
    for persistence. Backward compatibility is not guaranteed. Do not 
    use for external purposes. 
    &quot;&quot;&quot;</span>
    <span class="s1">file_handle.seek(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">header_length = len(_ZFILE_PREFIX) + _MAX_LEN</span>
    <span class="s1">length = file_handle.read(header_length)</span>
    <span class="s1">length = length[len(_ZFILE_PREFIX):]</span>
    <span class="s1">length = int(length</span><span class="s2">, </span><span class="s4">16</span><span class="s1">)</span>

    <span class="s5"># With python2 and joblib version &lt;= 0.8.4 compressed pickle header is one</span>
    <span class="s5"># character wider so we need to ignore an additional space if present.</span>
    <span class="s5"># Note: the first byte of the zlib data is guaranteed not to be a</span>
    <span class="s5"># space according to</span>
    <span class="s5"># https://tools.ietf.org/html/rfc6713#section-2.1</span>
    <span class="s1">next_byte = file_handle.read(</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">next_byte != </span><span class="s6">b' '</span><span class="s1">:</span>
        <span class="s5"># The zlib compressed data has started and we need to go back</span>
        <span class="s5"># one byte</span>
        <span class="s1">file_handle.seek(header_length)</span>

    <span class="s5"># We use the known length of the data to tell Zlib the size of the</span>
    <span class="s5"># buffer to allocate.</span>
    <span class="s1">data = zlib.decompress(file_handle.read()</span><span class="s2">, </span><span class="s4">15</span><span class="s2">, </span><span class="s1">length)</span>
    <span class="s2">assert </span><span class="s1">len(data) == length</span><span class="s2">, </span><span class="s1">(</span>
        <span class="s3">&quot;Incorrect data length while decompressing %s.&quot;</span>
        <span class="s3">&quot;The file could be corrupted.&quot; </span><span class="s1">% file_handle)</span>
    <span class="s2">return </span><span class="s1">data</span>


<span class="s2">def </span><span class="s1">write_zfile(file_handle</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">compress=</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Write the data in the given file as a Z-file. 
 
    Z-files are raw data compressed with zlib used internally by joblib 
    for persistence. Backward compatibility is not guaranteed. Do not 
    use for external purposes. 
    &quot;&quot;&quot;</span>
    <span class="s1">file_handle.write(_ZFILE_PREFIX)</span>
    <span class="s1">length = hex_str(len(data))</span>
    <span class="s5"># Store the length of the data</span>
    <span class="s1">file_handle.write(asbytes(length.ljust(_MAX_LEN)))</span>
    <span class="s1">file_handle.write(zlib.compress(asbytes(data)</span><span class="s2">, </span><span class="s1">compress))</span>

<span class="s5">###############################################################################</span>
<span class="s5"># Utility objects for persistence.</span>


<span class="s2">class </span><span class="s1">NDArrayWrapper(object):</span>
    <span class="s0">&quot;&quot;&quot;An object to be persisted instead of numpy arrays. 
 
    The only thing this object does, is to carry the filename in which 
    the array has been persisted, and the array subclass. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">subclass</span><span class="s2">, </span><span class="s1">allow_mmap=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;Constructor. Store the useful information for later.&quot;&quot;&quot;</span>
        <span class="s1">self.filename = filename</span>
        <span class="s1">self.subclass = subclass</span>
        <span class="s1">self.allow_mmap = allow_mmap</span>

    <span class="s2">def </span><span class="s1">read(self</span><span class="s2">, </span><span class="s1">unpickler):</span>
        <span class="s0">&quot;&quot;&quot;Reconstruct the array.&quot;&quot;&quot;</span>
        <span class="s1">filename = os.path.join(unpickler._dirname</span><span class="s2">, </span><span class="s1">self.filename)</span>
        <span class="s5"># Load the array from the disk</span>
        <span class="s5"># use getattr instead of self.allow_mmap to ensure backward compat</span>
        <span class="s5"># with NDArrayWrapper instances pickled with joblib &lt; 0.9.0</span>
        <span class="s1">allow_mmap = getattr(self</span><span class="s2">, </span><span class="s3">'allow_mmap'</span><span class="s2">, True</span><span class="s1">)</span>
        <span class="s1">kwargs = {}</span>
        <span class="s2">if </span><span class="s1">allow_mmap:</span>
            <span class="s1">kwargs[</span><span class="s3">'mmap_mode'</span><span class="s1">] = unpickler.mmap_mode</span>
        <span class="s2">if </span><span class="s3">&quot;allow_pickle&quot; </span><span class="s2">in </span><span class="s1">inspect.signature(unpickler.np.load).parameters:</span>
            <span class="s5"># Required in numpy 1.16.3 and later to aknowledge the security</span>
            <span class="s5"># risk.</span>
            <span class="s1">kwargs[</span><span class="s3">&quot;allow_pickle&quot;</span><span class="s1">] = </span><span class="s2">True</span>
        <span class="s1">array = unpickler.np.load(filename</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s5"># Detect byte order mismatch and swap as needed.</span>
        <span class="s1">array = _ensure_native_byte_order(array)</span>

        <span class="s5"># Reconstruct subclasses. This does not work with old</span>
        <span class="s5"># versions of numpy</span>
        <span class="s2">if </span><span class="s1">(hasattr(array</span><span class="s2">, </span><span class="s3">'__array_prepare__'</span><span class="s1">) </span><span class="s2">and</span>
            <span class="s1">self.subclass </span><span class="s2">not in </span><span class="s1">(unpickler.np.ndarray</span><span class="s2">,</span>
                                  <span class="s1">unpickler.np.memmap)):</span>
            <span class="s5"># We need to reconstruct another subclass</span>
            <span class="s1">new_array = unpickler.np.core.multiarray._reconstruct(</span>
                <span class="s1">self.subclass</span><span class="s2">, </span><span class="s1">(</span><span class="s4">0</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s3">'b'</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">new_array.__array_prepare__(array)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">array</span>


<span class="s2">class </span><span class="s1">ZNDArrayWrapper(NDArrayWrapper):</span>
    <span class="s0">&quot;&quot;&quot;An object to be persisted instead of numpy arrays. 
 
    This object store the Zfile filename in which 
    the data array has been persisted, and the meta information to 
    retrieve it. 
    The reason that we store the raw buffer data of the array and 
    the meta information, rather than array representation routine 
    (tobytes) is that it enables us to use completely the strided 
    model to avoid memory copies (a and a.T store as fast). In 
    addition saving the heavy information separately can avoid 
    creating large temporary buffers when unpickling data with 
    large arrays. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">init_args</span><span class="s2">, </span><span class="s1">state):</span>
        <span class="s0">&quot;&quot;&quot;Constructor. Store the useful information for later.&quot;&quot;&quot;</span>
        <span class="s1">self.filename = filename</span>
        <span class="s1">self.state = state</span>
        <span class="s1">self.init_args = init_args</span>

    <span class="s2">def </span><span class="s1">read(self</span><span class="s2">, </span><span class="s1">unpickler):</span>
        <span class="s0">&quot;&quot;&quot;Reconstruct the array from the meta-information and the z-file.&quot;&quot;&quot;</span>
        <span class="s5"># Here we a simply reproducing the unpickling mechanism for numpy</span>
        <span class="s5"># arrays</span>
        <span class="s1">filename = os.path.join(unpickler._dirname</span><span class="s2">, </span><span class="s1">self.filename)</span>
        <span class="s1">array = unpickler.np.core.multiarray._reconstruct(*self.init_args)</span>
        <span class="s2">with </span><span class="s1">open(filename</span><span class="s2">, </span><span class="s3">'rb'</span><span class="s1">) </span><span class="s2">as </span><span class="s1">f:</span>
            <span class="s1">data = read_zfile(f)</span>
        <span class="s1">state = self.state + (data</span><span class="s2">,</span><span class="s1">)</span>
        <span class="s1">array.__setstate__(state)</span>
        <span class="s2">return </span><span class="s1">array</span>


<span class="s2">class </span><span class="s1">ZipNumpyUnpickler(Unpickler):</span>
    <span class="s0">&quot;&quot;&quot;A subclass of the Unpickler to unpickle our numpy pickles.&quot;&quot;&quot;</span>

    <span class="s1">dispatch = Unpickler.dispatch.copy()</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">file_handle</span><span class="s2">, </span><span class="s1">mmap_mode=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;Constructor.&quot;&quot;&quot;</span>
        <span class="s1">self._filename = os.path.basename(filename)</span>
        <span class="s1">self._dirname = os.path.dirname(filename)</span>
        <span class="s1">self.mmap_mode = mmap_mode</span>
        <span class="s1">self.file_handle = self._open_pickle(file_handle)</span>
        <span class="s1">Unpickler.__init__(self</span><span class="s2">, </span><span class="s1">self.file_handle)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
        <span class="s2">except </span><span class="s1">ImportError:</span>
            <span class="s1">np = </span><span class="s2">None</span>
        <span class="s1">self.np = np</span>

    <span class="s2">def </span><span class="s1">_open_pickle(self</span><span class="s2">, </span><span class="s1">file_handle):</span>
        <span class="s2">return </span><span class="s1">BytesIO(read_zfile(file_handle))</span>

    <span class="s2">def </span><span class="s1">load_build(self):</span>
        <span class="s0">&quot;&quot;&quot;Set the state of a newly created object. 
 
        We capture it to replace our place-holder objects, 
        NDArrayWrapper, by the array we are interested in. We 
        replace them directly in the stack of pickler. 
        &quot;&quot;&quot;</span>
        <span class="s1">Unpickler.load_build(self)</span>
        <span class="s2">if </span><span class="s1">isinstance(self.stack[-</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">NDArrayWrapper):</span>
            <span class="s2">if </span><span class="s1">self.np </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ImportError(</span><span class="s3">&quot;Trying to unpickle an ndarray, &quot;</span>
                                  <span class="s3">&quot;but numpy didn't import correctly&quot;</span><span class="s1">)</span>
            <span class="s1">nd_array_wrapper = self.stack.pop()</span>
            <span class="s1">array = nd_array_wrapper.read(self)</span>
            <span class="s1">self.stack.append(array)</span>

    <span class="s1">dispatch[pickle.BUILD[</span><span class="s4">0</span><span class="s1">]] = load_build</span>


<span class="s2">def </span><span class="s1">load_compatibility(filename):</span>
    <span class="s0">&quot;&quot;&quot;Reconstruct a Python object from a file persisted with joblib.dump. 
 
    This function ensures the compatibility with joblib old persistence format 
    (&lt;= 0.9.3). 
 
    Parameters 
    ---------- 
    filename: string 
        The name of the file from which to load the object 
 
    Returns 
    ------- 
    result: any Python object 
        The object stored in the file. 
 
    See Also 
    -------- 
    joblib.dump : function to save an object 
 
    Notes 
    ----- 
 
    This function can load numpy array files saved separately during the 
    dump. 
    &quot;&quot;&quot;</span>
    <span class="s2">with </span><span class="s1">open(filename</span><span class="s2">, </span><span class="s3">'rb'</span><span class="s1">) </span><span class="s2">as </span><span class="s1">file_handle:</span>
        <span class="s5"># We are careful to open the file handle early and keep it open to</span>
        <span class="s5"># avoid race-conditions on renames. That said, if data is stored in</span>
        <span class="s5"># companion files, moving the directory will create a race when</span>
        <span class="s5"># joblib tries to access the companion files.</span>
        <span class="s1">unpickler = ZipNumpyUnpickler(filename</span><span class="s2">, </span><span class="s1">file_handle=file_handle)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">obj = unpickler.load()</span>
        <span class="s2">except </span><span class="s1">UnicodeDecodeError </span><span class="s2">as </span><span class="s1">exc:</span>
            <span class="s5"># More user-friendly error message</span>
            <span class="s1">new_exc = ValueError(</span>
                <span class="s3">'You may be trying to read with '</span>
                <span class="s3">'python 3 a joblib pickle generated with python 2. '</span>
                <span class="s3">'This feature is not supported by joblib.'</span><span class="s1">)</span>
            <span class="s1">new_exc.__cause__ = exc</span>
            <span class="s2">raise </span><span class="s1">new_exc</span>
        <span class="s2">finally</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">hasattr(unpickler</span><span class="s2">, </span><span class="s3">'file_handle'</span><span class="s1">):</span>
                <span class="s1">unpickler.file_handle.close()</span>
        <span class="s2">return </span><span class="s1">obj</span>
</pre>
</body>
</html>
<html>
<head>
<title>smoothers.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
smoothers.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
This module contains scatterplot smoothers, that is classes 
who generate a smooth fit of a set of (x,y) pairs. 
&quot;&quot;&quot;</span>

<span class="s2"># pylint: disable-msg=C0103</span>
<span class="s2"># pylint: disable-msg=W0142</span>
<span class="s2"># pylint: disable-msg=E0611</span>
<span class="s2"># pylint: disable-msg=E1101</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">. </span><span class="s3">import </span><span class="s1">kernels</span>


<span class="s3">class </span><span class="s1">KernelSmoother:</span>
    <span class="s0">&quot;&quot;&quot; 
    1D Kernel Density Regression/Kernel Smoother 
 
    Requires: 
    x - array_like of x values 
    y - array_like of y values 
    Kernel - Kernel object, Default is Gaussian. 
    &quot;&quot;&quot;</span>
    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">Kernel = </span><span class="s3">None</span><span class="s1">):</span>
        <span class="s3">if </span><span class="s1">Kernel </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">Kernel = kernels.Gaussian()</span>
        <span class="s1">self.Kernel = Kernel</span>
        <span class="s1">self.x = np.array(x)</span>
        <span class="s1">self.y = np.array(y)</span>

    <span class="s3">def </span><span class="s1">fit(self):</span>
        <span class="s3">pass</span>

    <span class="s3">def </span><span class="s1">__call__(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s3">return </span><span class="s1">np.array([self.predict(xx) </span><span class="s3">for </span><span class="s1">xx </span><span class="s3">in </span><span class="s1">x])</span>

    <span class="s3">def </span><span class="s1">predict(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the kernel smoothed prediction at x 
 
        If x is a real number then a single value is returned. 
 
        Otherwise an attempt is made to cast x to numpy.ndarray and an array of 
        corresponding y-points is returned. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">np.size(x) == </span><span class="s4">1</span><span class="s1">: </span><span class="s2"># if isinstance(x, numbers.Real):</span>
            <span class="s3">return </span><span class="s1">self.Kernel.smooth(self.x</span><span class="s3">, </span><span class="s1">self.y</span><span class="s3">, </span><span class="s1">x)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">np.array([self.Kernel.smooth(self.x</span><span class="s3">, </span><span class="s1">self.y</span><span class="s3">, </span><span class="s1">xx) </span><span class="s3">for </span><span class="s1">xx</span>
                                                <span class="s3">in </span><span class="s1">np.array(x)])</span>

    <span class="s3">def </span><span class="s1">conf(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the fitted curve and 1-sigma upper and lower point-wise 
        confidence. 
        These bounds are based on variance only, and do not include the bias. 
        If the bandwidth is much larger than the curvature of the underlying 
        function then the bias could be large. 
 
        x is the points on which you want to evaluate the fit and the errors. 
 
        Alternatively if x is specified as a positive integer, then the fit and 
        confidence bands points will be returned after every 
        xth sample point - so they are closer together where the data 
        is denser. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">isinstance(x</span><span class="s3">, </span><span class="s1">int):</span>
            <span class="s1">sorted_x = np.array(self.x)</span>
            <span class="s1">sorted_x.sort()</span>
            <span class="s1">confx = sorted_x[::x]</span>
            <span class="s1">conffit = self.conf(confx)</span>
            <span class="s3">return </span><span class="s1">(confx</span><span class="s3">, </span><span class="s1">conffit)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">np.array([self.Kernel.smoothconf(self.x</span><span class="s3">, </span><span class="s1">self.y</span><span class="s3">, </span><span class="s1">xx)</span>
                                                                <span class="s3">for </span><span class="s1">xx </span><span class="s3">in </span><span class="s1">x])</span>


    <span class="s3">def </span><span class="s1">var(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s3">return </span><span class="s1">np.array([self.Kernel.smoothvar(self.x</span><span class="s3">, </span><span class="s1">self.y</span><span class="s3">, </span><span class="s1">xx) </span><span class="s3">for </span><span class="s1">xx </span><span class="s3">in </span><span class="s1">x])</span>

    <span class="s3">def </span><span class="s1">std(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s3">return </span><span class="s1">np.sqrt(self.var(x))</span>

<span class="s3">class </span><span class="s1">PolySmoother:</span>
    <span class="s0">&quot;&quot;&quot; 
    Polynomial smoother up to a given order. 
    Fit based on weighted least squares. 
 
    The x values can be specified at instantiation or when called. 
 
    This is a 3 liner with OLS or WLS, see test. 
    It's here as a test smoother for GAM 
    &quot;&quot;&quot;</span>
    <span class="s2">#JP: heavily adjusted to work as plugin replacement for bspline</span>
    <span class="s2">#   smoother in gam.py  initialized by function default_smoother</span>
    <span class="s2">#   Only fixed exceptions, I did not check whether it is statistically</span>
    <span class="s2">#   correctand I think it is not, there are still be some dimension</span>
    <span class="s2">#   problems, and there were some dimension problems initially.</span>
    <span class="s2"># TODO: undo adjustments and fix dimensions correctly</span>
    <span class="s2"># comment: this is just like polyfit with initialization options</span>
    <span class="s2">#          and additional results (OLS on polynomial of x (x is 1d?))</span>


    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">order</span><span class="s3">, </span><span class="s1">x=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">#order = 4 # set this because we get knots instead of order</span>
        <span class="s1">self.order = order</span>

        <span class="s2">#print order, x.shape</span>
        <span class="s1">self.coef = np.zeros((order+</span><span class="s4">1</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">np.float64)</span>
        <span class="s3">if </span><span class="s1">x </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">x.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">print(</span><span class="s5">'Warning: 2d x detected in PolySmoother init, shape:'</span><span class="s3">, </span><span class="s1">x.shape)</span>
                <span class="s1">x=x[</span><span class="s4">0</span><span class="s3">,</span><span class="s1">:] </span><span class="s2">#check orientation</span>
            <span class="s1">self.X = np.array([x**i </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(order+</span><span class="s4">1</span><span class="s1">)]).T</span>

    <span class="s3">def </span><span class="s1">df_fit(self):</span>
        <span class="s0">'''alias of df_model for backwards compatibility 
        '''</span>
        <span class="s3">return </span><span class="s1">self.df_model()</span>

    <span class="s3">def </span><span class="s1">df_model(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Degrees of freedom used in the fit. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.order + </span><span class="s4">1</span>

    <span class="s3">def </span><span class="s1">gram(self</span><span class="s3">, </span><span class="s1">d=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">#fake for spline imitation</span>
        <span class="s3">pass</span>

    <span class="s3">def </span><span class="s1">smooth(self</span><span class="s3">,</span><span class="s1">*args</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s0">'''alias for fit,  for backwards compatibility, 
 
        do we need it with different behavior than fit? 
 
        '''</span>
        <span class="s3">return </span><span class="s1">self.fit(*args</span><span class="s3">, </span><span class="s1">**kwds)</span>

    <span class="s3">def </span><span class="s1">df_resid(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Residual degrees of freedom from last fit. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.N - self.order - </span><span class="s4">1</span>

    <span class="s3">def </span><span class="s1">__call__(self</span><span class="s3">, </span><span class="s1">x=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s3">return </span><span class="s1">self.predict(x=x)</span>


    <span class="s3">def </span><span class="s1">predict(self</span><span class="s3">, </span><span class="s1">x=</span><span class="s3">None</span><span class="s1">):</span>

        <span class="s3">if </span><span class="s1">x </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s2">#if x.ndim &gt; 1: x=x[0,:]  #why this this should select column not row</span>
            <span class="s3">if </span><span class="s1">x.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">print(</span><span class="s5">'Warning: 2d x detected in PolySmoother predict, shape:'</span><span class="s3">, </span><span class="s1">x.shape)</span>
                <span class="s1">x=x[:</span><span class="s3">,</span><span class="s4">0</span><span class="s1">]  </span><span class="s2">#TODO: check and clean this up</span>
            <span class="s1">X = np.array([(x**i) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.order+</span><span class="s4">1</span><span class="s1">)])</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">X = self.X</span>
        <span class="s2">#return np.squeeze(np.dot(X.T, self.coef))</span>
        <span class="s2">#need to check what dimension this is supposed to be</span>
        <span class="s3">if </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">] == self.coef.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s3">return </span><span class="s1">np.squeeze(np.dot(X</span><span class="s3">, </span><span class="s1">self.coef))</span><span class="s2">#[0]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">np.squeeze(np.dot(X.T</span><span class="s3">, </span><span class="s1">self.coef))</span><span class="s2">#[0]</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">x=</span><span class="s3">None, </span><span class="s1">weights=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.N = y.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">y.ndim == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">y = y[:</span><span class="s3">,None</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">weights </span><span class="s3">is None or </span><span class="s1">np.isnan(weights).all():</span>
            <span class="s1">weights = </span><span class="s4">1</span>
            <span class="s1">_w = </span><span class="s4">1</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">_w = np.sqrt(weights)[:</span><span class="s3">,None</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">x </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">if not </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s5">&quot;X&quot;</span><span class="s1">):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;x needed to fit PolySmoother&quot;</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">x.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">print(</span><span class="s5">'Warning: 2d x detected in PolySmoother predict, shape:'</span><span class="s3">, </span><span class="s1">x.shape)</span>
                <span class="s2">#x=x[0,:] #TODO: check orientation, row or col</span>
            <span class="s1">self.X = np.array([(x**i) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.order+</span><span class="s4">1</span><span class="s1">)]).T</span>
        <span class="s2">#print _w.shape</span>

        <span class="s1">X = self.X * _w</span>

        <span class="s1">_y = y * _w</span><span class="s2">#[:,None]</span>
        <span class="s2">#self.coef = np.dot(L.pinv(X).T, _y[:,None])</span>
        <span class="s2">#self.coef = np.dot(L.pinv(X), _y)</span>
        <span class="s1">self.coef = np.linalg.lstsq(X</span><span class="s3">, </span><span class="s1">_y</span><span class="s3">, </span><span class="s1">rcond=-</span><span class="s4">1</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">self.params = np.squeeze(self.coef)</span>




















<span class="s2"># comment out for now to remove dependency on _hbspline</span>

<span class="s2">##class SmoothingSpline(BSpline):</span>
<span class="s2">##</span>
<span class="s2">##    penmax = 30.</span>
<span class="s2">##</span>
<span class="s2">##    def fit(self, y, x=None, weights=None, pen=0.):</span>
<span class="s2">##        banded = True</span>
<span class="s2">##</span>
<span class="s2">##        if x is None:</span>
<span class="s2">##            x = self.tau[(self.M-1):-(self.M-1)] # internal knots</span>
<span class="s2">##</span>
<span class="s2">##        if pen == 0.: # cannot use cholesky for singular matrices</span>
<span class="s2">##            banded = False</span>
<span class="s2">##</span>
<span class="s2">##        if x.shape != y.shape:</span>
<span class="s2">##            raise ValueError('x and y shape do not agree, by default x are the Bspline\'s internal knots')</span>
<span class="s2">##</span>
<span class="s2">##        bt = self.basis(x)</span>
<span class="s2">##        if pen &gt;= self.penmax:</span>
<span class="s2">##            pen = self.penmax</span>
<span class="s2">##</span>
<span class="s2">##        if weights is None:</span>
<span class="s2">##            weights = np.array(1.)</span>
<span class="s2">##</span>
<span class="s2">##        wmean = weights.mean()</span>
<span class="s2">##        _w = np.sqrt(weights / wmean)</span>
<span class="s2">##        bt *= _w</span>
<span class="s2">##</span>
<span class="s2">##        # throw out rows with zeros (this happens at boundary points!)</span>
<span class="s2">##</span>
<span class="s2">##        mask = np.flatnonzero(1 - np.alltrue(np.equal(bt, 0), axis=0))</span>
<span class="s2">##</span>
<span class="s2">##        bt = bt[:, mask]</span>
<span class="s2">##        y = y[mask]</span>
<span class="s2">##</span>
<span class="s2">##        self.df_total = y.shape[0]</span>
<span class="s2">##</span>
<span class="s2">##        if bt.shape[1] != y.shape[0]:</span>
<span class="s2">##            raise ValueError(&quot;some x values are outside range of B-spline knots&quot;)</span>
<span class="s2">##        bty = np.dot(bt, _w * y)</span>
<span class="s2">##        self.N = y.shape[0]</span>
<span class="s2">##        if not banded:</span>
<span class="s2">##            self.btb = np.dot(bt, bt.T)</span>
<span class="s2">##            _g = _band2array(self.g, lower=1, symmetric=True)</span>
<span class="s2">##            self.coef, _, self.rank = L.lstsq(self.btb + pen*_g, bty)[0:3]</span>
<span class="s2">##            self.rank = min(self.rank, self.btb.shape[0])</span>
<span class="s2">##        else:</span>
<span class="s2">##            self.btb = np.zeros(self.g.shape, np.float64)</span>
<span class="s2">##            nband, nbasis = self.g.shape</span>
<span class="s2">##            for i in range(nbasis):</span>
<span class="s2">##                for k in range(min(nband, nbasis-i)):</span>
<span class="s2">##                    self.btb[k, i] = (bt[i] * bt[i+k]).sum()</span>
<span class="s2">##</span>
<span class="s2">##            bty.shape = (1, bty.shape[0])</span>
<span class="s2">##            self.chol, self.coef = solveh_banded(self.btb +</span>
<span class="s2">##                                                 pen*self.g,</span>
<span class="s2">##                                                 bty, lower=1)</span>
<span class="s2">##</span>
<span class="s2">##        self.coef = np.squeeze(self.coef)</span>
<span class="s2">##        self.resid = np.sqrt(wmean) * (y * _w - np.dot(self.coef, bt))</span>
<span class="s2">##        self.pen = pen</span>
<span class="s2">##</span>
<span class="s2">##    def gcv(self):</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##        Generalized cross-validation score of current fit.</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##        norm_resid = (self.resid**2).sum()</span>
<span class="s2">##        return norm_resid / (self.df_total - self.trace())</span>
<span class="s2">##</span>
<span class="s2">##    def df_resid(self):</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##        self.N - self.trace()</span>
<span class="s2">##</span>
<span class="s2">##        where self.N is the number of observations of last fit.</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##        return self.N - self.trace()</span>
<span class="s2">##</span>
<span class="s2">##    def df_fit(self):</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##        = self.trace()</span>
<span class="s2">##</span>
<span class="s2">##        How many degrees of freedom used in the fit?</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##        return self.trace()</span>
<span class="s2">##</span>
<span class="s2">##    def trace(self):</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##        Trace of the smoothing matrix S(pen)</span>
<span class="s2">##        &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##        if self.pen &gt; 0:</span>
<span class="s2">##            _invband = _hbspline.invband(self.chol.copy())</span>
<span class="s2">##            tr = _trace_symbanded(_invband, self.btb, lower=1)</span>
<span class="s2">##            return tr</span>
<span class="s2">##        else:</span>
<span class="s2">##            return self.rank</span>
<span class="s2">##</span>
<span class="s2">##class SmoothingSplineFixedDF(SmoothingSpline):</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##    Fit smoothing spline with approximately df degrees of freedom</span>
<span class="s2">##    used in the fit, i.e. so that self.trace() is approximately df.</span>
<span class="s2">##</span>
<span class="s2">##    In general, df must be greater than the dimension of the null space</span>
<span class="s2">##    of the Gram inner product. For cubic smoothing splines, this means</span>
<span class="s2">##    that df &gt; 2.</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##    target_df = 5</span>
<span class="s2">##</span>
<span class="s2">##    def __init__(self, knots, order=4, coef=None, M=None, target_df=None):</span>
<span class="s2">##        if target_df is not None:</span>
<span class="s2">##            self.target_df = target_df</span>
<span class="s2">##        BSpline.__init__(self, knots, order=order, coef=coef, M=M)</span>
<span class="s2">##        self.target_reached = False</span>
<span class="s2">##</span>
<span class="s2">##    def fit(self, y, x=None, df=None, weights=None, tol=1.0e-03):</span>
<span class="s2">##</span>
<span class="s2">##        df = df or self.target_df</span>
<span class="s2">##</span>
<span class="s2">##        apen, bpen = 0, 1.0e-03</span>
<span class="s2">##        olddf = y.shape[0] - self.m</span>
<span class="s2">##</span>
<span class="s2">##        if not self.target_reached:</span>
<span class="s2">##            while True:</span>
<span class="s2">##                curpen = 0.5 * (apen + bpen)</span>
<span class="s2">##                SmoothingSpline.fit(self, y, x=x, weights=weights, pen=curpen)</span>
<span class="s2">##                curdf = self.trace()</span>
<span class="s2">##                if curdf &gt; df:</span>
<span class="s2">##                    apen, bpen = curpen, 2 * curpen</span>
<span class="s2">##                else:</span>
<span class="s2">##                    apen, bpen = apen, curpen</span>
<span class="s2">##                    if apen &gt;= self.penmax:</span>
<span class="s2">##                        raise ValueError(&quot;penalty too large, try setting penmax higher or decreasing df&quot;)</span>
<span class="s2">##                if np.fabs(curdf - df) / df &lt; tol:</span>
<span class="s2">##                    self.target_reached = True</span>
<span class="s2">##                    break</span>
<span class="s2">##        else:</span>
<span class="s2">##            SmoothingSpline.fit(self, y, x=x, weights=weights, pen=self.pen)</span>
<span class="s2">##</span>
<span class="s2">##class SmoothingSplineGCV(SmoothingSpline):</span>
<span class="s2">##</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##    Fit smoothing spline trying to optimize GCV.</span>
<span class="s2">##</span>
<span class="s2">##    Try to find a bracketing interval for scipy.optimize.golden</span>
<span class="s2">##    based on bracket.</span>
<span class="s2">##</span>
<span class="s2">##    It is probably best to use target_df instead, as it is</span>
<span class="s2">##    sometimes difficult to find a bracketing interval.</span>
<span class="s2">##</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##    def fit(self, y, x=None, weights=None, tol=1.0e-03,</span>
<span class="s2">##            bracket=(0,1.0e-03)):</span>
<span class="s2">##</span>
<span class="s2">##        def _gcv(pen, y, x):</span>
<span class="s2">##            SmoothingSpline.fit(y, x=x, pen=np.exp(pen), weights=weights)</span>
<span class="s2">##            a = self.gcv()</span>
<span class="s2">##            return a</span>
<span class="s2">##</span>
<span class="s2">##        a = golden(_gcv, args=(y,x), brack=(-100,20), tol=tol)</span>
<span class="s2">##</span>
<span class="s2">##def _trace_symbanded(a,b, lower=0):</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##    Compute the trace(a*b) for two upper or lower banded real symmetric matrices.</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##    if lower:</span>
<span class="s2">##        t = _zero_triband(a * b, lower=1)</span>
<span class="s2">##        return t[0].sum() + 2 * t[1:].sum()</span>
<span class="s2">##    else:</span>
<span class="s2">##        t = _zero_triband(a * b, lower=0)</span>
<span class="s2">##        return t[-1].sum() + 2 * t[:-1].sum()</span>
<span class="s2">##</span>
<span class="s2">##</span>
<span class="s2">##</span>
<span class="s2">##def _zero_triband(a, lower=0):</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##    Zero out unnecessary elements of a real symmetric banded matrix.</span>
<span class="s2">##    &quot;&quot;&quot;</span>
<span class="s2">##</span>
<span class="s2">##    nrow, ncol = a.shape</span>
<span class="s2">##    if lower:</span>
<span class="s2">##        for i in range(nrow): a[i,(ncol-i):] = 0.</span>
<span class="s2">##    else:</span>
<span class="s2">##        for i in range(nrow): a[i,0:i] = 0.</span>
<span class="s2">##    return a</span>
</pre>
</body>
</html>
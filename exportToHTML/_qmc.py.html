<html>
<head>
<title>_qmc.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_qmc.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Quasi-Monte Carlo engines and helpers.&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">import </span><span class="s1">copy</span>
<span class="s2">import </span><span class="s1">math</span>
<span class="s2">import </span><span class="s1">numbers</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">warnings</span>
<span class="s2">from </span><span class="s1">abc </span><span class="s2">import </span><span class="s1">ABC</span><span class="s2">, </span><span class="s1">abstractmethod</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Callable</span><span class="s2">,</span>
    <span class="s1">ClassVar</span><span class="s2">,</span>
    <span class="s1">Literal</span><span class="s2">,</span>
    <span class="s1">overload</span><span class="s2">,</span>
    <span class="s1">TYPE_CHECKING</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">if </span><span class="s1">TYPE_CHECKING:</span>
    <span class="s2">import </span><span class="s1">numpy.typing </span><span class="s2">as </span><span class="s1">npt</span>
    <span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">DecimalNumber</span><span class="s2">, </span><span class="s1">GeneratorType</span><span class="s2">, </span><span class="s1">IntNumber</span><span class="s2">, </span><span class="s1">SeedType</span>
    <span class="s1">)</span>

<span class="s2">import </span><span class="s1">scipy.stats </span><span class="s2">as </span><span class="s1">stats</span>
<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">rng_integers</span><span class="s2">, </span><span class="s1">_rng_spawn</span>
<span class="s2">from </span><span class="s1">scipy.spatial </span><span class="s2">import </span><span class="s1">distance</span><span class="s2">, </span><span class="s1">Voronoi</span>
<span class="s2">from </span><span class="s1">scipy.special </span><span class="s2">import </span><span class="s1">gammainc</span>
<span class="s2">from </span><span class="s1">._sobol </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_initialize_v</span><span class="s2">, </span><span class="s1">_cscramble</span><span class="s2">, </span><span class="s1">_fill_p_cumulative</span><span class="s2">, </span><span class="s1">_draw</span><span class="s2">, </span><span class="s1">_fast_forward</span><span class="s2">,</span>
    <span class="s1">_categorize</span><span class="s2">, </span><span class="s1">_MAXDIM</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">._qmc_cy </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_cy_wrapper_centered_discrepancy</span><span class="s2">,</span>
    <span class="s1">_cy_wrapper_wrap_around_discrepancy</span><span class="s2">,</span>
    <span class="s1">_cy_wrapper_mixture_discrepancy</span><span class="s2">,</span>
    <span class="s1">_cy_wrapper_l2_star_discrepancy</span><span class="s2">,</span>
    <span class="s1">_cy_wrapper_update_discrepancy</span><span class="s2">,</span>
    <span class="s1">_cy_van_der_corput_scrambled</span><span class="s2">,</span>
    <span class="s1">_cy_van_der_corput</span><span class="s2">,</span>
<span class="s1">)</span>


<span class="s1">__all__ = [</span><span class="s3">'scale'</span><span class="s2">, </span><span class="s3">'discrepancy'</span><span class="s2">, </span><span class="s3">'update_discrepancy'</span><span class="s2">,</span>
           <span class="s3">'QMCEngine'</span><span class="s2">, </span><span class="s3">'Sobol'</span><span class="s2">, </span><span class="s3">'Halton'</span><span class="s2">, </span><span class="s3">'LatinHypercube'</span><span class="s2">, </span><span class="s3">'PoissonDisk'</span><span class="s2">,</span>
           <span class="s3">'MultinomialQMC'</span><span class="s2">, </span><span class="s3">'MultivariateNormalQMC'</span><span class="s1">]</span>


<span class="s1">@overload</span>
<span class="s2">def </span><span class="s1">check_random_state(seed: IntNumber | </span><span class="s2">None </span><span class="s1">= ...) -&gt; np.random.Generator:</span>
    <span class="s1">...</span>


<span class="s1">@overload</span>
<span class="s2">def </span><span class="s1">check_random_state(seed: GeneratorType) -&gt; GeneratorType:</span>
    <span class="s1">...</span>


<span class="s4"># Based on scipy._lib._util.check_random_state</span>
<span class="s2">def </span><span class="s1">check_random_state(seed=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Turn `seed` into a `numpy.random.Generator` instance. 
 
    Parameters 
    ---------- 
    seed : {None, int, `numpy.random.Generator`, `numpy.random.RandomState`}, optional  # noqa 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` or ``RandomState`` instance, then 
        the provided instance is used. 
 
    Returns 
    ------- 
    seed : {`numpy.random.Generator`, `numpy.random.RandomState`} 
        Random number generator. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">seed </span><span class="s2">is None or </span><span class="s1">isinstance(seed</span><span class="s2">, </span><span class="s1">(numbers.Integral</span><span class="s2">, </span><span class="s1">np.integer)):</span>
        <span class="s2">return </span><span class="s1">np.random.default_rng(seed)</span>
    <span class="s2">elif </span><span class="s1">isinstance(seed</span><span class="s2">, </span><span class="s1">(np.random.RandomState</span><span class="s2">, </span><span class="s1">np.random.Generator)):</span>
        <span class="s2">return </span><span class="s1">seed</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">seed</span><span class="s2">!r} </span><span class="s3">cannot be used to seed a'</span>
                         <span class="s3">' numpy.random.Generator instance'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">scale(</span>
    <span class="s1">sample: npt.ArrayLike</span><span class="s2">,</span>
    <span class="s1">l_bounds: npt.ArrayLike</span><span class="s2">,</span>
    <span class="s1">u_bounds: npt.ArrayLike</span><span class="s2">,</span>
    <span class="s1">*</span><span class="s2">,</span>
    <span class="s1">reverse: bool = </span><span class="s2">False</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">r&quot;&quot;&quot;Sample scaling from unit hypercube to different bounds. 
 
    To convert a sample from :math:`[0, 1)` to :math:`[a, b), b&gt;a`, 
    with :math:`a` the lower bounds and :math:`b` the upper bounds. 
    The following transformation is used: 
 
    .. math:: 
 
        (b - a) \cdot \text{sample} + a 
 
    Parameters 
    ---------- 
    sample : array_like (n, d) 
        Sample to scale. 
    l_bounds, u_bounds : array_like (d,) 
        Lower and upper bounds (resp. :math:`a`, :math:`b`) of transformed 
        data. If `reverse` is True, range of the original data to transform 
        to the unit hypercube. 
    reverse : bool, optional 
        Reverse the transformation from different bounds to the unit hypercube. 
        Default is False. 
 
    Returns 
    ------- 
    sample : array_like (n, d) 
        Scaled sample. 
 
    Examples 
    -------- 
    Transform 3 samples in the unit hypercube to bounds: 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; l_bounds = [-2, 0] 
    &gt;&gt;&gt; u_bounds = [6, 5] 
    &gt;&gt;&gt; sample = [[0.5 , 0.75], 
    ...           [0.5 , 0.5], 
    ...           [0.75, 0.25]] 
    &gt;&gt;&gt; sample_scaled = qmc.scale(sample, l_bounds, u_bounds) 
    &gt;&gt;&gt; sample_scaled 
    array([[2.  , 3.75], 
           [2.  , 2.5 ], 
           [4.  , 1.25]]) 
 
    And convert back to the unit hypercube: 
 
    &gt;&gt;&gt; sample_ = qmc.scale(sample_scaled, l_bounds, u_bounds, reverse=True) 
    &gt;&gt;&gt; sample_ 
    array([[0.5 , 0.75], 
           [0.5 , 0.5 ], 
           [0.75, 0.25]]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">sample = np.asarray(sample)</span>

    <span class="s4"># Checking bounds and sample</span>
    <span class="s2">if not </span><span class="s1">sample.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Sample is not a 2D array'</span><span class="s1">)</span>

    <span class="s1">lower</span><span class="s2">, </span><span class="s1">upper = _validate_bounds(</span>
        <span class="s1">l_bounds=l_bounds</span><span class="s2">, </span><span class="s1">u_bounds=u_bounds</span><span class="s2">, </span><span class="s1">d=sample.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">reverse:</span>
        <span class="s4"># Checking that sample is within the hypercube</span>
        <span class="s2">if </span><span class="s1">(sample.max() &gt; </span><span class="s5">1.</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(sample.min() &lt; </span><span class="s5">0.</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Sample is not in unit hypercube'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">sample * (upper - lower) + lower</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s4"># Checking that sample is within the bounds</span>
        <span class="s2">if not </span><span class="s1">(np.all(sample &gt;= lower) </span><span class="s2">and </span><span class="s1">np.all(sample &lt;= upper)):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Sample is out of bounds'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">(sample - lower) / (upper - lower)</span>


<span class="s2">def </span><span class="s1">discrepancy(</span>
        <span class="s1">sample: npt.ArrayLike</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">iterative: bool = </span><span class="s2">False,</span>
        <span class="s1">method: Literal[</span><span class="s3">&quot;CD&quot;</span><span class="s2">, </span><span class="s3">&quot;WD&quot;</span><span class="s2">, </span><span class="s3">&quot;MD&quot;</span><span class="s2">, </span><span class="s3">&quot;L2-star&quot;</span><span class="s1">] = </span><span class="s3">&quot;CD&quot;</span><span class="s2">,</span>
        <span class="s1">workers: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; float:</span>
    <span class="s0">&quot;&quot;&quot;Discrepancy of a given sample. 
 
    Parameters 
    ---------- 
    sample : array_like (n, d) 
        The sample to compute the discrepancy from. 
    iterative : bool, optional 
        Must be False if not using it for updating the discrepancy. 
        Default is False. Refer to the notes for more details. 
    method : str, optional 
        Type of discrepancy, can be ``CD``, ``WD``, ``MD`` or ``L2-star``. 
        Refer to the notes for more details. Default is ``CD``. 
    workers : int, optional 
        Number of workers to use for parallel processing. If -1 is given all 
        CPU threads are used. Default is 1. 
 
    Returns 
    ------- 
    discrepancy : float 
        Discrepancy. 
 
    Notes 
    ----- 
    The discrepancy is a uniformity criterion used to assess the space filling 
    of a number of samples in a hypercube. A discrepancy quantifies the 
    distance between the continuous uniform distribution on a hypercube and the 
    discrete uniform distribution on :math:`n` distinct sample points. 
 
    The lower the value is, the better the coverage of the parameter space is. 
 
    For a collection of subsets of the hypercube, the discrepancy is the 
    difference between the fraction of sample points in one of those 
    subsets and the volume of that subset. There are different definitions of 
    discrepancy corresponding to different collections of subsets. Some 
    versions take a root mean square difference over subsets instead of 
    a maximum. 
 
    A measure of uniformity is reasonable if it satisfies the following 
    criteria [1]_: 
 
    1. It is invariant under permuting factors and/or runs. 
    2. It is invariant under rotation of the coordinates. 
    3. It can measure not only uniformity of the sample over the hypercube, 
       but also the projection uniformity of the sample over non-empty 
       subset of lower dimension hypercubes. 
    4. There is some reasonable geometric meaning. 
    5. It is easy to compute. 
    6. It satisfies the Koksma-Hlawka-like inequality. 
    7. It is consistent with other criteria in experimental design. 
 
    Four methods are available: 
 
    * ``CD``: Centered Discrepancy - subspace involves a corner of the 
      hypercube 
    * ``WD``: Wrap-around Discrepancy - subspace can wrap around bounds 
    * ``MD``: Mixture Discrepancy - mix between CD/WD covering more criteria 
    * ``L2-star``: L2-star discrepancy - like CD BUT variant to rotation 
 
    See [2]_ for precise definitions of each method. 
 
    Lastly, using ``iterative=True``, it is possible to compute the 
    discrepancy as if we had :math:`n+1` samples. This is useful if we want 
    to add a point to a sampling and check the candidate which would give the 
    lowest discrepancy. Then you could just update the discrepancy with 
    each candidate using `update_discrepancy`. This method is faster than 
    computing the discrepancy for a large number of candidates. 
 
    References 
    ---------- 
    .. [1] Fang et al. &quot;Design and modeling for computer experiments&quot;. 
       Computer Science and Data Analysis Series, 2006. 
    .. [2] Zhou Y.-D. et al. &quot;Mixture discrepancy for quasi-random point sets.&quot; 
       Journal of Complexity, 29 (3-4) , pp. 283-301, 2013. 
    .. [3] T. T. Warnock. &quot;Computational investigations of low discrepancy 
       point sets.&quot; Applications of Number Theory to Numerical 
       Analysis, Academic Press, pp. 319-343, 1972. 
 
    Examples 
    -------- 
    Calculate the quality of the sample using the discrepancy: 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; space = np.array([[1, 3], [2, 6], [3, 2], [4, 5], [5, 1], [6, 4]]) 
    &gt;&gt;&gt; l_bounds = [0.5, 0.5] 
    &gt;&gt;&gt; u_bounds = [6.5, 6.5] 
    &gt;&gt;&gt; space = qmc.scale(space, l_bounds, u_bounds, reverse=True) 
    &gt;&gt;&gt; space 
    array([[0.08333333, 0.41666667], 
           [0.25      , 0.91666667], 
           [0.41666667, 0.25      ], 
           [0.58333333, 0.75      ], 
           [0.75      , 0.08333333], 
           [0.91666667, 0.58333333]]) 
    &gt;&gt;&gt; qmc.discrepancy(space) 
    0.008142039609053464 
 
    We can also compute iteratively the ``CD`` discrepancy by using 
    ``iterative=True``. 
 
    &gt;&gt;&gt; disc_init = qmc.discrepancy(space[:-1], iterative=True) 
    &gt;&gt;&gt; disc_init 
    0.04769081147119336 
    &gt;&gt;&gt; qmc.update_discrepancy(space[-1], space[:-1], disc_init) 
    0.008142039609053513 
 
    &quot;&quot;&quot;</span>
    <span class="s1">sample = np.asarray(sample</span><span class="s2">, </span><span class="s1">dtype=np.float64</span><span class="s2">, </span><span class="s1">order=</span><span class="s3">&quot;C&quot;</span><span class="s1">)</span>

    <span class="s4"># Checking that sample is within the hypercube and 2D</span>
    <span class="s2">if not </span><span class="s1">sample.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Sample is not a 2D array&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">(sample.max() &gt; </span><span class="s5">1.</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(sample.min() &lt; </span><span class="s5">0.</span><span class="s1">):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Sample is not in unit hypercube&quot;</span><span class="s1">)</span>

    <span class="s1">workers = _validate_workers(workers)</span>

    <span class="s1">methods = {</span>
        <span class="s3">&quot;CD&quot;</span><span class="s1">: _cy_wrapper_centered_discrepancy</span><span class="s2">,</span>
        <span class="s3">&quot;WD&quot;</span><span class="s1">: _cy_wrapper_wrap_around_discrepancy</span><span class="s2">,</span>
        <span class="s3">&quot;MD&quot;</span><span class="s1">: _cy_wrapper_mixture_discrepancy</span><span class="s2">,</span>
        <span class="s3">&quot;L2-star&quot;</span><span class="s1">: _cy_wrapper_l2_star_discrepancy</span><span class="s2">,</span>
    <span class="s1">}</span>

    <span class="s2">if </span><span class="s1">method </span><span class="s2">in </span><span class="s1">methods:</span>
        <span class="s2">return </span><span class="s1">methods[method](sample</span><span class="s2">, </span><span class="s1">iterative</span><span class="s2">, </span><span class="s1">workers=workers)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">method</span><span class="s2">!r} </span><span class="s3">is not a valid method. It must be one of&quot;</span>
                         <span class="s3">f&quot; </span><span class="s2">{</span><span class="s1">set(methods)</span><span class="s2">!r}</span><span class="s3">&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">update_discrepancy(</span>
        <span class="s1">x_new: npt.ArrayLike</span><span class="s2">,</span>
        <span class="s1">sample: npt.ArrayLike</span><span class="s2">,</span>
        <span class="s1">initial_disc: DecimalNumber) -&gt; float:</span>
    <span class="s0">&quot;&quot;&quot;Update the centered discrepancy with a new sample. 
 
    Parameters 
    ---------- 
    x_new : array_like (1, d) 
        The new sample to add in `sample`. 
    sample : array_like (n, d) 
        The initial sample. 
    initial_disc : float 
        Centered discrepancy of the `sample`. 
 
    Returns 
    ------- 
    discrepancy : float 
        Centered discrepancy of the sample composed of `x_new` and `sample`. 
 
    Examples 
    -------- 
    We can also compute iteratively the discrepancy by using 
    ``iterative=True``. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; space = np.array([[1, 3], [2, 6], [3, 2], [4, 5], [5, 1], [6, 4]]) 
    &gt;&gt;&gt; l_bounds = [0.5, 0.5] 
    &gt;&gt;&gt; u_bounds = [6.5, 6.5] 
    &gt;&gt;&gt; space = qmc.scale(space, l_bounds, u_bounds, reverse=True) 
    &gt;&gt;&gt; disc_init = qmc.discrepancy(space[:-1], iterative=True) 
    &gt;&gt;&gt; disc_init 
    0.04769081147119336 
    &gt;&gt;&gt; qmc.update_discrepancy(space[-1], space[:-1], disc_init) 
    0.008142039609053513 
 
    &quot;&quot;&quot;</span>
    <span class="s1">sample = np.asarray(sample</span><span class="s2">, </span><span class="s1">dtype=np.float64</span><span class="s2">, </span><span class="s1">order=</span><span class="s3">&quot;C&quot;</span><span class="s1">)</span>
    <span class="s1">x_new = np.asarray(x_new</span><span class="s2">, </span><span class="s1">dtype=np.float64</span><span class="s2">, </span><span class="s1">order=</span><span class="s3">&quot;C&quot;</span><span class="s1">)</span>

    <span class="s4"># Checking that sample is within the hypercube and 2D</span>
    <span class="s2">if not </span><span class="s1">sample.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Sample is not a 2D array'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">(sample.max() &gt; </span><span class="s5">1.</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(sample.min() &lt; </span><span class="s5">0.</span><span class="s1">):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Sample is not in unit hypercube'</span><span class="s1">)</span>

    <span class="s4"># Checking that x_new is within the hypercube and 1D</span>
    <span class="s2">if not </span><span class="s1">x_new.ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'x_new is not a 1D array'</span><span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">(np.all(x_new &gt;= </span><span class="s5">0</span><span class="s1">) </span><span class="s2">and </span><span class="s1">np.all(x_new &lt;= </span><span class="s5">1</span><span class="s1">)):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'x_new is not in unit hypercube'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">x_new.shape[</span><span class="s5">0</span><span class="s1">] != sample.shape[</span><span class="s5">1</span><span class="s1">]:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;x_new and sample must be broadcastable&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">_cy_wrapper_update_discrepancy(x_new</span><span class="s2">, </span><span class="s1">sample</span><span class="s2">, </span><span class="s1">initial_disc)</span>


<span class="s2">def </span><span class="s1">_perturb_discrepancy(sample: np.ndarray</span><span class="s2">, </span><span class="s1">i1: int</span><span class="s2">, </span><span class="s1">i2: int</span><span class="s2">, </span><span class="s1">k: int</span><span class="s2">,</span>
                         <span class="s1">disc: float):</span>
    <span class="s0">&quot;&quot;&quot;Centered discrepancy after an elementary perturbation of a LHS. 
 
    An elementary perturbation consists of an exchange of coordinates between 
    two points: ``sample[i1, k] &lt;-&gt; sample[i2, k]``. By construction, 
    this operation conserves the LHS properties. 
 
    Parameters 
    ---------- 
    sample : array_like (n, d) 
        The sample (before permutation) to compute the discrepancy from. 
    i1 : int 
        The first line of the elementary permutation. 
    i2 : int 
        The second line of the elementary permutation. 
    k : int 
        The column of the elementary permutation. 
    disc : float 
        Centered discrepancy of the design before permutation. 
 
    Returns 
    ------- 
    discrepancy : float 
        Centered discrepancy of the design after permutation. 
 
    References 
    ---------- 
    .. [1] Jin et al. &quot;An efficient algorithm for constructing optimal design 
       of computer experiments&quot;, Journal of Statistical Planning and 
       Inference, 2005. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">n = sample.shape[</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s1">z_ij = sample - </span><span class="s5">0.5</span>

    <span class="s4"># Eq (19)</span>
    <span class="s1">c_i1j = (</span><span class="s5">1. </span><span class="s1">/ n ** </span><span class="s5">2.</span>
             <span class="s1">* np.prod(</span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">2. </span><span class="s1">+ abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:])</span>
                              <span class="s1">+ abs(z_ij) - abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:] - z_ij))</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">c_i2j = (</span><span class="s5">1. </span><span class="s1">/ n ** </span><span class="s5">2.</span>
             <span class="s1">* np.prod(</span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">2. </span><span class="s1">+ abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:])</span>
                              <span class="s1">+ abs(z_ij) - abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:] - z_ij))</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">))</span>

    <span class="s4"># Eq (20)</span>
    <span class="s1">c_i1i1 = (</span><span class="s5">1. </span><span class="s1">/ n ** </span><span class="s5">2 </span><span class="s1">* np.prod(</span><span class="s5">1 </span><span class="s1">+ abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:]))</span>
              <span class="s1">- </span><span class="s5">2. </span><span class="s1">/ n * np.prod(</span><span class="s5">1. </span><span class="s1">+ </span><span class="s5">0.5 </span><span class="s1">* abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:])</span>
                                 <span class="s1">- </span><span class="s5">0.5 </span><span class="s1">* z_ij[i1</span><span class="s2">, </span><span class="s1">:] ** </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">c_i2i2 = (</span><span class="s5">1. </span><span class="s1">/ n ** </span><span class="s5">2 </span><span class="s1">* np.prod(</span><span class="s5">1 </span><span class="s1">+ abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:]))</span>
              <span class="s1">- </span><span class="s5">2. </span><span class="s1">/ n * np.prod(</span><span class="s5">1. </span><span class="s1">+ </span><span class="s5">0.5 </span><span class="s1">* abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:])</span>
                                 <span class="s1">- </span><span class="s5">0.5 </span><span class="s1">* z_ij[i2</span><span class="s2">, </span><span class="s1">:] ** </span><span class="s5">2</span><span class="s1">))</span>

    <span class="s4"># Eq (22), typo in the article in the denominator i2 -&gt; i1</span>
    <span class="s1">num = (</span><span class="s5">2 </span><span class="s1">+ abs(z_ij[i2</span><span class="s2">, </span><span class="s1">k]) + abs(z_ij[:</span><span class="s2">, </span><span class="s1">k])</span>
           <span class="s1">- abs(z_ij[i2</span><span class="s2">, </span><span class="s1">k] - z_ij[:</span><span class="s2">, </span><span class="s1">k]))</span>
    <span class="s1">denum = (</span><span class="s5">2 </span><span class="s1">+ abs(z_ij[i1</span><span class="s2">, </span><span class="s1">k]) + abs(z_ij[:</span><span class="s2">, </span><span class="s1">k])</span>
             <span class="s1">- abs(z_ij[i1</span><span class="s2">, </span><span class="s1">k] - z_ij[:</span><span class="s2">, </span><span class="s1">k]))</span>
    <span class="s1">gamma = num / denum</span>

    <span class="s4"># Eq (23)</span>
    <span class="s1">c_p_i1j = gamma * c_i1j</span>
    <span class="s4"># Eq (24)</span>
    <span class="s1">c_p_i2j = c_i2j / gamma</span>

    <span class="s1">alpha = (</span><span class="s5">1 </span><span class="s1">+ abs(z_ij[i2</span><span class="s2">, </span><span class="s1">k])) / (</span><span class="s5">1 </span><span class="s1">+ abs(z_ij[i1</span><span class="s2">, </span><span class="s1">k]))</span>
    <span class="s1">beta = (</span><span class="s5">2 </span><span class="s1">- abs(z_ij[i2</span><span class="s2">, </span><span class="s1">k])) / (</span><span class="s5">2 </span><span class="s1">- abs(z_ij[i1</span><span class="s2">, </span><span class="s1">k]))</span>

    <span class="s1">g_i1 = np.prod(</span><span class="s5">1. </span><span class="s1">+ abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:]))</span>
    <span class="s1">g_i2 = np.prod(</span><span class="s5">1. </span><span class="s1">+ abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:]))</span>
    <span class="s1">h_i1 = np.prod(</span><span class="s5">1. </span><span class="s1">+ </span><span class="s5">0.5 </span><span class="s1">* abs(z_ij[i1</span><span class="s2">, </span><span class="s1">:]) - </span><span class="s5">0.5 </span><span class="s1">* (z_ij[i1</span><span class="s2">, </span><span class="s1">:] ** </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">h_i2 = np.prod(</span><span class="s5">1. </span><span class="s1">+ </span><span class="s5">0.5 </span><span class="s1">* abs(z_ij[i2</span><span class="s2">, </span><span class="s1">:]) - </span><span class="s5">0.5 </span><span class="s1">* (z_ij[i2</span><span class="s2">, </span><span class="s1">:] ** </span><span class="s5">2</span><span class="s1">))</span>

    <span class="s4"># Eq (25), typo in the article g is missing</span>
    <span class="s1">c_p_i1i1 = ((g_i1 * alpha) / (n ** </span><span class="s5">2</span><span class="s1">) - </span><span class="s5">2. </span><span class="s1">* alpha * beta * h_i1 / n)</span>
    <span class="s4"># Eq (26), typo in the article n ** 2</span>
    <span class="s1">c_p_i2i2 = ((g_i2 / ((n ** </span><span class="s5">2</span><span class="s1">) * alpha)) - (</span><span class="s5">2. </span><span class="s1">* h_i2 / (n * alpha * beta)))</span>

    <span class="s4"># Eq (26)</span>
    <span class="s1">sum_ = c_p_i1j - c_i1j + c_p_i2j - c_i2j</span>

    <span class="s1">mask = np.ones(n</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
    <span class="s1">mask[[i1</span><span class="s2">, </span><span class="s1">i2]] = </span><span class="s2">False</span>
    <span class="s1">sum_ = sum(sum_[mask])</span>

    <span class="s1">disc_ep = (disc + c_p_i1i1 - c_i1i1 + c_p_i2i2 - c_i2i2 + </span><span class="s5">2 </span><span class="s1">* sum_)</span>

    <span class="s2">return </span><span class="s1">disc_ep</span>


<span class="s2">def </span><span class="s1">primes_from_2_to(n: int) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Prime numbers from 2 to *n*. 
 
    Parameters 
    ---------- 
    n : int 
        Sup bound with ``n &gt;= 6``. 
 
    Returns 
    ------- 
    primes : list(int) 
        Primes in ``2 &lt;= p &lt; n``. 
 
    Notes 
    ----- 
    Taken from [1]_ by P.T. Roy, written consent given on 23.04.2021 
    by the original author, Bruno Astrolino, for free use in SciPy under 
    the 3-clause BSD. 
 
    References 
    ---------- 
    .. [1] `StackOverflow &lt;https://stackoverflow.com/questions/2068372&gt;`_. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">sieve = np.ones(n // </span><span class="s5">3 </span><span class="s1">+ (n % </span><span class="s5">6 </span><span class="s1">== </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">int(n ** </span><span class="s5">0.5</span><span class="s1">) // </span><span class="s5">3 </span><span class="s1">+ </span><span class="s5">1</span><span class="s1">):</span>
        <span class="s1">k = </span><span class="s5">3 </span><span class="s1">* i + </span><span class="s5">1 </span><span class="s1">| </span><span class="s5">1</span>
        <span class="s1">sieve[k * k // </span><span class="s5">3</span><span class="s1">::</span><span class="s5">2 </span><span class="s1">* k] = </span><span class="s2">False</span>
        <span class="s1">sieve[k * (k - </span><span class="s5">2 </span><span class="s1">* (i &amp; </span><span class="s5">1</span><span class="s1">) + </span><span class="s5">4</span><span class="s1">) // </span><span class="s5">3</span><span class="s1">::</span><span class="s5">2 </span><span class="s1">* k] = </span><span class="s2">False</span>
    <span class="s2">return </span><span class="s1">np.r_[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s1">((</span><span class="s5">3 </span><span class="s1">* np.nonzero(sieve)[</span><span class="s5">0</span><span class="s1">][</span><span class="s5">1</span><span class="s1">:] + </span><span class="s5">1</span><span class="s1">) | </span><span class="s5">1</span><span class="s1">)]</span>


<span class="s2">def </span><span class="s1">n_primes(n: IntNumber) -&gt; list[int]:</span>
    <span class="s0">&quot;&quot;&quot;List of the n-first prime numbers. 
 
    Parameters 
    ---------- 
    n : int 
        Number of prime numbers wanted. 
 
    Returns 
    ------- 
    primes : list(int) 
        List of primes. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">primes = [</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">5</span><span class="s2">, </span><span class="s5">7</span><span class="s2">, </span><span class="s5">11</span><span class="s2">, </span><span class="s5">13</span><span class="s2">, </span><span class="s5">17</span><span class="s2">, </span><span class="s5">19</span><span class="s2">, </span><span class="s5">23</span><span class="s2">, </span><span class="s5">29</span><span class="s2">, </span><span class="s5">31</span><span class="s2">, </span><span class="s5">37</span><span class="s2">, </span><span class="s5">41</span><span class="s2">, </span><span class="s5">43</span><span class="s2">, </span><span class="s5">47</span><span class="s2">, </span><span class="s5">53</span><span class="s2">, </span><span class="s5">59</span><span class="s2">,</span>
              <span class="s5">61</span><span class="s2">, </span><span class="s5">67</span><span class="s2">, </span><span class="s5">71</span><span class="s2">, </span><span class="s5">73</span><span class="s2">, </span><span class="s5">79</span><span class="s2">, </span><span class="s5">83</span><span class="s2">, </span><span class="s5">89</span><span class="s2">, </span><span class="s5">97</span><span class="s2">, </span><span class="s5">101</span><span class="s2">, </span><span class="s5">103</span><span class="s2">, </span><span class="s5">107</span><span class="s2">, </span><span class="s5">109</span><span class="s2">, </span><span class="s5">113</span><span class="s2">, </span><span class="s5">127</span><span class="s2">,</span>
              <span class="s5">131</span><span class="s2">, </span><span class="s5">137</span><span class="s2">, </span><span class="s5">139</span><span class="s2">, </span><span class="s5">149</span><span class="s2">, </span><span class="s5">151</span><span class="s2">, </span><span class="s5">157</span><span class="s2">, </span><span class="s5">163</span><span class="s2">, </span><span class="s5">167</span><span class="s2">, </span><span class="s5">173</span><span class="s2">, </span><span class="s5">179</span><span class="s2">, </span><span class="s5">181</span><span class="s2">, </span><span class="s5">191</span><span class="s2">, </span><span class="s5">193</span><span class="s2">,</span>
              <span class="s5">197</span><span class="s2">, </span><span class="s5">199</span><span class="s2">, </span><span class="s5">211</span><span class="s2">, </span><span class="s5">223</span><span class="s2">, </span><span class="s5">227</span><span class="s2">, </span><span class="s5">229</span><span class="s2">, </span><span class="s5">233</span><span class="s2">, </span><span class="s5">239</span><span class="s2">, </span><span class="s5">241</span><span class="s2">, </span><span class="s5">251</span><span class="s2">, </span><span class="s5">257</span><span class="s2">, </span><span class="s5">263</span><span class="s2">, </span><span class="s5">269</span><span class="s2">,</span>
              <span class="s5">271</span><span class="s2">, </span><span class="s5">277</span><span class="s2">, </span><span class="s5">281</span><span class="s2">, </span><span class="s5">283</span><span class="s2">, </span><span class="s5">293</span><span class="s2">, </span><span class="s5">307</span><span class="s2">, </span><span class="s5">311</span><span class="s2">, </span><span class="s5">313</span><span class="s2">, </span><span class="s5">317</span><span class="s2">, </span><span class="s5">331</span><span class="s2">, </span><span class="s5">337</span><span class="s2">, </span><span class="s5">347</span><span class="s2">, </span><span class="s5">349</span><span class="s2">,</span>
              <span class="s5">353</span><span class="s2">, </span><span class="s5">359</span><span class="s2">, </span><span class="s5">367</span><span class="s2">, </span><span class="s5">373</span><span class="s2">, </span><span class="s5">379</span><span class="s2">, </span><span class="s5">383</span><span class="s2">, </span><span class="s5">389</span><span class="s2">, </span><span class="s5">397</span><span class="s2">, </span><span class="s5">401</span><span class="s2">, </span><span class="s5">409</span><span class="s2">, </span><span class="s5">419</span><span class="s2">, </span><span class="s5">421</span><span class="s2">, </span><span class="s5">431</span><span class="s2">,</span>
              <span class="s5">433</span><span class="s2">, </span><span class="s5">439</span><span class="s2">, </span><span class="s5">443</span><span class="s2">, </span><span class="s5">449</span><span class="s2">, </span><span class="s5">457</span><span class="s2">, </span><span class="s5">461</span><span class="s2">, </span><span class="s5">463</span><span class="s2">, </span><span class="s5">467</span><span class="s2">, </span><span class="s5">479</span><span class="s2">, </span><span class="s5">487</span><span class="s2">, </span><span class="s5">491</span><span class="s2">, </span><span class="s5">499</span><span class="s2">, </span><span class="s5">503</span><span class="s2">,</span>
              <span class="s5">509</span><span class="s2">, </span><span class="s5">521</span><span class="s2">, </span><span class="s5">523</span><span class="s2">, </span><span class="s5">541</span><span class="s2">, </span><span class="s5">547</span><span class="s2">, </span><span class="s5">557</span><span class="s2">, </span><span class="s5">563</span><span class="s2">, </span><span class="s5">569</span><span class="s2">, </span><span class="s5">571</span><span class="s2">, </span><span class="s5">577</span><span class="s2">, </span><span class="s5">587</span><span class="s2">, </span><span class="s5">593</span><span class="s2">, </span><span class="s5">599</span><span class="s2">,</span>
              <span class="s5">601</span><span class="s2">, </span><span class="s5">607</span><span class="s2">, </span><span class="s5">613</span><span class="s2">, </span><span class="s5">617</span><span class="s2">, </span><span class="s5">619</span><span class="s2">, </span><span class="s5">631</span><span class="s2">, </span><span class="s5">641</span><span class="s2">, </span><span class="s5">643</span><span class="s2">, </span><span class="s5">647</span><span class="s2">, </span><span class="s5">653</span><span class="s2">, </span><span class="s5">659</span><span class="s2">, </span><span class="s5">661</span><span class="s2">, </span><span class="s5">673</span><span class="s2">,</span>
              <span class="s5">677</span><span class="s2">, </span><span class="s5">683</span><span class="s2">, </span><span class="s5">691</span><span class="s2">, </span><span class="s5">701</span><span class="s2">, </span><span class="s5">709</span><span class="s2">, </span><span class="s5">719</span><span class="s2">, </span><span class="s5">727</span><span class="s2">, </span><span class="s5">733</span><span class="s2">, </span><span class="s5">739</span><span class="s2">, </span><span class="s5">743</span><span class="s2">, </span><span class="s5">751</span><span class="s2">, </span><span class="s5">757</span><span class="s2">, </span><span class="s5">761</span><span class="s2">,</span>
              <span class="s5">769</span><span class="s2">, </span><span class="s5">773</span><span class="s2">, </span><span class="s5">787</span><span class="s2">, </span><span class="s5">797</span><span class="s2">, </span><span class="s5">809</span><span class="s2">, </span><span class="s5">811</span><span class="s2">, </span><span class="s5">821</span><span class="s2">, </span><span class="s5">823</span><span class="s2">, </span><span class="s5">827</span><span class="s2">, </span><span class="s5">829</span><span class="s2">, </span><span class="s5">839</span><span class="s2">, </span><span class="s5">853</span><span class="s2">, </span><span class="s5">857</span><span class="s2">,</span>
              <span class="s5">859</span><span class="s2">, </span><span class="s5">863</span><span class="s2">, </span><span class="s5">877</span><span class="s2">, </span><span class="s5">881</span><span class="s2">, </span><span class="s5">883</span><span class="s2">, </span><span class="s5">887</span><span class="s2">, </span><span class="s5">907</span><span class="s2">, </span><span class="s5">911</span><span class="s2">, </span><span class="s5">919</span><span class="s2">, </span><span class="s5">929</span><span class="s2">, </span><span class="s5">937</span><span class="s2">, </span><span class="s5">941</span><span class="s2">, </span><span class="s5">947</span><span class="s2">,</span>
              <span class="s5">953</span><span class="s2">, </span><span class="s5">967</span><span class="s2">, </span><span class="s5">971</span><span class="s2">, </span><span class="s5">977</span><span class="s2">, </span><span class="s5">983</span><span class="s2">, </span><span class="s5">991</span><span class="s2">, </span><span class="s5">997</span><span class="s1">][:n]  </span><span class="s4"># type: ignore[misc]</span>

    <span class="s2">if </span><span class="s1">len(primes) &lt; n:</span>
        <span class="s1">big_number = </span><span class="s5">2000</span>
        <span class="s2">while </span><span class="s3">'Not enough primes'</span><span class="s1">:</span>
            <span class="s1">primes = primes_from_2_to(big_number)[:n]  </span><span class="s4"># type: ignore</span>
            <span class="s2">if </span><span class="s1">len(primes) == n:</span>
                <span class="s2">break</span>
            <span class="s1">big_number += </span><span class="s5">1000</span>

    <span class="s2">return </span><span class="s1">primes</span>


<span class="s2">def </span><span class="s1">_van_der_corput_permutations(</span>
    <span class="s1">base: IntNumber</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">random_state: SeedType = </span><span class="s2">None</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Permutations for scrambling a Van der Corput sequence. 
 
    Parameters 
    ---------- 
    base : int 
        Base of the sequence. 
    random_state : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Returns 
    ------- 
    permutations : array_like 
        Permutation indices. 
 
    Notes 
    ----- 
    In Algorithm 1 of Owen 2017, a permutation of `np.arange(base)` is 
    created for each positive integer `k` such that `1 - base**-k &lt; 1` 
    using floating-point arithmetic. For double precision floats, the 
    condition `1 - base**-k &lt; 1` can also be written as `base**-k &gt; 
    2**-54`, which makes it more apparent how many permutations we need 
    to create. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = check_random_state(random_state)</span>
    <span class="s1">count = math.ceil(</span><span class="s5">54 </span><span class="s1">/ math.log2(base)) - </span><span class="s5">1</span>
    <span class="s1">permutations = np.repeat(np.arange(base)[</span><span class="s2">None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">count</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s2">for </span><span class="s1">perm </span><span class="s2">in </span><span class="s1">permutations:</span>
        <span class="s1">rng.shuffle(perm)</span>

    <span class="s2">return </span><span class="s1">permutations</span>


<span class="s2">def </span><span class="s1">van_der_corput(</span>
        <span class="s1">n: IntNumber</span><span class="s2">,</span>
        <span class="s1">base: IntNumber = </span><span class="s5">2</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">start_index: IntNumber = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">scramble: bool = </span><span class="s2">False,</span>
        <span class="s1">permutations: npt.ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None,</span>
        <span class="s1">workers: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Van der Corput sequence. 
 
    Pseudo-random number generator based on a b-adic expansion. 
 
    Scrambling uses permutations of the remainders (see [1]_). Multiple 
    permutations are applied to construct a point. The sequence of 
    permutations has to be the same for all points of the sequence. 
 
    Parameters 
    ---------- 
    n : int 
        Number of element of the sequence. 
    base : int, optional 
        Base of the sequence. Default is 2. 
    start_index : int, optional 
        Index to start the sequence from. Default is 0. 
    scramble : bool, optional 
        If True, use Owen scrambling. Otherwise no scrambling is done. 
        Default is True. 
    permutations : array_like, optional 
        Permutations used for scrambling. 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
    workers : int, optional 
        Number of workers to use for parallel processing. If -1 is 
        given all CPU threads are used. Default is 1. 
 
    Returns 
    ------- 
    sequence : list (n,) 
        Sequence of Van der Corput. 
 
    References 
    ---------- 
    .. [1] A. B. Owen. &quot;A randomized Halton algorithm in R&quot;, 
       :arxiv:`1706.02808`, 2017. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">base &lt; </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;'base' must be at least 2&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">scramble:</span>
        <span class="s2">if </span><span class="s1">permutations </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">permutations = _van_der_corput_permutations(</span>
                <span class="s1">base=base</span><span class="s2">, </span><span class="s1">random_state=seed</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">permutations = np.asarray(permutations)</span>

        <span class="s2">return </span><span class="s1">_cy_van_der_corput_scrambled(n</span><span class="s2">, </span><span class="s1">base</span><span class="s2">, </span><span class="s1">start_index</span><span class="s2">,</span>
                                            <span class="s1">permutations</span><span class="s2">, </span><span class="s1">workers)</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">_cy_van_der_corput(n</span><span class="s2">, </span><span class="s1">base</span><span class="s2">, </span><span class="s1">start_index</span><span class="s2">, </span><span class="s1">workers)</span>


<span class="s2">class </span><span class="s1">QMCEngine(ABC):</span>
    <span class="s0">&quot;&quot;&quot;A generic Quasi-Monte Carlo sampler class meant for subclassing. 
 
    QMCEngine is a base class to construct a specific Quasi-Monte Carlo 
    sampler. It cannot be used directly as a sampler. 
 
    Parameters 
    ---------- 
    d : int 
        Dimension of the parameter space. 
    optimization : {None, &quot;random-cd&quot;, &quot;lloyd&quot;}, optional 
        Whether to use an optimization scheme to improve the quality after 
        sampling. Note that this is a post-processing step that does not 
        guarantee that all properties of the sample will be conserved. 
        Default is None. 
 
        * ``random-cd``: random permutations of coordinates to lower the 
          centered discrepancy. The best sample based on the centered 
          discrepancy is constantly updated. Centered discrepancy-based 
          sampling shows better space-filling robustness toward 2D and 3D 
          subprojections compared to using other discrepancy measures. 
        * ``lloyd``: Perturb samples using a modified Lloyd-Max algorithm. 
          The process converges to equally spaced samples. 
 
        .. versionadded:: 1.10.0 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Notes 
    ----- 
    By convention samples are distributed over the half-open interval 
    ``[0, 1)``. Instances of the class can access the attributes: ``d`` for 
    the dimension; and ``rng`` for the random number generator (used for the 
    ``seed``). 
 
    **Subclassing** 
 
    When subclassing `QMCEngine` to create a new sampler,  ``__init__`` and 
    ``random`` must be redefined. 
 
    * ``__init__(d, seed=None)``: at least fix the dimension. If the sampler 
      does not take advantage of a ``seed`` (deterministic methods like 
      Halton), this parameter can be omitted. 
    * ``_random(n, *, workers=1)``: draw ``n`` from the engine. ``workers`` 
      is used for parallelism. See `Halton` for example. 
 
    Optionally, two other methods can be overwritten by subclasses: 
 
    * ``reset``: Reset the engine to its original state. 
    * ``fast_forward``: If the sequence is deterministic (like Halton 
      sequence), then ``fast_forward(n)`` is skipping the ``n`` first draw. 
 
    Examples 
    -------- 
    To create a random sampler based on ``np.random.random``, we would do the 
    following: 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; class RandomEngine(qmc.QMCEngine): 
    ...     def __init__(self, d, seed=None): 
    ...         super().__init__(d=d, seed=seed) 
    ... 
    ... 
    ...     def _random(self, n=1, *, workers=1): 
    ...         return self.rng.random((n, self.d)) 
    ... 
    ... 
    ...     def reset(self): 
    ...         super().__init__(d=self.d, seed=self.rng_seed) 
    ...         return self 
    ... 
    ... 
    ...     def fast_forward(self, n): 
    ...         self.random(n) 
    ...         return self 
 
    After subclassing `QMCEngine` to define the sampling strategy we want to 
    use, we can create an instance to sample from. 
 
    &gt;&gt;&gt; engine = RandomEngine(2) 
    &gt;&gt;&gt; engine.random(5) 
    array([[0.22733602, 0.31675834],  # random 
           [0.79736546, 0.67625467], 
           [0.39110955, 0.33281393], 
           [0.59830875, 0.18673419], 
           [0.67275604, 0.94180287]]) 
 
    We can also reset the state of the generator and resample again. 
 
    &gt;&gt;&gt; _ = engine.reset() 
    &gt;&gt;&gt; engine.random(5) 
    array([[0.22733602, 0.31675834],  # random 
           [0.79736546, 0.67625467], 
           [0.39110955, 0.33281393], 
           [0.59830875, 0.18673419], 
           [0.67275604, 0.94180287]]) 
 
    &quot;&quot;&quot;</span>

    <span class="s1">@abstractmethod</span>
    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">d: IntNumber</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">if not </span><span class="s1">np.issubdtype(type(d)</span><span class="s2">, </span><span class="s1">np.integer) </span><span class="s2">or </span><span class="s1">d &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'d must be a non-negative integer value'</span><span class="s1">)</span>

        <span class="s1">self.d = d</span>

        <span class="s2">if </span><span class="s1">isinstance(seed</span><span class="s2">, </span><span class="s1">np.random.Generator):</span>
            <span class="s4"># Spawn a Generator that we can own and reset.</span>
            <span class="s1">self.rng = _rng_spawn(seed</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># Create our instance of Generator, does not need spawning</span>
            <span class="s4"># Also catch RandomState which cannot be spawned</span>
            <span class="s1">self.rng = check_random_state(seed)</span>
        <span class="s1">self.rng_seed = copy.deepcopy(self.rng)</span>

        <span class="s1">self.num_generated = </span><span class="s5">0</span>

        <span class="s1">config = {</span>
            <span class="s4"># random-cd</span>
            <span class="s3">&quot;n_nochange&quot;</span><span class="s1">: </span><span class="s5">100</span><span class="s2">,</span>
            <span class="s3">&quot;n_iters&quot;</span><span class="s1">: </span><span class="s5">10_000</span><span class="s2">,</span>
            <span class="s3">&quot;rng&quot;</span><span class="s1">: self.rng</span><span class="s2">,</span>

            <span class="s4"># lloyd</span>
            <span class="s3">&quot;tol&quot;</span><span class="s1">: </span><span class="s5">1e-5</span><span class="s2">,</span>
            <span class="s3">&quot;maxiter&quot;</span><span class="s1">: </span><span class="s5">10</span><span class="s2">,</span>
            <span class="s3">&quot;qhull_options&quot;</span><span class="s1">: </span><span class="s2">None,</span>
        <span class="s1">}</span>
        <span class="s1">self.optimization_method = _select_optimizer(optimization</span><span class="s2">, </span><span class="s1">config)</span>

    <span class="s1">@abstractmethod</span>
    <span class="s2">def </span><span class="s1">_random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s1">...</span>

    <span class="s2">def </span><span class="s1">random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` in the half-open interval ``[0, 1)``. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. 
            Default is 1. 
        workers : int, optional 
            Only supported with `Halton`. 
            Number of workers to use for parallel processing. If -1 is 
            given all CPU threads are used. Default is 1. It becomes faster 
            than one worker for `n` greater than :math:`10^3`. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            QMC sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">sample = self._random(n</span><span class="s2">, </span><span class="s1">workers=workers)</span>
        <span class="s2">if </span><span class="s1">self.optimization_method </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">sample = self.optimization_method(sample)</span>

        <span class="s1">self.num_generated += n</span>
        <span class="s2">return </span><span class="s1">sample</span>

    <span class="s2">def </span><span class="s1">integers(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">l_bounds: npt.ArrayLike</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">u_bounds: npt.ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">endpoint: bool = </span><span class="s2">False,</span>
        <span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">r&quot;&quot;&quot; 
        Draw `n` integers from `l_bounds` (inclusive) to `u_bounds` 
        (exclusive), or if endpoint=True, `l_bounds` (inclusive) to 
        `u_bounds` (inclusive). 
 
        Parameters 
        ---------- 
        l_bounds : int or array-like of ints 
            Lowest (signed) integers to be drawn (unless ``u_bounds=None``, 
            in which case this parameter is 0 and this value is used for 
            `u_bounds`). 
        u_bounds : int or array-like of ints, optional 
            If provided, one above the largest (signed) integer to be drawn 
            (see above for behavior if ``u_bounds=None``). 
            If array-like, must contain integer values. 
        n : int, optional 
            Number of samples to generate in the parameter space. 
            Default is 1. 
        endpoint : bool, optional 
            If true, sample from the interval ``[l_bounds, u_bounds]`` instead 
            of the default ``[l_bounds, u_bounds)``. Defaults is False. 
        workers : int, optional 
            Number of workers to use for parallel processing. If -1 is 
            given all CPU threads are used. Only supported when using `Halton` 
            Default is 1. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            QMC sample. 
 
        Notes 
        ----- 
        It is safe to just use the same ``[0, 1)`` to integer mapping 
        with QMC that you would use with MC. You still get unbiasedness, 
        a strong law of large numbers, an asymptotically infinite variance 
        reduction and a finite sample variance bound. 
 
        To convert a sample from :math:`[0, 1)` to :math:`[a, b), b&gt;a`, 
        with :math:`a` the lower bounds and :math:`b` the upper bounds, 
        the following transformation is used: 
 
        .. math:: 
 
            \text{floor}((b - a) \cdot \text{sample} + a) 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">u_bounds </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">u_bounds = l_bounds</span>
            <span class="s1">l_bounds = </span><span class="s5">0</span>

        <span class="s1">u_bounds = np.atleast_1d(u_bounds)</span>
        <span class="s1">l_bounds = np.atleast_1d(l_bounds)</span>

        <span class="s2">if </span><span class="s1">endpoint:</span>
            <span class="s1">u_bounds = u_bounds + </span><span class="s5">1</span>

        <span class="s2">if </span><span class="s1">(</span><span class="s2">not </span><span class="s1">np.issubdtype(l_bounds.dtype</span><span class="s2">, </span><span class="s1">np.integer) </span><span class="s2">or</span>
                <span class="s2">not </span><span class="s1">np.issubdtype(u_bounds.dtype</span><span class="s2">, </span><span class="s1">np.integer)):</span>
            <span class="s1">message = (</span><span class="s3">&quot;'u_bounds' and 'l_bounds' must be integers or&quot;</span>
                       <span class="s3">&quot; array-like of integers&quot;</span><span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">ValueError(message)</span>

        <span class="s2">if </span><span class="s1">isinstance(self</span><span class="s2">, </span><span class="s1">Halton):</span>
            <span class="s1">sample = self.random(n=n</span><span class="s2">, </span><span class="s1">workers=workers)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sample = self.random(n=n)</span>

        <span class="s1">sample = scale(sample</span><span class="s2">, </span><span class="s1">l_bounds=l_bounds</span><span class="s2">, </span><span class="s1">u_bounds=u_bounds)</span>
        <span class="s1">sample = np.floor(sample).astype(np.int64)</span>

        <span class="s2">return </span><span class="s1">sample</span>

    <span class="s2">def </span><span class="s1">reset(self) -&gt; QMCEngine:</span>
        <span class="s0">&quot;&quot;&quot;Reset the engine to base state. 
 
        Returns 
        ------- 
        engine : QMCEngine 
            Engine reset to its base state. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">seed = copy.deepcopy(self.rng_seed)</span>
        <span class="s1">self.rng = check_random_state(seed)</span>
        <span class="s1">self.num_generated = </span><span class="s5">0</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">fast_forward(self</span><span class="s2">, </span><span class="s1">n: IntNumber) -&gt; QMCEngine:</span>
        <span class="s0">&quot;&quot;&quot;Fast-forward the sequence by `n` positions. 
 
        Parameters 
        ---------- 
        n : int 
            Number of points to skip in the sequence. 
 
        Returns 
        ------- 
        engine : QMCEngine 
            Engine reset to its base state. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">self.random(n=n)</span>
        <span class="s2">return </span><span class="s1">self</span>


<span class="s2">class </span><span class="s1">Halton(QMCEngine):</span>
    <span class="s0">&quot;&quot;&quot;Halton sequence. 
 
    Pseudo-random number generator that generalize the Van der Corput sequence 
    for multiple dimensions. The Halton sequence uses the base-two Van der 
    Corput sequence for the first dimension, base-three for its second and 
    base-:math:`n` for its n-dimension. 
 
    Parameters 
    ---------- 
    d : int 
        Dimension of the parameter space. 
    scramble : bool, optional 
        If True, use Owen scrambling. Otherwise no scrambling is done. 
        Default is True. 
    optimization : {None, &quot;random-cd&quot;, &quot;lloyd&quot;}, optional 
        Whether to use an optimization scheme to improve the quality after 
        sampling. Note that this is a post-processing step that does not 
        guarantee that all properties of the sample will be conserved. 
        Default is None. 
 
        * ``random-cd``: random permutations of coordinates to lower the 
          centered discrepancy. The best sample based on the centered 
          discrepancy is constantly updated. Centered discrepancy-based 
          sampling shows better space-filling robustness toward 2D and 3D 
          subprojections compared to using other discrepancy measures. 
        * ``lloyd``: Perturb samples using a modified Lloyd-Max algorithm. 
          The process converges to equally spaced samples. 
 
        .. versionadded:: 1.10.0 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Notes 
    ----- 
    The Halton sequence has severe striping artifacts for even modestly 
    large dimensions. These can be ameliorated by scrambling. Scrambling 
    also supports replication-based error estimates and extends 
    applicabiltiy to unbounded integrands. 
 
    References 
    ---------- 
    .. [1] Halton, &quot;On the efficiency of certain quasi-random sequences of 
       points in evaluating multi-dimensional integrals&quot;, Numerische 
       Mathematik, 1960. 
    .. [2] A. B. Owen. &quot;A randomized Halton algorithm in R&quot;, 
       :arxiv:`1706.02808`, 2017. 
 
    Examples 
    -------- 
    Generate samples from a low discrepancy sequence of Halton. 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; sampler = qmc.Halton(d=2, scramble=False) 
    &gt;&gt;&gt; sample = sampler.random(n=5) 
    &gt;&gt;&gt; sample 
    array([[0.        , 0.        ], 
           [0.5       , 0.33333333], 
           [0.25      , 0.66666667], 
           [0.75      , 0.11111111], 
           [0.125     , 0.44444444]]) 
 
    Compute the quality of the sample using the discrepancy criterion. 
 
    &gt;&gt;&gt; qmc.discrepancy(sample) 
    0.088893711419753 
 
    If some wants to continue an existing design, extra points can be obtained 
    by calling again `random`. Alternatively, you can skip some points like: 
 
    &gt;&gt;&gt; _ = sampler.fast_forward(5) 
    &gt;&gt;&gt; sample_continued = sampler.random(n=5) 
    &gt;&gt;&gt; sample_continued 
    array([[0.3125    , 0.37037037], 
           [0.8125    , 0.7037037 ], 
           [0.1875    , 0.14814815], 
           [0.6875    , 0.48148148], 
           [0.4375    , 0.81481481]]) 
 
    Finally, samples can be scaled to bounds. 
 
    &gt;&gt;&gt; l_bounds = [0, 2] 
    &gt;&gt;&gt; u_bounds = [10, 5] 
    &gt;&gt;&gt; qmc.scale(sample_continued, l_bounds, u_bounds) 
    array([[3.125     , 3.11111111], 
           [8.125     , 4.11111111], 
           [1.875     , 2.44444444], 
           [6.875     , 3.44444444], 
           [4.375     , 4.44444444]]) 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">d: IntNumber</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">scramble: bool = </span><span class="s2">True,</span>
        <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s4"># Used in `scipy.integrate.qmc_quad`</span>
        <span class="s1">self._init_quad = {</span><span class="s3">'d'</span><span class="s1">: d</span><span class="s2">, </span><span class="s3">'scramble'</span><span class="s1">: </span><span class="s2">True,</span>
                           <span class="s3">'optimization'</span><span class="s1">: optimization}</span>
        <span class="s1">super().__init__(d=d</span><span class="s2">, </span><span class="s1">optimization=optimization</span><span class="s2">, </span><span class="s1">seed=seed)</span>
        <span class="s1">self.seed = seed</span>

        <span class="s4"># important to have ``type(bdim) == int`` for performance reason</span>
        <span class="s1">self.base = [int(bdim) </span><span class="s2">for </span><span class="s1">bdim </span><span class="s2">in </span><span class="s1">n_primes(d)]</span>
        <span class="s1">self.scramble = scramble</span>

        <span class="s1">self._initialize_permutations()</span>

    <span class="s2">def </span><span class="s1">_initialize_permutations(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot;Initialize permutations for all Van der Corput sequences. 
 
        Permutations are only needed for scrambling. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._permutations: list = [</span><span class="s2">None</span><span class="s1">] * len(self.base)</span>
        <span class="s2">if </span><span class="s1">self.scramble:</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">bdim </span><span class="s2">in </span><span class="s1">enumerate(self.base):</span>
                <span class="s1">permutations = _van_der_corput_permutations(</span>
                    <span class="s1">base=bdim</span><span class="s2">, </span><span class="s1">random_state=self.rng</span>
                <span class="s1">)</span>

                <span class="s1">self._permutations[i] = permutations</span>

    <span class="s2">def </span><span class="s1">_random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` in the half-open interval ``[0, 1)``. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
        workers : int, optional 
            Number of workers to use for parallel processing. If -1 is 
            given all CPU threads are used. Default is 1. It becomes faster 
            than one worker for `n` greater than :math:`10^3`. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            QMC sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">workers = _validate_workers(workers)</span>
        <span class="s4"># Generate a sample using a Van der Corput sequence per dimension.</span>
        <span class="s1">sample = [van_der_corput(n</span><span class="s2">, </span><span class="s1">bdim</span><span class="s2">, </span><span class="s1">start_index=self.num_generated</span><span class="s2">,</span>
                                 <span class="s1">scramble=self.scramble</span><span class="s2">,</span>
                                 <span class="s1">permutations=self._permutations[i]</span><span class="s2">,</span>
                                 <span class="s1">workers=workers)</span>
                  <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">bdim </span><span class="s2">in </span><span class="s1">enumerate(self.base)]</span>

        <span class="s2">return </span><span class="s1">np.array(sample).T.reshape(n</span><span class="s2">, </span><span class="s1">self.d)</span>


<span class="s2">class </span><span class="s1">LatinHypercube(QMCEngine):</span>
    <span class="s0">r&quot;&quot;&quot;Latin hypercube sampling (LHS). 
 
    A Latin hypercube sample [1]_ generates :math:`n` points in 
    :math:`[0,1)^{d}`. Each univariate marginal distribution is stratified, 
    placing exactly one point in :math:`[j/n, (j+1)/n)` for 
    :math:`j=0,1,...,n-1`. They are still applicable when :math:`n &lt;&lt; d`. 
 
    Parameters 
    ---------- 
    d : int 
        Dimension of the parameter space. 
    centered : bool, optional 
        Center samples within cells of a multi-dimensional grid. 
        Default is False. 
 
        .. deprecated:: 1.10.0 
            `centered` is deprecated as of SciPy 1.10.0 and will be removed in 
            1.12.0. Use `scramble` instead. ``centered=True`` corresponds to 
            ``scramble=False``. 
 
    scramble : bool, optional 
        When False, center samples within cells of a multi-dimensional grid. 
        Otherwise, samples are randomly placed within cells of the grid. 
 
        .. note:: 
            Setting ``scramble=False`` does not ensure deterministic output. 
            For that, use the `seed` parameter. 
 
        Default is True. 
 
        .. versionadded:: 1.10.0 
 
    optimization : {None, &quot;random-cd&quot;, &quot;lloyd&quot;}, optional 
        Whether to use an optimization scheme to improve the quality after 
        sampling. Note that this is a post-processing step that does not 
        guarantee that all properties of the sample will be conserved. 
        Default is None. 
 
        * ``random-cd``: random permutations of coordinates to lower the 
          centered discrepancy. The best sample based on the centered 
          discrepancy is constantly updated. Centered discrepancy-based 
          sampling shows better space-filling robustness toward 2D and 3D 
          subprojections compared to using other discrepancy measures. 
        * ``lloyd``: Perturb samples using a modified Lloyd-Max algorithm. 
          The process converges to equally spaced samples. 
 
        .. versionadded:: 1.8.0 
        .. versionchanged:: 1.10.0 
            Add ``lloyd``. 
 
    strength : {1, 2}, optional 
        Strength of the LHS. ``strength=1`` produces a plain LHS while 
        ``strength=2`` produces an orthogonal array based LHS of strength 2 
        [7]_, [8]_. In that case, only ``n=p**2`` points can be sampled, 
        with ``p`` a prime number. It also constrains ``d &lt;= p + 1``. 
        Default is 1. 
 
        .. versionadded:: 1.8.0 
 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Notes 
    ----- 
 
    When LHS is used for integrating a function :math:`f` over :math:`n`, 
    LHS is extremely effective on integrands that are nearly additive [2]_. 
    With a LHS of :math:`n` points, the variance of the integral is always 
    lower than plain MC on :math:`n-1` points [3]_. There is a central limit 
    theorem for LHS on the mean and variance of the integral [4]_, but not 
    necessarily for optimized LHS due to the randomization. 
 
    :math:`A` is called an orthogonal array of strength :math:`t` if in each 
    n-row-by-t-column submatrix of :math:`A`: all :math:`p^t` possible 
    distinct rows occur the same number of times. The elements of :math:`A` 
    are in the set :math:`\{0, 1, ..., p-1\}`, also called symbols. 
    The constraint that :math:`p` must be a prime number is to allow modular 
    arithmetic. Increasing strength adds some symmetry to the sub-projections 
    of a sample. With strength 2, samples are symmetric along the diagonals of 
    2D sub-projections. This may be undesirable, but on the other hand, the 
    sample dispersion is improved. 
 
    Strength 1 (plain LHS) brings an advantage over strength 0 (MC) and 
    strength 2 is a useful increment over strength 1. Going to strength 3 is 
    a smaller increment and scrambled QMC like Sobol', Halton are more 
    performant [7]_. 
 
    To create a LHS of strength 2, the orthogonal array :math:`A` is 
    randomized by applying a random, bijective map of the set of symbols onto 
    itself. For example, in column 0, all 0s might become 2; in column 1, 
    all 0s might become 1, etc. 
    Then, for each column :math:`i` and symbol :math:`j`, we add a plain, 
    one-dimensional LHS of size :math:`p` to the subarray where 
    :math:`A^i = j`. The resulting matrix is finally divided by :math:`p`. 
 
    References 
    ---------- 
    .. [1] Mckay et al., &quot;A Comparison of Three Methods for Selecting Values 
       of Input Variables in the Analysis of Output from a Computer Code.&quot; 
       Technometrics, 1979. 
    .. [2] M. Stein, &quot;Large sample properties of simulations using Latin 
       hypercube sampling.&quot; Technometrics 29, no. 2: 143-151, 1987. 
    .. [3] A. B. Owen, &quot;Monte Carlo variance of scrambled net quadrature.&quot; 
       SIAM Journal on Numerical Analysis 34, no. 5: 1884-1910, 1997 
    .. [4]  Loh, W.-L. &quot;On Latin hypercube sampling.&quot; The annals of statistics 
       24, no. 5: 2058-2080, 1996. 
    .. [5] Fang et al. &quot;Design and modeling for computer experiments&quot;. 
       Computer Science and Data Analysis Series, 2006. 
    .. [6] Damblin et al., &quot;Numerical studies of space filling designs: 
       optimization of Latin Hypercube Samples and subprojection properties.&quot; 
       Journal of Simulation, 2013. 
    .. [7] A. B. Owen , &quot;Orthogonal arrays for computer experiments, 
       integration and visualization.&quot; Statistica Sinica, 1992. 
    .. [8] B. Tang, &quot;Orthogonal Array-Based Latin Hypercubes.&quot; 
       Journal of the American Statistical Association, 1993. 
    .. [9] Susan K. Seaholm et al. &quot;Latin hypercube sampling and the 
       sensitivity analysis of a Monte Carlo epidemic model&quot;. 
       Int J Biomed Comput, 23(1-2), 97-112, 
       :doi:`10.1016/0020-7101(88)90067-0`, 1988. 
 
    Examples 
    -------- 
    In [9]_, a Latin Hypercube sampling strategy was used to sample a 
    parameter space to study the importance of each parameter of an epidemic 
    model. Such analysis is also called a sensitivity analysis. 
 
    Since the dimensionality of the problem is high (6), it is computationally 
    expensive to cover the space. When numerical experiments are costly, 
    QMC enables analysis that may not be possible if using a grid. 
 
    The six parameters of the model represented the probability of illness, 
    the probability of withdrawal, and four contact probabilities, 
    The authors assumed uniform distributions for all parameters and generated 
    50 samples. 
 
    Using `scipy.stats.qmc.LatinHypercube` to replicate the protocol, the 
    first step is to create a sample in the unit hypercube: 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; sampler = qmc.LatinHypercube(d=6) 
    &gt;&gt;&gt; sample = sampler.random(n=50) 
 
    Then the sample can be scaled to the appropriate bounds: 
 
    &gt;&gt;&gt; l_bounds = [0.000125, 0.01, 0.0025, 0.05, 0.47, 0.7] 
    &gt;&gt;&gt; u_bounds = [0.000375, 0.03, 0.0075, 0.15, 0.87, 0.9] 
    &gt;&gt;&gt; sample_scaled = qmc.scale(sample, l_bounds, u_bounds) 
 
    Such a sample was used to run the model 50 times, and a polynomial 
    response surface was constructed. This allowed the authors to study the 
    relative importance of each parameter across the range of 
    possibilities of every other parameter. 
    In this computer experiment, they showed a 14-fold reduction in the number 
    of samples required to maintain an error below 2% on their response surface 
    when compared to a grid sampling. 
 
    Below are other examples showing alternative ways to construct LHS 
    with even better coverage of the space. 
 
    Using a base LHS as a baseline. 
 
    &gt;&gt;&gt; sampler = qmc.LatinHypercube(d=2) 
    &gt;&gt;&gt; sample = sampler.random(n=5) 
    &gt;&gt;&gt; qmc.discrepancy(sample) 
    0.0196...  # random 
 
    Use the `optimization` keyword argument to produce a LHS with 
    lower discrepancy at higher computational cost. 
 
    &gt;&gt;&gt; sampler = qmc.LatinHypercube(d=2, optimization=&quot;random-cd&quot;) 
    &gt;&gt;&gt; sample = sampler.random(n=5) 
    &gt;&gt;&gt; qmc.discrepancy(sample) 
    0.0176...  # random 
 
    Use the `strength` keyword argument to produce an orthogonal array based 
    LHS of strength 2. In this case, the number of sample points must be the 
    square of a prime number. 
 
    &gt;&gt;&gt; sampler = qmc.LatinHypercube(d=2, strength=2) 
    &gt;&gt;&gt; sample = sampler.random(n=9) 
    &gt;&gt;&gt; qmc.discrepancy(sample) 
    0.00526...  # random 
 
    Options could be combined to produce an optimized centered 
    orthogonal array based LHS. After optimization, the result would not 
    be guaranteed to be of strength 2. 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">d: IntNumber</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">centered: bool = </span><span class="s2">False,</span>
        <span class="s1">scramble: bool = </span><span class="s2">True,</span>
        <span class="s1">strength: int = </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">centered:</span>
            <span class="s1">scramble = </span><span class="s2">False</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;'centered' is deprecated and will be removed in SciPy 1.12.&quot;</span>
                <span class="s3">&quot; Please use 'scramble' instead. 'centered=True' corresponds&quot;</span>
                <span class="s3">&quot; to 'scramble=False'.&quot;</span><span class="s2">,</span>
                <span class="s1">stacklevel=</span><span class="s5">2</span>
            <span class="s1">)</span>

        <span class="s4"># Used in `scipy.integrate.qmc_quad`</span>
        <span class="s1">self._init_quad = {</span><span class="s3">'d'</span><span class="s1">: d</span><span class="s2">, </span><span class="s3">'scramble'</span><span class="s1">: </span><span class="s2">True, </span><span class="s3">'strength'</span><span class="s1">: strength</span><span class="s2">,</span>
                           <span class="s3">'optimization'</span><span class="s1">: optimization}</span>
        <span class="s1">super().__init__(d=d</span><span class="s2">, </span><span class="s1">seed=seed</span><span class="s2">, </span><span class="s1">optimization=optimization)</span>
        <span class="s1">self.scramble = scramble</span>

        <span class="s1">lhs_method_strength = {</span>
            <span class="s5">1</span><span class="s1">: self._random_lhs</span><span class="s2">,</span>
            <span class="s5">2</span><span class="s1">: self._random_oa_lhs</span>
        <span class="s1">}</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">self.lhs_method: Callable = lhs_method_strength[strength]</span>
        <span class="s2">except </span><span class="s1">KeyError </span><span class="s2">as </span><span class="s1">exc:</span>
            <span class="s1">message = (</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">strength</span><span class="s2">!r} </span><span class="s3">is not a valid strength. It must be one&quot;</span>
                       <span class="s3">f&quot; of </span><span class="s2">{</span><span class="s1">set(lhs_method_strength)</span><span class="s2">!r}</span><span class="s3">&quot;</span><span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">ValueError(message) </span><span class="s2">from </span><span class="s1">exc</span>

    <span class="s2">def </span><span class="s1">_random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s1">lhs = self.lhs_method(n)</span>
        <span class="s2">return </span><span class="s1">lhs</span>

    <span class="s2">def </span><span class="s1">_random_lhs(self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Base LHS algorithm.&quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">self.scramble:</span>
            <span class="s1">samples: np.ndarray | float = </span><span class="s5">0.5</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">samples = self.rng.uniform(size=(n</span><span class="s2">, </span><span class="s1">self.d))</span>

        <span class="s1">perms = np.tile(np.arange(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n + </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">(self.d</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))  </span><span class="s4"># type: ignore[arg-type]</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.d):</span>
            <span class="s1">self.rng.shuffle(perms[i</span><span class="s2">, </span><span class="s1">:])</span>
        <span class="s1">perms = perms.T</span>

        <span class="s1">samples = (perms - samples) / n</span>
        <span class="s2">return </span><span class="s1">samples</span>

    <span class="s2">def </span><span class="s1">_random_oa_lhs(self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">4</span><span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Orthogonal array based LHS of strength 2.&quot;&quot;&quot;</span>
        <span class="s1">p = np.sqrt(n).astype(int)</span>
        <span class="s1">n_row = p**</span><span class="s5">2</span>
        <span class="s1">n_col = p + </span><span class="s5">1</span>

        <span class="s1">primes = primes_from_2_to(p + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">p </span><span class="s2">not in </span><span class="s1">primes </span><span class="s2">or </span><span class="s1">n != n_row:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;n is not the square of a prime number. Close&quot;</span>
                <span class="s3">f&quot; values are </span><span class="s2">{</span><span class="s1">primes[-</span><span class="s5">2</span><span class="s1">:]**</span><span class="s5">2</span><span class="s2">}</span><span class="s3">&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.d &gt; p + </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;n is too small for d. Must be n &gt; (d-1)**2&quot;</span><span class="s1">)</span>

        <span class="s1">oa_sample = np.zeros(shape=(n_row</span><span class="s2">, </span><span class="s1">n_col)</span><span class="s2">, </span><span class="s1">dtype=int)</span>

        <span class="s4"># OA of strength 2</span>
        <span class="s1">arrays = np.tile(np.arange(p)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">oa_sample[:</span><span class="s2">, </span><span class="s1">:</span><span class="s5">2</span><span class="s1">] = np.stack(np.meshgrid(*arrays)</span><span class="s2">,</span>
                                    <span class="s1">axis=-</span><span class="s5">1</span><span class="s1">).reshape(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">p_ </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">p):</span>
            <span class="s1">oa_sample[:</span><span class="s2">, </span><span class="s5">2</span><span class="s1">+p_-</span><span class="s5">1</span><span class="s1">] = np.mod(oa_sample[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
                                          <span class="s1">+ p_*oa_sample[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">p)</span>

        <span class="s4"># scramble the OA</span>
        <span class="s1">oa_sample_ = np.empty(shape=(n_row</span><span class="s2">, </span><span class="s1">n_col)</span><span class="s2">, </span><span class="s1">dtype=int)</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(n_col):</span>
            <span class="s1">perms = self.rng.permutation(p)</span>
            <span class="s1">oa_sample_[:</span><span class="s2">, </span><span class="s1">j] = perms[oa_sample[:</span><span class="s2">, </span><span class="s1">j]]</span>

        <span class="s4"># following is making a scrambled OA into an OA-LHS</span>
        <span class="s1">oa_lhs_sample = np.zeros(shape=(n_row</span><span class="s2">, </span><span class="s1">n_col))</span>
        <span class="s1">lhs_engine = LatinHypercube(d=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">scramble=self.scramble</span><span class="s2">, </span><span class="s1">strength=</span><span class="s5">1</span><span class="s2">,</span>
                                    <span class="s1">seed=self.rng)  </span><span class="s4"># type: QMCEngine</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(n_col):</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(p):</span>
                <span class="s1">idx = oa_sample[:</span><span class="s2">, </span><span class="s1">j] == k</span>
                <span class="s1">lhs = lhs_engine.random(p).flatten()</span>
                <span class="s1">oa_lhs_sample[:</span><span class="s2">, </span><span class="s1">j][idx] = lhs + oa_sample[:</span><span class="s2">, </span><span class="s1">j][idx]</span>

                <span class="s1">lhs_engine = lhs_engine.reset()</span>

        <span class="s1">oa_lhs_sample /= p</span>

        <span class="s2">return </span><span class="s1">oa_lhs_sample[:</span><span class="s2">, </span><span class="s1">:self.d]  </span><span class="s4"># type: ignore</span>


<span class="s2">class </span><span class="s1">Sobol(QMCEngine):</span>
    <span class="s0">&quot;&quot;&quot;Engine for generating (scrambled) Sobol' sequences. 
 
    Sobol' sequences are low-discrepancy, quasi-random numbers. Points 
    can be drawn using two methods: 
 
    * `random_base2`: safely draw :math:`n=2^m` points. This method 
      guarantees the balance properties of the sequence. 
    * `random`: draw an arbitrary number of points from the 
      sequence. See warning below. 
 
    Parameters 
    ---------- 
    d : int 
        Dimensionality of the sequence. Max dimensionality is 21201. 
    scramble : bool, optional 
        If True, use LMS+shift scrambling. Otherwise, no scrambling is done. 
        Default is True. 
    bits : int, optional 
        Number of bits of the generator. Control the maximum number of points 
        that can be generated, which is ``2**bits``. Maximal value is 64. 
        It does not correspond to the return type, which is always 
        ``np.float64`` to prevent points from repeating themselves. 
        Default is None, which for backward compatibility, corresponds to 30. 
 
        .. versionadded:: 1.9.0 
    optimization : {None, &quot;random-cd&quot;, &quot;lloyd&quot;}, optional 
        Whether to use an optimization scheme to improve the quality after 
        sampling. Note that this is a post-processing step that does not 
        guarantee that all properties of the sample will be conserved. 
        Default is None. 
 
        * ``random-cd``: random permutations of coordinates to lower the 
          centered discrepancy. The best sample based on the centered 
          discrepancy is constantly updated. Centered discrepancy-based 
          sampling shows better space-filling robustness toward 2D and 3D 
          subprojections compared to using other discrepancy measures. 
        * ``lloyd``: Perturb samples using a modified Lloyd-Max algorithm. 
          The process converges to equally spaced samples. 
 
        .. versionadded:: 1.10.0 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Notes 
    ----- 
    Sobol' sequences [1]_ provide :math:`n=2^m` low discrepancy points in 
    :math:`[0,1)^{d}`. Scrambling them [3]_ makes them suitable for singular 
    integrands, provides a means of error estimation, and can improve their 
    rate of convergence. The scrambling strategy which is implemented is a 
    (left) linear matrix scramble (LMS) followed by a digital random shift 
    (LMS+shift) [2]_. 
 
    There are many versions of Sobol' sequences depending on their 
    'direction numbers'. This code uses direction numbers from [4]_. Hence, 
    the maximum number of dimension is 21201. The direction numbers have been 
    precomputed with search criterion 6 and can be retrieved at 
    https://web.maths.unsw.edu.au/~fkuo/sobol/. 
 
    .. warning:: 
 
       Sobol' sequences are a quadrature rule and they lose their balance 
       properties if one uses a sample size that is not a power of 2, or skips 
       the first point, or thins the sequence [5]_. 
 
       If :math:`n=2^m` points are not enough then one should take :math:`2^M` 
       points for :math:`M&gt;m`. When scrambling, the number R of independent 
       replicates does not have to be a power of 2. 
 
       Sobol' sequences are generated to some number :math:`B` of bits. 
       After :math:`2^B` points have been generated, the sequence would 
       repeat. Hence, an error is raised. 
       The number of bits can be controlled with the parameter `bits`. 
 
    References 
    ---------- 
    .. [1] I. M. Sobol', &quot;The distribution of points in a cube and the accurate 
       evaluation of integrals.&quot; Zh. Vychisl. Mat. i Mat. Phys., 7:784-802, 
       1967. 
    .. [2] J. Matousek, &quot;On the L2-discrepancy for anchored boxes.&quot; 
       J. of Complexity 14, 527-556, 1998. 
    .. [3] Art B. Owen, &quot;Scrambling Sobol and Niederreiter-Xing points.&quot; 
       Journal of Complexity, 14(4):466-489, December 1998. 
    .. [4] S. Joe and F. Y. Kuo, &quot;Constructing sobol sequences with better 
       two-dimensional projections.&quot; SIAM Journal on Scientific Computing, 
       30(5):2635-2654, 2008. 
    .. [5] Art B. Owen, &quot;On dropping the first Sobol' point.&quot; 
       :arxiv:`2008.08051`, 2020. 
 
    Examples 
    -------- 
    Generate samples from a low discrepancy sequence of Sobol'. 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; sampler = qmc.Sobol(d=2, scramble=False) 
    &gt;&gt;&gt; sample = sampler.random_base2(m=3) 
    &gt;&gt;&gt; sample 
    array([[0.   , 0.   ], 
           [0.5  , 0.5  ], 
           [0.75 , 0.25 ], 
           [0.25 , 0.75 ], 
           [0.375, 0.375], 
           [0.875, 0.875], 
           [0.625, 0.125], 
           [0.125, 0.625]]) 
 
    Compute the quality of the sample using the discrepancy criterion. 
 
    &gt;&gt;&gt; qmc.discrepancy(sample) 
    0.013882107204860938 
 
    To continue an existing design, extra points can be obtained 
    by calling again `random_base2`. Alternatively, you can skip some 
    points like: 
 
    &gt;&gt;&gt; _ = sampler.reset() 
    &gt;&gt;&gt; _ = sampler.fast_forward(4) 
    &gt;&gt;&gt; sample_continued = sampler.random_base2(m=2) 
    &gt;&gt;&gt; sample_continued 
    array([[0.375, 0.375], 
           [0.875, 0.875], 
           [0.625, 0.125], 
           [0.125, 0.625]]) 
 
    Finally, samples can be scaled to bounds. 
 
    &gt;&gt;&gt; l_bounds = [0, 2] 
    &gt;&gt;&gt; u_bounds = [10, 5] 
    &gt;&gt;&gt; qmc.scale(sample_continued, l_bounds, u_bounds) 
    array([[3.75 , 3.125], 
           [8.75 , 4.625], 
           [6.25 , 2.375], 
           [1.25 , 3.875]]) 
 
    &quot;&quot;&quot;</span>

    <span class="s1">MAXDIM: ClassVar[int] = _MAXDIM</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">d: IntNumber</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">scramble: bool = </span><span class="s2">True,</span>
        <span class="s1">bits: IntNumber | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">seed: SeedType = </span><span class="s2">None,</span>
        <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s4"># Used in `scipy.integrate.qmc_quad`</span>
        <span class="s1">self._init_quad = {</span><span class="s3">'d'</span><span class="s1">: d</span><span class="s2">, </span><span class="s3">'scramble'</span><span class="s1">: </span><span class="s2">True, </span><span class="s3">'bits'</span><span class="s1">: bits</span><span class="s2">,</span>
                           <span class="s3">'optimization'</span><span class="s1">: optimization}</span>

        <span class="s1">super().__init__(d=d</span><span class="s2">, </span><span class="s1">optimization=optimization</span><span class="s2">, </span><span class="s1">seed=seed)</span>
        <span class="s2">if </span><span class="s1">d &gt; self.MAXDIM:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">f&quot;Maximum supported dimensionality is </span><span class="s2">{</span><span class="s1">self.MAXDIM</span><span class="s2">}</span><span class="s3">.&quot;</span>
            <span class="s1">)</span>

        <span class="s1">self.bits = bits</span>
        <span class="s1">self.dtype_i: type</span>

        <span class="s2">if </span><span class="s1">self.bits </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.bits = </span><span class="s5">30</span>

        <span class="s2">if </span><span class="s1">self.bits &lt;= </span><span class="s5">32</span><span class="s1">:</span>
            <span class="s1">self.dtype_i = np.uint32</span>
        <span class="s2">elif </span><span class="s5">32 </span><span class="s1">&lt; self.bits &lt;= </span><span class="s5">64</span><span class="s1">:</span>
            <span class="s1">self.dtype_i = np.uint64</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Maximum supported 'bits' is 64&quot;</span><span class="s1">)</span>

        <span class="s1">self.maxn = </span><span class="s5">2</span><span class="s1">**self.bits</span>

        <span class="s4"># v is d x maxbit matrix</span>
        <span class="s1">self._sv: np.ndarray = np.zeros((d</span><span class="s2">, </span><span class="s1">self.bits)</span><span class="s2">, </span><span class="s1">dtype=self.dtype_i)</span>
        <span class="s1">_initialize_v(self._sv</span><span class="s2">, </span><span class="s1">dim=d</span><span class="s2">, </span><span class="s1">bits=self.bits)</span>

        <span class="s2">if not </span><span class="s1">scramble:</span>
            <span class="s1">self._shift: np.ndarray = np.zeros(d</span><span class="s2">, </span><span class="s1">dtype=self.dtype_i)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># scramble self._shift and self._sv</span>
            <span class="s1">self._scramble()</span>

        <span class="s1">self._quasi = self._shift.copy()</span>

        <span class="s4"># normalization constant with the largest possible number</span>
        <span class="s4"># calculate in Python to not overflow int with 2**64</span>
        <span class="s1">self._scale = </span><span class="s5">1.0 </span><span class="s1">/ </span><span class="s5">2 </span><span class="s1">** self.bits</span>

        <span class="s1">self._first_point = (self._quasi * self._scale).reshape(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s4"># explicit casting to float64</span>
        <span class="s1">self._first_point = self._first_point.astype(np.float64)</span>

    <span class="s2">def </span><span class="s1">_scramble(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot;Scramble the sequence using LMS+shift.&quot;&quot;&quot;</span>
        <span class="s4"># Generate shift vector</span>
        <span class="s1">self._shift = np.dot(</span>
            <span class="s1">rng_integers(self.rng</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s1">size=(self.d</span><span class="s2">, </span><span class="s1">self.bits)</span><span class="s2">,</span>
                         <span class="s1">dtype=self.dtype_i)</span><span class="s2">,</span>
            <span class="s5">2 </span><span class="s1">** np.arange(self.bits</span><span class="s2">, </span><span class="s1">dtype=self.dtype_i)</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s4"># Generate lower triangular matrices (stacked across dimensions)</span>
        <span class="s1">ltm = np.tril(rng_integers(self.rng</span><span class="s2">, </span><span class="s5">2</span><span class="s2">,</span>
                                   <span class="s1">size=(self.d</span><span class="s2">, </span><span class="s1">self.bits</span><span class="s2">, </span><span class="s1">self.bits)</span><span class="s2">,</span>
                                   <span class="s1">dtype=self.dtype_i))</span>
        <span class="s1">_cscramble(</span>
            <span class="s1">dim=self.d</span><span class="s2">, </span><span class="s1">bits=self.bits</span><span class="s2">,  </span><span class="s4"># type: ignore[arg-type]</span>
            <span class="s1">ltm=ltm</span><span class="s2">, </span><span class="s1">sv=self._sv</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw next point(s) in the Sobol' sequence. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            Sobol' sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">sample: np.ndarray = np.empty((n</span><span class="s2">, </span><span class="s1">self.d)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s2">if </span><span class="s1">n == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">sample</span>

        <span class="s1">total_n = self.num_generated + n</span>
        <span class="s2">if </span><span class="s1">total_n &gt; self.maxn:</span>
            <span class="s1">msg = (</span>
                <span class="s3">f&quot;At most 2**</span><span class="s2">{</span><span class="s1">self.bits</span><span class="s2">}</span><span class="s3">=</span><span class="s2">{</span><span class="s1">self.maxn</span><span class="s2">} </span><span class="s3">distinct points can be &quot;</span>
                <span class="s3">f&quot;generated. </span><span class="s2">{</span><span class="s1">self.num_generated</span><span class="s2">} </span><span class="s3">points have been previously &quot;</span>
                <span class="s3">f&quot;generated, then: n=</span><span class="s2">{</span><span class="s1">self.num_generated</span><span class="s2">}</span><span class="s3">+</span><span class="s2">{</span><span class="s1">n</span><span class="s2">}</span><span class="s3">=</span><span class="s2">{</span><span class="s1">total_n</span><span class="s2">}</span><span class="s3">. &quot;</span>
            <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">self.bits != </span><span class="s5">64</span><span class="s1">:</span>
                <span class="s1">msg += </span><span class="s3">&quot;Consider increasing `bits`.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">if </span><span class="s1">self.num_generated == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># verify n is 2**n</span>
            <span class="s2">if not </span><span class="s1">(n &amp; (n - </span><span class="s5">1</span><span class="s1">) == </span><span class="s5">0</span><span class="s1">):</span>
                <span class="s1">warnings.warn(</span><span class="s3">&quot;The balance properties of Sobol' points require&quot;</span>
                              <span class="s3">&quot; n to be a power of 2.&quot;</span><span class="s2">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">n == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">sample = self._first_point</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">_draw(</span>
                    <span class="s1">n=n - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">num_gen=self.num_generated</span><span class="s2">, </span><span class="s1">dim=self.d</span><span class="s2">,</span>
                    <span class="s1">scale=self._scale</span><span class="s2">, </span><span class="s1">sv=self._sv</span><span class="s2">, </span><span class="s1">quasi=self._quasi</span><span class="s2">,</span>
                    <span class="s1">sample=sample</span>
                <span class="s1">)</span>
                <span class="s1">sample = np.concatenate(</span>
                    <span class="s1">[self._first_point</span><span class="s2">, </span><span class="s1">sample]</span>
                <span class="s1">)[:n]  </span><span class="s4"># type: ignore[misc]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">_draw(</span>
                <span class="s1">n=n</span><span class="s2">, </span><span class="s1">num_gen=self.num_generated - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">dim=self.d</span><span class="s2">,</span>
                <span class="s1">scale=self._scale</span><span class="s2">, </span><span class="s1">sv=self._sv</span><span class="s2">, </span><span class="s1">quasi=self._quasi</span><span class="s2">,</span>
                <span class="s1">sample=sample</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">sample</span>

    <span class="s2">def </span><span class="s1">random_base2(self</span><span class="s2">, </span><span class="s1">m: IntNumber) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw point(s) from the Sobol' sequence. 
 
        This function draws :math:`n=2^m` points in the parameter space 
        ensuring the balance properties of the sequence. 
 
        Parameters 
        ---------- 
        m : int 
            Logarithm in base 2 of the number of samples; i.e., n = 2^m. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            Sobol' sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">n = </span><span class="s5">2 </span><span class="s1">** m</span>

        <span class="s1">total_n = self.num_generated + n</span>
        <span class="s2">if not </span><span class="s1">(total_n &amp; (total_n - </span><span class="s5">1</span><span class="s1">) == </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;The balance properties of Sobol' points require &quot;</span>
                             <span class="s3">&quot;n to be a power of 2. {0} points have been &quot;</span>
                             <span class="s3">&quot;previously generated, then: n={0}+2**{1}={2}. &quot;</span>
                             <span class="s3">&quot;If you still want to do this, the function &quot;</span>
                             <span class="s3">&quot;'Sobol.random()' can be used.&quot;</span>
                             <span class="s1">.format(self.num_generated</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">total_n))</span>

        <span class="s2">return </span><span class="s1">self.random(n)</span>

    <span class="s2">def </span><span class="s1">reset(self) -&gt; Sobol:</span>
        <span class="s0">&quot;&quot;&quot;Reset the engine to base state. 
 
        Returns 
        ------- 
        engine : Sobol 
            Engine reset to its base state. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">super().reset()</span>
        <span class="s1">self._quasi = self._shift.copy()</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">fast_forward(self</span><span class="s2">, </span><span class="s1">n: IntNumber) -&gt; Sobol:</span>
        <span class="s0">&quot;&quot;&quot;Fast-forward the sequence by `n` positions. 
 
        Parameters 
        ---------- 
        n : int 
            Number of points to skip in the sequence. 
 
        Returns 
        ------- 
        engine : Sobol 
            The fast-forwarded engine. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.num_generated == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">_fast_forward(</span>
                <span class="s1">n=n - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">num_gen=self.num_generated</span><span class="s2">, </span><span class="s1">dim=self.d</span><span class="s2">,</span>
                <span class="s1">sv=self._sv</span><span class="s2">, </span><span class="s1">quasi=self._quasi</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">_fast_forward(</span>
                <span class="s1">n=n</span><span class="s2">, </span><span class="s1">num_gen=self.num_generated - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">dim=self.d</span><span class="s2">,</span>
                <span class="s1">sv=self._sv</span><span class="s2">, </span><span class="s1">quasi=self._quasi</span>
            <span class="s1">)</span>
        <span class="s1">self.num_generated += n</span>
        <span class="s2">return </span><span class="s1">self</span>


<span class="s2">class </span><span class="s1">PoissonDisk(QMCEngine):</span>
    <span class="s0">&quot;&quot;&quot;Poisson disk sampling. 
 
    Parameters 
    ---------- 
    d : int 
        Dimension of the parameter space. 
    radius : float 
        Minimal distance to keep between points when sampling new candidates. 
    hypersphere : {&quot;volume&quot;, &quot;surface&quot;}, optional 
        Sampling strategy to generate potential candidates to be added in the 
        final sample. Default is &quot;volume&quot;. 
 
        * ``volume``: original Bridson algorithm as described in [1]_. 
          New candidates are sampled *within* the hypersphere. 
        * ``surface``: only sample the surface of the hypersphere. 
    ncandidates : int 
        Number of candidates to sample per iteration. More candidates result 
        in a denser sampling as more candidates can be accepted per iteration. 
    optimization : {None, &quot;random-cd&quot;, &quot;lloyd&quot;}, optional 
        Whether to use an optimization scheme to improve the quality after 
        sampling. Note that this is a post-processing step that does not 
        guarantee that all properties of the sample will be conserved. 
        Default is None. 
 
        * ``random-cd``: random permutations of coordinates to lower the 
          centered discrepancy. The best sample based on the centered 
          discrepancy is constantly updated. Centered discrepancy-based 
          sampling shows better space-filling robustness toward 2D and 3D 
          subprojections compared to using other discrepancy measures. 
        * ``lloyd``: Perturb samples using a modified Lloyd-Max algorithm. 
          The process converges to equally spaced samples. 
 
        .. versionadded:: 1.10.0 
    seed : {None, int, `numpy.random.Generator`}, optional 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Notes 
    ----- 
    Poisson disk sampling is an iterative sampling strategy. Starting from 
    a seed sample, `ncandidates` are sampled in the hypersphere 
    surrounding the seed. Candidates bellow a certain `radius` or outside the 
    domain are rejected. New samples are added in a pool of sample seed. The 
    process stops when the pool is empty or when the number of required 
    samples is reached. 
 
    The maximum number of point that a sample can contain is directly linked 
    to the `radius`. As the dimension of the space increases, a higher radius 
    spreads the points further and help overcome the curse of dimensionality. 
    See the :ref:`quasi monte carlo tutorial &lt;quasi-monte-carlo&gt;` for more 
    details. 
 
    .. warning:: 
 
       The algorithm is more suitable for low dimensions and sampling size 
       due to its iterative nature and memory requirements. 
       Selecting a small radius with a high dimension would 
       mean that the space could contain more samples than using lower 
       dimension or a bigger radius. 
 
    Some code taken from [2]_, written consent given on 31.03.2021 
    by the original author, Shamis, for free use in SciPy under 
    the 3-clause BSD. 
 
    References 
    ---------- 
    .. [1] Robert Bridson, &quot;Fast Poisson Disk Sampling in Arbitrary 
       Dimensions.&quot; SIGGRAPH, 2007. 
    .. [2] `StackOverflow &lt;https://stackoverflow.com/questions/66047540&gt;`__. 
 
    Examples 
    -------- 
    Generate a 2D sample using a `radius` of 0.2. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from matplotlib.collections import PatchCollection 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; radius = 0.2 
    &gt;&gt;&gt; engine = qmc.PoissonDisk(d=2, radius=radius, seed=rng) 
    &gt;&gt;&gt; sample = engine.random(20) 
 
    Visualizing the 2D sample and showing that no points are closer than 
    `radius`. ``radius/2`` is used to visualize non-intersecting circles. 
    If two samples are exactly at `radius` from each other, then their circle 
    of radius ``radius/2`` will touch. 
 
    &gt;&gt;&gt; fig, ax = plt.subplots() 
    &gt;&gt;&gt; _ = ax.scatter(sample[:, 0], sample[:, 1]) 
    &gt;&gt;&gt; circles = [plt.Circle((xi, yi), radius=radius/2, fill=False) 
    ...            for xi, yi in sample] 
    &gt;&gt;&gt; collection = PatchCollection(circles, match_original=True) 
    &gt;&gt;&gt; ax.add_collection(collection) 
    &gt;&gt;&gt; _ = ax.set(aspect='equal', xlabel=r'$x_1$', ylabel=r'$x_2$', 
    ...            xlim=[0, 1], ylim=[0, 1]) 
    &gt;&gt;&gt; plt.show() 
 
    Such visualization can be seen as circle packing: how many circle can 
    we put in the space. It is a np-hard problem. The method `fill_space` 
    can be used to add samples until no more samples can be added. This is 
    a hard problem and parameters may need to be adjusted manually. Beware of 
    the dimension: as the dimensionality increases, the number of samples 
    required to fill the space increases exponentially 
    (curse-of-dimensionality). 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">d: IntNumber</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">radius: DecimalNumber = </span><span class="s5">0.05</span><span class="s2">,</span>
        <span class="s1">hypersphere: Literal[</span><span class="s3">&quot;volume&quot;</span><span class="s2">, </span><span class="s3">&quot;surface&quot;</span><span class="s1">] = </span><span class="s3">&quot;volume&quot;</span><span class="s2">,</span>
        <span class="s1">ncandidates: IntNumber = </span><span class="s5">30</span><span class="s2">,</span>
        <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s4"># Used in `scipy.integrate.qmc_quad`</span>
        <span class="s1">self._init_quad = {</span><span class="s3">'d'</span><span class="s1">: d</span><span class="s2">, </span><span class="s3">'radius'</span><span class="s1">: radius</span><span class="s2">,</span>
                           <span class="s3">'hypersphere'</span><span class="s1">: hypersphere</span><span class="s2">,</span>
                           <span class="s3">'ncandidates'</span><span class="s1">: ncandidates</span><span class="s2">,</span>
                           <span class="s3">'optimization'</span><span class="s1">: optimization}</span>
        <span class="s1">super().__init__(d=d</span><span class="s2">, </span><span class="s1">optimization=optimization</span><span class="s2">, </span><span class="s1">seed=seed)</span>

        <span class="s1">hypersphere_sample = {</span>
            <span class="s3">&quot;volume&quot;</span><span class="s1">: self._hypersphere_volume_sample</span><span class="s2">,</span>
            <span class="s3">&quot;surface&quot;</span><span class="s1">: self._hypersphere_surface_sample</span>
        <span class="s1">}</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">self.hypersphere_method = hypersphere_sample[hypersphere]</span>
        <span class="s2">except </span><span class="s1">KeyError </span><span class="s2">as </span><span class="s1">exc:</span>
            <span class="s1">message = (</span>
                <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">hypersphere</span><span class="s2">!r} </span><span class="s3">is not a valid hypersphere sampling&quot;</span>
                <span class="s3">f&quot; method. It must be one of </span><span class="s2">{</span><span class="s1">set(hypersphere_sample)</span><span class="s2">!r}</span><span class="s3">&quot;</span><span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">ValueError(message) </span><span class="s2">from </span><span class="s1">exc</span>

        <span class="s4"># size of the sphere from which the samples are drawn relative to the</span>
        <span class="s4"># size of a disk (radius)</span>
        <span class="s4"># for the surface sampler, all new points are almost exactly 1 radius</span>
        <span class="s4"># away from at least one existing sample +eps to avoid rejection</span>
        <span class="s1">self.radius_factor = </span><span class="s5">2 </span><span class="s2">if </span><span class="s1">hypersphere == </span><span class="s3">&quot;volume&quot; </span><span class="s2">else </span><span class="s5">1.001</span>
        <span class="s1">self.radius = radius</span>
        <span class="s1">self.radius_squared = self.radius**</span><span class="s5">2</span>

        <span class="s4"># sample to generate per iteration in the hypersphere around center</span>
        <span class="s1">self.ncandidates = ncandidates</span>

        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s3">'ignore'</span><span class="s1">):</span>
            <span class="s1">self.cell_size = self.radius / np.sqrt(self.d)</span>
            <span class="s1">self.grid_size = (</span>
                <span class="s1">np.ceil(np.ones(self.d) / self.cell_size)</span>
            <span class="s1">).astype(int)</span>

        <span class="s1">self._initialize_grid_pool()</span>

    <span class="s2">def </span><span class="s1">_initialize_grid_pool(self):</span>
        <span class="s0">&quot;&quot;&quot;Sampling pool and sample grid.&quot;&quot;&quot;</span>
        <span class="s1">self.sample_pool = []</span>
        <span class="s4"># Positions of cells</span>
        <span class="s4"># n-dim value for each grid cell</span>
        <span class="s1">self.sample_grid = np.empty(</span>
            <span class="s1">np.append(self.grid_size</span><span class="s2">, </span><span class="s1">self.d)</span><span class="s2">,</span>
            <span class="s1">dtype=np.float32</span>
        <span class="s1">)</span>
        <span class="s4"># Initialise empty cells with NaNs</span>
        <span class="s1">self.sample_grid.fill(np.nan)</span>

    <span class="s2">def </span><span class="s1">_random(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">workers: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` in the interval ``[0, 1]``. 
 
        Note that it can return fewer samples if the space is full. 
        See the note section of the class. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            QMC sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">n == </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">self.d == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.empty((n</span><span class="s2">, </span><span class="s1">self.d))</span>

        <span class="s2">def </span><span class="s1">in_limits(sample: np.ndarray) -&gt; bool:</span>
            <span class="s2">return </span><span class="s1">(sample.max() &lt;= </span><span class="s5">1.</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(sample.min() &gt;= </span><span class="s5">0.</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">in_neighborhood(candidate: np.ndarray</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">2</span><span class="s1">) -&gt; bool:</span>
            <span class="s0">&quot;&quot;&quot; 
            Check if there are samples closer than ``radius_squared`` to the 
            `candidate` sample. 
            &quot;&quot;&quot;</span>
            <span class="s1">indices = (candidate / self.cell_size).astype(int)</span>
            <span class="s1">ind_min = np.maximum(indices - n</span><span class="s2">, </span><span class="s1">np.zeros(self.d</span><span class="s2">, </span><span class="s1">dtype=int))</span>
            <span class="s1">ind_max = np.minimum(indices + n + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.grid_size)</span>

            <span class="s4"># Check if the center cell is empty</span>
            <span class="s2">if not </span><span class="s1">np.isnan(self.sample_grid[tuple(indices)][</span><span class="s5">0</span><span class="s1">]):</span>
                <span class="s2">return True</span>

            <span class="s1">a = [slice(ind_min[i]</span><span class="s2">, </span><span class="s1">ind_max[i]) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.d)]</span>

            <span class="s4"># guards against: invalid value encountered in less as we are</span>
            <span class="s4"># comparing with nan and returns False. Which is wanted.</span>
            <span class="s2">with </span><span class="s1">np.errstate(invalid=</span><span class="s3">'ignore'</span><span class="s1">):</span>
                <span class="s2">if </span><span class="s1">np.any(</span>
                    <span class="s1">np.sum(</span>
                        <span class="s1">np.square(candidate - self.sample_grid[tuple(a)])</span><span class="s2">,</span>
                        <span class="s1">axis=self.d</span>
                    <span class="s1">) &lt; self.radius_squared</span>
                <span class="s1">):</span>
                    <span class="s2">return True</span>

            <span class="s2">return False</span>

        <span class="s2">def </span><span class="s1">add_sample(candidate: np.ndarray) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
            <span class="s1">self.sample_pool.append(candidate)</span>
            <span class="s1">indices = (candidate / self.cell_size).astype(int)</span>
            <span class="s1">self.sample_grid[tuple(indices)] = candidate</span>
            <span class="s1">curr_sample.append(candidate)</span>

        <span class="s1">curr_sample: list[np.ndarray] = []</span>

        <span class="s2">if </span><span class="s1">len(self.sample_pool) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># the pool is being initialized with a single random sample</span>
            <span class="s1">add_sample(self.rng.random(self.d))</span>
            <span class="s1">num_drawn = </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">num_drawn = </span><span class="s5">0</span>

        <span class="s4"># exhaust sample pool to have up to n sample</span>
        <span class="s2">while </span><span class="s1">len(self.sample_pool) </span><span class="s2">and </span><span class="s1">num_drawn &lt; n:</span>
            <span class="s4"># select a sample from the available pool</span>
            <span class="s1">idx_center = rng_integers(self.rng</span><span class="s2">, </span><span class="s1">len(self.sample_pool))</span>
            <span class="s1">center = self.sample_pool[idx_center]</span>
            <span class="s2">del </span><span class="s1">self.sample_pool[idx_center]</span>

            <span class="s4"># generate candidates around the center sample</span>
            <span class="s1">candidates = self.hypersphere_method(</span>
                <span class="s1">center</span><span class="s2">, </span><span class="s1">self.radius * self.radius_factor</span><span class="s2">, </span><span class="s1">self.ncandidates</span>
            <span class="s1">)</span>

            <span class="s4"># keep candidates that satisfy some conditions</span>
            <span class="s2">for </span><span class="s1">candidate </span><span class="s2">in </span><span class="s1">candidates:</span>
                <span class="s2">if </span><span class="s1">in_limits(candidate) </span><span class="s2">and not </span><span class="s1">in_neighborhood(candidate):</span>
                    <span class="s1">add_sample(candidate)</span>

                    <span class="s1">num_drawn += </span><span class="s5">1</span>
                    <span class="s2">if </span><span class="s1">num_drawn &gt;= n:</span>
                        <span class="s2">break</span>

        <span class="s1">self.num_generated += num_drawn</span>
        <span class="s2">return </span><span class="s1">np.array(curr_sample)</span>

    <span class="s2">def </span><span class="s1">fill_space(self) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw ``n`` samples in the interval ``[0, 1]``. 
 
        Unlike `random`, this method will try to add points until 
        the space is full. Depending on ``candidates`` (and to a lesser extent 
        other parameters), some empty areas can still be present in the sample. 
 
        .. warning:: 
 
           This can be extremely slow in high dimensions or if the 
           ``radius`` is very small-with respect to the dimensionality. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            QMC sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.random(np.inf)  </span><span class="s4"># type: ignore[arg-type]</span>

    <span class="s2">def </span><span class="s1">reset(self) -&gt; PoissonDisk:</span>
        <span class="s0">&quot;&quot;&quot;Reset the engine to base state. 
 
        Returns 
        ------- 
        engine : PoissonDisk 
            Engine reset to its base state. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">super().reset()</span>
        <span class="s1">self._initialize_grid_pool()</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">_hypersphere_volume_sample(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">center: np.ndarray</span><span class="s2">, </span><span class="s1">radius: DecimalNumber</span><span class="s2">,</span>
        <span class="s1">candidates: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Uniform sampling within hypersphere.&quot;&quot;&quot;</span>
        <span class="s4"># should remove samples within r/2</span>
        <span class="s1">x = self.rng.standard_normal(size=(candidates</span><span class="s2">, </span><span class="s1">self.d))</span>
        <span class="s1">ssq = np.sum(x**</span><span class="s5">2</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">fr = radius * gammainc(self.d/</span><span class="s5">2</span><span class="s2">, </span><span class="s1">ssq/</span><span class="s5">2</span><span class="s1">)**(</span><span class="s5">1</span><span class="s1">/self.d) / np.sqrt(ssq)</span>
        <span class="s1">fr_tiled = np.tile(</span>
            <span class="s1">fr.reshape(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.d)  </span><span class="s4"># type: ignore[arg-type]</span>
        <span class="s1">)</span>
        <span class="s1">p = center + np.multiply(x</span><span class="s2">, </span><span class="s1">fr_tiled)</span>
        <span class="s2">return </span><span class="s1">p</span>

    <span class="s2">def </span><span class="s1">_hypersphere_surface_sample(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">center: np.ndarray</span><span class="s2">, </span><span class="s1">radius: DecimalNumber</span><span class="s2">,</span>
        <span class="s1">candidates: IntNumber = </span><span class="s5">1</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Uniform sampling on the hypersphere's surface.&quot;&quot;&quot;</span>
        <span class="s1">vec = self.rng.standard_normal(size=(candidates</span><span class="s2">, </span><span class="s1">self.d))</span>
        <span class="s1">vec /= np.linalg.norm(vec</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">p = center + np.multiply(vec</span><span class="s2">, </span><span class="s1">radius)</span>
        <span class="s2">return </span><span class="s1">p</span>


<span class="s2">class </span><span class="s1">MultivariateNormalQMC:</span>
    <span class="s0">r&quot;&quot;&quot;QMC sampling from a multivariate Normal :math:`N(\mu, \Sigma)`. 
 
    Parameters 
    ---------- 
    mean : array_like (d,) 
        The mean vector. Where ``d`` is the dimension. 
    cov : array_like (d, d), optional 
        The covariance matrix. If omitted, use `cov_root` instead. 
        If both `cov` and `cov_root` are omitted, use the identity matrix. 
    cov_root : array_like (d, d'), optional 
        A root decomposition of the covariance matrix, where ``d'`` may be less 
        than ``d`` if the covariance is not full rank. If omitted, use `cov`. 
    inv_transform : bool, optional 
        If True, use inverse transform instead of Box-Muller. Default is True. 
    engine : QMCEngine, optional 
        Quasi-Monte Carlo engine sampler. If None, `Sobol` is used. 
    seed : {None, int, `numpy.random.Generator`}, optional 
        Used only if `engine` is None. 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; dist = qmc.MultivariateNormalQMC(mean=[0, 5], cov=[[1, 0], [0, 1]]) 
    &gt;&gt;&gt; sample = dist.random(512) 
    &gt;&gt;&gt; _ = plt.scatter(sample[:, 0], sample[:, 1]) 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">mean: npt.ArrayLike</span><span class="s2">, </span><span class="s1">cov: npt.ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">*</span><span class="s2">,</span>
            <span class="s1">cov_root: npt.ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
            <span class="s1">inv_transform: bool = </span><span class="s2">True,</span>
            <span class="s1">engine: QMCEngine | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
            <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">mean = np.array(mean</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">d = mean.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">cov </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s4"># covariance matrix provided</span>
            <span class="s1">cov = np.array(cov</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False, </span><span class="s1">ndmin=</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s4"># check for square/symmetric cov matrix and mean vector has the</span>
            <span class="s4"># same d</span>
            <span class="s2">if not </span><span class="s1">mean.shape[</span><span class="s5">0</span><span class="s1">] == cov.shape[</span><span class="s5">0</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Dimension mismatch between mean and &quot;</span>
                                 <span class="s3">&quot;covariance.&quot;</span><span class="s1">)</span>
            <span class="s2">if not </span><span class="s1">np.allclose(cov</span><span class="s2">, </span><span class="s1">cov.transpose()):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Covariance matrix is not symmetric.&quot;</span><span class="s1">)</span>
            <span class="s4"># compute Cholesky decomp; if it fails, do the eigen decomposition</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">cov_root = np.linalg.cholesky(cov).transpose()</span>
            <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                <span class="s1">eigval</span><span class="s2">, </span><span class="s1">eigvec = np.linalg.eigh(cov)</span>
                <span class="s2">if not </span><span class="s1">np.all(eigval &gt;= -</span><span class="s5">1.0e-8</span><span class="s1">):</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Covariance matrix not PSD.&quot;</span><span class="s1">)</span>
                <span class="s1">eigval = np.clip(eigval</span><span class="s2">, </span><span class="s5">0.0</span><span class="s2">, None</span><span class="s1">)</span>
                <span class="s1">cov_root = (eigvec * np.sqrt(eigval)).transpose()</span>
        <span class="s2">elif </span><span class="s1">cov_root </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s4"># root decomposition provided</span>
            <span class="s1">cov_root = np.atleast_2d(cov_root)</span>
            <span class="s2">if not </span><span class="s1">mean.shape[</span><span class="s5">0</span><span class="s1">] == cov_root.shape[</span><span class="s5">0</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Dimension mismatch between mean and &quot;</span>
                                 <span class="s3">&quot;covariance.&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># corresponds to identity covariance matrix</span>
            <span class="s1">cov_root = </span><span class="s2">None</span>

        <span class="s1">self._inv_transform = inv_transform</span>

        <span class="s2">if not </span><span class="s1">inv_transform:</span>
            <span class="s4"># to apply Box-Muller, we need an even number of dimensions</span>
            <span class="s1">engine_dim = </span><span class="s5">2 </span><span class="s1">* math.ceil(d / </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">engine_dim = d</span>
        <span class="s2">if </span><span class="s1">engine </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.engine = Sobol(</span>
                <span class="s1">d=engine_dim</span><span class="s2">, </span><span class="s1">scramble=</span><span class="s2">True, </span><span class="s1">bits=</span><span class="s5">30</span><span class="s2">, </span><span class="s1">seed=seed</span>
            <span class="s1">)  </span><span class="s4"># type: QMCEngine</span>
        <span class="s2">elif </span><span class="s1">isinstance(engine</span><span class="s2">, </span><span class="s1">QMCEngine):</span>
            <span class="s2">if </span><span class="s1">engine.d != engine_dim:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Dimension of `engine` must be consistent&quot;</span>
                                 <span class="s3">&quot; with dimensions of mean and covariance.&quot;</span>
                                 <span class="s3">&quot; If `inv_transform` is False, it must be&quot;</span>
                                 <span class="s3">&quot; an even number.&quot;</span><span class="s1">)</span>
            <span class="s1">self.engine = engine</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`engine` must be an instance of &quot;</span>
                             <span class="s3">&quot;`scipy.stats.qmc.QMCEngine` or `None`.&quot;</span><span class="s1">)</span>

        <span class="s1">self._mean = mean</span>
        <span class="s1">self._corr_matrix = cov_root</span>

        <span class="s1">self._d = d</span>

    <span class="s2">def </span><span class="s1">random(self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` QMC samples from the multivariate Normal. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            Sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">base_samples = self._standard_normal_samples(n)</span>
        <span class="s2">return </span><span class="s1">self._correlate(base_samples)</span>

    <span class="s2">def </span><span class="s1">_correlate(self</span><span class="s2">, </span><span class="s1">base_samples: np.ndarray) -&gt; np.ndarray:</span>
        <span class="s2">if </span><span class="s1">self._corr_matrix </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">base_samples @ self._corr_matrix + self._mean</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># avoid multiplying with identity here</span>
            <span class="s2">return </span><span class="s1">base_samples + self._mean</span>

    <span class="s2">def </span><span class="s1">_standard_normal_samples(self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` QMC samples from the standard Normal :math:`N(0, I_d)`. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
 
        Returns 
        ------- 
        sample : array_like (n, d) 
            Sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s4"># get base samples</span>
        <span class="s1">samples = self.engine.random(n)</span>
        <span class="s2">if </span><span class="s1">self._inv_transform:</span>
            <span class="s4"># apply inverse transform</span>
            <span class="s4"># (values to close to 0/1 result in inf values)</span>
            <span class="s2">return </span><span class="s1">stats.norm.ppf(</span><span class="s5">0.5 </span><span class="s1">+ (</span><span class="s5">1 </span><span class="s1">- </span><span class="s5">1e-10</span><span class="s1">) * (samples - </span><span class="s5">0.5</span><span class="s1">))  </span><span class="s4"># type: ignore[attr-defined]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># apply Box-Muller transform (note: indexes starting from 1)</span>
            <span class="s1">even = np.arange(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">samples.shape[-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">Rs = np.sqrt(-</span><span class="s5">2 </span><span class="s1">* np.log(samples[:</span><span class="s2">, </span><span class="s1">even]))</span>
            <span class="s1">thetas = </span><span class="s5">2 </span><span class="s1">* math.pi * samples[:</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">+ even]</span>
            <span class="s1">cos = np.cos(thetas)</span>
            <span class="s1">sin = np.sin(thetas)</span>
            <span class="s1">transf_samples = np.stack([Rs * cos</span><span class="s2">, </span><span class="s1">Rs * sin]</span><span class="s2">,</span>
                                      <span class="s1">-</span><span class="s5">1</span><span class="s1">).reshape(n</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s4"># make sure we only return the number of dimension requested</span>
            <span class="s2">return </span><span class="s1">transf_samples[:</span><span class="s2">, </span><span class="s1">: self._d]</span>


<span class="s2">class </span><span class="s1">MultinomialQMC:</span>
    <span class="s0">r&quot;&quot;&quot;QMC sampling from a multinomial distribution. 
 
    Parameters 
    ---------- 
    pvals : array_like (k,) 
        Vector of probabilities of size ``k``, where ``k`` is the number 
        of categories. Elements must be non-negative and sum to 1. 
    n_trials : int 
        Number of trials. 
    engine : QMCEngine, optional 
        Quasi-Monte Carlo engine sampler. If None, `Sobol` is used. 
    seed : {None, int, `numpy.random.Generator`}, optional 
        Used only if `engine` is None. 
        If `seed` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(seed)``. 
        If `seed` is already a ``Generator`` instance, then the provided 
        instance is used. 
 
    Examples 
    -------- 
    Let's define 3 categories and for a given sample, the sum of the trials 
    of each category is 8. The number of trials per category is determined 
    by the `pvals` associated to each category. 
    Then, we sample this distribution 64 times. 
 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; dist = qmc.MultinomialQMC( 
    ...     pvals=[0.2, 0.4, 0.4], n_trials=10, engine=qmc.Halton(d=1) 
    ... ) 
    &gt;&gt;&gt; sample = dist.random(64) 
 
    We can plot the sample and verify that the median of number of trials 
    for each category is following the `pvals`. That would be 
    ``pvals * n_trials = [2, 4, 4]``. 
 
    &gt;&gt;&gt; fig, ax = plt.subplots() 
    &gt;&gt;&gt; ax.yaxis.get_major_locator().set_params(integer=True) 
    &gt;&gt;&gt; _ = ax.boxplot(sample) 
    &gt;&gt;&gt; ax.set(xlabel=&quot;Categories&quot;, ylabel=&quot;Trials&quot;) 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">pvals: npt.ArrayLike</span><span class="s2">, </span><span class="s1">n_trials: IntNumber</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">, </span><span class="s1">engine: QMCEngine | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">seed: SeedType = </span><span class="s2">None</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">self.pvals = np.array(pvals</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">np.min(pvals) &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Elements of pvals must be non-negative.'</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">np.isclose(np.sum(pvals)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Elements of pvals must sum to 1.'</span><span class="s1">)</span>
        <span class="s1">self.n_trials = n_trials</span>
        <span class="s2">if </span><span class="s1">engine </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.engine = Sobol(</span>
                <span class="s1">d=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">scramble=</span><span class="s2">True, </span><span class="s1">bits=</span><span class="s5">30</span><span class="s2">, </span><span class="s1">seed=seed</span>
            <span class="s1">)  </span><span class="s4"># type: QMCEngine</span>
        <span class="s2">elif </span><span class="s1">isinstance(engine</span><span class="s2">, </span><span class="s1">QMCEngine):</span>
            <span class="s2">if </span><span class="s1">engine.d != </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Dimension of `engine` must be 1.&quot;</span><span class="s1">)</span>
            <span class="s1">self.engine = engine</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`engine` must be an instance of &quot;</span>
                             <span class="s3">&quot;`scipy.stats.qmc.QMCEngine` or `None`.&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">random(self</span><span class="s2">, </span><span class="s1">n: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot;Draw `n` QMC samples from the multinomial distribution. 
 
        Parameters 
        ---------- 
        n : int, optional 
            Number of samples to generate in the parameter space. Default is 1. 
 
        Returns 
        ------- 
        samples : array_like (n, pvals) 
            Sample. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">sample = np.empty((n</span><span class="s2">, </span><span class="s1">len(self.pvals)))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(n):</span>
            <span class="s1">base_draws = self.engine.random(self.n_trials).ravel()</span>
            <span class="s1">p_cumulative = np.empty_like(self.pvals</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">_fill_p_cumulative(np.array(self.pvals</span><span class="s2">, </span><span class="s1">dtype=float)</span><span class="s2">, </span><span class="s1">p_cumulative)</span>
            <span class="s1">sample_ = np.zeros_like(self.pvals</span><span class="s2">, </span><span class="s1">dtype=int)</span>
            <span class="s1">_categorize(base_draws</span><span class="s2">, </span><span class="s1">p_cumulative</span><span class="s2">, </span><span class="s1">sample_)</span>
            <span class="s1">sample[i] = sample_</span>
        <span class="s2">return </span><span class="s1">sample</span>


<span class="s2">def </span><span class="s1">_select_optimizer(</span>
    <span class="s1">optimization: Literal[</span><span class="s3">&quot;random-cd&quot;</span><span class="s2">, </span><span class="s3">&quot;lloyd&quot;</span><span class="s1">] | </span><span class="s2">None, </span><span class="s1">config: dict</span>
<span class="s1">) -&gt; Callable | </span><span class="s2">None</span><span class="s1">:</span>
    <span class="s0">&quot;&quot;&quot;A factory for optimization methods.&quot;&quot;&quot;</span>
    <span class="s1">optimization_method: dict[str</span><span class="s2">, </span><span class="s1">Callable] = {</span>
        <span class="s3">&quot;random-cd&quot;</span><span class="s1">: _random_cd</span><span class="s2">,</span>
        <span class="s3">&quot;lloyd&quot;</span><span class="s1">: _lloyd_centroidal_voronoi_tessellation</span>
    <span class="s1">}</span>

    <span class="s1">optimizer: partial | </span><span class="s2">None</span>
    <span class="s2">if </span><span class="s1">optimization </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">optimization = optimization.lower()  </span><span class="s4"># type: ignore[assignment]</span>
            <span class="s1">optimizer_ = optimization_method[optimization]</span>
        <span class="s2">except </span><span class="s1">KeyError </span><span class="s2">as </span><span class="s1">exc:</span>
            <span class="s1">message = (</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">optimization</span><span class="s2">!r} </span><span class="s3">is not a valid optimization&quot;</span>
                       <span class="s3">f&quot; method. It must be one of&quot;</span>
                       <span class="s3">f&quot; </span><span class="s2">{</span><span class="s1">set(optimization_method)</span><span class="s2">!r}</span><span class="s3">&quot;</span><span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">ValueError(message) </span><span class="s2">from </span><span class="s1">exc</span>

        <span class="s4"># config</span>
        <span class="s1">optimizer = partial(optimizer_</span><span class="s2">, </span><span class="s1">**config)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">optimizer = </span><span class="s2">None</span>

    <span class="s2">return </span><span class="s1">optimizer</span>


<span class="s2">def </span><span class="s1">_random_cd(</span>
    <span class="s1">best_sample: np.ndarray</span><span class="s2">, </span><span class="s1">n_iters: int</span><span class="s2">, </span><span class="s1">n_nochange: int</span><span class="s2">, </span><span class="s1">rng: GeneratorType</span><span class="s2">,</span>
    <span class="s1">**kwargs: dict</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Optimal LHS on CD. 
 
    Create a base LHS and do random permutations of coordinates to 
    lower the centered discrepancy. 
    Because it starts with a normal LHS, it also works with the 
    `centered` keyword argument. 
 
    Two stopping criterion are used to stop the algorithm: at most, 
    `n_iters` iterations are performed; or if there is no improvement 
    for `n_nochange` consecutive iterations. 
    &quot;&quot;&quot;</span>
    <span class="s2">del </span><span class="s1">kwargs  </span><span class="s4"># only use keywords which are defined, needed by factory</span>

    <span class="s1">n</span><span class="s2">, </span><span class="s1">d = best_sample.shape</span>

    <span class="s2">if </span><span class="s1">d == </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">n == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">np.empty((n</span><span class="s2">, </span><span class="s1">d))</span>

    <span class="s2">if </span><span class="s1">d == </span><span class="s5">1 </span><span class="s2">or </span><span class="s1">n == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s4"># discrepancy measures are invariant under permuting factors and runs</span>
        <span class="s2">return </span><span class="s1">best_sample</span>

    <span class="s1">best_disc = discrepancy(best_sample)</span>

    <span class="s1">bounds = ([</span><span class="s5">0</span><span class="s2">, </span><span class="s1">d - </span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
              <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n - </span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
              <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n - </span><span class="s5">1</span><span class="s1">])</span>

    <span class="s1">n_nochange_ = </span><span class="s5">0</span>
    <span class="s1">n_iters_ = </span><span class="s5">0</span>
    <span class="s2">while </span><span class="s1">n_nochange_ &lt; n_nochange </span><span class="s2">and </span><span class="s1">n_iters_ &lt; n_iters:</span>
        <span class="s1">n_iters_ += </span><span class="s5">1</span>

        <span class="s1">col = rng_integers(rng</span><span class="s2">, </span><span class="s1">*bounds[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">endpoint=</span><span class="s2">True</span><span class="s1">)  </span><span class="s4"># type: ignore[misc]</span>
        <span class="s1">row_1 = rng_integers(rng</span><span class="s2">, </span><span class="s1">*bounds[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">endpoint=</span><span class="s2">True</span><span class="s1">)  </span><span class="s4"># type: ignore[misc]</span>
        <span class="s1">row_2 = rng_integers(rng</span><span class="s2">, </span><span class="s1">*bounds[</span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">endpoint=</span><span class="s2">True</span><span class="s1">)  </span><span class="s4"># type: ignore[misc]</span>
        <span class="s1">disc = _perturb_discrepancy(best_sample</span><span class="s2">,</span>
                                    <span class="s1">row_1</span><span class="s2">, </span><span class="s1">row_2</span><span class="s2">, </span><span class="s1">col</span><span class="s2">,</span>
                                    <span class="s1">best_disc)</span>
        <span class="s2">if </span><span class="s1">disc &lt; best_disc:</span>
            <span class="s1">best_sample[row_1</span><span class="s2">, </span><span class="s1">col]</span><span class="s2">, </span><span class="s1">best_sample[row_2</span><span class="s2">, </span><span class="s1">col] = (</span>
                <span class="s1">best_sample[row_2</span><span class="s2">, </span><span class="s1">col]</span><span class="s2">, </span><span class="s1">best_sample[row_1</span><span class="s2">, </span><span class="s1">col])</span>

            <span class="s1">best_disc = disc</span>
            <span class="s1">n_nochange_ = </span><span class="s5">0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">n_nochange_ += </span><span class="s5">1</span>

    <span class="s2">return </span><span class="s1">best_sample</span>


<span class="s2">def </span><span class="s1">_l1_norm(sample: np.ndarray) -&gt; float:</span>
    <span class="s2">return </span><span class="s1">distance.pdist(sample</span><span class="s2">, </span><span class="s3">'cityblock'</span><span class="s1">).min()</span>


<span class="s2">def </span><span class="s1">_lloyd_iteration(</span>
    <span class="s1">sample: np.ndarray</span><span class="s2">,</span>
    <span class="s1">decay: float</span><span class="s2">,</span>
    <span class="s1">qhull_options: str</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Lloyd-Max algorithm iteration. 
 
    Based on the implementation of Stéfan van der Walt: 
 
    https://github.com/stefanv/lloyd 
 
    which is: 
 
        Copyright (c) 2021-04-21 Stéfan van der Walt 
        https://github.com/stefanv/lloyd 
        MIT License 
 
    Parameters 
    ---------- 
    sample : array_like (n, d) 
        The sample to iterate on. 
    decay : float 
        Relaxation decay. A positive value would move the samples toward 
        their centroid, and negative value would move them away. 
        1 would move the samples to their centroid. 
    qhull_options : str 
        Additional options to pass to Qhull. See Qhull manual 
        for details. (Default: &quot;Qbb Qc Qz Qj Qx&quot; for ndim &gt; 4 and 
        &quot;Qbb Qc Qz Qj&quot; otherwise.) 
 
    Returns 
    ------- 
    sample : array_like (n, d) 
        The sample after an iteration of Lloyd's algorithm. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">new_sample = np.empty_like(sample)</span>

    <span class="s1">voronoi = Voronoi(sample</span><span class="s2">, </span><span class="s1">qhull_options=qhull_options)</span>

    <span class="s2">for </span><span class="s1">ii</span><span class="s2">, </span><span class="s1">idx </span><span class="s2">in </span><span class="s1">enumerate(voronoi.point_region):</span>
        <span class="s4"># the region is a series of indices into self.voronoi.vertices</span>
        <span class="s4"># remove samples at infinity, designated by index -1</span>
        <span class="s1">region = [i </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">voronoi.regions[idx] </span><span class="s2">if </span><span class="s1">i != -</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s4"># get the vertices for this region</span>
        <span class="s1">verts = voronoi.vertices[region]</span>

        <span class="s4"># clipping would be wrong, we need to intersect</span>
        <span class="s4"># verts = np.clip(verts, 0, 1)</span>

        <span class="s4"># move samples towards centroids:</span>
        <span class="s4"># Centroid in n-D is the mean for uniformly distributed nodes</span>
        <span class="s4"># of a geometry.</span>
        <span class="s1">centroid = np.mean(verts</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">new_sample[ii] = sample[ii] + (centroid - sample[ii]) * decay</span>

    <span class="s4"># only update sample to centroid within the region</span>
    <span class="s1">is_valid = np.all(np.logical_and(new_sample &gt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">new_sample &lt;= </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">sample[is_valid] = new_sample[is_valid]</span>

    <span class="s2">return </span><span class="s1">sample</span>


<span class="s2">def </span><span class="s1">_lloyd_centroidal_voronoi_tessellation(</span>
    <span class="s1">sample: npt.ArrayLike</span><span class="s2">,</span>
    <span class="s1">*</span><span class="s2">,</span>
    <span class="s1">tol: DecimalNumber = </span><span class="s5">1e-5</span><span class="s2">,</span>
    <span class="s1">maxiter: IntNumber = </span><span class="s5">10</span><span class="s2">,</span>
    <span class="s1">qhull_options: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">**kwargs: dict</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;Approximate Centroidal Voronoi Tessellation. 
 
    Perturb samples in N-dimensions using Lloyd-Max algorithm. 
 
    Parameters 
    ---------- 
    sample : array_like (n, d) 
        The sample to iterate on. With ``n`` the number of samples and ``d`` 
        the dimension. Samples must be in :math:`[0, 1]^d`, with ``d&gt;=2``. 
    tol : float, optional 
        Tolerance for termination. If the min of the L1-norm over the samples 
        changes less than `tol`, it stops the algorithm. Default is 1e-5. 
    maxiter : int, optional 
        Maximum number of iterations. It will stop the algorithm even if 
        `tol` is above the threshold. 
        Too many iterations tend to cluster the samples as a hypersphere. 
        Default is 10. 
    qhull_options : str, optional 
        Additional options to pass to Qhull. See Qhull manual 
        for details. (Default: &quot;Qbb Qc Qz Qj Qx&quot; for ndim &gt; 4 and 
        &quot;Qbb Qc Qz Qj&quot; otherwise.) 
 
    Returns 
    ------- 
    sample : array_like (n, d) 
        The sample after being processed by Lloyd-Max algorithm. 
 
    Notes 
    ----- 
    Lloyd-Max algorithm is an iterative process with the purpose of improving 
    the dispersion of samples. For given sample: (i) compute a Voronoi 
    Tessellation; (ii) find the centroid of each Voronoi cell; (iii) move the 
    samples toward the centroid of their respective cell. See [1]_, [2]_. 
 
    A relaxation factor is used to control how fast samples can move at each 
    iteration. This factor is starting at 2 and ending at 1 after `maxiter` 
    following an exponential decay. 
 
    The process converges to equally spaced samples. It implies that measures 
    like the discrepancy could suffer from too many iterations. On the other 
    hand, L1 and L2 distances should improve. This is especially true with 
    QMC methods which tend to favor the discrepancy over other criteria. 
 
    .. note:: 
 
        The current implementation does not intersect the Voronoi Tessellation 
        with the boundaries. This implies that for a low number of samples, 
        empirically below 20, no Voronoi cell is touching the boundaries. 
        Hence, samples cannot be moved close to the boundaries. 
 
        Further improvements could consider the samples at infinity so that 
        all boundaries are segments of some Voronoi cells. This would fix 
        the computation of the centroid position. 
 
    .. warning:: 
 
       The Voronoi Tessellation step is expensive and quickly becomes 
       intractable with dimensions as low as 10 even for a sample 
       of size as low as 1000. 
 
    .. versionadded:: 1.9.0 
 
    References 
    ---------- 
    .. [1] Lloyd. &quot;Least Squares Quantization in PCM&quot;. 
       IEEE Transactions on Information Theory, 1982. 
    .. [2] Max J. &quot;Quantizing for minimum distortion&quot;. 
       IEEE Transactions on Information Theory, 1960. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.spatial import distance 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; sample = rng.random((128, 2)) 
 
    .. note:: 
 
        The samples need to be in :math:`[0, 1]^d`. `scipy.stats.qmc.scale` 
        can be used to scale the samples from their 
        original bounds to :math:`[0, 1]^d`. And back to their original bounds. 
 
    Compute the quality of the sample using the L1 criterion. 
 
    &gt;&gt;&gt; def l1_norm(sample): 
    ...    return distance.pdist(sample, 'cityblock').min() 
 
    &gt;&gt;&gt; l1_norm(sample) 
    0.00161...  # random 
 
    Now process the sample using Lloyd's algorithm and check the improvement 
    on the L1. The value should increase. 
 
    &gt;&gt;&gt; sample = _lloyd_centroidal_voronoi_tessellation(sample) 
    &gt;&gt;&gt; l1_norm(sample) 
    0.0278...  # random 
 
    &quot;&quot;&quot;</span>
    <span class="s2">del </span><span class="s1">kwargs  </span><span class="s4"># only use keywords which are defined, needed by factory</span>

    <span class="s1">sample = np.asarray(sample).copy()</span>

    <span class="s2">if not </span><span class="s1">sample.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'`sample` is not a 2D array'</span><span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">sample.shape[</span><span class="s5">1</span><span class="s1">] &gt;= </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'`sample` dimension is not &gt;= 2'</span><span class="s1">)</span>

    <span class="s4"># Checking that sample is within the hypercube</span>
    <span class="s2">if </span><span class="s1">(sample.max() &gt; </span><span class="s5">1.</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(sample.min() &lt; </span><span class="s5">0.</span><span class="s1">):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'`sample` is not in unit hypercube'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">qhull_options </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">qhull_options = </span><span class="s3">'Qbb Qc Qz QJ'</span>

        <span class="s2">if </span><span class="s1">sample.shape[</span><span class="s5">1</span><span class="s1">] &gt;= </span><span class="s5">5</span><span class="s1">:</span>
            <span class="s1">qhull_options += </span><span class="s3">' Qx'</span>

    <span class="s4"># Fit an exponential to be 2 at 0 and 1 at `maxiter`.</span>
    <span class="s4"># The decay is used for relaxation.</span>
    <span class="s4"># analytical solution for y=exp(-maxiter/x) - 0.1</span>
    <span class="s1">root = -maxiter / np.log(</span><span class="s5">0.1</span><span class="s1">)</span>
    <span class="s1">decay = [np.exp(-x / root)+</span><span class="s5">0.9 </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">range(maxiter)]</span>

    <span class="s1">l1_old = _l1_norm(sample=sample)</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(maxiter):</span>
        <span class="s1">sample = _lloyd_iteration(</span>
                <span class="s1">sample=sample</span><span class="s2">, </span><span class="s1">decay=decay[i]</span><span class="s2">,</span>
                <span class="s1">qhull_options=qhull_options</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s1">l1_new = _l1_norm(sample=sample)</span>

        <span class="s2">if </span><span class="s1">abs(l1_new - l1_old) &lt; tol:</span>
            <span class="s2">break</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">l1_old = l1_new</span>

    <span class="s2">return </span><span class="s1">sample</span>


<span class="s2">def </span><span class="s1">_validate_workers(workers: IntNumber = </span><span class="s5">1</span><span class="s1">) -&gt; IntNumber:</span>
    <span class="s0">&quot;&quot;&quot;Validate `workers` based on platform and value. 
 
    Parameters 
    ---------- 
    workers : int, optional 
        Number of workers to use for parallel processing. If -1 is 
        given all CPU threads are used. Default is 1. 
 
    Returns 
    ------- 
    Workers : int 
        Number of CPU used by the algorithm 
 
    &quot;&quot;&quot;</span>
    <span class="s1">workers = int(workers)</span>
    <span class="s2">if </span><span class="s1">workers == -</span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">workers = os.cpu_count()  </span><span class="s4"># type: ignore[assignment]</span>
        <span class="s2">if </span><span class="s1">workers </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
                <span class="s3">&quot;Cannot determine the number of cpus using os.cpu_count(), &quot;</span>
                <span class="s3">&quot;cannot use -1 for the number of workers&quot;</span>
            <span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">workers &lt;= </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;Invalid number of workers: </span><span class="s2">{</span><span class="s1">workers</span><span class="s2">}</span><span class="s3">, must be -1 &quot;</span>
                         <span class="s3">&quot;or &gt; 0&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">workers</span>


<span class="s2">def </span><span class="s1">_validate_bounds(</span>
    <span class="s1">l_bounds: npt.ArrayLike</span><span class="s2">, </span><span class="s1">u_bounds: npt.ArrayLike</span><span class="s2">, </span><span class="s1">d: int</span>
<span class="s1">) -&gt; tuple[np.ndarray</span><span class="s2">, </span><span class="s1">...]:</span>
    <span class="s0">&quot;&quot;&quot;Bounds input validation. 
 
    Parameters 
    ---------- 
    l_bounds, u_bounds : array_like (d,) 
        Lower and upper bounds. 
    d : int 
        Dimension to use for broadcasting. 
 
    Returns 
    ------- 
    l_bounds, u_bounds : array_like (d,) 
        Lower and upper bounds. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">lower = np.broadcast_to(l_bounds</span><span class="s2">, </span><span class="s1">d)</span>
        <span class="s1">upper = np.broadcast_to(u_bounds</span><span class="s2">, </span><span class="s1">d)</span>
    <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">exc:</span>
        <span class="s1">msg = (</span><span class="s3">&quot;'l_bounds' and 'u_bounds' must be broadcastable and respect&quot;</span>
               <span class="s3">&quot; the sample dimension&quot;</span><span class="s1">)</span>
        <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from </span><span class="s1">exc</span>

    <span class="s2">if not </span><span class="s1">np.all(lower &lt; upper):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Bounds are not consistent 'l_bounds' &lt; 'u_bounds'&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper</span>
</pre>
</body>
</html>
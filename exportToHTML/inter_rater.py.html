<html>
<head>
<title>inter_rater.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
inter_rater.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot;Inter Rater Agreement 
 
contains 
-------- 
fleiss_kappa 
cohens_kappa 
 
aggregate_raters: 
    helper function to get data into fleiss_kappa format 
to_table: 
    helper function to create contingency table, can be used for cohens_kappa 
 
Created on Thu Dec 06 22:57:56 2012 
Author: Josef Perktold 
License: BSD-3 
 
References 
---------- 
Wikipedia: kappa's initially based on these two pages 
    https://en.wikipedia.org/wiki/Fleiss%27_kappa 
    https://en.wikipedia.org/wiki/Cohen's_kappa 
SAS-Manual : formulas for cohens_kappa, especially variances 
see also R package irr 
 
TODO 
---- 
standard errors and hypothesis tests for fleiss_kappa 
other statistics and tests, 
   in R package irr, SAS has more 
inconsistent internal naming, changed variable names as I added more 
   functionality 
convenience functions to create required data format from raw data 
   DONE 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats  </span><span class="s0">#get rid of this? need only norm.sf</span>


<span class="s3">class </span><span class="s1">ResultsBunch(dict):</span>

    <span class="s1">template = </span><span class="s4">'%r'</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s1">dict.__init__(self</span><span class="s3">, </span><span class="s1">kwds)</span>
        <span class="s1">self.__dict__ = self</span>
        <span class="s1">self._initialize()</span>

    <span class="s3">def </span><span class="s1">_initialize(self):</span>
        <span class="s3">pass</span>

    <span class="s3">def </span><span class="s1">__str__(self):</span>
        <span class="s3">return </span><span class="s1">self.template % self</span>

<span class="s3">def </span><span class="s1">_int_ifclose(x</span><span class="s3">, </span><span class="s1">dec=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">width=</span><span class="s5">4</span><span class="s1">):</span>
    <span class="s2">'''helper function for creating result string for int or float 
 
    only dec=1 and width=4 is implemented 
 
    Parameters 
    ---------- 
    x : int or float 
        value to format 
    dec : 1 
        number of decimals to print if x is not an integer 
    width : 4 
        width of string 
 
    Returns 
    ------- 
    xint : int or float 
        x is converted to int if it is within 1e-14 of an integer 
    x_string : str 
        x formatted as string, either '%4d' or '%4.1f' 
 
    '''</span>
    <span class="s1">xint = int(round(x))</span>
    <span class="s3">if </span><span class="s1">np.max(np.abs(xint - x)) &lt; </span><span class="s5">1e-14</span><span class="s1">:</span>
        <span class="s3">return </span><span class="s1">xint</span><span class="s3">, </span><span class="s4">'%4d' </span><span class="s1">% xint</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">return </span><span class="s1">x</span><span class="s3">, </span><span class="s4">'%4.1f' </span><span class="s1">% x</span>


<span class="s3">def </span><span class="s1">aggregate_raters(data</span><span class="s3">, </span><span class="s1">n_cat=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">'''convert raw data with shape (subject, rater) to (subject, cat_counts) 
 
    brings data into correct format for fleiss_kappa 
 
    bincount will raise exception if data cannot be converted to integer. 
 
    Parameters 
    ---------- 
    data : array_like, 2-Dim 
        data containing category assignment with subjects in rows and raters 
        in columns. 
    n_cat : None or int 
        If None, then the data is converted to integer categories, 
        0,1,2,...,n_cat-1. Because of the relabeling only category levels 
        with non-zero counts are included. 
        If this is an integer, then the category levels in the data are already 
        assumed to be in integers, 0,1,2,...,n_cat-1. In this case, the 
        returned array may contain columns with zero count, if no subject 
        has been categorized with this level. 
 
    Returns 
    ------- 
    arr : nd_array, (n_rows, n_cat) 
        Contains counts of raters that assigned a category level to individuals. 
        Subjects are in rows, category levels in columns. 
    categories : nd_array, (n_category_levels,) 
        Contains the category levels. 
 
    '''</span>
    <span class="s1">data = np.asarray(data)</span>
    <span class="s1">n_rows = data.shape[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s3">if </span><span class="s1">n_cat </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s0">#I could add int conversion (reverse_index) to np.unique</span>
        <span class="s1">cat_uni</span><span class="s3">, </span><span class="s1">cat_int = np.unique(data.ravel()</span><span class="s3">, </span><span class="s1">return_inverse=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s1">n_cat = len(cat_uni)</span>
        <span class="s1">data_ = cat_int.reshape(data.shape)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">cat_uni = np.arange(n_cat)  </span><span class="s0">#for return only, assumed cat levels</span>
        <span class="s1">data_ = data</span>

    <span class="s1">tt = np.zeros((n_rows</span><span class="s3">, </span><span class="s1">n_cat)</span><span class="s3">, </span><span class="s1">int)</span>
    <span class="s3">for </span><span class="s1">idx</span><span class="s3">, </span><span class="s1">row </span><span class="s3">in </span><span class="s1">enumerate(data_):</span>
        <span class="s1">ro = np.bincount(row)</span>
        <span class="s1">tt[idx</span><span class="s3">, </span><span class="s1">:len(ro)] = ro</span>

    <span class="s3">return </span><span class="s1">tt</span><span class="s3">, </span><span class="s1">cat_uni</span>

<span class="s3">def </span><span class="s1">to_table(data</span><span class="s3">, </span><span class="s1">bins=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">'''convert raw data with shape (subject, rater) to (rater1, rater2) 
 
    brings data into correct format for cohens_kappa 
 
    Parameters 
    ---------- 
    data : array_like, 2-Dim 
        data containing category assignment with subjects in rows and raters 
        in columns. 
    bins : None, int or tuple of array_like 
        If None, then the data is converted to integer categories, 
        0,1,2,...,n_cat-1. Because of the relabeling only category levels 
        with non-zero counts are included. 
        If this is an integer, then the category levels in the data are already 
        assumed to be in integers, 0,1,2,...,n_cat-1. In this case, the 
        returned array may contain columns with zero count, if no subject 
        has been categorized with this level. 
        If bins are a tuple of two array_like, then the bins are directly used 
        by ``numpy.histogramdd``. This is useful if we want to merge categories. 
 
    Returns 
    ------- 
    arr : nd_array, (n_cat, n_cat) 
        Contingency table that contains counts of category level with rater1 
        in rows and rater2 in columns. 
 
    Notes 
    ----- 
    no NaN handling, delete rows with missing values 
 
    This works also for more than two raters. In that case the dimension of 
    the resulting contingency table is the same as the number of raters 
    instead of 2-dimensional. 
 
    '''</span>

    <span class="s1">data = np.asarray(data)</span>
    <span class="s1">n_rows</span><span class="s3">, </span><span class="s1">n_cols = data.shape</span>
    <span class="s3">if </span><span class="s1">bins </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s0">#I could add int conversion (reverse_index) to np.unique</span>
        <span class="s1">cat_uni</span><span class="s3">, </span><span class="s1">cat_int = np.unique(data.ravel()</span><span class="s3">, </span><span class="s1">return_inverse=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s1">n_cat = len(cat_uni)</span>
        <span class="s1">data_ = cat_int.reshape(data.shape)</span>
        <span class="s1">bins_ = np.arange(n_cat+</span><span class="s5">1</span><span class="s1">) - </span><span class="s5">0.5</span>
        <span class="s0">#alternative implementation with double loop</span>
        <span class="s0">#tt = np.asarray([[(x == [i,j]).all(1).sum() for j in cat_uni]</span>
        <span class="s0">#                 for i in cat_uni] )</span>
        <span class="s0">#other altervative: unique rows and bincount</span>
    <span class="s3">elif </span><span class="s1">np.isscalar(bins):</span>
        <span class="s1">bins_ = np.arange(bins+</span><span class="s5">1</span><span class="s1">) - </span><span class="s5">0.5</span>
        <span class="s1">data_ = data</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">bins_ = bins</span>
        <span class="s1">data_ = data</span>


    <span class="s1">tt = np.histogramdd(data_</span><span class="s3">, </span><span class="s1">(bins_</span><span class="s3">,</span><span class="s1">)*n_cols)</span>

    <span class="s3">return </span><span class="s1">tt[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">bins_</span>

<span class="s3">def </span><span class="s1">fleiss_kappa(table</span><span class="s3">, </span><span class="s1">method=</span><span class="s4">'fleiss'</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Fleiss' and Randolph's kappa multi-rater agreement measure 
 
    Parameters 
    ---------- 
    table : array_like, 2-D 
        assumes subjects in rows, and categories in columns. Convert raw data 
        into this format by using 
        :func:`statsmodels.stats.inter_rater.aggregate_raters` 
    method : str 
        Method 'fleiss' returns Fleiss' kappa which uses the sample margin 
        to define the chance outcome. 
        Method 'randolph' or 'uniform' (only first 4 letters are needed) 
        returns Randolph's (2005) multirater kappa which assumes a uniform 
        distribution of the categories to define the chance outcome. 
 
    Returns 
    ------- 
    kappa : float 
        Fleiss's or Randolph's kappa statistic for inter rater agreement 
 
    Notes 
    ----- 
    no variance or hypothesis tests yet 
 
    Interrater agreement measures like Fleiss's kappa measure agreement relative 
    to chance agreement. Different authors have proposed ways of defining 
    these chance agreements. Fleiss' is based on the marginal sample distribution 
    of categories, while Randolph uses a uniform distribution of categories as 
    benchmark. Warrens (2010) showed that Randolph's kappa is always larger or 
    equal to Fleiss' kappa. Under some commonly observed condition, Fleiss' and 
    Randolph's kappa provide lower and upper bounds for two similar kappa_like 
    measures by Light (1971) and Hubert (1977). 
 
    References 
    ---------- 
    Wikipedia https://en.wikipedia.org/wiki/Fleiss%27_kappa 
 
    Fleiss, Joseph L. 1971. &quot;Measuring Nominal Scale Agreement among Many 
    Raters.&quot; Psychological Bulletin 76 (5): 378-82. 
    https://doi.org/10.1037/h0031619. 
 
    Randolph, Justus J. 2005 &quot;Free-Marginal Multirater Kappa (multirater 
    K [free]): An Alternative to Fleiss' Fixed-Marginal Multirater Kappa.&quot; 
    Presented at the Joensuu Learning and Instruction Symposium, vol. 2005 
    https://eric.ed.gov/?id=ED490661 
 
    Warrens, Matthijs J. 2010. &quot;Inequalities between Multi-Rater Kappas.&quot; 
    Advances in Data Analysis and Classification 4 (4): 271-86. 
    https://doi.org/10.1007/s11634-010-0073-4. 
    &quot;&quot;&quot;</span>

    <span class="s1">table = </span><span class="s5">1.0 </span><span class="s1">* np.asarray(table)   </span><span class="s0">#avoid integer division</span>
    <span class="s1">n_sub</span><span class="s3">, </span><span class="s1">n_cat =  table.shape</span>
    <span class="s1">n_total = table.sum()</span>
    <span class="s1">n_rater = table.sum(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">n_rat = n_rater.max()</span>
    <span class="s0">#assume fully ranked</span>
    <span class="s3">assert </span><span class="s1">n_total == n_sub * n_rat</span>

    <span class="s0">#marginal frequency  of categories</span>
    <span class="s1">p_cat = table.sum(</span><span class="s5">0</span><span class="s1">) / n_total</span>

    <span class="s1">table2 = table * table</span>
    <span class="s1">p_rat = (table2.sum(</span><span class="s5">1</span><span class="s1">) - n_rat) / (n_rat * (n_rat - </span><span class="s5">1.</span><span class="s1">))</span>
    <span class="s1">p_mean = p_rat.mean()</span>

    <span class="s3">if </span><span class="s1">method == </span><span class="s4">'fleiss'</span><span class="s1">:</span>
        <span class="s1">p_mean_exp = (p_cat*p_cat).sum()</span>
    <span class="s3">elif </span><span class="s1">method.startswith(</span><span class="s4">'rand'</span><span class="s1">) </span><span class="s3">or </span><span class="s1">method.startswith(</span><span class="s4">'unif'</span><span class="s1">):</span>
        <span class="s1">p_mean_exp = </span><span class="s5">1 </span><span class="s1">/ n_cat</span>

    <span class="s1">kappa = (p_mean - p_mean_exp) / (</span><span class="s5">1</span><span class="s1">- p_mean_exp)</span>
    <span class="s3">return </span><span class="s1">kappa</span>


<span class="s3">def </span><span class="s1">cohens_kappa(table</span><span class="s3">, </span><span class="s1">weights=</span><span class="s3">None, </span><span class="s1">return_results=</span><span class="s3">True, </span><span class="s1">wt=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">'''Compute Cohen's kappa with variance and equal-zero test 
 
    Parameters 
    ---------- 
    table : array_like, 2-Dim 
        square array with results of two raters, one rater in rows, second 
        rater in columns 
    weights : array_like 
        The interpretation of weights depends on the wt argument. 
        If both are None, then the simple kappa is computed. 
        see wt for the case when wt is not None 
        If weights is two dimensional, then it is directly used as a weight 
        matrix. For computing the variance of kappa, the maximum of the 
        weights is assumed to be smaller or equal to one. 
        TODO: fix conflicting definitions in the 2-Dim case for 
    wt : {None, str} 
        If wt and weights are None, then the simple kappa is computed. 
        If wt is given, but weights is None, then the weights are set to 
        be [0, 1, 2, ..., k]. 
        If weights is a one-dimensional array, then it is used to construct 
        the weight matrix given the following options. 
 
        wt in ['linear', 'ca' or None] : use linear weights, Cicchetti-Allison 
            actual weights are linear in the score &quot;weights&quot; difference 
        wt in ['quadratic', 'fc'] : use linear weights, Fleiss-Cohen 
            actual weights are squared in the score &quot;weights&quot; difference 
        wt = 'toeplitz' : weight matrix is constructed as a toeplitz matrix 
            from the one dimensional weights. 
 
    return_results : bool 
        If True (default), then an instance of KappaResults is returned. 
        If False, then only kappa is computed and returned. 
 
    Returns 
    ------- 
    results or kappa 
        If return_results is True (default), then a results instance with all 
        statistics is returned 
        If return_results is False, then only kappa is calculated and returned. 
 
    Notes 
    ----- 
    There are two conflicting definitions of the weight matrix, Wikipedia 
    versus SAS manual. However, the computation are invariant to rescaling 
    of the weights matrix, so there is no difference in the results. 
 
    Weights for 'linear' and 'quadratic' are interpreted as scores for the 
    categories, the weights in the computation are based on the pairwise 
    difference between the scores. 
    Weights for 'toeplitz' are a interpreted as weighted distance. The distance 
    only depends on how many levels apart two entries in the table are but 
    not on the levels themselves. 
 
    example: 
 
    weights = '0, 1, 2, 3' and wt is either linear or toeplitz means that the 
    weighting only depends on the simple distance of levels. 
 
    weights = '0, 0, 1, 1' and wt = 'linear' means that the first two levels 
    are zero distance apart and the same for the last two levels. This is 
    the sample as forming two aggregated levels by merging the first two and 
    the last two levels, respectively. 
 
    weights = [0, 1, 2, 3] and wt = 'quadratic' is the same as squaring these 
    weights and using wt = 'toeplitz'. 
 
    References 
    ---------- 
    Wikipedia 
    SAS Manual 
 
    '''</span>
    <span class="s1">table = np.asarray(table</span><span class="s3">, </span><span class="s1">float) </span><span class="s0">#avoid integer division</span>
    <span class="s1">agree = np.diag(table).sum()</span>
    <span class="s1">nobs = table.sum()</span>
    <span class="s1">probs = table / nobs</span>
    <span class="s1">freqs = probs  </span><span class="s0">#TODO: rename to use freqs instead of probs for observed</span>
    <span class="s1">probs_diag = np.diag(probs)</span>
    <span class="s1">freq_row = table.sum(</span><span class="s5">1</span><span class="s1">) / nobs</span>
    <span class="s1">freq_col = table.sum(</span><span class="s5">0</span><span class="s1">) / nobs</span>
    <span class="s1">prob_exp = freq_col * freq_row[:</span><span class="s3">, None</span><span class="s1">]</span>
    <span class="s3">assert </span><span class="s1">np.allclose(prob_exp.sum()</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s0">#print prob_exp.sum()</span>
    <span class="s1">agree_exp = np.diag(prob_exp).sum() </span><span class="s0">#need for kappa_max</span>
    <span class="s3">if </span><span class="s1">weights </span><span class="s3">is None and </span><span class="s1">wt </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">kind = </span><span class="s4">'Simple'</span>
        <span class="s1">kappa = (agree / nobs - agree_exp) / (</span><span class="s5">1 </span><span class="s1">- agree_exp)</span>

        <span class="s3">if </span><span class="s1">return_results:</span>
            <span class="s0">#variance</span>
            <span class="s1">term_a = probs_diag * (</span><span class="s5">1 </span><span class="s1">- (freq_row + freq_col) * (</span><span class="s5">1 </span><span class="s1">- kappa))**</span><span class="s5">2</span>
            <span class="s1">term_a = term_a.sum()</span>
            <span class="s1">term_b = probs * (freq_col[:</span><span class="s3">, None</span><span class="s1">] + freq_row)**</span><span class="s5">2</span>
            <span class="s1">d_idx = np.arange(table.shape[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s1">term_b[d_idx</span><span class="s3">, </span><span class="s1">d_idx] = </span><span class="s5">0   </span><span class="s0">#set diagonal to zero</span>
            <span class="s1">term_b = (</span><span class="s5">1 </span><span class="s1">- kappa)**</span><span class="s5">2 </span><span class="s1">* term_b.sum()</span>
            <span class="s1">term_c = (kappa - agree_exp * (</span><span class="s5">1</span><span class="s1">-kappa))**</span><span class="s5">2</span>
            <span class="s1">var_kappa = (term_a + term_b - term_c) / (</span><span class="s5">1 </span><span class="s1">- agree_exp)**</span><span class="s5">2 </span><span class="s1">/ nobs</span>
            <span class="s0">#term_c = freq_col * freq_row[:, None] * (freq_col + freq_row[:,None])</span>
            <span class="s1">term_c = freq_col * freq_row * (freq_col + freq_row)</span>
            <span class="s1">var_kappa0 = (agree_exp + agree_exp**</span><span class="s5">2 </span><span class="s1">- term_c.sum())</span>
            <span class="s1">var_kappa0 /= (</span><span class="s5">1 </span><span class="s1">- agree_exp)**</span><span class="s5">2 </span><span class="s1">* nobs</span>

    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">weights </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">weights = np.arange(table.shape[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s0">#weights follows the Wikipedia definition, not the SAS, which is 1 -</span>
        <span class="s1">kind = </span><span class="s4">'Weighted'</span>
        <span class="s1">weights = np.asarray(weights</span><span class="s3">, </span><span class="s1">float)</span>
        <span class="s3">if </span><span class="s1">weights.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">wt </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'ca'</span><span class="s3">, </span><span class="s4">'linear'</span><span class="s3">, None</span><span class="s1">]:</span>
                <span class="s1">weights = np.abs(weights[:</span><span class="s3">, None</span><span class="s1">] - weights) /  \</span>
                           <span class="s1">(weights[-</span><span class="s5">1</span><span class="s1">] - weights[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s3">elif </span><span class="s1">wt </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'fc'</span><span class="s3">, </span><span class="s4">'quadratic'</span><span class="s1">]:</span>
                <span class="s1">weights = (weights[:</span><span class="s3">, None</span><span class="s1">] - weights)**</span><span class="s5">2 </span><span class="s1">/  \</span>
                           <span class="s1">(weights[-</span><span class="s5">1</span><span class="s1">] - weights[</span><span class="s5">0</span><span class="s1">])**</span><span class="s5">2</span>
            <span class="s3">elif </span><span class="s1">wt == </span><span class="s4">'toeplitz'</span><span class="s1">:</span>
                <span class="s0">#assume toeplitz structure</span>
                <span class="s3">from </span><span class="s1">scipy.linalg </span><span class="s3">import </span><span class="s1">toeplitz</span>
                <span class="s0">#weights = toeplitz(np.arange(table.shape[0]))</span>
                <span class="s1">weights = toeplitz(weights)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'wt option is not known'</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">rows</span><span class="s3">, </span><span class="s1">cols = table.shape</span>
            <span class="s3">if </span><span class="s1">(table.shape != weights.shape):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'weights are not square'</span><span class="s1">)</span>
        <span class="s0">#this is formula from Wikipedia</span>
        <span class="s1">kappa = </span><span class="s5">1 </span><span class="s1">- (weights * table).sum() / nobs / (weights * prob_exp).sum()</span>
        <span class="s0">#TODO: add var_kappa for weighted version</span>
        <span class="s3">if </span><span class="s1">return_results:</span>
            <span class="s1">var_kappa = np.nan</span>
            <span class="s1">var_kappa0 = np.nan</span>
            <span class="s0">#switch to SAS manual weights, problem if user specifies weights</span>
            <span class="s0">#w is negative in some examples,</span>
            <span class="s0">#but weights is scale invariant in examples and rough check of source</span>
            <span class="s1">w = </span><span class="s5">1. </span><span class="s1">- weights</span>
            <span class="s1">w_row = (freq_col * w).sum(</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">w_col = (freq_row[:</span><span class="s3">, None</span><span class="s1">] * w).sum(</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">agree_wexp = (w * freq_col * freq_row[:</span><span class="s3">, None</span><span class="s1">]).sum()</span>
            <span class="s1">term_a = freqs * (w -  (w_col + w_row[:</span><span class="s3">, None</span><span class="s1">]) * (</span><span class="s5">1 </span><span class="s1">- kappa))**</span><span class="s5">2</span>
            <span class="s1">fac = </span><span class="s5">1. </span><span class="s1">/ ((</span><span class="s5">1 </span><span class="s1">- agree_wexp)**</span><span class="s5">2 </span><span class="s1">* nobs)</span>
            <span class="s1">var_kappa = term_a.sum() - (kappa - agree_wexp * (</span><span class="s5">1 </span><span class="s1">- kappa))**</span><span class="s5">2</span>
            <span class="s1">var_kappa *=  fac</span>

            <span class="s1">freqse = freq_col * freq_row[:</span><span class="s3">, None</span><span class="s1">]</span>
            <span class="s1">var_kappa0 = (freqse * (w -  (w_col + w_row[:</span><span class="s3">, None</span><span class="s1">]))**</span><span class="s5">2</span><span class="s1">).sum()</span>
            <span class="s1">var_kappa0 -= agree_wexp**</span><span class="s5">2</span>
            <span class="s1">var_kappa0 *=  fac</span>

    <span class="s1">kappa_max = (np.minimum(freq_row</span><span class="s3">, </span><span class="s1">freq_col).sum() - agree_exp) / \</span>
                <span class="s1">(</span><span class="s5">1 </span><span class="s1">- agree_exp)</span>

    <span class="s3">if </span><span class="s1">return_results:</span>
        <span class="s1">res = KappaResults( kind=kind</span><span class="s3">,</span>
                    <span class="s1">kappa=kappa</span><span class="s3">,</span>
                    <span class="s1">kappa_max=kappa_max</span><span class="s3">,</span>
                    <span class="s1">weights=weights</span><span class="s3">,</span>
                    <span class="s1">var_kappa=var_kappa</span><span class="s3">,</span>
                    <span class="s1">var_kappa0=var_kappa0)</span>
        <span class="s3">return </span><span class="s1">res</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">return </span><span class="s1">kappa</span>


<span class="s1">_kappa_template = </span><span class="s4">'''</span><span class="s3">\ 
                  </span><span class="s4">%(kind)s Kappa Coefficient 
              -------------------------------- 
              Kappa                     %(kappa)6.4f 
              ASE                       %(std_kappa)6.4f 
            %(alpha_ci)s%% Lower Conf Limit      %(kappa_low)6.4f 
            %(alpha_ci)s%% Upper Conf Limit      %(kappa_upp)6.4f 
 
                 Test of H0: %(kind)s Kappa = 0 
 
              ASE under H0              %(std_kappa0)6.4f 
              Z                         %(z_value)6.4f 
              One-sided Pr &gt;  Z         %(pvalue_one_sided)6.4f 
              Two-sided Pr &gt; |Z|        %(pvalue_two_sided)6.4f 
'''</span>

<span class="s4">''' 
                   Weighted Kappa Coefficient 
              -------------------------------- 
              Weighted Kappa            0.4701 
              ASE                       0.1457 
              95% Lower Conf Limit      0.1845 
              95% Upper Conf Limit      0.7558 
 
               Test of H0: Weighted Kappa = 0 
 
              ASE under H0              0.1426 
              Z                         3.2971 
              One-sided Pr &gt;  Z         0.0005 
              Two-sided Pr &gt; |Z|        0.0010 
'''</span>


<span class="s3">class </span><span class="s1">KappaResults(ResultsBunch):</span>
    <span class="s2">'''Results for Cohen's kappa 
 
    Attributes 
    ---------- 
    kappa : cohen's kappa 
    var_kappa : variance of kappa 
    std_kappa : standard deviation of kappa 
    alpha : one-sided probability for confidence interval 
    kappa_low : lower (1-alpha) confidence limit 
    kappa_upp : upper (1-alpha) confidence limit 
    var_kappa0 : variance of kappa under H0: kappa=0 
    std_kappa0 : standard deviation of kappa under H0: kappa=0 
    z_value : test statistic for H0: kappa=0, is standard normal distributed 
    pvalue_one_sided : one sided p-value for H0: kappa=0 and H1: kappa&gt;0 
    pvalue_two_sided : two sided p-value for H0: kappa=0 and H1: kappa!=0 
    distribution_kappa : asymptotic normal distribution of kappa 
    distribution_zero_null : asymptotic normal distribution of kappa under 
        H0: kappa=0 
 
    The confidence interval for kappa and the statistics for the test of 
    H0: kappa=0 are based on the asymptotic normal distribution of kappa. 
 
    '''</span>

    <span class="s1">template = _kappa_template</span>

    <span class="s3">def </span><span class="s1">_initialize(self):</span>
        <span class="s3">if </span><span class="s4">'alpha' </span><span class="s3">not in </span><span class="s1">self:</span>
            <span class="s1">self[</span><span class="s4">'alpha'</span><span class="s1">] = </span><span class="s5">0.025</span>
            <span class="s1">self[</span><span class="s4">'alpha_ci'</span><span class="s1">] = _int_ifclose(</span><span class="s5">100 </span><span class="s1">- </span><span class="s5">0.025 </span><span class="s1">* </span><span class="s5">200</span><span class="s1">)[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">self[</span><span class="s4">'std_kappa'</span><span class="s1">] = np.sqrt(self[</span><span class="s4">'var_kappa'</span><span class="s1">])</span>
        <span class="s1">self[</span><span class="s4">'std_kappa0'</span><span class="s1">] = np.sqrt(self[</span><span class="s4">'var_kappa0'</span><span class="s1">])</span>

        <span class="s1">self[</span><span class="s4">'z_value'</span><span class="s1">] = self[</span><span class="s4">'kappa'</span><span class="s1">] / self[</span><span class="s4">'std_kappa0'</span><span class="s1">]</span>

        <span class="s1">self[</span><span class="s4">'pvalue_one_sided'</span><span class="s1">] = stats.norm.sf(self[</span><span class="s4">'z_value'</span><span class="s1">])</span>
        <span class="s1">self[</span><span class="s4">'pvalue_two_sided'</span><span class="s1">] = stats.norm.sf(np.abs(self[</span><span class="s4">'z_value'</span><span class="s1">])) * </span><span class="s5">2</span>

        <span class="s1">delta = stats.norm.isf(self[</span><span class="s4">'alpha'</span><span class="s1">]) * self[</span><span class="s4">'std_kappa'</span><span class="s1">]</span>
        <span class="s1">self[</span><span class="s4">'kappa_low'</span><span class="s1">] = self[</span><span class="s4">'kappa'</span><span class="s1">] - delta</span>
        <span class="s1">self[</span><span class="s4">'kappa_upp'</span><span class="s1">] = self[</span><span class="s4">'kappa'</span><span class="s1">] + delta</span>
        <span class="s1">self[</span><span class="s4">'distribution_kappa'</span><span class="s1">] = stats.norm(loc=self[</span><span class="s4">'kappa'</span><span class="s1">]</span><span class="s3">,</span>
                                                <span class="s1">scale=self[</span><span class="s4">'std_kappa'</span><span class="s1">])</span>
        <span class="s1">self[</span><span class="s4">'distribution_zero_null'</span><span class="s1">] = stats.norm(loc=</span><span class="s5">0</span><span class="s3">,</span>
                                                <span class="s1">scale=self[</span><span class="s4">'std_kappa0'</span><span class="s1">])</span>

    <span class="s3">def </span><span class="s1">__str__(self):</span>
        <span class="s3">return </span><span class="s1">self.template % self</span>
</pre>
</body>
</html>
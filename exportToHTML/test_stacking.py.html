<html>
<head>
<title>test_stacking.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_stacking.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Test the stacking classifier and regressor.&quot;&quot;&quot;</span>

<span class="s2"># Authors: Guillaume Lemaitre &lt;g.lemaitre58@gmail.com&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">from </span><span class="s1">unittest.mock </span><span class="s3">import </span><span class="s1">Mock</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pytest</span>
<span class="s3">import </span><span class="s1">scipy.sparse </span><span class="s3">as </span><span class="s1">sparse</span>
<span class="s3">from </span><span class="s1">numpy.testing </span><span class="s3">import </span><span class="s1">assert_array_equal</span>

<span class="s3">from </span><span class="s1">sklearn.base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">ClassifierMixin</span><span class="s3">, </span><span class="s1">RegressorMixin</span><span class="s3">, </span><span class="s1">clone</span>
<span class="s3">from </span><span class="s1">sklearn.datasets </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">load_breast_cancer</span><span class="s3">,</span>
    <span class="s1">load_diabetes</span><span class="s3">,</span>
    <span class="s1">load_iris</span><span class="s3">,</span>
    <span class="s1">make_classification</span><span class="s3">,</span>
    <span class="s1">make_multilabel_classification</span><span class="s3">,</span>
    <span class="s1">make_regression</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">sklearn.dummy </span><span class="s3">import </span><span class="s1">DummyClassifier</span><span class="s3">, </span><span class="s1">DummyRegressor</span>
<span class="s3">from </span><span class="s1">sklearn.ensemble </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">RandomForestClassifier</span><span class="s3">,</span>
    <span class="s1">RandomForestRegressor</span><span class="s3">,</span>
    <span class="s1">StackingClassifier</span><span class="s3">,</span>
    <span class="s1">StackingRegressor</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">sklearn.exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span><span class="s3">, </span><span class="s1">NotFittedError</span>
<span class="s3">from </span><span class="s1">sklearn.linear_model </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">LinearRegression</span><span class="s3">,</span>
    <span class="s1">LogisticRegression</span><span class="s3">,</span>
    <span class="s1">Ridge</span><span class="s3">,</span>
    <span class="s1">RidgeClassifier</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">sklearn.model_selection </span><span class="s3">import </span><span class="s1">KFold</span><span class="s3">, </span><span class="s1">StratifiedKFold</span><span class="s3">, </span><span class="s1">train_test_split</span>
<span class="s3">from </span><span class="s1">sklearn.neighbors </span><span class="s3">import </span><span class="s1">KNeighborsClassifier</span>
<span class="s3">from </span><span class="s1">sklearn.neural_network </span><span class="s3">import </span><span class="s1">MLPClassifier</span>
<span class="s3">from </span><span class="s1">sklearn.preprocessing </span><span class="s3">import </span><span class="s1">scale</span>
<span class="s3">from </span><span class="s1">sklearn.svm </span><span class="s3">import </span><span class="s1">SVC</span><span class="s3">, </span><span class="s1">LinearSVC</span><span class="s3">, </span><span class="s1">LinearSVR</span>
<span class="s3">from </span><span class="s1">sklearn.utils._mocking </span><span class="s3">import </span><span class="s1">CheckingClassifier</span>
<span class="s3">from </span><span class="s1">sklearn.utils._testing </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s3">,</span>
    <span class="s1">assert_allclose_dense_sparse</span><span class="s3">,</span>
    <span class="s1">ignore_warnings</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s1">diabetes = load_diabetes()</span>
<span class="s1">X_diabetes</span><span class="s3">, </span><span class="s1">y_diabetes = diabetes.data</span><span class="s3">, </span><span class="s1">diabetes.target</span>
<span class="s1">iris = load_iris()</span>
<span class="s1">X_iris</span><span class="s3">, </span><span class="s1">y_iris = iris.data</span><span class="s3">, </span><span class="s1">iris.target</span>
<span class="s1">X_multilabel</span><span class="s3">, </span><span class="s1">y_multilabel = make_multilabel_classification(</span>
    <span class="s1">n_classes=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
<span class="s1">)</span>
<span class="s1">X_binary</span><span class="s3">, </span><span class="s1">y_binary = make_classification(n_classes=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;cv&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s1">StratifiedKFold(n_splits=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">shuffle=</span><span class="s3">True, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)]</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;final_estimator&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s3">None, </span><span class="s1">RandomForestClassifier(random_state=</span><span class="s4">42</span><span class="s1">)]</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;passthrough&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s3">False, True</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_stacking_classifier_iris(cv</span><span class="s3">, </span><span class="s1">final_estimator</span><span class="s3">, </span><span class="s1">passthrough):</span>
    <span class="s2"># prescale the data to avoid convergence warning without using a pipeline</span>
    <span class="s2"># for later assert</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">scale(X_iris)</span><span class="s3">, </span><span class="s1">y_iris</span><span class="s3">, </span><span class="s1">stratify=y_iris</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svc&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))]</span>
    <span class="s1">clf = StackingClassifier(</span>
        <span class="s1">estimators=estimators</span><span class="s3">,</span>
        <span class="s1">final_estimator=final_estimator</span><span class="s3">,</span>
        <span class="s1">cv=cv</span><span class="s3">,</span>
        <span class="s1">passthrough=passthrough</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">clf.predict(X_test)</span>
    <span class="s1">clf.predict_proba(X_test)</span>
    <span class="s3">assert </span><span class="s1">clf.score(X_test</span><span class="s3">, </span><span class="s1">y_test) &gt; </span><span class="s4">0.8</span>

    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s1">expected_column_count = </span><span class="s4">10 </span><span class="s3">if </span><span class="s1">passthrough </span><span class="s3">else </span><span class="s4">6</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == expected_column_count</span>
    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">assert_allclose(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">4</span><span class="s1">:])</span>

    <span class="s1">clf.set_params(lr=</span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span>
    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">clf.predict(X_test)</span>
    <span class="s1">clf.predict_proba(X_test)</span>
    <span class="s3">if </span><span class="s1">final_estimator </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s2"># LogisticRegression has decision_function method</span>
        <span class="s1">clf.decision_function(X_test)</span>

    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s1">expected_column_count_drop = </span><span class="s4">7 </span><span class="s3">if </span><span class="s1">passthrough </span><span class="s3">else </span><span class="s4">3</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == expected_column_count_drop</span>
    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">assert_allclose(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">4</span><span class="s1">:])</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_drop_column_binary_classification():</span>
    <span class="s2"># check that a column is dropped in binary classification</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = load_breast_cancer(return_X_y=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">scale(X)</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">stratify=y</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>

    <span class="s2"># both classifiers implement 'predict_proba' and will both drop one column</span>
    <span class="s1">estimators = [</span>
        <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;rf&quot;</span><span class="s3">, </span><span class="s1">RandomForestClassifier(random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
    <span class="s1">]</span>
    <span class="s1">clf = StackingClassifier(estimators=estimators</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">3</span><span class="s1">)</span>

    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">2</span>

    <span class="s2"># LinearSVC does not implement 'predict_proba' and will not drop one column</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svc&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))]</span>
    <span class="s1">clf.set_params(estimators=estimators)</span>

    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">2</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_drop_estimator():</span>
    <span class="s2"># prescale the data to avoid convergence warning without using a pipeline</span>
    <span class="s2"># for later assert</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">scale(X_iris)</span><span class="s3">, </span><span class="s1">y_iris</span><span class="s3">, </span><span class="s1">stratify=y_iris</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svc&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))]</span>
    <span class="s1">rf = RandomForestClassifier(n_estimators=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">clf = StackingClassifier(</span>
        <span class="s1">estimators=[(</span><span class="s5">&quot;svc&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))]</span><span class="s3">,</span>
        <span class="s1">final_estimator=rf</span><span class="s3">,</span>
        <span class="s1">cv=</span><span class="s4">5</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">clf_drop = StackingClassifier(estimators=estimators</span><span class="s3">, </span><span class="s1">final_estimator=rf</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">clf_drop.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">assert_allclose(clf.predict(X_test)</span><span class="s3">, </span><span class="s1">clf_drop.predict(X_test))</span>
    <span class="s1">assert_allclose(clf.predict_proba(X_test)</span><span class="s3">, </span><span class="s1">clf_drop.predict_proba(X_test))</span>
    <span class="s1">assert_allclose(clf.transform(X_test)</span><span class="s3">, </span><span class="s1">clf_drop.transform(X_test))</span>


<span class="s3">def </span><span class="s1">test_stacking_regressor_drop_estimator():</span>
    <span class="s2"># prescale the data to avoid convergence warning without using a pipeline</span>
    <span class="s2"># for later assert</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">scale(X_diabetes)</span><span class="s3">, </span><span class="s1">y_diabetes</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svr&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))]</span>
    <span class="s1">rf = RandomForestRegressor(n_estimators=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">reg = StackingRegressor(</span>
        <span class="s1">estimators=[(</span><span class="s5">&quot;svr&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))]</span><span class="s3">,</span>
        <span class="s1">final_estimator=rf</span><span class="s3">,</span>
        <span class="s1">cv=</span><span class="s4">5</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">reg_drop = StackingRegressor(estimators=estimators</span><span class="s3">, </span><span class="s1">final_estimator=rf</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">reg.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">reg_drop.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">assert_allclose(reg.predict(X_test)</span><span class="s3">, </span><span class="s1">reg_drop.predict(X_test))</span>
    <span class="s1">assert_allclose(reg.transform(X_test)</span><span class="s3">, </span><span class="s1">reg_drop.transform(X_test))</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;cv&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s1">KFold(n_splits=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">shuffle=</span><span class="s3">True, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)])</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;final_estimator, predict_params&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">None, </span><span class="s1">{})</span><span class="s3">,</span>
        <span class="s1">(RandomForestRegressor(random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">, </span><span class="s1">{})</span><span class="s3">,</span>
        <span class="s1">(DummyRegressor()</span><span class="s3">, </span><span class="s1">{</span><span class="s5">&quot;return_std&quot;</span><span class="s1">: </span><span class="s3">True</span><span class="s1">})</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;passthrough&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s3">False, True</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_stacking_regressor_diabetes(cv</span><span class="s3">, </span><span class="s1">final_estimator</span><span class="s3">, </span><span class="s1">predict_params</span><span class="s3">, </span><span class="s1">passthrough):</span>
    <span class="s2"># prescale the data to avoid convergence warning without using a pipeline</span>
    <span class="s2"># for later assert</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">scale(X_diabetes)</span><span class="s3">, </span><span class="s1">y_diabetes</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svr&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))]</span>
    <span class="s1">reg = StackingRegressor(</span>
        <span class="s1">estimators=estimators</span><span class="s3">,</span>
        <span class="s1">final_estimator=final_estimator</span><span class="s3">,</span>
        <span class="s1">cv=cv</span><span class="s3">,</span>
        <span class="s1">passthrough=passthrough</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">reg.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">result = reg.predict(X_test</span><span class="s3">, </span><span class="s1">**predict_params)</span>
    <span class="s1">expected_result_length = </span><span class="s4">2 </span><span class="s3">if </span><span class="s1">predict_params </span><span class="s3">else </span><span class="s4">1</span>
    <span class="s3">if </span><span class="s1">predict_params:</span>
        <span class="s3">assert </span><span class="s1">len(result) == expected_result_length</span>

    <span class="s1">X_trans = reg.transform(X_test)</span>
    <span class="s1">expected_column_count = </span><span class="s4">12 </span><span class="s3">if </span><span class="s1">passthrough </span><span class="s3">else </span><span class="s4">2</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == expected_column_count</span>
    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">assert_allclose(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">10</span><span class="s1">:])</span>

    <span class="s1">reg.set_params(lr=</span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span>
    <span class="s1">reg.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">reg.predict(X_test)</span>

    <span class="s1">X_trans = reg.transform(X_test)</span>
    <span class="s1">expected_column_count_drop = </span><span class="s4">11 </span><span class="s3">if </span><span class="s1">passthrough </span><span class="s3">else </span><span class="s4">1</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape[</span><span class="s4">1</span><span class="s1">] == expected_column_count_drop</span>
    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">assert_allclose(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">10</span><span class="s1">:])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;fmt&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s5">&quot;csc&quot;</span><span class="s3">, </span><span class="s5">&quot;csr&quot;</span><span class="s3">, </span><span class="s5">&quot;coo&quot;</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_stacking_regressor_sparse_passthrough(fmt):</span>
    <span class="s2"># Check passthrough behavior on a sparse X matrix</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">sparse.coo_matrix(scale(X_diabetes)).asformat(fmt)</span><span class="s3">, </span><span class="s1">y_diabetes</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svr&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))]</span>
    <span class="s1">rf = RandomForestRegressor(n_estimators=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">clf = StackingRegressor(</span>
        <span class="s1">estimators=estimators</span><span class="s3">, </span><span class="s1">final_estimator=rf</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">passthrough=</span><span class="s3">True</span>
    <span class="s1">)</span>
    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s1">assert_allclose_dense_sparse(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">10</span><span class="s1">:])</span>
    <span class="s3">assert </span><span class="s1">sparse.issparse(X_trans)</span>
    <span class="s3">assert </span><span class="s1">X_test.format == X_trans.format</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;fmt&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s5">&quot;csc&quot;</span><span class="s3">, </span><span class="s5">&quot;csr&quot;</span><span class="s3">, </span><span class="s5">&quot;coo&quot;</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_stacking_classifier_sparse_passthrough(fmt):</span>
    <span class="s2"># Check passthrough behavior on a sparse X matrix</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">sparse.coo_matrix(scale(X_iris)).asformat(fmt)</span><span class="s3">, </span><span class="s1">y_iris</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svc&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))]</span>
    <span class="s1">rf = RandomForestClassifier(n_estimators=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">clf = StackingClassifier(</span>
        <span class="s1">estimators=estimators</span><span class="s3">, </span><span class="s1">final_estimator=rf</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">passthrough=</span><span class="s3">True</span>
    <span class="s1">)</span>
    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s1">assert_allclose_dense_sparse(X_test</span><span class="s3">, </span><span class="s1">X_trans[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">4</span><span class="s1">:])</span>
    <span class="s3">assert </span><span class="s1">sparse.issparse(X_trans)</span>
    <span class="s3">assert </span><span class="s1">X_test.format == X_trans.format</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_drop_binary_prob():</span>
    <span class="s2"># check that classifier will drop one of the probability column for</span>
    <span class="s2"># binary classification problem</span>

    <span class="s2"># Select only the 2 first classes</span>
    <span class="s1">X_</span><span class="s3">, </span><span class="s1">y_ = scale(X_iris[:</span><span class="s4">100</span><span class="s1">])</span><span class="s3">, </span><span class="s1">y_iris[:</span><span class="s4">100</span><span class="s1">]</span>

    <span class="s1">estimators = [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;rf&quot;</span><span class="s3">, </span><span class="s1">RandomForestClassifier())]</span>
    <span class="s1">clf = StackingClassifier(estimators=estimators)</span>
    <span class="s1">clf.fit(X_</span><span class="s3">, </span><span class="s1">y_)</span>
    <span class="s1">X_meta = clf.transform(X_)</span>
    <span class="s3">assert </span><span class="s1">X_meta.shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">2</span>


<span class="s3">class </span><span class="s1">NoWeightRegressor(RegressorMixin</span><span class="s3">, </span><span class="s1">BaseEstimator):</span>
    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
        <span class="s1">self.reg = DummyRegressor()</span>
        <span class="s3">return </span><span class="s1">self.reg.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s3">def </span><span class="s1">predict(self</span><span class="s3">, </span><span class="s1">X):</span>
        <span class="s3">return </span><span class="s1">np.ones(X.shape[</span><span class="s4">0</span><span class="s1">])</span>


<span class="s3">class </span><span class="s1">NoWeightClassifier(ClassifierMixin</span><span class="s3">, </span><span class="s1">BaseEstimator):</span>
    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
        <span class="s1">self.clf = DummyClassifier(strategy=</span><span class="s5">&quot;stratified&quot;</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">self.clf.fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;y, params, type_err, msg_err&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(y_iris</span><span class="s3">, </span><span class="s1">{</span><span class="s5">&quot;estimators&quot;</span><span class="s1">: []}</span><span class="s3">, </span><span class="s1">ValueError</span><span class="s3">, </span><span class="s5">&quot;Invalid 'estimators' attribute,&quot;</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
            <span class="s1">{</span>
                <span class="s5">&quot;estimators&quot;</span><span class="s1">: [</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">SVC(max_iter=</span><span class="s4">50_000</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s5">&quot;stack_method&quot;</span><span class="s1">: </span><span class="s5">&quot;predict_proba&quot;</span><span class="s3">,</span>
            <span class="s1">}</span><span class="s3">,</span>
            <span class="s1">ValueError</span><span class="s3">,</span>
            <span class="s5">&quot;does not implement the method predict_proba&quot;</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
            <span class="s1">{</span>
                <span class="s5">&quot;estimators&quot;</span><span class="s1">: [</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;cor&quot;</span><span class="s3">, </span><span class="s1">NoWeightClassifier())</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">}</span><span class="s3">,</span>
            <span class="s1">TypeError</span><span class="s3">,</span>
            <span class="s5">&quot;does not support sample weight&quot;</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
            <span class="s1">{</span>
                <span class="s5">&quot;estimators&quot;</span><span class="s1">: [</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;cor&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">max_iter=</span><span class="s4">50_000</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s5">&quot;final_estimator&quot;</span><span class="s1">: NoWeightClassifier()</span><span class="s3">,</span>
            <span class="s1">}</span><span class="s3">,</span>
            <span class="s1">TypeError</span><span class="s3">,</span>
            <span class="s5">&quot;does not support sample weight&quot;</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_classifier_error(y</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">type_err</span><span class="s3">, </span><span class="s1">msg_err):</span>
    <span class="s3">with </span><span class="s1">pytest.raises(type_err</span><span class="s3">, </span><span class="s1">match=msg_err):</span>
        <span class="s1">clf = StackingClassifier(**params</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">clf.fit(scale(X_iris)</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight=np.ones(X_iris.shape[</span><span class="s4">0</span><span class="s1">]))</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;y, params, type_err, msg_err&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(y_diabetes</span><span class="s3">, </span><span class="s1">{</span><span class="s5">&quot;estimators&quot;</span><span class="s1">: []}</span><span class="s3">, </span><span class="s1">ValueError</span><span class="s3">, </span><span class="s5">&quot;Invalid 'estimators' attribute,&quot;</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
            <span class="s1">{</span><span class="s5">&quot;estimators&quot;</span><span class="s1">: [(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;cor&quot;</span><span class="s3">, </span><span class="s1">NoWeightRegressor())]}</span><span class="s3">,</span>
            <span class="s1">TypeError</span><span class="s3">,</span>
            <span class="s5">&quot;does not support sample weight&quot;</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
            <span class="s1">{</span>
                <span class="s5">&quot;estimators&quot;</span><span class="s1">: [</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;cor&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s5">&quot;final_estimator&quot;</span><span class="s1">: NoWeightRegressor()</span><span class="s3">,</span>
            <span class="s1">}</span><span class="s3">,</span>
            <span class="s1">TypeError</span><span class="s3">,</span>
            <span class="s5">&quot;does not support sample weight&quot;</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_regressor_error(y</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">type_err</span><span class="s3">, </span><span class="s1">msg_err):</span>
    <span class="s3">with </span><span class="s1">pytest.raises(type_err</span><span class="s3">, </span><span class="s1">match=msg_err):</span>
        <span class="s1">reg = StackingRegressor(**params</span><span class="s3">, </span><span class="s1">cv=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">reg.fit(scale(X_diabetes)</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight=np.ones(X_diabetes.shape[</span><span class="s4">0</span><span class="s1">]))</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;estimator, X, y&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression(random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_iris[:</span><span class="s4">100</span><span class="s1">]</span><span class="s3">,</span>
            <span class="s1">y_iris[:</span><span class="s4">100</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,  </span><span class="s2"># keep only classes 0 and 1</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">ids=[</span><span class="s5">&quot;StackingClassifier&quot;</span><span class="s3">, </span><span class="s5">&quot;StackingRegressor&quot;</span><span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_randomness(estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
    <span class="s2"># checking that fixing the random state of the CV will lead to the same</span>
    <span class="s2"># results</span>
    <span class="s1">estimator_full = clone(estimator)</span>
    <span class="s1">estimator_full.set_params(</span>
        <span class="s1">cv=KFold(shuffle=</span><span class="s3">True, </span><span class="s1">random_state=np.random.RandomState(</span><span class="s4">0</span><span class="s1">))</span>
    <span class="s1">)</span>

    <span class="s1">estimator_drop = clone(estimator)</span>
    <span class="s1">estimator_drop.set_params(lr=</span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span>
    <span class="s1">estimator_drop.set_params(</span>
        <span class="s1">cv=KFold(shuffle=</span><span class="s3">True, </span><span class="s1">random_state=np.random.RandomState(</span><span class="s4">0</span><span class="s1">))</span>
    <span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">estimator_full.fit(X</span><span class="s3">, </span><span class="s1">y).transform(X)[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span><span class="s3">,</span>
        <span class="s1">estimator_drop.fit(X</span><span class="s3">, </span><span class="s1">y).transform(X)</span><span class="s3">,</span>
    <span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_stratify_default():</span>
    <span class="s2"># check that we stratify the classes for the default CV</span>
    <span class="s1">clf = StackingClassifier(</span>
        <span class="s1">estimators=[</span>
            <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression(max_iter=</span><span class="s4">10_000</span><span class="s1">))</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">max_iter=</span><span class="s4">10_000</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s2"># since iris is not shuffled, a simple k-fold would not contain the</span>
    <span class="s2"># 3 classes during training</span>
    <span class="s1">clf.fit(X_iris</span><span class="s3">, </span><span class="s1">y_iris)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;stacker, X, y&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s1">final_estimator=LogisticRegression()</span><span class="s3">,</span>
                <span class="s1">cv=KFold(shuffle=</span><span class="s3">True, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">*load_breast_cancer(return_X_y=</span><span class="s3">True</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s1">final_estimator=LinearRegression()</span><span class="s3">,</span>
                <span class="s1">cv=KFold(shuffle=</span><span class="s3">True, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">ids=[</span><span class="s5">&quot;StackingClassifier&quot;</span><span class="s3">, </span><span class="s5">&quot;StackingRegressor&quot;</span><span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_with_sample_weight(stacker</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
    <span class="s2"># check that sample weights has an influence on the fitting</span>
    <span class="s2"># note: ConvergenceWarning are catch since we are not worrying about the</span>
    <span class="s2"># convergence here</span>
    <span class="s1">n_half_samples = len(y) // </span><span class="s4">2</span>
    <span class="s1">total_sample_weight = np.array(</span>
        <span class="s1">[</span><span class="s4">0.1</span><span class="s1">] * n_half_samples + [</span><span class="s4">0.9</span><span class="s1">] * (len(y) - n_half_samples)</span>
    <span class="s1">)</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">sample_weight_train</span><span class="s3">, </span><span class="s1">_ = train_test_split(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">total_sample_weight</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>

    <span class="s3">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
        <span class="s1">stacker.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">y_pred_no_weight = stacker.predict(X_test)</span>

    <span class="s3">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
        <span class="s1">stacker.fit(X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sample_weight=np.ones(y_train.shape))</span>
    <span class="s1">y_pred_unit_weight = stacker.predict(X_test)</span>

    <span class="s1">assert_allclose(y_pred_no_weight</span><span class="s3">, </span><span class="s1">y_pred_unit_weight)</span>

    <span class="s3">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
        <span class="s1">stacker.fit(X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sample_weight=sample_weight_train)</span>
    <span class="s1">y_pred_biased = stacker.predict(X_test)</span>

    <span class="s3">assert </span><span class="s1">np.abs(y_pred_no_weight - y_pred_biased).sum() &gt; </span><span class="s4">0</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_sample_weight_fit_param():</span>
    <span class="s2"># check sample_weight is passed to all invocations of fit</span>
    <span class="s1">stacker = StackingClassifier(</span>
        <span class="s1">estimators=[(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">CheckingClassifier(expected_sample_weight=</span><span class="s3">True</span><span class="s1">))]</span><span class="s3">,</span>
        <span class="s1">final_estimator=CheckingClassifier(expected_sample_weight=</span><span class="s3">True</span><span class="s1">)</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">stacker.fit(X_iris</span><span class="s3">, </span><span class="s1">y_iris</span><span class="s3">, </span><span class="s1">sample_weight=np.ones(X_iris.shape[</span><span class="s4">0</span><span class="s1">]))</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s5">&quot;ignore::sklearn.exceptions.ConvergenceWarning&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;stacker, X, y&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s1">final_estimator=LogisticRegression()</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">*load_breast_cancer(return_X_y=</span><span class="s3">True</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s1">final_estimator=LinearRegression()</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">ids=[</span><span class="s5">&quot;StackingClassifier&quot;</span><span class="s3">, </span><span class="s5">&quot;StackingRegressor&quot;</span><span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_cv_influence(stacker</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
    <span class="s2"># check that the stacking affects the fit of the final estimator but not</span>
    <span class="s2"># the fit of the base estimators</span>
    <span class="s2"># note: ConvergenceWarning are catch since we are not worrying about the</span>
    <span class="s2"># convergence here</span>
    <span class="s1">stacker_cv_3 = clone(stacker)</span>
    <span class="s1">stacker_cv_5 = clone(stacker)</span>

    <span class="s1">stacker_cv_3.set_params(cv=</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">stacker_cv_5.set_params(cv=</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">stacker_cv_3.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">stacker_cv_5.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># the base estimators should be identical</span>
    <span class="s3">for </span><span class="s1">est_cv_3</span><span class="s3">, </span><span class="s1">est_cv_5 </span><span class="s3">in </span><span class="s1">zip(stacker_cv_3.estimators_</span><span class="s3">, </span><span class="s1">stacker_cv_5.estimators_):</span>
        <span class="s1">assert_allclose(est_cv_3.coef_</span><span class="s3">, </span><span class="s1">est_cv_5.coef_)</span>

    <span class="s2"># the final estimator should be different</span>
    <span class="s3">with </span><span class="s1">pytest.raises(AssertionError</span><span class="s3">, </span><span class="s1">match=</span><span class="s5">&quot;Not equal&quot;</span><span class="s1">):</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">stacker_cv_3.final_estimator_.coef_</span><span class="s3">, </span><span class="s1">stacker_cv_5.final_estimator_.coef_</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;Stacker, Estimator, stack_method, final_estimator, X, y&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier</span><span class="s3">,</span>
            <span class="s1">DummyClassifier</span><span class="s3">,</span>
            <span class="s5">&quot;predict_proba&quot;</span><span class="s3">,</span>
            <span class="s1">LogisticRegression(random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_iris</span><span class="s3">,</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor</span><span class="s3">,</span>
            <span class="s1">DummyRegressor</span><span class="s3">,</span>
            <span class="s5">&quot;predict&quot;</span><span class="s3">,</span>
            <span class="s1">LinearRegression()</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_prefit(Stacker</span><span class="s3">, </span><span class="s1">Estimator</span><span class="s3">, </span><span class="s1">stack_method</span><span class="s3">, </span><span class="s1">final_estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
    <span class="s0">&quot;&quot;&quot;Check the behaviour of stacking when `cv='prefit'`&quot;&quot;&quot;</span>
    <span class="s1">X_train1</span><span class="s3">, </span><span class="s1">X_train2</span><span class="s3">, </span><span class="s1">y_train1</span><span class="s3">, </span><span class="s1">y_train2 = train_test_split(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span><span class="s3">, </span><span class="s1">test_size=</span><span class="s4">0.5</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [</span>
        <span class="s1">(</span><span class="s5">&quot;d0&quot;</span><span class="s3">, </span><span class="s1">Estimator().fit(X_train1</span><span class="s3">, </span><span class="s1">y_train1))</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;d1&quot;</span><span class="s3">, </span><span class="s1">Estimator().fit(X_train1</span><span class="s3">, </span><span class="s1">y_train1))</span><span class="s3">,</span>
    <span class="s1">]</span>

    <span class="s2"># mock out fit and stack_method to be asserted later</span>
    <span class="s3">for </span><span class="s1">_</span><span class="s3">, </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">estimators:</span>
        <span class="s1">estimator.fit = Mock(name=</span><span class="s5">&quot;fit&quot;</span><span class="s1">)</span>
        <span class="s1">stack_func = getattr(estimator</span><span class="s3">, </span><span class="s1">stack_method)</span>
        <span class="s1">predict_method_mocked = Mock(side_effect=stack_func)</span>
        <span class="s2"># Mocking a method will not provide a `__name__` while Python methods</span>
        <span class="s2"># do and we are using it in `_get_response_method`.</span>
        <span class="s1">predict_method_mocked.__name__ = stack_method</span>
        <span class="s1">setattr(estimator</span><span class="s3">, </span><span class="s1">stack_method</span><span class="s3">, </span><span class="s1">predict_method_mocked)</span>

    <span class="s1">stacker = Stacker(</span>
        <span class="s1">estimators=estimators</span><span class="s3">, </span><span class="s1">cv=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">, </span><span class="s1">final_estimator=final_estimator</span>
    <span class="s1">)</span>
    <span class="s1">stacker.fit(X_train2</span><span class="s3">, </span><span class="s1">y_train2)</span>

    <span class="s3">assert </span><span class="s1">stacker.estimators_ == [estimator </span><span class="s3">for </span><span class="s1">_</span><span class="s3">, </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">estimators]</span>
    <span class="s2"># fit was not called again</span>
    <span class="s3">assert </span><span class="s1">all(estimator.fit.call_count == </span><span class="s4">0 </span><span class="s3">for </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">stacker.estimators_)</span>

    <span class="s2"># stack method is called with the proper inputs</span>
    <span class="s3">for </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">stacker.estimators_:</span>
        <span class="s1">stack_func_mock = getattr(estimator</span><span class="s3">, </span><span class="s1">stack_method)</span>
        <span class="s1">stack_func_mock.assert_called_with(X_train2)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;stacker, X, y&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression())</span><span class="s3">, </span><span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">SVC())]</span><span class="s3">,</span>
                <span class="s1">cv=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_iris</span><span class="s3">,</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span><span class="s3">,</span>
                <span class="s1">cv=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">,</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_prefit_error(stacker</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
    <span class="s2"># check that NotFittedError is raised</span>
    <span class="s2"># if base estimators are not fitted when cv=&quot;prefit&quot;</span>
    <span class="s3">with </span><span class="s1">pytest.raises(NotFittedError):</span>
        <span class="s1">stacker.fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;make_dataset, Stacking, Estimator&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(make_classification</span><span class="s3">, </span><span class="s1">StackingClassifier</span><span class="s3">, </span><span class="s1">LogisticRegression)</span><span class="s3">,</span>
        <span class="s1">(make_regression</span><span class="s3">, </span><span class="s1">StackingRegressor</span><span class="s3">, </span><span class="s1">LinearRegression)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_without_n_features_in(make_dataset</span><span class="s3">, </span><span class="s1">Stacking</span><span class="s3">, </span><span class="s1">Estimator):</span>
    <span class="s2"># Stacking supports estimators without `n_features_in_`. Regression test</span>
    <span class="s2"># for #17353</span>

    <span class="s3">class </span><span class="s1">MyEstimator(Estimator):</span>
        <span class="s0">&quot;&quot;&quot;Estimator without n_features_in_&quot;&quot;&quot;</span>

        <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
            <span class="s1">super().fit(X</span><span class="s3">, </span><span class="s1">y)</span>
            <span class="s3">del </span><span class="s1">self.n_features_in_</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = make_dataset(random_state=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">n_samples=</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">stacker = Stacking(estimators=[(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">MyEstimator())])</span>

    <span class="s1">msg = </span><span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">Stacking.__name__</span><span class="s3">} </span><span class="s5">object has no attribute n_features_in_&quot;</span>
    <span class="s3">with </span><span class="s1">pytest.raises(AttributeError</span><span class="s3">, </span><span class="s1">match=msg):</span>
        <span class="s1">stacker.n_features_in_</span>

    <span class="s2"># Does not raise</span>
    <span class="s1">stacker.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s5">&quot;'MyEstimator' object has no attribute 'n_features_in_'&quot;</span>
    <span class="s3">with </span><span class="s1">pytest.raises(AttributeError</span><span class="s3">, </span><span class="s1">match=msg):</span>
        <span class="s1">stacker.n_features_in_</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;estimator&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s2"># output a 2D array of the probability of the positive class for each output</span>
        <span class="s1">MLPClassifier(random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s2"># output a list of 2D array containing the probability of each class</span>
        <span class="s2"># for each output</span>
        <span class="s1">RandomForestClassifier(random_state=</span><span class="s4">42</span><span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">ids=[</span><span class="s5">&quot;MLPClassifier&quot;</span><span class="s3">, </span><span class="s5">&quot;RandomForestClassifier&quot;</span><span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_stacking_classifier_multilabel_predict_proba(estimator):</span>
    <span class="s0">&quot;&quot;&quot;Check the behaviour for the multilabel classification case and the 
    `predict_proba` stacking method. 
 
    Estimators are not consistent with the output arrays and we need to ensure that 
    we handle all cases. 
    &quot;&quot;&quot;</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">X_multilabel</span><span class="s3">, </span><span class="s1">y_multilabel</span><span class="s3">, </span><span class="s1">stratify=y_multilabel</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">n_outputs = </span><span class="s4">3</span>

    <span class="s1">estimators = [(</span><span class="s5">&quot;est&quot;</span><span class="s3">, </span><span class="s1">estimator)]</span>
    <span class="s1">stacker = StackingClassifier(</span>
        <span class="s1">estimators=estimators</span><span class="s3">,</span>
        <span class="s1">final_estimator=KNeighborsClassifier()</span><span class="s3">,</span>
        <span class="s1">stack_method=</span><span class="s5">&quot;predict_proba&quot;</span><span class="s3">,</span>
    <span class="s1">).fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>

    <span class="s1">X_trans = stacker.transform(X_test)</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape == (X_test.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">n_outputs)</span>
    <span class="s2"># we should not have any collinear classes and thus nothing should sum to 1</span>
    <span class="s3">assert not </span><span class="s1">any(np.isclose(X_trans.sum(axis=</span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s4">1.0</span><span class="s1">))</span>

    <span class="s1">y_pred = stacker.predict(X_test)</span>
    <span class="s3">assert </span><span class="s1">y_pred.shape == y_test.shape</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_multilabel_decision_function():</span>
    <span class="s0">&quot;&quot;&quot;Check the behaviour for the multilabel classification case and the 
    `decision_function` stacking method. Only `RidgeClassifier` supports this 
    case. 
    &quot;&quot;&quot;</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">X_multilabel</span><span class="s3">, </span><span class="s1">y_multilabel</span><span class="s3">, </span><span class="s1">stratify=y_multilabel</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">n_outputs = </span><span class="s4">3</span>

    <span class="s1">estimators = [(</span><span class="s5">&quot;est&quot;</span><span class="s3">, </span><span class="s1">RidgeClassifier())]</span>
    <span class="s1">stacker = StackingClassifier(</span>
        <span class="s1">estimators=estimators</span><span class="s3">,</span>
        <span class="s1">final_estimator=KNeighborsClassifier()</span><span class="s3">,</span>
        <span class="s1">stack_method=</span><span class="s5">&quot;decision_function&quot;</span><span class="s3">,</span>
    <span class="s1">).fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>

    <span class="s1">X_trans = stacker.transform(X_test)</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape == (X_test.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">n_outputs)</span>

    <span class="s1">y_pred = stacker.predict(X_test)</span>
    <span class="s3">assert </span><span class="s1">y_pred.shape == y_test.shape</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;stack_method&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s5">&quot;predict&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;passthrough&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s3">False, True</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_stacking_classifier_multilabel_auto_predict(stack_method</span><span class="s3">, </span><span class="s1">passthrough):</span>
    <span class="s0">&quot;&quot;&quot;Check the behaviour for the multilabel classification case for stack methods 
    supported for all estimators or automatically picked up. 
    &quot;&quot;&quot;</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">X_multilabel</span><span class="s3">, </span><span class="s1">y_multilabel</span><span class="s3">, </span><span class="s1">stratify=y_multilabel</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">y_train_before_fit = y_train.copy()</span>
    <span class="s1">n_outputs = </span><span class="s4">3</span>

    <span class="s1">estimators = [</span>
        <span class="s1">(</span><span class="s5">&quot;mlp&quot;</span><span class="s3">, </span><span class="s1">MLPClassifier(random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;rf&quot;</span><span class="s3">, </span><span class="s1">RandomForestClassifier(random_state=</span><span class="s4">42</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;ridge&quot;</span><span class="s3">, </span><span class="s1">RidgeClassifier())</span><span class="s3">,</span>
    <span class="s1">]</span>
    <span class="s1">final_estimator = KNeighborsClassifier()</span>

    <span class="s1">clf = StackingClassifier(</span>
        <span class="s1">estimators=estimators</span><span class="s3">,</span>
        <span class="s1">final_estimator=final_estimator</span><span class="s3">,</span>
        <span class="s1">passthrough=passthrough</span><span class="s3">,</span>
        <span class="s1">stack_method=stack_method</span><span class="s3">,</span>
    <span class="s1">).fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>

    <span class="s2"># make sure we don't change `y_train` inplace</span>
    <span class="s1">assert_array_equal(y_train_before_fit</span><span class="s3">, </span><span class="s1">y_train)</span>

    <span class="s1">y_pred = clf.predict(X_test)</span>
    <span class="s3">assert </span><span class="s1">y_pred.shape == y_test.shape</span>

    <span class="s3">if </span><span class="s1">stack_method == </span><span class="s5">&quot;auto&quot;</span><span class="s1">:</span>
        <span class="s1">expected_stack_methods = [</span><span class="s5">&quot;predict_proba&quot;</span><span class="s3">, </span><span class="s5">&quot;predict_proba&quot;</span><span class="s3">, </span><span class="s5">&quot;decision_function&quot;</span><span class="s1">]</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">expected_stack_methods = [</span><span class="s5">&quot;predict&quot;</span><span class="s1">] * len(estimators)</span>
    <span class="s3">assert </span><span class="s1">clf.stack_method_ == expected_stack_methods</span>

    <span class="s1">n_features_X_trans = n_outputs * len(estimators)</span>
    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">n_features_X_trans += X_train.shape[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">X_trans = clf.transform(X_test)</span>
    <span class="s3">assert </span><span class="s1">X_trans.shape == (X_test.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">n_features_X_trans)</span>

    <span class="s1">assert_array_equal(clf.classes_</span><span class="s3">, </span><span class="s1">[np.array([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])] * n_outputs)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;stacker, feature_names, X, y, expected_names&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression(random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">iris.feature_names</span><span class="s3">,</span>
            <span class="s1">X_iris</span><span class="s3">,</span>
            <span class="s1">y_iris</span><span class="s3">,</span>
            <span class="s1">[</span>
                <span class="s5">&quot;stackingclassifier_lr0&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_lr1&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_lr2&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_svm0&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_svm1&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_svm2&quot;</span><span class="s3">,</span>
            <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingClassifier(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LogisticRegression(random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;other&quot;</span><span class="s3">, </span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVC(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">iris.feature_names</span><span class="s3">,</span>
            <span class="s1">X_iris[:</span><span class="s4">100</span><span class="s1">]</span><span class="s3">,</span>
            <span class="s1">y_iris[:</span><span class="s4">100</span><span class="s1">]</span><span class="s3">,  </span><span class="s2"># keep only classes 0 and 1</span>
            <span class="s1">[</span>
                <span class="s5">&quot;stackingclassifier_lr&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingclassifier_svm&quot;</span><span class="s3">,</span>
            <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
        <span class="s1">(</span>
            <span class="s1">StackingRegressor(</span>
                <span class="s1">estimators=[</span>
                    <span class="s1">(</span><span class="s5">&quot;lr&quot;</span><span class="s3">, </span><span class="s1">LinearRegression())</span><span class="s3">,</span>
                    <span class="s1">(</span><span class="s5">&quot;svm&quot;</span><span class="s3">, </span><span class="s1">LinearSVR(dual=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">))</span><span class="s3">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">diabetes.feature_names</span><span class="s3">,</span>
            <span class="s1">X_diabetes</span><span class="s3">,</span>
            <span class="s1">y_diabetes</span><span class="s3">,</span>
            <span class="s1">[</span>
                <span class="s5">&quot;stackingregressor_lr&quot;</span><span class="s3">,</span>
                <span class="s5">&quot;stackingregressor_svm&quot;</span><span class="s3">,</span>
            <span class="s1">]</span><span class="s3">,</span>
        <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
    <span class="s1">ids=[</span>
        <span class="s5">&quot;StackingClassifier_multiclass&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;StackingClassifier_binary&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;StackingRegressor&quot;</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;passthrough&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s3">True, False</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_get_feature_names_out(</span>
    <span class="s1">stacker</span><span class="s3">, </span><span class="s1">feature_names</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">expected_names</span><span class="s3">, </span><span class="s1">passthrough</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Check get_feature_names_out works for stacking.&quot;&quot;&quot;</span>

    <span class="s1">stacker.set_params(passthrough=passthrough)</span>
    <span class="s1">stacker.fit(scale(X)</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s3">if </span><span class="s1">passthrough:</span>
        <span class="s1">expected_names = np.concatenate((expected_names</span><span class="s3">, </span><span class="s1">feature_names))</span>

    <span class="s1">names_out = stacker.get_feature_names_out(feature_names)</span>
    <span class="s1">assert_array_equal(names_out</span><span class="s3">, </span><span class="s1">expected_names)</span>


<span class="s3">def </span><span class="s1">test_stacking_classifier_base_regressor():</span>
    <span class="s0">&quot;&quot;&quot;Check that a regressor can be used as the first layer in `StackingClassifier`.&quot;&quot;&quot;</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">scale(X_iris)</span><span class="s3">, </span><span class="s1">y_iris</span><span class="s3">, </span><span class="s1">stratify=y_iris</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">clf = StackingClassifier(estimators=[(</span><span class="s5">&quot;ridge&quot;</span><span class="s3">, </span><span class="s1">Ridge())])</span>
    <span class="s1">clf.fit(X_train</span><span class="s3">, </span><span class="s1">y_train)</span>
    <span class="s1">clf.predict(X_test)</span>
    <span class="s1">clf.predict_proba(X_test)</span>
    <span class="s3">assert </span><span class="s1">clf.score(X_test</span><span class="s3">, </span><span class="s1">y_test) &gt; </span><span class="s4">0.8</span>
</pre>
</body>
</html>
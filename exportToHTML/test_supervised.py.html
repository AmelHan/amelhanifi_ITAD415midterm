<html>
<head>
<title>test_supervised.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_supervised.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_array_almost_equal</span><span class="s0">, </span><span class="s1">assert_array_equal</span>

<span class="s0">from </span><span class="s1">sklearn.metrics.cluster </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">adjusted_mutual_info_score</span><span class="s0">,</span>
    <span class="s1">adjusted_rand_score</span><span class="s0">,</span>
    <span class="s1">completeness_score</span><span class="s0">,</span>
    <span class="s1">contingency_matrix</span><span class="s0">,</span>
    <span class="s1">entropy</span><span class="s0">,</span>
    <span class="s1">expected_mutual_information</span><span class="s0">,</span>
    <span class="s1">fowlkes_mallows_score</span><span class="s0">,</span>
    <span class="s1">homogeneity_completeness_v_measure</span><span class="s0">,</span>
    <span class="s1">homogeneity_score</span><span class="s0">,</span>
    <span class="s1">mutual_info_score</span><span class="s0">,</span>
    <span class="s1">normalized_mutual_info_score</span><span class="s0">,</span>
    <span class="s1">pair_confusion_matrix</span><span class="s0">,</span>
    <span class="s1">rand_score</span><span class="s0">,</span>
    <span class="s1">v_measure_score</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.metrics.cluster._supervised </span><span class="s0">import </span><span class="s1">_generalized_average</span><span class="s0">, </span><span class="s1">check_clusterings</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">assert_all_finite</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">assert_almost_equal</span>

<span class="s1">score_funcs = [</span>
    <span class="s1">adjusted_rand_score</span><span class="s0">,</span>
    <span class="s1">rand_score</span><span class="s0">,</span>
    <span class="s1">homogeneity_score</span><span class="s0">,</span>
    <span class="s1">completeness_score</span><span class="s0">,</span>
    <span class="s1">v_measure_score</span><span class="s0">,</span>
    <span class="s1">adjusted_mutual_info_score</span><span class="s0">,</span>
    <span class="s1">normalized_mutual_info_score</span><span class="s0">,</span>
<span class="s1">]</span>


<span class="s0">def </span><span class="s1">test_error_messages_on_wrong_input():</span>
    <span class="s0">for </span><span class="s1">score_func </span><span class="s0">in </span><span class="s1">score_funcs:</span>
        <span class="s1">expected = (</span>
            <span class="s2">r&quot;Found input variables with inconsistent numbers &quot; r&quot;of samples: \[2, 3\]&quot;</span>
        <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=expected):</span>
            <span class="s1">score_func([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

        <span class="s1">expected = </span><span class="s2">r&quot;labels_true must be 1D: shape is \(2&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=expected):</span>
            <span class="s1">score_func([[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

        <span class="s1">expected = </span><span class="s2">r&quot;labels_pred must be 1D: shape is \(2&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=expected):</span>
            <span class="s1">score_func([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]])</span>


<span class="s0">def </span><span class="s1">test_generalized_average():</span>
    <span class="s1">a</span><span class="s0">, </span><span class="s1">b = </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span>
    <span class="s1">methods = [</span><span class="s2">&quot;min&quot;</span><span class="s0">, </span><span class="s2">&quot;geometric&quot;</span><span class="s0">, </span><span class="s2">&quot;arithmetic&quot;</span><span class="s0">, </span><span class="s2">&quot;max&quot;</span><span class="s1">]</span>
    <span class="s1">means = [_generalized_average(a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">method) </span><span class="s0">for </span><span class="s1">method </span><span class="s0">in </span><span class="s1">methods]</span>
    <span class="s0">assert </span><span class="s1">means[</span><span class="s3">0</span><span class="s1">] &lt;= means[</span><span class="s3">1</span><span class="s1">] &lt;= means[</span><span class="s3">2</span><span class="s1">] &lt;= means[</span><span class="s3">3</span><span class="s1">]</span>
    <span class="s1">c</span><span class="s0">, </span><span class="s1">d = </span><span class="s3">12</span><span class="s0">, </span><span class="s3">12</span>
    <span class="s1">means = [_generalized_average(c</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">method) </span><span class="s0">for </span><span class="s1">method </span><span class="s0">in </span><span class="s1">methods]</span>
    <span class="s0">assert </span><span class="s1">means[</span><span class="s3">0</span><span class="s1">] == means[</span><span class="s3">1</span><span class="s1">] == means[</span><span class="s3">2</span><span class="s1">] == means[</span><span class="s3">3</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">test_perfect_matches():</span>
    <span class="s0">for </span><span class="s1">score_func </span><span class="s0">in </span><span class="s1">score_funcs:</span>
        <span class="s0">assert </span><span class="s1">score_func([]</span><span class="s0">, </span><span class="s1">[]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">42</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42.0</span><span class="s0">, </span><span class="s3">7.0</span><span class="s0">, </span><span class="s3">42.0</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42.0</span><span class="s0">, </span><span class="s3">7.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s1">score_funcs_with_changing_means = [</span>
        <span class="s1">normalized_mutual_info_score</span><span class="s0">,</span>
        <span class="s1">adjusted_mutual_info_score</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">means = {</span><span class="s2">&quot;min&quot;</span><span class="s0">, </span><span class="s2">&quot;geometric&quot;</span><span class="s0">, </span><span class="s2">&quot;arithmetic&quot;</span><span class="s0">, </span><span class="s2">&quot;max&quot;</span><span class="s1">}</span>
    <span class="s0">for </span><span class="s1">score_func </span><span class="s0">in </span><span class="s1">score_funcs_with_changing_means:</span>
        <span class="s0">for </span><span class="s1">mean </span><span class="s0">in </span><span class="s1">means:</span>
            <span class="s0">assert </span><span class="s1">score_func([]</span><span class="s0">, </span><span class="s1">[]</span><span class="s0">, </span><span class="s1">average_method=mean) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func([</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func(</span>
                <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func(</span>
                <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">42</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func(</span>
                <span class="s1">[</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42.0</span><span class="s0">, </span><span class="s3">7.0</span><span class="s0">, </span><span class="s3">42.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func(</span>
                <span class="s1">[</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42.0</span><span class="s0">, </span><span class="s3">7.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">score_func(</span>
                <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">42</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average_method=mean</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_homogeneous_but_not_complete_labeling():</span>
    <span class="s4"># homogeneous but not complete clustering</span>
    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s3">1.00</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s3">0.69</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s3">0.81</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_complete_but_not_homogeneous_labeling():</span>
    <span class="s4"># complete but not homogeneous clustering</span>
    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s3">0.58</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s3">1.00</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s3">0.73</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_not_complete_and_not_homogeneous_labeling():</span>
    <span class="s4"># neither complete nor homogeneous but not so bad either</span>
    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s3">0.67</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s3">0.42</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s3">0.52</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_beta_parameter():</span>
    <span class="s4"># test for when beta passed to</span>
    <span class="s4"># homogeneity_completeness_v_measure</span>
    <span class="s4"># and v_measure_score</span>
    <span class="s1">beta_test = </span><span class="s3">0.2</span>
    <span class="s1">h_test = </span><span class="s3">0.67</span>
    <span class="s1">c_test = </span><span class="s3">0.42</span>
    <span class="s1">v_test = (</span><span class="s3">1 </span><span class="s1">+ beta_test) * h_test * c_test / (beta_test * h_test + c_test)</span>

    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure(</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=beta_test</span>
    <span class="s1">)</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s1">h_test</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s1">c_test</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s1">v_test</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s1">v = v_measure_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=beta_test)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s1">v_test</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_non_consecutive_labels():</span>
    <span class="s4"># regression tests for labels with gaps</span>
    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s3">0.67</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s3">0.42</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s3">0.52</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s1">h</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">v = homogeneity_completeness_v_measure([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(h</span><span class="s0">, </span><span class="s3">0.67</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(c</span><span class="s0">, </span><span class="s3">0.42</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(v</span><span class="s0">, </span><span class="s3">0.52</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s1">ari_1 = adjusted_rand_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">ari_2 = adjusted_rand_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(ari_1</span><span class="s0">, </span><span class="s3">0.24</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(ari_2</span><span class="s0">, </span><span class="s3">0.24</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s1">ri_1 = rand_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">ri_2 = rand_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(ri_1</span><span class="s0">, </span><span class="s3">0.66</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(ri_2</span><span class="s0">, </span><span class="s3">0.66</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">uniform_labelings_scores(score_func</span><span class="s0">, </span><span class="s1">n_samples</span><span class="s0">, </span><span class="s1">k_range</span><span class="s0">, </span><span class="s1">n_runs=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">seed=</span><span class="s3">42</span><span class="s1">):</span>
    <span class="s4"># Compute score for random uniform cluster labelings</span>
    <span class="s1">random_labels = np.random.RandomState(seed).randint</span>
    <span class="s1">scores = np.zeros((len(k_range)</span><span class="s0">, </span><span class="s1">n_runs))</span>
    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">k </span><span class="s0">in </span><span class="s1">enumerate(k_range):</span>
        <span class="s0">for </span><span class="s1">j </span><span class="s0">in </span><span class="s1">range(n_runs):</span>
            <span class="s1">labels_a = random_labels(low=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">high=k</span><span class="s0">, </span><span class="s1">size=n_samples)</span>
            <span class="s1">labels_b = random_labels(low=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">high=k</span><span class="s0">, </span><span class="s1">size=n_samples)</span>
            <span class="s1">scores[i</span><span class="s0">, </span><span class="s1">j] = score_func(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s0">return </span><span class="s1">scores</span>


<span class="s0">def </span><span class="s1">test_adjustment_for_chance():</span>
    <span class="s4"># Check that adjusted scores are almost zero on random labels</span>
    <span class="s1">n_clusters_range = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s3">90</span><span class="s1">]</span>
    <span class="s1">n_samples = </span><span class="s3">100</span>
    <span class="s1">n_runs = </span><span class="s3">10</span>

    <span class="s1">scores = uniform_labelings_scores(</span>
        <span class="s1">adjusted_rand_score</span><span class="s0">, </span><span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_clusters_range</span><span class="s0">, </span><span class="s1">n_runs</span>
    <span class="s1">)</span>

    <span class="s1">max_abs_scores = np.abs(scores).max(axis=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(max_abs_scores</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.02</span><span class="s0">, </span><span class="s3">0.03</span><span class="s0">, </span><span class="s3">0.03</span><span class="s0">, </span><span class="s3">0.02</span><span class="s1">]</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_adjusted_mutual_info_score():</span>
    <span class="s4"># Compute the Adjusted Mutual Information and test against known values</span>
    <span class="s1">labels_a = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
    <span class="s1">labels_b = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s4"># Mutual information</span>
    <span class="s1">mi = mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">assert_almost_equal(mi</span><span class="s0">, </span><span class="s3">0.41022</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s4"># with provided sparse contingency</span>
    <span class="s1">C = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">sparse=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">mi = mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">contingency=C)</span>
    <span class="s1">assert_almost_equal(mi</span><span class="s0">, </span><span class="s3">0.41022</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s4"># with provided dense contingency</span>
    <span class="s1">C = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">mi = mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">contingency=C)</span>
    <span class="s1">assert_almost_equal(mi</span><span class="s0">, </span><span class="s3">0.41022</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s4"># Expected mutual information</span>
    <span class="s1">n_samples = C.sum()</span>
    <span class="s1">emi = expected_mutual_information(C</span><span class="s0">, </span><span class="s1">n_samples)</span>
    <span class="s1">assert_almost_equal(emi</span><span class="s0">, </span><span class="s3">0.15042</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s4"># Adjusted mutual information</span>
    <span class="s1">ami = adjusted_mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">assert_almost_equal(ami</span><span class="s0">, </span><span class="s3">0.27821</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">ami = adjusted_mutual_info_score([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">ami == pytest.approx(</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s4"># Test with a very large array</span>
    <span class="s1">a110 = np.array([list(labels_a) * </span><span class="s3">110</span><span class="s1">]).flatten()</span>
    <span class="s1">b110 = np.array([list(labels_b) * </span><span class="s3">110</span><span class="s1">]).flatten()</span>
    <span class="s1">ami = adjusted_mutual_info_score(a110</span><span class="s0">, </span><span class="s1">b110)</span>
    <span class="s1">assert_almost_equal(ami</span><span class="s0">, </span><span class="s3">0.38</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_expected_mutual_info_overflow():</span>
    <span class="s4"># Test for regression where contingency cell exceeds 2**16</span>
    <span class="s4"># leading to overflow in np.outer, resulting in EMI &gt; 1</span>
    <span class="s0">assert </span><span class="s1">expected_mutual_information(np.array([[</span><span class="s3">70000</span><span class="s1">]])</span><span class="s0">, </span><span class="s3">70000</span><span class="s1">) &lt;= </span><span class="s3">1</span>


<span class="s0">def </span><span class="s1">test_int_overflow_mutual_info_fowlkes_mallows_score():</span>
    <span class="s4"># Test overflow in mutual_info_classif and fowlkes_mallows_score</span>
    <span class="s1">x = np.array(</span>
        <span class="s1">[</span><span class="s3">1</span><span class="s1">] * (</span><span class="s3">52632 </span><span class="s1">+ </span><span class="s3">2529</span><span class="s1">)</span>
        <span class="s1">+ [</span><span class="s3">2</span><span class="s1">] * (</span><span class="s3">14660 </span><span class="s1">+ </span><span class="s3">793</span><span class="s1">)</span>
        <span class="s1">+ [</span><span class="s3">3</span><span class="s1">] * (</span><span class="s3">3271 </span><span class="s1">+ </span><span class="s3">204</span><span class="s1">)</span>
        <span class="s1">+ [</span><span class="s3">4</span><span class="s1">] * (</span><span class="s3">814 </span><span class="s1">+ </span><span class="s3">39</span><span class="s1">)</span>
        <span class="s1">+ [</span><span class="s3">5</span><span class="s1">] * (</span><span class="s3">316 </span><span class="s1">+ </span><span class="s3">20</span><span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s1">y = np.array(</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">52632</span>
        <span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">2529</span>
        <span class="s1">+ [</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">14660</span>
        <span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">793</span>
        <span class="s1">+ [</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">3271</span>
        <span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">204</span>
        <span class="s1">+ [</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">814</span>
        <span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">39</span>
        <span class="s1">+ [</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">316</span>
        <span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">20</span>
    <span class="s1">)</span>

    <span class="s1">assert_all_finite(mutual_info_score(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s1">assert_all_finite(fowlkes_mallows_score(x</span><span class="s0">, </span><span class="s1">y))</span>


<span class="s0">def </span><span class="s1">test_entropy():</span>
    <span class="s1">ent = entropy([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">42.0</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(ent</span><span class="s0">, </span><span class="s3">0.6365141</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(entropy([])</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">entropy([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]) == </span><span class="s3">0</span>


<span class="s0">def </span><span class="s1">test_contingency_matrix():</span>
    <span class="s1">labels_a = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
    <span class="s1">labels_b = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">C = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">C2 = np.histogram2d(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">bins=(np.arange(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.arange(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)))[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">assert_array_almost_equal(C</span><span class="s0">, </span><span class="s1">C2)</span>
    <span class="s1">C = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">0.1</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(C</span><span class="s0">, </span><span class="s1">C2 + </span><span class="s3">0.1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_contingency_matrix_sparse():</span>
    <span class="s1">labels_a = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
    <span class="s1">labels_b = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">C = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">C_sparse = contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">sparse=</span><span class="s0">True</span><span class="s1">).toarray()</span>
    <span class="s1">assert_array_almost_equal(C</span><span class="s0">, </span><span class="s1">C_sparse)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s2">&quot;Cannot set 'eps' when sparse=True&quot;</span><span class="s1">):</span>
        <span class="s1">contingency_matrix(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">1e-10</span><span class="s0">, </span><span class="s1">sparse=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_exactly_zero_info_score():</span>
    <span class="s4"># Check numerical stability when information is exactly zero</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">np.logspace(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s1">).astype(int):</span>
        <span class="s1">labels_a</span><span class="s0">, </span><span class="s1">labels_b = (np.ones(i</span><span class="s0">, </span><span class="s1">dtype=int)</span><span class="s0">, </span><span class="s1">np.arange(i</span><span class="s0">, </span><span class="s1">dtype=int))</span>
        <span class="s0">assert </span><span class="s1">normalized_mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">v_measure_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">adjusted_mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">normalized_mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>
        <span class="s0">for </span><span class="s1">method </span><span class="s0">in </span><span class="s1">[</span><span class="s2">&quot;min&quot;</span><span class="s0">, </span><span class="s2">&quot;geometric&quot;</span><span class="s0">, </span><span class="s2">&quot;arithmetic&quot;</span><span class="s0">, </span><span class="s2">&quot;max&quot;</span><span class="s1">]:</span>
            <span class="s0">assert </span><span class="s1">adjusted_mutual_info_score(</span>
                <span class="s1">labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">average_method=method</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">normalized_mutual_info_score(</span>
                <span class="s1">labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">average_method=method</span>
            <span class="s1">) == pytest.approx(</span><span class="s3">0.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_v_measure_and_mutual_information(seed=</span><span class="s3">36</span><span class="s1">):</span>
    <span class="s4"># Check relation between v_measure, entropy and mutual information</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">np.logspace(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s1">).astype(int):</span>
        <span class="s1">random_state = np.random.RandomState(seed)</span>
        <span class="s1">labels_a</span><span class="s0">, </span><span class="s1">labels_b = (</span>
            <span class="s1">random_state.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">i)</span><span class="s0">,</span>
            <span class="s1">random_state.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">i)</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">v_measure_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span><span class="s0">,</span>
            <span class="s3">2.0</span>
            <span class="s1">* mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
            <span class="s1">/ (entropy(labels_a) + entropy(labels_b))</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">avg = </span><span class="s2">&quot;arithmetic&quot;</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">v_measure_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span><span class="s0">,</span>
            <span class="s1">normalized_mutual_info_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b</span><span class="s0">, </span><span class="s1">average_method=avg)</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_fowlkes_mallows_score():</span>
    <span class="s4"># General case</span>
    <span class="s1">score = fowlkes_mallows_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(score</span><span class="s0">, </span><span class="s3">4.0 </span><span class="s1">/ np.sqrt(</span><span class="s3">12.0 </span><span class="s1">* </span><span class="s3">6.0</span><span class="s1">))</span>

    <span class="s4"># Perfect match but where the label names changed</span>
    <span class="s1">perfect_score = fowlkes_mallows_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(perfect_score</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">)</span>

    <span class="s4"># Worst case</span>
    <span class="s1">worst_score = fowlkes_mallows_score([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(worst_score</span><span class="s0">, </span><span class="s3">0.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_fowlkes_mallows_score_properties():</span>
    <span class="s4"># handcrafted example</span>
    <span class="s1">labels_a = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">labels_b = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">expected = </span><span class="s3">1.0 </span><span class="s1">/ np.sqrt((</span><span class="s3">1.0 </span><span class="s1">+ </span><span class="s3">3.0</span><span class="s1">) * (</span><span class="s3">1.0 </span><span class="s1">+ </span><span class="s3">2.0</span><span class="s1">))</span>
    <span class="s4"># FMI = TP / sqrt((TP + FP) * (TP + FN))</span>

    <span class="s1">score_original = fowlkes_mallows_score(labels_a</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">assert_almost_equal(score_original</span><span class="s0">, </span><span class="s1">expected)</span>

    <span class="s4"># symmetric property</span>
    <span class="s1">score_symmetric = fowlkes_mallows_score(labels_b</span><span class="s0">, </span><span class="s1">labels_a)</span>
    <span class="s1">assert_almost_equal(score_symmetric</span><span class="s0">, </span><span class="s1">expected)</span>

    <span class="s4"># permutation property</span>
    <span class="s1">score_permuted = fowlkes_mallows_score((labels_a + </span><span class="s3">1</span><span class="s1">) % </span><span class="s3">3</span><span class="s0">, </span><span class="s1">labels_b)</span>
    <span class="s1">assert_almost_equal(score_permuted</span><span class="s0">, </span><span class="s1">expected)</span>

    <span class="s4"># symmetric and permutation(both together)</span>
    <span class="s1">score_both = fowlkes_mallows_score(labels_b</span><span class="s0">, </span><span class="s1">(labels_a + </span><span class="s3">2</span><span class="s1">) % </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(score_both</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;labels_true, labels_pred&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s2">&quot;a&quot;</span><span class="s1">] * </span><span class="s3">6</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">6</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;a&quot;</span><span class="s1">] * </span><span class="s3">6</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">6</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s2">&quot;a&quot;</span><span class="s1">] * </span><span class="s3">6</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;a&quot;</span><span class="s1">] * </span><span class="s3">6</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_mutual_info_score_positive_constant_label(labels_true</span><span class="s0">, </span><span class="s1">labels_pred):</span>
    <span class="s4"># Check that MI = 0 when one or both labelling are constant</span>
    <span class="s4"># non-regression test for #16355</span>
    <span class="s0">assert </span><span class="s1">mutual_info_score(labels_true</span><span class="s0">, </span><span class="s1">labels_pred) == </span><span class="s3">0</span>


<span class="s0">def </span><span class="s1">test_check_clustering_error():</span>
    <span class="s4"># Test warning message for continuous values</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">noise = rng.rand(</span><span class="s3">500</span><span class="s1">)</span>
    <span class="s1">wavelength = np.linspace(</span><span class="s3">0.01</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">500</span><span class="s1">) * </span><span class="s3">1e-6</span>
    <span class="s1">msg = (</span>
        <span class="s2">&quot;Clustering metrics expects discrete values but received &quot;</span>
        <span class="s2">&quot;continuous values for label, and continuous values for &quot;</span>
        <span class="s2">&quot;target&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">check_clusterings(wavelength</span><span class="s0">, </span><span class="s1">noise)</span>


<span class="s0">def </span><span class="s1">test_pair_confusion_matrix_fully_dispersed():</span>
    <span class="s4"># edge case: every element is its own cluster</span>
    <span class="s1">N = </span><span class="s3">100</span>
    <span class="s1">clustering1 = list(range(N))</span>
    <span class="s1">clustering2 = clustering1</span>
    <span class="s1">expected = np.array([[N * (N - </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]])</span>
    <span class="s1">assert_array_equal(pair_confusion_matrix(clustering1</span><span class="s0">, </span><span class="s1">clustering2)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_pair_confusion_matrix_single_cluster():</span>
    <span class="s4"># edge case: only one cluster</span>
    <span class="s1">N = </span><span class="s3">100</span>
    <span class="s1">clustering1 = np.zeros((N</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">clustering2 = clustering1</span>
    <span class="s1">expected = np.array([[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s1">N * (N - </span><span class="s3">1</span><span class="s1">)]])</span>
    <span class="s1">assert_array_equal(pair_confusion_matrix(clustering1</span><span class="s0">, </span><span class="s1">clustering2)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_pair_confusion_matrix():</span>
    <span class="s4"># regular case: different non-trivial clusterings</span>
    <span class="s1">n = </span><span class="s3">10</span>
    <span class="s1">N = n**</span><span class="s3">2</span>
    <span class="s1">clustering1 = np.hstack([[i + </span><span class="s3">1</span><span class="s1">] * n </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n)])</span>
    <span class="s1">clustering2 = np.hstack([[i + </span><span class="s3">1</span><span class="s1">] * (n + </span><span class="s3">1</span><span class="s1">) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n)])[:N]</span>
    <span class="s4"># basic quadratic implementation</span>
    <span class="s1">expected = np.zeros(shape=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=np.int64)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(len(clustering1)):</span>
        <span class="s0">for </span><span class="s1">j </span><span class="s0">in </span><span class="s1">range(len(clustering2)):</span>
            <span class="s0">if </span><span class="s1">i != j:</span>
                <span class="s1">same_cluster_1 = int(clustering1[i] == clustering1[j])</span>
                <span class="s1">same_cluster_2 = int(clustering2[i] == clustering2[j])</span>
                <span class="s1">expected[same_cluster_1</span><span class="s0">, </span><span class="s1">same_cluster_2] += </span><span class="s3">1</span>
    <span class="s1">assert_array_equal(pair_confusion_matrix(clustering1</span><span class="s0">, </span><span class="s1">clustering2)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;clustering1, clustering2&quot;</span><span class="s0">,</span>
    <span class="s1">[(list(range(</span><span class="s3">100</span><span class="s1">))</span><span class="s0">, </span><span class="s1">list(range(</span><span class="s3">100</span><span class="s1">)))</span><span class="s0">, </span><span class="s1">(np.zeros((</span><span class="s3">100</span><span class="s0">,</span><span class="s1">))</span><span class="s0">, </span><span class="s1">np.zeros((</span><span class="s3">100</span><span class="s0">,</span><span class="s1">)))]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_rand_score_edge_cases(clustering1</span><span class="s0">, </span><span class="s1">clustering2):</span>
    <span class="s4"># edge case 1: every element is its own cluster</span>
    <span class="s4"># edge case 2: only one cluster</span>
    <span class="s1">assert_allclose(rand_score(clustering1</span><span class="s0">, </span><span class="s1">clustering2)</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_rand_score():</span>
    <span class="s4"># regular case: different non-trivial clusterings</span>
    <span class="s1">clustering1 = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">clustering2 = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s4"># pair confusion matrix</span>
    <span class="s1">D11 = </span><span class="s3">2 </span><span class="s1">* </span><span class="s3">2  </span><span class="s4"># ordered pairs (1, 3), (5, 6)</span>
    <span class="s1">D10 = </span><span class="s3">2 </span><span class="s1">* </span><span class="s3">4  </span><span class="s4"># ordered pairs (1, 2), (2, 3), (4, 5), (4, 6)</span>
    <span class="s1">D01 = </span><span class="s3">2 </span><span class="s1">* </span><span class="s3">1  </span><span class="s4"># ordered pair (2, 4)</span>
    <span class="s1">D00 = </span><span class="s3">5 </span><span class="s1">* </span><span class="s3">6 </span><span class="s1">- D11 - D01 - D10  </span><span class="s4"># the remaining pairs</span>
    <span class="s4"># rand score</span>
    <span class="s1">expected_numerator = D00 + D11</span>
    <span class="s1">expected_denominator = D00 + D01 + D10 + D11</span>
    <span class="s1">expected = expected_numerator / expected_denominator</span>
    <span class="s1">assert_allclose(rand_score(clustering1</span><span class="s0">, </span><span class="s1">clustering2)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_adjusted_rand_score_overflow():</span>
    <span class="s5">&quot;&quot;&quot;Check that large amount of data will not lead to overflow in 
    `adjusted_rand_score`. 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/20305 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">y_true = rng.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">100_000</span><span class="s0">, </span><span class="s1">dtype=np.int8)</span>
    <span class="s1">y_pred = rng.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">100_000</span><span class="s0">, </span><span class="s1">dtype=np.int8)</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s2">&quot;error&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s1">adjusted_rand_score(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;average_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;min&quot;</span><span class="s0">, </span><span class="s2">&quot;arithmetic&quot;</span><span class="s0">, </span><span class="s2">&quot;geometric&quot;</span><span class="s0">, </span><span class="s2">&quot;max&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_normalized_mutual_info_score_bounded(average_method):</span>
    <span class="s5">&quot;&quot;&quot;Check that nmi returns a score between 0 (included) and 1 (excluded 
    for non-perfect match) 
 
    Non-regression test for issue #13836 
    &quot;&quot;&quot;</span>
    <span class="s1">labels1 = [</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">469</span>
    <span class="s1">labels2 = [</span><span class="s3">1</span><span class="s1">] + labels1[</span><span class="s3">1</span><span class="s1">:]</span>
    <span class="s1">labels3 = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] + labels1[</span><span class="s3">2</span><span class="s1">:]</span>

    <span class="s4"># labels1 is constant. The mutual info between labels1 and any other labelling is 0.</span>
    <span class="s1">nmi = normalized_mutual_info_score(labels1</span><span class="s0">, </span><span class="s1">labels2</span><span class="s0">, </span><span class="s1">average_method=average_method)</span>
    <span class="s0">assert </span><span class="s1">nmi == </span><span class="s3">0</span>

    <span class="s4"># non constant, non perfect matching labels</span>
    <span class="s1">nmi = normalized_mutual_info_score(labels2</span><span class="s0">, </span><span class="s1">labels3</span><span class="s0">, </span><span class="s1">average_method=average_method)</span>
    <span class="s0">assert </span><span class="s3">0 </span><span class="s1">&lt;= nmi &lt; </span><span class="s3">1</span>
</pre>
</body>
</html>
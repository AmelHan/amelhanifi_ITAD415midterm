<html>
<head>
<title>test_classification.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_classification.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">re</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>
<span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">chain</span><span class="s0">, </span><span class="s1">permutations</span><span class="s0">, </span><span class="s1">product</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">linalg</span>
<span class="s0">from </span><span class="s1">scipy.spatial.distance </span><span class="s0">import </span><span class="s1">hamming </span><span class="s0">as </span><span class="s1">sp_hamming</span>
<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">bernoulli</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">datasets</span><span class="s0">, </span><span class="s1">svm</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">make_multilabel_classification</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">UndefinedMetricWarning</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">accuracy_score</span><span class="s0">,</span>
    <span class="s1">average_precision_score</span><span class="s0">,</span>
    <span class="s1">balanced_accuracy_score</span><span class="s0">,</span>
    <span class="s1">brier_score_loss</span><span class="s0">,</span>
    <span class="s1">class_likelihood_ratios</span><span class="s0">,</span>
    <span class="s1">classification_report</span><span class="s0">,</span>
    <span class="s1">cohen_kappa_score</span><span class="s0">,</span>
    <span class="s1">confusion_matrix</span><span class="s0">,</span>
    <span class="s1">f1_score</span><span class="s0">,</span>
    <span class="s1">fbeta_score</span><span class="s0">,</span>
    <span class="s1">hamming_loss</span><span class="s0">,</span>
    <span class="s1">hinge_loss</span><span class="s0">,</span>
    <span class="s1">jaccard_score</span><span class="s0">,</span>
    <span class="s1">log_loss</span><span class="s0">,</span>
    <span class="s1">make_scorer</span><span class="s0">,</span>
    <span class="s1">matthews_corrcoef</span><span class="s0">,</span>
    <span class="s1">multilabel_confusion_matrix</span><span class="s0">,</span>
    <span class="s1">precision_recall_fscore_support</span><span class="s0">,</span>
    <span class="s1">precision_score</span><span class="s0">,</span>
    <span class="s1">recall_score</span><span class="s0">,</span>
    <span class="s1">zero_one_loss</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.metrics._classification </span><span class="s0">import </span><span class="s1">_check_targets</span>
<span class="s0">from </span><span class="s1">sklearn.model_selection </span><span class="s0">import </span><span class="s1">cross_val_score</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">LabelBinarizer</span><span class="s0">, </span><span class="s1">label_binarize</span>
<span class="s0">from </span><span class="s1">sklearn.tree </span><span class="s0">import </span><span class="s1">DecisionTreeClassifier</span>
<span class="s0">from </span><span class="s1">sklearn.utils._mocking </span><span class="s0">import </span><span class="s1">MockDataFrame</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
    <span class="s1">assert_no_warnings</span><span class="s0">,</span>
    <span class="s1">ignore_warnings</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils.extmath </span><span class="s0">import </span><span class="s1">_nanaverage</span>
<span class="s0">from </span><span class="s1">sklearn.utils.validation </span><span class="s0">import </span><span class="s1">check_random_state</span>

<span class="s2">###############################################################################</span>
<span class="s2"># Utilities for testing</span>


<span class="s0">def </span><span class="s1">make_prediction(dataset=</span><span class="s0">None, </span><span class="s1">binary=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot;Make some classification predictions on a toy dataset using a SVC 
 
    If binary is True restrict to a binary classification problem instead of a 
    multiclass classification problem 
    &quot;&quot;&quot;</span>

    <span class="s0">if </span><span class="s1">dataset </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s2"># import some data to play with</span>
        <span class="s1">dataset = datasets.load_iris()</span>

    <span class="s1">X = dataset.data</span>
    <span class="s1">y = dataset.target</span>

    <span class="s0">if </span><span class="s1">binary:</span>
        <span class="s2"># restrict to a binary classification task</span>
        <span class="s1">X</span><span class="s0">, </span><span class="s1">y = X[y &lt; </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y[y &lt; </span><span class="s4">2</span><span class="s1">]</span>

    <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features = X.shape</span>
    <span class="s1">p = np.arange(n_samples)</span>

    <span class="s1">rng = check_random_state(</span><span class="s4">37</span><span class="s1">)</span>
    <span class="s1">rng.shuffle(p)</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = X[p]</span><span class="s0">, </span><span class="s1">y[p]</span>
    <span class="s1">half = int(n_samples / </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s2"># add noisy features to make the problem harder and avoid perfect results</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">X = np.c_[X</span><span class="s0">, </span><span class="s1">rng.randn(n_samples</span><span class="s0">, </span><span class="s4">200 </span><span class="s1">* n_features)]</span>

    <span class="s2"># run classifier, get class probabilities and label predictions</span>
    <span class="s1">clf = svm.SVC(kernel=</span><span class="s5">&quot;linear&quot;</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">probas_pred = clf.fit(X[:half]</span><span class="s0">, </span><span class="s1">y[:half]).predict_proba(X[half:])</span>

    <span class="s0">if </span><span class="s1">binary:</span>
        <span class="s2"># only interested in probabilities of the positive case</span>
        <span class="s2"># XXX: do we really want a special API for the binary case?</span>
        <span class="s1">probas_pred = probas_pred[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>

    <span class="s1">y_pred = clf.predict(X[half:])</span>
    <span class="s1">y_true = y[half:]</span>
    <span class="s0">return </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">probas_pred</span>


<span class="s2">###############################################################################</span>
<span class="s2"># Tests</span>


<span class="s0">def </span><span class="s1">test_classification_report_dictionary_output():</span>
    <span class="s2"># Test performance report with dictionary output</span>
    <span class="s1">iris = datasets.load_iris()</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(dataset=iris</span><span class="s0">, </span><span class="s1">binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># print classification report with class names</span>
    <span class="s1">expected_report = {</span>
        <span class="s5">&quot;setosa&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: </span><span class="s4">0.82608695652173914</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: </span><span class="s4">0.79166666666666663</span><span class="s0">,</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: </span><span class="s4">0.8085106382978724</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">24</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s5">&quot;versicolor&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: </span><span class="s4">0.33333333333333331</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: </span><span class="s4">0.096774193548387094</span><span class="s0">,</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: </span><span class="s4">0.15000000000000002</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">31</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s5">&quot;virginica&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: </span><span class="s4">0.41860465116279072</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: </span><span class="s4">0.90000000000000002</span><span class="s0">,</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: </span><span class="s4">0.57142857142857151</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">20</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s5">&quot;macro avg&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: </span><span class="s4">0.5099797365754813</span><span class="s0">,</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: </span><span class="s4">0.5260083136726211</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: </span><span class="s4">0.596146953405018</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">75</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s5">&quot;accuracy&quot;</span><span class="s1">: </span><span class="s4">0.5333333333333333</span><span class="s0">,</span>
        <span class="s5">&quot;weighted avg&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: </span><span class="s4">0.47310435663627154</span><span class="s0">,</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: </span><span class="s4">0.5137535108414785</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: </span><span class="s4">0.5333333333333333</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">75</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
    <span class="s1">}</span>

    <span class="s1">report = classification_report(</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">labels=np.arange(len(iris.target_names))</span><span class="s0">,</span>
        <span class="s1">target_names=iris.target_names</span><span class="s0">,</span>
        <span class="s1">output_dict=</span><span class="s0">True,</span>
    <span class="s1">)</span>

    <span class="s2"># assert the 2 dicts are equal.</span>
    <span class="s0">assert </span><span class="s1">report.keys() == expected_report.keys()</span>
    <span class="s0">for </span><span class="s1">key </span><span class="s0">in </span><span class="s1">expected_report:</span>
        <span class="s0">if </span><span class="s1">key == </span><span class="s5">&quot;accuracy&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">isinstance(report[key]</span><span class="s0">, </span><span class="s1">float)</span>
            <span class="s0">assert </span><span class="s1">report[key] == expected_report[key]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">report[key].keys() == expected_report[key].keys()</span>
            <span class="s0">for </span><span class="s1">metric </span><span class="s0">in </span><span class="s1">expected_report[key]:</span>
                <span class="s1">assert_almost_equal(expected_report[key][metric]</span><span class="s0">, </span><span class="s1">report[key][metric])</span>

    <span class="s0">assert </span><span class="s1">isinstance(expected_report[</span><span class="s5">&quot;setosa&quot;</span><span class="s1">][</span><span class="s5">&quot;precision&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">float)</span>
    <span class="s0">assert </span><span class="s1">isinstance(expected_report[</span><span class="s5">&quot;macro avg&quot;</span><span class="s1">][</span><span class="s5">&quot;precision&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">float)</span>
    <span class="s0">assert </span><span class="s1">isinstance(expected_report[</span><span class="s5">&quot;setosa&quot;</span><span class="s1">][</span><span class="s5">&quot;support&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">int)</span>
    <span class="s0">assert </span><span class="s1">isinstance(expected_report[</span><span class="s5">&quot;macro avg&quot;</span><span class="s1">][</span><span class="s5">&quot;support&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">int)</span>


<span class="s0">def </span><span class="s1">test_classification_report_output_dict_empty_input():</span>
    <span class="s1">report = classification_report(y_true=[]</span><span class="s0">, </span><span class="s1">y_pred=[]</span><span class="s0">, </span><span class="s1">output_dict=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">expected_report = {</span>
        <span class="s5">&quot;accuracy&quot;</span><span class="s1">: </span><span class="s4">0.0</span><span class="s0">,</span>
        <span class="s5">&quot;macro avg&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s5">&quot;weighted avg&quot;</span><span class="s1">: {</span>
            <span class="s5">&quot;f1-score&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;precision&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;recall&quot;</span><span class="s1">: np.nan</span><span class="s0">,</span>
            <span class="s5">&quot;support&quot;</span><span class="s1">: </span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
    <span class="s1">}</span>
    <span class="s0">assert </span><span class="s1">isinstance(report</span><span class="s0">, </span><span class="s1">dict)</span>
    <span class="s2"># assert the 2 dicts are equal.</span>
    <span class="s0">assert </span><span class="s1">report.keys() == expected_report.keys()</span>
    <span class="s0">for </span><span class="s1">key </span><span class="s0">in </span><span class="s1">expected_report:</span>
        <span class="s0">if </span><span class="s1">key == </span><span class="s5">&quot;accuracy&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">isinstance(report[key]</span><span class="s0">, </span><span class="s1">float)</span>
            <span class="s0">assert </span><span class="s1">report[key] == expected_report[key]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">report[key].keys() == expected_report[key].keys()</span>
            <span class="s0">for </span><span class="s1">metric </span><span class="s0">in </span><span class="s1">expected_report[key]:</span>
                <span class="s1">assert_almost_equal(expected_report[key][metric]</span><span class="s0">, </span><span class="s1">report[key][metric])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;warn&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_classification_report_zero_division_warning(zero_division):</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred = [</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;c&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;d&quot;</span><span class="s1">]</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">classification_report(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span><span class="s0">, </span><span class="s1">output_dict=</span><span class="s0">True</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">len(record) &gt; </span><span class="s4">1</span>
            <span class="s0">for </span><span class="s1">item </span><span class="s0">in </span><span class="s1">record:</span>
                <span class="s1">msg = </span><span class="s5">&quot;Use `zero_division` parameter to control this behavior.&quot;</span>
                <span class="s0">assert </span><span class="s1">msg </span><span class="s0">in </span><span class="s1">str(item.message)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert not </span><span class="s1">record</span>


<span class="s0">def </span><span class="s1">test_multilabel_accuracy_score_subset_accuracy():</span>
    <span class="s2"># Dense label indicator matrix format</span>
    <span class="s1">y1 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y2 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>

    <span class="s0">assert </span><span class="s1">accuracy_score(y1</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">0.5</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y1</span><span class="s0">, </span><span class="s1">y1) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y2</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y2</span><span class="s0">, </span><span class="s1">np.logical_not(y2)) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y1</span><span class="s0">, </span><span class="s1">np.logical_not(y1)) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y1</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">accuracy_score(y2</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">0</span>


<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_binary():</span>
    <span class="s2"># Test Precision Recall and F1 Score for binary classification task</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s2"># detailed measures for each class</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.73</span><span class="s0">, </span><span class="s4">0.85</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.88</span><span class="s0">, </span><span class="s4">0.68</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.80</span><span class="s0">, </span><span class="s4">0.76</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">25</span><span class="s0">, </span><span class="s4">25</span><span class="s1">])</span>

    <span class="s2"># individual scoring function that can be used for grid search: in the</span>
    <span class="s2"># binary class case the score is the value of the measure for the positive</span>
    <span class="s2"># class (e.g. label == 1). This is deprecated for average != 'binary'.</span>
    <span class="s0">for </span><span class="s1">kwargs</span><span class="s0">, </span><span class="s1">my_assert </span><span class="s0">in </span><span class="s1">[</span>
        <span class="s1">({}</span><span class="s0">, </span><span class="s1">assert_no_warnings)</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s5">&quot;average&quot;</span><span class="s1">: </span><span class="s5">&quot;binary&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">assert_no_warnings)</span><span class="s0">,</span>
    <span class="s1">]:</span>
        <span class="s1">ps = my_assert(precision_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">**kwargs)</span>
        <span class="s1">assert_array_almost_equal(ps</span><span class="s0">, </span><span class="s4">0.85</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s1">rs = my_assert(recall_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">**kwargs)</span>
        <span class="s1">assert_array_almost_equal(rs</span><span class="s0">, </span><span class="s4">0.68</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s1">fs = my_assert(f1_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">**kwargs)</span>
        <span class="s1">assert_array_almost_equal(fs</span><span class="s0">, </span><span class="s4">0.76</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s1">assert_almost_equal(</span>
            <span class="s1">my_assert(fbeta_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">**kwargs)</span><span class="s0">,</span>
            <span class="s1">(</span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">2</span><span class="s1">**</span><span class="s4">2</span><span class="s1">) * ps * rs / (</span><span class="s4">2</span><span class="s1">**</span><span class="s4">2 </span><span class="s1">* ps + rs)</span><span class="s0">,</span>
            <span class="s4">2</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f_binary_single_class():</span>
    <span class="s2"># Test precision, recall and F-scores behave with a single positive or</span>
    <span class="s2"># negative class</span>
    <span class="s2"># Such a case may occur with non-stratified cross-validation</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s1">== precision_score([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s1">== recall_score([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s1">== f1_score([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s1">== fbeta_score([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s4">0.0 </span><span class="s1">== precision_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">0.0 </span><span class="s1">== recall_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">0.0 </span><span class="s1">== f1_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s4">0.0 </span><span class="s1">== fbeta_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=float(</span><span class="s5">&quot;inf&quot;</span><span class="s1">))</span>
    <span class="s0">assert </span><span class="s1">fbeta_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=float(</span><span class="s5">&quot;inf&quot;</span><span class="s1">)) == pytest.approx(</span>
        <span class="s1">fbeta_score([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1e5</span><span class="s1">)</span>
    <span class="s1">)</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f_extra_labels():</span>
    <span class="s2"># Test handling of explicit additional (not in input) labels to PRF</span>
    <span class="s1">y_true = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_true_bin = label_binarize(y_true</span><span class="s0">, </span><span class="s1">classes=np.arange(</span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">y_pred_bin = label_binarize(y_pred</span><span class="s0">, </span><span class="s1">classes=np.arange(</span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">data = [(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">(y_true_bin</span><span class="s0">, </span><span class="s1">y_pred_bin)]</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">(y_true</span><span class="s0">, </span><span class="s1">y_pred) </span><span class="s0">in </span><span class="s1">enumerate(data):</span>
        <span class="s2"># No average: zeros in array</span>
        <span class="s1">actual = recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
        <span class="s1">assert_array_almost_equal([</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">actual)</span>

        <span class="s2"># Macro average is changed</span>
        <span class="s1">actual = recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
        <span class="s1">assert_array_almost_equal(np.mean([</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">])</span><span class="s0">, </span><span class="s1">actual)</span>

        <span class="s2"># No effect otherwise</span>
        <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">[</span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;samples&quot;</span><span class="s1">]:</span>
            <span class="s0">if </span><span class="s1">average == </span><span class="s5">&quot;samples&quot; </span><span class="s0">and </span><span class="s1">i == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s0">continue</span>
            <span class="s1">assert_almost_equal(</span>
                <span class="s1">recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=average)</span><span class="s0">,</span>
                <span class="s1">recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=</span><span class="s0">None, </span><span class="s1">average=average)</span><span class="s0">,</span>
            <span class="s1">)</span>

    <span class="s2"># Error when introducing invalid label in multilabel case</span>
    <span class="s2"># (although it would only affect performance if average='macro'/None)</span>
    <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">[</span><span class="s0">None, </span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s5">&quot;samples&quot;</span><span class="s1">]:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">recall_score(y_true_bin</span><span class="s0">, </span><span class="s1">y_pred_bin</span><span class="s0">, </span><span class="s1">labels=np.arange(</span><span class="s4">6</span><span class="s1">)</span><span class="s0">, </span><span class="s1">average=average)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">recall_score(</span>
                <span class="s1">y_true_bin</span><span class="s0">, </span><span class="s1">y_pred_bin</span><span class="s0">, </span><span class="s1">labels=np.arange(-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">4</span><span class="s1">)</span><span class="s0">, </span><span class="s1">average=average</span>
            <span class="s1">)</span>

    <span class="s2"># tests non-regression on issue #10307</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">_ = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">assert_almost_equal(np.array([p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f])</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s4">3 </span><span class="s1">/ </span><span class="s4">4</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">5 </span><span class="s1">/ </span><span class="s4">6</span><span class="s1">]))</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f_ignored_labels():</span>
    <span class="s2"># Test a subset of labels may be requested for PRF</span>
    <span class="s1">y_true = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">y_true_bin = label_binarize(y_true</span><span class="s0">, </span><span class="s1">classes=np.arange(</span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">y_pred_bin = label_binarize(y_pred</span><span class="s0">, </span><span class="s1">classes=np.arange(</span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">data = [(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">(y_true_bin</span><span class="s0">, </span><span class="s1">y_pred_bin)]</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">(y_true</span><span class="s0">, </span><span class="s1">y_pred) </span><span class="s0">in </span><span class="s1">enumerate(data):</span>
        <span class="s1">recall_13 = partial(recall_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>
        <span class="s1">recall_all = partial(recall_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=</span><span class="s0">None</span><span class="s1">)</span>

        <span class="s1">assert_array_almost_equal([</span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">recall_13(average=</span><span class="s0">None</span><span class="s1">))</span>
        <span class="s1">assert_almost_equal((</span><span class="s4">0.5 </span><span class="s1">+ </span><span class="s4">1.0</span><span class="s1">) / </span><span class="s4">2</span><span class="s0">, </span><span class="s1">recall_13(average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">))</span>
        <span class="s1">assert_almost_equal((</span><span class="s4">0.5 </span><span class="s1">* </span><span class="s4">2 </span><span class="s1">+ </span><span class="s4">1.0 </span><span class="s1">* </span><span class="s4">1</span><span class="s1">) / </span><span class="s4">3</span><span class="s0">, </span><span class="s1">recall_13(average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">))</span>
        <span class="s1">assert_almost_equal(</span><span class="s4">2.0 </span><span class="s1">/ </span><span class="s4">3</span><span class="s0">, </span><span class="s1">recall_13(average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">))</span>

        <span class="s2"># ensure the above were meaningful tests:</span>
        <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">[</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s1">]:</span>
            <span class="s0">assert </span><span class="s1">recall_13(average=average) != recall_all(average=average)</span>


<span class="s0">def </span><span class="s1">test_average_precision_score_non_binary_class():</span>
    <span class="s3">&quot;&quot;&quot;Test multiclass-multiouptut for `average_precision_score`.&quot;&quot;&quot;</span>
    <span class="s1">y_true = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">y_score = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[</span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.8</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">err_msg = </span><span class="s5">&quot;multiclass-multioutput format is not supported&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">average_precision_score(y_true</span><span class="s0">, </span><span class="s1">y_score</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;y_true, y_score&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">np.array(</span>
                <span class="s1">[</span>
                    <span class="s1">[</span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.8</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_average_precision_score_duplicate_values(y_true</span><span class="s0">, </span><span class="s1">y_score):</span>
    <span class="s3">&quot;&quot;&quot; 
    Duplicate values with precision-recall require a different 
    processing than when computing the AUC of a ROC, because the 
    precision-recall curve is a decreasing curve 
    The following situation corresponds to a perfect 
    test statistic, the average_precision_score should be 1. 
    &quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">average_precision_score(y_true</span><span class="s0">, </span><span class="s1">y_score) == </span><span class="s4">1</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;y_true, y_score&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">np.array(</span>
                <span class="s1">[</span>
                    <span class="s1">[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">0.8</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">]</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.6</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_average_precision_score_tied_values(y_true</span><span class="s0">, </span><span class="s1">y_score):</span>
    <span class="s2"># Here if we go from left to right in y_true, the 0 values are</span>
    <span class="s2"># separated from the 1 values, so it appears that we've</span>
    <span class="s2"># correctly sorted our classifications. But in fact the first two</span>
    <span class="s2"># values have the same score (0.5) and so the first two values</span>
    <span class="s2"># could be swapped around, creating an imperfect sorting. This</span>
    <span class="s2"># imperfection should come through in the end score, making it less</span>
    <span class="s2"># than one.</span>
    <span class="s0">assert </span><span class="s1">average_precision_score(y_true</span><span class="s0">, </span><span class="s1">y_score) != </span><span class="s4">1.0</span>


<span class="s0">def </span><span class="s1">test_precision_recall_f_unused_pos_label():</span>
    <span class="s2"># Check warning that pos_label unused when set to non-default value</span>
    <span class="s2"># but average != 'binary'; even if data is binary.</span>

    <span class="s1">msg = (</span>
        <span class="s5">r&quot;Note that pos_label \(set to 2\) is &quot;</span>
        <span class="s5">r&quot;ignored when average != 'binary' \(got 'macro'\). You &quot;</span>
        <span class="s5">r&quot;may use labels=\[pos_label\] to specify a single &quot;</span>
        <span class="s5">&quot;positive class.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">precision_recall_fscore_support(</span>
            <span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_confusion_matrix_binary():</span>
    <span class="s2"># Test confusion matrix - binary classification case</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred):</span>
        <span class="s1">cm = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">22</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">8</span><span class="s0">, </span><span class="s4">17</span><span class="s1">]])</span>

        <span class="s1">tp</span><span class="s0">, </span><span class="s1">fp</span><span class="s0">, </span><span class="s1">fn</span><span class="s0">, </span><span class="s1">tn = cm.flatten()</span>
        <span class="s1">num = tp * tn - fp * fn</span>
        <span class="s1">den = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))</span>

        <span class="s1">true_mcc = </span><span class="s4">0 </span><span class="s0">if </span><span class="s1">den == </span><span class="s4">0 </span><span class="s0">else </span><span class="s1">num / den</span>
        <span class="s1">mcc = matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">assert_array_almost_equal(mcc</span><span class="s0">, </span><span class="s1">true_mcc</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">assert_array_almost_equal(mcc</span><span class="s0">, </span><span class="s4">0.57</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">test([str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_true]</span><span class="s0">, </span><span class="s1">[str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_pred])</span>


<span class="s0">def </span><span class="s1">test_multilabel_confusion_matrix_binary():</span>
    <span class="s2"># Test multilabel confusion matrix - binary classification case</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred):</span>
        <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">17</span><span class="s0">, </span><span class="s4">8</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">22</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">22</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">8</span><span class="s0">, </span><span class="s4">17</span><span class="s1">]]])</span>

    <span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">test([str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_true]</span><span class="s0">, </span><span class="s1">[str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_pred])</span>


<span class="s0">def </span><span class="s1">test_multilabel_confusion_matrix_multiclass():</span>
    <span class="s2"># Test multilabel confusion matrix - multi-class case</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">string_type=</span><span class="s0">False</span><span class="s1">):</span>
        <span class="s2"># compute confusion matrix with default labels introspection</span>
        <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">assert_array_equal(</span>
            <span class="s1">cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">47</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">5</span><span class="s0">, </span><span class="s4">19</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">38</span><span class="s0">, </span><span class="s4">6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">28</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">30</span><span class="s0">, </span><span class="s4">25</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">18</span><span class="s1">]]]</span>
        <span class="s1">)</span>

        <span class="s2"># compute confusion matrix with explicit label ordering</span>
        <span class="s1">labels = [</span><span class="s5">&quot;0&quot;</span><span class="s0">, </span><span class="s5">&quot;2&quot;</span><span class="s0">, </span><span class="s5">&quot;1&quot;</span><span class="s1">] </span><span class="s0">if </span><span class="s1">string_type </span><span class="s0">else </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=labels)</span>
        <span class="s1">assert_array_equal(</span>
            <span class="s1">cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">47</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">5</span><span class="s0">, </span><span class="s4">19</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">30</span><span class="s0">, </span><span class="s4">25</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">18</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">38</span><span class="s0">, </span><span class="s4">6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">28</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]]]</span>
        <span class="s1">)</span>

        <span class="s2"># compute confusion matrix with super set of present labels</span>
        <span class="s1">labels = [</span><span class="s5">&quot;0&quot;</span><span class="s0">, </span><span class="s5">&quot;2&quot;</span><span class="s0">, </span><span class="s5">&quot;1&quot;</span><span class="s0">, </span><span class="s5">&quot;3&quot;</span><span class="s1">] </span><span class="s0">if </span><span class="s1">string_type </span><span class="s0">else </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=labels)</span>
        <span class="s1">assert_array_equal(</span>
            <span class="s1">cm</span><span class="s0">,</span>
            <span class="s1">[</span>
                <span class="s1">[[</span><span class="s4">47</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">5</span><span class="s0">, </span><span class="s4">19</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s1">[[</span><span class="s4">30</span><span class="s0">, </span><span class="s4">25</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">18</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s1">[[</span><span class="s4">38</span><span class="s0">, </span><span class="s4">6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">28</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s1">[[</span><span class="s4">75</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">,</span>
            <span class="s1">]</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s1">test(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">test([str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_true]</span><span class="s0">, </span><span class="s1">[str(y) </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">y_pred]</span><span class="s0">, </span><span class="s1">string_type=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_multilabel_confusion_matrix_multilabel():</span>
    <span class="s2"># Test multilabel confusion matrix - multilabel-indicator case</span>
    <span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">csc_matrix</span><span class="s0">, </span><span class="s1">csr_matrix</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y_true_csr = csr_matrix(y_true)</span>
    <span class="s1">y_pred_csr = csr_matrix(y_pred)</span>
    <span class="s1">y_true_csc = csc_matrix(y_true)</span>
    <span class="s1">y_pred_csc = csc_matrix(y_pred)</span>

    <span class="s2"># cross test different types</span>
    <span class="s1">sample_weight = np.array([</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">real_cm = [[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]]</span>
    <span class="s1">trues = [y_true</span><span class="s0">, </span><span class="s1">y_true_csr</span><span class="s0">, </span><span class="s1">y_true_csc]</span>
    <span class="s1">preds = [y_pred</span><span class="s0">, </span><span class="s1">y_pred_csr</span><span class="s0">, </span><span class="s1">y_pred_csc]</span>

    <span class="s0">for </span><span class="s1">y_true_tmp </span><span class="s0">in </span><span class="s1">trues:</span>
        <span class="s0">for </span><span class="s1">y_pred_tmp </span><span class="s0">in </span><span class="s1">preds:</span>
            <span class="s1">cm = multilabel_confusion_matrix(y_true_tmp</span><span class="s0">, </span><span class="s1">y_pred_tmp)</span>
            <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">real_cm)</span>

    <span class="s2"># test support for samplewise</span>
    <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">samplewise=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]])</span>

    <span class="s2"># test support for labels</span>
    <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]])</span>

    <span class="s2"># test support for labels with samplewise</span>
    <span class="s1">cm = multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">samplewise=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]])</span>

    <span class="s2"># test support for sample_weight with sample_wise</span>
    <span class="s1">cm = multilabel_confusion_matrix(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight</span><span class="s0">, </span><span class="s1">samplewise=</span><span class="s0">True</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">6</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]])</span>


<span class="s0">def </span><span class="s1">test_multilabel_confusion_matrix_errors():</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>

    <span class="s2"># Bad sample_weight</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s5">&quot;inconsistent numbers of samples&quot;</span><span class="s1">):</span>
        <span class="s1">multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s5">&quot;should be a 1d array&quot;</span><span class="s1">):</span>
        <span class="s1">multilabel_confusion_matrix(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">5</span><span class="s1">]]</span>
        <span class="s1">)</span>

    <span class="s2"># Bad labels</span>
    <span class="s1">err_msg = </span><span class="s5">r&quot;All labels must be in \[0, n labels\)&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">err_msg = </span><span class="s5">r&quot;All labels must be in \[0, n labels\)&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">multilabel_confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">3</span><span class="s1">])</span>

    <span class="s2"># Using samplewise outside multilabel</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s5">&quot;Samplewise metrics&quot;</span><span class="s1">):</span>
        <span class="s1">multilabel_confusion_matrix([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">samplewise=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s2"># Bad y_type</span>
    <span class="s1">err_msg = </span><span class="s5">&quot;multiclass-multioutput is not supported&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">multilabel_confusion_matrix([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]])</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;normalize, cm_dtype, expected_results&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s5">&quot;true&quot;</span><span class="s0">, </span><span class="s5">&quot;f&quot;</span><span class="s0">, </span><span class="s4">0.333333333</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s5">&quot;pred&quot;</span><span class="s0">, </span><span class="s5">&quot;f&quot;</span><span class="s0">, </span><span class="s4">0.333333333</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s5">&quot;all&quot;</span><span class="s0">, </span><span class="s5">&quot;f&quot;</span><span class="s0">, </span><span class="s4">0.1111111111</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s0">None, </span><span class="s5">&quot;i&quot;</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_confusion_matrix_normalize(normalize</span><span class="s0">, </span><span class="s1">cm_dtype</span><span class="s0">, </span><span class="s1">expected_results):</span>
    <span class="s1">y_test = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">] * </span><span class="s4">6</span>
    <span class="s1">y_pred = list(chain(*permutations([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])))</span>
    <span class="s1">cm = confusion_matrix(y_test</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=normalize)</span>
    <span class="s1">assert_allclose(cm</span><span class="s0">, </span><span class="s1">expected_results)</span>
    <span class="s0">assert </span><span class="s1">cm.dtype.kind == cm_dtype</span>


<span class="s0">def </span><span class="s1">test_confusion_matrix_normalize_single_class():</span>
    <span class="s1">y_test = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">cm_true = confusion_matrix(y_test</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s5">&quot;true&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">cm_true.sum() == pytest.approx(</span><span class="s4">2.0</span><span class="s1">)</span>

    <span class="s2"># additionally check that no warnings are raised due to a division by zero</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;error&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s1">cm_pred = confusion_matrix(y_test</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s5">&quot;pred&quot;</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">cm_pred.sum() == pytest.approx(</span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;error&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s1">confusion_matrix(y_pred</span><span class="s0">, </span><span class="s1">y_test</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s5">&quot;true&quot;</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;params, warn_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s2"># When y_test contains one class only and y_test==y_pred, LR+ is undefined</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s5">&quot;samples of only one class were seen during testing&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s2"># When `fp == 0` and `tp != 0`, LR+ is undefined</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s5">&quot;positive_likelihood_ratio ill-defined and being set to nan&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s2"># When `fp == 0` and `tp == 0`, LR+ is undefined</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s5">&quot;no samples predicted for the positive class&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s2"># When `tn == 0`, LR- is undefined</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s5">&quot;negative_likelihood_ratio ill-defined and being set to nan&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s2"># When `tp + fn == 0` both ratios are undefined</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s5">&quot;no samples of the positive class were present in the testing set&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_likelihood_ratios_warnings(params</span><span class="s0">, </span><span class="s1">warn_msg):</span>
    <span class="s2"># likelihood_ratios must raise warnings when at</span>
    <span class="s2"># least one of the ratios is ill-defined.</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">class_likelihood_ratios(**params)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;params, err_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">{</span>
                <span class="s5">&quot;y_true&quot;</span><span class="s1">: np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">,</span>
                <span class="s5">&quot;y_pred&quot;</span><span class="s1">: np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
            <span class="s1">(</span>
                <span class="s5">&quot;class_likelihood_ratios only supports binary classification &quot;</span>
                <span class="s5">&quot;problems, got targets of type: multiclass&quot;</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_likelihood_ratios_errors(params</span><span class="s0">, </span><span class="s1">err_msg):</span>
    <span class="s2"># likelihood_ratios must raise error when attempting</span>
    <span class="s2"># non-binary classes to avoid Simpson's paradox</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">class_likelihood_ratios(**params)</span>


<span class="s0">def </span><span class="s1">test_likelihood_ratios():</span>
    <span class="s2"># Build confusion matrix with tn=9, fp=8, fn=1, tp=2,</span>
    <span class="s2"># sensitivity=2/3, specificity=9/17, prevalence=3/20,</span>
    <span class="s2"># LR+=34/24, LR-=17/27</span>
    <span class="s1">y_true = np.array([</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">3 </span><span class="s1">+ [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">17</span><span class="s1">)</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">2 </span><span class="s1">+ [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">8</span><span class="s1">)</span>

    <span class="s1">pos</span><span class="s0">, </span><span class="s1">neg = class_likelihood_ratios(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">assert_allclose(pos</span><span class="s0">, </span><span class="s4">34 </span><span class="s1">/ </span><span class="s4">24</span><span class="s1">)</span>
    <span class="s1">assert_allclose(neg</span><span class="s0">, </span><span class="s4">17 </span><span class="s1">/ </span><span class="s4">27</span><span class="s1">)</span>

    <span class="s2"># Build limit case with y_pred = y_true</span>
    <span class="s1">pos</span><span class="s0">, </span><span class="s1">neg = class_likelihood_ratios(y_true</span><span class="s0">, </span><span class="s1">y_true)</span>
    <span class="s1">assert_array_equal(pos</span><span class="s0">, </span><span class="s1">np.nan * </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(neg</span><span class="s0">, </span><span class="s1">np.zeros(</span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-12</span><span class="s1">)</span>

    <span class="s2"># Ignore last 5 samples to get tn=9, fp=3, fn=1, tp=2,</span>
    <span class="s2"># sensitivity=2/3, specificity=9/12, prevalence=3/20,</span>
    <span class="s2"># LR+=24/9, LR-=12/27</span>
    <span class="s1">sample_weight = np.array([</span><span class="s4">1.0</span><span class="s1">] * </span><span class="s4">15 </span><span class="s1">+ [</span><span class="s4">0.0</span><span class="s1">] * </span><span class="s4">5</span><span class="s1">)</span>
    <span class="s1">pos</span><span class="s0">, </span><span class="s1">neg = class_likelihood_ratios(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
    <span class="s1">assert_allclose(pos</span><span class="s0">, </span><span class="s4">24 </span><span class="s1">/ </span><span class="s4">9</span><span class="s1">)</span>
    <span class="s1">assert_allclose(neg</span><span class="s0">, </span><span class="s4">12 </span><span class="s1">/ </span><span class="s4">27</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_cohen_kappa():</span>
    <span class="s2"># These label vectors reproduce the contingency matrix from Artstein and</span>
    <span class="s2"># Poesio (2008), Table 1: np.array([[20, 20], [10, 50]]).</span>
    <span class="s1">y1 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">40 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">60</span><span class="s1">)</span>
    <span class="s1">y2 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">20 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">20 </span><span class="s1">+ [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">50</span><span class="s1">)</span>
    <span class="s1">kappa = cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2)</span>
    <span class="s1">assert_almost_equal(kappa</span><span class="s0">, </span><span class="s4">0.348</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">kappa == cohen_kappa_score(y2</span><span class="s0">, </span><span class="s1">y1)</span>

    <span class="s2"># Add spurious labels and ignore them.</span>
    <span class="s1">y1 = np.append(y1</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">y2 = np.append(y2</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]) == kappa</span>

    <span class="s1">assert_almost_equal(cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y1)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s2"># Multiclass example: Artstein and Poesio, Table 4.</span>
    <span class="s1">y1 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">46 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">44 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">y2 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">52 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">32 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">16</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2)</span><span class="s0">, </span><span class="s4">0.8013</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>

    <span class="s2"># Weighting example: none, linear, quadratic.</span>
    <span class="s1">y1 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">46 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">44 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">y2 = np.array([</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">50 </span><span class="s1">+ [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">40 </span><span class="s1">+ [</span><span class="s4">2</span><span class="s1">] * </span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2)</span><span class="s0">, </span><span class="s4">0.9315</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">weights=</span><span class="s5">&quot;linear&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.9412</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">cohen_kappa_score(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">weights=</span><span class="s5">&quot;quadratic&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.9541</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">4</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_matthews_corrcoef_nan():</span>
    <span class="s0">assert </span><span class="s1">matthews_corrcoef([</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">]) == </span><span class="s4">0.0</span>
    <span class="s0">assert </span><span class="s1">matthews_corrcoef([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]) == </span><span class="s4">0.0</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;y_true, y_pred&quot;</span><span class="s0">, </span><span class="s1">[([</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">])</span><span class="s0">, </span><span class="s1">([]</span><span class="s0">, </span><span class="s1">[])])</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;metric&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">f1_score</span><span class="s0">,</span>
        <span class="s1">partial(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">precision_score</span><span class="s0">,</span>
        <span class="s1">recall_score</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_zero_division_nan_no_warning(metric</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">zero_division):</span>
    <span class="s3">&quot;&quot;&quot;Check the behaviour of `zero_division` when setting to 0, 1 or np.nan. 
    No warnings should be raised. 
    &quot;&quot;&quot;</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;error&quot;</span><span class="s1">)</span>
        <span class="s1">result = metric(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">zero_division=zero_division)</span>

    <span class="s0">if </span><span class="s1">np.isnan(zero_division):</span>
        <span class="s0">assert </span><span class="s1">np.isnan(result)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">result == zero_division</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;y_true, y_pred&quot;</span><span class="s0">, </span><span class="s1">[([</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">])</span><span class="s0">, </span><span class="s1">([]</span><span class="s0">, </span><span class="s1">[])])</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;metric&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">f1_score</span><span class="s0">,</span>
        <span class="s1">partial(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">precision_score</span><span class="s0">,</span>
        <span class="s1">recall_score</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_zero_division_nan_warning(metric</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred):</span>
    <span class="s3">&quot;&quot;&quot;Check the behaviour of `zero_division` when setting to &quot;warn&quot;. 
    A `UndefinedMetricWarning` should be raised. 
    &quot;&quot;&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning):</span>
        <span class="s1">result = metric(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">zero_division=</span><span class="s5">&quot;warn&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">result == </span><span class="s4">0.0</span>


<span class="s0">def </span><span class="s1">test_matthews_corrcoef_against_numpy_corrcoef():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">y_true = rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)</span>
    <span class="s1">y_pred = rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)</span>

    <span class="s1">assert_almost_equal(</span>
        <span class="s1">matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">np.corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">10</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_matthews_corrcoef_against_jurman():</span>
    <span class="s2"># Check that the multiclass matthews_corrcoef agrees with the definition</span>
    <span class="s2"># presented in Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC</span>
    <span class="s2"># and CEN Error Measures in MultiClass Prediction</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">y_true = rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)</span>
    <span class="s1">y_pred = rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)</span>
    <span class="s1">sample_weight = rng.rand(</span><span class="s4">20</span><span class="s1">)</span>

    <span class="s1">C = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
    <span class="s1">N = len(C)</span>
    <span class="s1">cov_ytyp = sum(</span>
        <span class="s1">[</span>
            <span class="s1">C[k</span><span class="s0">, </span><span class="s1">k] * C[m</span><span class="s0">, </span><span class="s1">l] - C[l</span><span class="s0">, </span><span class="s1">k] * C[k</span><span class="s0">, </span><span class="s1">m]</span>
            <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(N)</span>
            <span class="s0">for </span><span class="s1">m </span><span class="s0">in </span><span class="s1">range(N)</span>
            <span class="s0">for </span><span class="s1">l </span><span class="s0">in </span><span class="s1">range(N)</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">cov_ytyt = sum(</span>
        <span class="s1">[</span>
            <span class="s1">C[:</span><span class="s0">, </span><span class="s1">k].sum()</span>
            <span class="s1">* np.sum([C[g</span><span class="s0">, </span><span class="s1">f] </span><span class="s0">for </span><span class="s1">f </span><span class="s0">in </span><span class="s1">range(N) </span><span class="s0">for </span><span class="s1">g </span><span class="s0">in </span><span class="s1">range(N) </span><span class="s0">if </span><span class="s1">f != k])</span>
            <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(N)</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">cov_ypyp = np.sum(</span>
        <span class="s1">[</span>
            <span class="s1">C[k</span><span class="s0">, </span><span class="s1">:].sum()</span>
            <span class="s1">* np.sum([C[f</span><span class="s0">, </span><span class="s1">g] </span><span class="s0">for </span><span class="s1">f </span><span class="s0">in </span><span class="s1">range(N) </span><span class="s0">for </span><span class="s1">g </span><span class="s0">in </span><span class="s1">range(N) </span><span class="s0">if </span><span class="s1">f != k])</span>
            <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(N)</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">mcc_jurman = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)</span>
    <span class="s1">mcc_ours = matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>

    <span class="s1">assert_almost_equal(mcc_ours</span><span class="s0">, </span><span class="s1">mcc_jurman</span><span class="s0">, </span><span class="s4">10</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_matthews_corrcoef():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">y_true = [</span><span class="s5">&quot;a&quot; </span><span class="s0">if </span><span class="s1">i == </span><span class="s4">0 </span><span class="s0">else </span><span class="s5">&quot;b&quot; </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)]</span>

    <span class="s2"># corrcoef of same vectors must be 1</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_true)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s2"># corrcoef, when the two vectors are opposites of each other, should be -1</span>
    <span class="s1">y_true_inv = [</span><span class="s5">&quot;b&quot; </span><span class="s0">if </span><span class="s1">i == </span><span class="s5">&quot;a&quot; </span><span class="s0">else </span><span class="s5">&quot;a&quot; </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">y_true]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_true_inv)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">y_true_inv2 = label_binarize(y_true</span><span class="s0">, </span><span class="s1">classes=[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">])</span>
    <span class="s1">y_true_inv2 = np.where(y_true_inv2</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_true_inv2)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s2"># For the zero vector case, the corrcoef cannot be calculated and should</span>
    <span class="s2"># output 0</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># And also for any other vector with 0 variance</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;a&quot;</span><span class="s1">] * len(y_true))</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># These two vectors have 0 correlation and hence mcc should be 0</span>
    <span class="s1">y_1 = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">y_2 = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_1</span><span class="s0">, </span><span class="s1">y_2)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># Check that sample weight is able to selectively exclude</span>
    <span class="s1">mask = [</span><span class="s4">1</span><span class="s1">] * </span><span class="s4">10 </span><span class="s1">+ [</span><span class="s4">0</span><span class="s1">] * </span><span class="s4">10</span>
    <span class="s2"># Now the first half of the vector elements are alone given a weight of 1</span>
    <span class="s2"># and hence the mcc will not be a perfect 0 as in the previous case</span>
    <span class="s0">with </span><span class="s1">pytest.raises(AssertionError):</span>
        <span class="s1">assert_almost_equal(matthews_corrcoef(y_1</span><span class="s0">, </span><span class="s1">y_2</span><span class="s0">, </span><span class="s1">sample_weight=mask)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_matthews_corrcoef_multiclass():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">ord_a = ord(</span><span class="s5">&quot;a&quot;</span><span class="s1">)</span>
    <span class="s1">n_classes = </span><span class="s4">4</span>
    <span class="s1">y_true = [chr(ord_a + i) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">rng.randint(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">n_classes</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">20</span><span class="s1">)]</span>

    <span class="s2"># corrcoef of same vectors must be 1</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_true)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s2"># with multiclass &gt; 2 it is not possible to achieve -1</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred_bad = [</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred_bad)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.5</span><span class="s1">)</span>

    <span class="s2"># Maximizing false positives and negatives minimizes the MCC</span>
    <span class="s2"># The minimum will be different for depending on the input</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred_min = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred_min)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">12 </span><span class="s1">/ np.sqrt(</span><span class="s4">24 </span><span class="s1">* </span><span class="s4">16</span><span class="s1">))</span>

    <span class="s2"># Zero variance will result in an mcc of zero</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># Also for ground truth with zero variance</span>
    <span class="s1">y_true = [</span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># These two vectors have 0 correlation and hence mcc should be 0</span>
    <span class="s1">y_1 = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_2 = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_1</span><span class="s0">, </span><span class="s1">y_2)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s2"># We can test that binary assumptions hold using the multiclass computation</span>
    <span class="s2"># by masking the weight of samples not in the first two classes</span>

    <span class="s2"># Masking the last label should let us get an MCC of -1</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">sample_weight = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span>
    <span class="s1">)</span>

    <span class="s2"># For the zero vector case, the corrcoef cannot be calculated and should</span>
    <span class="s2"># output 0</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">sample_weight = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span><span class="s0">, </span><span class="s4">0.0</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n_points&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">100</span><span class="s0">, </span><span class="s4">10000</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_matthews_corrcoef_overflow(n_points):</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/9622</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">20170906</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">mcc_safe(y_true</span><span class="s0">, </span><span class="s1">y_pred):</span>
        <span class="s1">conf_matrix = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">true_pos = conf_matrix[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">false_pos = conf_matrix[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">false_neg = conf_matrix[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">n_points = len(y_true)</span>
        <span class="s1">pos_rate = (true_pos + false_neg) / n_points</span>
        <span class="s1">activity = (true_pos + false_pos) / n_points</span>
        <span class="s1">mcc_numerator = true_pos / n_points - pos_rate * activity</span>
        <span class="s1">mcc_denominator = activity * pos_rate * (</span><span class="s4">1 </span><span class="s1">- activity) * (</span><span class="s4">1 </span><span class="s1">- pos_rate)</span>
        <span class="s0">return </span><span class="s1">mcc_numerator / np.sqrt(mcc_denominator)</span>

    <span class="s0">def </span><span class="s1">random_ys(n_points):  </span><span class="s2"># binary</span>
        <span class="s1">x_true = rng.random_sample(n_points)</span>
        <span class="s1">x_pred = x_true + </span><span class="s4">0.2 </span><span class="s1">* (rng.random_sample(n_points) - </span><span class="s4">0.5</span><span class="s1">)</span>
        <span class="s1">y_true = x_true &gt; </span><span class="s4">0.5</span>
        <span class="s1">y_pred = x_pred &gt; </span><span class="s4">0.5</span>
        <span class="s0">return </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span>

    <span class="s1">arr = np.repeat([</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_points)  </span><span class="s2"># binary</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(arr</span><span class="s0">, </span><span class="s1">arr)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>
    <span class="s1">arr = np.repeat([</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_points)  </span><span class="s2"># multiclass</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(arr</span><span class="s0">, </span><span class="s1">arr)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred = random_ys(n_points)</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_true)</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(matthews_corrcoef(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">mcc_safe(y_true</span><span class="s0">, </span><span class="s1">y_pred))</span>


<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_multiclass():</span>
    <span class="s2"># Test Precision Recall and F1 Score for multiclass classification task</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># compute scores with default labels introspection</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.83</span><span class="s0">, </span><span class="s4">0.33</span><span class="s0">, </span><span class="s4">0.42</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.79</span><span class="s0">, </span><span class="s4">0.09</span><span class="s0">, </span><span class="s4">0.90</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.81</span><span class="s0">, </span><span class="s4">0.15</span><span class="s0">, </span><span class="s4">0.57</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">24</span><span class="s0">, </span><span class="s4">31</span><span class="s0">, </span><span class="s4">20</span><span class="s1">])</span>

    <span class="s2"># averaging tests</span>
    <span class="s1">ps = precision_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(ps</span><span class="s0">, </span><span class="s4">0.53</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">rs = recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(rs</span><span class="s0">, </span><span class="s4">0.53</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">fs = f1_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(fs</span><span class="s0">, </span><span class="s4">0.53</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">ps = precision_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(ps</span><span class="s0">, </span><span class="s4">0.53</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">rs = recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(rs</span><span class="s0">, </span><span class="s4">0.60</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">fs = f1_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(fs</span><span class="s0">, </span><span class="s4">0.51</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">ps = precision_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(ps</span><span class="s0">, </span><span class="s4">0.51</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">rs = recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(rs</span><span class="s0">, </span><span class="s4">0.53</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">fs = f1_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(fs</span><span class="s0">, </span><span class="s4">0.47</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">precision_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">f1_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">0.5</span><span class="s1">)</span>

    <span class="s2"># same prediction but with and explicit label ordering</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.83</span><span class="s0">, </span><span class="s4">0.41</span><span class="s0">, </span><span class="s4">0.33</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.79</span><span class="s0">, </span><span class="s4">0.90</span><span class="s0">, </span><span class="s4">0.10</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.81</span><span class="s0">, </span><span class="s4">0.57</span><span class="s0">, </span><span class="s4">0.15</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">24</span><span class="s0">, </span><span class="s4">20</span><span class="s0">, </span><span class="s4">31</span><span class="s1">])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;average&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, None</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_precision_refcall_f1_score_multilabel_unordered_labels(average):</span>
    <span class="s2"># test that labels need not be sorted in the multilabel case</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">warn_for=[]</span><span class="s0">, </span><span class="s1">average=average</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_equal(p</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(r</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(f</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">average </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">assert_array_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_binary_averaged():</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>

    <span class="s2"># compute scores with default labels introspection</span>
    <span class="s1">ps</span><span class="s0">, </span><span class="s1">rs</span><span class="s0">, </span><span class="s1">fs</span><span class="s0">, </span><span class="s1">_ = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">_ = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">p == np.mean(ps)</span>
    <span class="s0">assert </span><span class="s1">r == np.mean(rs)</span>
    <span class="s0">assert </span><span class="s1">f == np.mean(fs)</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">_ = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">support = np.bincount(y_true)</span>
    <span class="s0">assert </span><span class="s1">p == np.average(ps</span><span class="s0">, </span><span class="s1">weights=support)</span>
    <span class="s0">assert </span><span class="s1">r == np.average(rs</span><span class="s0">, </span><span class="s1">weights=support)</span>
    <span class="s0">assert </span><span class="s1">f == np.average(fs</span><span class="s0">, </span><span class="s1">weights=support)</span>


<span class="s0">def </span><span class="s1">test_zero_precision_recall():</span>
    <span class="s2"># Check that pathological cases do not bring NaNs</span>

    <span class="s1">old_error_settings = np.seterr(all=</span><span class="s5">&quot;raise&quot;</span><span class="s1">)</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
        <span class="s1">y_pred = np.array([</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>

        <span class="s1">assert_almost_equal(precision_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(recall_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(f1_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s0">finally</span><span class="s1">:</span>
        <span class="s1">np.seterr(**old_error_settings)</span>


<span class="s0">def </span><span class="s1">test_confusion_matrix_multiclass_subset_labels():</span>
    <span class="s2"># Test confusion matrix - multi-class case with subset of labels</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># compute confusion matrix with only first two labels considered</span>
    <span class="s1">cm = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">19</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]])</span>

    <span class="s2"># compute confusion matrix with explicit label ordering for only subset</span>
    <span class="s2"># of labels</span>
    <span class="s1">cm = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">18</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">24</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]])</span>

    <span class="s2"># a label not in y_true should result in zeros for that row/column</span>
    <span class="s1">extra_label = np.max(y_true) + </span><span class="s4">1</span>
    <span class="s1">cm = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">2</span><span class="s0">, </span><span class="s1">extra_label])</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">18</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;labels, err_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([]</span><span class="s0">, </span><span class="s5">&quot;'labels' should contains at least one label.&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s5">&quot;At least one label specified must be in y_true&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
    <span class="s1">ids=[</span><span class="s5">&quot;empty list&quot;</span><span class="s0">, </span><span class="s5">&quot;unknown labels&quot;</span><span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_confusion_matrix_error(labels</span><span class="s0">, </span><span class="s1">err_msg):</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=labels)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;labels&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s0">None, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span><span class="s0">, </span><span class="s1">ids=[</span><span class="s5">&quot;None&quot;</span><span class="s0">, </span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s5">&quot;multiclass&quot;</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_confusion_matrix_on_zero_length_input(labels):</span>
    <span class="s1">expected_n_classes = len(labels) </span><span class="s0">if </span><span class="s1">labels </span><span class="s0">else </span><span class="s4">0</span>
    <span class="s1">expected = np.zeros((expected_n_classes</span><span class="s0">, </span><span class="s1">expected_n_classes)</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">cm = confusion_matrix([]</span><span class="s0">, </span><span class="s1">[]</span><span class="s0">, </span><span class="s1">labels=labels)</span>
    <span class="s1">assert_array_equal(cm</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_confusion_matrix_dtype():</span>
    <span class="s1">y = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">weight = np.ones(len(y))</span>
    <span class="s2"># confusion_matrix returns int64 by default</span>
    <span class="s1">cm = confusion_matrix(y</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">cm.dtype == np.int64</span>
    <span class="s2"># The dtype of confusion_matrix is always 64 bit</span>
    <span class="s0">for </span><span class="s1">dtype </span><span class="s0">in </span><span class="s1">[np.bool_</span><span class="s0">, </span><span class="s1">np.int32</span><span class="s0">, </span><span class="s1">np.uint64]:</span>
        <span class="s1">cm = confusion_matrix(y</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=weight.astype(dtype</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">))</span>
        <span class="s0">assert </span><span class="s1">cm.dtype == np.int64</span>
    <span class="s0">for </span><span class="s1">dtype </span><span class="s0">in </span><span class="s1">[np.float32</span><span class="s0">, </span><span class="s1">np.float64</span><span class="s0">, None, </span><span class="s1">object]:</span>
        <span class="s1">cm = confusion_matrix(y</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=weight.astype(dtype</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">))</span>
        <span class="s0">assert </span><span class="s1">cm.dtype == np.float64</span>

    <span class="s2"># np.iinfo(np.uint32).max should be accumulated correctly</span>
    <span class="s1">weight = np.full(len(y)</span><span class="s0">, </span><span class="s4">4294967295</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">cm = confusion_matrix(y</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=weight)</span>
    <span class="s0">assert </span><span class="s1">cm[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] == </span><span class="s4">4294967295</span>
    <span class="s0">assert </span><span class="s1">cm[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">] == </span><span class="s4">8589934590</span>

    <span class="s2"># np.iinfo(np.int64).max should cause an overflow</span>
    <span class="s1">weight = np.full(len(y)</span><span class="s0">, </span><span class="s4">9223372036854775807</span><span class="s0">, </span><span class="s1">dtype=np.int64)</span>
    <span class="s1">cm = confusion_matrix(y</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=weight)</span>
    <span class="s0">assert </span><span class="s1">cm[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] == </span><span class="s4">9223372036854775807</span>
    <span class="s0">assert </span><span class="s1">cm[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">] == -</span><span class="s4">2</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;Int64&quot;</span><span class="s0">, </span><span class="s5">&quot;Float64&quot;</span><span class="s0">, </span><span class="s5">&quot;boolean&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_confusion_matrix_pandas_nullable(dtype):</span>
    <span class="s3">&quot;&quot;&quot;Checks that confusion_matrix works with pandas nullable dtypes. 
 
    Non-regression test for gh-25635. 
    &quot;&quot;&quot;</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s5">&quot;pandas&quot;</span><span class="s1">)</span>

    <span class="s1">y_ndarray = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">y_true = pd.Series(y_ndarray</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">y_predicted = pd.Series([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s5">&quot;int64&quot;</span><span class="s1">)</span>

    <span class="s1">output = confusion_matrix(y_true</span><span class="s0">, </span><span class="s1">y_predicted)</span>
    <span class="s1">expected_output = confusion_matrix(y_ndarray</span><span class="s0">, </span><span class="s1">y_predicted)</span>

    <span class="s1">assert_array_equal(output</span><span class="s0">, </span><span class="s1">expected_output)</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass():</span>
    <span class="s2"># Test performance report</span>
    <span class="s1">iris = datasets.load_iris()</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(dataset=iris</span><span class="s0">, </span><span class="s1">binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># print classification report with class names</span>
    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
      setosa       0.83      0.79      0.81        24 
  versicolor       0.33      0.10      0.15        31 
   virginica       0.42      0.90      0.57        20 
 
    accuracy                           0.53        75 
   macro avg       0.53      0.60      0.51        75 
weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">labels=np.arange(len(iris.target_names))</span><span class="s0">,</span>
        <span class="s1">target_names=iris.target_names</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_balanced():</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
           0       0.33      0.33      0.33         3 
           1       0.33      0.33      0.33         3 
           2       0.33      0.33      0.33         3 
 
    accuracy                           0.33         9 
   macro avg       0.33      0.33      0.33         9 
weighted avg       0.33      0.33      0.33         9 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_with_label_detection():</span>
    <span class="s1">iris = datasets.load_iris()</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(dataset=iris</span><span class="s0">, </span><span class="s1">binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># print classification report with label detection</span>
    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
           0       0.83      0.79      0.81        24 
           1       0.33      0.10      0.15        31 
           2       0.42      0.90      0.57        20 
 
    accuracy                           0.53        75 
   macro avg       0.53      0.60      0.51        75 
weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_with_digits():</span>
    <span class="s2"># Test performance report with added digits in floating point values</span>
    <span class="s1">iris = datasets.load_iris()</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(dataset=iris</span><span class="s0">, </span><span class="s1">binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s2"># print classification report with class names</span>
    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
      setosa    0.82609   0.79167   0.80851        24 
  versicolor    0.33333   0.09677   0.15000        31 
   virginica    0.41860   0.90000   0.57143        20 
 
    accuracy                        0.53333        75 
   macro avg    0.52601   0.59615   0.50998        75 
weighted avg    0.51375   0.53333   0.47310        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">labels=np.arange(len(iris.target_names))</span><span class="s0">,</span>
        <span class="s1">target_names=iris.target_names</span><span class="s0">,</span>
        <span class="s1">digits=</span><span class="s4">5</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_with_string_label():</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">y_true = np.array([</span><span class="s5">&quot;blue&quot;</span><span class="s0">, </span><span class="s5">&quot;green&quot;</span><span class="s0">, </span><span class="s5">&quot;red&quot;</span><span class="s1">])[y_true]</span>
    <span class="s1">y_pred = np.array([</span><span class="s5">&quot;blue&quot;</span><span class="s0">, </span><span class="s5">&quot;green&quot;</span><span class="s0">, </span><span class="s5">&quot;red&quot;</span><span class="s1">])[y_pred]</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
        blue       0.83      0.79      0.81        24 
       green       0.33      0.10      0.15        31 
         red       0.42      0.90      0.57        20 
 
    accuracy                           0.53        75 
   macro avg       0.53      0.60      0.51        75 
weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
           a       0.83      0.79      0.81        24 
           b       0.33      0.10      0.15        31 
           c       0.42      0.90      0.57        20 
 
    accuracy                           0.53        75 
   macro avg       0.53      0.60      0.51        75 
weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">target_names=[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;c&quot;</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_with_unicode_label():</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">labels = np.array([</span><span class="s5">&quot;blue</span><span class="s0">\xa2</span><span class="s5">&quot;</span><span class="s0">, </span><span class="s5">&quot;green</span><span class="s0">\xa2</span><span class="s5">&quot;</span><span class="s0">, </span><span class="s5">&quot;red</span><span class="s0">\xa2</span><span class="s5">&quot;</span><span class="s1">])</span>
    <span class="s1">y_true = labels[y_true]</span>
    <span class="s1">y_pred = labels[y_pred]</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
       blue</span><span class="s0">\xa2       </span><span class="s5">0.83      0.79      0.81        24 
      green</span><span class="s0">\xa2       </span><span class="s5">0.33      0.10      0.15        31 
        red</span><span class="s0">\xa2       </span><span class="s5">0.42      0.90      0.57        20 
 
    accuracy                           0.53        75 
   macro avg       0.53      0.60      0.51        75 
weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>
    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_multiclass_with_long_string_label():</span>
    <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">_ = make_prediction(binary=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">labels = np.array([</span><span class="s5">&quot;blue&quot;</span><span class="s0">, </span><span class="s5">&quot;green&quot; </span><span class="s1">* </span><span class="s4">5</span><span class="s0">, </span><span class="s5">&quot;red&quot;</span><span class="s1">])</span>
    <span class="s1">y_true = labels[y_true]</span>
    <span class="s1">y_pred = labels[y_pred]</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
                           </span><span class="s5">precision    recall  f1-score   support 
 
                     blue       0.83      0.79      0.81        24 
greengreengreengreengreen       0.33      0.10      0.15        31 
                      red       0.42      0.90      0.57        20 
 
                 accuracy                           0.53        75 
                macro avg       0.53      0.60      0.51        75 
             weighted avg       0.51      0.53      0.47        75 
&quot;&quot;&quot;</span>

    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_classification_report_labels_target_names_unequal_length():</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">target_names = [</span><span class="s5">&quot;class 0&quot;</span><span class="s0">, </span><span class="s5">&quot;class 1&quot;</span><span class="s0">, </span><span class="s5">&quot;class 2&quot;</span><span class="s1">]</span>

    <span class="s1">msg = </span><span class="s5">&quot;labels size, 2, does not match size of target_names, 3&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">target_names=target_names)</span>


<span class="s0">def </span><span class="s1">test_classification_report_no_labels_target_names_unequal_length():</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">target_names = [</span><span class="s5">&quot;class 0&quot;</span><span class="s0">, </span><span class="s5">&quot;class 1&quot;</span><span class="s0">, </span><span class="s5">&quot;class 2&quot;</span><span class="s1">]</span>

    <span class="s1">err_msg = (</span>
        <span class="s5">&quot;Number of classes, 2, does not &quot;</span>
        <span class="s5">&quot;match size of target_names, 3. &quot;</span>
        <span class="s5">&quot;Try specifying the labels parameter&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">target_names=target_names)</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_multilabel_classification_report():</span>
    <span class="s1">n_classes = </span><span class="s4">4</span>
    <span class="s1">n_samples = </span><span class="s4">50</span>

    <span class="s1">_</span><span class="s0">, </span><span class="s1">y_true = make_multilabel_classification(</span>
        <span class="s1">n_features=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">n_samples=n_samples</span><span class="s0">, </span><span class="s1">n_classes=n_classes</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span>
    <span class="s1">)</span>

    <span class="s1">_</span><span class="s0">, </span><span class="s1">y_pred = make_multilabel_classification(</span>
        <span class="s1">n_features=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">n_samples=n_samples</span><span class="s0">, </span><span class="s1">n_classes=n_classes</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">1</span>
    <span class="s1">)</span>

    <span class="s1">expected_report = </span><span class="s5">&quot;&quot;&quot;</span><span class="s0">\ 
              </span><span class="s5">precision    recall  f1-score   support 
 
           0       0.50      0.67      0.57        24 
           1       0.51      0.74      0.61        27 
           2       0.29      0.08      0.12        26 
           3       0.52      0.56      0.54        27 
 
   micro avg       0.50      0.51      0.50       104 
   macro avg       0.45      0.51      0.46       104 
weighted avg       0.45      0.51      0.46       104 
 samples avg       0.46      0.42      0.40       104 
&quot;&quot;&quot;</span>

    <span class="s1">report = classification_report(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">report == expected_report</span>


<span class="s0">def </span><span class="s1">test_multilabel_zero_one_loss_subset():</span>
    <span class="s2"># Dense label indicator matrix format</span>
    <span class="s1">y1 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y2 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>

    <span class="s0">assert </span><span class="s1">zero_one_loss(y1</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">0.5</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y1</span><span class="s0">, </span><span class="s1">y1) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y2</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y2</span><span class="s0">, </span><span class="s1">np.logical_not(y2)) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y1</span><span class="s0">, </span><span class="s1">np.logical_not(y1)) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y1</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">zero_one_loss(y2</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">1</span>


<span class="s0">def </span><span class="s1">test_multilabel_hamming_loss():</span>
    <span class="s2"># Dense label indicator matrix format</span>
    <span class="s1">y1 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y2 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">w = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>

    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">6</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s1">y1) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y2</span><span class="s0">, </span><span class="s1">y2) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y2</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">- y2) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">- y1) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">4 </span><span class="s1">/ </span><span class="s4">6</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y2</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)) == </span><span class="s4">0.5</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">sample_weight=w) == </span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">12</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">- y2</span><span class="s0">, </span><span class="s1">sample_weight=w) == </span><span class="s4">11.0 </span><span class="s1">/ </span><span class="s4">12</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1</span><span class="s0">, </span><span class="s1">np.zeros_like(y1)</span><span class="s0">, </span><span class="s1">sample_weight=w) == </span><span class="s4">2.0 </span><span class="s1">/ </span><span class="s4">3</span>
    <span class="s2"># sp_hamming only works with 1-D arrays</span>
    <span class="s0">assert </span><span class="s1">hamming_loss(y1[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y2[</span><span class="s4">0</span><span class="s1">]) == sp_hamming(y1[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y2[</span><span class="s4">0</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_jaccard_score_validation():</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">err_msg = </span><span class="s5">r&quot;pos_label=2 is not a valid label. It should be one of \[0, 1\]&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">msg1 = (</span>
        <span class="s5">r&quot;Target is multilabel-indicator but average='binary'. &quot;</span>
        <span class="s5">r&quot;Please choose another average setting, one of \[None, &quot;</span>
        <span class="s5">r&quot;'micro', 'macro', 'weighted', 'samples'\].&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg1):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">pos_label=-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">msg2 = (</span>
        <span class="s5">r&quot;Target is multiclass but average='binary'. Please choose &quot;</span>
        <span class="s5">r&quot;another average setting, one of \[None, 'micro', 'macro', &quot;</span>
        <span class="s5">r&quot;'weighted'\].&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg2):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">)</span>
    <span class="s1">msg3 = </span><span class="s5">&quot;Samplewise metrics are not available outside of multilabel classification.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg3):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">r&quot;Note that pos_label \(set to 3\) is ignored when &quot;</span>
        <span class="s5">r&quot;average != 'binary' \(got 'micro'\). You may use &quot;</span>
        <span class="s5">r&quot;labels=\[pos_label\] to specify a single positive &quot;</span>
        <span class="s5">&quot;class.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_multilabel_jaccard_score(recwarn):</span>
    <span class="s2"># Dense label indicator matrix format</span>
    <span class="s1">y1 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y2 = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>

    <span class="s2"># size(y1 \inter y2) = [1, 2]</span>
    <span class="s2"># size(y1 \union y2) = [2, 2]</span>

    <span class="s0">assert </span><span class="s1">jaccard_score(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">0.75</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y1</span><span class="s0">, </span><span class="s1">y1</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y2</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y2</span><span class="s0">, </span><span class="s1">np.logical_not(y2)</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y1</span><span class="s0">, </span><span class="s1">np.logical_not(y1)</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y1</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">0</span>
    <span class="s0">assert </span><span class="s1">jaccard_score(y2</span><span class="s0">, </span><span class="s1">np.zeros(y1.shape)</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">) == </span><span class="s4">0</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s2"># average='macro'</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">2.0 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s2"># average='micro'</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">3.0 </span><span class="s1">/ </span><span class="s4">5</span><span class="s1">)</span>
    <span class="s2"># average='samples'</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">7.0 </span><span class="s1">/ </span><span class="s4">12</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span><span class="s0">, </span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">2</span>
    <span class="s1">)</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span><span class="s0">, </span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">2</span>
    <span class="s1">)</span>
    <span class="s2"># average=None</span>
    <span class="s1">assert_array_equal(</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">)</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">5.0 </span><span class="s1">/ </span><span class="s4">6</span><span class="s1">)</span>
    <span class="s2"># average='weighted'</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">7.0 </span><span class="s1">/ </span><span class="s4">8</span><span class="s1">)</span>

    <span class="s1">msg2 = </span><span class="s5">&quot;Got 4 &gt; 2&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg2):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">msg3 = </span><span class="s5">&quot;Got -1 &lt; 0&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg3):</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">labels=[-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">&quot;Jaccard is ill-defined and being set to 0.0 in labels &quot;</span>
        <span class="s5">&quot;with no true or predicted samples.&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s0">assert </span><span class="s1">(</span>
            <span class="s1">jaccard_score(np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
            <span class="s1">== </span><span class="s4">0.5</span>
        <span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">&quot;Jaccard is ill-defined and being set to 0.0 in samples &quot;</span>
        <span class="s5">&quot;with no true or predicted labels.&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s0">assert </span><span class="s1">(</span>
            <span class="s1">jaccard_score(</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">== </span><span class="s4">0.5</span>
        <span class="s1">)</span>

    <span class="s0">assert not </span><span class="s1">list(recwarn)</span>


<span class="s0">def </span><span class="s1">test_multiclass_jaccard_score(recwarn):</span>
    <span class="s1">y_true = [</span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s1">]</span>
    <span class="s1">labels = [</span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s1">]</span>
    <span class="s1">lb = LabelBinarizer()</span>
    <span class="s1">lb.fit(labels)</span>
    <span class="s1">y_true_bin = lb.transform(y_true)</span>
    <span class="s1">y_pred_bin = lb.transform(y_pred)</span>
    <span class="s1">multi_jaccard_score = partial(jaccard_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">bin_jaccard_score = partial(jaccard_score</span><span class="s0">, </span><span class="s1">y_true_bin</span><span class="s0">, </span><span class="s1">y_pred_bin)</span>
    <span class="s1">multi_labels_list = [</span>
        <span class="s1">[</span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s5">&quot;ant&quot;</span><span class="s0">, </span><span class="s5">&quot;cat&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s5">&quot;cat&quot;</span><span class="s0">, </span><span class="s5">&quot;bird&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s5">&quot;ant&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s5">&quot;bird&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s5">&quot;cat&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s0">None,</span>
    <span class="s1">]</span>
    <span class="s1">bin_labels_list = [[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s1">]</span><span class="s0">, None</span><span class="s1">]</span>

    <span class="s2"># other than average='samples'/'none-samples', test everything else here</span>
    <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">(</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s0">, None</span><span class="s1">):</span>
        <span class="s0">for </span><span class="s1">m_label</span><span class="s0">, </span><span class="s1">b_label </span><span class="s0">in </span><span class="s1">zip(multi_labels_list</span><span class="s0">, </span><span class="s1">bin_labels_list):</span>
            <span class="s1">assert_almost_equal(</span>
                <span class="s1">multi_jaccard_score(average=average</span><span class="s0">, </span><span class="s1">labels=m_label)</span><span class="s0">,</span>
                <span class="s1">bin_jaccard_score(average=average</span><span class="s0">, </span><span class="s1">labels=b_label)</span><span class="s0">,</span>
            <span class="s1">)</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s0">with </span><span class="s1">ignore_warnings():</span>
        <span class="s0">assert </span><span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">) == </span><span class="s4">0</span>

    <span class="s0">assert not </span><span class="s1">list(recwarn)</span>


<span class="s0">def </span><span class="s1">test_average_binary_jaccard_score(recwarn):</span>
    <span class="s2"># tp=0, fp=0, fn=1, tn=0</span>
    <span class="s0">assert </span><span class="s1">jaccard_score([</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">) == </span><span class="s4">0.0</span>
    <span class="s2"># tp=0, fp=0, fn=0, tn=1</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;Jaccard is ill-defined and being set to 0.0 due to &quot;</span>
        <span class="s5">&quot;no true or predicted samples&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s0">assert </span><span class="s1">jaccard_score([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">) == </span><span class="s4">0.0</span>

    <span class="s2"># tp=1, fp=0, fn=0, tn=0 (pos_label=0)</span>
    <span class="s0">assert </span><span class="s1">jaccard_score([</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">) == </span><span class="s4">1.0</span>
    <span class="s1">y_true = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">3.0 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">2</span>
    <span class="s1">)</span>

    <span class="s0">assert not </span><span class="s1">list(recwarn)</span>


<span class="s0">def </span><span class="s1">test_jaccard_score_zero_division_warning():</span>
    <span class="s2"># check that we raised a warning with default behavior if a zero division</span>
    <span class="s2"># happens</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;Jaccard is ill-defined and being set to 0.0 in &quot;</span>
        <span class="s5">&quot;samples with no true or predicted labels.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">score = jaccard_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">zero_division=</span><span class="s5">&quot;warn&quot;</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">score == pytest.approx(</span><span class="s4">0.0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division, expected_score&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)])</span>
<span class="s0">def </span><span class="s1">test_jaccard_score_zero_division_set_value(zero_division</span><span class="s0">, </span><span class="s1">expected_score):</span>
    <span class="s2"># check that we don't issue warning by passing the zero_division parameter</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UndefinedMetricWarning)</span>
        <span class="s1">score = jaccard_score(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">score == pytest.approx(expected_score)</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_multilabel_1():</span>
    <span class="s2"># Test precision_recall_f1_score on a crafted multilabel example</span>
    <span class="s2"># First crafted example</span>

    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>

    <span class="s2"># tp = [0, 1, 1, 0]</span>
    <span class="s2"># fn = [1, 0, 0, 1]</span>
    <span class="s2"># fp = [1, 1, 0, 0]</span>
    <span class="s2"># Check per class</span>

    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">1.5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">f2 = fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">support = s</span>
    <span class="s1">assert_array_almost_equal(f2</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.83</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s2"># Check macro</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">1.5 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2.5 </span><span class="s1">/ </span><span class="s4">1.5 </span><span class="s1">* </span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean(f2)</span>
    <span class="s1">)</span>

    <span class="s2"># Check micro</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">4</span><span class="s1">) * p * r / (</span><span class="s4">4 </span><span class="s1">* p + r)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s2"># Check weighted</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">1.5 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2.5 </span><span class="s1">/ </span><span class="s4">1.5 </span><span class="s1">* </span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">np.average(f2</span><span class="s0">, </span><span class="s1">weights=support)</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s2"># Check samples</span>
    <span class="s2"># |h(x_i) inter y_i | = [0, 1, 1]</span>
    <span class="s2"># |y_i| = [1, 1, 2]</span>
    <span class="s2"># |h(x_i)| = [1, 1, 2]</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>


<span class="s1">@ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_multilabel_2():</span>
    <span class="s2"># Test precision_recall_f1_score on a crafted multilabel example 2</span>
    <span class="s2"># Second crafted example</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>

    <span class="s2"># tp = [ 0.  1.  0.  0.]</span>
    <span class="s2"># fp = [ 1.  0.  0.  2.]</span>
    <span class="s2"># fn = [ 1.  1.  1.  0.]</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.66</span><span class="s0">, </span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">f2 = fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">support = s</span>
    <span class="s1">assert_array_almost_equal(f2</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.55</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">* </span><span class="s4">0.25 </span><span class="s1">* </span><span class="s4">0.25 </span><span class="s1">/ </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">4</span><span class="s1">) * p * r / (</span><span class="s4">4 </span><span class="s1">* p + r)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.125</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">12</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean(f2)</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3 </span><span class="s1">* </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">np.average(f2</span><span class="s0">, </span><span class="s1">weights=support)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s2"># Check samples</span>
    <span class="s2"># |h(x_i) inter y_i | = [0, 0, 1]</span>
    <span class="s2"># |y_i| = [1, 1, 2]</span>
    <span class="s2"># |h(x_i)| = [1, 1, 2]</span>

    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">6</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">6</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">4 </span><span class="s1">* </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.1666</span><span class="s0">, </span><span class="s4">2</span>
    <span class="s1">)</span>


<span class="s1">@ignore_warnings</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;zero_division, zero_division_expected&quot;</span><span class="s0">,</span>
    <span class="s1">[(</span><span class="s5">&quot;warn&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(np.nan</span><span class="s0">, </span><span class="s1">np.nan)]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_score_with_an_empty_prediction(</span>
    <span class="s1">zero_division</span><span class="s0">, </span><span class="s1">zero_division_expected</span>
<span class="s1">):</span>
    <span class="s1">y_true = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">y_pred = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>

    <span class="s2"># true_pos = [ 0.  1.  1.  0.]</span>
    <span class="s2"># false_pos = [ 0.  0.  0.  1.]</span>
    <span class="s2"># false_neg = [ 1.  1.  0.  0.]</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[zero_division_expected</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s1">zero_division_expected]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">expected_f = </span><span class="s4">0 </span><span class="s0">if not </span><span class="s1">np.isnan(zero_division_expected) </span><span class="s0">else </span><span class="s1">np.nan</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[expected_f</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">1.5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">expected_f]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">f2 = fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None, </span><span class="s1">zero_division=zero_division)</span>
    <span class="s1">support = s</span>
    <span class="s1">assert_array_almost_equal(f2</span><span class="s0">, </span><span class="s1">[expected_f</span><span class="s0">, </span><span class="s4">0.55</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">expected_f]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>

    <span class="s1">value_to_sum = </span><span class="s4">0 </span><span class="s0">if </span><span class="s1">np.isnan(zero_division_expected) </span><span class="s0">else </span><span class="s1">zero_division_expected</span>
    <span class="s1">values_to_average = </span><span class="s4">3 </span><span class="s1">+ (</span><span class="s0">not </span><span class="s1">np.isnan(zero_division_expected))</span>

    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s1">(</span><span class="s4">2 </span><span class="s1">+ value_to_sum) / values_to_average)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1.5 </span><span class="s1">+ value_to_sum) / values_to_average)</span>
    <span class="s1">expected_f = (</span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3 </span><span class="s1">+ </span><span class="s4">1</span><span class="s1">) / (</span><span class="s4">4 </span><span class="s0">if not </span><span class="s1">np.isnan(zero_division_expected) </span><span class="s0">else </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s1">expected_f)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(</span>
            <span class="s1">y_true</span><span class="s0">,</span>
            <span class="s1">y_pred</span><span class="s0">,</span>
            <span class="s1">beta=</span><span class="s4">2</span><span class="s0">,</span>
            <span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s0">,</span>
            <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">_nanaverage(f2</span><span class="s0">, </span><span class="s1">weights=</span><span class="s0">None</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3 </span><span class="s1">/ (</span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3 </span><span class="s1">+ </span><span class="s4">0.5</span><span class="s1">))</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">4</span><span class="s1">) * p * r / (</span><span class="s4">4 </span><span class="s1">* p + r)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">3 </span><span class="s1">/ </span><span class="s4">4 </span><span class="s0">if </span><span class="s1">zero_division_expected == </span><span class="s4">0 </span><span class="s0">else </span><span class="s4">1.0</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">values_to_average = </span><span class="s4">4 </span><span class="s0">if not </span><span class="s1">np.isnan(zero_division_expected) </span><span class="s0">else </span><span class="s4">3</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s1">(</span><span class="s4">2 </span><span class="s1">* </span><span class="s4">2 </span><span class="s1">/ </span><span class="s4">3 </span><span class="s1">+ </span><span class="s4">1</span><span class="s1">) / values_to_average)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">_nanaverage(f2</span><span class="s0">, </span><span class="s1">weights=support)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>
    <span class="s2"># |h(x_i) inter y_i | = [0, 0, 2]</span>
    <span class="s2"># |y_i| = [1, 1, 2]</span>
    <span class="s2"># |h(x_i)| = [0, 1, 2]</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>
    <span class="s1">expected_result = {</span><span class="s4">1</span><span class="s1">: </span><span class="s4">0.666</span><span class="s0">, </span><span class="s1">np.nan: </span><span class="s4">1.0</span><span class="s1">}</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">fbeta_score(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">expected_result.get(zero_division</span><span class="s0">, </span><span class="s4">0.333</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s4">2</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;beta&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;average&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;samples&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_no_labels(beta</span><span class="s0">, </span><span class="s1">average</span><span class="s0">, </span><span class="s1">zero_division):</span>
    <span class="s1">y_true = np.zeros((</span><span class="s4">20</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
    <span class="s1">y_pred = np.zeros_like(y_true)</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = assert_no_warnings(</span>
        <span class="s1">precision_recall_fscore_support</span><span class="s0">,</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">average=average</span><span class="s0">,</span>
        <span class="s1">beta=beta</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">fbeta = assert_no_warnings(</span>
        <span class="s1">fbeta_score</span><span class="s0">,</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">beta=beta</span><span class="s0">,</span>
        <span class="s1">average=average</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>

    <span class="s2"># if zero_division = nan, check that all metrics are nan and exit</span>
    <span class="s0">if </span><span class="s1">np.isnan(zero_division):</span>
        <span class="s0">for </span><span class="s1">metric </span><span class="s0">in </span><span class="s1">[p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">fbeta]:</span>
            <span class="s0">assert </span><span class="s1">np.isnan(metric)</span>
        <span class="s0">return</span>

    <span class="s1">zero_division = float(zero_division)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s1">zero_division)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s1">zero_division)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s1">zero_division)</span>

    <span class="s1">assert_almost_equal(fbeta</span><span class="s0">, </span><span class="s1">float(zero_division))</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;average&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s5">&quot;micro&quot;</span><span class="s0">, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;samples&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_no_labels_check_warnings(average):</span>
    <span class="s1">y_true = np.zeros((</span><span class="s4">20</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
    <span class="s1">y_pred = np.zeros_like(y_true)</span>

    <span class="s1">func = precision_recall_fscore_support</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning):</span>
        <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = func(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(r</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(f</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s </span><span class="s0">is None</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning):</span>
        <span class="s1">fbeta = fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s1">assert_almost_equal(fbeta</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_f1_no_labels_average_none(zero_division):</span>
    <span class="s1">y_true = np.zeros((</span><span class="s4">20</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
    <span class="s1">y_pred = np.zeros_like(y_true)</span>

    <span class="s2"># tp = [0, 0, 0]</span>
    <span class="s2"># fn = [0, 0, 0]</span>
    <span class="s2"># fp = [0, 0, 0]</span>
    <span class="s2"># support = [0, 0, 0]</span>
    <span class="s2"># |y_hat_i inter y_i | = [0, 0, 0]</span>
    <span class="s2"># |y_i| = [0, 0, 0]</span>
    <span class="s2"># |y_hat_i| = [0, 0, 0]</span>

    <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = assert_no_warnings(</span>
        <span class="s1">precision_recall_fscore_support</span><span class="s0">,</span>
        <span class="s1">y_true</span><span class="s0">,</span>
        <span class="s1">y_pred</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s0">None,</span>
        <span class="s1">beta=</span><span class="s4">1.0</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">fbeta = assert_no_warnings(</span>
        <span class="s1">fbeta_score</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1.0</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>
    <span class="s1">zero_division = np.float64(zero_division)</span>
    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[zero_division</span><span class="s0">, </span><span class="s1">zero_division</span><span class="s0">, </span><span class="s1">zero_division]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[zero_division</span><span class="s0">, </span><span class="s1">zero_division</span><span class="s0">, </span><span class="s1">zero_division]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[zero_division</span><span class="s0">, </span><span class="s1">zero_division</span><span class="s0">, </span><span class="s1">zero_division]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(fbeta</span><span class="s0">, </span><span class="s1">[zero_division</span><span class="s0">, </span><span class="s1">zero_division</span><span class="s0">, </span><span class="s1">zero_division]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_precision_recall_f1_no_labels_average_none_warn():</span>
    <span class="s1">y_true = np.zeros((</span><span class="s4">20</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
    <span class="s1">y_pred = np.zeros_like(y_true)</span>

    <span class="s2"># tp = [0, 0, 0]</span>
    <span class="s2"># fn = [0, 0, 0]</span>
    <span class="s2"># fp = [0, 0, 0]</span>
    <span class="s2"># support = [0, 0, 0]</span>
    <span class="s2"># |y_hat_i inter y_i | = [0, 0, 0]</span>
    <span class="s2"># |y_i| = [0, 0, 0]</span>
    <span class="s2"># |y_hat_i| = [0, 0, 0]</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning):</span>
        <span class="s1">p</span><span class="s0">, </span><span class="s1">r</span><span class="s0">, </span><span class="s1">f</span><span class="s0">, </span><span class="s1">s = precision_recall_fscore_support(</span>
            <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None, </span><span class="s1">beta=</span><span class="s4">1</span>
        <span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(p</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(r</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(s</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UndefinedMetricWarning):</span>
        <span class="s1">fbeta = fbeta_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">average=</span><span class="s0">None</span><span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(fbeta</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_prf_warnings():</span>
    <span class="s2"># average of per-label scores</span>
    <span class="s1">f</span><span class="s0">, </span><span class="s1">w = precision_recall_fscore_support</span><span class="s0">, </span><span class="s1">UndefinedMetricWarning</span>
    <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">[</span><span class="s0">None, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;macro&quot;</span><span class="s1">]:</span>
        <span class="s1">msg = (</span>
            <span class="s5">&quot;Precision and F-score are ill-defined and &quot;</span>
            <span class="s5">&quot;being set to 0.0 in labels with no predicted samples.&quot;</span>
            <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
            <span class="s5">&quot; this behavior.&quot;</span>
        <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">f([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=average)</span>

        <span class="s1">msg = (</span>
            <span class="s5">&quot;Recall and F-score are ill-defined and &quot;</span>
            <span class="s5">&quot;being set to 0.0 in labels with no true samples.&quot;</span>
            <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
            <span class="s5">&quot; this behavior.&quot;</span>
        <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">f([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=average)</span>

    <span class="s2"># average of per-sample scores</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;Precision and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 in samples with no predicted labels.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f(np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">&quot;Recall and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 in samples with no true labels.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f(np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s1">)</span>

    <span class="s2"># single score: micro-average</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;Precision and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 due to no predicted samples.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f(np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">&quot;Recall and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 due to no true samples.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f(np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s1">)</span>

    <span class="s2"># single positive label</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;Precision and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 due to no predicted samples.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f([</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s5">&quot;Recall and F-score are ill-defined and &quot;</span>
        <span class="s5">&quot;being set to 0.0 due to no true samples.&quot;</span>
        <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
        <span class="s5">&quot; this behavior.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(w</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">f([-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">precision_recall_fscore_support([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s1">)</span>
        <span class="s1">msg = (</span>
            <span class="s5">&quot;Recall and F-score are ill-defined and &quot;</span>
            <span class="s5">&quot;being set to 0.0 due to no true samples.&quot;</span>
            <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
            <span class="s5">&quot; this behavior.&quot;</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">str(record.pop().message) == msg</span>
        <span class="s1">msg = (</span>
            <span class="s5">&quot;Precision and F-score are ill-defined and &quot;</span>
            <span class="s5">&quot;being set to 0.0 due to no predicted samples.&quot;</span>
            <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
            <span class="s5">&quot; this behavior.&quot;</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">str(record.pop().message) == msg</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_prf_no_warnings_if_zero_division_set(zero_division):</span>
    <span class="s2"># average of per-label scores</span>
    <span class="s1">f = precision_recall_fscore_support</span>
    <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">[</span><span class="s0">None, </span><span class="s5">&quot;weighted&quot;</span><span class="s0">, </span><span class="s5">&quot;macro&quot;</span><span class="s1">]:</span>
        <span class="s1">assert_no_warnings(</span>
            <span class="s1">f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span>

        <span class="s1">assert_no_warnings(</span>
            <span class="s1">f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span>

    <span class="s2"># average of per-sample scores</span>
    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;samples&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s2"># single score: micro-average</span>
    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s2"># single positive label</span>
    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>

    <span class="s1">assert_no_warnings(</span>
        <span class="s1">f</span><span class="s0">, </span><span class="s1">[-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">precision_recall_fscore_support(</span>
            <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;binary&quot;</span><span class="s0">, </span><span class="s1">zero_division=zero_division</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;warn&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_recall_warnings(zero_division):</span>
    <span class="s1">assert_no_warnings(</span>
        <span class="s1">recall_score</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">recall_score(</span>
            <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
            <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
            <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
            <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">(</span>
                <span class="s1">str(record.pop().message)</span>
                <span class="s1">== </span><span class="s5">&quot;Recall is ill-defined and &quot;</span>
                <span class="s5">&quot;being set to 0.0 due to no true samples.&quot;</span>
                <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
                <span class="s5">&quot; this behavior.&quot;</span>
            <span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>

        <span class="s1">recall_score([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
        <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">(</span>
                <span class="s1">str(record.pop().message)</span>
                <span class="s1">== </span><span class="s5">&quot;Recall is ill-defined and &quot;</span>
                <span class="s5">&quot;being set to 0.0 due to no true samples.&quot;</span>
                <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
                <span class="s5">&quot; this behavior.&quot;</span>
            <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;warn&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_precision_warnings(zero_division):</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;always&quot;</span><span class="s1">)</span>
        <span class="s1">precision_score(</span>
            <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
            <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
            <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
            <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">(</span>
                <span class="s1">str(record.pop().message)</span>
                <span class="s1">== </span><span class="s5">&quot;Precision is ill-defined and &quot;</span>
                <span class="s5">&quot;being set to 0.0 due to no predicted samples.&quot;</span>
                <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
                <span class="s5">&quot; this behavior.&quot;</span>
            <span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>

        <span class="s1">precision_score([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
        <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">(</span>
                <span class="s1">str(record.pop().message)</span>
                <span class="s1">== </span><span class="s5">&quot;Precision is ill-defined and &quot;</span>
                <span class="s5">&quot;being set to 0.0 due to no predicted samples.&quot;</span>
                <span class="s5">&quot; Use `zero_division` parameter to control&quot;</span>
                <span class="s5">&quot; this behavior.&quot;</span>
            <span class="s1">)</span>

    <span class="s1">assert_no_warnings(</span>
        <span class="s1">precision_score</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
        <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;zero_division&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;warn&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">np.nan])</span>
<span class="s0">def </span><span class="s1">test_fscore_warnings(zero_division):</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">record:</span>
        <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;always&quot;</span><span class="s1">)</span>

        <span class="s0">for </span><span class="s1">score </span><span class="s0">in </span><span class="s1">[f1_score</span><span class="s0">, </span><span class="s1">partial(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s1">)]:</span>
            <span class="s1">score(</span>
                <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
                <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>

            <span class="s1">score(</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">np.array([[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
                <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>

            <span class="s1">score(</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span><span class="s0">,</span>
                <span class="s1">average=</span><span class="s5">&quot;micro&quot;</span><span class="s0">,</span>
                <span class="s1">zero_division=zero_division</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s0">if </span><span class="s1">zero_division == </span><span class="s5">&quot;warn&quot;</span><span class="s1">:</span>
                <span class="s0">assert </span><span class="s1">(</span>
                    <span class="s1">str(record.pop().message)</span>
                    <span class="s1">== </span><span class="s5">&quot;F-score is ill-defined and &quot;</span>
                    <span class="s5">&quot;being set to 0.0 due to no true nor predicted &quot;</span>
                    <span class="s5">&quot;samples. Use `zero_division` parameter to &quot;</span>
                    <span class="s5">&quot;control this behavior.&quot;</span>
                <span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">assert </span><span class="s1">len(record) == </span><span class="s4">0</span>


<span class="s0">def </span><span class="s1">test_prf_average_binary_data_non_binary():</span>
    <span class="s2"># Error if user does not explicitly set non-binary average mode</span>
    <span class="s1">y_true_mc = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">y_pred_mc = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">msg_mc = (</span>
        <span class="s5">r&quot;Target is multiclass but average='binary'. Please &quot;</span>
        <span class="s5">r&quot;choose another average setting, one of \[&quot;</span>
        <span class="s5">r&quot;None, 'micro', 'macro', 'weighted'\].&quot;</span>
    <span class="s1">)</span>
    <span class="s1">y_true_ind = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y_pred_ind = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">msg_ind = (</span>
        <span class="s5">r&quot;Target is multilabel-indicator but average='binary'. Please &quot;</span>
        <span class="s5">r&quot;choose another average setting, one of \[&quot;</span>
        <span class="s5">r&quot;None, 'micro', 'macro', 'weighted', 'samples'\].&quot;</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">msg </span><span class="s0">in </span><span class="s1">[</span>
        <span class="s1">(y_true_mc</span><span class="s0">, </span><span class="s1">y_pred_mc</span><span class="s0">, </span><span class="s1">msg_mc)</span><span class="s0">,</span>
        <span class="s1">(y_true_ind</span><span class="s0">, </span><span class="s1">y_pred_ind</span><span class="s0">, </span><span class="s1">msg_ind)</span><span class="s0">,</span>
    <span class="s1">]:</span>
        <span class="s0">for </span><span class="s1">metric </span><span class="s0">in </span><span class="s1">[</span>
            <span class="s1">precision_score</span><span class="s0">,</span>
            <span class="s1">recall_score</span><span class="s0">,</span>
            <span class="s1">f1_score</span><span class="s0">,</span>
            <span class="s1">partial(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">]:</span>
            <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
                <span class="s1">metric(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>


<span class="s0">def </span><span class="s1">test__check_targets():</span>
    <span class="s2"># Check that _check_targets correctly merges target types, squeezes</span>
    <span class="s2"># output and fails if input lengths differ.</span>
    <span class="s1">IND = </span><span class="s5">&quot;multilabel-indicator&quot;</span>
    <span class="s1">MC = </span><span class="s5">&quot;multiclass&quot;</span>
    <span class="s1">BIN = </span><span class="s5">&quot;binary&quot;</span>
    <span class="s1">CNT = </span><span class="s5">&quot;continuous&quot;</span>
    <span class="s1">MMC = </span><span class="s5">&quot;multiclass-multioutput&quot;</span>
    <span class="s1">MCN = </span><span class="s5">&quot;continuous-multioutput&quot;</span>
    <span class="s2"># all of length 3</span>
    <span class="s1">EXAMPLES = [</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s2"># must not be considered binary</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">(CNT</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.5</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s1">(CNT</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1.0</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s1">(MMC</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]]))</span><span class="s0">,</span>
        <span class="s1">(MCN</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1.1</span><span class="s0">, </span><span class="s4">3.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2.0</span><span class="s0">, </span><span class="s4">3.0</span><span class="s1">]]))</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s2"># expected type given input types, or None for error</span>
    <span class="s2"># (types will be tried in either order)</span>
    <span class="s1">EXPECTED = {</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">IND): IND</span><span class="s0">,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">MC): MC</span><span class="s0">,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">BIN): BIN</span><span class="s0">,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">IND): </span><span class="s0">None,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">IND): </span><span class="s0">None,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">MC): MC</span><span class="s0">,</span>
        <span class="s2"># Disallowed types</span>
        <span class="s1">(CNT</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(MMC</span><span class="s0">, </span><span class="s1">MMC): </span><span class="s0">None,</span>
        <span class="s1">(MCN</span><span class="s0">, </span><span class="s1">MCN): </span><span class="s0">None,</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(MMC</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(MCN</span><span class="s0">, </span><span class="s1">CNT): </span><span class="s0">None,</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">MMC): </span><span class="s0">None,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">MMC): </span><span class="s0">None,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">MMC): </span><span class="s0">None,</span>
        <span class="s1">(MCN</span><span class="s0">, </span><span class="s1">MMC): </span><span class="s0">None,</span>
        <span class="s1">(IND</span><span class="s0">, </span><span class="s1">MCN): </span><span class="s0">None,</span>
        <span class="s1">(MC</span><span class="s0">, </span><span class="s1">MCN): </span><span class="s0">None,</span>
        <span class="s1">(BIN</span><span class="s0">, </span><span class="s1">MCN): </span><span class="s0">None,</span>
    <span class="s1">}</span>

    <span class="s0">for </span><span class="s1">(type1</span><span class="s0">, </span><span class="s1">y1)</span><span class="s0">, </span><span class="s1">(type2</span><span class="s0">, </span><span class="s1">y2) </span><span class="s0">in </span><span class="s1">product(EXAMPLES</span><span class="s0">, </span><span class="s1">repeat=</span><span class="s4">2</span><span class="s1">):</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">expected = EXPECTED[type1</span><span class="s0">, </span><span class="s1">type2]</span>
        <span class="s0">except </span><span class="s1">KeyError:</span>
            <span class="s1">expected = EXPECTED[type2</span><span class="s0">, </span><span class="s1">type1]</span>
        <span class="s0">if </span><span class="s1">expected </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
                <span class="s1">_check_targets(y1</span><span class="s0">, </span><span class="s1">y2)</span>

            <span class="s0">if </span><span class="s1">type1 != type2:</span>
                <span class="s1">err_msg = (</span>
                    <span class="s5">&quot;Classification metrics can't handle a mix &quot;</span>
                    <span class="s5">&quot;of {0} and {1} targets&quot;</span><span class="s1">.format(type1</span><span class="s0">, </span><span class="s1">type2)</span>
                <span class="s1">)</span>
                <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
                    <span class="s1">_check_targets(y1</span><span class="s0">, </span><span class="s1">y2)</span>

            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">type1 </span><span class="s0">not in </span><span class="s1">(BIN</span><span class="s0">, </span><span class="s1">MC</span><span class="s0">, </span><span class="s1">IND):</span>
                    <span class="s1">err_msg = </span><span class="s5">&quot;{0} is not supported&quot;</span><span class="s1">.format(type1)</span>
                    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
                        <span class="s1">_check_targets(y1</span><span class="s0">, </span><span class="s1">y2)</span>

        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">merged_type</span><span class="s0">, </span><span class="s1">y1out</span><span class="s0">, </span><span class="s1">y2out = _check_targets(y1</span><span class="s0">, </span><span class="s1">y2)</span>
            <span class="s0">assert </span><span class="s1">merged_type == expected</span>
            <span class="s0">if </span><span class="s1">merged_type.startswith(</span><span class="s5">&quot;multilabel&quot;</span><span class="s1">):</span>
                <span class="s0">assert </span><span class="s1">y1out.format == </span><span class="s5">&quot;csr&quot;</span>
                <span class="s0">assert </span><span class="s1">y2out.format == </span><span class="s5">&quot;csr&quot;</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">assert_array_equal(y1out</span><span class="s0">, </span><span class="s1">np.squeeze(y1))</span>
                <span class="s1">assert_array_equal(y2out</span><span class="s0">, </span><span class="s1">np.squeeze(y2))</span>
            <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
                <span class="s1">_check_targets(y1[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y2)</span>

    <span class="s2"># Make sure seq of seq is not supported</span>
    <span class="s1">y1 = [(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)]</span>
    <span class="s1">y2 = [(</span><span class="s4">2</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;You appear to be using a legacy multi-label data representation. &quot;</span>
        <span class="s5">&quot;Sequence of sequences are no longer supported; use a binary array&quot;</span>
        <span class="s5">&quot; or sparse matrix instead - the MultiLabelBinarizer&quot;</span>
        <span class="s5">&quot; transformer can convert to this format.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">_check_targets(y1</span><span class="s0">, </span><span class="s1">y2)</span>


<span class="s0">def </span><span class="s1">test__check_targets_multiclass_with_both_y_true_and_y_pred_binary():</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/8098</span>
    <span class="s1">y_true = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">y_pred = [</span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">_check_targets(y_true</span><span class="s0">, </span><span class="s1">y_pred)[</span><span class="s4">0</span><span class="s1">] == </span><span class="s5">&quot;multiclass&quot;</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_binary():</span>
    <span class="s1">y_true = np.array([-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">pred_decision = np.array([-</span><span class="s4">8.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.5</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.3</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision) == </span><span class="s4">1.2 </span><span class="s1">/ </span><span class="s4">4</span>

    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">pred_decision = np.array([-</span><span class="s4">8.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.5</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.3</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision) == </span><span class="s4">1.2 </span><span class="s1">/ </span><span class="s4">4</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass():</span>
    <span class="s1">pred_decision = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[+</span><span class="s4">0.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.99</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.54</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.37</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.54</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">2.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.79</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.27</span><span class="s0">, </span><span class="s1">+</span><span class="s4">0.24</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">dummy_losses = np.array(</span>
        <span class="s1">[</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] + pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">3</span><span class="s1">] + pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">5</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">5</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">np.clip(dummy_losses</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, None, </span><span class="s1">out=dummy_losses)</span>
    <span class="s1">dummy_hinge_loss = np.mean(dummy_losses)</span>
    <span class="s0">assert </span><span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision) == dummy_hinge_loss</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass_missing_labels_with_labels_none():</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">pred_decision = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[+</span><span class="s4">1.27</span><span class="s0">, </span><span class="s4">0.034</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.68</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1.40</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">2.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.79</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.27</span><span class="s0">, </span><span class="s1">+</span><span class="s4">0.24</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">2.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.79</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.27</span><span class="s0">, </span><span class="s1">+</span><span class="s4">0.24</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">error_message = (</span>
        <span class="s5">&quot;Please include all labels in y_true or pass labels as third argument&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=error_message):</span>
        <span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision)</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass_no_consistent_pred_decision_shape():</span>
    <span class="s2"># test for inconsistency between multiclass problem and pred_decision</span>
    <span class="s2"># argument</span>
    <span class="s1">y_true = np.array([</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">pred_decision = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">error_message = (</span>
        <span class="s5">&quot;The shape of pred_decision cannot be 1d array&quot;</span>
        <span class="s5">&quot;with a multiclass target. pred_decision shape &quot;</span>
        <span class="s5">&quot;must be (n_samples, n_classes), that is &quot;</span>
        <span class="s5">&quot;(7, 3). Got: (7,)&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=re.escape(error_message)):</span>
        <span class="s1">hinge_loss(y_true=y_true</span><span class="s0">, </span><span class="s1">pred_decision=pred_decision)</span>

    <span class="s2"># test for inconsistency between pred_decision shape and labels number</span>
    <span class="s1">pred_decision = np.array([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]])</span>
    <span class="s1">labels = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">error_message = (</span>
        <span class="s5">&quot;The shape of pred_decision is not &quot;</span>
        <span class="s5">&quot;consistent with the number of classes. &quot;</span>
        <span class="s5">&quot;With a multiclass target, pred_decision &quot;</span>
        <span class="s5">&quot;shape must be (n_samples, n_classes), that is &quot;</span>
        <span class="s5">&quot;(7, 3). Got: (7, 2)&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=re.escape(error_message)):</span>
        <span class="s1">hinge_loss(y_true=y_true</span><span class="s0">, </span><span class="s1">pred_decision=pred_decision</span><span class="s0">, </span><span class="s1">labels=labels)</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass_with_missing_labels():</span>
    <span class="s1">pred_decision = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[+</span><span class="s4">0.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.99</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.55</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.55</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">labels = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">dummy_losses = np.array(</span>
        <span class="s1">[</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] + pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">np.clip(dummy_losses</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, None, </span><span class="s1">out=dummy_losses)</span>
    <span class="s1">dummy_hinge_loss = np.mean(dummy_losses)</span>
    <span class="s0">assert </span><span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision</span><span class="s0">, </span><span class="s1">labels=labels) == dummy_hinge_loss</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass_missing_labels_only_two_unq_in_y_true():</span>
    <span class="s2"># non-regression test for:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/17630</span>
    <span class="s2"># check that we can compute the hinge loss when providing an array</span>
    <span class="s2"># with labels allowing to not have all labels in y_true</span>
    <span class="s1">pred_decision = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[+</span><span class="s4">0.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.15</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">0.55</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.78</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.42</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">labels = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">dummy_losses = np.array(</span>
        <span class="s1">[</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] + pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] + pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">np.clip(dummy_losses</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, None, </span><span class="s1">out=dummy_losses)</span>
    <span class="s1">dummy_hinge_loss = np.mean(dummy_losses)</span>
    <span class="s1">assert_almost_equal(</span>
        <span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision</span><span class="s0">, </span><span class="s1">labels=labels)</span><span class="s0">, </span><span class="s1">dummy_hinge_loss</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_hinge_loss_multiclass_invariance_lists():</span>
    <span class="s2"># Currently, invariance of string and integer labels cannot be tested</span>
    <span class="s2"># in common invariance tests because invariance tests for multiclass</span>
    <span class="s2"># decision functions is not implemented yet.</span>
    <span class="s1">y_true = [</span><span class="s5">&quot;blue&quot;</span><span class="s0">, </span><span class="s5">&quot;green&quot;</span><span class="s0">, </span><span class="s5">&quot;red&quot;</span><span class="s0">, </span><span class="s5">&quot;green&quot;</span><span class="s0">, </span><span class="s5">&quot;white&quot;</span><span class="s0">, </span><span class="s5">&quot;red&quot;</span><span class="s1">]</span>
    <span class="s1">pred_decision = [</span>
        <span class="s1">[+</span><span class="s4">0.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.99</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s4">0.55</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s4">0.55</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.48</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s4">2.36</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.79</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.27</span><span class="s0">, </span><span class="s1">+</span><span class="s4">0.24</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s4">1.45</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.58</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.38</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.17</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">dummy_losses = np.array(</span>
        <span class="s1">[</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] + pred_decision[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">2</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">1</span><span class="s1">] + pred_decision[</span><span class="s4">3</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">3</span><span class="s1">] + pred_decision[</span><span class="s4">4</span><span class="s1">][</span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s4">1 </span><span class="s1">- pred_decision[</span><span class="s4">5</span><span class="s1">][</span><span class="s4">2</span><span class="s1">] + pred_decision[</span><span class="s4">5</span><span class="s1">][</span><span class="s4">3</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">np.clip(dummy_losses</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, None, </span><span class="s1">out=dummy_losses)</span>
    <span class="s1">dummy_hinge_loss = np.mean(dummy_losses)</span>
    <span class="s0">assert </span><span class="s1">hinge_loss(y_true</span><span class="s0">, </span><span class="s1">pred_decision) == dummy_hinge_loss</span>


<span class="s0">def </span><span class="s1">test_log_loss():</span>
    <span class="s2"># binary case with symbolic labels (&quot;no&quot; &lt; &quot;yes&quot;)</span>
    <span class="s1">y_true = [</span><span class="s5">&quot;no&quot;</span><span class="s0">, </span><span class="s5">&quot;no&quot;</span><span class="s0">, </span><span class="s5">&quot;no&quot;</span><span class="s0">, </span><span class="s5">&quot;yes&quot;</span><span class="s0">, </span><span class="s5">&quot;yes&quot;</span><span class="s0">, </span><span class="s5">&quot;yes&quot;</span><span class="s1">]</span>
    <span class="s1">y_pred = np.array(</span>
        <span class="s1">[[</span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.9</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.01</span><span class="s0">, </span><span class="s4">0.99</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.75</span><span class="s0">, </span><span class="s4">0.25</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.001</span><span class="s0">, </span><span class="s4">0.999</span><span class="s1">]]</span>
    <span class="s1">)</span>
    <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">loss_true = -np.mean(bernoulli.logpmf(np.array(y_true) == </span><span class="s5">&quot;yes&quot;</span><span class="s0">, </span><span class="s1">y_pred[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]))</span>
    <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s1">loss_true)</span>

    <span class="s2"># multiclass case; adapted from http://bit.ly/RJJHWA</span>
    <span class="s1">y_true = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]]</span>
    <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s4">0.6904911</span><span class="s1">)</span>

    <span class="s2"># check that we got all the shapes and axes right</span>
    <span class="s2"># by doubling the length of y_true and y_pred</span>
    <span class="s1">y_true *= </span><span class="s4">2</span>
    <span class="s1">y_pred *= </span><span class="s4">2</span>
    <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s4">0.6904911 </span><span class="s1">* </span><span class="s4">6</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>

    <span class="s1">user_warning_msg = </span><span class="s5">&quot;y_pred values do not sum to one&quot;</span>
    <span class="s2"># check eps and handling of absolute zero and one probabilities</span>
    <span class="s1">y_pred = np.asarray(y_pred) &gt; </span><span class="s4">0.5</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">True, </span><span class="s1">eps=</span><span class="s4">0.1</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=user_warning_msg):</span>
        <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s1">log_loss(y_true</span><span class="s0">, </span><span class="s1">np.clip(y_pred</span><span class="s0">, </span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.9</span><span class="s1">)))</span>

    <span class="s2"># binary case: check correct boundary values for eps = 0</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s0">assert </span><span class="s1">log_loss([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">) == </span><span class="s4">0</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s0">assert </span><span class="s1">log_loss([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">) == np.inf</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s0">assert </span><span class="s1">log_loss([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">) == np.inf</span>

    <span class="s2"># multiclass case: check correct boundary values for eps = 0</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s0">assert </span><span class="s1">log_loss([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">) == </span><span class="s4">0</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s0">assert </span><span class="s1">(</span>
            <span class="s1">log_loss([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">) == np.inf</span>
        <span class="s1">)</span>

    <span class="s2"># raise error if number of classes are not equal.</span>
    <span class="s1">y_true = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]]</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>

    <span class="s2"># case when y_true is a string array object</span>
    <span class="s1">y_true = [</span><span class="s5">&quot;ham&quot;</span><span class="s0">, </span><span class="s5">&quot;spam&quot;</span><span class="s0">, </span><span class="s5">&quot;spam&quot;</span><span class="s0">, </span><span class="s5">&quot;ham&quot;</span><span class="s1">]</span>
    <span class="s1">y_pred = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.2</span><span class="s1">]]</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=user_warning_msg):</span>
        <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s4">1.0383217</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>

    <span class="s2"># test labels option</span>

    <span class="s1">y_true = [</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_pred = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]]</span>
    <span class="s1">y_score = np.array([[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.9</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.9</span><span class="s1">]])</span>
    <span class="s1">error_str = (</span>
        <span class="s5">r&quot;y_true contains only one label \(2\). Please provide &quot;</span>
        <span class="s5">r&quot;the true labels explicitly through the labels argument.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=error_str):</span>
        <span class="s1">log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>

    <span class="s1">y_pred = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]]</span>
    <span class="s1">error_str = </span><span class="s5">&quot;Found input variables with inconsistent numbers of samples: [3, 2]&quot;</span>
    <span class="s1">(ValueError</span><span class="s0">, </span><span class="s1">error_str</span><span class="s0">, </span><span class="s1">log_loss</span><span class="s0">, </span><span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>

    <span class="s2"># works when the labels argument is used</span>

    <span class="s1">true_log_loss = -np.mean(np.log(y_score[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]))</span>
    <span class="s1">calculated_log_loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_score</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(calculated_log_loss</span><span class="s0">, </span><span class="s1">true_log_loss)</span>

    <span class="s2"># ensure labels work when len(np.unique(y_true)) != y_pred.shape[1]</span>
    <span class="s1">y_true = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">y_score2 = [[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]]</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=user_warning_msg):</span>
        <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_score2</span><span class="s0">, </span><span class="s1">labels=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s4">1.0630345</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_log_loss_eps_auto(global_dtype):</span>
    <span class="s3">&quot;&quot;&quot;Check the behaviour of `eps=&quot;auto&quot;` that changes depending on the input 
    array dtype. 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/24315 
    &quot;&quot;&quot;</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=global_dtype)</span>
    <span class="s1">y_pred = y_true.copy()</span>

    <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">eps=</span><span class="s5">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.isfinite(loss)</span>


<span class="s0">def </span><span class="s1">test_log_loss_eps_auto_float16():</span>
    <span class="s3">&quot;&quot;&quot;Check the behaviour of `eps=&quot;auto&quot;` for np.float16&quot;&quot;&quot;</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float16)</span>
    <span class="s1">y_pred = y_true.copy()</span>

    <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">eps=</span><span class="s5">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.isfinite(loss)</span>


<span class="s0">def </span><span class="s1">test_log_loss_pandas_input():</span>
    <span class="s2"># case when input is a pandas series and dataframe gh-5715</span>
    <span class="s1">y_tr = np.array([</span><span class="s5">&quot;ham&quot;</span><span class="s0">, </span><span class="s5">&quot;spam&quot;</span><span class="s0">, </span><span class="s5">&quot;spam&quot;</span><span class="s0">, </span><span class="s5">&quot;ham&quot;</span><span class="s1">])</span>
    <span class="s1">y_pr = np.array([[</span><span class="s4">0.2</span><span class="s0">, </span><span class="s4">0.7</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.7</span><span class="s0">, </span><span class="s4">0.2</span><span class="s1">]])</span>
    <span class="s1">types = [(MockDataFrame</span><span class="s0">, </span><span class="s1">MockDataFrame)]</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">from </span><span class="s1">pandas </span><span class="s0">import </span><span class="s1">DataFrame</span><span class="s0">, </span><span class="s1">Series</span>

        <span class="s1">types.append((Series</span><span class="s0">, </span><span class="s1">DataFrame))</span>
    <span class="s0">except </span><span class="s1">ImportError:</span>
        <span class="s0">pass</span>
    <span class="s0">for </span><span class="s1">TrueInputType</span><span class="s0">, </span><span class="s1">PredInputType </span><span class="s0">in </span><span class="s1">types:</span>
        <span class="s2"># y_pred dataframe, y_true series</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred = TrueInputType(y_tr)</span><span class="s0">, </span><span class="s1">PredInputType(y_pr)</span>
        <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=</span><span class="s5">&quot;y_pred values do not sum to one&quot;</span><span class="s1">):</span>
            <span class="s1">loss = log_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
        <span class="s1">assert_almost_equal(loss</span><span class="s0">, </span><span class="s4">1.0383217</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_brier_score_loss():</span>
    <span class="s2"># Check brier_score_loss function</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">0.8</span><span class="s0">, </span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">0.3</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.95</span><span class="s1">])</span>
    <span class="s1">true_score = linalg.norm(y_true - y_pred) ** </span><span class="s4">2 </span><span class="s1">/ len(y_true)</span>

    <span class="s1">assert_almost_equal(brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_true)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">true_score)</span>
    <span class="s1">assert_almost_equal(brier_score_loss(</span><span class="s4">1.0 </span><span class="s1">+ y_true</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">true_score)</span>
    <span class="s1">assert_almost_equal(brier_score_loss(</span><span class="s4">2 </span><span class="s1">* y_true - </span><span class="s4">1</span><span class="s0">, </span><span class="s1">y_pred)</span><span class="s0">, </span><span class="s1">true_score)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred[</span><span class="s4">1</span><span class="s1">:])</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred + </span><span class="s4">1.0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred - </span><span class="s4">1.0</span><span class="s1">)</span>

    <span class="s2"># ensure to raise an error for multiclass y_true</span>
    <span class="s1">y_true = np.array([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">y_pred = np.array([</span><span class="s4">0.8</span><span class="s0">, </span><span class="s4">0.6</span><span class="s0">, </span><span class="s4">0.4</span><span class="s0">, </span><span class="s4">0.2</span><span class="s1">])</span>
    <span class="s1">error_message = (</span>
        <span class="s5">&quot;Only binary classification is supported. The type of the target is multiclass&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=error_message):</span>
        <span class="s1">brier_score_loss(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>

    <span class="s2"># calculate correctly when there's only one class in y_true</span>
    <span class="s1">assert_almost_equal(brier_score_loss([-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s1">])</span><span class="s0">, </span><span class="s4">0.16</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(brier_score_loss([</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s1">])</span><span class="s0">, </span><span class="s4">0.16</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(brier_score_loss([</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s1">])</span><span class="s0">, </span><span class="s4">0.36</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(brier_score_loss([</span><span class="s5">&quot;foo&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s5">&quot;bar&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.16</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(brier_score_loss([</span><span class="s5">&quot;foo&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pos_label=</span><span class="s5">&quot;foo&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.36</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_balanced_accuracy_score_unseen():</span>
    <span class="s1">msg = </span><span class="s5">&quot;y_pred contains classes not in y_true&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">balanced_accuracy_score([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;y_true,y_pred&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;c&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s5">&quot;a&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s0">, </span><span class="s5">&quot;c&quot;</span><span class="s0">, </span><span class="s5">&quot;b&quot;</span><span class="s1">])</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_balanced_accuracy_score(y_true</span><span class="s0">, </span><span class="s1">y_pred):</span>
    <span class="s1">macro_recall = recall_score(</span>
        <span class="s1">y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">average=</span><span class="s5">&quot;macro&quot;</span><span class="s0">, </span><span class="s1">labels=np.unique(y_true)</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">ignore_warnings():</span>
        <span class="s2"># Warnings are tested in test_balanced_accuracy_score_unseen</span>
        <span class="s1">balanced = balanced_accuracy_score(y_true</span><span class="s0">, </span><span class="s1">y_pred)</span>
    <span class="s0">assert </span><span class="s1">balanced == pytest.approx(macro_recall)</span>
    <span class="s1">adjusted = balanced_accuracy_score(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">adjusted=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">chance = balanced_accuracy_score(y_true</span><span class="s0">, </span><span class="s1">np.full_like(y_true</span><span class="s0">, </span><span class="s1">y_true[</span><span class="s4">0</span><span class="s1">]))</span>
    <span class="s0">assert </span><span class="s1">adjusted == (balanced - chance) / (</span><span class="s4">1 </span><span class="s1">- chance)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;metric&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">jaccard_score</span><span class="s0">,</span>
        <span class="s1">f1_score</span><span class="s0">,</span>
        <span class="s1">partial(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">0.5</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">precision_recall_fscore_support</span><span class="s0">,</span>
        <span class="s1">precision_score</span><span class="s0">,</span>
        <span class="s1">recall_score</span><span class="s0">,</span>
        <span class="s1">brier_score_loss</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;classes&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s0">False, True</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0.0</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s5">&quot;zero&quot;</span><span class="s0">, </span><span class="s5">&quot;one&quot;</span><span class="s1">)]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_classification_metric_pos_label_types(metric</span><span class="s0">, </span><span class="s1">classes):</span>
    <span class="s3">&quot;&quot;&quot;Check that the metric works with different types of `pos_label`. 
 
    We can expect `pos_label` to be a bool, an integer, a float, a string. 
    No error should be raised for those types. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">pos_label = </span><span class="s4">10</span><span class="s0">, </span><span class="s1">classes[-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">y_true = rng.choice(classes</span><span class="s0">, </span><span class="s1">size=n_samples</span><span class="s0">, </span><span class="s1">replace=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">metric </span><span class="s0">is </span><span class="s1">brier_score_loss:</span>
        <span class="s2"># brier score loss requires probabilities</span>
        <span class="s1">y_pred = rng.uniform(size=n_samples)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">y_pred = y_true.copy()</span>
    <span class="s1">result = metric(y_true</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label)</span>
    <span class="s0">assert not </span><span class="s1">np.any(np.isnan(result))</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;scoring&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">make_scorer(f1_score</span><span class="s0">, </span><span class="s1">zero_division=np.nan)</span><span class="s0">,</span>
        <span class="s1">make_scorer(fbeta_score</span><span class="s0">, </span><span class="s1">beta=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">zero_division=np.nan)</span><span class="s0">,</span>
        <span class="s1">make_scorer(precision_score</span><span class="s0">, </span><span class="s1">zero_division=np.nan)</span><span class="s0">,</span>
        <span class="s1">make_scorer(recall_score</span><span class="s0">, </span><span class="s1">zero_division=np.nan)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_classification_metric_division_by_zero_nan_validaton(scoring):</span>
    <span class="s3">&quot;&quot;&quot;Check that we validate `np.nan` properly for classification metrics. 
 
    With `n_jobs=2` in cross-validation, the `np.nan` used for the singleton will be 
    different in the sub-process and we should not use the `is` operator but 
    `math.isnan`. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/27563 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = datasets.make_classification(random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">classifier = DecisionTreeClassifier(max_depth=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">cross_val_score(classifier</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">scoring=scoring</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">error_score=</span><span class="s5">&quot;raise&quot;</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_cython_arma_innovations_fast.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_cython_arma_innovations_fast.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for fast version of ARMA innovations algorithm 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">assert_equal</span><span class="s2">, </span><span class="s1">assert_allclose</span>

<span class="s2">from </span><span class="s1">statsmodels.tsa.arima_process </span><span class="s2">import </span><span class="s1">arma_acovf</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.innovations </span><span class="s2">import </span><span class="s1">_arma_innovations</span><span class="s2">, </span><span class="s1">arma_innovations</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.sarimax </span><span class="s2">import </span><span class="s1">SARIMAX</span>


<span class="s2">def </span><span class="s1">test_brockwell_davis_ex533():</span>
    <span class="s3"># See Brockwell and Davis (2009) - Time Series Theory and Methods</span>
    <span class="s3"># Example 5.3.3: ARMA(1, 1) process, p.g. 177</span>
    <span class="s1">nobs = </span><span class="s4">10</span>

    <span class="s1">ar_params = np.array([</span><span class="s4">0.2</span><span class="s1">])</span>
    <span class="s1">ma_params = np.array([</span><span class="s4">0.4</span><span class="s1">])</span>
    <span class="s1">sigma2 = </span><span class="s4">8.92</span>
    <span class="s1">p = len(ar_params)</span>
    <span class="s1">q = len(ma_params)</span>
    <span class="s1">m = max(p</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s1">ar = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">-ar_params]</span>
    <span class="s1">ma = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">ma_params]</span>

    <span class="s3"># First, get the autocovariance of the process</span>
    <span class="s1">arma_process_acovf = arma_acovf(ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">nobs=nobs</span><span class="s2">, </span><span class="s1">sigma2=sigma2)</span>
    <span class="s1">unconditional_variance = (</span>
        <span class="s1">sigma2 * (</span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">2 </span><span class="s1">* ar_params[</span><span class="s4">0</span><span class="s1">] * ma_params[</span><span class="s4">0</span><span class="s1">] + ma_params[</span><span class="s4">0</span><span class="s1">]**</span><span class="s4">2</span><span class="s1">) /</span>
        <span class="s1">(</span><span class="s4">1 </span><span class="s1">- ar_params[</span><span class="s4">0</span><span class="s1">]**</span><span class="s4">2</span><span class="s1">))</span>
    <span class="s1">assert_allclose(arma_process_acovf[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">unconditional_variance)</span>

    <span class="s3"># Next, get the autocovariance of the transformed process</span>
    <span class="s3"># Note: as required by {{prefix}}arma_transformed_acovf, we first divide</span>
    <span class="s3"># through by sigma^2</span>
    <span class="s1">arma_process_acovf /= sigma2</span>
    <span class="s1">unconditional_variance /= sigma2</span>
    <span class="s1">transformed_acovf = _arma_innovations.darma_transformed_acovf_fast(</span>
        <span class="s1">ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">arma_process_acovf)</span>
    <span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2 = (np.array(arr) </span><span class="s2">for </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">transformed_acovf)</span>

    <span class="s3"># `acovf` is an m^2 x m^2 matrix, where m = max(p, q)</span>
    <span class="s3"># but it is only valid for the autocovariances of the first m observations</span>
    <span class="s3"># (this means in particular that the block `acovf[m:, m:]` should *not* be</span>
    <span class="s3"># used)</span>
    <span class="s3"># `acovf2` then contains the (time invariant) autocovariance terms for</span>
    <span class="s3"># the observations m + 1, ..., nobs - since the autocovariance is the same</span>
    <span class="s3"># for these terms, to save space we do not construct the autocovariance</span>
    <span class="s3"># matrix as we did for the first m terms. Thus `acovf2[0]` is the variance,</span>
    <span class="s3"># `acovf2[1]` is the first autocovariance, etc.</span>

    <span class="s3"># Test the autocovariance function for observations m + 1, ..., nobs</span>
    <span class="s3"># (it is time invariant here)</span>
    <span class="s1">assert_equal(acovf2.shape</span><span class="s2">, </span><span class="s1">(nobs - m</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">assert_allclose(acovf2[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">1 </span><span class="s1">+ ma_params[</span><span class="s4">0</span><span class="s1">]**</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(acovf2[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ma_params[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">assert_allclose(acovf2[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test the autocovariance function for observations 1, ..., m</span>
    <span class="s3"># (it is time varying here)</span>
    <span class="s1">assert_equal(acovf.shape</span><span class="s2">, </span><span class="s1">(m * </span><span class="s4">2</span><span class="s2">, </span><span class="s1">m * </span><span class="s4">2</span><span class="s1">))</span>

    <span class="s3"># (we need to check `acovf[:m * 2, :m]`, i.e. `acovf[:2, :1])`</span>
    <span class="s1">ix = np.diag_indices_from(acovf)</span>
    <span class="s1">ix_lower = (ix[</span><span class="s4">0</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">ix[</span><span class="s4">1</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3"># acovf[ix] is the diagonal, and we want to check the first m</span>
    <span class="s3"># elements of the diagonal</span>
    <span class="s1">assert_allclose(acovf[ix][:m]</span><span class="s2">, </span><span class="s1">unconditional_variance)</span>

    <span class="s3"># acovf[ix_lower] is the first lower off-diagonal</span>
    <span class="s1">assert_allclose(acovf[ix_lower][:m]</span><span class="s2">, </span><span class="s1">ma_params[</span><span class="s4">0</span><span class="s1">])</span>

    <span class="s3"># Now, check that we compute the moving average coefficients and the</span>
    <span class="s3"># associated variances correctly</span>
    <span class="s1">out = _arma_innovations.darma_innovations_algo_fast(</span>
        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2)</span>
    <span class="s1">theta = np.array(out[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">v = np.array(out[</span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3"># Test v (see eq. 5.3.13)</span>
    <span class="s1">desired_v = np.zeros(nobs)</span>
    <span class="s1">desired_v[</span><span class="s4">0</span><span class="s1">] = unconditional_variance</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">nobs):</span>
        <span class="s1">desired_v[i] = </span><span class="s4">1 </span><span class="s1">+ (</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1 </span><span class="s1">/ desired_v[i - </span><span class="s4">1</span><span class="s1">]) * ma_params[</span><span class="s4">0</span><span class="s1">]**</span><span class="s4">2</span>
    <span class="s1">assert_allclose(v</span><span class="s2">, </span><span class="s1">desired_v)</span>

    <span class="s3"># Test theta (see eq. 5.3.13)</span>
    <span class="s3"># Note that they will have shape (nobs, m + 1) here, not (nobs, nobs - 1)</span>
    <span class="s3"># as in the original (non-fast) version</span>
    <span class="s1">assert_equal(theta.shape</span><span class="s2">, </span><span class="s1">(nobs</span><span class="s2">, </span><span class="s1">m + </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">desired_theta = np.zeros(nobs)</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">nobs):</span>
        <span class="s1">desired_theta[i] = ma_params[</span><span class="s4">0</span><span class="s1">] / desired_v[i - </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">assert_allclose(theta[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">desired_theta)</span>
    <span class="s1">assert_allclose(theta[:</span><span class="s2">, </span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test against Table 5.3.1</span>
    <span class="s1">endog = np.array([</span>
        <span class="s1">-</span><span class="s4">1.1</span><span class="s2">, </span><span class="s4">0.514</span><span class="s2">, </span><span class="s4">0.116</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.845</span><span class="s2">, </span><span class="s4">0.872</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.467</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.977</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.699</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.228</span><span class="s2">,</span>
        <span class="s1">-</span><span class="s4">1.093</span><span class="s1">])</span>
    <span class="s1">u = _arma_innovations.darma_innovations_filter(endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">,</span>
                                                   <span class="s1">theta)</span>

    <span class="s3"># Note: Table 5.3.1 has \hat X_n+1 = -0.5340 for n = 1, but this seems to</span>
    <span class="s3"># be a typo, since equation 5.3.12 gives the form of the prediction</span>
    <span class="s3"># equation as \hat X_n+1 = \phi X_n + \theta_n1 (X_n - \hat X_n)</span>
    <span class="s3"># Then for n = 1 we have:</span>
    <span class="s3"># \hat X_n+1 = 0.2 (-1.1) + (0.2909) (-1.1 - 0) = -0.5399</span>
    <span class="s3"># And for n = 2 if we use what we have computed, then we get:</span>
    <span class="s3"># \hat X_n+1 = 0.2 (0.514) + (0.3833) (0.514 - (-0.54)) = 0.5068</span>
    <span class="s3"># as desired, whereas if we used the book's number for n=1 we would get:</span>
    <span class="s3"># \hat X_n+1 = 0.2 (0.514) + (0.3833) (0.514 - (-0.534)) = 0.5045</span>
    <span class="s3"># which is not what Table 5.3.1 shows.</span>
    <span class="s1">desired_hat = np.array([</span>
        <span class="s4">0</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.540</span><span class="s2">, </span><span class="s4">0.5068</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.1321</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4539</span><span class="s2">, </span><span class="s4">0.7046</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.5620</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.3614</span><span class="s2">,</span>
        <span class="s1">-</span><span class="s4">0.8748</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.3869</span><span class="s1">])</span>
    <span class="s1">desired_u = endog - desired_hat</span>
    <span class="s1">assert_allclose(u</span><span class="s2">, </span><span class="s1">desired_u</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_brockwell_davis_ex534():</span>
    <span class="s3"># See Brockwell and Davis (2009) - Time Series Theory and Methods</span>
    <span class="s3"># Example 5.3.4: ARMA(1, 1) process, p.g. 178</span>
    <span class="s1">nobs = </span><span class="s4">10</span>

    <span class="s1">ar_params = np.array([</span><span class="s4">1</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.24</span><span class="s1">])</span>
    <span class="s1">ma_params = np.array([</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span>
    <span class="s1">sigma2 = </span><span class="s4">1</span>
    <span class="s1">p = len(ar_params)</span>
    <span class="s1">q = len(ma_params)</span>
    <span class="s1">m = max(p</span><span class="s2">, </span><span class="s1">q)</span>

    <span class="s1">ar = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">-ar_params]</span>
    <span class="s1">ma = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">ma_params]</span>

    <span class="s3"># First, get the autocovariance of the process</span>
    <span class="s1">arma_process_acovf = arma_acovf(ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">nobs=nobs</span><span class="s2">, </span><span class="s1">sigma2=sigma2)</span>
    <span class="s1">assert_allclose(arma_process_acovf[:</span><span class="s4">3</span><span class="s1">]</span><span class="s2">,</span>
                    <span class="s1">[</span><span class="s4">7.17133</span><span class="s2">, </span><span class="s4">6.44139</span><span class="s2">, </span><span class="s4">5.06027</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>

    <span class="s3"># Next, get the autocovariance of the transformed process</span>
    <span class="s1">transformed_acovf = _arma_innovations.darma_transformed_acovf_fast(</span>
        <span class="s1">ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">arma_process_acovf)</span>
    <span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2 = (np.array(arr) </span><span class="s2">for </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">transformed_acovf)</span>
    <span class="s3"># See test_brockwell_davis_ex533 for details on acovf vs acovf2</span>

    <span class="s3"># Test acovf</span>
    <span class="s1">assert_equal(acovf.shape</span><span class="s2">, </span><span class="s1">(m * </span><span class="s4">2</span><span class="s2">, </span><span class="s1">m * </span><span class="s4">2</span><span class="s1">))</span>

    <span class="s1">ix = np.diag_indices_from(acovf)</span>
    <span class="s1">ix_lower1 = (ix[</span><span class="s4">0</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">ix[</span><span class="s4">1</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">ix_lower2 = (ix[</span><span class="s4">0</span><span class="s1">][:-</span><span class="s4">2</span><span class="s1">] + </span><span class="s4">2</span><span class="s2">, </span><span class="s1">ix[</span><span class="s4">1</span><span class="s1">][:-</span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">ix_lower3 = (ix[</span><span class="s4">0</span><span class="s1">][:-</span><span class="s4">3</span><span class="s1">] + </span><span class="s4">3</span><span class="s2">, </span><span class="s1">ix[</span><span class="s4">1</span><span class="s1">][:-</span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">ix_lower4 = (ix[</span><span class="s4">0</span><span class="s1">][:-</span><span class="s4">4</span><span class="s1">] + </span><span class="s4">4</span><span class="s2">, </span><span class="s1">ix[</span><span class="s4">1</span><span class="s1">][:-</span><span class="s4">4</span><span class="s1">])</span>

    <span class="s1">assert_allclose(acovf[ix][:m]</span><span class="s2">, </span><span class="s4">7.17133</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>
    <span class="s1">desired = [</span><span class="s4">6.44139</span><span class="s2">, </span><span class="s4">6.44139</span><span class="s2">, </span><span class="s4">0.816</span><span class="s1">]</span>
    <span class="s1">assert_allclose(acovf[ix_lower1][:m]</span><span class="s2">, </span><span class="s1">desired</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(acovf[ix_lower2][</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">5.06027</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(acovf[ix_lower2][</span><span class="s4">1</span><span class="s1">:m]</span><span class="s2">, </span><span class="s4">0.34</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(acovf[ix_lower3][:m]</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(acovf[ix_lower4][:m]</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>

    <span class="s3"># Test acovf2</span>
    <span class="s1">assert_equal(acovf2.shape</span><span class="s2">, </span><span class="s1">(nobs - m</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">assert_allclose(acovf2[:</span><span class="s4">4</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s4">1.21</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.24</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span>
    <span class="s1">assert_allclose(acovf2[</span><span class="s4">4</span><span class="s1">:]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test innovations algorithm output</span>
    <span class="s1">out = _arma_innovations.darma_innovations_algo_fast(</span>
        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2)</span>
    <span class="s1">theta = np.array(out[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">v = np.array(out[</span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3"># Test v (see Table 5.3.2)</span>
    <span class="s1">desired_v = [</span><span class="s4">7.1713</span><span class="s2">, </span><span class="s4">1.3856</span><span class="s2">, </span><span class="s4">1.0057</span><span class="s2">, </span><span class="s4">1.0019</span><span class="s2">, </span><span class="s4">1.0016</span><span class="s2">, </span><span class="s4">1.0005</span><span class="s2">, </span><span class="s4">1.0000</span><span class="s2">,</span>
                 <span class="s4">1.0000</span><span class="s2">, </span><span class="s4">1.0000</span><span class="s2">, </span><span class="s4">1.0000</span><span class="s1">]</span>
    <span class="s1">assert_allclose(v</span><span class="s2">, </span><span class="s1">desired_v</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>

    <span class="s3"># Test theta (see Table 5.3.2)</span>
    <span class="s1">assert_equal(theta.shape</span><span class="s2">, </span><span class="s1">(nobs</span><span class="s2">, </span><span class="s1">m + </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">desired_theta = np.array([</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.8982</span><span class="s2">, </span><span class="s4">1.3685</span><span class="s2">, </span><span class="s4">0.4008</span><span class="s2">, </span><span class="s4">0.3998</span><span class="s2">, </span><span class="s4">0.3992</span><span class="s2">, </span><span class="s4">0.4000</span><span class="s2">, </span><span class="s4">0.4000</span><span class="s2">, </span><span class="s4">0.4000</span><span class="s2">,</span>
         <span class="s4">0.4000</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.7056</span><span class="s2">, </span><span class="s4">0.1806</span><span class="s2">, </span><span class="s4">0.2020</span><span class="s2">, </span><span class="s4">0.1995</span><span class="s2">, </span><span class="s4">0.1997</span><span class="s2">, </span><span class="s4">0.2000</span><span class="s2">, </span><span class="s4">0.2000</span><span class="s2">, </span><span class="s4">0.2000</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.0139</span><span class="s2">, </span><span class="s4">0.0722</span><span class="s2">, </span><span class="s4">0.0994</span><span class="s2">, </span><span class="s4">0.0998</span><span class="s2">, </span><span class="s4">0.0998</span><span class="s2">, </span><span class="s4">0.0999</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">]]).T</span>
    <span class="s1">assert_allclose(theta[:</span><span class="s2">, </span><span class="s1">:m]</span><span class="s2">, </span><span class="s1">desired_theta</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>
    <span class="s1">assert_allclose(theta[:</span><span class="s2">, </span><span class="s1">m:]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test innovations filter output</span>
    <span class="s1">endog = np.array([</span><span class="s4">1.704</span><span class="s2">, </span><span class="s4">0.527</span><span class="s2">, </span><span class="s4">1.041</span><span class="s2">, </span><span class="s4">0.942</span><span class="s2">, </span><span class="s4">0.555</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.002</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.585</span><span class="s2">, </span><span class="s4">0.010</span><span class="s2">,</span>
                      <span class="s1">-</span><span class="s4">0.638</span><span class="s2">, </span><span class="s4">0.525</span><span class="s1">])</span>
    <span class="s1">u = _arma_innovations.darma_innovations_filter(endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">,</span>
                                                   <span class="s1">theta)</span>

    <span class="s1">desired_hat = np.array([</span>
        <span class="s4">0</span><span class="s2">, </span><span class="s4">1.5305</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.1710</span><span class="s2">, </span><span class="s4">1.2428</span><span class="s2">, </span><span class="s4">0.7443</span><span class="s2">, </span><span class="s4">0.3138</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.7293</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.1688</span><span class="s2">,</span>
        <span class="s4">0.3193</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.8731</span><span class="s1">])</span>
    <span class="s1">desired_u = endog - desired_hat</span>
    <span class="s1">assert_allclose(u</span><span class="s2">, </span><span class="s1">desired_u</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;ar_params,ma_params,sigma2&quot;</span><span class="s2">, </span><span class="s1">[</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
<span class="s1">])</span>
<span class="s2">def </span><span class="s1">test_innovations_algo_filter_kalman_filter(ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2):</span>
    <span class="s3"># Test the innovations algorithm and filter against the Kalman filter</span>
    <span class="s3"># for exact likelihood evaluation of an ARMA process</span>

    <span class="s1">ar = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">-ar_params]</span>
    <span class="s1">ma = np.r_[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">ma_params]</span>

    <span class="s1">endog = np.random.normal(size=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">nobs = len(endog)</span>

    <span class="s3"># Innovations algorithm approach</span>
    <span class="s1">arma_process_acovf = arma_acovf(ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">nobs=nobs</span><span class="s2">, </span><span class="s1">sigma2=sigma2)</span>
    <span class="s1">transformed_acov = _arma_innovations.darma_transformed_acovf_fast(</span>
        <span class="s1">ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">arma_process_acovf / sigma2)</span>
    <span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2 = (np.array(mv) </span><span class="s2">for </span><span class="s1">mv </span><span class="s2">in </span><span class="s1">transformed_acov)</span>
    <span class="s1">theta</span><span class="s2">, </span><span class="s1">r = _arma_innovations.darma_innovations_algo_fast(</span>
        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">acovf</span><span class="s2">, </span><span class="s1">acovf2)</span>
    <span class="s1">u = _arma_innovations.darma_innovations_filter(endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">,</span>
                                                   <span class="s1">theta)</span>

    <span class="s1">v = np.array(r) * sigma2</span>
    <span class="s1">u = np.array(u)</span>

    <span class="s1">llf_obs = -</span><span class="s4">0.5 </span><span class="s1">* u**</span><span class="s4">2 </span><span class="s1">/ v - </span><span class="s4">0.5 </span><span class="s1">* np.log(</span><span class="s4">2 </span><span class="s1">* np.pi * v)</span>

    <span class="s3"># Kalman filter apparoach</span>
    <span class="s1">mod = SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(len(ar_params)</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">len(ma_params)))</span>
    <span class="s1">res = mod.filter(np.r_[ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2])</span>

    <span class="s3"># Test that the two approaches are identical</span>
    <span class="s1">assert_allclose(u</span><span class="s2">, </span><span class="s1">res.forecasts_error[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s3"># assert_allclose(theta[1:, 0], res.filter_results.kalman_gain[0, 0, :-1])</span>
    <span class="s1">assert_allclose(llf_obs</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>

    <span class="s3"># Get llf_obs directly</span>
    <span class="s1">llf_obs2 = _arma_innovations.darma_loglikeobs_fast(</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2)</span>

    <span class="s1">assert_allclose(llf_obs2</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;ar_params,ma_params,sigma2&quot;</span><span class="s2">, </span><span class="s1">[</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
<span class="s1">])</span>
<span class="s2">def </span><span class="s1">test_innovations_algo_direct_filter_kalman_filter(ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">,</span>
                                                      <span class="s1">sigma2):</span>
    <span class="s3"># Test the innovations algorithm and filter against the Kalman filter</span>
    <span class="s3"># for exact likelihood evaluation of an ARMA process, using the direct</span>
    <span class="s3"># function.</span>

    <span class="s1">endog = np.random.normal(size=</span><span class="s4">10</span><span class="s1">)</span>

    <span class="s3"># Innovations algorithm approach</span>
    <span class="s1">u</span><span class="s2">, </span><span class="s1">r = arma_innovations.arma_innovations(endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">,</span>
                                             <span class="s1">sigma2)</span>

    <span class="s1">v = np.array(r) * sigma2</span>
    <span class="s1">u = np.array(u)</span>

    <span class="s1">llf_obs = -</span><span class="s4">0.5 </span><span class="s1">* u**</span><span class="s4">2 </span><span class="s1">/ v - </span><span class="s4">0.5 </span><span class="s1">* np.log(</span><span class="s4">2 </span><span class="s1">* np.pi * v)</span>

    <span class="s3"># Kalman filter apparoach</span>
    <span class="s1">mod = SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(len(ar_params)</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">len(ma_params)))</span>
    <span class="s1">res = mod.filter(np.r_[ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2])</span>

    <span class="s3"># Test that the two approaches are identical</span>
    <span class="s1">assert_allclose(u</span><span class="s2">, </span><span class="s1">res.forecasts_error[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s3"># assert_allclose(theta[1:, 0], res.filter_results.kalman_gain[0, 0, :-1])</span>
    <span class="s1">assert_allclose(llf_obs</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>

    <span class="s3"># Get llf_obs directly</span>
    <span class="s1">llf_obs2 = _arma_innovations.darma_loglikeobs_fast(</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2)</span>

    <span class="s1">assert_allclose(llf_obs2</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;ar_params,diff,ma_params,sigma2&quot;</span><span class="s2">, </span><span class="s1">[</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
<span class="s1">])</span>
<span class="s2">def </span><span class="s1">test_integrated_process(ar_params</span><span class="s2">, </span><span class="s1">diff</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2):</span>
    <span class="s3"># Test loglikelihood computation when model has integration</span>

    <span class="s1">nobs = </span><span class="s4">100</span>

    <span class="s1">endog = np.cumsum(np.random.normal(size=nobs))</span>

    <span class="s3"># Innovations algorithm approach</span>
    <span class="s1">llf_obs = arma_innovations.arma_loglikeobs(</span>
        <span class="s1">np.diff(endog</span><span class="s2">, </span><span class="s1">diff)</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2)</span>

    <span class="s3"># Kalman filter apparoach</span>
    <span class="s1">mod = SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(len(ar_params)</span><span class="s2">, </span><span class="s1">diff</span><span class="s2">, </span><span class="s1">len(ma_params))</span><span class="s2">,</span>
                  <span class="s1">simple_differencing=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">res = mod.filter(np.r_[ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2])</span>

    <span class="s3"># Test that the two approaches are identical</span>
    <span class="s1">assert_allclose(llf_obs</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;ar_params,ma_params,sigma2&quot;</span><span class="s2">, </span><span class="s1">[</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.9</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">(np.array([</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.1</span><span class="s1">])</span><span class="s2">, </span><span class="s4">1.123</span><span class="s1">)</span><span class="s2">,</span>
<span class="s1">])</span>
<span class="s2">def </span><span class="s1">test_regression_with_arma_errors(ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2):</span>
    <span class="s3"># Test loglikelihood computation when model has regressors</span>
    <span class="s1">nobs = </span><span class="s4">100</span>

    <span class="s1">eps = np.random.normal(nobs)</span>
    <span class="s1">exog = np.c_[np.ones(nobs)</span><span class="s2">, </span><span class="s1">np.random.uniform(size=nobs)]</span>
    <span class="s1">beta = [</span><span class="s4">5</span><span class="s2">, </span><span class="s1">-</span><span class="s4">0.2</span><span class="s1">]</span>
    <span class="s1">endog = np.dot(exog</span><span class="s2">, </span><span class="s1">beta) + eps</span>

    <span class="s3"># Innovations algorithm approach</span>
    <span class="s1">beta_hat = np.squeeze(np.linalg.pinv(exog).dot(endog))</span>
    <span class="s1">demeaned = endog - np.dot(exog</span><span class="s2">, </span><span class="s1">beta_hat)</span>
    <span class="s1">llf_obs = arma_innovations.arma_loglikeobs(</span>
        <span class="s1">demeaned</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2)</span>

    <span class="s3"># Kalman filter approach</span>
    <span class="s3"># (this works since we impose here that the regression coefficients are</span>
    <span class="s3"># beta_hat - in practice, the MLE estimates will not necessarily match</span>
    <span class="s3"># the OLS estimates beta_hat)</span>
    <span class="s1">mod = SARIMAX(endog</span><span class="s2">, </span><span class="s1">exog=exog</span><span class="s2">, </span><span class="s1">order=(len(ar_params)</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">len(ma_params)))</span>
    <span class="s1">res = mod.filter(np.r_[beta_hat</span><span class="s2">, </span><span class="s1">ar_params</span><span class="s2">, </span><span class="s1">ma_params</span><span class="s2">, </span><span class="s1">sigma2])</span>

    <span class="s3"># Test that the two approaches are identical</span>
    <span class="s1">assert_allclose(llf_obs</span><span class="s2">, </span><span class="s1">res.llf_obs)</span>
</pre>
</body>
</html>
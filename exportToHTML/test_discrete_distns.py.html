<html>
<head>
<title>test_discrete_distns.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_discrete_distns.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">itertools</span>

<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">(betabinom</span><span class="s0">, </span><span class="s1">hypergeom</span><span class="s0">, </span><span class="s1">nhypergeom</span><span class="s0">, </span><span class="s1">bernoulli</span><span class="s0">,</span>
                         <span class="s1">boltzmann</span><span class="s0">, </span><span class="s1">skellam</span><span class="s0">, </span><span class="s1">zipf</span><span class="s0">, </span><span class="s1">zipfian</span><span class="s0">, </span><span class="s1">binom</span><span class="s0">, </span><span class="s1">nbinom</span><span class="s0">,</span>
                         <span class="s1">nchypergeom_fisher</span><span class="s0">, </span><span class="s1">nchypergeom_wallenius</span><span class="s0">, </span><span class="s1">randint)</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_almost_equal</span><span class="s0">, </span><span class="s1">assert_equal</span><span class="s0">, </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">suppress_warnings</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">scipy.special </span><span class="s0">import </span><span class="s1">binom </span><span class="s0">as </span><span class="s1">special_binom</span>
<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">root_scalar</span>
<span class="s0">from </span><span class="s1">scipy.integrate </span><span class="s0">import </span><span class="s1">quad</span>


<span class="s2"># The expected values were computed with Wolfram Alpha, using</span>
<span class="s2"># the expression CDF[HypergeometricDistribution[N, n, M], k].</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">'k, M, n, N, expected, rtol'</span><span class="s0">,</span>
                         <span class="s1">[(</span><span class="s4">3</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">5</span><span class="s0">,</span>
                           <span class="s4">0.9761904761904762</span><span class="s0">, </span><span class="s4">1e-15</span><span class="s1">)</span><span class="s0">,</span>
                          <span class="s1">(</span><span class="s4">107</span><span class="s0">, </span><span class="s4">10000</span><span class="s0">, </span><span class="s4">3000</span><span class="s0">, </span><span class="s4">215</span><span class="s0">,</span>
                           <span class="s4">0.9999999997226765</span><span class="s0">, </span><span class="s4">1e-15</span><span class="s1">)</span><span class="s0">,</span>
                          <span class="s1">(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">10000</span><span class="s0">, </span><span class="s4">3000</span><span class="s0">, </span><span class="s4">215</span><span class="s0">,</span>
                           <span class="s4">2.681682217692179e-21</span><span class="s0">, </span><span class="s4">5e-11</span><span class="s1">)])</span>
<span class="s0">def </span><span class="s1">test_hypergeom_cdf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol):</span>
    <span class="s1">p = hypergeom.cdf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N)</span>
    <span class="s1">assert_allclose(p</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>


<span class="s2"># The expected values were computed with Wolfram Alpha, using</span>
<span class="s2"># the expression SurvivalFunction[HypergeometricDistribution[N, n, M], k].</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">'k, M, n, N, expected, rtol'</span><span class="s0">,</span>
                         <span class="s1">[(</span><span class="s4">25</span><span class="s0">, </span><span class="s4">10000</span><span class="s0">, </span><span class="s4">3000</span><span class="s0">, </span><span class="s4">215</span><span class="s0">,</span>
                           <span class="s4">0.9999999999052958</span><span class="s0">, </span><span class="s4">1e-15</span><span class="s1">)</span><span class="s0">,</span>
                          <span class="s1">(</span><span class="s4">125</span><span class="s0">, </span><span class="s4">10000</span><span class="s0">, </span><span class="s4">3000</span><span class="s0">, </span><span class="s4">215</span><span class="s0">,</span>
                           <span class="s4">1.4416781705752128e-18</span><span class="s0">, </span><span class="s4">5e-11</span><span class="s1">)])</span>
<span class="s0">def </span><span class="s1">test_hypergeom_sf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol):</span>
    <span class="s1">p = hypergeom.sf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N)</span>
    <span class="s1">assert_allclose(p</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>


<span class="s0">def </span><span class="s1">test_hypergeom_logpmf():</span>
    <span class="s2"># symmetries test</span>
    <span class="s2"># f(k,N,K,n) = f(n-k,N,N-K,n) = f(K-k,N,K,N-n) = f(k,N,n,K)</span>
    <span class="s1">k = </span><span class="s4">5</span>
    <span class="s1">N = </span><span class="s4">50</span>
    <span class="s1">K = </span><span class="s4">10</span>
    <span class="s1">n = </span><span class="s4">5</span>
    <span class="s1">logpmf1 = hypergeom.logpmf(k</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">K</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s1">logpmf2 = hypergeom.logpmf(n - k</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">N - K</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s1">logpmf3 = hypergeom.logpmf(K - k</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">K</span><span class="s0">, </span><span class="s1">N - n)</span>
    <span class="s1">logpmf4 = hypergeom.logpmf(k</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">K)</span>
    <span class="s1">assert_almost_equal(logpmf1</span><span class="s0">, </span><span class="s1">logpmf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">12</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(logpmf1</span><span class="s0">, </span><span class="s1">logpmf3</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">12</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(logpmf1</span><span class="s0">, </span><span class="s1">logpmf4</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">12</span><span class="s1">)</span>

    <span class="s2"># test related distribution</span>
    <span class="s2"># Bernoulli distribution if n = 1</span>
    <span class="s1">k = </span><span class="s4">1</span>
    <span class="s1">N = </span><span class="s4">10</span>
    <span class="s1">K = </span><span class="s4">7</span>
    <span class="s1">n = </span><span class="s4">1</span>
    <span class="s1">hypergeom_logpmf = hypergeom.logpmf(k</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">K</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s1">bernoulli_logpmf = bernoulli.logpmf(k</span><span class="s0">, </span><span class="s1">K/N)</span>
    <span class="s1">assert_almost_equal(hypergeom_logpmf</span><span class="s0">, </span><span class="s1">bernoulli_logpmf</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s4">12</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nhypergeom_pmf():</span>
    <span class="s2"># test with hypergeom</span>
    <span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">r = </span><span class="s4">45</span><span class="s0">, </span><span class="s4">13</span><span class="s0">, </span><span class="s4">8</span>
    <span class="s1">k = </span><span class="s4">6</span>
    <span class="s1">NHG = nhypergeom.pmf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">r)</span>
    <span class="s1">HG = hypergeom.pmf(k</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">k+r-</span><span class="s4">1</span><span class="s1">) * (M - n - (r-</span><span class="s4">1</span><span class="s1">)) / (M - (k+r-</span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">assert_allclose(HG</span><span class="s0">, </span><span class="s1">NHG</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nhypergeom_pmfcdf():</span>
    <span class="s2"># test pmf and cdf with arbitrary values.</span>
    <span class="s1">M = </span><span class="s4">8</span>
    <span class="s1">n = </span><span class="s4">3</span>
    <span class="s1">r = </span><span class="s4">4</span>
    <span class="s1">support = np.arange(n+</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">pmf = nhypergeom.pmf(support</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">r)</span>
    <span class="s1">cdf = nhypergeom.cdf(support</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">r)</span>
    <span class="s1">assert_allclose(pmf</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">5</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">5</span><span class="s1">/</span><span class="s4">14</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>
    <span class="s1">assert_allclose(cdf</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">4</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">9</span><span class="s1">/</span><span class="s4">14</span><span class="s0">, </span><span class="s4">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nhypergeom_r0():</span>
    <span class="s2"># test with `r = 0`.</span>
    <span class="s1">M = </span><span class="s4">10</span>
    <span class="s1">n = </span><span class="s4">3</span>
    <span class="s1">r = </span><span class="s4">0</span>
    <span class="s1">pmf = nhypergeom.pmf([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">r)</span>
    <span class="s1">assert_allclose(pmf</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nhypergeom_rvs_shape():</span>
    <span class="s2"># Check that when given a size with more dimensions than the</span>
    <span class="s2"># dimensions of the broadcast parameters, rvs returns an array</span>
    <span class="s2"># with the correct shape.</span>
    <span class="s1">x = nhypergeom.rvs(</span><span class="s4">22</span><span class="s0">, </span><span class="s1">[</span><span class="s4">7</span><span class="s0">, </span><span class="s4">8</span><span class="s0">, </span><span class="s4">9</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">12</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">13</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">size=(</span><span class="s4">5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
    <span class="s0">assert </span><span class="s1">x.shape == (</span><span class="s4">5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nhypergeom_accuracy():</span>
    <span class="s2"># Check that nhypergeom.rvs post-gh-13431 gives the same values as</span>
    <span class="s2"># inverse transform sampling</span>
    <span class="s1">np.random.seed(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">x = nhypergeom.rvs(</span><span class="s4">22</span><span class="s0">, </span><span class="s4">7</span><span class="s0">, </span><span class="s4">11</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">np.random.seed(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">p = np.random.uniform(size=</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">y = nhypergeom.ppf(p</span><span class="s0">, </span><span class="s4">22</span><span class="s0">, </span><span class="s4">7</span><span class="s0">, </span><span class="s4">11</span><span class="s1">)</span>
    <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s0">def </span><span class="s1">test_boltzmann_upper_bound():</span>
    <span class="s1">k = np.arange(-</span><span class="s4">3</span><span class="s0">, </span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">N = </span><span class="s4">1</span>
    <span class="s1">p = boltzmann.pmf(k</span><span class="s0">, </span><span class="s4">0.123</span><span class="s0">, </span><span class="s1">N)</span>
    <span class="s1">expected = k == </span><span class="s4">0</span>
    <span class="s1">assert_equal(p</span><span class="s0">, </span><span class="s1">expected)</span>

    <span class="s1">lam = np.log(</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">N = </span><span class="s4">3</span>
    <span class="s1">p = boltzmann.pmf(k</span><span class="s0">, </span><span class="s1">lam</span><span class="s0">, </span><span class="s1">N)</span>
    <span class="s1">expected = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">/</span><span class="s4">7</span><span class="s0">, </span><span class="s4">2</span><span class="s1">/</span><span class="s4">7</span><span class="s0">, </span><span class="s4">1</span><span class="s1">/</span><span class="s4">7</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">assert_allclose(p</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>

    <span class="s1">c = boltzmann.cdf(k</span><span class="s0">, </span><span class="s1">lam</span><span class="s0">, </span><span class="s1">N)</span>
    <span class="s1">expected = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">/</span><span class="s4">7</span><span class="s0">, </span><span class="s4">6</span><span class="s1">/</span><span class="s4">7</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">assert_allclose(c</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_betabinom_a_and_b_unity():</span>
    <span class="s2"># test limiting case that betabinom(n, 1, 1) is a discrete uniform</span>
    <span class="s2"># distribution from 0 to n</span>
    <span class="s1">n = </span><span class="s4">20</span>
    <span class="s1">k = np.arange(n + </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">p = betabinom(n</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">).pmf(k)</span>
    <span class="s1">expected = np.repeat(</span><span class="s4">1 </span><span class="s1">/ (n + </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">n + </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">'dtypes'</span><span class="s0">, </span><span class="s1">itertools.product(*[(int</span><span class="s0">, </span><span class="s1">float)]*</span><span class="s4">3</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_betabinom_stats_a_and_b_integers_gh18026(dtypes):</span>
    <span class="s2"># gh-18026 reported that `betabinom` kurtosis calculation fails when some</span>
    <span class="s2"># parameters are integers. Check that this is resolved.</span>
    <span class="s1">n_type</span><span class="s0">, </span><span class="s1">a_type</span><span class="s0">, </span><span class="s1">b_type = dtypes</span>
    <span class="s1">n</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">b = n_type(</span><span class="s4">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">a_type(</span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">b_type(</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">assert_allclose(betabinom.stats(n</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'k'</span><span class="s1">)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.6904761904761907</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_betabinom_bernoulli():</span>
    <span class="s2"># test limiting case that betabinom(1, a, b) = bernoulli(a / (a + b))</span>
    <span class="s1">a = </span><span class="s4">2.3</span>
    <span class="s1">b = </span><span class="s4">0.63</span>
    <span class="s1">k = np.arange(</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">p = betabinom(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">b).pmf(k)</span>
    <span class="s1">expected = bernoulli(a / (a + b)).pmf(k)</span>
    <span class="s1">assert_almost_equal(p</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_issue_10317():</span>
    <span class="s1">alpha</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p = </span><span class="s4">0.9</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">1</span>
    <span class="s1">assert_equal(nbinom.interval(confidence=alpha</span><span class="s0">, </span><span class="s1">n=n</span><span class="s0">, </span><span class="s1">p=p)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">test_issue_11134():</span>
    <span class="s1">alpha</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p = </span><span class="s4">0.95</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">0</span>
    <span class="s1">assert_equal(binom.interval(confidence=alpha</span><span class="s0">, </span><span class="s1">n=n</span><span class="s0">, </span><span class="s1">p=p)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">))</span>


<span class="s0">def </span><span class="s1">test_issue_7406():</span>
    <span class="s1">np.random.seed(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_equal(binom.ppf(np.random.rand(</span><span class="s4">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s2"># Also check that endpoints (q=0, q=1) are correct</span>
    <span class="s1">assert_equal(binom.ppf(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(binom.ppf(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_issue_5122():</span>
    <span class="s1">p = </span><span class="s4">0</span>
    <span class="s1">n = np.random.randint(</span><span class="s4">100</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">10</span><span class="s1">)</span>

    <span class="s1">x = </span><span class="s4">0</span>
    <span class="s1">ppf = binom.ppf(x</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span>
    <span class="s1">assert_equal(ppf</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">x = np.linspace(</span><span class="s4">0.01</span><span class="s0">, </span><span class="s4">0.99</span><span class="s0">, </span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">ppf = binom.ppf(x</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span>
    <span class="s1">assert_equal(ppf</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">x = </span><span class="s4">1</span>
    <span class="s1">ppf = binom.ppf(x</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span>
    <span class="s1">assert_equal(ppf</span><span class="s0">, </span><span class="s1">n)</span>


<span class="s0">def </span><span class="s1">test_issue_1603():</span>
    <span class="s1">assert_equal(binom(</span><span class="s4">1000</span><span class="s0">, </span><span class="s1">np.logspace(-</span><span class="s4">3</span><span class="s0">, </span><span class="s1">-</span><span class="s4">100</span><span class="s1">)).ppf(</span><span class="s4">0.01</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_issue_5503():</span>
    <span class="s1">p = </span><span class="s4">0.5</span>
    <span class="s1">x = np.logspace(</span><span class="s4">3</span><span class="s0">, </span><span class="s4">14</span><span class="s0">, </span><span class="s4">12</span><span class="s1">)</span>
    <span class="s1">assert_allclose(binom.cdf(x</span><span class="s0">, </span><span class="s4">2</span><span class="s1">*x</span><span class="s0">, </span><span class="s1">p)</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">'x, n, p, cdf_desired'</span><span class="s0">, </span><span class="s1">[</span>
    <span class="s1">(</span><span class="s4">300</span><span class="s0">, </span><span class="s4">1000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.51559351981411995636</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">3000</span><span class="s0">, </span><span class="s4">10000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.50493298381929698016</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">30000</span><span class="s0">, </span><span class="s4">100000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.50156000591726422864</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">300000</span><span class="s0">, </span><span class="s4">1000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.50049331906666960038</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">3000000</span><span class="s0">, </span><span class="s4">10000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.50015600124585261196</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">30000000</span><span class="s0">, </span><span class="s4">100000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.50004933192735230102</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">30010000</span><span class="s0">, </span><span class="s4">100000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.98545384016570790717</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">29990000</span><span class="s0">, </span><span class="s4">100000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">0.01455017177985268670</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s4">29950000</span><span class="s0">, </span><span class="s4">100000000</span><span class="s0">, </span><span class="s4">3</span><span class="s1">/</span><span class="s4">10</span><span class="s0">, </span><span class="s4">5.02250963487432024943e-28</span><span class="s1">)</span><span class="s0">,</span>
<span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_issue_5503pt2(x</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">cdf_desired):</span>
    <span class="s1">assert_allclose(binom.cdf(x</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span><span class="s0">, </span><span class="s1">cdf_desired)</span>


<span class="s0">def </span><span class="s1">test_issue_5503pt3():</span>
    <span class="s2"># From Wolfram Alpha: CDF[BinomialDistribution[1e12, 1e-12], 2]</span>
    <span class="s1">assert_allclose(binom.cdf(</span><span class="s4">2</span><span class="s0">, </span><span class="s4">10</span><span class="s1">**</span><span class="s4">12</span><span class="s0">, </span><span class="s4">10</span><span class="s1">**-</span><span class="s4">12</span><span class="s1">)</span><span class="s0">, </span><span class="s4">0.91969860292869777384</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_issue_6682():</span>
    <span class="s2"># Reference value from R:</span>
    <span class="s2"># options(digits=16)</span>
    <span class="s2"># print(pnbinom(250, 50, 32/63, lower.tail=FALSE))</span>
    <span class="s1">assert_allclose(nbinom.sf(</span><span class="s4">250</span><span class="s0">, </span><span class="s4">50</span><span class="s0">, </span><span class="s4">32.</span><span class="s1">/</span><span class="s4">63.</span><span class="s1">)</span><span class="s0">, </span><span class="s4">1.460458510976452e-35</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_boost_divide_by_zero_issue_15101():</span>
    <span class="s1">n = </span><span class="s4">1000</span>
    <span class="s1">p = </span><span class="s4">0.01</span>
    <span class="s1">k = </span><span class="s4">996</span>
    <span class="s1">assert_allclose(binom.pmf(k</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span><span class="s0">, </span><span class="s4">0.0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_skellam_gh11474():</span>
    <span class="s2"># test issue reported in gh-11474 caused by `cdfchn`</span>
    <span class="s1">mu = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s4">1000</span><span class="s0">, </span><span class="s4">5000</span><span class="s0">, </span><span class="s4">5050</span><span class="s0">, </span><span class="s4">5100</span><span class="s0">, </span><span class="s4">5250</span><span class="s0">, </span><span class="s4">6000</span><span class="s1">]</span>
    <span class="s1">cdf = skellam.cdf(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">mu</span><span class="s0">, </span><span class="s1">mu)</span>
    <span class="s2"># generated in R</span>
    <span class="s2"># library(skellam)</span>
    <span class="s2"># options(digits = 16)</span>
    <span class="s2"># mu = c(1, 10, 100, 1000, 5000, 5050, 5100, 5250, 6000)</span>
    <span class="s2"># pskellam(0, mu, mu, TRUE)</span>
    <span class="s1">cdf_expected = [</span><span class="s4">0.6542541612768356</span><span class="s0">, </span><span class="s4">0.5448901559424127</span><span class="s0">, </span><span class="s4">0.5141135799745580</span><span class="s0">,</span>
                    <span class="s4">0.5044605891382528</span><span class="s0">, </span><span class="s4">0.5019947363350450</span><span class="s0">, </span><span class="s4">0.5019848365953181</span><span class="s0">,</span>
                    <span class="s4">0.5019750827993392</span><span class="s0">, </span><span class="s4">0.5019466621805060</span><span class="s0">, </span><span class="s4">0.5018209330219539</span><span class="s1">]</span>
    <span class="s1">assert_allclose(cdf</span><span class="s0">, </span><span class="s1">cdf_expected)</span>


<span class="s0">class </span><span class="s1">TestZipfian:</span>
    <span class="s0">def </span><span class="s1">test_zipfian_asymptotic(self):</span>
        <span class="s2"># test limiting case that zipfian(a, n) -&gt; zipf(a) as n-&gt; oo</span>
        <span class="s1">a = </span><span class="s4">6.5</span>
        <span class="s1">N = </span><span class="s4">10000000</span>
        <span class="s1">k = np.arange(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">21</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.pmf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipf.pmf(k</span><span class="s0">, </span><span class="s1">a))</span>
        <span class="s1">assert_allclose(zipfian.cdf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipf.cdf(k</span><span class="s0">, </span><span class="s1">a))</span>
        <span class="s1">assert_allclose(zipfian.sf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipf.sf(k</span><span class="s0">, </span><span class="s1">a))</span>
        <span class="s1">assert_allclose(zipfian.stats(a</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'msvk'</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">zipf.stats(a</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'msvk'</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">test_zipfian_continuity(self):</span>
        <span class="s2"># test that zipfian(0.999999, n) ~ zipfian(1.000001, n)</span>
        <span class="s2"># (a = 1 switches between methods of calculating harmonic sum)</span>
        <span class="s1">alt1</span><span class="s0">, </span><span class="s1">agt1 = </span><span class="s4">0.99999999</span><span class="s0">, </span><span class="s4">1.00000001</span>
        <span class="s1">N = </span><span class="s4">30</span>
        <span class="s1">k = np.arange(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">N + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.pmf(k</span><span class="s0">, </span><span class="s1">alt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipfian.pmf(k</span><span class="s0">, </span><span class="s1">agt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">,</span>
                        <span class="s1">rtol=</span><span class="s4">5e-7</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.cdf(k</span><span class="s0">, </span><span class="s1">alt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipfian.cdf(k</span><span class="s0">, </span><span class="s1">agt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">,</span>
                        <span class="s1">rtol=</span><span class="s4">5e-7</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.sf(k</span><span class="s0">, </span><span class="s1">alt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">, </span><span class="s1">zipfian.sf(k</span><span class="s0">, </span><span class="s1">agt1</span><span class="s0">, </span><span class="s1">N)</span><span class="s0">,</span>
                        <span class="s1">rtol=</span><span class="s4">5e-7</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.stats(alt1</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'msvk'</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">zipfian.stats(agt1</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'msvk'</span><span class="s1">)</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">5e-7</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_zipfian_R(self):</span>
        <span class="s2"># test against R VGAM package</span>
        <span class="s2"># library(VGAM)</span>
        <span class="s2"># k &lt;- c(13, 16,  1,  4,  4,  8, 10, 19,  5,  7)</span>
        <span class="s2"># a &lt;- c(1.56712977, 3.72656295, 5.77665117, 9.12168729, 5.79977172,</span>
        <span class="s2">#        4.92784796, 9.36078764, 4.3739616 , 7.48171872, 4.6824154)</span>
        <span class="s2"># n &lt;- c(70, 80, 48, 65, 83, 89, 50, 30, 20, 20)</span>
        <span class="s2"># pmf &lt;- dzipf(k, N = n, shape = a)</span>
        <span class="s2"># cdf &lt;- pzipf(k, N = n, shape = a)</span>
        <span class="s2"># print(pmf)</span>
        <span class="s2"># print(cdf)</span>
        <span class="s1">np.random.seed(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">k = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">20</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">10</span><span class="s1">)</span>
        <span class="s1">a = np.random.rand(</span><span class="s4">10</span><span class="s1">)*</span><span class="s4">10 </span><span class="s1">+ </span><span class="s4">1</span>
        <span class="s1">n = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s1">size=</span><span class="s4">10</span><span class="s1">)</span>
        <span class="s1">pmf = [</span><span class="s4">8.076972e-03</span><span class="s0">, </span><span class="s4">2.950214e-05</span><span class="s0">, </span><span class="s4">9.799333e-01</span><span class="s0">, </span><span class="s4">3.216601e-06</span><span class="s0">,</span>
               <span class="s4">3.158895e-04</span><span class="s0">, </span><span class="s4">3.412497e-05</span><span class="s0">, </span><span class="s4">4.350472e-10</span><span class="s0">, </span><span class="s4">2.405773e-06</span><span class="s0">,</span>
               <span class="s4">5.860662e-06</span><span class="s0">, </span><span class="s4">1.053948e-04</span><span class="s1">]</span>
        <span class="s1">cdf = [</span><span class="s4">0.8964133</span><span class="s0">, </span><span class="s4">0.9998666</span><span class="s0">, </span><span class="s4">0.9799333</span><span class="s0">, </span><span class="s4">0.9999995</span><span class="s0">, </span><span class="s4">0.9998584</span><span class="s0">,</span>
               <span class="s4">0.9999458</span><span class="s0">, </span><span class="s4">1.0000000</span><span class="s0">, </span><span class="s4">0.9999920</span><span class="s0">, </span><span class="s4">0.9999977</span><span class="s0">, </span><span class="s4">0.9998498</span><span class="s1">]</span>
        <span class="s2"># skip the first point; zipUC is not accurate for low a, n</span>
        <span class="s1">assert_allclose(zipfian.pmf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n)[</span><span class="s4">1</span><span class="s1">:]</span><span class="s0">, </span><span class="s1">pmf[</span><span class="s4">1</span><span class="s1">:]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s1">)</span>
        <span class="s1">assert_allclose(zipfian.cdf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n)[</span><span class="s4">1</span><span class="s1">:]</span><span class="s0">, </span><span class="s1">cdf[</span><span class="s4">1</span><span class="s1">:]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">5e-5</span><span class="s1">)</span>

    <span class="s1">np.random.seed(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">naive_tests = np.vstack((np.logspace(-</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">10</span><span class="s1">)</span><span class="s0">,</span>
                             <span class="s1">np.random.randint(</span><span class="s4">2</span><span class="s0">, </span><span class="s4">40</span><span class="s0">, </span><span class="s4">10</span><span class="s1">))).T</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;a, n&quot;</span><span class="s0">, </span><span class="s1">naive_tests)</span>
    <span class="s0">def </span><span class="s1">test_zipfian_naive(self</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n):</span>
        <span class="s2"># test against bare-bones implementation</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">Hns(n</span><span class="s0">, </span><span class="s1">s):</span>
            <span class="s5">&quot;&quot;&quot;Naive implementation of harmonic sum&quot;&quot;&quot;</span>
            <span class="s0">return </span><span class="s1">(</span><span class="s4">1</span><span class="s1">/np.arange(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">n+</span><span class="s4">1</span><span class="s1">)**s).sum()</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">pzip(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n):</span>
            <span class="s5">&quot;&quot;&quot;Naive implementation of zipfian pmf&quot;&quot;&quot;</span>
            <span class="s0">if </span><span class="s1">k &lt; </span><span class="s4">1 </span><span class="s0">or </span><span class="s1">k &gt; n:</span>
                <span class="s0">return </span><span class="s4">0.</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s4">1 </span><span class="s1">/ k**a / Hns(n</span><span class="s0">, </span><span class="s1">a)</span>

        <span class="s1">k = np.arange(n+</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">pmf = pzip(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n)</span>
        <span class="s1">cdf = np.cumsum(pmf)</span>
        <span class="s1">mean = np.average(k</span><span class="s0">, </span><span class="s1">weights=pmf)</span>
        <span class="s1">var = np.average((k - mean)**</span><span class="s4">2</span><span class="s0">, </span><span class="s1">weights=pmf)</span>
        <span class="s1">std = var**</span><span class="s4">0.5</span>
        <span class="s1">skew = np.average(((k-mean)/std)**</span><span class="s4">3</span><span class="s0">, </span><span class="s1">weights=pmf)</span>
        <span class="s1">kurtosis = np.average(((k-mean)/std)**</span><span class="s4">4</span><span class="s0">, </span><span class="s1">weights=pmf) - </span><span class="s4">3</span>
        <span class="s1">assert_allclose(zipfian.pmf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">, </span><span class="s1">pmf)</span>
        <span class="s1">assert_allclose(zipfian.cdf(k</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">, </span><span class="s1">cdf)</span>
        <span class="s1">assert_allclose(zipfian.stats(a</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">&quot;mvsk&quot;</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">[mean</span><span class="s0">, </span><span class="s1">var</span><span class="s0">, </span><span class="s1">skew</span><span class="s0">, </span><span class="s1">kurtosis])</span>


<span class="s0">class </span><span class="s1">TestNCH():</span>
    <span class="s1">np.random.seed(</span><span class="s4">2</span><span class="s1">)  </span><span class="s2"># seeds 0 and 1 had some xl = xu; randint failed</span>
    <span class="s1">shape = (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">max_m = </span><span class="s4">100</span>
    <span class="s1">m1 = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">max_m</span><span class="s0">, </span><span class="s1">size=shape)    </span><span class="s2"># red balls</span>
    <span class="s1">m2 = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">max_m</span><span class="s0">, </span><span class="s1">size=shape)    </span><span class="s2"># white balls</span>
    <span class="s1">N = m1 + m2                                     </span><span class="s2"># total balls</span>
    <span class="s1">n = randint.rvs(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">size=N.shape)             </span><span class="s2"># number of draws</span>
    <span class="s1">xl = np.maximum(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">n-m2)                        </span><span class="s2"># lower bound of support</span>
    <span class="s1">xu = np.minimum(n</span><span class="s0">, </span><span class="s1">m1)                          </span><span class="s2"># upper bound of support</span>
    <span class="s1">x = randint.rvs(xl</span><span class="s0">, </span><span class="s1">xu</span><span class="s0">, </span><span class="s1">size=xl.shape)</span>
    <span class="s1">odds = np.random.rand(*x.shape)*</span><span class="s4">2</span>

    <span class="s2"># test output is more readable when function names (strings) are passed</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s3">'dist_name'</span><span class="s0">,</span>
                             <span class="s1">[</span><span class="s3">'nchypergeom_fisher'</span><span class="s0">, </span><span class="s3">'nchypergeom_wallenius'</span><span class="s1">])</span>
    <span class="s0">def </span><span class="s1">test_nch_hypergeom(self</span><span class="s0">, </span><span class="s1">dist_name):</span>
        <span class="s2"># Both noncentral hypergeometric distributions reduce to the</span>
        <span class="s2"># hypergeometric distribution when odds = 1</span>
        <span class="s1">dists = {</span><span class="s3">'nchypergeom_fisher'</span><span class="s1">: nchypergeom_fisher</span><span class="s0">,</span>
                 <span class="s3">'nchypergeom_wallenius'</span><span class="s1">: nchypergeom_wallenius}</span>
        <span class="s1">dist = dists[dist_name]</span>
        <span class="s1">x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n = self.x</span><span class="s0">, </span><span class="s1">self.N</span><span class="s0">, </span><span class="s1">self.m1</span><span class="s0">, </span><span class="s1">self.n</span>
        <span class="s1">assert_allclose(dist.pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds=</span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">hypergeom.pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n))</span>

    <span class="s0">def </span><span class="s1">test_nchypergeom_fisher_naive(self):</span>
        <span class="s2"># test against a very simple implementation</span>
        <span class="s1">x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds = self.x</span><span class="s0">, </span><span class="s1">self.N</span><span class="s0">, </span><span class="s1">self.m1</span><span class="s0">, </span><span class="s1">self.n</span><span class="s0">, </span><span class="s1">self.odds</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">pmf_mean_var(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w):</span>
            <span class="s2"># simple implementation of nchypergeom_fisher pmf</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">xl = np.maximum(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">n-m2)</span>
            <span class="s1">xu = np.minimum(n</span><span class="s0">, </span><span class="s1">m1)</span>

            <span class="s0">def </span><span class="s1">f(x):</span>
                <span class="s1">t1 = special_binom(m1</span><span class="s0">, </span><span class="s1">x)</span>
                <span class="s1">t2 = special_binom(m2</span><span class="s0">, </span><span class="s1">n - x)</span>
                <span class="s0">return </span><span class="s1">t1 * t2 * w**x</span>

            <span class="s0">def </span><span class="s1">P(k):</span>
                <span class="s0">return </span><span class="s1">sum(f(y)*y**k </span><span class="s0">for </span><span class="s1">y </span><span class="s0">in </span><span class="s1">range(xl</span><span class="s0">, </span><span class="s1">xu + </span><span class="s4">1</span><span class="s1">))</span>

            <span class="s1">P0 = P(</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">P1 = P(</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">P2 = P(</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">pmf = f(x) / P0</span>
            <span class="s1">mean = P1 / P0</span>
            <span class="s1">var = P2 / P0 - (P1 / P0)**</span><span class="s4">2</span>
            <span class="s0">return </span><span class="s1">pmf</span><span class="s0">, </span><span class="s1">mean</span><span class="s0">, </span><span class="s1">var</span>

        <span class="s1">pmf</span><span class="s0">, </span><span class="s1">mean</span><span class="s0">, </span><span class="s1">var = pmf_mean_var(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds)</span>
        <span class="s1">assert_allclose(nchypergeom_fisher.pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds)</span><span class="s0">, </span><span class="s1">pmf)</span>
        <span class="s1">assert_allclose(nchypergeom_fisher.stats(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'m'</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">mean)</span>
        <span class="s1">assert_allclose(nchypergeom_fisher.stats(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">odds</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'v'</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">var)</span>

    <span class="s0">def </span><span class="s1">test_nchypergeom_wallenius_naive(self):</span>
        <span class="s2"># test against a very simple implementation</span>

        <span class="s1">np.random.seed(</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">shape = (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">max_m = </span><span class="s4">100</span>
        <span class="s1">m1 = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">max_m</span><span class="s0">, </span><span class="s1">size=shape)</span>
        <span class="s1">m2 = np.random.randint(</span><span class="s4">1</span><span class="s0">, </span><span class="s1">max_m</span><span class="s0">, </span><span class="s1">size=shape)</span>
        <span class="s1">N = m1 + m2</span>
        <span class="s1">n = randint.rvs(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">size=N.shape)</span>
        <span class="s1">xl = np.maximum(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">n-m2)</span>
        <span class="s1">xu = np.minimum(n</span><span class="s0">, </span><span class="s1">m1)</span>
        <span class="s1">x = randint.rvs(xl</span><span class="s0">, </span><span class="s1">xu</span><span class="s0">, </span><span class="s1">size=xl.shape)</span>
        <span class="s1">w = np.random.rand(*x.shape)*</span><span class="s4">2</span>

        <span class="s0">def </span><span class="s1">support(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w):</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">xl = np.maximum(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">n-m2)</span>
            <span class="s1">xu = np.minimum(n</span><span class="s0">, </span><span class="s1">m1)</span>
            <span class="s0">return </span><span class="s1">xl</span><span class="s0">, </span><span class="s1">xu</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">mean(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w):</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">xl</span><span class="s0">, </span><span class="s1">xu = support(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>

            <span class="s0">def </span><span class="s1">fun(u):</span>
                <span class="s0">return </span><span class="s1">u/m1 + (</span><span class="s4">1 </span><span class="s1">- (n-u)/m2)**w - </span><span class="s4">1</span>

            <span class="s0">return </span><span class="s1">root_scalar(fun</span><span class="s0">, </span><span class="s1">bracket=(xl</span><span class="s0">, </span><span class="s1">xu)).root</span>

        <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(RuntimeWarning</span><span class="s0">,</span>
                       <span class="s1">message=</span><span class="s3">&quot;invalid value encountered in mean&quot;</span><span class="s1">)</span>
            <span class="s1">assert_allclose(nchypergeom_wallenius.mean(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span><span class="s0">,</span>
                            <span class="s1">mean(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">2e-2</span><span class="s1">)</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">variance(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w):</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">u = mean(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>
            <span class="s1">a = u * (m1 - u)</span>
            <span class="s1">b = (n-u)*(u + m2 - n)</span>
            <span class="s0">return </span><span class="s1">N*a*b / ((N-</span><span class="s4">1</span><span class="s1">) * (m1*b + m2*a))</span>

        <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(RuntimeWarning</span><span class="s0">,</span>
                       <span class="s1">message=</span><span class="s3">&quot;invalid value encountered in mean&quot;</span><span class="s1">)</span>
            <span class="s1">assert_allclose(</span>
                <span class="s1">nchypergeom_wallenius.stats(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w</span><span class="s0">, </span><span class="s1">moments=</span><span class="s3">'v'</span><span class="s1">)</span><span class="s0">,</span>
                <span class="s1">variance(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span><span class="s0">,</span>
                <span class="s1">rtol=</span><span class="s4">5e-2</span>
            <span class="s1">)</span>

        <span class="s1">@np.vectorize</span>
        <span class="s0">def </span><span class="s1">pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w):</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">xl</span><span class="s0">, </span><span class="s1">xu = support(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>

            <span class="s0">def </span><span class="s1">integrand(t):</span>
                <span class="s1">D = w*(m1 - x) + (m2 - (n-x))</span>
                <span class="s1">res = (</span><span class="s4">1</span><span class="s1">-t**(w/D))**x * (</span><span class="s4">1</span><span class="s1">-t**(</span><span class="s4">1</span><span class="s1">/D))**(n-x)</span>
                <span class="s0">return </span><span class="s1">res</span>

            <span class="s0">def </span><span class="s1">f(x):</span>
                <span class="s1">t1 = special_binom(m1</span><span class="s0">, </span><span class="s1">x)</span>
                <span class="s1">t2 = special_binom(m2</span><span class="s0">, </span><span class="s1">n - x)</span>
                <span class="s1">the_integral = quad(integrand</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">,</span>
                                    <span class="s1">epsrel=</span><span class="s4">1e-16</span><span class="s0">, </span><span class="s1">epsabs=</span><span class="s4">1e-16</span><span class="s1">)</span>
                <span class="s0">return </span><span class="s1">t1 * t2 * the_integral[</span><span class="s4">0</span><span class="s1">]</span>

            <span class="s0">return </span><span class="s1">f(x)</span>

        <span class="s1">pmf0 = pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>
        <span class="s1">pmf1 = nchypergeom_wallenius.pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>

        <span class="s1">atol</span><span class="s0">, </span><span class="s1">rtol = </span><span class="s4">1e-6</span><span class="s0">, </span><span class="s4">1e-6</span>
        <span class="s1">i = np.abs(pmf1 - pmf0) &lt; atol + rtol*np.abs(pmf0)</span>
        <span class="s0">assert </span><span class="s1">i.sum() &gt; np.prod(shape) / </span><span class="s4">2  </span><span class="s2"># works at least half the time</span>

        <span class="s2"># for those that fail, discredit the naive implementation</span>
        <span class="s0">for </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w </span><span class="s0">in </span><span class="s1">zip(N[~i]</span><span class="s0">, </span><span class="s1">m1[~i]</span><span class="s0">, </span><span class="s1">n[~i]</span><span class="s0">, </span><span class="s1">w[~i]):</span>
            <span class="s2"># get the support</span>
            <span class="s1">m2 = N - m1</span>
            <span class="s1">xl</span><span class="s0">, </span><span class="s1">xu = support(N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w)</span>
            <span class="s1">x = np.arange(xl</span><span class="s0">, </span><span class="s1">xu + </span><span class="s4">1</span><span class="s1">)</span>

            <span class="s2"># calculate sum of pmf over the support</span>
            <span class="s2"># the naive implementation is very wrong in these cases</span>
            <span class="s0">assert </span><span class="s1">pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w).sum() &lt; </span><span class="s4">.5</span>
            <span class="s1">assert_allclose(nchypergeom_wallenius.pmf(x</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">m1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">w).sum()</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_wallenius_against_mpmath(self):</span>
        <span class="s2"># precompute data with mpmath since naive implementation above</span>
        <span class="s2"># is not reliable. See source code in gh-13330.</span>
        <span class="s1">M = </span><span class="s4">50</span>
        <span class="s1">n = </span><span class="s4">30</span>
        <span class="s1">N = </span><span class="s4">20</span>
        <span class="s1">odds = </span><span class="s4">2.25</span>
        <span class="s2"># Expected results, computed with mpmath.</span>
        <span class="s1">sup = np.arange(</span><span class="s4">21</span><span class="s1">)</span>
        <span class="s1">pmf = np.array([</span><span class="s4">3.699003068656875e-20</span><span class="s0">,</span>
                        <span class="s4">5.89398584245431e-17</span><span class="s0">,</span>
                        <span class="s4">2.1594437742911123e-14</span><span class="s0">,</span>
                        <span class="s4">3.221458044649955e-12</span><span class="s0">,</span>
                        <span class="s4">2.4658279241205077e-10</span><span class="s0">,</span>
                        <span class="s4">1.0965862603981212e-08</span><span class="s0">,</span>
                        <span class="s4">3.057890479665704e-07</span><span class="s0">,</span>
                        <span class="s4">5.622818831643761e-06</span><span class="s0">,</span>
                        <span class="s4">7.056482841531681e-05</span><span class="s0">,</span>
                        <span class="s4">0.000618899425358671</span><span class="s0">,</span>
                        <span class="s4">0.003854172932571669</span><span class="s0">,</span>
                        <span class="s4">0.01720592676256026</span><span class="s0">,</span>
                        <span class="s4">0.05528844897093792</span><span class="s0">,</span>
                        <span class="s4">0.12772363313574242</span><span class="s0">,</span>
                        <span class="s4">0.21065898367825722</span><span class="s0">,</span>
                        <span class="s4">0.24465958845359234</span><span class="s0">,</span>
                        <span class="s4">0.1955114898110033</span><span class="s0">,</span>
                        <span class="s4">0.10355390084949237</span><span class="s0">,</span>
                        <span class="s4">0.03414490375225675</span><span class="s0">,</span>
                        <span class="s4">0.006231989845775931</span><span class="s0">,</span>
                        <span class="s4">0.0004715577304677075</span><span class="s1">])</span>
        <span class="s1">mean = </span><span class="s4">14.808018384813426</span>
        <span class="s1">var = </span><span class="s4">2.6085975877923717</span>

        <span class="s2"># nchypergeom_wallenius.pmf returns 0 for pmf(0) and pmf(1), and pmf(2)</span>
        <span class="s2"># has only three digits of accuracy (~ 2.1511e-14).</span>
        <span class="s1">assert_allclose(nchypergeom_wallenius.pmf(sup</span><span class="s0">, </span><span class="s1">M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">odds)</span><span class="s0">, </span><span class="s1">pmf</span><span class="s0">,</span>
                        <span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-13</span><span class="s1">)</span>
        <span class="s1">assert_allclose(nchypergeom_wallenius.mean(M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">odds)</span><span class="s0">,</span>
                        <span class="s1">mean</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-13</span><span class="s1">)</span>
        <span class="s1">assert_allclose(nchypergeom_wallenius.var(M</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">N</span><span class="s0">, </span><span class="s1">odds)</span><span class="s0">,</span>
                        <span class="s1">var</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s4">1e-11</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s3">'dist_name'</span><span class="s0">,</span>
                             <span class="s1">[</span><span class="s3">'nchypergeom_fisher'</span><span class="s0">, </span><span class="s3">'nchypergeom_wallenius'</span><span class="s1">])</span>
    <span class="s0">def </span><span class="s1">test_rvs_shape(self</span><span class="s0">, </span><span class="s1">dist_name):</span>
        <span class="s2"># Check that when given a size with more dimensions than the</span>
        <span class="s2"># dimensions of the broadcast parameters, rvs returns an array</span>
        <span class="s2"># with the correct shape.</span>
        <span class="s1">dists = {</span><span class="s3">'nchypergeom_fisher'</span><span class="s1">: nchypergeom_fisher</span><span class="s0">,</span>
                 <span class="s3">'nchypergeom_wallenius'</span><span class="s1">: nchypergeom_wallenius}</span>
        <span class="s1">dist = dists[dist_name]</span>
        <span class="s1">x = dist.rvs(</span><span class="s4">50</span><span class="s0">, </span><span class="s4">30</span><span class="s0">, </span><span class="s1">[[</span><span class="s4">10</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">20</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">size=(</span><span class="s4">5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span>
        <span class="s0">assert </span><span class="s1">x.shape == (</span><span class="s4">5</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;mu, q, expected&quot;</span><span class="s0">,</span>
                         <span class="s1">[[</span><span class="s4">10</span><span class="s0">, </span><span class="s4">120</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1.240089881791596e-38</span><span class="s1">]</span><span class="s0">,</span>
                          <span class="s1">[</span><span class="s4">1500</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">86.61466680572661</span><span class="s1">]])</span>
<span class="s0">def </span><span class="s1">test_nbinom_11465(mu</span><span class="s0">, </span><span class="s1">q</span><span class="s0">, </span><span class="s1">expected):</span>
    <span class="s2"># test nbinom.logcdf at extreme tails</span>
    <span class="s1">size = </span><span class="s4">20</span>
    <span class="s1">n</span><span class="s0">, </span><span class="s1">p = size</span><span class="s0">, </span><span class="s1">size/(size+mu)</span>
    <span class="s2"># In R:</span>
    <span class="s2"># options(digits=16)</span>
    <span class="s2"># pnbinom(mu=10, size=20, q=120, log.p=TRUE)</span>
    <span class="s1">assert_allclose(nbinom.logcdf(q</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s0">def </span><span class="s1">test_gh_17146():</span>
    <span class="s2"># Check that discrete distributions return PMF of zero at non-integral x.</span>
    <span class="s2"># See gh-17146.</span>
    <span class="s1">x = np.linspace(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">11</span><span class="s1">)</span>
    <span class="s1">p = </span><span class="s4">0.8</span>
    <span class="s1">pmf = bernoulli(p).pmf(x)</span>
    <span class="s1">i = (x % </span><span class="s4">1 </span><span class="s1">== </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(pmf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">p)</span>
    <span class="s1">assert_allclose(pmf[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">1</span><span class="s1">-p)</span>
    <span class="s1">assert_equal(pmf[~i]</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>covtype.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
covtype.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Mon Aug 04 08:00:16 2014 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">from </span><span class="s1">statsmodels.compat.python </span><span class="s3">import </span><span class="s1">lzip</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s1">descriptions = {</span>
    <span class="s4">'HC0'</span><span class="s1">: </span><span class="s4">'Standard Errors are heteroscedasticity robust (HC0)'</span><span class="s3">,</span>
    <span class="s4">'HC1'</span><span class="s1">: </span><span class="s4">'Standard Errors are heteroscedasticity robust (HC1)'</span><span class="s3">,</span>
    <span class="s4">'HC2'</span><span class="s1">: </span><span class="s4">'Standard Errors are heteroscedasticity robust (HC2)'</span><span class="s3">,</span>
    <span class="s4">'HC3'</span><span class="s1">: </span><span class="s4">'Standard Errors are heteroscedasticity robust (HC3)'</span><span class="s3">,</span>
    <span class="s4">'HAC'</span><span class="s1">: </span><span class="s4">'Standard Errors are heteroscedasticity and autocorrelation '</span>
           <span class="s4">'robust (HAC) using {maxlags} lags and '</span>
           <span class="s4">'{correction} small sample correction'</span><span class="s3">,</span>
    <span class="s4">'fixed_scale'</span><span class="s1">: </span><span class="s4">'Standard Errors are based on fixed scale'</span><span class="s3">,</span>
    <span class="s4">'cluster'</span><span class="s1">: </span><span class="s4">'Standard Errors are robust to cluster correlation (cluster)'</span><span class="s3">,</span>
    <span class="s4">'HAC-Panel'</span><span class="s1">: </span><span class="s4">'Standard Errors are robust to '</span>
                 <span class="s4">'cluster correlation (HAC-Panel)'</span><span class="s3">,</span>
    <span class="s4">'HAC-Groupsum'</span><span class="s1">: </span><span class="s4">'Driscoll and Kraay Standard Errors are robust to '</span>
                    <span class="s4">'cluster correlation (HAC-Groupsum)'</span><span class="s3">,</span>
    <span class="s4">'none'</span><span class="s1">: </span><span class="s4">'Covariance matrix not calculated.'</span><span class="s3">,</span>
    <span class="s4">'approx'</span><span class="s1">: </span><span class="s4">'Covariance matrix calculated using numerical ({approx_type}) '</span>
              <span class="s4">'differentiation.'</span><span class="s3">,</span>
    <span class="s4">'OPG'</span><span class="s1">: </span><span class="s4">'Covariance matrix calculated using the outer product of '</span>
           <span class="s4">'gradients ({approx_type}).'</span><span class="s3">,</span>
    <span class="s4">'OIM'</span><span class="s1">: </span><span class="s4">'Covariance matrix calculated using the observed information '</span>
           <span class="s4">'matrix ({approx_type}) described in Harvey (1989).'</span><span class="s3">,</span>
    <span class="s4">'robust'</span><span class="s1">: </span><span class="s4">'Quasi-maximum likelihood covariance matrix used for '</span>
              <span class="s4">'robustness to some misspecifications; calculated using '</span>
              <span class="s4">'numerical ({approx_type}) differentiation.'</span><span class="s3">,</span>
    <span class="s4">'robust-OIM'</span><span class="s1">: </span><span class="s4">'Quasi-maximum likelihood covariance matrix used for '</span>
                  <span class="s4">'robustness to some misspecifications; calculated using the '</span>
                  <span class="s4">'observed information matrix ({approx_type}) described in '</span>
                  <span class="s4">'Harvey (1989).'</span><span class="s3">,</span>
    <span class="s4">'robust-approx'</span><span class="s1">: </span><span class="s4">'Quasi-maximum likelihood covariance matrix used for '</span>
                     <span class="s4">'robustness to some misspecifications; calculated using '</span>
                     <span class="s4">'numerical ({approx_type}) differentiation.'</span><span class="s3">,</span>
<span class="s1">}</span>


<span class="s3">def </span><span class="s1">normalize_cov_type(cov_type):</span>
    <span class="s2">&quot;&quot;&quot; 
    Normalize the cov_type string to a canonical version 
 
    Parameters 
    ---------- 
    cov_type : str 
 
    Returns 
    ------- 
    normalized_cov_type : str 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">cov_type == </span><span class="s4">'nw-panel'</span><span class="s1">:</span>
        <span class="s1">cov_type = </span><span class="s4">'hac-panel'</span>
    <span class="s3">if </span><span class="s1">cov_type == </span><span class="s4">'nw-groupsum'</span><span class="s1">:</span>
        <span class="s1">cov_type = </span><span class="s4">'hac-groupsum'</span>
    <span class="s3">return </span><span class="s1">cov_type</span>


<span class="s3">def </span><span class="s1">get_robustcov_results(self</span><span class="s3">, </span><span class="s1">cov_type=</span><span class="s4">'HC1'</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">None, </span><span class="s1">**kwds):</span>
    <span class="s2">&quot;&quot;&quot;create new results instance with robust covariance as default 
 
    Parameters 
    ---------- 
    cov_type : str 
        the type of robust sandwich estimator to use. see Notes below 
    use_t : bool 
        If true, then the t distribution is used for inference. 
        If false, then the normal distribution is used. 
    kwds : depends on cov_type 
        Required or optional arguments for robust covariance calculation. 
        see Notes below 
 
    Returns 
    ------- 
    results : results instance 
        This method creates a new results instance with the requested 
        robust covariance as the default covariance of the parameters. 
        Inferential statistics like p-values and hypothesis tests will be 
        based on this covariance matrix. 
 
    Notes 
    ----- 
    Warning: Some of the options and defaults in cov_kwds may be changed in a 
    future version. 
 
    The covariance keywords provide an option 'scaling_factor' to adjust the 
    scaling of the covariance matrix, that is the covariance is multiplied by 
    this factor if it is given and is not `None`. This allows the user to 
    adjust the scaling of the covariance matrix to match other statistical 
    packages. 
    For example, `scaling_factor=(nobs - 1.) / (nobs - k_params)` provides a 
    correction so that the robust covariance matrices match those of Stata in 
    some models like GLM and discrete Models. 
 
    The following covariance types and required or optional arguments are 
    currently available: 
 
    - 'HC0', 'HC1', 'HC2', 'HC3': heteroscedasticity robust covariance 
 
      - no keyword arguments 
 
    - 'HAC': heteroskedasticity-autocorrelation robust covariance 
 
      ``maxlags`` :  integer, required 
        number of lags to use 
 
      ``kernel`` : {callable, str}, optional 
        kernels currently available kernels are ['bartlett', 'uniform'], 
        default is Bartlett 
 
      ``use_correction``: bool, optional 
        If true, use small sample correction 
 
    - 'cluster': clustered covariance estimator 
 
      ``groups`` : array_like[int], required : 
        Integer-valued index of clusters or groups. 
 
      ``use_correction``: bool, optional 
        If True the sandwich covariance is calculated with a small 
        sample correction. 
        If False the sandwich covariance is calculated without 
        small sample correction. 
 
      ``df_correction``: bool, optional 
        If True (default), then the degrees of freedom for the 
        inferential statistics and hypothesis tests, such as 
        pvalues, f_pvalue, conf_int, and t_test and f_test, are 
        based on the number of groups minus one instead of the 
        total number of observations minus the number of explanatory 
        variables. `df_resid` of the results instance is also 
        adjusted. When `use_t` is also True, then pvalues are 
        computed using the Student's t distribution using the 
        corrected values. These may differ substantially from 
        p-values based on the normal is the number of groups is 
        small. 
        If False, then `df_resid` of the results instance is not 
        adjusted. 
 
 
    - 'hac-groupsum': Driscoll and Kraay, heteroscedasticity and 
      autocorrelation robust covariance for panel data 
      # TODO: more options needed here 
 
      ``time`` : array_like, required 
        index of time periods 
      ``maxlags`` : integer, required 
        number of lags to use 
      ``kernel`` : {callable, str}, optional 
        The available kernels are ['bartlett', 'uniform']. The default is 
        Bartlett. 
      ``use_correction`` : {False, 'hac', 'cluster'}, optional 
        If False the the sandwich covariance is calculated without small 
        sample correction. If `use_correction = 'cluster'` (default), 
        then the same small sample correction as in the case of 
        `covtype='cluster'` is used. 
      ``df_correction`` : bool, optional 
        The adjustment to df_resid, see cov_type 'cluster' above 
 
    - 'hac-panel': heteroscedasticity and autocorrelation robust standard 
      errors in panel data. The data needs to be sorted in this case, the 
      time series for each panel unit or cluster need to be stacked. The 
      membership to a time series of an individual or group can be either 
      specified by group indicators or by increasing time periods. One of 
      ``groups`` or ``time`` is required. # TODO: we need more options here 
 
      ``groups`` : array_like[int] 
        indicator for groups 
      ``time`` : array_like[int] 
        index of time periods 
      ``maxlags`` : int, required 
        number of lags to use 
      ``kernel`` : {callable, str}, optional 
        Available kernels are ['bartlett', 'uniform'], default 
        is Bartlett 
      ``use_correction`` : {False, 'hac', 'cluster'}, optional 
        If False the sandwich covariance is calculated without 
        small sample correction. 
      ``df_correction`` : bool, optional 
        Adjustment to df_resid, see cov_type 'cluster' above 
 
    **Reminder**: ``use_correction`` in &quot;hac-groupsum&quot; and &quot;hac-panel&quot; is 
    not bool, needs to be in {False, 'hac', 'cluster'}. 
 
    .. todo:: Currently there is no check for extra or misspelled keywords, 
         except in the case of cov_type `HCx` 
    &quot;&quot;&quot;</span>

    <span class="s3">import </span><span class="s1">statsmodels.stats.sandwich_covariance </span><span class="s3">as </span><span class="s1">sw</span>

    <span class="s1">cov_type = normalize_cov_type(cov_type)</span>

    <span class="s3">if </span><span class="s4">'kernel' </span><span class="s3">in </span><span class="s1">kwds:</span>
        <span class="s1">kwds[</span><span class="s4">'weights_func'</span><span class="s1">] = kwds.pop(</span><span class="s4">'kernel'</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s4">'weights_func' </span><span class="s3">in </span><span class="s1">kwds </span><span class="s3">and not </span><span class="s1">callable(kwds[</span><span class="s4">'weights_func'</span><span class="s1">]):</span>
        <span class="s1">kwds[</span><span class="s4">'weights_func'</span><span class="s1">] = sw.kernel_dict[kwds[</span><span class="s4">'weights_func'</span><span class="s1">]]</span>

    <span class="s0"># pop because HCx raises if any kwds</span>
    <span class="s1">sc_factor = kwds.pop(</span><span class="s4">'scaling_factor'</span><span class="s3">, None</span><span class="s1">)</span>

    <span class="s0"># TODO: make separate function that returns a robust cov plus info</span>
    <span class="s1">use_self = kwds.pop(</span><span class="s4">'use_self'</span><span class="s3">, False</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">use_self:</span>
        <span class="s1">res = self</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s0"># this does not work for most models, use raw instance instead from fit</span>
        <span class="s1">res = self.__class__(self.model</span><span class="s3">, </span><span class="s1">self.params</span><span class="s3">,</span>
                   <span class="s1">normalized_cov_params=self.normalized_cov_params</span><span class="s3">,</span>
                   <span class="s1">scale=self.scale)</span>

    <span class="s1">res.cov_type = cov_type</span>
    <span class="s0"># use_t might already be defined by the class, and already set</span>
    <span class="s3">if </span><span class="s1">use_t </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">use_t = self.use_t</span>
    <span class="s1">res.cov_kwds = {</span><span class="s4">'use_t'</span><span class="s1">:use_t}  </span><span class="s0"># store for information</span>
    <span class="s1">res.use_t = use_t</span>

    <span class="s1">adjust_df = </span><span class="s3">False</span>
    <span class="s3">if </span><span class="s1">cov_type </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'cluster'</span><span class="s3">, </span><span class="s4">'hac-panel'</span><span class="s3">, </span><span class="s4">'hac-groupsum'</span><span class="s1">]:</span>
        <span class="s1">df_correction = kwds.get(</span><span class="s4">'df_correction'</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s0"># TODO: check also use_correction, do I need all combinations?</span>
        <span class="s3">if </span><span class="s1">df_correction </span><span class="s3">is not False</span><span class="s1">: </span><span class="s0"># i.e. in [None, True]:</span>
            <span class="s0"># user did not explicitely set it to False</span>
            <span class="s1">adjust_df = </span><span class="s3">True</span>

    <span class="s1">res.cov_kwds[</span><span class="s4">'adjust_df'</span><span class="s1">] = adjust_df</span>

    <span class="s0"># verify and set kwds, and calculate cov</span>
    <span class="s0"># TODO: this should be outsourced in a function so we can reuse it in</span>
    <span class="s0">#       other models</span>
    <span class="s0"># TODO: make it DRYer   repeated code for checking kwds</span>
    <span class="s3">if </span><span class="s1">cov_type.upper() </span><span class="s3">in </span><span class="s1">(</span><span class="s4">'HC0'</span><span class="s3">, </span><span class="s4">'HC1'</span><span class="s3">, </span><span class="s4">'HC2'</span><span class="s3">, </span><span class="s4">'HC3'</span><span class="s1">):</span>
        <span class="s3">if </span><span class="s1">kwds:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'heteroscedasticity robust covariance '</span>
                             <span class="s4">'does not use keywords'</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">] = descriptions[cov_type.upper()]</span>

        <span class="s1">res.cov_params_default = getattr(self</span><span class="s3">, </span><span class="s4">'cov_' </span><span class="s1">+ cov_type.upper()</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">res.cov_params_default </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s0"># results classes that do not have cov_HCx attribute</span>
            <span class="s1">res.cov_params_default = sw.cov_white_simple(self</span><span class="s3">,</span>
                                                         <span class="s1">use_correction=</span><span class="s3">False</span><span class="s1">)</span>
    <span class="s3">elif </span><span class="s1">cov_type.lower() == </span><span class="s4">'hac'</span><span class="s1">:</span>
        <span class="s1">maxlags = kwds[</span><span class="s4">'maxlags'</span><span class="s1">]   </span><span class="s0"># required?, default in cov_hac_simple</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'maxlags'</span><span class="s1">] = maxlags</span>
        <span class="s1">weights_func = kwds.get(</span><span class="s4">'weights_func'</span><span class="s3">, </span><span class="s1">sw.weights_bartlett)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'weights_func'</span><span class="s1">] = weights_func</span>
        <span class="s1">use_correction = kwds.get(</span><span class="s4">'use_correction'</span><span class="s3">, False</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'use_correction'</span><span class="s1">] = use_correction</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">] =  descriptions[</span><span class="s4">'HAC'</span><span class="s1">].format(</span>
            <span class="s1">maxlags=maxlags</span><span class="s3">, </span><span class="s1">correction=[</span><span class="s4">'without'</span><span class="s3">, </span><span class="s4">'with'</span><span class="s1">][use_correction])</span>

        <span class="s1">res.cov_params_default = sw.cov_hac_simple(self</span><span class="s3">, </span><span class="s1">nlags=maxlags</span><span class="s3">,</span>
                                             <span class="s1">weights_func=weights_func</span><span class="s3">,</span>
                                             <span class="s1">use_correction=use_correction)</span>
    <span class="s3">elif </span><span class="s1">cov_type.lower() == </span><span class="s4">'cluster'</span><span class="s1">:</span>
        <span class="s0">#cluster robust standard errors, one- or two-way</span>
        <span class="s1">groups = kwds[</span><span class="s4">'groups'</span><span class="s1">]</span>
        <span class="s3">if not </span><span class="s1">hasattr(groups</span><span class="s3">, </span><span class="s4">'shape'</span><span class="s1">):</span>
            <span class="s1">groups = np.asarray(groups).T</span>

        <span class="s3">if </span><span class="s1">groups.ndim &gt;= </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">groups = groups.squeeze()</span>

        <span class="s1">res.cov_kwds[</span><span class="s4">'groups'</span><span class="s1">] = groups</span>
        <span class="s1">use_correction = kwds.get(</span><span class="s4">'use_correction'</span><span class="s3">, True</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'use_correction'</span><span class="s1">] = use_correction</span>
        <span class="s3">if </span><span class="s1">groups.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">adjust_df:</span>
                <span class="s0"># need to find number of groups</span>
                <span class="s0"># duplicate work</span>
                <span class="s1">self.n_groups = n_groups = len(np.unique(groups))</span>
            <span class="s1">res.cov_params_default = sw.cov_cluster(self</span><span class="s3">, </span><span class="s1">groups</span><span class="s3">,</span>
                                             <span class="s1">use_correction=use_correction)</span>

        <span class="s3">elif </span><span class="s1">groups.ndim == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">hasattr(groups</span><span class="s3">, </span><span class="s4">'values'</span><span class="s1">):</span>
                <span class="s1">groups = groups.values</span>

            <span class="s3">if </span><span class="s1">adjust_df:</span>
                <span class="s0"># need to find number of groups</span>
                <span class="s0"># duplicate work</span>
                <span class="s1">n_groups0 = len(np.unique(groups[:</span><span class="s3">,</span><span class="s5">0</span><span class="s1">]))</span>
                <span class="s1">n_groups1 = len(np.unique(groups[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]))</span>
                <span class="s1">self.n_groups = (n_groups0</span><span class="s3">, </span><span class="s1">n_groups1)</span>
                <span class="s1">n_groups = min(n_groups0</span><span class="s3">, </span><span class="s1">n_groups1) </span><span class="s0"># use for adjust_df</span>

            <span class="s0"># Note: sw.cov_cluster_2groups has 3 returns</span>
            <span class="s1">res.cov_params_default = sw.cov_cluster_2groups(self</span><span class="s3">, </span><span class="s1">groups</span><span class="s3">,</span>
                                         <span class="s1">use_correction=use_correction)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'only two groups are supported'</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">] = descriptions[</span><span class="s4">'cluster'</span><span class="s1">]</span>

    <span class="s3">elif </span><span class="s1">cov_type.lower() == </span><span class="s4">'hac-panel'</span><span class="s1">:</span>
        <span class="s0">#cluster robust standard errors</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'time'</span><span class="s1">] = time = kwds.get(</span><span class="s4">'time'</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'groups'</span><span class="s1">] = groups = kwds.get(</span><span class="s4">'groups'</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s0">#TODO: nlags is currently required</span>
        <span class="s0">#nlags = kwds.get('nlags', True)</span>
        <span class="s0">#res.cov_kwds['nlags'] = nlags</span>
        <span class="s0">#TODO: `nlags` or `maxlags`</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'maxlags'</span><span class="s1">] = maxlags = kwds[</span><span class="s4">'maxlags'</span><span class="s1">]</span>
        <span class="s1">use_correction = kwds.get(</span><span class="s4">'use_correction'</span><span class="s3">, </span><span class="s4">'hac'</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'use_correction'</span><span class="s1">] = use_correction</span>
        <span class="s1">weights_func = kwds.get(</span><span class="s4">'weights_func'</span><span class="s3">, </span><span class="s1">sw.weights_bartlett)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'weights_func'</span><span class="s1">] = weights_func</span>
        <span class="s0"># TODO: clumsy time index in cov_nw_panel</span>
        <span class="s3">if </span><span class="s1">groups </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">groups = np.asarray(groups)</span>
            <span class="s1">tt = (np.nonzero(groups[:-</span><span class="s5">1</span><span class="s1">] != groups[</span><span class="s5">1</span><span class="s1">:])[</span><span class="s5">0</span><span class="s1">] + </span><span class="s5">1</span><span class="s1">).tolist()</span>
            <span class="s1">nobs_ = len(groups)</span>
        <span class="s3">elif </span><span class="s1">time </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s0"># TODO: clumsy time index in cov_nw_panel</span>
            <span class="s1">time = np.asarray(time)</span>
            <span class="s1">tt = (np.nonzero(time[</span><span class="s5">1</span><span class="s1">:] &lt; time[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">] + </span><span class="s5">1</span><span class="s1">).tolist()</span>
            <span class="s1">nobs_ = len(time)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'either time or groups needs to be given'</span><span class="s1">)</span>
        <span class="s1">groupidx = lzip([</span><span class="s5">0</span><span class="s1">] + tt</span><span class="s3">, </span><span class="s1">tt + [nobs_])</span>
        <span class="s1">self.n_groups = n_groups = len(groupidx)</span>
        <span class="s1">res.cov_params_default = sw.cov_nw_panel(self</span><span class="s3">, </span><span class="s1">maxlags</span><span class="s3">, </span><span class="s1">groupidx</span><span class="s3">,</span>
                                            <span class="s1">weights_func=weights_func</span><span class="s3">,</span>
                                            <span class="s1">use_correction=use_correction)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">] = descriptions[</span><span class="s4">'HAC-Panel'</span><span class="s1">]</span>

    <span class="s3">elif </span><span class="s1">cov_type.lower() == </span><span class="s4">'hac-groupsum'</span><span class="s1">:</span>
        <span class="s0"># Driscoll-Kraay standard errors</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'time'</span><span class="s1">] = time = kwds[</span><span class="s4">'time'</span><span class="s1">]</span>
        <span class="s0">#TODO: nlags is currently required</span>
        <span class="s0">#nlags = kwds.get('nlags', True)</span>
        <span class="s0">#res.cov_kwds['nlags'] = nlags</span>
        <span class="s0">#TODO: `nlags` or `maxlags`</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'maxlags'</span><span class="s1">] = maxlags = kwds[</span><span class="s4">'maxlags'</span><span class="s1">]</span>
        <span class="s1">use_correction = kwds.get(</span><span class="s4">'use_correction'</span><span class="s3">, </span><span class="s4">'cluster'</span><span class="s1">)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'use_correction'</span><span class="s1">] = use_correction</span>
        <span class="s1">weights_func = kwds.get(</span><span class="s4">'weights_func'</span><span class="s3">, </span><span class="s1">sw.weights_bartlett)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'weights_func'</span><span class="s1">] = weights_func</span>
        <span class="s3">if </span><span class="s1">adjust_df:</span>
            <span class="s0"># need to find number of groups</span>
            <span class="s1">tt = (np.nonzero(time[</span><span class="s5">1</span><span class="s1">:] &lt; time[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">] + </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">self.n_groups = n_groups = len(tt) + </span><span class="s5">1</span>
        <span class="s1">res.cov_params_default = sw.cov_nw_groupsum(self</span><span class="s3">, </span><span class="s1">maxlags</span><span class="s3">, </span><span class="s1">time</span><span class="s3">,</span>
                                        <span class="s1">weights_func=weights_func</span><span class="s3">,</span>
                                        <span class="s1">use_correction=use_correction)</span>
        <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">] = descriptions[</span><span class="s4">'HAC-Groupsum'</span><span class="s1">]</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'cov_type not recognized. See docstring for ' </span><span class="s1">+</span>
                         <span class="s4">'available options and spelling'</span><span class="s1">)</span>

    <span class="s0"># generic optional factor to scale covariance</span>

    <span class="s1">res.cov_kwds[</span><span class="s4">'scaling_factor'</span><span class="s1">] = sc_factor</span>
    <span class="s3">if </span><span class="s1">sc_factor </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">res.cov_params_default *= sc_factor</span>

    <span class="s3">if </span><span class="s1">adjust_df:</span>
        <span class="s0"># Note: df_resid is used for scale and others, add new attribute</span>
        <span class="s1">res.df_resid_inference = n_groups - </span><span class="s5">1</span>

    <span class="s3">return </span><span class="s1">res</span>
</pre>
</body>
</html>
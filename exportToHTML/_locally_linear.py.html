<html>
<head>
<title>_locally_linear.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_locally_linear.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Locally Linear Embedding&quot;&quot;&quot;</span>

<span class="s2"># Author: Fabian Pedregosa -- &lt;fabian.pedregosa@inria.fr&gt;</span>
<span class="s2">#         Jake Vanderplas  -- &lt;vanderplas@astro.washington.edu&gt;</span>
<span class="s2"># License: BSD 3 clause (C) INRIA 2011</span>

<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s3">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy.linalg </span><span class="s3">import </span><span class="s1">eigh</span><span class="s3">, </span><span class="s1">qr</span><span class="s3">, </span><span class="s1">solve</span><span class="s3">, </span><span class="s1">svd</span>
<span class="s3">from </span><span class="s1">scipy.sparse </span><span class="s3">import </span><span class="s1">csr_matrix</span><span class="s3">, </span><span class="s1">eye</span>
<span class="s3">from </span><span class="s1">scipy.sparse.linalg </span><span class="s3">import </span><span class="s1">eigsh</span>

<span class="s3">from </span><span class="s1">..base </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">BaseEstimator</span><span class="s3">,</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s3">,</span>
    <span class="s1">TransformerMixin</span><span class="s3">,</span>
    <span class="s1">_fit_context</span><span class="s3">,</span>
    <span class="s1">_UnstableArchMixin</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">..neighbors </span><span class="s3">import </span><span class="s1">NearestNeighbors</span>
<span class="s3">from </span><span class="s1">..utils </span><span class="s3">import </span><span class="s1">check_array</span><span class="s3">, </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s1">..utils._arpack </span><span class="s3">import </span><span class="s1">_init_arpack_v0</span>
<span class="s3">from </span><span class="s1">..utils._param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s1">..utils.extmath </span><span class="s3">import </span><span class="s1">stable_cumsum</span>
<span class="s3">from </span><span class="s1">..utils.validation </span><span class="s3">import </span><span class="s1">FLOAT_DTYPES</span><span class="s3">, </span><span class="s1">check_is_fitted</span>


<span class="s3">def </span><span class="s1">barycenter_weights(X</span><span class="s3">, </span><span class="s1">Y</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">reg=</span><span class="s4">1e-3</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Compute barycenter weights of X from Y along the first axis 
 
    We estimate the weights to assign to each point in Y[indices] to recover 
    the point X[i]. The barycenter weights sum to 1. 
 
    Parameters 
    ---------- 
    X : array-like, shape (n_samples, n_dim) 
 
    Y : array-like, shape (n_samples, n_dim) 
 
    indices : array-like, shape (n_samples, n_dim) 
            Indices of the points in Y used to compute the barycenter 
 
    reg : float, default=1e-3 
        Amount of regularization to add for the problem to be 
        well-posed in the case of n_neighbors &gt; n_dim 
 
    Returns 
    ------- 
    B : array-like, shape (n_samples, n_neighbors) 
 
    Notes 
    ----- 
    See developers note for more information. 
    &quot;&quot;&quot;</span>
    <span class="s1">X = check_array(X</span><span class="s3">, </span><span class="s1">dtype=FLOAT_DTYPES)</span>
    <span class="s1">Y = check_array(Y</span><span class="s3">, </span><span class="s1">dtype=FLOAT_DTYPES)</span>
    <span class="s1">indices = check_array(indices</span><span class="s3">, </span><span class="s1">dtype=int)</span>

    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_neighbors = indices.shape</span>
    <span class="s3">assert </span><span class="s1">X.shape[</span><span class="s4">0</span><span class="s1">] == n_samples</span>

    <span class="s1">B = np.empty((n_samples</span><span class="s3">, </span><span class="s1">n_neighbors)</span><span class="s3">, </span><span class="s1">dtype=X.dtype)</span>
    <span class="s1">v = np.ones(n_neighbors</span><span class="s3">, </span><span class="s1">dtype=X.dtype)</span>

    <span class="s2"># this might raise a LinalgError if G is singular and has trace</span>
    <span class="s2"># zero</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">ind </span><span class="s3">in </span><span class="s1">enumerate(indices):</span>
        <span class="s1">A = Y[ind]</span>
        <span class="s1">C = A - X[i]  </span><span class="s2"># broadcasting</span>
        <span class="s1">G = np.dot(C</span><span class="s3">, </span><span class="s1">C.T)</span>
        <span class="s1">trace = np.trace(G)</span>
        <span class="s3">if </span><span class="s1">trace &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">R = reg * trace</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">R = reg</span>
        <span class="s1">G.flat[:: n_neighbors + </span><span class="s4">1</span><span class="s1">] += R</span>
        <span class="s1">w = solve(G</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">assume_a=</span><span class="s5">&quot;pos&quot;</span><span class="s1">)</span>
        <span class="s1">B[i</span><span class="s3">, </span><span class="s1">:] = w / np.sum(w)</span>
    <span class="s3">return </span><span class="s1">B</span>


<span class="s3">def </span><span class="s1">barycenter_kneighbors_graph(X</span><span class="s3">, </span><span class="s1">n_neighbors</span><span class="s3">, </span><span class="s1">reg=</span><span class="s4">1e-3</span><span class="s3">, </span><span class="s1">n_jobs=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Computes the barycenter weighted graph of k-Neighbors for points in X 
 
    Parameters 
    ---------- 
    X : {array-like, NearestNeighbors} 
        Sample data, shape = (n_samples, n_features), in the form of a 
        numpy array or a NearestNeighbors object. 
 
    n_neighbors : int 
        Number of neighbors for each sample. 
 
    reg : float, default=1e-3 
        Amount of regularization when solving the least-squares 
        problem. Only relevant if mode='barycenter'. If None, use the 
        default. 
 
    n_jobs : int or None, default=None 
        The number of parallel jobs to run for neighbors search. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    Returns 
    ------- 
    A : sparse matrix in CSR format, shape = [n_samples, n_samples] 
        A[i, j] is assigned the weight of edge that connects i to j. 
 
    See Also 
    -------- 
    sklearn.neighbors.kneighbors_graph 
    sklearn.neighbors.radius_neighbors_graph 
    &quot;&quot;&quot;</span>
    <span class="s1">knn = NearestNeighbors(n_neighbors=n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n_jobs=n_jobs).fit(X)</span>
    <span class="s1">X = knn._fit_X</span>
    <span class="s1">n_samples = knn.n_samples_fit_</span>
    <span class="s1">ind = knn.kneighbors(X</span><span class="s3">, </span><span class="s1">return_distance=</span><span class="s3">False</span><span class="s1">)[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span>
    <span class="s1">data = barycenter_weights(X</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">ind</span><span class="s3">, </span><span class="s1">reg=reg)</span>
    <span class="s1">indptr = np.arange(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">n_samples * n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n_neighbors)</span>
    <span class="s3">return </span><span class="s1">csr_matrix((data.ravel()</span><span class="s3">, </span><span class="s1">ind.ravel()</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">shape=(n_samples</span><span class="s3">, </span><span class="s1">n_samples))</span>


<span class="s3">def </span><span class="s1">null_space(</span>
    <span class="s1">M</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k_skip=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">eigen_solver=</span><span class="s5">&quot;arpack&quot;</span><span class="s3">, </span><span class="s1">tol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">max_iter=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s3">None</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Find the null space of a matrix M. 
 
    Parameters 
    ---------- 
    M : {array, matrix, sparse matrix, LinearOperator} 
        Input covariance matrix: should be symmetric positive semi-definite 
 
    k : int 
        Number of eigenvalues/vectors to return 
 
    k_skip : int, default=1 
        Number of low eigenvalues to skip. 
 
    eigen_solver : {'auto', 'arpack', 'dense'}, default='arpack' 
        auto : algorithm will attempt to choose the best method for input data 
        arpack : use arnoldi iteration in shift-invert mode. 
                    For this method, M may be a dense matrix, sparse matrix, 
                    or general linear operator. 
                    Warning: ARPACK can be unstable for some problems.  It is 
                    best to try several random seeds in order to check results. 
        dense  : use standard dense matrix operations for the eigenvalue 
                    decomposition.  For this method, M must be an array 
                    or matrix type.  This method should be avoided for 
                    large problems. 
 
    tol : float, default=1e-6 
        Tolerance for 'arpack' method. 
        Not used if eigen_solver=='dense'. 
 
    max_iter : int, default=100 
        Maximum number of iterations for 'arpack' method. 
        Not used if eigen_solver=='dense' 
 
    random_state : int, RandomState instance, default=None 
        Determines the random number generator when ``solver`` == 'arpack'. 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">eigen_solver == </span><span class="s5">&quot;auto&quot;</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">M.shape[</span><span class="s4">0</span><span class="s1">] &gt; </span><span class="s4">200 </span><span class="s3">and </span><span class="s1">k + k_skip &lt; </span><span class="s4">10</span><span class="s1">:</span>
            <span class="s1">eigen_solver = </span><span class="s5">&quot;arpack&quot;</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">eigen_solver = </span><span class="s5">&quot;dense&quot;</span>

    <span class="s3">if </span><span class="s1">eigen_solver == </span><span class="s5">&quot;arpack&quot;</span><span class="s1">:</span>
        <span class="s1">v0 = _init_arpack_v0(M.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">random_state)</span>
        <span class="s3">try</span><span class="s1">:</span>
            <span class="s1">eigen_values</span><span class="s3">, </span><span class="s1">eigen_vectors = eigsh(</span>
                <span class="s1">M</span><span class="s3">, </span><span class="s1">k + k_skip</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s4">0.0</span><span class="s3">, </span><span class="s1">tol=tol</span><span class="s3">, </span><span class="s1">maxiter=max_iter</span><span class="s3">, </span><span class="s1">v0=v0</span>
            <span class="s1">)</span>
        <span class="s3">except </span><span class="s1">RuntimeError </span><span class="s3">as </span><span class="s1">e:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;Error in determining null-space with ARPACK. Error message: &quot;</span>
                <span class="s5">&quot;'%s'. Note that eigen_solver='arpack' can fail when the &quot;</span>
                <span class="s5">&quot;weight matrix is singular or otherwise ill-behaved. In that &quot;</span>
                <span class="s5">&quot;case, eigen_solver='dense' is recommended. See online &quot;</span>
                <span class="s5">&quot;documentation for more information.&quot; </span><span class="s1">% e</span>
            <span class="s1">) </span><span class="s3">from </span><span class="s1">e</span>

        <span class="s3">return </span><span class="s1">eigen_vectors[:</span><span class="s3">, </span><span class="s1">k_skip:]</span><span class="s3">, </span><span class="s1">np.sum(eigen_values[k_skip:])</span>
    <span class="s3">elif </span><span class="s1">eigen_solver == </span><span class="s5">&quot;dense&quot;</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">hasattr(M</span><span class="s3">, </span><span class="s5">&quot;toarray&quot;</span><span class="s1">):</span>
            <span class="s1">M = M.toarray()</span>
        <span class="s1">eigen_values</span><span class="s3">, </span><span class="s1">eigen_vectors = eigh(</span>
            <span class="s1">M</span><span class="s3">, </span><span class="s1">subset_by_index=(k_skip</span><span class="s3">, </span><span class="s1">k + k_skip - </span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">overwrite_a=</span><span class="s3">True</span>
        <span class="s1">)</span>
        <span class="s1">index = np.argsort(np.abs(eigen_values))</span>
        <span class="s3">return </span><span class="s1">eigen_vectors[:</span><span class="s3">, </span><span class="s1">index]</span><span class="s3">, </span><span class="s1">np.sum(eigen_values)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Unrecognized eigen_solver '%s'&quot; </span><span class="s1">% eigen_solver)</span>


<span class="s3">def </span><span class="s1">locally_linear_embedding(</span>
    <span class="s1">X</span><span class="s3">,</span>
    <span class="s1">*</span><span class="s3">,</span>
    <span class="s1">n_neighbors</span><span class="s3">,</span>
    <span class="s1">n_components</span><span class="s3">,</span>
    <span class="s1">reg=</span><span class="s4">1e-3</span><span class="s3">,</span>
    <span class="s1">eigen_solver=</span><span class="s5">&quot;auto&quot;</span><span class="s3">,</span>
    <span class="s1">tol=</span><span class="s4">1e-6</span><span class="s3">,</span>
    <span class="s1">max_iter=</span><span class="s4">100</span><span class="s3">,</span>
    <span class="s1">method=</span><span class="s5">&quot;standard&quot;</span><span class="s3">,</span>
    <span class="s1">hessian_tol=</span><span class="s4">1e-4</span><span class="s3">,</span>
    <span class="s1">modified_tol=</span><span class="s4">1e-12</span><span class="s3">,</span>
    <span class="s1">random_state=</span><span class="s3">None,</span>
    <span class="s1">n_jobs=</span><span class="s3">None,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Perform a Locally Linear Embedding analysis on the data. 
 
    Read more in the :ref:`User Guide &lt;locally_linear_embedding&gt;`. 
 
    Parameters 
    ---------- 
    X : {array-like, NearestNeighbors} 
        Sample data, shape = (n_samples, n_features), in the form of a 
        numpy array or a NearestNeighbors object. 
 
    n_neighbors : int 
        Number of neighbors to consider for each point. 
 
    n_components : int 
        Number of coordinates for the manifold. 
 
    reg : float, default=1e-3 
        Regularization constant, multiplies the trace of the local covariance 
        matrix of the distances. 
 
    eigen_solver : {'auto', 'arpack', 'dense'}, default='auto' 
        auto : algorithm will attempt to choose the best method for input data 
 
        arpack : use arnoldi iteration in shift-invert mode. 
                    For this method, M may be a dense matrix, sparse matrix, 
                    or general linear operator. 
                    Warning: ARPACK can be unstable for some problems.  It is 
                    best to try several random seeds in order to check results. 
 
        dense  : use standard dense matrix operations for the eigenvalue 
                    decomposition.  For this method, M must be an array 
                    or matrix type.  This method should be avoided for 
                    large problems. 
 
    tol : float, default=1e-6 
        Tolerance for 'arpack' method 
        Not used if eigen_solver=='dense'. 
 
    max_iter : int, default=100 
        Maximum number of iterations for the arpack solver. 
 
    method : {'standard', 'hessian', 'modified', 'ltsa'}, default='standard' 
        standard : use the standard locally linear embedding algorithm. 
                   see reference [1]_ 
        hessian  : use the Hessian eigenmap method.  This method requires 
                   n_neighbors &gt; n_components * (1 + (n_components + 1) / 2. 
                   see reference [2]_ 
        modified : use the modified locally linear embedding algorithm. 
                   see reference [3]_ 
        ltsa     : use local tangent space alignment algorithm 
                   see reference [4]_ 
 
    hessian_tol : float, default=1e-4 
        Tolerance for Hessian eigenmapping method. 
        Only used if method == 'hessian'. 
 
    modified_tol : float, default=1e-12 
        Tolerance for modified LLE method. 
        Only used if method == 'modified'. 
 
    random_state : int, RandomState instance, default=None 
        Determines the random number generator when ``solver`` == 'arpack'. 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    n_jobs : int or None, default=None 
        The number of parallel jobs to run for neighbors search. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    Returns 
    ------- 
    Y : array-like, shape [n_samples, n_components] 
        Embedding vectors. 
 
    squared_error : float 
        Reconstruction error for the embedding vectors. Equivalent to 
        ``norm(Y - W Y, 'fro')**2``, where W are the reconstruction weights. 
 
    References 
    ---------- 
 
    .. [1] Roweis, S. &amp; Saul, L. Nonlinear dimensionality reduction 
        by locally linear embedding.  Science 290:2323 (2000). 
    .. [2] Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally 
        linear embedding techniques for high-dimensional data. 
        Proc Natl Acad Sci U S A.  100:5591 (2003). 
    .. [3] `Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear 
        Embedding Using Multiple Weights. 
        &lt;https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3&gt;`_ 
    .. [4] Zhang, Z. &amp; Zha, H. Principal manifolds and nonlinear 
        dimensionality reduction via tangent space alignment. 
        Journal of Shanghai Univ.  8:406 (2004) 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">eigen_solver </span><span class="s3">not in </span><span class="s1">(</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s5">&quot;arpack&quot;</span><span class="s3">, </span><span class="s5">&quot;dense&quot;</span><span class="s1">):</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;unrecognized eigen_solver '%s'&quot; </span><span class="s1">% eigen_solver)</span>

    <span class="s3">if </span><span class="s1">method </span><span class="s3">not in </span><span class="s1">(</span><span class="s5">&quot;standard&quot;</span><span class="s3">, </span><span class="s5">&quot;hessian&quot;</span><span class="s3">, </span><span class="s5">&quot;modified&quot;</span><span class="s3">, </span><span class="s5">&quot;ltsa&quot;</span><span class="s1">):</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;unrecognized method '%s'&quot; </span><span class="s1">% method)</span>

    <span class="s1">nbrs = NearestNeighbors(n_neighbors=n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n_jobs=n_jobs)</span>
    <span class="s1">nbrs.fit(X)</span>
    <span class="s1">X = nbrs._fit_X</span>

    <span class="s1">N</span><span class="s3">, </span><span class="s1">d_in = X.shape</span>

    <span class="s3">if </span><span class="s1">n_components &gt; d_in:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s5">&quot;output dimension must be less than or equal to input dimension&quot;</span>
        <span class="s1">)</span>
    <span class="s3">if </span><span class="s1">n_neighbors &gt;= N:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s5">&quot;Expected n_neighbors &lt;= n_samples,  but n_samples = %d, n_neighbors = %d&quot;</span>
            <span class="s1">% (N</span><span class="s3">, </span><span class="s1">n_neighbors)</span>
        <span class="s1">)</span>

    <span class="s3">if </span><span class="s1">n_neighbors &lt;= </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;n_neighbors must be positive&quot;</span><span class="s1">)</span>

    <span class="s1">M_sparse = eigen_solver != </span><span class="s5">&quot;dense&quot;</span>

    <span class="s3">if </span><span class="s1">method == </span><span class="s5">&quot;standard&quot;</span><span class="s1">:</span>
        <span class="s1">W = barycenter_kneighbors_graph(</span>
            <span class="s1">nbrs</span><span class="s3">, </span><span class="s1">n_neighbors=n_neighbors</span><span class="s3">, </span><span class="s1">reg=reg</span><span class="s3">, </span><span class="s1">n_jobs=n_jobs</span>
        <span class="s1">)</span>

        <span class="s2"># we'll compute M = (I-W)'(I-W)</span>
        <span class="s2"># depending on the solver, we'll do this differently</span>
        <span class="s3">if </span><span class="s1">M_sparse:</span>
            <span class="s1">M = eye(*W.shape</span><span class="s3">, </span><span class="s1">format=W.format) - W</span>
            <span class="s1">M = (M.T * M).tocsr()</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">M = (W.T * W - W.T - W).toarray()</span>
            <span class="s1">M.flat[:: M.shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">] += </span><span class="s4">1  </span><span class="s2"># W = W - I = W - I</span>

    <span class="s3">elif </span><span class="s1">method == </span><span class="s5">&quot;hessian&quot;</span><span class="s1">:</span>
        <span class="s1">dp = n_components * (n_components + </span><span class="s4">1</span><span class="s1">) // </span><span class="s4">2</span>

        <span class="s3">if </span><span class="s1">n_neighbors &lt;= n_components + dp:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;for method='hessian', n_neighbors must be &quot;</span>
                <span class="s5">&quot;greater than &quot;</span>
                <span class="s5">&quot;[n_components * (n_components + 3) / 2]&quot;</span>
            <span class="s1">)</span>

        <span class="s1">neighbors = nbrs.kneighbors(</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">n_neighbors=n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">return_distance=</span><span class="s3">False</span>
        <span class="s1">)</span>
        <span class="s1">neighbors = neighbors[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span>

        <span class="s1">Yi = np.empty((n_neighbors</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">+ n_components + dp)</span><span class="s3">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">Yi[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>

        <span class="s1">M = np.zeros((N</span><span class="s3">, </span><span class="s1">N)</span><span class="s3">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s1">use_svd = n_neighbors &gt; d_in</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
            <span class="s1">Gi = X[neighbors[i]]</span>
            <span class="s1">Gi -= Gi.mean(</span><span class="s4">0</span><span class="s1">)</span>

            <span class="s2"># build Hessian estimator</span>
            <span class="s3">if </span><span class="s1">use_svd:</span>
                <span class="s1">U = svd(Gi</span><span class="s3">, </span><span class="s1">full_matrices=</span><span class="s4">0</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">Ci = np.dot(Gi</span><span class="s3">, </span><span class="s1">Gi.T)</span>
                <span class="s1">U = eigh(Ci)[</span><span class="s4">1</span><span class="s1">][:</span><span class="s3">, </span><span class="s1">::-</span><span class="s4">1</span><span class="s1">]</span>

            <span class="s1">Yi[:</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">: </span><span class="s4">1 </span><span class="s1">+ n_components] = U[:</span><span class="s3">, </span><span class="s1">:n_components]</span>

            <span class="s1">j = </span><span class="s4">1 </span><span class="s1">+ n_components</span>
            <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range(n_components):</span>
                <span class="s1">Yi[:</span><span class="s3">, </span><span class="s1">j : j + n_components - k] = U[:</span><span class="s3">, </span><span class="s1">k : k + </span><span class="s4">1</span><span class="s1">] * U[:</span><span class="s3">, </span><span class="s1">k:n_components]</span>
                <span class="s1">j += n_components - k</span>

            <span class="s1">Q</span><span class="s3">, </span><span class="s1">R = qr(Yi)</span>

            <span class="s1">w = Q[:</span><span class="s3">, </span><span class="s1">n_components + </span><span class="s4">1 </span><span class="s1">:]</span>
            <span class="s1">S = w.sum(</span><span class="s4">0</span><span class="s1">)</span>

            <span class="s1">S[np.where(abs(S) &lt; hessian_tol)] = </span><span class="s4">1</span>
            <span class="s1">w /= S</span>

            <span class="s1">nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y = np.meshgrid(neighbors[i]</span><span class="s3">, </span><span class="s1">neighbors[i])</span>
            <span class="s1">M[nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y] += np.dot(w</span><span class="s3">, </span><span class="s1">w.T)</span>

        <span class="s3">if </span><span class="s1">M_sparse:</span>
            <span class="s1">M = csr_matrix(M)</span>

    <span class="s3">elif </span><span class="s1">method == </span><span class="s5">&quot;modified&quot;</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">n_neighbors &lt; n_components:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;modified LLE requires n_neighbors &gt;= n_components&quot;</span><span class="s1">)</span>

        <span class="s1">neighbors = nbrs.kneighbors(</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">n_neighbors=n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">return_distance=</span><span class="s3">False</span>
        <span class="s1">)</span>
        <span class="s1">neighbors = neighbors[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span>

        <span class="s2"># find the eigenvectors and eigenvalues of each local covariance</span>
        <span class="s2"># matrix. We want V[i] to be a [n_neighbors x n_neighbors] matrix,</span>
        <span class="s2"># where the columns are eigenvectors</span>
        <span class="s1">V = np.zeros((N</span><span class="s3">, </span><span class="s1">n_neighbors</span><span class="s3">, </span><span class="s1">n_neighbors))</span>
        <span class="s1">nev = min(d_in</span><span class="s3">, </span><span class="s1">n_neighbors)</span>
        <span class="s1">evals = np.zeros([N</span><span class="s3">, </span><span class="s1">nev])</span>

        <span class="s2"># choose the most efficient way to find the eigenvectors</span>
        <span class="s1">use_svd = n_neighbors &gt; d_in</span>

        <span class="s3">if </span><span class="s1">use_svd:</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
                <span class="s1">X_nbrs = X[neighbors[i]] - X[i]</span>
                <span class="s1">V[i]</span><span class="s3">, </span><span class="s1">evals[i]</span><span class="s3">, </span><span class="s1">_ = svd(X_nbrs</span><span class="s3">, </span><span class="s1">full_matrices=</span><span class="s3">True</span><span class="s1">)</span>
            <span class="s1">evals **= </span><span class="s4">2</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
                <span class="s1">X_nbrs = X[neighbors[i]] - X[i]</span>
                <span class="s1">C_nbrs = np.dot(X_nbrs</span><span class="s3">, </span><span class="s1">X_nbrs.T)</span>
                <span class="s1">evi</span><span class="s3">, </span><span class="s1">vi = eigh(C_nbrs)</span>
                <span class="s1">evals[i] = evi[::-</span><span class="s4">1</span><span class="s1">]</span>
                <span class="s1">V[i] = vi[:</span><span class="s3">, </span><span class="s1">::-</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s2"># find regularized weights: this is like normal LLE.</span>
        <span class="s2"># because we've already computed the SVD of each covariance matrix,</span>
        <span class="s2"># it's faster to use this rather than np.linalg.solve</span>
        <span class="s1">reg = </span><span class="s4">1e-3 </span><span class="s1">* evals.sum(</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s1">tmp = np.dot(V.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">np.ones(n_neighbors))</span>
        <span class="s1">tmp[:</span><span class="s3">, </span><span class="s1">:nev] /= evals + reg[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">tmp[:</span><span class="s3">, </span><span class="s1">nev:] /= reg[:</span><span class="s3">, None</span><span class="s1">]</span>

        <span class="s1">w_reg = np.zeros((N</span><span class="s3">, </span><span class="s1">n_neighbors))</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
            <span class="s1">w_reg[i] = np.dot(V[i]</span><span class="s3">, </span><span class="s1">tmp[i])</span>
        <span class="s1">w_reg /= w_reg.sum(</span><span class="s4">1</span><span class="s1">)[:</span><span class="s3">, None</span><span class="s1">]</span>

        <span class="s2"># calculate eta: the median of the ratio of small to large eigenvalues</span>
        <span class="s2"># across the points.  This is used to determine s_i, below</span>
        <span class="s1">rho = evals[:</span><span class="s3">, </span><span class="s1">n_components:].sum(</span><span class="s4">1</span><span class="s1">) / evals[:</span><span class="s3">, </span><span class="s1">:n_components].sum(</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">eta = np.median(rho)</span>

        <span class="s2"># find s_i, the size of the &quot;almost null space&quot; for each point:</span>
        <span class="s2"># this is the size of the largest set of eigenvalues</span>
        <span class="s2"># such that Sum[v; v in set]/Sum[v; v not in set] &lt; eta</span>
        <span class="s1">s_range = np.zeros(N</span><span class="s3">, </span><span class="s1">dtype=int)</span>
        <span class="s1">evals_cumsum = stable_cumsum(evals</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">eta_range = evals_cumsum[:</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">:] / evals_cumsum[:</span><span class="s3">, </span><span class="s1">:-</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">1</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
            <span class="s1">s_range[i] = np.searchsorted(eta_range[i</span><span class="s3">, </span><span class="s1">::-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">eta)</span>
        <span class="s1">s_range += n_neighbors - nev  </span><span class="s2"># number of zero eigenvalues</span>

        <span class="s2"># Now calculate M.</span>
        <span class="s2"># This is the [N x N] matrix whose null space is the desired embedding</span>
        <span class="s1">M = np.zeros((N</span><span class="s3">, </span><span class="s1">N)</span><span class="s3">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
            <span class="s1">s_i = s_range[i]</span>

            <span class="s2"># select bottom s_i eigenvectors and calculate alpha</span>
            <span class="s1">Vi = V[i</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">n_neighbors - s_i :]</span>
            <span class="s1">alpha_i = np.linalg.norm(Vi.sum(</span><span class="s4">0</span><span class="s1">)) / np.sqrt(s_i)</span>

            <span class="s2"># compute Householder matrix which satisfies</span>
            <span class="s2">#  Hi*Vi.T*ones(n_neighbors) = alpha_i*ones(s)</span>
            <span class="s2"># using prescription from paper</span>
            <span class="s1">h = np.full(s_i</span><span class="s3">, </span><span class="s1">alpha_i) - np.dot(Vi.T</span><span class="s3">, </span><span class="s1">np.ones(n_neighbors))</span>

            <span class="s1">norm_h = np.linalg.norm(h)</span>
            <span class="s3">if </span><span class="s1">norm_h &lt; modified_tol:</span>
                <span class="s1">h *= </span><span class="s4">0</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">h /= norm_h</span>

            <span class="s2"># Householder matrix is</span>
            <span class="s2">#  &gt;&gt; Hi = np.identity(s_i) - 2*np.outer(h,h)</span>
            <span class="s2"># Then the weight matrix is</span>
            <span class="s2">#  &gt;&gt; Wi = np.dot(Vi,Hi) + (1-alpha_i) * w_reg[i,:,None]</span>
            <span class="s2"># We do this much more efficiently:</span>
            <span class="s1">Wi = Vi - </span><span class="s4">2 </span><span class="s1">* np.outer(np.dot(Vi</span><span class="s3">, </span><span class="s1">h)</span><span class="s3">, </span><span class="s1">h) + (</span><span class="s4">1 </span><span class="s1">- alpha_i) * w_reg[i</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, None</span><span class="s1">]</span>

            <span class="s2"># Update M as follows:</span>
            <span class="s2"># &gt;&gt; W_hat = np.zeros( (N,s_i) )</span>
            <span class="s2"># &gt;&gt; W_hat[neighbors[i],:] = Wi</span>
            <span class="s2"># &gt;&gt; W_hat[i] -= 1</span>
            <span class="s2"># &gt;&gt; M += np.dot(W_hat,W_hat.T)</span>
            <span class="s2"># We can do this much more efficiently:</span>
            <span class="s1">nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y = np.meshgrid(neighbors[i]</span><span class="s3">, </span><span class="s1">neighbors[i])</span>
            <span class="s1">M[nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y] += np.dot(Wi</span><span class="s3">, </span><span class="s1">Wi.T)</span>
            <span class="s1">Wi_sum1 = Wi.sum(</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">M[i</span><span class="s3">, </span><span class="s1">neighbors[i]] -= Wi_sum1</span>
            <span class="s1">M[neighbors[i]</span><span class="s3">, </span><span class="s1">i] -= Wi_sum1</span>
            <span class="s1">M[i</span><span class="s3">, </span><span class="s1">i] += s_i</span>

        <span class="s3">if </span><span class="s1">M_sparse:</span>
            <span class="s1">M = csr_matrix(M)</span>

    <span class="s3">elif </span><span class="s1">method == </span><span class="s5">&quot;ltsa&quot;</span><span class="s1">:</span>
        <span class="s1">neighbors = nbrs.kneighbors(</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">n_neighbors=n_neighbors + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">return_distance=</span><span class="s3">False</span>
        <span class="s1">)</span>
        <span class="s1">neighbors = neighbors[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span>

        <span class="s1">M = np.zeros((N</span><span class="s3">, </span><span class="s1">N))</span>

        <span class="s1">use_svd = n_neighbors &gt; d_in</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(N):</span>
            <span class="s1">Xi = X[neighbors[i]]</span>
            <span class="s1">Xi -= Xi.mean(</span><span class="s4">0</span><span class="s1">)</span>

            <span class="s2"># compute n_components largest eigenvalues of Xi * Xi^T</span>
            <span class="s3">if </span><span class="s1">use_svd:</span>
                <span class="s1">v = svd(Xi</span><span class="s3">, </span><span class="s1">full_matrices=</span><span class="s3">True</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">Ci = np.dot(Xi</span><span class="s3">, </span><span class="s1">Xi.T)</span>
                <span class="s1">v = eigh(Ci)[</span><span class="s4">1</span><span class="s1">][:</span><span class="s3">, </span><span class="s1">::-</span><span class="s4">1</span><span class="s1">]</span>

            <span class="s1">Gi = np.zeros((n_neighbors</span><span class="s3">, </span><span class="s1">n_components + </span><span class="s4">1</span><span class="s1">))</span>
            <span class="s1">Gi[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:] = v[:</span><span class="s3">, </span><span class="s1">:n_components]</span>
            <span class="s1">Gi[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1.0 </span><span class="s1">/ np.sqrt(n_neighbors)</span>

            <span class="s1">GiGiT = np.dot(Gi</span><span class="s3">, </span><span class="s1">Gi.T)</span>

            <span class="s1">nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y = np.meshgrid(neighbors[i]</span><span class="s3">, </span><span class="s1">neighbors[i])</span>
            <span class="s1">M[nbrs_x</span><span class="s3">, </span><span class="s1">nbrs_y] -= GiGiT</span>
            <span class="s1">M[neighbors[i]</span><span class="s3">, </span><span class="s1">neighbors[i]] += </span><span class="s4">1</span>

    <span class="s3">return </span><span class="s1">null_space(</span>
        <span class="s1">M</span><span class="s3">,</span>
        <span class="s1">n_components</span><span class="s3">,</span>
        <span class="s1">k_skip=</span><span class="s4">1</span><span class="s3">,</span>
        <span class="s1">eigen_solver=eigen_solver</span><span class="s3">,</span>
        <span class="s1">tol=tol</span><span class="s3">,</span>
        <span class="s1">max_iter=max_iter</span><span class="s3">,</span>
        <span class="s1">random_state=random_state</span><span class="s3">,</span>
    <span class="s1">)</span>


<span class="s3">class </span><span class="s1">LocallyLinearEmbedding(</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s3">,</span>
    <span class="s1">TransformerMixin</span><span class="s3">,</span>
    <span class="s1">_UnstableArchMixin</span><span class="s3">,</span>
    <span class="s1">BaseEstimator</span><span class="s3">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Locally Linear Embedding. 
 
    Read more in the :ref:`User Guide &lt;locally_linear_embedding&gt;`. 
 
    Parameters 
    ---------- 
    n_neighbors : int, default=5 
        Number of neighbors to consider for each point. 
 
    n_components : int, default=2 
        Number of coordinates for the manifold. 
 
    reg : float, default=1e-3 
        Regularization constant, multiplies the trace of the local covariance 
        matrix of the distances. 
 
    eigen_solver : {'auto', 'arpack', 'dense'}, default='auto' 
        The solver used to compute the eigenvectors. The available options are: 
 
        - `'auto'` : algorithm will attempt to choose the best method for input 
          data. 
        - `'arpack'` : use arnoldi iteration in shift-invert mode. For this 
          method, M may be a dense matrix, sparse matrix, or general linear 
          operator. 
        - `'dense'`  : use standard dense matrix operations for the eigenvalue 
          decomposition. For this method, M must be an array or matrix type. 
          This method should be avoided for large problems. 
 
        .. warning:: 
           ARPACK can be unstable for some problems.  It is best to try several 
           random seeds in order to check results. 
 
    tol : float, default=1e-6 
        Tolerance for 'arpack' method 
        Not used if eigen_solver=='dense'. 
 
    max_iter : int, default=100 
        Maximum number of iterations for the arpack solver. 
        Not used if eigen_solver=='dense'. 
 
    method : {'standard', 'hessian', 'modified', 'ltsa'}, default='standard' 
        - `standard`: use the standard locally linear embedding algorithm. see 
          reference [1]_ 
        - `hessian`: use the Hessian eigenmap method. This method requires 
          ``n_neighbors &gt; n_components * (1 + (n_components + 1) / 2``. see 
          reference [2]_ 
        - `modified`: use the modified locally linear embedding algorithm. 
          see reference [3]_ 
        - `ltsa`: use local tangent space alignment algorithm. see 
          reference [4]_ 
 
    hessian_tol : float, default=1e-4 
        Tolerance for Hessian eigenmapping method. 
        Only used if ``method == 'hessian'``. 
 
    modified_tol : float, default=1e-12 
        Tolerance for modified LLE method. 
        Only used if ``method == 'modified'``. 
 
    neighbors_algorithm : {'auto', 'brute', 'kd_tree', 'ball_tree'}, \ 
                          default='auto' 
        Algorithm to use for nearest neighbors search, passed to 
        :class:`~sklearn.neighbors.NearestNeighbors` instance. 
 
    random_state : int, RandomState instance, default=None 
        Determines the random number generator when 
        ``eigen_solver`` == 'arpack'. Pass an int for reproducible results 
        across multiple function calls. See :term:`Glossary &lt;random_state&gt;`. 
 
    n_jobs : int or None, default=None 
        The number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    Attributes 
    ---------- 
    embedding_ : array-like, shape [n_samples, n_components] 
        Stores the embedding vectors 
 
    reconstruction_error_ : float 
        Reconstruction error associated with `embedding_` 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    nbrs_ : NearestNeighbors object 
        Stores nearest neighbors instance, including BallTree or KDtree 
        if applicable. 
 
    See Also 
    -------- 
    SpectralEmbedding : Spectral embedding for non-linear dimensionality 
        reduction. 
    TSNE : Distributed Stochastic Neighbor Embedding. 
 
    References 
    ---------- 
 
    .. [1] Roweis, S. &amp; Saul, L. Nonlinear dimensionality reduction 
        by locally linear embedding.  Science 290:2323 (2000). 
    .. [2] Donoho, D. &amp; Grimes, C. Hessian eigenmaps: Locally 
        linear embedding techniques for high-dimensional data. 
        Proc Natl Acad Sci U S A.  100:5591 (2003). 
    .. [3] `Zhang, Z. &amp; Wang, J. MLLE: Modified Locally Linear 
        Embedding Using Multiple Weights. 
        &lt;https://citeseerx.ist.psu.edu/doc_view/pid/0b060fdbd92cbcc66b383bcaa9ba5e5e624d7ee3&gt;`_ 
    .. [4] Zhang, Z. &amp; Zha, H. Principal manifolds and nonlinear 
        dimensionality reduction via tangent space alignment. 
        Journal of Shanghai Univ.  8:406 (2004) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.datasets import load_digits 
    &gt;&gt;&gt; from sklearn.manifold import LocallyLinearEmbedding 
    &gt;&gt;&gt; X, _ = load_digits(return_X_y=True) 
    &gt;&gt;&gt; X.shape 
    (1797, 64) 
    &gt;&gt;&gt; embedding = LocallyLinearEmbedding(n_components=2) 
    &gt;&gt;&gt; X_transformed = embedding.fit_transform(X[:100]) 
    &gt;&gt;&gt; X_transformed.shape 
    (100, 2) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints: dict = {</span>
        <span class="s5">&quot;n_neighbors&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;reg&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;eigen_solver&quot;</span><span class="s1">: [StrOptions({</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s5">&quot;arpack&quot;</span><span class="s3">, </span><span class="s5">&quot;dense&quot;</span><span class="s1">})]</span><span class="s3">,</span>
        <span class="s5">&quot;tol&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;method&quot;</span><span class="s1">: [StrOptions({</span><span class="s5">&quot;standard&quot;</span><span class="s3">, </span><span class="s5">&quot;hessian&quot;</span><span class="s3">, </span><span class="s5">&quot;modified&quot;</span><span class="s3">, </span><span class="s5">&quot;ltsa&quot;</span><span class="s1">})]</span><span class="s3">,</span>
        <span class="s5">&quot;hessian_tol&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;modified_tol&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s5">&quot;left&quot;</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s5">&quot;neighbors_algorithm&quot;</span><span class="s1">: [StrOptions({</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s5">&quot;brute&quot;</span><span class="s3">, </span><span class="s5">&quot;kd_tree&quot;</span><span class="s3">, </span><span class="s5">&quot;ball_tree&quot;</span><span class="s1">})]</span><span class="s3">,</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s1">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s1">: [</span><span class="s3">None, </span><span class="s1">Integral]</span><span class="s3">,</span>
    <span class="s1">}</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">*</span><span class="s3">,</span>
        <span class="s1">n_neighbors=</span><span class="s4">5</span><span class="s3">,</span>
        <span class="s1">n_components=</span><span class="s4">2</span><span class="s3">,</span>
        <span class="s1">reg=</span><span class="s4">1e-3</span><span class="s3">,</span>
        <span class="s1">eigen_solver=</span><span class="s5">&quot;auto&quot;</span><span class="s3">,</span>
        <span class="s1">tol=</span><span class="s4">1e-6</span><span class="s3">,</span>
        <span class="s1">max_iter=</span><span class="s4">100</span><span class="s3">,</span>
        <span class="s1">method=</span><span class="s5">&quot;standard&quot;</span><span class="s3">,</span>
        <span class="s1">hessian_tol=</span><span class="s4">1e-4</span><span class="s3">,</span>
        <span class="s1">modified_tol=</span><span class="s4">1e-12</span><span class="s3">,</span>
        <span class="s1">neighbors_algorithm=</span><span class="s5">&quot;auto&quot;</span><span class="s3">,</span>
        <span class="s1">random_state=</span><span class="s3">None,</span>
        <span class="s1">n_jobs=</span><span class="s3">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.n_neighbors = n_neighbors</span>
        <span class="s1">self.n_components = n_components</span>
        <span class="s1">self.reg = reg</span>
        <span class="s1">self.eigen_solver = eigen_solver</span>
        <span class="s1">self.tol = tol</span>
        <span class="s1">self.max_iter = max_iter</span>
        <span class="s1">self.method = method</span>
        <span class="s1">self.hessian_tol = hessian_tol</span>
        <span class="s1">self.modified_tol = modified_tol</span>
        <span class="s1">self.random_state = random_state</span>
        <span class="s1">self.neighbors_algorithm = neighbors_algorithm</span>
        <span class="s1">self.n_jobs = n_jobs</span>

    <span class="s3">def </span><span class="s1">_fit_transform(self</span><span class="s3">, </span><span class="s1">X):</span>
        <span class="s1">self.nbrs_ = NearestNeighbors(</span>
            <span class="s1">n_neighbors=self.n_neighbors</span><span class="s3">,</span>
            <span class="s1">algorithm=self.neighbors_algorithm</span><span class="s3">,</span>
            <span class="s1">n_jobs=self.n_jobs</span><span class="s3">,</span>
        <span class="s1">)</span>

        <span class="s1">random_state = check_random_state(self.random_state)</span>
        <span class="s1">X = self._validate_data(X</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s1">self.nbrs_.fit(X)</span>
        <span class="s1">self.embedding_</span><span class="s3">, </span><span class="s1">self.reconstruction_error_ = locally_linear_embedding(</span>
            <span class="s1">X=self.nbrs_</span><span class="s3">,</span>
            <span class="s1">n_neighbors=self.n_neighbors</span><span class="s3">,</span>
            <span class="s1">n_components=self.n_components</span><span class="s3">,</span>
            <span class="s1">eigen_solver=self.eigen_solver</span><span class="s3">,</span>
            <span class="s1">tol=self.tol</span><span class="s3">,</span>
            <span class="s1">max_iter=self.max_iter</span><span class="s3">,</span>
            <span class="s1">method=self.method</span><span class="s3">,</span>
            <span class="s1">hessian_tol=self.hessian_tol</span><span class="s3">,</span>
            <span class="s1">modified_tol=self.modified_tol</span><span class="s3">,</span>
            <span class="s1">random_state=random_state</span><span class="s3">,</span>
            <span class="s1">reg=self.reg</span><span class="s3">,</span>
            <span class="s1">n_jobs=self.n_jobs</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s1">self._n_features_out = self.embedding_.shape[</span><span class="s4">1</span><span class="s1">]</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the embedding vectors for data X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training set. 
 
        y : Ignored 
            Not used, present here for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Fitted `LocallyLinearEmbedding` class instance. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._fit_transform(X)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">fit_transform(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the embedding vectors for data X and transform X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training set. 
 
        y : Ignored 
            Not used, present here for API consistency by convention. 
 
        Returns 
        ------- 
        X_new : array-like, shape (n_samples, n_components) 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._fit_transform(X)</span>
        <span class="s3">return </span><span class="s1">self.embedding_</span>

    <span class="s3">def </span><span class="s1">transform(self</span><span class="s3">, </span><span class="s1">X):</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform new points into embedding space. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training set. 
 
        Returns 
        ------- 
        X_new : ndarray of shape (n_samples, n_components) 
            Returns the instance itself. 
 
        Notes 
        ----- 
        Because of scaling performed by this method, it is discouraged to use 
        it together with methods that are not scale-invariant (like SVMs). 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s1">X = self._validate_data(X</span><span class="s3">, </span><span class="s1">reset=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">ind = self.nbrs_.kneighbors(</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">n_neighbors=self.n_neighbors</span><span class="s3">, </span><span class="s1">return_distance=</span><span class="s3">False</span>
        <span class="s1">)</span>
        <span class="s1">weights = barycenter_weights(X</span><span class="s3">, </span><span class="s1">self.nbrs_._fit_X</span><span class="s3">, </span><span class="s1">ind</span><span class="s3">, </span><span class="s1">reg=self.reg)</span>
        <span class="s1">X_new = np.empty((X.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.n_components))</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(X.shape[</span><span class="s4">0</span><span class="s1">]):</span>
            <span class="s1">X_new[i] = np.dot(self.embedding_[ind[i]].T</span><span class="s3">, </span><span class="s1">weights[i])</span>
        <span class="s3">return </span><span class="s1">X_new</span>
</pre>
</body>
</html>
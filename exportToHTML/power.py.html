<html>
<head>
<title>power.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
power.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s0">#pylint: disable-msg=W0142</span>
<span class="s2">&quot;&quot;&quot;Statistical power, solving for nobs, ... - trial version 
 
Created on Sat Jan 12 21:48:06 2013 
 
Author: Josef Perktold 
 
Example 
roundtrip - root with respect to all variables 
 
       calculated, desired 
nobs   33.367204205 33.367204205 
effect 0.5 0.5 
alpha  0.05 0.05 
power   0.8 0.8 
 
 
TODO: 
refactoring 
 - rename beta -&gt; power,    beta (type 2 error is beta = 1-power)  DONE 
 - I think the current implementation can handle any kinds of extra keywords 
   (except for maybe raising meaningful exceptions 
 - streamline code, I think internally classes can be merged 
   how to extend to k-sample tests? 
   user interface for different tests that map to the same (internal) test class 
 - sequence of arguments might be inconsistent, 
   arg and/or kwds so python checks what's required and what can be None. 
 - templating for docstrings ? 
 
 
&quot;&quot;&quot;</span>
<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span><span class="s3">, </span><span class="s1">optimize</span><span class="s3">, </span><span class="s1">special</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.rootfinding </span><span class="s3">import </span><span class="s1">brentq_expanding</span>


<span class="s3">def </span><span class="s1">nct_cdf(x</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">nc):</span>
    <span class="s3">return </span><span class="s1">special.nctdtr(df</span><span class="s3">, </span><span class="s1">nc</span><span class="s3">, </span><span class="s1">x)</span>


<span class="s3">def </span><span class="s1">nct_sf(x</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">nc):</span>
    <span class="s3">return </span><span class="s4">1 </span><span class="s1">- special.nctdtr(df</span><span class="s3">, </span><span class="s1">nc</span><span class="s3">, </span><span class="s1">x)</span>


<span class="s3">def </span><span class="s1">ncf_cdf(x</span><span class="s3">, </span><span class="s1">dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc):</span>
    <span class="s3">return </span><span class="s1">special.ncfdtr(dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc</span><span class="s3">, </span><span class="s1">x)</span>


<span class="s3">def </span><span class="s1">ncf_sf(x</span><span class="s3">, </span><span class="s1">dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc):</span>
    <span class="s3">return </span><span class="s4">1 </span><span class="s1">- special.ncfdtr(dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc</span><span class="s3">, </span><span class="s1">x)</span>


<span class="s3">def </span><span class="s1">ncf_ppf(q</span><span class="s3">, </span><span class="s1">dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc):</span>
    <span class="s3">return </span><span class="s1">special.ncfdtri(dfn</span><span class="s3">, </span><span class="s1">dfd</span><span class="s3">, </span><span class="s1">nc</span><span class="s3">, </span><span class="s1">q)</span>


<span class="s3">def </span><span class="s1">ttest_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">df=</span><span class="s3">None, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
    <span class="s2">'''Calculate power of a ttest 
    '''</span>
    <span class="s1">d = effect_size</span>
    <span class="s3">if </span><span class="s1">df </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">df = nobs - </span><span class="s4">1</span>

    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha / </span><span class="s4">2.  </span><span class="s0">#no inplace changes, does not work</span>
    <span class="s3">elif </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'smaller'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;alternative has to be 'two-sided', 'larger' &quot; </span><span class="s1">+</span>
                         <span class="s5">&quot;or 'smaller'&quot;</span><span class="s1">)</span>

    <span class="s1">pow_ = </span><span class="s4">0</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">crit_upp = stats.t.isf(alpha_</span><span class="s3">, </span><span class="s1">df)</span>
        <span class="s0">#print crit_upp, df, d*np.sqrt(nobs)</span>
        <span class="s0"># use private methods, generic methods return nan with negative d</span>
        <span class="s3">if </span><span class="s1">np.any(np.isnan(crit_upp)):</span>
            <span class="s0"># avoid endless loop, https://github.com/scipy/scipy/issues/2667</span>
            <span class="s1">pow_ = np.nan</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s0"># pow_ = stats.nct._sf(crit_upp, df, d*np.sqrt(nobs))</span>
            <span class="s0"># use scipy.special</span>
            <span class="s1">pow_ = nct_sf(crit_upp</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">d*np.sqrt(nobs))</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'smaller'</span><span class="s1">]:</span>
        <span class="s1">crit_low = stats.t.ppf(alpha_</span><span class="s3">, </span><span class="s1">df)</span>
        <span class="s0">#print crit_low, df, d*np.sqrt(nobs)</span>
        <span class="s3">if </span><span class="s1">np.any(np.isnan(crit_low)):</span>
            <span class="s1">pow_ = np.nan</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s0"># pow_ += stats.nct._cdf(crit_low, df, d*np.sqrt(nobs))</span>
            <span class="s1">pow_ += nct_cdf(crit_low</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">d*np.sqrt(nobs))</span>
    <span class="s3">return </span><span class="s1">pow_</span>


<span class="s3">def </span><span class="s1">normal_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s4">1.</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Calculate power of a normal distributed test statistic 
 
    This is an generalization of `normal_power` when variance under Null and 
    Alternative differ. 
 
    Parameters 
    ---------- 
    effect size : float 
        difference in the estimated means or statistics under the alternative 
        normalized by the standard deviation (without division by sqrt(nobs). 
    nobs : float or int 
        number of observations 
    alpha : float in interval (0,1) 
        significance level, e.g. 0.05, is the probability of a type I 
        error, that is wrong rejections if the Null Hypothesis is true. 
    alternative : string, 'two-sided' (default), 'larger', 'smaller' 
        extra argument to choose whether the power is calculated for a 
        two-sided (default) or one sided test. The one-sided test can be 
        either 'larger', 'smaller'. 
    &quot;&quot;&quot;</span>

    <span class="s1">d = effect_size</span>

    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha / </span><span class="s4">2.  </span><span class="s0">#no inplace changes, does not work</span>
    <span class="s3">elif </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'smaller'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;alternative has to be 'two-sided', 'larger' &quot; </span><span class="s1">+</span>
                         <span class="s5">&quot;or 'smaller'&quot;</span><span class="s1">)</span>

    <span class="s1">pow_ = </span><span class="s4">0</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">crit = stats.norm.isf(alpha_)</span>
        <span class="s1">pow_ = stats.norm.sf(crit - d*np.sqrt(nobs)/sigma)</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'smaller'</span><span class="s1">]:</span>
        <span class="s1">crit = stats.norm.ppf(alpha_)</span>
        <span class="s1">pow_ += stats.norm.cdf(crit - d*np.sqrt(nobs)/sigma)</span>
    <span class="s3">return </span><span class="s1">pow_</span>


<span class="s3">def </span><span class="s1">normal_power_het(diff</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">std_null=</span><span class="s4">1.</span><span class="s3">, </span><span class="s1">std_alternative=</span><span class="s3">None,</span>
                 <span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Calculate power of a normal distributed test statistic 
 
    This is an generalization of `normal_power` when variance under Null and 
    Alternative differ. 
 
    Parameters 
    ---------- 
    diff : float 
        difference in the estimated means or statistics under the alternative. 
    nobs : float or int 
        number of observations 
    alpha : float in interval (0,1) 
        significance level, e.g. 0.05, is the probability of a type I 
        error, that is wrong rejections if the Null Hypothesis is true. 
    std_null : float 
        standard deviation under the Null hypothesis without division by 
        sqrt(nobs) 
    std_alternative : float 
        standard deviation under the Alternative hypothesis without division 
        by sqrt(nobs) 
    alternative : string, 'two-sided' (default), 'larger', 'smaller' 
        extra argument to choose whether the power is calculated for a 
        two-sided (default) or one sided test. The one-sided test can be 
        either 'larger', 'smaller'. 
 
    Returns 
    ------- 
    power : float 
    &quot;&quot;&quot;</span>

    <span class="s1">d = diff</span>
    <span class="s3">if </span><span class="s1">std_alternative </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">std_alternative = std_null</span>

    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha / </span><span class="s4">2.  </span><span class="s0">#no inplace changes, does not work</span>
    <span class="s3">elif </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'smaller'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">alpha_ = alpha</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;alternative has to be 'two-sided', 'larger' &quot; </span><span class="s1">+</span>
                         <span class="s5">&quot;or 'smaller'&quot;</span><span class="s1">)</span>

    <span class="s1">std_ratio = std_null / std_alternative</span>
    <span class="s1">pow_ = </span><span class="s4">0</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'larger'</span><span class="s1">]:</span>
        <span class="s1">crit = stats.norm.isf(alpha_)</span>
        <span class="s1">pow_ = stats.norm.sf(crit * std_ratio -</span>
                             <span class="s1">d*np.sqrt(nobs) / std_alternative)</span>
    <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'two-sided'</span><span class="s3">, </span><span class="s5">'2s'</span><span class="s3">, </span><span class="s5">'smaller'</span><span class="s1">]:</span>
        <span class="s1">crit = stats.norm.ppf(alpha_)</span>
        <span class="s1">pow_ += stats.norm.cdf(crit * std_ratio -</span>
                               <span class="s1">d*np.sqrt(nobs) / std_alternative)</span>
    <span class="s3">return </span><span class="s1">pow_</span>


<span class="s3">def </span><span class="s1">normal_sample_size_one_tail(diff</span><span class="s3">, </span><span class="s1">power</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">std_null=</span><span class="s4">1.</span><span class="s3">,</span>
                                <span class="s1">std_alternative=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;explicit sample size computation if only one tail is relevant 
 
    The sample size is based on the power in one tail assuming that the 
    alternative is in the tail where the test has power that increases 
    with sample size. 
    Use alpha/2 to compute the one tail approximation to the two-sided 
    test, i.e. consider only one tail of two-sided test. 
 
    Parameters 
    ---------- 
    diff : float 
        difference in the estimated means or statistics under the alternative. 
    power : float in interval (0,1) 
        power of the test, e.g. 0.8, is one minus the probability of a type II 
        error. Power is the probability that the test correctly rejects the 
        Null Hypothesis if the Alternative Hypothesis is true. 
    alpha : float in interval (0,1) 
        significance level, e.g. 0.05, is the probability of a type I 
        error, that is wrong rejections if the Null Hypothesis is true. 
        Note: alpha is used for one tail. Use alpha/2 for two-sided 
        alternative. 
    std_null : float 
        standard deviation under the Null hypothesis without division by 
        sqrt(nobs) 
    std_alternative : float 
        standard deviation under the Alternative hypothesis without division 
        by sqrt(nobs). Defaults to None. If None, ``std_alternative`` is set 
        to the value of ``std_null``. 
 
    Returns 
    ------- 
    nobs : float 
        Sample size to achieve (at least) the desired power. 
        If the minimum power is satisfied for all positive sample sizes, then 
        ``nobs`` will be zero. This will be the case when power &lt;= alpha if 
        std_alternative is equal to std_null. 
 
    &quot;&quot;&quot;</span>

    <span class="s3">if </span><span class="s1">std_alternative </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">std_alternative = std_null</span>

    <span class="s1">crit_power = stats.norm.isf(power)</span>
    <span class="s1">crit = stats.norm.isf(alpha)</span>
    <span class="s1">n1 = (np.maximum(crit * std_null - crit_power * std_alternative</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
          <span class="s1">/ diff)**</span><span class="s4">2</span>
    <span class="s3">return </span><span class="s1">n1</span>


<span class="s3">def </span><span class="s1">ftest_anova_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">k_groups=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">df=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">'''power for ftest for one way anova with k equal sized groups 
 
    nobs total sample size, sum over all groups 
 
    should be general nobs observations, k_groups restrictions ??? 
    '''</span>
    <span class="s1">df_num = k_groups - </span><span class="s4">1</span>
    <span class="s1">df_denom = nobs - k_groups</span>
    <span class="s1">crit = stats.f.isf(alpha</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom)</span>
    <span class="s1">pow_ = ncf_sf(crit</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">effect_size**</span><span class="s4">2 </span><span class="s1">* nobs)</span>
    <span class="s3">return </span><span class="s1">pow_</span>


<span class="s3">def </span><span class="s1">ftest_power(effect_size</span><span class="s3">, </span><span class="s1">df2</span><span class="s3">, </span><span class="s1">df1</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s2">'''Calculate the power of a F-test. 
 
    Parameters 
    ---------- 
    effect_size : float 
        The effect size is here Cohen's ``f``, the square root of ``f2``. 
    df2 : int or float 
        Denominator degrees of freedom. 
        This corresponds to the df_resid in Wald tests. 
    df1 : int or float 
        Numerator degrees of freedom. 
        This corresponds to the number of constraints in Wald tests. 
    alpha : float in interval (0,1) 
        significance level, e.g. 0.05, is the probability of a type I 
        error, that is wrong rejections if the Null Hypothesis is true. 
    ncc : int 
        degrees of freedom correction for non-centrality parameter. 
        see Notes 
 
    Returns 
    ------- 
    power : float 
        Power of the test, e.g. 0.8, is one minus the probability of a 
        type II error. Power is the probability that the test correctly 
        rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
    Notes 
    ----- 
    changed in 0.14: use df2, df1 instead of df_num, df_denom as arg names. 
    The latter had reversed meaning. 
 
    The sample size is given implicitly by ``df2`` with fixed number of 
    constraints given by numerator degrees of freedom ``df1``: 
 
        nobs = df2 + df1 + ncc 
 
    Set ncc=0 to match t-test, or f-test in LikelihoodModelResults. 
    ncc=1 matches the non-centrality parameter in R::pwr::pwr.f2.test 
 
    ftest_power with ncc=0 should also be correct for f_test in regression 
    models, with df_num (df1) as number of constraints and d_denom (df2) as 
    df_resid. 
    '''</span>
    <span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom = df1</span><span class="s3">, </span><span class="s1">df2</span>
    <span class="s1">nc = effect_size**</span><span class="s4">2 </span><span class="s1">* (df_denom + df_num + ncc)</span>
    <span class="s1">crit = stats.f.isf(alpha</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom)</span>
    <span class="s0"># pow_ = stats.ncf.sf(crit, df_num, df_denom, nc)</span>
    <span class="s0"># use scipy.special for ncf</span>
    <span class="s1">pow_ = ncf_sf(crit</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">nc)</span>
    <span class="s3">return </span><span class="s1">pow_ </span><span class="s0">#, crit, nc</span>


<span class="s3">def </span><span class="s1">ftest_power_f2(effect_size</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s2">'''Calculate the power of a F-test. 
 
    Based on Cohen's `f^2` effect size. 
 
    This assumes 
 
        df_num : numerator degrees of freedom, (number of constraints) 
        df_denom : denominator degrees of freedom (df_resid in regression) 
        nobs = df_denom + df_num + ncc 
        nc = effect_size * nobs  (noncentrality index) 
 
    Power is computed one-sided in the upper tail. 
 
    Parameters 
    ---------- 
    effect_size : float 
        Cohen's f2 effect size or noncentrality divided by nobs. 
    df_num : int or float 
        Numerator degrees of freedom. 
        This corresponds to the number of constraints in Wald tests. 
    df_denom : int or float 
        Denominator degrees of freedom. 
        This corresponds to the df_resid in Wald tests. 
    alpha : float in interval (0,1) 
        significance level, e.g. 0.05, is the probability of a type I 
        error, that is wrong rejections if the Null Hypothesis is true. 
    ncc : int 
        degrees of freedom correction for non-centrality parameter. 
        see Notes 
 
    Returns 
    ------- 
    power : float 
        Power of the test, e.g. 0.8, is one minus the probability of a 
        type II error. Power is the probability that the test correctly 
        rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
    Notes 
 
    The sample size is given implicitly by ``df_denom`` with fixed number of 
    constraints given by numerator degrees of freedom ``df_num``: 
 
        nobs = df_denom + df_num + ncc 
 
    Set ncc=0 to match t-test, or f-test in LikelihoodModelResults. 
    ncc=1 matches the non-centrality parameter in R::pwr::pwr.f2.test 
 
    ftest_power with ncc=0 should also be correct for f_test in regression 
    models, with df_num (df1) as number of constraints and d_denom (df2) as 
    df_resid. 
    '''</span>

    <span class="s1">nc = effect_size * (df_denom + df_num + ncc)</span>
    <span class="s1">crit = stats.f.isf(alpha</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom)</span>
    <span class="s0"># pow_ = stats.ncf.sf(crit, df_num, df_denom, nc)</span>
    <span class="s0"># use scipy.special for ncf</span>
    <span class="s1">pow_ = ncf_sf(crit</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">nc)</span>
    <span class="s3">return </span><span class="s1">pow_</span>


<span class="s0">#class based implementation</span>
<span class="s0">#--------------------------</span>

<span class="s3">class </span><span class="s1">Power:</span>
    <span class="s2">'''Statistical Power calculations, Base Class 
 
    so far this could all be class methods 
    '''</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s1">self.__dict__.update(kwds)</span>
        <span class="s0"># used only for instance level start values</span>
        <span class="s1">self.start_ttp = dict(effect_size=</span><span class="s4">0.01</span><span class="s3">, </span><span class="s1">nobs=</span><span class="s4">10.</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.15</span><span class="s3">,</span>
                              <span class="s1">power=</span><span class="s4">0.6</span><span class="s3">, </span><span class="s1">nobs1=</span><span class="s4">10.</span><span class="s3">, </span><span class="s1">ratio=</span><span class="s4">1</span><span class="s3">,</span>
                              <span class="s1">df_num=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">df_denom=</span><span class="s4">3   </span><span class="s0"># for FTestPower</span>
                              <span class="s1">)</span>
        <span class="s0"># TODO: nobs1 and ratio are for ttest_ind,</span>
        <span class="s0">#      need start_ttp for each test/class separately,</span>
        <span class="s0"># possible rootfinding problem for effect_size, starting small seems to</span>
        <span class="s0"># work</span>
        <span class="s3">from </span><span class="s1">collections </span><span class="s3">import </span><span class="s1">defaultdict</span>
        <span class="s1">self.start_bqexp = defaultdict(dict)</span>
        <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'nobs'</span><span class="s3">, </span><span class="s5">'nobs1'</span><span class="s3">, </span><span class="s5">'df_num'</span><span class="s3">, </span><span class="s5">'df_denom'</span><span class="s1">]:</span>
            <span class="s1">self.start_bqexp[key] = dict(low=</span><span class="s4">2.</span><span class="s3">, </span><span class="s1">start_upp=</span><span class="s4">50.</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'df_denom'</span><span class="s1">]:</span>
            <span class="s1">self.start_bqexp[key] = dict(low=</span><span class="s4">1.</span><span class="s3">, </span><span class="s1">start_upp=</span><span class="s4">50.</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'ratio'</span><span class="s1">]:</span>
            <span class="s1">self.start_bqexp[key] = dict(low=</span><span class="s4">1e-8</span><span class="s3">, </span><span class="s1">start_upp=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'alpha'</span><span class="s1">]:</span>
            <span class="s1">self.start_bqexp[key] = dict(low=</span><span class="s4">1e-12</span><span class="s3">, </span><span class="s1">upp=</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-12</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">*args</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError</span>

    <span class="s3">def </span><span class="s1">_power_identity(self</span><span class="s3">, </span><span class="s1">*args</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s1">power_ = kwds.pop(</span><span class="s5">'power'</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">self.power(*args</span><span class="s3">, </span><span class="s1">**kwds) - power_</span>

    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s2">'''solve for any one of the parameters of a t-test 
 
        for t-test the keywords are: 
            effect_size, nobs, alpha, power 
 
        exactly one needs to be ``None``, all others need numeric values 
 
        *attaches* 
 
        cache_fit_res : list 
            Cache of the result of the root finding procedure for the latest 
            call to ``solve_power``, mainly for debugging purposes. 
            The first element is the success indicator, one if successful. 
            The remaining elements contain the return information of the up to 
            three solvers that have been tried. 
 
 
        '''</span>
        <span class="s0">#TODO: maybe use explicit kwds,</span>
        <span class="s0">#    nicer but requires inspect? and not generic across tests</span>
        <span class="s0">#    I'm duplicating this in the subclass to get informative docstring</span>
        <span class="s1">key = [k </span><span class="s3">for </span><span class="s1">k</span><span class="s3">,</span><span class="s1">v </span><span class="s3">in </span><span class="s1">kwds.items() </span><span class="s3">if </span><span class="s1">v </span><span class="s3">is None</span><span class="s1">]</span>
        <span class="s0">#print kwds, key</span>
        <span class="s3">if </span><span class="s1">len(key) != </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'need exactly one keyword that is None'</span><span class="s1">)</span>
        <span class="s1">key = key[</span><span class="s4">0</span><span class="s1">]</span>

        <span class="s3">if </span><span class="s1">key == </span><span class="s5">'power'</span><span class="s1">:</span>
            <span class="s3">del </span><span class="s1">kwds[</span><span class="s5">'power'</span><span class="s1">]</span>
            <span class="s3">return </span><span class="s1">self.power(**kwds)</span>

        <span class="s3">if </span><span class="s1">kwds[</span><span class="s5">'effect_size'</span><span class="s1">] == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s3">import </span><span class="s1">warnings</span>
            <span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">HypothesisTestWarning</span>
            <span class="s1">warnings.warn(</span><span class="s5">'Warning: Effect size of 0 detected'</span><span class="s3">, </span><span class="s1">HypothesisTestWarning)</span>
            <span class="s3">if </span><span class="s1">key == </span><span class="s5">'power'</span><span class="s1">:</span>
                <span class="s3">return </span><span class="s1">kwds[</span><span class="s5">'alpha'</span><span class="s1">]</span>
            <span class="s3">if </span><span class="s1">key == </span><span class="s5">'alpha'</span><span class="s1">:</span>
                <span class="s3">return </span><span class="s1">kwds[</span><span class="s5">'power'</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Cannot detect an effect-size of 0. Try changing your effect-size.'</span><span class="s1">)</span>


        <span class="s1">self._counter = </span><span class="s4">0</span>

        <span class="s3">def </span><span class="s1">func(x):</span>
            <span class="s1">kwds[key] = x</span>
            <span class="s1">fval = self._power_identity(**kwds)</span>
            <span class="s1">self._counter += </span><span class="s4">1</span>
            <span class="s0">#print self._counter,</span>
            <span class="s3">if </span><span class="s1">self._counter &gt; </span><span class="s4">500</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">RuntimeError(</span><span class="s5">'possible endless loop (500 NaNs)'</span><span class="s1">)</span>
            <span class="s3">if </span><span class="s1">np.isnan(fval):</span>
                <span class="s3">return </span><span class="s1">np.inf</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">return </span><span class="s1">fval</span>

        <span class="s0">#TODO: I'm using the following so I get a warning when start_ttp is not defined</span>
        <span class="s3">try</span><span class="s1">:</span>
            <span class="s1">start_value = self.start_ttp[key]</span>
        <span class="s3">except </span><span class="s1">KeyError:</span>
            <span class="s1">start_value = </span><span class="s4">0.9</span>
            <span class="s3">import </span><span class="s1">warnings</span>
            <span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">ValueWarning</span>
            <span class="s1">warnings.warn(</span><span class="s5">'Warning: using default start_value for {0}'</span><span class="s1">.format(key)</span><span class="s3">, </span><span class="s1">ValueWarning)</span>

        <span class="s1">fit_kwds = self.start_bqexp[key]</span>
        <span class="s1">fit_res = []</span>
        <span class="s0">#print vars()</span>
        <span class="s3">try</span><span class="s1">:</span>
            <span class="s1">val</span><span class="s3">, </span><span class="s1">res = brentq_expanding(func</span><span class="s3">, </span><span class="s1">full_output=</span><span class="s3">True, </span><span class="s1">**fit_kwds)</span>
            <span class="s1">failed = </span><span class="s3">False</span>
            <span class="s1">fit_res.append(res)</span>
        <span class="s3">except </span><span class="s1">ValueError:</span>
            <span class="s1">failed = </span><span class="s3">True</span>
            <span class="s1">fit_res.append(</span><span class="s3">None</span><span class="s1">)</span>

        <span class="s1">success = </span><span class="s3">None</span>
        <span class="s3">if </span><span class="s1">(</span><span class="s3">not </span><span class="s1">failed) </span><span class="s3">and </span><span class="s1">res.converged:</span>
            <span class="s1">success = </span><span class="s4">1</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s0"># try backup</span>
            <span class="s0"># TODO: check more cases to make this robust</span>
            <span class="s3">if not </span><span class="s1">np.isnan(start_value):</span>
                <span class="s1">val</span><span class="s3">, </span><span class="s1">infodict</span><span class="s3">, </span><span class="s1">ier</span><span class="s3">, </span><span class="s1">msg = optimize.fsolve(func</span><span class="s3">, </span><span class="s1">start_value</span><span class="s3">,</span>
                                                          <span class="s1">full_output=</span><span class="s3">True</span><span class="s1">) </span><span class="s0">#scalar</span>
                <span class="s0">#val = optimize.newton(func, start_value) #scalar</span>
                <span class="s1">fval = infodict[</span><span class="s5">'fvec'</span><span class="s1">]</span>
                <span class="s1">fit_res.append(infodict)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">ier = -</span><span class="s4">1</span>
                <span class="s1">fval = </span><span class="s4">1</span>
                <span class="s1">fit_res.append([</span><span class="s3">None</span><span class="s1">])</span>

            <span class="s3">if </span><span class="s1">ier == </span><span class="s4">1 </span><span class="s3">and </span><span class="s1">np.abs(fval) &lt; </span><span class="s4">1e-4 </span><span class="s1">:</span>
                <span class="s1">success = </span><span class="s4">1</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s0">#print infodict</span>
                <span class="s3">if </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'alpha'</span><span class="s3">, </span><span class="s5">'power'</span><span class="s3">, </span><span class="s5">'effect_size'</span><span class="s1">]:</span>
                    <span class="s1">val</span><span class="s3">, </span><span class="s1">r = optimize.brentq(func</span><span class="s3">, </span><span class="s4">1e-8</span><span class="s3">, </span><span class="s4">1</span><span class="s1">-</span><span class="s4">1e-8</span><span class="s3">,</span>
                                             <span class="s1">full_output=</span><span class="s3">True</span><span class="s1">) </span><span class="s0">#scalar</span>
                    <span class="s1">success = </span><span class="s4">1 </span><span class="s3">if </span><span class="s1">r.converged </span><span class="s3">else </span><span class="s4">0</span>
                    <span class="s1">fit_res.append(r)</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">success = </span><span class="s4">0</span>

        <span class="s3">if not </span><span class="s1">success == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">import </span><span class="s1">warnings</span>
            <span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">(ConvergenceWarning</span><span class="s3">,</span>
                <span class="s1">convergence_doc)</span>
            <span class="s1">warnings.warn(convergence_doc</span><span class="s3">, </span><span class="s1">ConvergenceWarning)</span>

        <span class="s0">#attach fit_res, for reading only, should be needed only for debugging</span>
        <span class="s1">fit_res.insert(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">success)</span>
        <span class="s1">self.cache_fit_res = fit_res</span>
        <span class="s3">return </span><span class="s1">val</span>

    <span class="s3">def </span><span class="s1">plot_power(self</span><span class="s3">, </span><span class="s1">dep_var=</span><span class="s5">'nobs'</span><span class="s3">, </span><span class="s1">nobs=</span><span class="s3">None, </span><span class="s1">effect_size=</span><span class="s3">None,</span>
                   <span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">ax=</span><span class="s3">None, </span><span class="s1">title=</span><span class="s3">None, </span><span class="s1">plt_kwds=</span><span class="s3">None, </span><span class="s1">**kwds):</span>
        <span class="s2">&quot;&quot;&quot; 
        Plot power with number of observations or effect size on x-axis 
 
        Parameters 
        ---------- 
        dep_var : {'nobs', 'effect_size', 'alpha'} 
            This specifies which variable is used for the horizontal axis. 
            If dep_var='nobs' (default), then one curve is created for each 
            value of ``effect_size``. If dep_var='effect_size' or alpha, then 
            one curve is created for each value of ``nobs``. 
        nobs : {scalar, array_like} 
            specifies the values of the number of observations in the plot 
        effect_size : {scalar, array_like} 
            specifies the values of the effect_size in the plot 
        alpha : {float, array_like} 
            The significance level (type I error) used in the power 
            calculation. Can only be more than a scalar, if ``dep_var='alpha'`` 
        ax : None or axis instance 
            If ax is None, than a matplotlib figure is created. If ax is a 
            matplotlib axis instance, then it is reused, and the plot elements 
            are created with it. 
        title : str 
            title for the axis. Use an empty string, ``''``, to avoid a title. 
        plt_kwds : {None, dict} 
            not used yet 
        kwds : dict 
            These remaining keyword arguments are used as arguments to the 
            power function. Many power function support ``alternative`` as a 
            keyword argument, two-sample test support ``ratio``. 
 
        Returns 
        ------- 
        Figure 
            If `ax` is None, the created figure.  Otherwise the figure to which 
            `ax` is connected. 
 
        Notes 
        ----- 
        This works only for classes where the ``power`` method has 
        ``effect_size``, ``nobs`` and ``alpha`` as the first three arguments. 
        If the second argument is ``nobs1``, then the number of observations 
        in the plot are those for the first sample. 
        TODO: fix this for FTestPower and GofChisquarePower 
 
        TODO: maybe add line variable, if we want more than nobs and effectsize 
        &quot;&quot;&quot;</span>
        <span class="s0">#if pwr_kwds is None:</span>
        <span class="s0">#    pwr_kwds = {}</span>
        <span class="s3">from </span><span class="s1">statsmodels.graphics </span><span class="s3">import </span><span class="s1">utils</span>
        <span class="s3">from </span><span class="s1">statsmodels.graphics.plottools </span><span class="s3">import </span><span class="s1">rainbow</span>
        <span class="s1">fig</span><span class="s3">, </span><span class="s1">ax = utils.create_mpl_ax(ax)</span>
        <span class="s3">import </span><span class="s1">matplotlib.pyplot </span><span class="s3">as </span><span class="s1">plt</span>
        <span class="s1">colormap = plt.cm.Dark2 </span><span class="s0">#pylint: disable-msg=E1101</span>
        <span class="s1">plt_alpha = </span><span class="s4">1 </span><span class="s0">#0.75</span>
        <span class="s1">lw = </span><span class="s4">2</span>
        <span class="s3">if </span><span class="s1">dep_var == </span><span class="s5">'nobs'</span><span class="s1">:</span>
            <span class="s1">colors = rainbow(len(effect_size))</span>
            <span class="s1">colors = [colormap(i) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">np.linspace(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s1">len(effect_size))]</span>
            <span class="s3">for </span><span class="s1">ii</span><span class="s3">, </span><span class="s1">es </span><span class="s3">in </span><span class="s1">enumerate(effect_size):</span>
                <span class="s1">power = self.power(es</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">**kwds)</span>
                <span class="s1">ax.plot(nobs</span><span class="s3">, </span><span class="s1">power</span><span class="s3">, </span><span class="s1">lw=lw</span><span class="s3">, </span><span class="s1">alpha=plt_alpha</span><span class="s3">,</span>
                        <span class="s1">color=colors[ii]</span><span class="s3">, </span><span class="s1">label=</span><span class="s5">'es=%4.2F' </span><span class="s1">% es)</span>
                <span class="s1">xlabel = </span><span class="s5">'Number of Observations'</span>
        <span class="s3">elif </span><span class="s1">dep_var </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'effect size'</span><span class="s3">, </span><span class="s5">'effect_size'</span><span class="s3">, </span><span class="s5">'es'</span><span class="s1">]:</span>
            <span class="s1">colors = rainbow(len(nobs))</span>
            <span class="s1">colors = [colormap(i) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">np.linspace(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s1">len(nobs))]</span>
            <span class="s3">for </span><span class="s1">ii</span><span class="s3">, </span><span class="s1">n </span><span class="s3">in </span><span class="s1">enumerate(nobs):</span>
                <span class="s1">power = self.power(effect_size</span><span class="s3">, </span><span class="s1">n</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">**kwds)</span>
                <span class="s1">ax.plot(effect_size</span><span class="s3">, </span><span class="s1">power</span><span class="s3">, </span><span class="s1">lw=lw</span><span class="s3">, </span><span class="s1">alpha=plt_alpha</span><span class="s3">,</span>
                        <span class="s1">color=colors[ii]</span><span class="s3">, </span><span class="s1">label=</span><span class="s5">'N=%4.2F' </span><span class="s1">% n)</span>
                <span class="s1">xlabel = </span><span class="s5">'Effect Size'</span>
        <span class="s3">elif </span><span class="s1">dep_var </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'alpha'</span><span class="s1">]:</span>
            <span class="s0"># experimental nobs as defining separate lines</span>
            <span class="s1">colors = rainbow(len(nobs))</span>

            <span class="s3">for </span><span class="s1">ii</span><span class="s3">, </span><span class="s1">n </span><span class="s3">in </span><span class="s1">enumerate(nobs):</span>
                <span class="s1">power = self.power(effect_size</span><span class="s3">, </span><span class="s1">n</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">**kwds)</span>
                <span class="s1">ax.plot(alpha</span><span class="s3">, </span><span class="s1">power</span><span class="s3">, </span><span class="s1">lw=lw</span><span class="s3">, </span><span class="s1">alpha=plt_alpha</span><span class="s3">,</span>
                        <span class="s1">color=colors[ii]</span><span class="s3">, </span><span class="s1">label=</span><span class="s5">'N=%4.2F' </span><span class="s1">% n)</span>
                <span class="s1">xlabel = </span><span class="s5">'alpha'</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'depvar not implemented'</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">title </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">title = </span><span class="s5">'Power of Test'</span>
        <span class="s1">ax.set_xlabel(xlabel)</span>
        <span class="s1">ax.set_title(title)</span>
        <span class="s1">ax.legend(loc=</span><span class="s5">'lower right'</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>


<span class="s3">class </span><span class="s1">TTestPower(Power):</span>
    <span class="s2">'''Statistical Power calculations for one sample or paired sample t-test 
 
    '''</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">df=</span><span class="s3">None, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a t-test for one sample or paired samples. 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, mean divided by the standard deviation. 
            effect size has to be positive. 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        df : int or float 
            degrees of freedom. By default this is None, and the df from the 
            one sample or paired ttest is used, ``df = nobs1 - 1`` 
        alternative : str, 'two-sided' (default), 'larger', 'smaller' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. The one-sided test can be 
            either 'larger', 'smaller'. 
            . 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
       '''</span>
        <span class="s0"># for debugging</span>
        <span class="s0">#print 'calling ttest power with', (effect_size, nobs, alpha, df, alternative)</span>
        <span class="s3">return </span><span class="s1">ttest_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">df=df</span><span class="s3">,</span>
                           <span class="s1">alternative=alternative)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None,</span>
                    <span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a one sample t-test 
 
        for the one sample t-test the keywords are: 
            effect_size, nobs, alpha, power 
 
        Exactly one needs to be ``None``, all others need numeric values. 
 
        This test can also be used for a paired t-test, where effect size is 
        defined in terms of the mean difference, and nobs is the number of 
        pairs. 
 
        Parameters 
        ---------- 
        effect_size : float 
            Standardized effect size.The effect size is here Cohen's f, square 
            root of &quot;f2&quot;. 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        alternative : str, 'two-sided' (default) or 'one-sided' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. 
            'one-sided' assumes we are in the relevant tail. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
        *attaches* 
 
        cache_fit_res : list 
            Cache of the result of the root finding procedure for the latest 
            call to ``solve_power``, mainly for debugging purposes. 
            The first element is the success indicator, one if successful. 
            The remaining elements contain the return information of the up to 
            three solvers that have been tried. 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s0"># for debugging</span>
        <span class="s0">#print 'calling ttest solve with', (effect_size, nobs, alpha, power, alternative)</span>
        <span class="s3">return </span><span class="s1">super(TTestPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs=nobs</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">alternative=alternative)</span>

<span class="s3">class </span><span class="s1">TTestIndPower(Power):</span>
    <span class="s2">'''Statistical Power calculations for t-test for two independent sample 
 
    currently only uses pooled variance 
 
    '''</span>


    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs1</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ratio=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">df=</span><span class="s3">None,</span>
              <span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a t-test for two independent sample 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, difference between the two means divided 
            by the standard deviation. `effect_size` has to be positive. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
            The default for ratio is 1; to solve for ratio given the other 
            arguments, it has to be explicitly set to None. 
        df : int or float 
            degrees of freedom. By default this is None, and the df from the 
            ttest with pooled variance is used, ``df = (nobs1 - 1 + nobs2 - 1)`` 
        alternative : str, 'two-sided' (default), 'larger', 'smaller' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. The one-sided test can be 
            either 'larger', 'smaller'. 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        '''</span>

        <span class="s1">nobs2 = nobs1*ratio</span>
        <span class="s0">#pooled variance</span>
        <span class="s3">if </span><span class="s1">df </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">df = (nobs1 - </span><span class="s4">1 </span><span class="s1">+ nobs2 - </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s1">nobs = </span><span class="s4">1.</span><span class="s1">/ (</span><span class="s4">1. </span><span class="s1">/ nobs1 + </span><span class="s4">1. </span><span class="s1">/ nobs2)</span>
        <span class="s0">#print 'calling ttest power with', (effect_size, nobs, alpha, df, alternative)</span>
        <span class="s3">return </span><span class="s1">ttest_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">df=df</span><span class="s3">, </span><span class="s1">alternative=alternative)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs1=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None,</span>
                    <span class="s1">ratio=</span><span class="s4">1.</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a two sample t-test 
 
        for t-test the keywords are: 
            effect_size, nobs1, alpha, power, ratio 
 
        exactly one needs to be ``None``, all others need numeric values 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, difference between the two means divided 
            by the standard deviation. `effect_size` has to be positive. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
            The default for ratio is 1; to solve for ratio given the other 
            arguments it has to be explicitly set to None. 
        alternative : str, 'two-sided' (default), 'larger', 'smaller' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. The one-sided test can be 
            either 'larger', 'smaller'. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s3">return </span><span class="s1">super(TTestIndPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs1=nobs1</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">ratio=ratio</span><span class="s3">,</span>
                                                      <span class="s1">alternative=alternative)</span>

<span class="s3">class </span><span class="s1">NormalIndPower(Power):</span>
    <span class="s2">'''Statistical Power calculations for z-test for two independent samples. 
 
    currently only uses pooled variance 
 
    '''</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">ddof=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s1">self.ddof = ddof</span>
        <span class="s1">super(NormalIndPower</span><span class="s3">, </span><span class="s1">self).__init__(**kwds)</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs1</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ratio=</span><span class="s4">1</span><span class="s3">,</span>
              <span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a z-test for two independent sample 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, difference between the two means divided 
            by the standard deviation. effect size has to be positive. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
            ``ratio`` can be set to zero in order to get the power for a 
            one sample test. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
        alternative : str, 'two-sided' (default), 'larger', 'smaller' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. The one-sided test can be 
            either 'larger', 'smaller'. 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        '''</span>

        <span class="s1">ddof = self.ddof  </span><span class="s0"># for correlation, ddof=3</span>

        <span class="s0"># get effective nobs, factor for std of test statistic</span>
        <span class="s3">if </span><span class="s1">ratio &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">nobs2 = nobs1*ratio</span>
            <span class="s0">#equivalent to nobs = n1*n2/(n1+n2)=n1*ratio/(1+ratio)</span>
            <span class="s1">nobs = </span><span class="s4">1.</span><span class="s1">/ (</span><span class="s4">1. </span><span class="s1">/ (nobs1 - ddof) + </span><span class="s4">1. </span><span class="s1">/ (nobs2 - ddof))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">nobs = nobs1 - ddof</span>
        <span class="s3">return </span><span class="s1">normal_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">alternative=alternative)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs1=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None,</span>
                    <span class="s1">ratio=</span><span class="s4">1.</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a two sample z-test 
 
        for z-test the keywords are: 
            effect_size, nobs1, alpha, power, ratio 
 
        exactly one needs to be ``None``, all others need numeric values 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, difference between the two means divided 
            by the standard deviation. 
            If ratio=0, then this is the standardized mean in the one sample 
            test. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
            ``ratio`` can be set to zero in order to get the power for a 
            one sample test. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
            The default for ratio is 1; to solve for ration given the other 
            arguments it has to be explicitly set to None. 
        alternative : str, 'two-sided' (default), 'larger', 'smaller' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. The one-sided test can be 
            either 'larger', 'smaller'. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s3">return </span><span class="s1">super(NormalIndPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs1=nobs1</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">ratio=ratio</span><span class="s3">,</span>
                                                      <span class="s1">alternative=alternative)</span>


<span class="s3">class </span><span class="s1">FTestPower(Power):</span>
    <span class="s2">&quot;&quot;&quot;Statistical Power calculations for generic F-test of a constraint 
 
    This class is not recommended, use `FTestPowerF2` with corrected interface. 
 
    This is based on Cohen's f as effect size measure. 
 
    Warning: Methods in this class have the names df_num and df_denom reversed. 
 
    See Also 
    -------- 
    FTestPowerF2 : 
        Class with Cohen's f-squared as effect size, corrected keyword names. 
 
    Examples 
    -------- 
    Sample size and power for multiple regression base on R-squared 
 
    Compute effect size from R-squared 
 
    &gt;&gt;&gt; r2 = 0.1 
    &gt;&gt;&gt; f2 = r2 / (1 - r2) 
    &gt;&gt;&gt; f = np.sqrt(f2) 
    &gt;&gt;&gt; r2, f2, f 
    (0.1, 0.11111111111111112, 0.33333333333333337) 
 
    Find sample size by solving for denominator df, wrongly named ``df_num`` 
 
    &gt;&gt;&gt; df1 = 1  # number of constraints in hypothesis test 
    &gt;&gt;&gt; df2 = FTestPower().solve_power(effect_size=f, alpha=0.1, power=0.9, 
                                       df_denom=df1) 
    &gt;&gt;&gt; ncc = 1  # default 
    &gt;&gt;&gt; nobs = df2 + df1 + ncc 
    &gt;&gt;&gt; df2, nobs 
    (76.46459758305376, 78.46459758305376) 
 
    verify power at df2 
 
    &gt;&gt;&gt; FTestPower().power(effect_size=f, alpha=0.1, df_denom=df1, df_num=df2) 
    0.8999999972109698 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a F-test. 
 
        The effect size is Cohen's ``f``, square root of ``f2``. 
 
        The sample size is given by ``nobs = df_denom + df_num + ncc`` 
 
        Warning: The meaning of df_num and df_denom is reversed. 
 
        Parameters 
        ---------- 
        effect_size : float 
            Standardized effect size. The effect size is here Cohen's ``f``, 
            square root of ``f2``. 
        df_num : int or float 
            Warning incorrect name 
            denominator degrees of freedom, 
            This corresponds to the number of constraints in Wald tests. 
        df_denom : int or float 
            Warning incorrect name 
            numerator degrees of freedom. 
            This corresponds to the df_resid in Wald tests. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        ncc : int 
            degrees of freedom correction for non-centrality parameter. 
            see Notes 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        Notes 
        ----- 
 
        sample size is given implicitly by df_num 
 
        set ncc=0 to match t-test, or f-test in LikelihoodModelResults. 
        ncc=1 matches the non-centrality parameter in R::pwr::pwr.f2.test 
 
        ftest_power with ncc=0 should also be correct for f_test in regression 
        models, with df_num and d_denom as defined there. (not verified yet) 
        '''</span>

        <span class="s1">pow_ = ftest_power(effect_size</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=ncc)</span>
        <span class="s0">#print effect_size, df_num, df_denom, alpha, pow_</span>
        <span class="s3">return </span><span class="s1">pow_</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">df_num=</span><span class="s3">None, </span><span class="s1">df_denom=</span><span class="s3">None,</span>
                    <span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s2">'''solve for any one parameter of the power of a F-test 
 
        for the one sample F-test the keywords are: 
            effect_size, df_num, df_denom, alpha, power 
 
        Exactly one needs to be ``None``, all others need numeric values. 
 
        The effect size is Cohen's ``f``, square root of ``f2``. 
 
        The sample size is given by ``nobs = df_denom + df_num + ncc``. 
 
        Warning: The meaning of df_num and df_denom is reversed. 
 
        Parameters 
        ---------- 
        effect_size : float 
            Standardized effect size. The effect size is here Cohen's ``f``, 
            square root of ``f2``. 
        df_num : int or float 
            Warning incorrect name 
            denominator degrees of freedom, 
            This corresponds to the number of constraints in Wald tests. 
            Sample size is given by ``nobs = df_denom + df_num + ncc`` 
        df_denom : int or float 
            Warning incorrect name 
            numerator degrees of freedom. 
            This corresponds to the df_resid in Wald tests. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        ncc : int 
            degrees of freedom correction for non-centrality parameter. 
            see Notes 
        kwargs : empty 
            ``kwargs`` are not used and included for backwards compatibility. 
            If ``nobs`` is used as keyword, then a warning is issued. All 
            other keywords in ``kwargs`` raise a ValueError. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The method uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s3">if </span><span class="s1">kwargs:</span>
            <span class="s3">if </span><span class="s5">&quot;nobs&quot; </span><span class="s3">in </span><span class="s1">kwargs:</span>
                <span class="s1">warnings.warn(</span><span class="s5">&quot;nobs is not used&quot;</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;incorrect keyword(s) </span><span class="s3">{</span><span class="s1">kwargs</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">super(FTestPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">df_num=df_num</span><span class="s3">,</span>
                                                      <span class="s1">df_denom=df_denom</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">ncc=ncc)</span>



<span class="s3">class </span><span class="s1">FTestPowerF2(Power):</span>
    <span class="s2">&quot;&quot;&quot;Statistical Power calculations for generic F-test of a constraint 
 
    This is based on Cohen's f^2 as effect size measure. 
 
    Examples 
    -------- 
    Sample size and power for multiple regression base on R-squared 
 
    Compute effect size from R-squared 
 
    &gt;&gt;&gt; r2 = 0.1 
    &gt;&gt;&gt; f2 = r2 / (1 - r2) 
    &gt;&gt;&gt; f = np.sqrt(f2) 
    &gt;&gt;&gt; r2, f2, f 
    (0.1, 0.11111111111111112, 0.33333333333333337) 
 
    Find sample size by solving for denominator degrees of freedom. 
 
    &gt;&gt;&gt; df1 = 1  # number of constraints in hypothesis test 
    &gt;&gt;&gt; df2 = FTestPowerF2().solve_power(effect_size=f2, alpha=0.1, power=0.9, 
                                         df_num=df1) 
    &gt;&gt;&gt; ncc = 1  # default 
    &gt;&gt;&gt; nobs = df2 + df1 + ncc 
    &gt;&gt;&gt; df2, nobs 
    (76.46459758305376, 78.46459758305376) 
 
    verify power at df2 
 
    &gt;&gt;&gt; FTestPowerF2().power(effect_size=f, alpha=0.1, df_num=df1, df_denom=df2) 
    0.8999999972109698 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a F-test. 
 
        The effect size is Cohen's ``f^2``. 
 
        The sample size is given by ``nobs = df_denom + df_num + ncc`` 
 
        Parameters 
        ---------- 
        effect_size : float 
            The effect size is here Cohen's ``f2``. This is equal to 
            the noncentrality of an F-test divided by nobs. 
        df_num : int or float 
            Numerator degrees of freedom, 
            This corresponds to the number of constraints in Wald tests. 
        df_denom : int or float 
            Denominator degrees of freedom. 
            This corresponds to the df_resid in Wald tests. 
        alpha : float in interval (0,1) 
            Significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        ncc : int 
            Degrees of freedom correction for non-centrality parameter. 
            see Notes 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        Notes 
        ----- 
        The sample size is given implicitly by df_denom 
 
        set ncc=0 to match t-test, or f-test in LikelihoodModelResults. 
        ncc=1 matches the non-centrality parameter in R::pwr::pwr.f2.test 
 
        ftest_power with ncc=0 should also be correct for f_test in regression 
        models, with df_num and d_denom as defined there. (not verified yet) 
        '''</span>

        <span class="s1">pow_ = ftest_power_f2(effect_size</span><span class="s3">, </span><span class="s1">df_num</span><span class="s3">, </span><span class="s1">df_denom</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ncc=ncc)</span>
        <span class="s3">return </span><span class="s1">pow_</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">df_num=</span><span class="s3">None, </span><span class="s1">df_denom=</span><span class="s3">None,</span>
                    <span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None, </span><span class="s1">ncc=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">'''Solve for any one parameter of the power of a F-test 
 
        for the one sample F-test the keywords are: 
            effect_size, df_num, df_denom, alpha, power 
 
        Exactly one needs to be ``None``, all others need numeric values. 
 
        The effect size is Cohen's ``f2``. 
 
        The sample size is given by ``nobs = df_denom + df_num + ncc``, and 
        can be found by solving for df_denom. 
 
        Parameters 
        ---------- 
        effect_size : float 
            The effect size is here Cohen's ``f2``. This is equal to 
            the noncentrality of an F-test divided by nobs. 
        df_num : int or float 
            Numerator degrees of freedom, 
            This corresponds to the number of constraints in Wald tests. 
        df_denom : int or float 
            Denominator degrees of freedom. 
            This corresponds to the df_resid in Wald tests. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        ncc : int 
            degrees of freedom correction for non-centrality parameter. 
            see Notes 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>

        <span class="s3">return </span><span class="s1">super(FTestPowerF2</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">df_num=df_num</span><span class="s3">,</span>
                                                      <span class="s1">df_denom=df_denom</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">ncc=ncc)</span>


<span class="s3">class </span><span class="s1">FTestAnovaPower(Power):</span>
    <span class="s2">'''Statistical Power calculations F-test for one factor balanced ANOVA 
 
    This is based on Cohen's f as effect size measure. 
 
    See Also 
    -------- 
    statsmodels.stats.oneway.effectsize_oneway 
 
    '''</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">k_groups=</span><span class="s4">2</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a F-test for one factor ANOVA. 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size. The effect size is here Cohen's f, square 
            root of &quot;f2&quot;. 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        k_groups : int or float 
            number of groups in the ANOVA or k-sample comparison. Default is 2. 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
       '''</span>
        <span class="s3">return </span><span class="s1">ftest_anova_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">k_groups=k_groups)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None,</span>
                    <span class="s1">k_groups=</span><span class="s4">2</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a F-test 
 
        for the one sample F-test the keywords are: 
            effect_size, nobs, alpha, power 
 
        Exactly one needs to be ``None``, all others need numeric values. 
 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, mean divided by the standard deviation. 
            effect size has to be positive. 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s0"># update start values for root finding</span>
        <span class="s3">if </span><span class="s1">k_groups </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">self.start_ttp[</span><span class="s5">'nobs'</span><span class="s1">] = k_groups * </span><span class="s4">10</span>
            <span class="s1">self.start_bqexp[</span><span class="s5">'nobs'</span><span class="s1">] = dict(low=k_groups * </span><span class="s4">2</span><span class="s3">,</span>
                                            <span class="s1">start_upp=k_groups * </span><span class="s4">10</span><span class="s1">)</span>
        <span class="s0"># first attempt at special casing</span>
        <span class="s3">if </span><span class="s1">effect_size </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">self._solve_effect_size(effect_size=effect_size</span><span class="s3">,</span>
                                           <span class="s1">nobs=nobs</span><span class="s3">,</span>
                                           <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                           <span class="s1">k_groups=k_groups</span><span class="s3">,</span>
                                           <span class="s1">power=power)</span>

        <span class="s3">return </span><span class="s1">super(FTestAnovaPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs=nobs</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">k_groups=k_groups</span><span class="s3">,</span>
                                                      <span class="s1">power=power)</span>

    <span class="s3">def </span><span class="s1">_solve_effect_size(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None,</span>
                           <span class="s1">power=</span><span class="s3">None, </span><span class="s1">k_groups=</span><span class="s4">2</span><span class="s1">):</span>
        <span class="s2">'''experimental, test failure in solve_power for effect_size 
        '''</span>
        <span class="s3">def </span><span class="s1">func(x):</span>
            <span class="s1">effect_size = x</span>
            <span class="s3">return </span><span class="s1">self._power_identity(effect_size=effect_size</span><span class="s3">,</span>
                                          <span class="s1">nobs=nobs</span><span class="s3">,</span>
                                          <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                          <span class="s1">k_groups=k_groups</span><span class="s3">,</span>
                                          <span class="s1">power=power)</span>

        <span class="s1">val</span><span class="s3">, </span><span class="s1">r = optimize.brentq(func</span><span class="s3">, </span><span class="s4">1e-8</span><span class="s3">, </span><span class="s4">1</span><span class="s1">-</span><span class="s4">1e-8</span><span class="s3">, </span><span class="s1">full_output=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s3">if not </span><span class="s1">r.converged:</span>
            <span class="s1">print(r)</span>
        <span class="s3">return </span><span class="s1">val</span>


<span class="s3">class </span><span class="s1">GofChisquarePower(Power):</span>
    <span class="s2">'''Statistical Power calculations for one sample chisquare test 
 
    '''</span>

    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">, </span><span class="s1">ddof=</span><span class="s4">0</span><span class="s1">):</span><span class="s0">#alternative='two-sided'):</span>
        <span class="s2">'''Calculate the power of a chisquare test for one sample 
 
        Only two-sided alternative is implemented 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, according to Cohen's definition. 
            see :func:`statsmodels.stats.gof.chisquare_effectsize` 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        n_bins : int 
            number of bins or cells in the distribution. 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
       '''</span>
        <span class="s3">from </span><span class="s1">statsmodels.stats.gof </span><span class="s3">import </span><span class="s1">chisquare_power</span>
        <span class="s3">return </span><span class="s1">chisquare_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ddof=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None,</span>
                    <span class="s1">power=</span><span class="s3">None, </span><span class="s1">n_bins=</span><span class="s4">2</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a one sample chisquare-test 
 
        for the one sample chisquare-test the keywords are: 
            effect_size, nobs, alpha, power 
 
        Exactly one needs to be ``None``, all others need numeric values. 
 
        n_bins needs to be defined, a default=2 is used. 
 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardized effect size, according to Cohen's definition. 
            see :func:`statsmodels.stats.gof.chisquare_effectsize` 
        nobs : int or float 
            sample size, number of observations. 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        n_bins : int 
            number of bins or cells in the distribution 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s3">return </span><span class="s1">super(GofChisquarePower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs=nobs</span><span class="s3">,</span>
                                                      <span class="s1">n_bins=n_bins</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power)</span>

<span class="s3">class </span><span class="s1">_GofChisquareIndPower(Power):</span>
    <span class="s2">'''Statistical Power calculations for chisquare goodness-of-fit test 
 
    TODO: this is not working yet 
          for 2sample case need two nobs in function 
          no one-sided chisquare test, is there one? use normal distribution? 
          -&gt; drop one-sided options? 
    '''</span>


    <span class="s3">def </span><span class="s1">power(self</span><span class="s3">, </span><span class="s1">effect_size</span><span class="s3">, </span><span class="s1">nobs1</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">ratio=</span><span class="s4">1</span><span class="s3">,</span>
              <span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''Calculate the power of a chisquare for two independent sample 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardize effect size, difference between the two means divided 
            by the standard deviation. effect size has to be positive. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
            The default for ratio is 1; to solve for ration given the other 
            arguments it has to be explicitely set to None. 
        alternative : str, 'two-sided' (default) or 'one-sided' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. 
            'one-sided' assumes we are in the relevant tail. 
 
        Returns 
        ------- 
        power : float 
            Power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
 
        '''</span>

        <span class="s3">from </span><span class="s1">statsmodels.stats.gof </span><span class="s3">import </span><span class="s1">chisquare_power</span>
        <span class="s1">nobs2 = nobs1*ratio</span>
        <span class="s0">#equivalent to nobs = n1*n2/(n1+n2)=n1*ratio/(1+ratio)</span>
        <span class="s1">nobs = </span><span class="s4">1.</span><span class="s1">/ (</span><span class="s4">1. </span><span class="s1">/ nobs1 + </span><span class="s4">1. </span><span class="s1">/ nobs2)</span>
        <span class="s3">return </span><span class="s1">chisquare_power(effect_size</span><span class="s3">, </span><span class="s1">nobs</span><span class="s3">, </span><span class="s1">alpha)</span>

    <span class="s0">#method is only added to have explicit keywords and docstring</span>
    <span class="s3">def </span><span class="s1">solve_power(self</span><span class="s3">, </span><span class="s1">effect_size=</span><span class="s3">None, </span><span class="s1">nobs1=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s3">None, </span><span class="s1">power=</span><span class="s3">None,</span>
                    <span class="s1">ratio=</span><span class="s4">1.</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''solve for any one parameter of the power of a two sample z-test 
 
        for z-test the keywords are: 
            effect_size, nobs1, alpha, power, ratio 
 
        exactly one needs to be ``None``, all others need numeric values 
 
        Parameters 
        ---------- 
        effect_size : float 
            standardize effect size, difference between the two means divided 
            by the standard deviation. 
        nobs1 : int or float 
            number of observations of sample 1. The number of observations of 
            sample two is ratio times the size of sample 1, 
            i.e. ``nobs2 = nobs1 * ratio`` 
        alpha : float in interval (0,1) 
            significance level, e.g. 0.05, is the probability of a type I 
            error, that is wrong rejections if the Null Hypothesis is true. 
        power : float in interval (0,1) 
            power of the test, e.g. 0.8, is one minus the probability of a 
            type II error. Power is the probability that the test correctly 
            rejects the Null Hypothesis if the Alternative Hypothesis is true. 
        ratio : float 
            ratio of the number of observations in sample 2 relative to 
            sample 1. see description of nobs1 
            The default for ratio is 1; to solve for ration given the other 
            arguments it has to be explicitely set to None. 
        alternative : str, 'two-sided' (default) or 'one-sided' 
            extra argument to choose whether the power is calculated for a 
            two-sided (default) or one sided test. 
            'one-sided' assumes we are in the relevant tail. 
 
        Returns 
        ------- 
        value : float 
            The value of the parameter that was set to None in the call. The 
            value solves the power equation given the remaining parameters. 
 
 
        Notes 
        ----- 
        The function uses scipy.optimize for finding the value that satisfies 
        the power equation. It first uses ``brentq`` with a prior search for 
        bounds. If this fails to find a root, ``fsolve`` is used. If ``fsolve`` 
        also fails, then, for ``alpha``, ``power`` and ``effect_size``, 
        ``brentq`` with fixed bounds is used. However, there can still be cases 
        where this fails. 
 
        '''</span>
        <span class="s3">return </span><span class="s1">super(_GofChisquareIndPower</span><span class="s3">, </span><span class="s1">self).solve_power(effect_size=effect_size</span><span class="s3">,</span>
                                                      <span class="s1">nobs1=nobs1</span><span class="s3">,</span>
                                                      <span class="s1">alpha=alpha</span><span class="s3">,</span>
                                                      <span class="s1">power=power</span><span class="s3">,</span>
                                                      <span class="s1">ratio=ratio</span><span class="s3">,</span>
                                                      <span class="s1">alternative=alternative)</span>

<span class="s0">#shortcut functions</span>
<span class="s1">tt_solve_power = TTestPower().solve_power</span>
<span class="s1">tt_ind_solve_power = TTestIndPower().solve_power</span>
<span class="s1">zt_ind_solve_power = NormalIndPower().solve_power</span>
</pre>
</body>
</html>
<html>
<head>
<title>trf_linear.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
trf_linear.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;The adaptation of Trust Region Reflective algorithm for a linear 
least-squares problem.&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy.linalg </span><span class="s2">import </span><span class="s1">norm</span>
<span class="s2">from </span><span class="s1">scipy.linalg </span><span class="s2">import </span><span class="s1">qr</span><span class="s2">, </span><span class="s1">solve_triangular</span>
<span class="s2">from </span><span class="s1">scipy.sparse.linalg </span><span class="s2">import </span><span class="s1">lsmr</span>
<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">OptimizeResult</span>

<span class="s2">from </span><span class="s1">.givens_elimination </span><span class="s2">import </span><span class="s1">givens_elimination</span>
<span class="s2">from </span><span class="s1">.common </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">EPS</span><span class="s2">, </span><span class="s1">step_size_to_bound</span><span class="s2">, </span><span class="s1">find_active_constraints</span><span class="s2">, </span><span class="s1">in_bounds</span><span class="s2">,</span>
    <span class="s1">make_strictly_feasible</span><span class="s2">, </span><span class="s1">build_quadratic_1d</span><span class="s2">, </span><span class="s1">evaluate_quadratic</span><span class="s2">,</span>
    <span class="s1">minimize_quadratic_1d</span><span class="s2">, </span><span class="s1">CL_scaling_vector</span><span class="s2">, </span><span class="s1">reflective_transformation</span><span class="s2">,</span>
    <span class="s1">print_header_linear</span><span class="s2">, </span><span class="s1">print_iteration_linear</span><span class="s2">, </span><span class="s1">compute_grad</span><span class="s2">,</span>
    <span class="s1">regularized_lsq_operator</span><span class="s2">, </span><span class="s1">right_multiplied_operator)</span>


<span class="s2">def </span><span class="s1">regularized_lsq_with_qr(m</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">R</span><span class="s2">, </span><span class="s1">QTb</span><span class="s2">, </span><span class="s1">perm</span><span class="s2">, </span><span class="s1">diag</span><span class="s2">, </span><span class="s1">copy_R=</span><span class="s2">True</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Solve regularized least squares using information from QR-decomposition. 
 
    The initial problem is to solve the following system in a least-squares 
    sense:: 
 
        A x = b 
        D x = 0 
 
    where D is diagonal matrix. The method is based on QR decomposition 
    of the form A P = Q R, where P is a column permutation matrix, Q is an 
    orthogonal matrix and R is an upper triangular matrix. 
 
    Parameters 
    ---------- 
    m, n : int 
        Initial shape of A. 
    R : ndarray, shape (n, n) 
        Upper triangular matrix from QR decomposition of A. 
    QTb : ndarray, shape (n,) 
        First n components of Q^T b. 
    perm : ndarray, shape (n,) 
        Array defining column permutation of A, such that ith column of 
        P is perm[i]-th column of identity matrix. 
    diag : ndarray, shape (n,) 
        Array containing diagonal elements of D. 
 
    Returns 
    ------- 
    x : ndarray, shape (n,) 
        Found least-squares solution. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">copy_R:</span>
        <span class="s1">R = R.copy()</span>
    <span class="s1">v = QTb.copy()</span>

    <span class="s1">givens_elimination(R</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">diag[perm])</span>

    <span class="s1">abs_diag_R = np.abs(np.diag(R))</span>
    <span class="s1">threshold = EPS * max(m</span><span class="s2">, </span><span class="s1">n) * np.max(abs_diag_R)</span>
    <span class="s1">nns</span><span class="s2">, </span><span class="s1">= np.nonzero(abs_diag_R &gt; threshold)</span>

    <span class="s1">R = R[np.ix_(nns</span><span class="s2">, </span><span class="s1">nns)]</span>
    <span class="s1">v = v[nns]</span>

    <span class="s1">x = np.zeros(n)</span>
    <span class="s1">x[perm[nns]] = solve_triangular(R</span><span class="s2">, </span><span class="s1">v)</span>

    <span class="s2">return </span><span class="s1">x</span>


<span class="s2">def </span><span class="s1">backtracking(A</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">theta</span><span class="s2">, </span><span class="s1">p_dot_g</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub):</span>
    <span class="s0">&quot;&quot;&quot;Find an appropriate step size using backtracking line search.&quot;&quot;&quot;</span>
    <span class="s1">alpha = </span><span class="s3">1</span>
    <span class="s2">while True</span><span class="s1">:</span>
        <span class="s1">x_new</span><span class="s2">, </span><span class="s1">_ = reflective_transformation(x + alpha * p</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
        <span class="s1">step = x_new - x</span>
        <span class="s1">cost_change = -evaluate_quadratic(A</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">step)</span>
        <span class="s2">if </span><span class="s1">cost_change &gt; -</span><span class="s3">0.1 </span><span class="s1">* alpha * p_dot_g:</span>
            <span class="s2">break</span>
        <span class="s1">alpha *= </span><span class="s3">0.5</span>

    <span class="s1">active = find_active_constraints(x_new</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
    <span class="s2">if </span><span class="s1">np.any(active != </span><span class="s3">0</span><span class="s1">):</span>
        <span class="s1">x_new</span><span class="s2">, </span><span class="s1">_ = reflective_transformation(x + theta * alpha * p</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
        <span class="s1">x_new = make_strictly_feasible(x_new</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">rstep=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">step = x_new - x</span>
        <span class="s1">cost_change = -evaluate_quadratic(A</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">step)</span>

    <span class="s2">return </span><span class="s1">x</span><span class="s2">, </span><span class="s1">step</span><span class="s2">, </span><span class="s1">cost_change</span>


<span class="s2">def </span><span class="s1">select_step(x</span><span class="s2">, </span><span class="s1">A_h</span><span class="s2">, </span><span class="s1">g_h</span><span class="s2">, </span><span class="s1">c_h</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">p_h</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">theta):</span>
    <span class="s0">&quot;&quot;&quot;Select the best step according to Trust Region Reflective algorithm.&quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">in_bounds(x + p</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub):</span>
        <span class="s2">return </span><span class="s1">p</span>

    <span class="s1">p_stride</span><span class="s2">, </span><span class="s1">hits = step_size_to_bound(x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
    <span class="s1">r_h = np.copy(p_h)</span>
    <span class="s1">r_h[hits.astype(bool)] *= -</span><span class="s3">1</span>
    <span class="s1">r = d * r_h</span>

    <span class="s4"># Restrict step, such that it hits the bound.</span>
    <span class="s1">p *= p_stride</span>
    <span class="s1">p_h *= p_stride</span>
    <span class="s1">x_on_bound = x + p</span>

    <span class="s4"># Find the step size along reflected direction.</span>
    <span class="s1">r_stride_u</span><span class="s2">, </span><span class="s1">_ = step_size_to_bound(x_on_bound</span><span class="s2">, </span><span class="s1">r</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>

    <span class="s4"># Stay interior.</span>
    <span class="s1">r_stride_l = (</span><span class="s3">1 </span><span class="s1">- theta) * r_stride_u</span>
    <span class="s1">r_stride_u *= theta</span>

    <span class="s2">if </span><span class="s1">r_stride_u &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">c = build_quadratic_1d(A_h</span><span class="s2">, </span><span class="s1">g_h</span><span class="s2">, </span><span class="s1">r_h</span><span class="s2">, </span><span class="s1">s0=p_h</span><span class="s2">, </span><span class="s1">diag=c_h)</span>
        <span class="s1">r_stride</span><span class="s2">, </span><span class="s1">r_value = minimize_quadratic_1d(</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">r_stride_l</span><span class="s2">, </span><span class="s1">r_stride_u</span><span class="s2">, </span><span class="s1">c=c)</span>
        <span class="s1">r_h = p_h + r_h * r_stride</span>
        <span class="s1">r = d * r_h</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">r_value = np.inf</span>

    <span class="s4"># Now correct p_h to make it strictly interior.</span>
    <span class="s1">p_h *= theta</span>
    <span class="s1">p *= theta</span>
    <span class="s1">p_value = evaluate_quadratic(A_h</span><span class="s2">, </span><span class="s1">g_h</span><span class="s2">, </span><span class="s1">p_h</span><span class="s2">, </span><span class="s1">diag=c_h)</span>

    <span class="s1">ag_h = -g_h</span>
    <span class="s1">ag = d * ag_h</span>
    <span class="s1">ag_stride_u</span><span class="s2">, </span><span class="s1">_ = step_size_to_bound(x</span><span class="s2">, </span><span class="s1">ag</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
    <span class="s1">ag_stride_u *= theta</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">b = build_quadratic_1d(A_h</span><span class="s2">, </span><span class="s1">g_h</span><span class="s2">, </span><span class="s1">ag_h</span><span class="s2">, </span><span class="s1">diag=c_h)</span>
    <span class="s1">ag_stride</span><span class="s2">, </span><span class="s1">ag_value = minimize_quadratic_1d(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s1">ag_stride_u)</span>
    <span class="s1">ag *= ag_stride</span>

    <span class="s2">if </span><span class="s1">p_value &lt; r_value </span><span class="s2">and </span><span class="s1">p_value &lt; ag_value:</span>
        <span class="s2">return </span><span class="s1">p</span>
    <span class="s2">elif </span><span class="s1">r_value &lt; p_value </span><span class="s2">and </span><span class="s1">r_value &lt; ag_value:</span>
        <span class="s2">return </span><span class="s1">r</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">ag</span>


<span class="s2">def </span><span class="s1">trf_linear(A</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">x_lsq</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">, </span><span class="s1">lsq_solver</span><span class="s2">, </span><span class="s1">lsmr_tol</span><span class="s2">,</span>
               <span class="s1">max_iter</span><span class="s2">, </span><span class="s1">verbose</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">lsmr_maxiter=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s1">m</span><span class="s2">, </span><span class="s1">n = A.shape</span>
    <span class="s1">x</span><span class="s2">, </span><span class="s1">_ = reflective_transformation(x_lsq</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
    <span class="s1">x = make_strictly_feasible(x</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">rstep=</span><span class="s3">0.1</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">lsq_solver == </span><span class="s5">'exact'</span><span class="s1">:</span>
        <span class="s1">QT</span><span class="s2">, </span><span class="s1">R</span><span class="s2">, </span><span class="s1">perm = qr(A</span><span class="s2">, </span><span class="s1">mode=</span><span class="s5">'economic'</span><span class="s2">, </span><span class="s1">pivoting=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">QT = QT.T</span>

        <span class="s2">if </span><span class="s1">m &lt; n:</span>
            <span class="s1">R = np.vstack((R</span><span class="s2">, </span><span class="s1">np.zeros((n - m</span><span class="s2">, </span><span class="s1">n))))</span>

        <span class="s1">QTr = np.zeros(n)</span>
        <span class="s1">k = min(m</span><span class="s2">, </span><span class="s1">n)</span>
    <span class="s2">elif </span><span class="s1">lsq_solver == </span><span class="s5">'lsmr'</span><span class="s1">:</span>
        <span class="s1">r_aug = np.zeros(m + n)</span>
        <span class="s1">auto_lsmr_tol = </span><span class="s2">False</span>
        <span class="s2">if </span><span class="s1">lsmr_tol </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lsmr_tol = </span><span class="s3">1e-2 </span><span class="s1">* tol</span>
        <span class="s2">elif </span><span class="s1">lsmr_tol == </span><span class="s5">'auto'</span><span class="s1">:</span>
            <span class="s1">auto_lsmr_tol = </span><span class="s2">True</span>

    <span class="s1">r = A.dot(x) - b</span>
    <span class="s1">g = compute_grad(A</span><span class="s2">, </span><span class="s1">r)</span>
    <span class="s1">cost = </span><span class="s3">0.5 </span><span class="s1">* np.dot(r</span><span class="s2">, </span><span class="s1">r)</span>
    <span class="s1">initial_cost = cost</span>

    <span class="s1">termination_status = </span><span class="s2">None</span>
    <span class="s1">step_norm = </span><span class="s2">None</span>
    <span class="s1">cost_change = </span><span class="s2">None</span>

    <span class="s2">if </span><span class="s1">max_iter </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">max_iter = </span><span class="s3">100</span>

    <span class="s2">if </span><span class="s1">verbose == </span><span class="s3">2</span><span class="s1">:</span>
        <span class="s1">print_header_linear()</span>

    <span class="s2">for </span><span class="s1">iteration </span><span class="s2">in </span><span class="s1">range(max_iter):</span>
        <span class="s1">v</span><span class="s2">, </span><span class="s1">dv = CL_scaling_vector(x</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
        <span class="s1">g_scaled = g * v</span>
        <span class="s1">g_norm = norm(g_scaled</span><span class="s2">, </span><span class="s1">ord=np.inf)</span>
        <span class="s2">if </span><span class="s1">g_norm &lt; tol:</span>
            <span class="s1">termination_status = </span><span class="s3">1</span>

        <span class="s2">if </span><span class="s1">verbose == </span><span class="s3">2</span><span class="s1">:</span>
            <span class="s1">print_iteration_linear(iteration</span><span class="s2">, </span><span class="s1">cost</span><span class="s2">, </span><span class="s1">cost_change</span><span class="s2">,</span>
                                   <span class="s1">step_norm</span><span class="s2">, </span><span class="s1">g_norm)</span>

        <span class="s2">if </span><span class="s1">termination_status </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">break</span>

        <span class="s1">diag_h = g * dv</span>
        <span class="s1">diag_root_h = diag_h ** </span><span class="s3">0.5</span>
        <span class="s1">d = v ** </span><span class="s3">0.5</span>
        <span class="s1">g_h = d * g</span>

        <span class="s1">A_h = right_multiplied_operator(A</span><span class="s2">, </span><span class="s1">d)</span>
        <span class="s2">if </span><span class="s1">lsq_solver == </span><span class="s5">'exact'</span><span class="s1">:</span>
            <span class="s1">QTr[:k] = QT.dot(r)</span>
            <span class="s1">p_h = -regularized_lsq_with_qr(m</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">R * d[perm]</span><span class="s2">, </span><span class="s1">QTr</span><span class="s2">, </span><span class="s1">perm</span><span class="s2">,</span>
                                           <span class="s1">diag_root_h</span><span class="s2">, </span><span class="s1">copy_R=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">lsq_solver == </span><span class="s5">'lsmr'</span><span class="s1">:</span>
            <span class="s1">lsmr_op = regularized_lsq_operator(A_h</span><span class="s2">, </span><span class="s1">diag_root_h)</span>
            <span class="s1">r_aug[:m] = r</span>
            <span class="s2">if </span><span class="s1">auto_lsmr_tol:</span>
                <span class="s1">eta = </span><span class="s3">1e-2 </span><span class="s1">* min(</span><span class="s3">0.5</span><span class="s2">, </span><span class="s1">g_norm)</span>
                <span class="s1">lsmr_tol = max(EPS</span><span class="s2">, </span><span class="s1">min(</span><span class="s3">0.1</span><span class="s2">, </span><span class="s1">eta * g_norm))</span>
            <span class="s1">p_h = -lsmr(lsmr_op</span><span class="s2">, </span><span class="s1">r_aug</span><span class="s2">, </span><span class="s1">maxiter=lsmr_maxiter</span><span class="s2">,</span>
                        <span class="s1">atol=lsmr_tol</span><span class="s2">, </span><span class="s1">btol=lsmr_tol)[</span><span class="s3">0</span><span class="s1">]</span>

        <span class="s1">p = d * p_h</span>

        <span class="s1">p_dot_g = np.dot(p</span><span class="s2">, </span><span class="s1">g)</span>
        <span class="s2">if </span><span class="s1">p_dot_g &gt; </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">termination_status = -</span><span class="s3">1</span>

        <span class="s1">theta = </span><span class="s3">1 </span><span class="s1">- min(</span><span class="s3">0.005</span><span class="s2">, </span><span class="s1">g_norm)</span>
        <span class="s1">step = select_step(x</span><span class="s2">, </span><span class="s1">A_h</span><span class="s2">, </span><span class="s1">g_h</span><span class="s2">, </span><span class="s1">diag_h</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">p_h</span><span class="s2">, </span><span class="s1">d</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">theta)</span>
        <span class="s1">cost_change = -evaluate_quadratic(A</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">step)</span>

        <span class="s4"># Perhaps almost never executed, the idea is that `p` is descent</span>
        <span class="s4"># direction thus we must find acceptable cost decrease using simple</span>
        <span class="s4"># &quot;backtracking&quot;, otherwise the algorithm's logic would break.</span>
        <span class="s2">if </span><span class="s1">cost_change &lt; </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">x</span><span class="s2">, </span><span class="s1">step</span><span class="s2">, </span><span class="s1">cost_change = backtracking(</span>
                <span class="s1">A</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">theta</span><span class="s2">, </span><span class="s1">p_dot_g</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">x = make_strictly_feasible(x + step</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">rstep=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s1">step_norm = norm(step)</span>
        <span class="s1">r = A.dot(x) - b</span>
        <span class="s1">g = compute_grad(A</span><span class="s2">, </span><span class="s1">r)</span>

        <span class="s2">if </span><span class="s1">cost_change &lt; tol * cost:</span>
            <span class="s1">termination_status = </span><span class="s3">2</span>

        <span class="s1">cost = </span><span class="s3">0.5 </span><span class="s1">* np.dot(r</span><span class="s2">, </span><span class="s1">r)</span>

    <span class="s2">if </span><span class="s1">termination_status </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">termination_status = </span><span class="s3">0</span>

    <span class="s1">active_mask = find_active_constraints(x</span><span class="s2">, </span><span class="s1">lb</span><span class="s2">, </span><span class="s1">ub</span><span class="s2">, </span><span class="s1">rtol=tol)</span>

    <span class="s2">return </span><span class="s1">OptimizeResult(</span>
        <span class="s1">x=x</span><span class="s2">, </span><span class="s1">fun=r</span><span class="s2">, </span><span class="s1">cost=cost</span><span class="s2">, </span><span class="s1">optimality=g_norm</span><span class="s2">, </span><span class="s1">active_mask=active_mask</span><span class="s2">,</span>
        <span class="s1">nit=iteration + </span><span class="s3">1</span><span class="s2">, </span><span class="s1">status=termination_status</span><span class="s2">,</span>
        <span class="s1">initial_cost=initial_cost)</span>
</pre>
</body>
</html>
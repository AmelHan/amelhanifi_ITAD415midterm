<html>
<head>
<title>weightstats.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
weightstats.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Tests and descriptive statistics with weights 
 
 
Created on 2010-09-18 
 
Author: josef-pktd 
License: BSD (3-clause) 
 
 
References 
---------- 
SPSS manual 
SAS manual 
 
This follows in large parts the SPSS manual, which is largely the same as 
the SAS manual with different, simpler notation. 
 
Freq, Weight in SAS seems redundant since they always show up as product, SPSS 
has only weights. 
 
Notes 
----- 
 
This has potential problems with ddof, I started to follow numpy with ddof=0 
by default and users can change it, but this might still mess up the t-tests, 
since the estimates for the standard deviation will be based on the ddof that 
the user chooses. 
- fixed ddof for the meandiff ttest, now matches scipy.stats.ttest_ind 
 
Note: scipy has now a separate, pooled variance option in ttest, but I have not 
compared yet. 
 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>

<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>


<span class="s2">class </span><span class="s1">DescrStatsW:</span>
    <span class="s0">&quot;&quot;&quot; 
    Descriptive statistics and tests with weights for case weights 
 
    Assumes that the data is 1d or 2d with (nobs, nvars) observations in rows, 
    variables in columns, and that the same weight applies to each column. 
 
    If degrees of freedom correction is used, then weights should add up to the 
    number of observations. ttest also assumes that the sum of weights 
    corresponds to the sample size. 
 
    This is essentially the same as replicating each observations by its 
    weight, if the weights are integers, often called case or frequency weights. 
 
    Parameters 
    ---------- 
    data : array_like, 1-D or 2-D 
        dataset 
    weights : None or 1-D ndarray 
        weights for each observation, with same length as zero axis of data 
    ddof : int 
        default ddof=0, degrees of freedom correction used for second moments, 
        var, std, cov, corrcoef. 
        However, statistical tests are independent of `ddof`, based on the 
        standard formulas. 
 
    Examples 
    -------- 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; np.random.seed(0) 
    &gt;&gt;&gt; x1_2d = 1.0 + np.random.randn(20, 3) 
    &gt;&gt;&gt; w1 = np.random.randint(1, 4, 20) 
    &gt;&gt;&gt; d1 = DescrStatsW(x1_2d, weights=w1) 
    &gt;&gt;&gt; d1.mean 
    array([ 1.42739844,  1.23174284,  1.083753  ]) 
    &gt;&gt;&gt; d1.var 
    array([ 0.94855633,  0.52074626,  1.12309325]) 
    &gt;&gt;&gt; d1.std_mean 
    array([ 0.14682676,  0.10878944,  0.15976497]) 
 
    &gt;&gt;&gt; tstat, pval, df = d1.ttest_mean(0) 
    &gt;&gt;&gt; tstat; pval; df 
    array([  9.72165021,  11.32226471,   6.78342055]) 
    array([  1.58414212e-12,   1.26536887e-14,   2.37623126e-08]) 
    44.0 
 
    &gt;&gt;&gt; tstat, pval, df = d1.ttest_mean([0, 1, 1]) 
    &gt;&gt;&gt; tstat; pval; df 
    array([ 9.72165021,  2.13019609,  0.52422632]) 
    array([  1.58414212e-12,   3.87842808e-02,   6.02752170e-01]) 
    44.0 
 
    # if weights are integers, then asrepeats can be used 
 
    &gt;&gt;&gt; x1r = d1.asrepeats() 
    &gt;&gt;&gt; x1r.shape 
    ... 
    &gt;&gt;&gt; stats.ttest_1samp(x1r, [0, 1, 1]) 
    ... 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">weights=</span><span class="s2">None, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">):</span>

        <span class="s1">self.data = np.asarray(data)</span>
        <span class="s2">if </span><span class="s1">weights </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.weights = np.ones(self.data.shape[</span><span class="s3">0</span><span class="s1">])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.weights = np.asarray(weights).astype(float)</span>
            <span class="s4"># TODO: why squeeze?</span>
            <span class="s2">if </span><span class="s1">len(self.weights.shape) &gt; </span><span class="s3">1 </span><span class="s2">and </span><span class="s1">len(self.weights) &gt; </span><span class="s3">1</span><span class="s1">:</span>
                <span class="s1">self.weights = self.weights.squeeze()</span>
        <span class="s1">self.ddof = ddof</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">sum_weights(self):</span>
        <span class="s0">&quot;&quot;&quot;Sum of weights&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.weights.sum(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">nobs(self):</span>
        <span class="s0">&quot;&quot;&quot;alias for number of observations/cases, equal to sum of weights 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.sum_weights</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">sum(self):</span>
        <span class="s0">&quot;&quot;&quot;weighted sum of data&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.dot(self.data.T</span><span class="s2">, </span><span class="s1">self.weights)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">mean(self):</span>
        <span class="s0">&quot;&quot;&quot;weighted mean of data&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.sum / self.sum_weights</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">demeaned(self):</span>
        <span class="s0">&quot;&quot;&quot;data with weighted mean subtracted&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.data - self.mean</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">sumsquares(self):</span>
        <span class="s0">&quot;&quot;&quot;weighted sum of squares of demeaned data&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.dot((self.demeaned ** </span><span class="s3">2</span><span class="s1">).T</span><span class="s2">, </span><span class="s1">self.weights)</span>

    <span class="s4"># need memoize instead of cache decorator</span>
    <span class="s2">def </span><span class="s1">var_ddof(self</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;variance of data given ddof 
 
        Parameters 
        ---------- 
        ddof : int, float 
            degrees of freedom correction, independent of attribute ddof 
 
        Returns 
        ------- 
        var : float, ndarray 
            variance with denominator ``sum_weights - ddof`` 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.sumsquares / (self.sum_weights - ddof)</span>

    <span class="s2">def </span><span class="s1">std_ddof(self</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;standard deviation of data with given ddof 
 
        Parameters 
        ---------- 
        ddof : int, float 
            degrees of freedom correction, independent of attribute ddof 
 
        Returns 
        ------- 
        std : float, ndarray 
            standard deviation with denominator ``sum_weights - ddof`` 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.sqrt(self.var_ddof(ddof=ddof))</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">var(self):</span>
        <span class="s0">&quot;&quot;&quot;variance with default degrees of freedom correction 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.sumsquares / (self.sum_weights - self.ddof)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">_var(self):</span>
        <span class="s0">&quot;&quot;&quot;variance without degrees of freedom correction 
 
        used for statistical tests with controlled ddof 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.sumsquares / self.sum_weights</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">std(self):</span>
        <span class="s0">&quot;&quot;&quot;standard deviation with default degrees of freedom correction 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.sqrt(self.var)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cov(self):</span>
        <span class="s0">&quot;&quot;&quot;weighted covariance of data if data is 2 dimensional 
 
        assumes variables in columns and observations in rows 
        uses default ddof 
        &quot;&quot;&quot;</span>
        <span class="s1">cov_ = np.dot(self.weights * self.demeaned.T</span><span class="s2">, </span><span class="s1">self.demeaned)</span>
        <span class="s1">cov_ /= self.sum_weights - self.ddof</span>
        <span class="s2">return </span><span class="s1">cov_</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">corrcoef(self):</span>
        <span class="s0">&quot;&quot;&quot;weighted correlation with default ddof 
 
        assumes variables in columns and observations in rows 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.cov / self.std / self.std[:</span><span class="s2">, None</span><span class="s1">]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">std_mean(self):</span>
        <span class="s0">&quot;&quot;&quot;standard deviation of weighted mean 
        &quot;&quot;&quot;</span>
        <span class="s1">std = self.std</span>
        <span class="s2">if </span><span class="s1">self.ddof != </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s4"># ddof correction,   (need copy of std)</span>
            <span class="s1">std = std * np.sqrt(</span>
                <span class="s1">(self.sum_weights - self.ddof) / self.sum_weights</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">std / np.sqrt(self.sum_weights - </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">quantile(self</span><span class="s2">, </span><span class="s1">probs</span><span class="s2">, </span><span class="s1">return_pandas=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute quantiles for a weighted sample. 
 
        Parameters 
        ---------- 
        probs : array_like 
            A vector of probability points at which to calculate the 
            quantiles.  Each element of `probs` should fall in [0, 1]. 
        return_pandas : bool 
            If True, return value is a Pandas DataFrame or Series. 
            Otherwise returns a ndarray. 
 
        Returns 
        ------- 
        quantiles : Series, DataFrame, or ndarray 
            If `return_pandas` = True, returns one of the following: 
              * data are 1d, `return_pandas` = True: a Series indexed by 
                the probability points. 
              * data are 2d, `return_pandas` = True: a DataFrame with 
                the probability points as row index and the variables 
                as column index. 
 
            If `return_pandas` = False, returns an ndarray containing the 
            same values as the Series/DataFrame. 
 
        Notes 
        ----- 
        To compute the quantiles, first, the weights are summed over 
        exact ties yielding distinct data values y_1 &lt; y_2 &lt; ..., and 
        corresponding weights w_1, w_2, ....  Let s_j denote the sum 
        of the first j weights, and let W denote the sum of all the 
        weights.  For a probability point p, if pW falls strictly 
        between s_j and s_{j+1} then the estimated quantile is 
        y_{j+1}.  If pW = s_j then the estimated quantile is (y_j + 
        y_{j+1})/2.  If pW &lt; p_1 then the estimated quantile is y_1. 
 
        References 
        ---------- 
        SAS documentation for weighted quantiles: 
 
        https://support.sas.com/documentation/cdl/en/procstat/63104/HTML/default/viewer.htm#procstat_univariate_sect028.htm 
        &quot;&quot;&quot;</span>

        <span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>

        <span class="s1">probs = np.asarray(probs)</span>
        <span class="s1">probs = np.atleast_1d(probs)</span>

        <span class="s2">if </span><span class="s1">self.data.ndim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">rslt = self._quantile(self.data</span><span class="s2">, </span><span class="s1">probs)</span>
            <span class="s2">if </span><span class="s1">return_pandas:</span>
                <span class="s1">rslt = pd.Series(rslt</span><span class="s2">, </span><span class="s1">index=probs)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">rslt = []</span>
            <span class="s2">for </span><span class="s1">vec </span><span class="s2">in </span><span class="s1">self.data.T:</span>
                <span class="s1">rslt.append(self._quantile(vec</span><span class="s2">, </span><span class="s1">probs))</span>
            <span class="s1">rslt = np.column_stack(rslt)</span>
            <span class="s2">if </span><span class="s1">return_pandas:</span>
                <span class="s1">columns = [</span><span class="s5">&quot;col%d&quot; </span><span class="s1">% (j + </span><span class="s3">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(rslt.shape[</span><span class="s3">1</span><span class="s1">])]</span>
                <span class="s1">rslt = pd.DataFrame(data=rslt</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">index=probs)</span>

        <span class="s2">if </span><span class="s1">return_pandas:</span>
            <span class="s1">rslt.index.name = </span><span class="s5">&quot;p&quot;</span>

        <span class="s2">return </span><span class="s1">rslt</span>

    <span class="s2">def </span><span class="s1">_quantile(self</span><span class="s2">, </span><span class="s1">vec</span><span class="s2">, </span><span class="s1">probs):</span>
        <span class="s4"># Helper function to calculate weighted quantiles for one column.</span>
        <span class="s4"># Follows definition from SAS documentation.</span>
        <span class="s4"># Returns ndarray</span>

        <span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>

        <span class="s4"># Aggregate over ties</span>
        <span class="s1">df = pd.DataFrame(index=np.arange(len(self.weights)))</span>
        <span class="s1">df[</span><span class="s5">&quot;weights&quot;</span><span class="s1">] = self.weights</span>
        <span class="s1">df[</span><span class="s5">&quot;vec&quot;</span><span class="s1">] = vec</span>
        <span class="s1">dfg = df.groupby(</span><span class="s5">&quot;vec&quot;</span><span class="s1">).agg(np.sum)</span>
        <span class="s1">weights = dfg.values[:</span><span class="s2">, </span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">values = np.asarray(dfg.index)</span>

        <span class="s1">cweights = np.cumsum(weights)</span>
        <span class="s1">totwt = cweights[-</span><span class="s3">1</span><span class="s1">]</span>
        <span class="s1">targets = probs * totwt</span>
        <span class="s1">ii = np.searchsorted(cweights</span><span class="s2">, </span><span class="s1">targets)</span>

        <span class="s1">rslt = values[ii]</span>

        <span class="s4"># Exact hits</span>
        <span class="s1">jj = np.flatnonzero(np.abs(targets - cweights[ii]) &lt; </span><span class="s3">1e-10</span><span class="s1">)</span>
        <span class="s1">jj = jj[ii[jj] &lt; len(cweights) - </span><span class="s3">1</span><span class="s1">]</span>
        <span class="s1">rslt[jj] = (values[ii[jj]] + values[ii[jj] + </span><span class="s3">1</span><span class="s1">]) / </span><span class="s3">2</span>

        <span class="s2">return </span><span class="s1">rslt</span>

    <span class="s2">def </span><span class="s1">tconfint_mean(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;two-sided confidence interval for weighted mean of data 
 
        If the data is 2d, then these are separate confidence intervals 
        for each column. 
 
        Parameters 
        ---------- 
        alpha : float 
            significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            This specifies the alternative hypothesis for the test that 
            corresponds to the confidence interval. 
            The alternative hypothesis, H1, has to be one of the following 
 
              'two-sided': H1: mean not equal to value (default) 
              'larger' :   H1: mean larger than value 
              'smaller' :  H1: mean smaller than value 
 
        Returns 
        ------- 
        lower, upper : floats or ndarrays 
            lower and upper bound of confidence interval 
 
        Notes 
        ----- 
        In a previous version, statsmodels 0.4, alpha was the confidence 
        level, e.g. 0.95 
        &quot;&quot;&quot;</span>
        <span class="s4"># TODO: add asymmetric</span>
        <span class="s1">dof = self.sum_weights - </span><span class="s3">1</span>
        <span class="s1">ci = _tconfint_generic(</span>
            <span class="s1">self.mean</span><span class="s2">, </span><span class="s1">self.std_mean</span><span class="s2">, </span><span class="s1">dof</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">alternative</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">ci</span>

    <span class="s2">def </span><span class="s1">zconfint_mean(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;two-sided confidence interval for weighted mean of data 
 
        Confidence interval is based on normal distribution. 
        If the data is 2d, then these are separate confidence intervals 
        for each column. 
 
        Parameters 
        ---------- 
        alpha : float 
            significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            This specifies the alternative hypothesis for the test that 
            corresponds to the confidence interval. 
            The alternative hypothesis, H1, has to be one of the following 
 
              'two-sided': H1: mean not equal to value (default) 
              'larger' :   H1: mean larger than value 
              'smaller' :  H1: mean smaller than value 
 
        Returns 
        ------- 
        lower, upper : floats or ndarrays 
            lower and upper bound of confidence interval 
 
        Notes 
        ----- 
        In a previous version, statsmodels 0.4, alpha was the confidence 
        level, e.g. 0.95 
        &quot;&quot;&quot;</span>

        <span class="s2">return </span><span class="s1">_zconfint_generic(self.mean</span><span class="s2">, </span><span class="s1">self.std_mean</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">alternative)</span>

    <span class="s2">def </span><span class="s1">ttest_mean(self</span><span class="s2">, </span><span class="s1">value=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;ttest of Null hypothesis that mean is equal to value. 
 
        The alternative hypothesis H1 is defined by the following 
 
        - 'two-sided': H1: mean not equal to value 
        - 'larger' :   H1: mean larger than value 
        - 'smaller' :  H1: mean smaller than value 
 
        Parameters 
        ---------- 
        value : float or array 
            the hypothesized value for the mean 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following: 
 
              - 'two-sided': H1: mean not equal to value (default) 
              - 'larger' :   H1: mean larger than value 
              - 'smaller' :  H1: mean smaller than value 
 
        Returns 
        ------- 
        tstat : float 
            test statistic 
        pvalue : float 
            pvalue of the t-test 
        df : int or float 
 
        &quot;&quot;&quot;</span>
        <span class="s4"># TODO: check direction with R, smaller=less, larger=greater</span>
        <span class="s1">tstat = (self.mean - value) / self.std_mean</span>
        <span class="s1">dof = self.sum_weights - </span><span class="s3">1</span>
        <span class="s4"># TODO: use outsourced</span>
        <span class="s2">if </span><span class="s1">alternative == </span><span class="s5">&quot;two-sided&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.t.sf(np.abs(tstat)</span><span class="s2">, </span><span class="s1">dof) * </span><span class="s3">2</span>
        <span class="s2">elif </span><span class="s1">alternative == </span><span class="s5">&quot;larger&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.t.sf(tstat</span><span class="s2">, </span><span class="s1">dof)</span>
        <span class="s2">elif </span><span class="s1">alternative == </span><span class="s5">&quot;smaller&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.t.cdf(tstat</span><span class="s2">, </span><span class="s1">dof)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;alternative not recognized&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">, </span><span class="s1">dof</span>

    <span class="s2">def </span><span class="s1">ttost_mean(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp):</span>
        <span class="s0">&quot;&quot;&quot;test of (non-)equivalence of one sample 
 
        TOST: two one-sided t tests 
 
        null hypothesis:  m &lt; low or m &gt; upp 
        alternative hypothesis:  low &lt; m &lt; upp 
 
        where m is the expected value of the sample (mean of the population). 
 
        If the pvalue is smaller than a threshold, say 0.05, then we reject the 
        hypothesis that the expected value of the sample (mean of the 
        population) is outside of the interval given by thresholds low and upp. 
 
        Parameters 
        ---------- 
        low, upp : float 
            equivalence interval low &lt; mean &lt; upp 
 
        Returns 
        ------- 
        pvalue : float 
            pvalue of the non-equivalence test 
        t1, pv1, df1 : tuple 
            test statistic, pvalue and degrees of freedom for lower threshold 
            test 
        t2, pv2, df2 : tuple 
            test statistic, pvalue and degrees of freedom for upper threshold 
            test 
 
        &quot;&quot;&quot;</span>

        <span class="s1">t1</span><span class="s2">, </span><span class="s1">pv1</span><span class="s2">, </span><span class="s1">df1 = self.ttest_mean(low</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s1">)</span>
        <span class="s1">t2</span><span class="s2">, </span><span class="s1">pv2</span><span class="s2">, </span><span class="s1">df2 = self.ttest_mean(upp</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.maximum(pv1</span><span class="s2">, </span><span class="s1">pv2)</span><span class="s2">, </span><span class="s1">(t1</span><span class="s2">, </span><span class="s1">pv1</span><span class="s2">, </span><span class="s1">df1)</span><span class="s2">, </span><span class="s1">(t2</span><span class="s2">, </span><span class="s1">pv2</span><span class="s2">, </span><span class="s1">df2)</span>

    <span class="s2">def </span><span class="s1">ztest_mean(self</span><span class="s2">, </span><span class="s1">value=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;z-test of Null hypothesis that mean is equal to value. 
 
        The alternative hypothesis H1 is defined by the following 
        'two-sided': H1: mean not equal to value 
        'larger' :   H1: mean larger than value 
        'smaller' :  H1: mean smaller than value 
 
        Parameters 
        ---------- 
        value : float or array 
            the hypothesized value for the mean 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
 
              'two-sided': H1: mean not equal to value (default) 
              'larger' :   H1: mean larger than value 
              'smaller' :  H1: mean smaller than value 
 
        Returns 
        ------- 
        tstat : float 
            test statistic 
        pvalue : float 
            pvalue of the t-test 
 
        Notes 
        ----- 
        This uses the same degrees of freedom correction as the t-test in the 
        calculation of the standard error of the mean, i.e it uses 
        `(sum_weights - 1)` instead of `sum_weights` in the denominator. 
        See Examples below for the difference. 
 
        Examples 
        -------- 
 
        z-test on a proportion, with 20 observations, 15 of those are our event 
 
        &gt;&gt;&gt; import statsmodels.api as sm 
        &gt;&gt;&gt; x1 = [0, 1] 
        &gt;&gt;&gt; w1 = [5, 15] 
        &gt;&gt;&gt; d1 = sm.stats.DescrStatsW(x1, w1) 
        &gt;&gt;&gt; d1.ztest_mean(0.5) 
        (2.5166114784235836, 0.011848940928347452) 
 
        This differs from the proportions_ztest because of the degrees of 
        freedom correction: 
        &gt;&gt;&gt; sm.stats.proportions_ztest(15, 20.0, value=0.5) 
        (2.5819888974716112, 0.009823274507519247). 
 
        We can replicate the results from ``proportions_ztest`` if we increase 
        the weights to have artificially one more observation: 
 
        &gt;&gt;&gt; sm.stats.DescrStatsW(x1, np.array(w1)*21./20).ztest_mean(0.5) 
        (2.5819888974716116, 0.0098232745075192366) 
        &quot;&quot;&quot;</span>
        <span class="s1">tstat = (self.mean - value) / self.std_mean</span>
        <span class="s4"># TODO: use outsourced</span>
        <span class="s2">if </span><span class="s1">alternative == </span><span class="s5">&quot;two-sided&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.norm.sf(np.abs(tstat)) * </span><span class="s3">2</span>
        <span class="s2">elif </span><span class="s1">alternative == </span><span class="s5">&quot;larger&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.norm.sf(tstat)</span>
        <span class="s2">elif </span><span class="s1">alternative == </span><span class="s5">&quot;smaller&quot;</span><span class="s1">:</span>
            <span class="s1">pvalue = stats.norm.cdf(tstat)</span>

        <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue</span>

    <span class="s2">def </span><span class="s1">ztost_mean(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp):</span>
        <span class="s0">&quot;&quot;&quot;test of (non-)equivalence of one sample, based on z-test 
 
        TOST: two one-sided z-tests 
 
        null hypothesis:  m &lt; low or m &gt; upp 
        alternative hypothesis:  low &lt; m &lt; upp 
 
        where m is the expected value of the sample (mean of the population). 
 
        If the pvalue is smaller than a threshold, say 0.05, then we reject the 
        hypothesis that the expected value of the sample (mean of the 
        population) is outside of the interval given by thresholds low and upp. 
 
        Parameters 
        ---------- 
        low, upp : float 
            equivalence interval low &lt; mean &lt; upp 
 
        Returns 
        ------- 
        pvalue : float 
            pvalue of the non-equivalence test 
        t1, pv1 : tuple 
            test statistic and p-value for lower threshold test 
        t2, pv2 : tuple 
            test statistic and p-value for upper threshold test 
 
        &quot;&quot;&quot;</span>

        <span class="s1">t1</span><span class="s2">, </span><span class="s1">pv1 = self.ztest_mean(low</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s1">)</span>
        <span class="s1">t2</span><span class="s2">, </span><span class="s1">pv2 = self.ztest_mean(upp</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.maximum(pv1</span><span class="s2">, </span><span class="s1">pv2)</span><span class="s2">, </span><span class="s1">(t1</span><span class="s2">, </span><span class="s1">pv1)</span><span class="s2">, </span><span class="s1">(t2</span><span class="s2">, </span><span class="s1">pv2)</span>

    <span class="s2">def </span><span class="s1">get_compare(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">weights=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;return an instance of CompareMeans with self and other 
 
        Parameters 
        ---------- 
        other : array_like or instance of DescrStatsW 
            If array_like then this creates an instance of DescrStatsW with 
            the given weights. 
        weights : None or array 
            weights are only used if other is not an instance of DescrStatsW 
 
        Returns 
        ------- 
        cm : instance of CompareMeans 
            the instance has self attached as d1 and other as d2. 
 
        See Also 
        -------- 
        CompareMeans 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">self.__class__):</span>
            <span class="s1">d2 = DescrStatsW(other</span><span class="s2">, </span><span class="s1">weights)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">d2 = other</span>
        <span class="s2">return </span><span class="s1">CompareMeans(self</span><span class="s2">, </span><span class="s1">d2)</span>

    <span class="s2">def </span><span class="s1">asrepeats(self):</span>
        <span class="s0">&quot;&quot;&quot;get array that has repeats given by floor(weights) 
 
        observations with weight=0 are dropped 
 
        &quot;&quot;&quot;</span>
        <span class="s1">w_int = np.floor(self.weights).astype(int)</span>
        <span class="s2">return </span><span class="s1">np.repeat(self.data</span><span class="s2">, </span><span class="s1">w_int</span><span class="s2">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_tstat_generic(value1</span><span class="s2">, </span><span class="s1">value2</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">dof</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">diff=</span><span class="s3">0</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;generic ttest based on summary statistic 
 
    The test statistic is : 
        tstat = (value1 - value2 - diff) / std_diff 
 
    and is assumed to be t-distributed with ``dof`` degrees of freedom. 
 
    Parameters 
    ---------- 
    value1 : float or ndarray 
        Value, for example mean, of the first sample. 
    value2 : float or ndarray 
        Value, for example mean, of the second sample. 
    std_diff : float or ndarray 
        Standard error of the difference value1 - value2 
    dof : int or float 
        Degrees of freedom 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' : H1: ``value1 - value2 - diff`` not equal to 0. 
           * 'larger' :   H1: ``value1 - value2 - diff &gt; 0`` 
           * 'smaller' :  H1: ``value1 - value2 - diff &lt; 0`` 
 
    diff : float 
        value of difference ``value1 - value2`` under the null hypothesis 
 
    Returns 
    ------- 
    tstat : float or ndarray 
        Test statistic. 
    pvalue : float or ndarray 
        P-value of the hypothesis test assuming that the test statistic is 
        t-distributed with ``df`` degrees of freedom. 
    &quot;&quot;&quot;</span>

    <span class="s1">tstat = (value1 - value2 - diff) / std_diff</span>
    <span class="s2">if </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.t.sf(np.abs(tstat)</span><span class="s2">, </span><span class="s1">dof) * </span><span class="s3">2</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s5">&quot;l&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.t.sf(tstat</span><span class="s2">, </span><span class="s1">dof)</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s5">&quot;s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.t.cdf(tstat</span><span class="s2">, </span><span class="s1">dof)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;invalid alternative&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue</span>


<span class="s2">def </span><span class="s1">_tconfint_generic(mean</span><span class="s2">, </span><span class="s1">std_mean</span><span class="s2">, </span><span class="s1">dof</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">alternative):</span>
    <span class="s0">&quot;&quot;&quot;generic t-confint based on summary statistic 
 
    Parameters 
    ---------- 
    mean : float or ndarray 
        Value, for example mean, of the first sample. 
    std_mean : float or ndarray 
        Standard error of the difference value1 - value2 
    dof : int or float 
        Degrees of freedom 
    alpha : float 
        Significance level for the confidence interval, coverage is 
        ``1-alpha``. 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' : H1: ``value1 - value2 - diff`` not equal to 0. 
           * 'larger' :   H1: ``value1 - value2 - diff &gt; 0`` 
           * 'smaller' :  H1: ``value1 - value2 - diff &lt; 0`` 
 
    Returns 
    ------- 
    lower : float or ndarray 
        Lower confidence limit. This is -inf for the one-sided alternative 
        &quot;smaller&quot;. 
    upper : float or ndarray 
        Upper confidence limit. This is inf for the one-sided alternative 
        &quot;larger&quot;. 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2s&quot;</span><span class="s1">]:</span>
        <span class="s1">tcrit = stats.t.ppf(</span><span class="s3">1 </span><span class="s1">- alpha / </span><span class="s3">2.0</span><span class="s2">, </span><span class="s1">dof)</span>
        <span class="s1">lower = mean - tcrit * std_mean</span>
        <span class="s1">upper = mean + tcrit * std_mean</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s5">&quot;l&quot;</span><span class="s1">]:</span>
        <span class="s1">tcrit = stats.t.ppf(alpha</span><span class="s2">, </span><span class="s1">dof)</span>
        <span class="s1">lower = mean + tcrit * std_mean</span>
        <span class="s1">upper = np.inf</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s5">&quot;s&quot;</span><span class="s1">]:</span>
        <span class="s1">tcrit = stats.t.ppf(</span><span class="s3">1 </span><span class="s1">- alpha</span><span class="s2">, </span><span class="s1">dof)</span>
        <span class="s1">lower = -np.inf</span>
        <span class="s1">upper = mean + tcrit * std_mean</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;invalid alternative&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper</span>


<span class="s2">def </span><span class="s1">_zstat_generic(value1</span><span class="s2">, </span><span class="s1">value2</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">diff=</span><span class="s3">0</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;generic (normal) z-test based on summary statistic 
 
    The test statistic is : 
        tstat = (value1 - value2 - diff) / std_diff 
 
    and is assumed to be normally distributed. 
 
    Parameters 
    ---------- 
    value1 : float or ndarray 
        Value, for example mean, of the first sample. 
    value2 : float or ndarray 
        Value, for example mean, of the second sample. 
    std_diff : float or ndarray 
        Standard error of the difference value1 - value2 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' : H1: ``value1 - value2 - diff`` not equal to 0. 
           * 'larger' :   H1: ``value1 - value2 - diff &gt; 0`` 
           * 'smaller' :  H1: ``value1 - value2 - diff &lt; 0`` 
 
    diff : float 
        value of difference ``value1 - value2`` under the null hypothesis 
 
    Returns 
    ------- 
    tstat : float or ndarray 
        Test statistic. 
    pvalue : float or ndarray 
        P-value of the hypothesis test assuming that the test statistic is 
        t-distributed with ``df`` degrees of freedom. 
    &quot;&quot;&quot;</span>

    <span class="s1">zstat = (value1 - value2 - diff) / std_diff</span>
    <span class="s2">if </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.sf(np.abs(zstat)) * </span><span class="s3">2</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s5">&quot;l&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.sf(zstat)</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s5">&quot;s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.cdf(zstat)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;invalid alternative&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">zstat</span><span class="s2">, </span><span class="s1">pvalue</span>


<span class="s2">def </span><span class="s1">_zstat_generic2(value</span><span class="s2">, </span><span class="s1">std</span><span class="s2">, </span><span class="s1">alternative):</span>
    <span class="s0">&quot;&quot;&quot;generic (normal) z-test based on summary statistic 
 
    The test statistic is : 
        zstat = value / std 
 
    and is assumed to be normally distributed with standard deviation ``std``. 
 
    Parameters 
    ---------- 
    value : float or ndarray 
        Value of a sample statistic, for example mean. 
    value2 : float or ndarray 
        Value, for example mean, of the second sample. 
    std : float or ndarray 
        Standard error of the sample statistic value. 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' : H1: ``value1 - value2 - diff`` not equal to 0. 
           * 'larger' :   H1: ``value1 - value2 - diff &gt; 0`` 
           * 'smaller' :  H1: ``value1 - value2 - diff &lt; 0`` 
 
    Returns 
    ------- 
    zstat : float or ndarray 
        Test statistic. 
    pvalue : float or ndarray 
        P-value of the hypothesis test assuming that the test statistic is 
        normally distributed. 
    &quot;&quot;&quot;</span>

    <span class="s1">zstat = value / std</span>
    <span class="s2">if </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.sf(np.abs(zstat)) * </span><span class="s3">2</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s5">&quot;l&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.sf(zstat)</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s5">&quot;s&quot;</span><span class="s1">]:</span>
        <span class="s1">pvalue = stats.norm.cdf(zstat)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;invalid alternative&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">zstat</span><span class="s2">, </span><span class="s1">pvalue</span>


<span class="s2">def </span><span class="s1">_zconfint_generic(mean</span><span class="s2">, </span><span class="s1">std_mean</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">alternative):</span>
    <span class="s0">&quot;&quot;&quot;generic normal-confint based on summary statistic 
 
    Parameters 
    ---------- 
    mean : float or ndarray 
        Value, for example mean, of the first sample. 
    std_mean : float or ndarray 
        Standard error of the difference value1 - value2 
    alpha : float 
        Significance level for the confidence interval, coverage is 
        ``1-alpha`` 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' : H1: ``value1 - value2 - diff`` not equal to 0. 
           * 'larger' :   H1: ``value1 - value2 - diff &gt; 0`` 
           * 'smaller' :  H1: ``value1 - value2 - diff &lt; 0`` 
 
    Returns 
    ------- 
    lower : float or ndarray 
        Lower confidence limit. This is -inf for the one-sided alternative 
        &quot;smaller&quot;. 
    upper : float or ndarray 
        Upper confidence limit. This is inf for the one-sided alternative 
        &quot;larger&quot;. 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2-sided&quot;</span><span class="s2">, </span><span class="s5">&quot;2s&quot;</span><span class="s1">]:</span>
        <span class="s1">zcrit = stats.norm.ppf(</span><span class="s3">1 </span><span class="s1">- alpha / </span><span class="s3">2.0</span><span class="s1">)</span>
        <span class="s1">lower = mean - zcrit * std_mean</span>
        <span class="s1">upper = mean + zcrit * std_mean</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s5">&quot;l&quot;</span><span class="s1">]:</span>
        <span class="s1">zcrit = stats.norm.ppf(alpha)</span>
        <span class="s1">lower = mean + zcrit * std_mean</span>
        <span class="s1">upper = np.inf</span>
    <span class="s2">elif </span><span class="s1">alternative </span><span class="s2">in </span><span class="s1">[</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s5">&quot;s&quot;</span><span class="s1">]:</span>
        <span class="s1">zcrit = stats.norm.ppf(</span><span class="s3">1 </span><span class="s1">- alpha)</span>
        <span class="s1">lower = -np.inf</span>
        <span class="s1">upper = mean + zcrit * std_mean</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;invalid alternative&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper</span>


<span class="s2">class </span><span class="s1">CompareMeans:</span>
    <span class="s0">&quot;&quot;&quot;class for two sample comparison 
 
    The tests and the confidence interval work for multi-endpoint comparison: 
    If d1 and d2 have the same number of rows, then each column of the data 
    in d1 is compared with the corresponding column in d2. 
 
    Parameters 
    ---------- 
    d1, d2 : instances of DescrStatsW 
 
    Notes 
    ----- 
    The result for the statistical tests and the confidence interval are 
    independent of the user specified ddof. 
 
    TODO: Extend to any number of groups or write a version that works in that 
    case, like in SAS and SPSS. 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">d1</span><span class="s2">, </span><span class="s1">d2):</span>
        <span class="s0">&quot;&quot;&quot;assume d1, d2 hold the relevant attributes 
 
        &quot;&quot;&quot;</span>
        <span class="s1">self.d1 = d1</span>
        <span class="s1">self.d2 = d2</span>
        <span class="s4"># assume nobs is available</span>

    <span class="s4">#        if not hasattr(self.d1, 'nobs'):</span>
    <span class="s4">#            d1.nobs1 = d1.sum_weights.astype(float)  #float just to make sure</span>
    <span class="s4">#        self.nobs2 = d2.sum_weights.astype(float)</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">from_data(</span>
        <span class="s1">cls</span><span class="s2">, </span><span class="s1">data1</span><span class="s2">, </span><span class="s1">data2</span><span class="s2">, </span><span class="s1">weights1=</span><span class="s2">None, </span><span class="s1">weights2=</span><span class="s2">None, </span><span class="s1">ddof1=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">ddof2=</span><span class="s3">0</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;construct a CompareMeans object from data 
 
        Parameters 
        ---------- 
        data1, data2 : array_like, 1-D or 2-D 
            compared datasets 
        weights1, weights2 : None or 1-D ndarray 
            weights for each observation of data1 and data2 respectively, 
            with same length as zero axis of corresponding dataset. 
        ddof1, ddof2 : int 
            default ddof1=0, ddof2=0, degrees of freedom for data1, 
            data2 respectively. 
 
        Returns 
        ------- 
        A CompareMeans instance. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">cls(</span>
            <span class="s1">DescrStatsW(data1</span><span class="s2">, </span><span class="s1">weights=weights1</span><span class="s2">, </span><span class="s1">ddof=ddof1)</span><span class="s2">,</span>
            <span class="s1">DescrStatsW(data2</span><span class="s2">, </span><span class="s1">weights=weights2</span><span class="s2">, </span><span class="s1">ddof=ddof2)</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">True, </span><span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">value=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;summarize the results of the hypothesis test 
 
        Parameters 
        ---------- 
        use_t : bool, optional 
            if use_t is True, then t test results are returned 
            if use_t is False, then z test results are returned 
        alpha : float 
            significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is 
            assumed to be the same. If ``unequal``, then the variance of 
            Welch ttest will be used, and the degrees of freedom are those 
            of Satterthwaite if ``use_t`` is True. 
        value : float 
            difference between the means under the Null hypothesis. 
 
        Returns 
        ------- 
        smry : SimpleTable 
 
        &quot;&quot;&quot;</span>

        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>

        <span class="s1">confint_percents = </span><span class="s3">100 </span><span class="s1">- alpha * </span><span class="s3">100</span>

        <span class="s2">if </span><span class="s1">use_t:</span>
            <span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">, </span><span class="s1">_ = self.ttest_ind(usevar=usevar</span><span class="s2">, </span><span class="s1">value=value)</span>
            <span class="s1">lower</span><span class="s2">, </span><span class="s1">upper = self.tconfint_diff(alpha=alpha</span><span class="s2">, </span><span class="s1">usevar=usevar)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue = self.ztest_ind(usevar=usevar</span><span class="s2">, </span><span class="s1">value=value)</span>
            <span class="s1">lower</span><span class="s2">, </span><span class="s1">upper = self.zconfint_diff(alpha=alpha</span><span class="s2">, </span><span class="s1">usevar=usevar)</span>

        <span class="s2">if </span><span class="s1">usevar == </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
            <span class="s1">std_err = self.std_meandiff_pooledvar</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">std_err = self.std_meandiff_separatevar</span>

        <span class="s1">std_err = np.atleast_1d(std_err)</span>
        <span class="s1">tstat = np.atleast_1d(tstat)</span>
        <span class="s1">pvalue = np.atleast_1d(pvalue)</span>
        <span class="s1">lower = np.atleast_1d(lower)</span>
        <span class="s1">upper = np.atleast_1d(upper)</span>
        <span class="s1">conf_int = np.column_stack((lower</span><span class="s2">, </span><span class="s1">upper))</span>
        <span class="s1">params = np.atleast_1d(d1.mean - d2.mean - value)</span>

        <span class="s1">title = </span><span class="s5">&quot;Test for equality of means&quot;</span>
        <span class="s1">yname = </span><span class="s5">&quot;y&quot;  </span><span class="s4"># not used in params_frame</span>
        <span class="s1">xname = [</span><span class="s5">&quot;subset #%d&quot; </span><span class="s1">% (ii + </span><span class="s3">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">ii </span><span class="s2">in </span><span class="s1">range(tstat.shape[</span><span class="s3">0</span><span class="s1">])]</span>

        <span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">summary_params</span>

        <span class="s2">return </span><span class="s1">summary_params(</span>
            <span class="s1">(</span><span class="s2">None, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">std_err</span><span class="s2">, </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">, </span><span class="s1">conf_int)</span><span class="s2">,</span>
            <span class="s1">alpha=alpha</span><span class="s2">,</span>
            <span class="s1">use_t=use_t</span><span class="s2">,</span>
            <span class="s1">yname=yname</span><span class="s2">,</span>
            <span class="s1">xname=xname</span><span class="s2">,</span>
            <span class="s1">title=title</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">std_meandiff_separatevar(self):</span>
        <span class="s4"># this uses ``_var`` to use ddof=0 for formula</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>
        <span class="s2">return </span><span class="s1">np.sqrt(d1._var / (d1.nobs - </span><span class="s3">1</span><span class="s1">) + d2._var / (d2.nobs - </span><span class="s3">1</span><span class="s1">))</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">std_meandiff_pooledvar(self):</span>
        <span class="s0">&quot;&quot;&quot;variance assuming equal variance in both data sets 
 
        &quot;&quot;&quot;</span>
        <span class="s4"># this uses ``_var`` to use ddof=0 for formula</span>

        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>
        <span class="s4"># could make var_pooled into attribute</span>
        <span class="s1">var_pooled = (</span>
            <span class="s1">(d1.sumsquares + d2.sumsquares)</span>
            <span class="s1">/</span>
            <span class="s4"># (d1.nobs - d1.ddof + d2.nobs - d2.ddof))</span>
            <span class="s1">(d1.nobs - </span><span class="s3">1 </span><span class="s1">+ d2.nobs - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">np.sqrt(var_pooled * (</span><span class="s3">1.0 </span><span class="s1">/ d1.nobs + </span><span class="s3">1.0 </span><span class="s1">/ d2.nobs))</span>

    <span class="s2">def </span><span class="s1">dof_satt(self):</span>
        <span class="s0">&quot;&quot;&quot;degrees of freedom of Satterthwaite for unequal variance 
        &quot;&quot;&quot;</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>
        <span class="s4"># this follows blindly the SPSS manual</span>
        <span class="s4"># except I use  ``_var`` which has ddof=0</span>
        <span class="s1">sem1 = d1._var / (d1.nobs - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">sem2 = d2._var / (d2.nobs - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">semsum = sem1 + sem2</span>
        <span class="s1">z1 = (sem1 / semsum) ** </span><span class="s3">2 </span><span class="s1">/ (d1.nobs - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">z2 = (sem2 / semsum) ** </span><span class="s3">2 </span><span class="s1">/ (d2.nobs - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">dof = </span><span class="s3">1.0 </span><span class="s1">/ (z1 + z2)</span>
        <span class="s2">return </span><span class="s1">dof</span>

    <span class="s2">def </span><span class="s1">ttest_ind(self</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">value=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;ttest for the null hypothesis of identical means 
 
        this should also be the same as onewaygls, except for ddof differences 
 
        Parameters 
        ---------- 
        x1 : array_like, 1-D or 2-D 
            first of the two independent samples, see notes for 2-D case 
        x2 : array_like, 1-D or 2-D 
            second of the two independent samples, see notes for 2-D case 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
            'two-sided': H1: difference in means not equal to value (default) 
            'larger' :   H1: difference in means larger than value 
            'smaller' :  H1: difference in means smaller than value 
 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
            of freedom is used 
        value : float 
            difference between the means under the Null hypothesis. 
 
 
        Returns 
        ------- 
        tstat : float 
            test statistic 
        pvalue : float 
            pvalue of the t-test 
        df : int or float 
            degrees of freedom used in the t-test 
 
        Notes 
        ----- 
        The result is independent of the user specified ddof. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>

        <span class="s2">if </span><span class="s1">usevar == </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
            <span class="s1">stdm = self.std_meandiff_pooledvar</span>
            <span class="s1">dof = d1.nobs - </span><span class="s3">1 </span><span class="s1">+ d2.nobs - </span><span class="s3">1</span>
        <span class="s2">elif </span><span class="s1">usevar == </span><span class="s5">&quot;unequal&quot;</span><span class="s1">:</span>
            <span class="s1">stdm = self.std_meandiff_separatevar</span>
            <span class="s1">dof = self.dof_satt()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">'usevar can only be &quot;pooled&quot; or &quot;unequal&quot;'</span><span class="s1">)</span>

        <span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval = _tstat_generic(</span>
            <span class="s1">d1.mean</span><span class="s2">, </span><span class="s1">d2.mean</span><span class="s2">, </span><span class="s1">stdm</span><span class="s2">, </span><span class="s1">dof</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">diff=value</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval</span><span class="s2">, </span><span class="s1">dof</span>

    <span class="s2">def </span><span class="s1">ztest_ind(self</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">value=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;z-test for the null hypothesis of identical means 
 
        Parameters 
        ---------- 
        x1 : array_like, 1-D or 2-D 
            first of the two independent samples, see notes for 2-D case 
        x2 : array_like, 1-D or 2-D 
            second of the two independent samples, see notes for 2-D case 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
            'two-sided': H1: difference in means not equal to value (default) 
            'larger' :   H1: difference in means larger than value 
            'smaller' :  H1: difference in means smaller than value 
 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then the standard deviations of the samples may 
            be different. 
        value : float 
            difference between the means under the Null hypothesis. 
 
        Returns 
        ------- 
        tstat : float 
            test statistic 
        pvalue : float 
            pvalue of the z-test 
 
        &quot;&quot;&quot;</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>

        <span class="s2">if </span><span class="s1">usevar == </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
            <span class="s1">stdm = self.std_meandiff_pooledvar</span>
        <span class="s2">elif </span><span class="s1">usevar == </span><span class="s5">&quot;unequal&quot;</span><span class="s1">:</span>
            <span class="s1">stdm = self.std_meandiff_separatevar</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">'usevar can only be &quot;pooled&quot; or &quot;unequal&quot;'</span><span class="s1">)</span>

        <span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval = _zstat_generic(</span>
            <span class="s1">d1.mean</span><span class="s2">, </span><span class="s1">d2.mean</span><span class="s2">, </span><span class="s1">stdm</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">diff=value</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval</span>

    <span class="s2">def </span><span class="s1">tconfint_diff(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;confidence interval for the difference in means 
 
        Parameters 
        ---------- 
        alpha : float 
            significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            This specifies the alternative hypothesis for the test that 
            corresponds to the confidence interval. 
            The alternative hypothesis, H1, has to be one of the following : 
 
            'two-sided': H1: difference in means not equal to value (default) 
            'larger' :   H1: difference in means larger than value 
            'smaller' :  H1: difference in means smaller than value 
 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
            of freedom is used 
 
        Returns 
        ------- 
        lower, upper : floats 
            lower and upper limits of the confidence interval 
 
        Notes 
        ----- 
        The result is independent of the user specified ddof. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>
        <span class="s1">diff = d1.mean - d2.mean</span>
        <span class="s2">if </span><span class="s1">usevar == </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
            <span class="s1">std_diff = self.std_meandiff_pooledvar</span>
            <span class="s1">dof = d1.nobs - </span><span class="s3">1 </span><span class="s1">+ d2.nobs - </span><span class="s3">1</span>
        <span class="s2">elif </span><span class="s1">usevar == </span><span class="s5">&quot;unequal&quot;</span><span class="s1">:</span>
            <span class="s1">std_diff = self.std_meandiff_separatevar</span>
            <span class="s1">dof = self.dof_satt()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">'usevar can only be &quot;pooled&quot; or &quot;unequal&quot;'</span><span class="s1">)</span>

        <span class="s1">res = _tconfint_generic(</span>
            <span class="s1">diff</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">dof</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">alternative=alternative</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">res</span>

    <span class="s2">def </span><span class="s1">zconfint_diff(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;confidence interval for the difference in means 
 
        Parameters 
        ---------- 
        alpha : float 
            significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            This specifies the alternative hypothesis for the test that 
            corresponds to the confidence interval. 
            The alternative hypothesis, H1, has to be one of the following : 
 
            'two-sided': H1: difference in means not equal to value (default) 
            'larger' :   H1: difference in means larger than value 
            'smaller' :  H1: difference in means smaller than value 
 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
            of freedom is used 
 
        Returns 
        ------- 
        lower, upper : floats 
            lower and upper limits of the confidence interval 
 
        Notes 
        ----- 
        The result is independent of the user specified ddof. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">d1 = self.d1</span>
        <span class="s1">d2 = self.d2</span>
        <span class="s1">diff = d1.mean - d2.mean</span>
        <span class="s2">if </span><span class="s1">usevar == </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
            <span class="s1">std_diff = self.std_meandiff_pooledvar</span>
        <span class="s2">elif </span><span class="s1">usevar == </span><span class="s5">&quot;unequal&quot;</span><span class="s1">:</span>
            <span class="s1">std_diff = self.std_meandiff_separatevar</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">'usevar can only be &quot;pooled&quot; or &quot;unequal&quot;'</span><span class="s1">)</span>

        <span class="s1">res = _zconfint_generic(</span>
            <span class="s1">diff</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">alternative=alternative</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">res</span>

    <span class="s2">def </span><span class="s1">ttost_ind(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        test of equivalence for two independent samples, base on t-test 
 
        Parameters 
        ---------- 
        low, upp : float 
            equivalence interval low &lt; m1 - m2 &lt; upp 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
            of freedom is used 
 
        Returns 
        ------- 
        pvalue : float 
            pvalue of the non-equivalence test 
        t1, pv1 : tuple of floats 
            test statistic and pvalue for lower threshold test 
        t2, pv2 : tuple of floats 
            test statistic and pvalue for upper threshold test 
        &quot;&quot;&quot;</span>
        <span class="s1">tt1 = self.ttest_ind(alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=low)</span>
        <span class="s1">tt2 = self.ttest_ind(alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=upp)</span>
        <span class="s4"># TODO: remove tuple return, use same as for function tost_ind</span>
        <span class="s2">return </span><span class="s1">np.maximum(tt1[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tt2[</span><span class="s3">1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">(tt1</span><span class="s2">, </span><span class="s1">tt2)</span>

    <span class="s2">def </span><span class="s1">ztost_ind(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        test of equivalence for two independent samples, based on z-test 
 
        Parameters 
        ---------- 
        low, upp : float 
            equivalence interval low &lt; m1 - m2 &lt; upp 
        usevar : str, 'pooled' or 'unequal' 
            If ``pooled``, then the standard deviation of the samples is assumed to be 
            the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
            of freedom is used 
 
        Returns 
        ------- 
        pvalue : float 
            pvalue of the non-equivalence test 
        t1, pv1 : tuple of floats 
            test statistic and pvalue for lower threshold test 
        t2, pv2 : tuple of floats 
            test statistic and pvalue for upper threshold test 
        &quot;&quot;&quot;</span>
        <span class="s1">tt1 = self.ztest_ind(alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=low)</span>
        <span class="s1">tt2 = self.ztest_ind(alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=upp)</span>
        <span class="s4"># TODO: remove tuple return, use same as for function tost_ind</span>
        <span class="s2">return </span><span class="s1">np.maximum(tt1[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tt2[</span><span class="s3">1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">tt1</span><span class="s2">, </span><span class="s1">tt2</span>

    <span class="s4"># tost.__doc__ = tost_ind.__doc__</span>


<span class="s4"># does not work for 2d, does not take weights into account</span>
<span class="s4">##    def test_equal_var(self):</span>
<span class="s4">##        &quot;&quot;&quot;Levene test for independence</span>
<span class="s4">##</span>
<span class="s4">##        &quot;&quot;&quot;</span>
<span class="s4">##        d1 = self.d1</span>
<span class="s4">##        d2 = self.d2</span>
<span class="s4">##        #rewrite this, for now just use scipy.stats</span>
<span class="s4">##        return stats.levene(d1.data, d2.data)</span>


<span class="s2">def </span><span class="s1">ttest_ind(</span>
    <span class="s1">x1</span><span class="s2">,</span>
    <span class="s1">x2</span><span class="s2">,</span>
    <span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">,</span>
    <span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">,</span>
    <span class="s1">weights=(</span><span class="s2">None, None</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">value=</span><span class="s3">0</span><span class="s2">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;ttest independent sample 
 
    Convenience function that uses the classes and throws away the intermediate 
    results, 
    compared to scipy stats: drops axis option, adds alternative, usevar, and 
    weights option. 
 
    Parameters 
    ---------- 
    x1 : array_like, 1-D or 2-D 
        first of the two independent samples, see notes for 2-D case 
    x2 : array_like, 1-D or 2-D 
        second of the two independent samples, see notes for 2-D case 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           * 'two-sided' (default): H1: difference in means not equal to value 
           * 'larger' :   H1: difference in means larger than value 
           * 'smaller' :  H1: difference in means smaller than value 
 
    usevar : str, 'pooled' or 'unequal' 
        If ``pooled``, then the standard deviation of the samples is assumed to be 
        the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
        of freedom is used 
    weights : tuple of None or ndarrays 
        Case weights for the two samples. For details on weights see 
        ``DescrStatsW`` 
    value : float 
        difference between the means under the Null hypothesis. 
 
 
    Returns 
    ------- 
    tstat : float 
        test statistic 
    pvalue : float 
        pvalue of the t-test 
    df : int or float 
        degrees of freedom used in the t-test 
 
    &quot;&quot;&quot;</span>
    <span class="s1">cm = CompareMeans(</span>
        <span class="s1">DescrStatsW(x1</span><span class="s2">, </span><span class="s1">weights=weights[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">DescrStatsW(x2</span><span class="s2">, </span><span class="s1">weights=weights[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval</span><span class="s2">, </span><span class="s1">dof = cm.ttest_ind(</span>
        <span class="s1">alternative=alternative</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=value</span>
    <span class="s1">)</span>

    <span class="s2">return </span><span class="s1">tstat</span><span class="s2">, </span><span class="s1">pval</span><span class="s2">, </span><span class="s1">dof</span>


<span class="s2">def </span><span class="s1">ttost_ind(</span>
    <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">weights=(</span><span class="s2">None, None</span><span class="s1">)</span><span class="s2">, </span><span class="s1">transform=</span><span class="s2">None</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;test of (non-)equivalence for two independent samples 
 
    TOST: two one-sided t tests 
 
    null hypothesis:  m1 - m2 &lt; low or m1 - m2 &gt; upp 
    alternative hypothesis:  low &lt; m1 - m2 &lt; upp 
 
    where m1, m2 are the means, expected values of the two samples. 
 
    If the pvalue is smaller than a threshold, say 0.05, then we reject the 
    hypothesis that the difference between the two samples is larger than the 
    the thresholds given by low and upp. 
 
    Parameters 
    ---------- 
    x1 : array_like, 1-D or 2-D 
        first of the two independent samples, see notes for 2-D case 
    x2 : array_like, 1-D or 2-D 
        second of the two independent samples, see notes for 2-D case 
    low, upp : float 
        equivalence interval low &lt; m1 - m2 &lt; upp 
    usevar : str, 'pooled' or 'unequal' 
        If ``pooled``, then the standard deviation of the samples is assumed to be 
        the same. If ``unequal``, then Welch ttest with Satterthwait degrees 
        of freedom is used 
    weights : tuple of None or ndarrays 
        Case weights for the two samples. For details on weights see 
        ``DescrStatsW`` 
    transform : None or function 
        If None (default), then the data is not transformed. Given a function, 
        sample data and thresholds are transformed. If transform is log, then 
        the equivalence interval is in ratio: low &lt; m1 / m2 &lt; upp 
 
    Returns 
    ------- 
    pvalue : float 
        pvalue of the non-equivalence test 
    t1, pv1 : tuple of floats 
        test statistic and pvalue for lower threshold test 
    t2, pv2 : tuple of floats 
        test statistic and pvalue for upper threshold test 
 
    Notes 
    ----- 
    The test rejects if the 2*alpha confidence interval for the difference 
    is contained in the ``(low, upp)`` interval. 
 
    This test works also for multi-endpoint comparisons: If d1 and d2 
    have the same number of columns, then each column of the data in d1 is 
    compared with the corresponding column in d2. This is the same as 
    comparing each of the corresponding columns separately. Currently no 
    multi-comparison correction is used. The raw p-values reported here can 
    be correction with the functions in ``multitest``. 
 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">transform:</span>
        <span class="s2">if </span><span class="s1">transform </span><span class="s2">is </span><span class="s1">np.log:</span>
            <span class="s4"># avoid hstack in special case</span>
            <span class="s1">x1 = transform(x1)</span>
            <span class="s1">x2 = transform(x2)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># for transforms like rankdata that will need both datasets</span>
            <span class="s4"># concatenate works for stacking 1d and 2d arrays</span>
            <span class="s1">xx = transform(np.concatenate((x1</span><span class="s2">, </span><span class="s1">x2)</span><span class="s2">, </span><span class="s3">0</span><span class="s1">))</span>
            <span class="s1">x1 = xx[: len(x1)]</span>
            <span class="s1">x2 = xx[len(x1) :]</span>
        <span class="s1">low = transform(low)</span>
        <span class="s1">upp = transform(upp)</span>
    <span class="s1">cm = CompareMeans(</span>
        <span class="s1">DescrStatsW(x1</span><span class="s2">, </span><span class="s1">weights=weights[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">DescrStatsW(x2</span><span class="s2">, </span><span class="s1">weights=weights[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">pval</span><span class="s2">, </span><span class="s1">res = cm.ttost_ind(low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">usevar=usevar)</span>
    <span class="s2">return </span><span class="s1">pval</span><span class="s2">, </span><span class="s1">res[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">res[</span><span class="s3">1</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">ttost_paired(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">transform=</span><span class="s2">None, </span><span class="s1">weights=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;test of (non-)equivalence for two dependent, paired sample 
 
    TOST: two one-sided t tests 
 
    null hypothesis:  md &lt; low or md &gt; upp 
    alternative hypothesis:  low &lt; md &lt; upp 
 
    where md is the mean, expected value of the difference x1 - x2 
 
    If the pvalue is smaller than a threshold,say 0.05, then we reject the 
    hypothesis that the difference between the two samples is larger than the 
    the thresholds given by low and upp. 
 
    Parameters 
    ---------- 
    x1 : array_like 
        first of the two independent samples 
    x2 : array_like 
        second of the two independent samples 
    low, upp : float 
        equivalence interval low &lt; mean of difference &lt; upp 
    weights : None or ndarray 
        case weights for the two samples. For details on weights see 
        ``DescrStatsW`` 
    transform : None or function 
        If None (default), then the data is not transformed. Given a function 
        sample data and thresholds are transformed. If transform is log the 
        the equivalence interval is in ratio: low &lt; x1 / x2 &lt; upp 
 
    Returns 
    ------- 
    pvalue : float 
        pvalue of the non-equivalence test 
    t1, pv1, df1 : tuple 
        test statistic, pvalue and degrees of freedom for lower threshold test 
    t2, pv2, df2 : tuple 
        test statistic, pvalue and degrees of freedom for upper threshold test 
 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">transform:</span>
        <span class="s2">if </span><span class="s1">transform </span><span class="s2">is </span><span class="s1">np.log:</span>
            <span class="s4"># avoid hstack in special case</span>
            <span class="s1">x1 = transform(x1)</span>
            <span class="s1">x2 = transform(x2)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># for transforms like rankdata that will need both datasets</span>
            <span class="s4"># concatenate works for stacking 1d and 2d arrays</span>
            <span class="s1">xx = transform(np.concatenate((x1</span><span class="s2">, </span><span class="s1">x2)</span><span class="s2">, </span><span class="s3">0</span><span class="s1">))</span>
            <span class="s1">x1 = xx[: len(x1)]</span>
            <span class="s1">x2 = xx[len(x1) :]</span>
        <span class="s1">low = transform(low)</span>
        <span class="s1">upp = transform(upp)</span>
    <span class="s1">dd = DescrStatsW(x1 - x2</span><span class="s2">, </span><span class="s1">weights=weights</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">t1</span><span class="s2">, </span><span class="s1">pv1</span><span class="s2">, </span><span class="s1">df1 = dd.ttest_mean(low</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s1">)</span>
    <span class="s1">t2</span><span class="s2">, </span><span class="s1">pv2</span><span class="s2">, </span><span class="s1">df2 = dd.ttest_mean(upp</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">np.maximum(pv1</span><span class="s2">, </span><span class="s1">pv2)</span><span class="s2">, </span><span class="s1">(t1</span><span class="s2">, </span><span class="s1">pv1</span><span class="s2">, </span><span class="s1">df1)</span><span class="s2">, </span><span class="s1">(t2</span><span class="s2">, </span><span class="s1">pv2</span><span class="s2">, </span><span class="s1">df2)</span>


<span class="s2">def </span><span class="s1">ztest(</span>
    <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2=</span><span class="s2">None, </span><span class="s1">value=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">1.0</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;test for mean based on normal distribution, one or two samples 
 
    In the case of two samples, the samples are assumed to be independent. 
 
    Parameters 
    ---------- 
    x1 : array_like, 1-D or 2-D 
        first of the two independent samples 
    x2 : array_like, 1-D or 2-D 
        second of the two independent samples 
    value : float 
        In the one sample case, value is the mean of x1 under the Null 
        hypothesis. 
        In the two sample case, value is the difference between mean of x1 and 
        mean of x2 under the Null hypothesis. The test statistic is 
        `x1_mean - x2_mean - value`. 
    alternative : str 
        The alternative hypothesis, H1, has to be one of the following 
 
           'two-sided': H1: difference in means not equal to value (default) 
           'larger' :   H1: difference in means larger than value 
           'smaller' :  H1: difference in means smaller than value 
 
    usevar : str, 'pooled' 
        Currently, only 'pooled' is implemented. 
        If ``pooled``, then the standard deviation of the samples is assumed to be 
        the same. see CompareMeans.ztest_ind for different options. 
    ddof : int 
        Degrees of freedom use in the calculation of the variance of the mean 
        estimate. In the case of comparing means this is one, however it can 
        be adjusted for testing other statistics (proportion, correlation) 
 
    Returns 
    ------- 
    tstat : float 
        test statistic 
    pvalue : float 
        pvalue of the t-test 
 
    Notes 
    ----- 
    usevar not implemented, is always pooled in two sample case 
    use CompareMeans instead. 
 
    &quot;&quot;&quot;</span>
    <span class="s4"># TODO: this should delegate to CompareMeans like ttest_ind</span>
    <span class="s4">#       However that does not implement ddof</span>

    <span class="s4"># usevar is not used, always pooled</span>

    <span class="s2">if </span><span class="s1">usevar != </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s5">'only usevar=&quot;pooled&quot; is implemented'</span><span class="s1">)</span>

    <span class="s1">x1 = np.asarray(x1)</span>
    <span class="s1">nobs1 = x1.shape[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">x1_mean = x1.mean(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x1_var = x1.var(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">x2 </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">x2 = np.asarray(x2)</span>
        <span class="s1">nobs2 = x2.shape[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">x2_mean = x2.mean(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">x2_var = x2.var(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">var_pooled = nobs1 * x1_var + nobs2 * x2_var</span>
        <span class="s1">var_pooled /= nobs1 + nobs2 - </span><span class="s3">2 </span><span class="s1">* ddof</span>
        <span class="s1">var_pooled *= </span><span class="s3">1.0 </span><span class="s1">/ nobs1 + </span><span class="s3">1.0 </span><span class="s1">/ nobs2</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">var_pooled = x1_var / (nobs1 - ddof)</span>
        <span class="s1">x2_mean = </span><span class="s3">0</span>

    <span class="s1">std_diff = np.sqrt(var_pooled)</span>
    <span class="s4"># stat = x1_mean - x2_mean - value</span>
    <span class="s2">return </span><span class="s1">_zstat_generic(x1_mean</span><span class="s2">, </span><span class="s1">x2_mean</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">diff=value)</span>


<span class="s2">def </span><span class="s1">zconfint(</span>
    <span class="s1">x1</span><span class="s2">,</span>
    <span class="s1">x2=</span><span class="s2">None,</span>
    <span class="s1">value=</span><span class="s3">0</span><span class="s2">,</span>
    <span class="s1">alpha=</span><span class="s3">0.05</span><span class="s2">,</span>
    <span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s2">,</span>
    <span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">,</span>
    <span class="s1">ddof=</span><span class="s3">1.0</span><span class="s2">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;confidence interval based on normal distribution z-test 
 
    Parameters 
    ---------- 
    x1 : array_like, 1-D or 2-D 
        first of the two independent samples, see notes for 2-D case 
    x2 : array_like, 1-D or 2-D 
        second of the two independent samples, see notes for 2-D case 
    value : float 
        In the one sample case, value is the mean of x1 under the Null 
        hypothesis. 
        In the two sample case, value is the difference between mean of x1 and 
        mean of x2 under the Null hypothesis. The test statistic is 
        `x1_mean - x2_mean - value`. 
    usevar : str, 'pooled' 
        Currently, only 'pooled' is implemented. 
        If ``pooled``, then the standard deviation of the samples is assumed to be 
        the same. see CompareMeans.ztest_ind for different options. 
    ddof : int 
        Degrees of freedom use in the calculation of the variance of the mean 
        estimate. In the case of comparing means this is one, however it can 
        be adjusted for testing other statistics (proportion, correlation) 
 
    Notes 
    ----- 
    checked only for 1 sample case 
 
    usevar not implemented, is always pooled in two sample case 
 
    ``value`` shifts the confidence interval so it is centered at 
    `x1_mean - x2_mean - value` 
 
    See Also 
    -------- 
    ztest 
    CompareMeans 
 
    &quot;&quot;&quot;</span>
    <span class="s4"># usevar is not used, always pooled</span>
    <span class="s4"># mostly duplicate code from ztest</span>

    <span class="s2">if </span><span class="s1">usevar != </span><span class="s5">&quot;pooled&quot;</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s5">'only usevar=&quot;pooled&quot; is implemented'</span><span class="s1">)</span>
    <span class="s1">x1 = np.asarray(x1)</span>
    <span class="s1">nobs1 = x1.shape[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">x1_mean = x1.mean(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x1_var = x1.var(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">x2 </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">x2 = np.asarray(x2)</span>
        <span class="s1">nobs2 = x2.shape[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">x2_mean = x2.mean(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">x2_var = x2.var(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">var_pooled = nobs1 * x1_var + nobs2 * x2_var</span>
        <span class="s1">var_pooled /= nobs1 + nobs2 - </span><span class="s3">2 </span><span class="s1">* ddof</span>
        <span class="s1">var_pooled *= </span><span class="s3">1.0 </span><span class="s1">/ nobs1 + </span><span class="s3">1.0 </span><span class="s1">/ nobs2</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">var_pooled = x1_var / (nobs1 - ddof)</span>
        <span class="s1">x2_mean = </span><span class="s3">0</span>

    <span class="s1">std_diff = np.sqrt(var_pooled)</span>
    <span class="s1">ci = _zconfint_generic(</span>
        <span class="s1">x1_mean - x2_mean - value</span><span class="s2">, </span><span class="s1">std_diff</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">alternative</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">ci</span>


<span class="s2">def </span><span class="s1">ztost(x1</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp</span><span class="s2">, </span><span class="s1">x2=</span><span class="s2">None, </span><span class="s1">usevar=</span><span class="s5">&quot;pooled&quot;</span><span class="s2">, </span><span class="s1">ddof=</span><span class="s3">1.0</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Equivalence test based on normal distribution 
 
    Parameters 
    ---------- 
    x1 : array_like 
        one sample or first sample for 2 independent samples 
    low, upp : float 
        equivalence interval low &lt; m1 - m2 &lt; upp 
    x1 : array_like or None 
        second sample for 2 independent samples test. If None, then a 
        one-sample test is performed. 
    usevar : str, 'pooled' 
        If `pooled`, then the standard deviation of the samples is assumed to be 
        the same. Only `pooled` is currently implemented. 
 
    Returns 
    ------- 
    pvalue : float 
        pvalue of the non-equivalence test 
    t1, pv1 : tuple of floats 
        test statistic and pvalue for lower threshold test 
    t2, pv2 : tuple of floats 
        test statistic and pvalue for upper threshold test 
 
    Notes 
    ----- 
    checked only for 1 sample case 
 
    &quot;&quot;&quot;</span>
    <span class="s1">tt1 = ztest(</span>
        <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;larger&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=low</span><span class="s2">, </span><span class="s1">ddof=ddof</span>
    <span class="s1">)</span>
    <span class="s1">tt2 = ztest(</span>
        <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">alternative=</span><span class="s5">&quot;smaller&quot;</span><span class="s2">, </span><span class="s1">usevar=usevar</span><span class="s2">, </span><span class="s1">value=upp</span><span class="s2">, </span><span class="s1">ddof=ddof</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">(</span>
        <span class="s1">np.maximum(tt1[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tt2[</span><span class="s3">1</span><span class="s1">])</span><span class="s2">,</span>
        <span class="s1">tt1</span><span class="s2">,</span>
        <span class="s1">tt2</span><span class="s2">,</span>
    <span class="s1">)</span>
</pre>
</body>
</html>
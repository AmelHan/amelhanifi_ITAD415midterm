<html>
<head>
<title>test_entropy.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_entropy.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_equal</span><span class="s0">, </span><span class="s1">assert_allclose</span>
<span class="s2"># avoid new uses of the following; prefer assert/np.testing.assert_allclose</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(assert_</span><span class="s0">, </span><span class="s1">assert_almost_equal</span><span class="s0">,</span>
                           <span class="s1">assert_array_almost_equal)</span>

<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">pytest </span><span class="s0">import </span><span class="s1">raises </span><span class="s0">as </span><span class="s1">assert_raises</span>
<span class="s0">import </span><span class="s1">scipy.stats </span><span class="s0">as </span><span class="s1">stats</span>


<span class="s0">class </span><span class="s1">TestEntropy:</span>
    <span class="s0">def </span><span class="s1">test_entropy_positive(self):</span>
        <span class="s2"># See ticket #497</span>
        <span class="s1">pk = [</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span>
        <span class="s1">qk = [</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">0.65</span><span class="s1">]</span>
        <span class="s1">eself = stats.entropy(pk</span><span class="s0">, </span><span class="s1">pk)</span>
        <span class="s1">edouble = stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk)</span>
        <span class="s1">assert_(</span><span class="s3">0.0 </span><span class="s1">== eself)</span>
        <span class="s1">assert_(edouble &gt;= </span><span class="s3">0.0</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_entropy_base(self):</span>
        <span class="s1">pk = np.ones(</span><span class="s3">16</span><span class="s0">, </span><span class="s1">float)</span>
        <span class="s1">S = stats.entropy(pk</span><span class="s0">, </span><span class="s1">base=</span><span class="s3">2.</span><span class="s1">)</span>
        <span class="s1">assert_(abs(S - </span><span class="s3">4.</span><span class="s1">) &lt; </span><span class="s3">1.e-5</span><span class="s1">)</span>

        <span class="s1">qk = np.ones(</span><span class="s3">16</span><span class="s0">, </span><span class="s1">float)</span>
        <span class="s1">qk[:</span><span class="s3">8</span><span class="s1">] = </span><span class="s3">2.</span>
        <span class="s1">S = stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk)</span>
        <span class="s1">S2 = stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk</span><span class="s0">, </span><span class="s1">base=</span><span class="s3">2.</span><span class="s1">)</span>
        <span class="s1">assert_(abs(S/S2 - np.log(</span><span class="s3">2.</span><span class="s1">)) &lt; </span><span class="s3">1.e-5</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_entropy_zero(self):</span>
        <span class="s2"># Test for PR-479</span>
        <span class="s1">assert_almost_equal(stats.entropy([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span><span class="s0">, </span><span class="s3">0.63651416829481278</span><span class="s0">,</span>
                            <span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_entropy_2d(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">qk = [[</span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk)</span><span class="s0">,</span>
                                  <span class="s1">[</span><span class="s3">0.1933259</span><span class="s0">, </span><span class="s3">0.18609809</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">test_entropy_2d_zero(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">qk = [[</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk)</span><span class="s0">,</span>
                                  <span class="s1">[np.inf</span><span class="s0">, </span><span class="s3">0.18609809</span><span class="s1">])</span>

        <span class="s1">pk[</span><span class="s3">0</span><span class="s1">][</span><span class="s3">0</span><span class="s1">] = </span><span class="s3">0.0</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk)</span><span class="s0">,</span>
                                  <span class="s1">[</span><span class="s3">0.17403988</span><span class="s0">, </span><span class="s3">0.18609809</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">test_entropy_base_2d_nondefault_axis(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">[</span><span class="s3">0.63651417</span><span class="s0">, </span><span class="s3">0.63651417</span><span class="s0">, </span><span class="s3">0.66156324</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">test_entropy_2d_nondefault_axis(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">qk = [[</span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">[</span><span class="s3">0.231049</span><span class="s0">, </span><span class="s3">0.231049</span><span class="s0">, </span><span class="s3">0.127706</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">test_entropy_raises_value_error(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">qk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]]</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">stats.entropy</span><span class="s0">, </span><span class="s1">pk</span><span class="s0">, </span><span class="s1">qk)</span>

    <span class="s0">def </span><span class="s1">test_base_entropy_with_axis_0_is_equal_to_default(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">stats.entropy(pk))</span>

    <span class="s0">def </span><span class="s1">test_entropy_with_axis_0_is_equal_to_default(self):</span>
        <span class="s1">pk = [[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]]</span>
        <span class="s1">qk = [[</span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]]</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk))</span>

    <span class="s0">def </span><span class="s1">test_base_entropy_transposed(self):</span>
        <span class="s1">pk = np.array([[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]])</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk.T).T</span><span class="s0">,</span>
                                  <span class="s1">stats.entropy(pk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">test_entropy_transposed(self):</span>
        <span class="s1">pk = np.array([[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.6</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]])</span>
        <span class="s1">qk = np.array([[</span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.6</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.3</span><span class="s1">]])</span>
        <span class="s1">assert_array_almost_equal(stats.entropy(pk.T</span><span class="s0">, </span><span class="s1">qk.T).T</span><span class="s0">,</span>
                                  <span class="s1">stats.entropy(pk</span><span class="s0">, </span><span class="s1">qk</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">test_entropy_broadcasting(self):</span>
        <span class="s1">np.random.rand(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">x = np.random.rand(</span><span class="s3">3</span><span class="s1">)</span>
        <span class="s1">y = np.random.rand(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">res = stats.entropy(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_equal(res[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.entropy(x</span><span class="s0">, </span><span class="s1">y[</span><span class="s3">0</span><span class="s1">]))</span>
        <span class="s1">assert_equal(res[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.entropy(x</span><span class="s0">, </span><span class="s1">y[</span><span class="s3">1</span><span class="s1">]))</span>

    <span class="s0">def </span><span class="s1">test_entropy_shape_mismatch(self):</span>
        <span class="s1">x = np.random.rand(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">12</span><span class="s1">)</span>
        <span class="s1">y = np.random.rand(</span><span class="s3">11</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">message = </span><span class="s4">&quot;shape mismatch: objects cannot be broadcast&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.entropy(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">def </span><span class="s1">test_input_validation(self):</span>
        <span class="s1">x = np.random.rand(</span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">message = </span><span class="s4">&quot;`base` must be a positive number.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.entropy(x</span><span class="s0">, </span><span class="s1">base=-</span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">TestDifferentialEntropy:</span>
    <span class="s5">&quot;&quot;&quot; 
    Vasicek results are compared with the R package vsgoftest. 
 
    # library(vsgoftest) 
    # 
    # samp &lt;- c(&lt;values&gt;) 
    # entropy.estimate(x = samp, window = &lt;window_length&gt;) 
 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">test_differential_entropy_vasicek(self):</span>

        <span class="s1">random_state = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">values = random_state.standard_normal(</span><span class="s3">100</span><span class="s1">)</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(entropy</span><span class="s0">, </span><span class="s3">1.342551</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">window_length=</span><span class="s3">1</span><span class="s0">,</span>
                                             <span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(entropy</span><span class="s0">, </span><span class="s3">1.122044</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">window_length=</span><span class="s3">8</span><span class="s0">,</span>
                                             <span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(entropy</span><span class="s0">, </span><span class="s3">1.349401</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_differential_entropy_vasicek_2d_nondefault_axis(self):</span>
        <span class="s1">random_state = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">values = random_state.standard_normal((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">100</span><span class="s1">))</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">entropy</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">1.342551</span><span class="s0">, </span><span class="s3">1.341826</span><span class="s0">, </span><span class="s3">1.293775</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s0">,</span>
        <span class="s1">)</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">window_length=</span><span class="s3">1</span><span class="s0">,</span>
                                             <span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">entropy</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">1.122044</span><span class="s0">, </span><span class="s3">1.102944</span><span class="s0">, </span><span class="s3">1.129616</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s0">,</span>
        <span class="s1">)</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">window_length=</span><span class="s3">8</span><span class="s0">,</span>
                                             <span class="s1">method=</span><span class="s4">'vasicek'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">entropy</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">1.349401</span><span class="s0">, </span><span class="s3">1.338514</span><span class="s0">, </span><span class="s3">1.292332</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_differential_entropy_raises_value_error(self):</span>
        <span class="s1">random_state = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">values = random_state.standard_normal((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">100</span><span class="s1">))</span>

        <span class="s1">error_str = (</span>
            <span class="s4">r&quot;Window length \({window_length}\) must be positive and less &quot;</span>
            <span class="s4">r&quot;than half the sample size \({sample_size}\).&quot;</span>
        <span class="s1">)</span>

        <span class="s1">sample_size = values.shape[</span><span class="s3">1</span><span class="s1">]</span>

        <span class="s0">for </span><span class="s1">window_length </span><span class="s0">in </span><span class="s1">{-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s1">sample_size//</span><span class="s3">2</span><span class="s0">, </span><span class="s1">sample_size}:</span>

            <span class="s1">formatted_error_str = error_str.format(</span>
                <span class="s1">window_length=window_length</span><span class="s0">,</span>
                <span class="s1">sample_size=sample_size</span><span class="s0">,</span>
            <span class="s1">)</span>

            <span class="s0">with </span><span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">match=formatted_error_str):</span>
                <span class="s1">stats.differential_entropy(</span>
                    <span class="s1">values</span><span class="s0">,</span>
                    <span class="s1">window_length=window_length</span><span class="s0">,</span>
                    <span class="s1">axis=</span><span class="s3">1</span><span class="s0">,</span>
                <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_base_differential_entropy_with_axis_0_is_equal_to_default(self):</span>
        <span class="s1">random_state = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">values = random_state.standard_normal((</span><span class="s3">100</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>

        <span class="s1">entropy = stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">default_entropy = stats.differential_entropy(values)</span>
        <span class="s1">assert_allclose(entropy</span><span class="s0">, </span><span class="s1">default_entropy)</span>

    <span class="s0">def </span><span class="s1">test_base_differential_entropy_transposed(self):</span>
        <span class="s1">random_state = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">values = random_state.standard_normal((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">100</span><span class="s1">))</span>

        <span class="s1">assert_allclose(</span>
            <span class="s1">stats.differential_entropy(values.T).T</span><span class="s0">,</span>
            <span class="s1">stats.differential_entropy(values</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_input_validation(self):</span>
        <span class="s1">x = np.random.rand(</span><span class="s3">10</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s4">&quot;`base` must be a positive number or `None`.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.differential_entropy(x</span><span class="s0">, </span><span class="s1">base=-</span><span class="s3">2</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s4">&quot;`method` must be one of...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.differential_entropy(x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'ekki-ekki'</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'method'</span><span class="s0">, </span><span class="s1">[</span><span class="s4">'vasicek'</span><span class="s0">, </span><span class="s4">'van es'</span><span class="s0">,</span>
                                        <span class="s4">'ebrahimi'</span><span class="s0">, </span><span class="s4">'correa'</span><span class="s1">])</span>
    <span class="s0">def </span><span class="s1">test_consistency(self</span><span class="s0">, </span><span class="s1">method):</span>
        <span class="s2"># test that method is a consistent estimator</span>
        <span class="s1">n = </span><span class="s3">10000 </span><span class="s0">if </span><span class="s1">method == </span><span class="s4">'correa' </span><span class="s0">else </span><span class="s3">1000000</span>
        <span class="s1">rvs = stats.norm.rvs(size=n</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">expected = stats.norm.entropy()</span>
        <span class="s1">res = stats.differential_entropy(rvs</span><span class="s0">, </span><span class="s1">method=method)</span>
        <span class="s1">assert_allclose(res</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">0.005</span><span class="s1">)</span>

    <span class="s2"># values from differential_entropy reference [6], table 1, n=50, m=7</span>
    <span class="s1">norm_rmse_std_cases = {  </span><span class="s2"># method: (RMSE, STD)</span>
                           <span class="s4">'vasicek'</span><span class="s1">: (</span><span class="s3">0.198</span><span class="s0">, </span><span class="s3">0.109</span><span class="s1">)</span><span class="s0">,</span>
                           <span class="s4">'van es'</span><span class="s1">: (</span><span class="s3">0.212</span><span class="s0">, </span><span class="s3">0.110</span><span class="s1">)</span><span class="s0">,</span>
                           <span class="s4">'correa'</span><span class="s1">: (</span><span class="s3">0.135</span><span class="s0">, </span><span class="s3">0.112</span><span class="s1">)</span><span class="s0">,</span>
                           <span class="s4">'ebrahimi'</span><span class="s1">: (</span><span class="s3">0.128</span><span class="s0">, </span><span class="s3">0.109</span><span class="s1">)</span>
                           <span class="s1">}</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'method, expected'</span><span class="s0">,</span>
                             <span class="s1">list(norm_rmse_std_cases.items()))</span>
    <span class="s0">def </span><span class="s1">test_norm_rmse_std(self</span><span class="s0">, </span><span class="s1">method</span><span class="s0">, </span><span class="s1">expected):</span>
        <span class="s2"># test that RMSE and standard deviation of estimators matches values</span>
        <span class="s2"># given in differential_entropy reference [6]. Incidentally, also</span>
        <span class="s2"># tests vectorization.</span>
        <span class="s1">reps</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">m = </span><span class="s3">10000</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s3">7</span>
        <span class="s1">rmse_expected</span><span class="s0">, </span><span class="s1">std_expected = expected</span>
        <span class="s1">rvs = stats.norm.rvs(size=(reps</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">true_entropy = stats.norm.entropy()</span>
        <span class="s1">res = stats.differential_entropy(rvs</span><span class="s0">, </span><span class="s1">window_length=m</span><span class="s0">,</span>
                                         <span class="s1">method=method</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.sqrt(np.mean((res - true_entropy)**</span><span class="s3">2</span><span class="s1">))</span><span class="s0">,</span>
                        <span class="s1">rmse_expected</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">0.005</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.std(res)</span><span class="s0">, </span><span class="s1">std_expected</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">0.002</span><span class="s1">)</span>

    <span class="s2"># values from differential_entropy reference [6], table 2, n=50, m=7</span>
    <span class="s1">expon_rmse_std_cases = {  </span><span class="s2"># method: (RMSE, STD)</span>
                            <span class="s4">'vasicek'</span><span class="s1">: (</span><span class="s3">0.194</span><span class="s0">, </span><span class="s3">0.148</span><span class="s1">)</span><span class="s0">,</span>
                            <span class="s4">'van es'</span><span class="s1">: (</span><span class="s3">0.179</span><span class="s0">, </span><span class="s3">0.149</span><span class="s1">)</span><span class="s0">,</span>
                            <span class="s4">'correa'</span><span class="s1">: (</span><span class="s3">0.155</span><span class="s0">, </span><span class="s3">0.152</span><span class="s1">)</span><span class="s0">,</span>
                            <span class="s4">'ebrahimi'</span><span class="s1">: (</span><span class="s3">0.151</span><span class="s0">, </span><span class="s3">0.148</span><span class="s1">)</span>
                            <span class="s1">}</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'method, expected'</span><span class="s0">,</span>
                             <span class="s1">list(expon_rmse_std_cases.items()))</span>
    <span class="s0">def </span><span class="s1">test_expon_rmse_std(self</span><span class="s0">, </span><span class="s1">method</span><span class="s0">, </span><span class="s1">expected):</span>
        <span class="s2"># test that RMSE and standard deviation of estimators matches values</span>
        <span class="s2"># given in differential_entropy reference [6]. Incidentally, also</span>
        <span class="s2"># tests vectorization.</span>
        <span class="s1">reps</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">m = </span><span class="s3">10000</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s3">7</span>
        <span class="s1">rmse_expected</span><span class="s0">, </span><span class="s1">std_expected = expected</span>
        <span class="s1">rvs = stats.expon.rvs(size=(reps</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">true_entropy = stats.expon.entropy()</span>
        <span class="s1">res = stats.differential_entropy(rvs</span><span class="s0">, </span><span class="s1">window_length=m</span><span class="s0">,</span>
                                         <span class="s1">method=method</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.sqrt(np.mean((res - true_entropy)**</span><span class="s3">2</span><span class="s1">))</span><span class="s0">,</span>
                        <span class="s1">rmse_expected</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">0.005</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.std(res)</span><span class="s0">, </span><span class="s1">std_expected</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">0.002</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'n, method'</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">8</span><span class="s0">, </span><span class="s4">'van es'</span><span class="s1">)</span><span class="s0">,</span>
                                           <span class="s1">(</span><span class="s3">12</span><span class="s0">, </span><span class="s4">'ebrahimi'</span><span class="s1">)</span><span class="s0">,</span>
                                           <span class="s1">(</span><span class="s3">1001</span><span class="s0">, </span><span class="s4">'vasicek'</span><span class="s1">)])</span>
    <span class="s0">def </span><span class="s1">test_method_auto(self</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">method):</span>
        <span class="s1">rvs = stats.norm.rvs(size=(n</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">res1 = stats.differential_entropy(rvs)</span>
        <span class="s1">res2 = stats.differential_entropy(rvs</span><span class="s0">, </span><span class="s1">method=method)</span>
        <span class="s0">assert </span><span class="s1">res1 == res2</span>
</pre>
</body>
</html>
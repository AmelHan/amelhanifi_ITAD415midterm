<html>
<head>
<title>test_kdeoth.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_kdeoth.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">stats</span><span class="s0">, </span><span class="s1">linalg</span><span class="s0">, </span><span class="s1">integrate</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(assert_almost_equal</span><span class="s0">, </span><span class="s1">assert_</span><span class="s0">, </span><span class="s1">assert_equal</span><span class="s0">,</span>
                           <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
                           <span class="s1">assert_array_almost_equal_nulp</span><span class="s0">, </span><span class="s1">assert_allclose)</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">pytest </span><span class="s0">import </span><span class="s1">raises </span><span class="s0">as </span><span class="s1">assert_raises</span>


<span class="s0">def </span><span class="s1">test_kde_1d():</span>
    <span class="s2">#some basic tests comparing to normal distribution</span>
    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">500</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>
    <span class="s1">xnmean = xn.mean()</span>
    <span class="s1">xnstd = xn.std(ddof=</span><span class="s3">1</span><span class="s1">)</span>

    <span class="s2"># get kde for original sample</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>

    <span class="s2"># evaluate the density function for the kde for some points</span>
    <span class="s1">xs = np.linspace(-</span><span class="s3">7</span><span class="s0">,</span><span class="s3">7</span><span class="s0">,</span><span class="s3">501</span><span class="s1">)</span>
    <span class="s1">kdepdf = gkde.evaluate(xs)</span>
    <span class="s1">normpdf = stats.norm.pdf(xs</span><span class="s0">, </span><span class="s1">loc=xnmean</span><span class="s0">, </span><span class="s1">scale=xnstd)</span>
    <span class="s1">intervall = xs[</span><span class="s3">1</span><span class="s1">] - xs[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">assert_(np.sum((kdepdf - normpdf)**</span><span class="s3">2</span><span class="s1">)*intervall &lt; </span><span class="s3">0.01</span><span class="s1">)</span>
    <span class="s1">prob1 = gkde.integrate_box_1d(xnmean</span><span class="s0">, </span><span class="s1">np.inf)</span>
    <span class="s1">prob2 = gkde.integrate_box_1d(-np.inf</span><span class="s0">, </span><span class="s1">xnmean)</span>
    <span class="s1">assert_almost_equal(prob1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(prob2</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_box(xnmean</span><span class="s0">, </span><span class="s1">np.inf)</span><span class="s0">, </span><span class="s1">prob1</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">13</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_box(-np.inf</span><span class="s0">, </span><span class="s1">xnmean)</span><span class="s0">, </span><span class="s1">prob2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">13</span><span class="s1">)</span>

    <span class="s1">assert_almost_equal(gkde.integrate_kde(gkde)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf**</span><span class="s3">2</span><span class="s1">).sum()*intervall</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_gaussian(xnmean</span><span class="s0">, </span><span class="s1">xnstd**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf*normpdf).sum()*intervall</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_kde_1d_weighted():</span>
    <span class="s2">#some basic tests comparing to normal distribution</span>
    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">500</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>
    <span class="s1">wn = np.random.rand(n_basesample)</span>
    <span class="s1">xnmean = np.average(xn</span><span class="s0">, </span><span class="s1">weights=wn)</span>
    <span class="s1">xnstd = np.sqrt(np.average((xn-xnmean)**</span><span class="s3">2</span><span class="s0">, </span><span class="s1">weights=wn))</span>

    <span class="s2"># get kde for original sample</span>
    <span class="s1">gkde = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">weights=wn)</span>

    <span class="s2"># evaluate the density function for the kde for some points</span>
    <span class="s1">xs = np.linspace(-</span><span class="s3">7</span><span class="s0">,</span><span class="s3">7</span><span class="s0">,</span><span class="s3">501</span><span class="s1">)</span>
    <span class="s1">kdepdf = gkde.evaluate(xs)</span>
    <span class="s1">normpdf = stats.norm.pdf(xs</span><span class="s0">, </span><span class="s1">loc=xnmean</span><span class="s0">, </span><span class="s1">scale=xnstd)</span>
    <span class="s1">intervall = xs[</span><span class="s3">1</span><span class="s1">] - xs[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">assert_(np.sum((kdepdf - normpdf)**</span><span class="s3">2</span><span class="s1">)*intervall &lt; </span><span class="s3">0.01</span><span class="s1">)</span>
    <span class="s1">prob1 = gkde.integrate_box_1d(xnmean</span><span class="s0">, </span><span class="s1">np.inf)</span>
    <span class="s1">prob2 = gkde.integrate_box_1d(-np.inf</span><span class="s0">, </span><span class="s1">xnmean)</span>
    <span class="s1">assert_almost_equal(prob1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(prob2</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_box(xnmean</span><span class="s0">, </span><span class="s1">np.inf)</span><span class="s0">, </span><span class="s1">prob1</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">13</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_box(-np.inf</span><span class="s0">, </span><span class="s1">xnmean)</span><span class="s0">, </span><span class="s1">prob2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">13</span><span class="s1">)</span>

    <span class="s1">assert_almost_equal(gkde.integrate_kde(gkde)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf**</span><span class="s3">2</span><span class="s1">).sum()*intervall</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_gaussian(xnmean</span><span class="s0">, </span><span class="s1">xnstd**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf*normpdf).sum()*intervall</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s0">def </span><span class="s1">test_kde_2d():</span>
    <span class="s2">#some basic tests comparing to normal distribution</span>
    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">500</span>

    <span class="s1">mean = np.array([</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s1">])</span>
    <span class="s1">covariance = np.array([[</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">6.0</span><span class="s1">]])</span>

    <span class="s2"># Need transpose (shape (2, 500)) for kde</span>
    <span class="s1">xn = np.random.multivariate_normal(mean</span><span class="s0">, </span><span class="s1">covariance</span><span class="s0">, </span><span class="s1">size=n_basesample).T</span>

    <span class="s2"># get kde for original sample</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>

    <span class="s2"># evaluate the density function for the kde for some points</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">y = np.mgrid[-</span><span class="s3">7</span><span class="s1">:</span><span class="s3">7</span><span class="s1">:</span><span class="s3">500j</span><span class="s0">, </span><span class="s1">-</span><span class="s3">7</span><span class="s1">:</span><span class="s3">7</span><span class="s1">:</span><span class="s3">500j</span><span class="s1">]</span>
    <span class="s1">grid_coords = np.vstack([x.ravel()</span><span class="s0">, </span><span class="s1">y.ravel()])</span>
    <span class="s1">kdepdf = gkde.evaluate(grid_coords)</span>
    <span class="s1">kdepdf = kdepdf.reshape(</span><span class="s3">500</span><span class="s0">, </span><span class="s3">500</span><span class="s1">)</span>

    <span class="s1">normpdf = stats.multivariate_normal.pdf(np.dstack([x</span><span class="s0">, </span><span class="s1">y])</span><span class="s0">, </span><span class="s1">mean=mean</span><span class="s0">, </span><span class="s1">cov=covariance)</span>
    <span class="s1">intervall = y.ravel()[</span><span class="s3">1</span><span class="s1">] - y.ravel()[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">assert_(np.sum((kdepdf - normpdf)**</span><span class="s3">2</span><span class="s1">) * (intervall**</span><span class="s3">2</span><span class="s1">) &lt; </span><span class="s3">0.01</span><span class="s1">)</span>

    <span class="s1">small = -</span><span class="s3">1e100</span>
    <span class="s1">large = </span><span class="s3">1e100</span>
    <span class="s1">prob1 = gkde.integrate_box([small</span><span class="s0">, </span><span class="s1">mean[</span><span class="s3">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[large</span><span class="s0">, </span><span class="s1">large])</span>
    <span class="s1">prob2 = gkde.integrate_box([small</span><span class="s0">, </span><span class="s1">small]</span><span class="s0">, </span><span class="s1">[large</span><span class="s0">, </span><span class="s1">mean[</span><span class="s3">1</span><span class="s1">]])</span>

    <span class="s1">assert_almost_equal(prob1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(prob2</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_kde(gkde)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf**</span><span class="s3">2</span><span class="s1">).sum()*(intervall**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_gaussian(mean</span><span class="s0">, </span><span class="s1">covariance)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf*normpdf).sum()*(intervall**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s0">def </span><span class="s1">test_kde_2d_weighted():</span>
    <span class="s2">#some basic tests comparing to normal distribution</span>
    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">500</span>

    <span class="s1">mean = np.array([</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s1">])</span>
    <span class="s1">covariance = np.array([[</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">6.0</span><span class="s1">]])</span>

    <span class="s2"># Need transpose (shape (2, 500)) for kde</span>
    <span class="s1">xn = np.random.multivariate_normal(mean</span><span class="s0">, </span><span class="s1">covariance</span><span class="s0">, </span><span class="s1">size=n_basesample).T</span>
    <span class="s1">wn = np.random.rand(n_basesample)</span>

    <span class="s2"># get kde for original sample</span>
    <span class="s1">gkde = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">weights=wn)</span>

    <span class="s2"># evaluate the density function for the kde for some points</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">y = np.mgrid[-</span><span class="s3">7</span><span class="s1">:</span><span class="s3">7</span><span class="s1">:</span><span class="s3">500j</span><span class="s0">, </span><span class="s1">-</span><span class="s3">7</span><span class="s1">:</span><span class="s3">7</span><span class="s1">:</span><span class="s3">500j</span><span class="s1">]</span>
    <span class="s1">grid_coords = np.vstack([x.ravel()</span><span class="s0">, </span><span class="s1">y.ravel()])</span>
    <span class="s1">kdepdf = gkde.evaluate(grid_coords)</span>
    <span class="s1">kdepdf = kdepdf.reshape(</span><span class="s3">500</span><span class="s0">, </span><span class="s3">500</span><span class="s1">)</span>

    <span class="s1">normpdf = stats.multivariate_normal.pdf(np.dstack([x</span><span class="s0">, </span><span class="s1">y])</span><span class="s0">, </span><span class="s1">mean=mean</span><span class="s0">, </span><span class="s1">cov=covariance)</span>
    <span class="s1">intervall = y.ravel()[</span><span class="s3">1</span><span class="s1">] - y.ravel()[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">assert_(np.sum((kdepdf - normpdf)**</span><span class="s3">2</span><span class="s1">) * (intervall**</span><span class="s3">2</span><span class="s1">) &lt; </span><span class="s3">0.01</span><span class="s1">)</span>

    <span class="s1">small = -</span><span class="s3">1e100</span>
    <span class="s1">large = </span><span class="s3">1e100</span>
    <span class="s1">prob1 = gkde.integrate_box([small</span><span class="s0">, </span><span class="s1">mean[</span><span class="s3">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[large</span><span class="s0">, </span><span class="s1">large])</span>
    <span class="s1">prob2 = gkde.integrate_box([small</span><span class="s0">, </span><span class="s1">small]</span><span class="s0">, </span><span class="s1">[large</span><span class="s0">, </span><span class="s1">mean[</span><span class="s3">1</span><span class="s1">]])</span>

    <span class="s1">assert_almost_equal(prob1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(prob2</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_kde(gkde)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf**</span><span class="s3">2</span><span class="s1">).sum()*(intervall**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(gkde.integrate_gaussian(mean</span><span class="s0">, </span><span class="s1">covariance)</span><span class="s0">,</span>
                        <span class="s1">(kdepdf*normpdf).sum()*(intervall**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_kde_bandwidth_method():</span>
    <span class="s0">def </span><span class="s1">scotts_factor(kde_obj):</span>
        <span class="s4">&quot;&quot;&quot;Same as default, just check that it works.&quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">np.power(kde_obj.n</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1.</span><span class="s1">/(kde_obj.d+</span><span class="s3">4</span><span class="s1">))</span>

    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">50</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>

    <span class="s2"># Default</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>
    <span class="s2"># Supply a callable</span>
    <span class="s1">gkde2 = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">bw_method=scotts_factor)</span>
    <span class="s2"># Supply a scalar</span>
    <span class="s1">gkde3 = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">bw_method=gkde.factor)</span>

    <span class="s1">xs = np.linspace(-</span><span class="s3">7</span><span class="s0">,</span><span class="s3">7</span><span class="s0">,</span><span class="s3">51</span><span class="s1">)</span>
    <span class="s1">kdepdf = gkde.evaluate(xs)</span>
    <span class="s1">kdepdf2 = gkde2.evaluate(xs)</span>
    <span class="s1">assert_almost_equal(kdepdf</span><span class="s0">, </span><span class="s1">kdepdf2)</span>
    <span class="s1">kdepdf3 = gkde3.evaluate(xs)</span>
    <span class="s1">assert_almost_equal(kdepdf</span><span class="s0">, </span><span class="s1">kdepdf3)</span>

    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">stats.gaussian_kde</span><span class="s0">, </span><span class="s1">xn</span><span class="s0">, </span><span class="s1">bw_method=</span><span class="s5">'wrongstring'</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_kde_bandwidth_method_weighted():</span>
    <span class="s0">def </span><span class="s1">scotts_factor(kde_obj):</span>
        <span class="s4">&quot;&quot;&quot;Same as default, just check that it works.&quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">np.power(kde_obj.neff</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1.</span><span class="s1">/(kde_obj.d+</span><span class="s3">4</span><span class="s1">))</span>

    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">50</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>

    <span class="s2"># Default</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>
    <span class="s2"># Supply a callable</span>
    <span class="s1">gkde2 = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">bw_method=scotts_factor)</span>
    <span class="s2"># Supply a scalar</span>
    <span class="s1">gkde3 = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">bw_method=gkde.factor)</span>

    <span class="s1">xs = np.linspace(-</span><span class="s3">7</span><span class="s0">,</span><span class="s3">7</span><span class="s0">,</span><span class="s3">51</span><span class="s1">)</span>
    <span class="s1">kdepdf = gkde.evaluate(xs)</span>
    <span class="s1">kdepdf2 = gkde2.evaluate(xs)</span>
    <span class="s1">assert_almost_equal(kdepdf</span><span class="s0">, </span><span class="s1">kdepdf2)</span>
    <span class="s1">kdepdf3 = gkde3.evaluate(xs)</span>
    <span class="s1">assert_almost_equal(kdepdf</span><span class="s0">, </span><span class="s1">kdepdf3)</span>

    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">stats.gaussian_kde</span><span class="s0">, </span><span class="s1">xn</span><span class="s0">, </span><span class="s1">bw_method=</span><span class="s5">'wrongstring'</span><span class="s1">)</span>


<span class="s2"># Subclasses that should stay working (extracted from various sources).</span>
<span class="s2"># Unfortunately the earlier design of gaussian_kde made it necessary for users</span>
<span class="s2"># to create these kinds of subclasses, or call _compute_covariance() directly.</span>

<span class="s0">class </span><span class="s1">_kde_subclass1(stats.gaussian_kde):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">dataset):</span>
        <span class="s1">self.dataset = np.atleast_2d(dataset)</span>
        <span class="s1">self.d</span><span class="s0">, </span><span class="s1">self.n = self.dataset.shape</span>
        <span class="s1">self.covariance_factor = self.scotts_factor</span>
        <span class="s1">self._compute_covariance()</span>


<span class="s0">class </span><span class="s1">_kde_subclass2(stats.gaussian_kde):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">dataset):</span>
        <span class="s1">self.covariance_factor = self.scotts_factor</span>
        <span class="s1">super().__init__(dataset)</span>


<span class="s0">class </span><span class="s1">_kde_subclass4(stats.gaussian_kde):</span>
    <span class="s0">def </span><span class="s1">covariance_factor(self):</span>
        <span class="s0">return </span><span class="s3">0.5 </span><span class="s1">* self.silverman_factor()</span>


<span class="s0">def </span><span class="s1">test_gaussian_kde_subclassing():</span>
    <span class="s1">x1 = np.array([-</span><span class="s3">7</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=float)</span>
    <span class="s1">xs = np.linspace(-</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">num=</span><span class="s3">50</span><span class="s1">)</span>

    <span class="s2"># gaussian_kde itself</span>
    <span class="s1">kde = stats.gaussian_kde(x1)</span>
    <span class="s1">ys = kde(xs)</span>

    <span class="s2"># subclass 1</span>
    <span class="s1">kde1 = _kde_subclass1(x1)</span>
    <span class="s1">y1 = kde1(xs)</span>
    <span class="s1">assert_array_almost_equal_nulp(ys</span><span class="s0">, </span><span class="s1">y1</span><span class="s0">, </span><span class="s1">nulp=</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s2"># subclass 2</span>
    <span class="s1">kde2 = _kde_subclass2(x1)</span>
    <span class="s1">y2 = kde2(xs)</span>
    <span class="s1">assert_array_almost_equal_nulp(ys</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">nulp=</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s2"># subclass 3 was removed because we have no obligation to maintain support</span>
    <span class="s2"># for user invocation of private methods</span>

    <span class="s2"># subclass 4</span>
    <span class="s1">kde4 = _kde_subclass4(x1)</span>
    <span class="s1">y4 = kde4(x1)</span>
    <span class="s1">y_expected = [</span><span class="s3">0.06292987</span><span class="s0">, </span><span class="s3">0.06346938</span><span class="s0">, </span><span class="s3">0.05860291</span><span class="s0">, </span><span class="s3">0.08657652</span><span class="s0">, </span><span class="s3">0.07904017</span><span class="s1">]</span>

    <span class="s1">assert_array_almost_equal(y_expected</span><span class="s0">, </span><span class="s1">y4</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">6</span><span class="s1">)</span>

    <span class="s2"># Not a subclass, but check for use of _compute_covariance()</span>
    <span class="s1">kde5 = kde</span>
    <span class="s1">kde5.covariance_factor = </span><span class="s0">lambda</span><span class="s1">: kde.factor</span>
    <span class="s1">kde5._compute_covariance()</span>
    <span class="s1">y5 = kde5(xs)</span>
    <span class="s1">assert_array_almost_equal_nulp(ys</span><span class="s0">, </span><span class="s1">y5</span><span class="s0">, </span><span class="s1">nulp=</span><span class="s3">10</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_gaussian_kde_covariance_caching():</span>
    <span class="s1">x1 = np.array([-</span><span class="s3">7</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=float)</span>
    <span class="s1">xs = np.linspace(-</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">num=</span><span class="s3">5</span><span class="s1">)</span>
    <span class="s2"># These expected values are from scipy 0.10, before some changes to</span>
    <span class="s2"># gaussian_kde.  They were not compared with any external reference.</span>
    <span class="s1">y_expected = [</span><span class="s3">0.02463386</span><span class="s0">, </span><span class="s3">0.04689208</span><span class="s0">, </span><span class="s3">0.05395444</span><span class="s0">, </span><span class="s3">0.05337754</span><span class="s0">, </span><span class="s3">0.01664475</span><span class="s1">]</span>

    <span class="s2"># Set the bandwidth, then reset it to the default.</span>
    <span class="s1">kde = stats.gaussian_kde(x1)</span>
    <span class="s1">kde.set_bandwidth(bw_method=</span><span class="s3">0.5</span><span class="s1">)</span>
    <span class="s1">kde.set_bandwidth(bw_method=</span><span class="s5">'scott'</span><span class="s1">)</span>
    <span class="s1">y2 = kde(xs)</span>

    <span class="s1">assert_array_almost_equal(y_expected</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">7</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_gaussian_kde_monkeypatch():</span>
    <span class="s4">&quot;&quot;&quot;Ugly, but people may rely on this.  See scipy pull request 123, 
    specifically the linked ML thread &quot;Width of the Gaussian in stats.kde&quot;. 
    If it is necessary to break this later on, that is to be discussed on ML. 
    &quot;&quot;&quot;</span>
    <span class="s1">x1 = np.array([-</span><span class="s3">7</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=float)</span>
    <span class="s1">xs = np.linspace(-</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">num=</span><span class="s3">50</span><span class="s1">)</span>

    <span class="s2"># The old monkeypatched version to get at Silverman's Rule.</span>
    <span class="s1">kde = stats.gaussian_kde(x1)</span>
    <span class="s1">kde.covariance_factor = kde.silverman_factor</span>
    <span class="s1">kde._compute_covariance()</span>
    <span class="s1">y1 = kde(xs)</span>

    <span class="s2"># The new saner version.</span>
    <span class="s1">kde2 = stats.gaussian_kde(x1</span><span class="s0">, </span><span class="s1">bw_method=</span><span class="s5">'silverman'</span><span class="s1">)</span>
    <span class="s1">y2 = kde2(xs)</span>

    <span class="s1">assert_array_almost_equal_nulp(y1</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">nulp=</span><span class="s3">10</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_kde_integer_input():</span>
    <span class="s4">&quot;&quot;&quot;Regression test for #1181.&quot;&quot;&quot;</span>
    <span class="s1">x1 = np.arange(</span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">kde = stats.gaussian_kde(x1)</span>
    <span class="s1">y_expected = [</span><span class="s3">0.13480721</span><span class="s0">, </span><span class="s3">0.18222869</span><span class="s0">, </span><span class="s3">0.19514935</span><span class="s0">, </span><span class="s3">0.18222869</span><span class="s0">, </span><span class="s3">0.13480721</span><span class="s1">]</span>
    <span class="s1">assert_array_almost_equal(kde(x1)</span><span class="s0">, </span><span class="s1">y_expected</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">6</span><span class="s1">)</span>


<span class="s1">_ftypes = [</span><span class="s5">'float32'</span><span class="s0">, </span><span class="s5">'float64'</span><span class="s0">, </span><span class="s5">'float96'</span><span class="s0">, </span><span class="s5">'float128'</span><span class="s0">, </span><span class="s5">'int32'</span><span class="s0">, </span><span class="s5">'int64'</span><span class="s1">]</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;bw_type&quot;</span><span class="s0">, </span><span class="s1">_ftypes + [</span><span class="s5">&quot;scott&quot;</span><span class="s0">, </span><span class="s5">&quot;silverman&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">_ftypes)</span>
<span class="s0">def </span><span class="s1">test_kde_output_dtype(dtype</span><span class="s0">, </span><span class="s1">bw_type):</span>
    <span class="s2"># Check whether the datatypes are available</span>
    <span class="s1">dtype = getattr(np</span><span class="s0">, </span><span class="s1">dtype</span><span class="s0">, None</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">bw_type </span><span class="s0">in </span><span class="s1">[</span><span class="s5">&quot;scott&quot;</span><span class="s0">, </span><span class="s5">&quot;silverman&quot;</span><span class="s1">]:</span>
        <span class="s1">bw = bw_type</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">bw_type = getattr(np</span><span class="s0">, </span><span class="s1">bw_type</span><span class="s0">, None</span><span class="s1">)</span>
        <span class="s1">bw = bw_type(</span><span class="s3">3</span><span class="s1">) </span><span class="s0">if </span><span class="s1">bw_type </span><span class="s0">else None</span>

    <span class="s0">if </span><span class="s1">any(dt </span><span class="s0">is None for </span><span class="s1">dt </span><span class="s0">in </span><span class="s1">[dtype</span><span class="s0">, </span><span class="s1">bw]):</span>
        <span class="s1">pytest.skip()</span>

    <span class="s1">weights = np.arange(</span><span class="s3">5</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">dataset = np.arange(</span><span class="s3">5</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">k = stats.gaussian_kde(dataset</span><span class="s0">, </span><span class="s1">bw_method=bw</span><span class="s0">, </span><span class="s1">weights=weights)</span>
    <span class="s1">points = np.arange(</span><span class="s3">5</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">result = k(points)</span>
    <span class="s2"># weights are always cast to float64</span>
    <span class="s0">assert </span><span class="s1">result.dtype == np.result_type(dataset</span><span class="s0">, </span><span class="s1">points</span><span class="s0">, </span><span class="s1">np.float64(weights)</span><span class="s0">,</span>
                                          <span class="s1">k.factor)</span>


<span class="s0">def </span><span class="s1">test_pdf_logpdf_validation():</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">64202298293133848336925499069837723291</span><span class="s1">)</span>
    <span class="s1">xn = rng.standard_normal((</span><span class="s3">2</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>
    <span class="s1">xs = rng.standard_normal((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span>

    <span class="s1">msg = </span><span class="s5">&quot;points have dimension 3, dataset has dimension 2&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">gkde.logpdf(xs)</span>


<span class="s0">def </span><span class="s1">test_pdf_logpdf():</span>
    <span class="s1">np.random.seed(</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">50</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>

    <span class="s2"># Default</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>

    <span class="s1">xs = np.linspace(-</span><span class="s3">15</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">25</span><span class="s1">)</span>
    <span class="s1">pdf = gkde.evaluate(xs)</span>
    <span class="s1">pdf2 = gkde.pdf(xs)</span>
    <span class="s1">assert_almost_equal(pdf</span><span class="s0">, </span><span class="s1">pdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>

    <span class="s1">logpdf = np.log(pdf)</span>
    <span class="s1">logpdf2 = gkde.logpdf(xs)</span>
    <span class="s1">assert_almost_equal(logpdf</span><span class="s0">, </span><span class="s1">logpdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>

    <span class="s2"># There are more points than data</span>
    <span class="s1">gkde = stats.gaussian_kde(xs)</span>
    <span class="s1">pdf = np.log(gkde.evaluate(xn))</span>
    <span class="s1">pdf2 = gkde.logpdf(xn)</span>
    <span class="s1">assert_almost_equal(pdf</span><span class="s0">, </span><span class="s1">pdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_pdf_logpdf_weighted():</span>
    <span class="s1">np.random.seed(</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">50</span>
    <span class="s1">xn = np.random.randn(n_basesample)</span>
    <span class="s1">wn = np.random.rand(n_basesample)</span>

    <span class="s2"># Default</span>
    <span class="s1">gkde = stats.gaussian_kde(xn</span><span class="s0">, </span><span class="s1">weights=wn)</span>

    <span class="s1">xs = np.linspace(-</span><span class="s3">15</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">25</span><span class="s1">)</span>
    <span class="s1">pdf = gkde.evaluate(xs)</span>
    <span class="s1">pdf2 = gkde.pdf(xs)</span>
    <span class="s1">assert_almost_equal(pdf</span><span class="s0">, </span><span class="s1">pdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>

    <span class="s1">logpdf = np.log(pdf)</span>
    <span class="s1">logpdf2 = gkde.logpdf(xs)</span>
    <span class="s1">assert_almost_equal(logpdf</span><span class="s0">, </span><span class="s1">logpdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>

    <span class="s2"># There are more points than data</span>
    <span class="s1">gkde = stats.gaussian_kde(xs</span><span class="s0">, </span><span class="s1">weights=np.random.rand(len(xs)))</span>
    <span class="s1">pdf = np.log(gkde.evaluate(xn))</span>
    <span class="s1">pdf2 = gkde.logpdf(xn)</span>
    <span class="s1">assert_almost_equal(pdf</span><span class="s0">, </span><span class="s1">pdf2</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">12</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_marginal_1_axis():</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">6111799263660870475</span><span class="s1">)</span>
    <span class="s1">n_data = </span><span class="s3">50</span>
    <span class="s1">n_dim = </span><span class="s3">10</span>
    <span class="s1">dataset = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s1">n_data))</span>
    <span class="s1">points = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>

    <span class="s1">dimensions = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">9</span><span class="s1">])  </span><span class="s2"># dimensions to keep</span>

    <span class="s1">kde = stats.gaussian_kde(dataset)</span>
    <span class="s1">marginal = kde.marginal(dimensions)</span>
    <span class="s1">pdf = marginal.pdf(points[dimensions])</span>

    <span class="s0">def </span><span class="s1">marginal_pdf_single(point):</span>
        <span class="s0">def </span><span class="s1">f(x):</span>
            <span class="s1">x = np.concatenate(([x]</span><span class="s0">, </span><span class="s1">point[dimensions]))</span>
            <span class="s0">return </span><span class="s1">kde.pdf(x)[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s0">return </span><span class="s1">integrate.quad(f</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf)[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s0">def </span><span class="s1">marginal_pdf(points):</span>
        <span class="s0">return </span><span class="s1">np.apply_along_axis(marginal_pdf_single</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">arr=points)</span>

    <span class="s1">ref = marginal_pdf(points)</span>

    <span class="s1">assert_allclose(pdf</span><span class="s0">, </span><span class="s1">ref</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>


<span class="s1">@pytest.mark.xslow</span>
<span class="s0">def </span><span class="s1">test_marginal_2_axis():</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">6111799263660870475</span><span class="s1">)</span>
    <span class="s1">n_data = </span><span class="s3">30</span>
    <span class="s1">n_dim = </span><span class="s3">4</span>
    <span class="s1">dataset = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s1">n_data))</span>
    <span class="s1">points = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>

    <span class="s1">dimensions = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])  </span><span class="s2"># dimensions to keep</span>

    <span class="s1">kde = stats.gaussian_kde(dataset)</span>
    <span class="s1">marginal = kde.marginal(dimensions)</span>
    <span class="s1">pdf = marginal.pdf(points[dimensions])</span>

    <span class="s0">def </span><span class="s1">marginal_pdf(points):</span>
        <span class="s0">def </span><span class="s1">marginal_pdf_single(point):</span>
            <span class="s0">def </span><span class="s1">f(y</span><span class="s0">, </span><span class="s1">x):</span>
                <span class="s1">w</span><span class="s0">, </span><span class="s1">z = point[dimensions]</span>
                <span class="s1">x = np.array([x</span><span class="s0">, </span><span class="s1">w</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z])</span>
                <span class="s0">return </span><span class="s1">kde.pdf(x)[</span><span class="s3">0</span><span class="s1">]</span>
            <span class="s0">return </span><span class="s1">integrate.dblquad(f</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf)[</span><span class="s3">0</span><span class="s1">]</span>

        <span class="s0">return </span><span class="s1">np.apply_along_axis(marginal_pdf_single</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">arr=points)</span>

    <span class="s1">ref = marginal_pdf(points)</span>

    <span class="s1">assert_allclose(pdf</span><span class="s0">, </span><span class="s1">ref</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_marginal_iv():</span>
    <span class="s2"># test input validation</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">6111799263660870475</span><span class="s1">)</span>
    <span class="s1">n_data = </span><span class="s3">30</span>
    <span class="s1">n_dim = </span><span class="s3">4</span>
    <span class="s1">dataset = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s1">n_data))</span>
    <span class="s1">points = rng.normal(size=(n_dim</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>

    <span class="s1">kde = stats.gaussian_kde(dataset)</span>

    <span class="s2"># check that positive and negative indices are equivalent</span>
    <span class="s1">dimensions1 = [-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">marginal1 = kde.marginal(dimensions1)</span>
    <span class="s1">pdf1 = marginal1.pdf(points[dimensions1])</span>

    <span class="s1">dimensions2 = [</span><span class="s3">3</span><span class="s0">, </span><span class="s1">-</span><span class="s3">3</span><span class="s1">]</span>
    <span class="s1">marginal2 = kde.marginal(dimensions2)</span>
    <span class="s1">pdf2 = marginal2.pdf(points[dimensions2])</span>

    <span class="s1">assert_equal(pdf1</span><span class="s0">, </span><span class="s1">pdf2)</span>

    <span class="s2"># IV for non-integer dimensions</span>
    <span class="s1">message = </span><span class="s5">&quot;Elements of `dimensions` must be integers...&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">kde.marginal([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">])</span>

    <span class="s2"># IV for uniquenes</span>
    <span class="s1">message = </span><span class="s5">&quot;All elements of `dimensions` must be unique.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">kde.marginal([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>

    <span class="s2"># IV for non-integer dimensions</span>
    <span class="s1">message = (</span><span class="s5">r&quot;Dimensions \[-5  6\] are invalid for a distribution in 4...&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">kde.marginal([</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">])</span>


<span class="s1">@pytest.mark.xslow</span>
<span class="s0">def </span><span class="s1">test_logpdf_overflow():</span>
    <span class="s2"># regression test for gh-12988; testing against linalg instability for</span>
    <span class="s2"># very high dimensionality kde</span>
    <span class="s1">np.random.seed(</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">n_dimensions = </span><span class="s3">2500</span>
    <span class="s1">n_samples = </span><span class="s3">5000</span>
    <span class="s1">xn = np.array([np.random.randn(n_samples) + (n) </span><span class="s0">for </span><span class="s1">n </span><span class="s0">in </span><span class="s1">range(</span>
        <span class="s3">0</span><span class="s0">, </span><span class="s1">n_dimensions)])</span>

    <span class="s2"># Default</span>
    <span class="s1">gkde = stats.gaussian_kde(xn)</span>

    <span class="s1">logpdf = gkde.logpdf(np.arange(</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_dimensions))</span>
    <span class="s1">np.testing.assert_equal(np.isneginf(logpdf[</span><span class="s3">0</span><span class="s1">])</span><span class="s0">, False</span><span class="s1">)</span>
    <span class="s1">np.testing.assert_equal(np.isnan(logpdf[</span><span class="s3">0</span><span class="s1">])</span><span class="s0">, False</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_weights_intact():</span>
    <span class="s2"># regression test for gh-9709: weights are not modified</span>
    <span class="s1">np.random.seed(</span><span class="s3">12345</span><span class="s1">)</span>
    <span class="s1">vals = np.random.lognormal(size=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">weights = np.random.choice([</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">10.0</span><span class="s0">, </span><span class="s3">100</span><span class="s1">]</span><span class="s0">, </span><span class="s1">size=vals.size)</span>
    <span class="s1">orig_weights = weights.copy()</span>

    <span class="s1">stats.gaussian_kde(np.log10(vals)</span><span class="s0">, </span><span class="s1">weights=weights)</span>
    <span class="s1">assert_allclose(weights</span><span class="s0">, </span><span class="s1">orig_weights</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-14</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-14</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_weights_integer():</span>
    <span class="s2"># integer weights are OK, cf gh-9709 (comment)</span>
    <span class="s1">np.random.seed(</span><span class="s3">12345</span><span class="s1">)</span>
    <span class="s1">values = [</span><span class="s3">0.2</span><span class="s0">, </span><span class="s3">13.5</span><span class="s0">, </span><span class="s3">21.0</span><span class="s0">, </span><span class="s3">75.0</span><span class="s0">, </span><span class="s3">99.0</span><span class="s1">]</span>
    <span class="s1">weights = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">16</span><span class="s1">]  </span><span class="s2"># a list of integers</span>
    <span class="s1">pdf_i = stats.gaussian_kde(values</span><span class="s0">, </span><span class="s1">weights=weights)</span>
    <span class="s1">pdf_f = stats.gaussian_kde(values</span><span class="s0">, </span><span class="s1">weights=np.float64(weights))</span>

    <span class="s1">xn = [</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">88</span><span class="s1">]</span>
    <span class="s1">assert_allclose(pdf_i.evaluate(xn)</span><span class="s0">,</span>
                    <span class="s1">pdf_f.evaluate(xn)</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-14</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-14</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_seed():</span>
    <span class="s2"># Test the seed option of the resample method</span>
    <span class="s0">def </span><span class="s1">test_seed_sub(gkde_trail):</span>
        <span class="s1">n_sample = </span><span class="s3">200</span>
        <span class="s2"># The results should be different without using seed</span>
        <span class="s1">samp1 = gkde_trail.resample(n_sample)</span>
        <span class="s1">samp2 = gkde_trail.resample(n_sample)</span>
        <span class="s1">assert_raises(</span>
            <span class="s1">AssertionError</span><span class="s0">, </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">samp1</span><span class="s0">, </span><span class="s1">samp2</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-13</span>
        <span class="s1">)</span>
        <span class="s2"># Use integer seed</span>
        <span class="s1">seed = </span><span class="s3">831</span>
        <span class="s1">samp1 = gkde_trail.resample(n_sample</span><span class="s0">, </span><span class="s1">seed=seed)</span>
        <span class="s1">samp2 = gkde_trail.resample(n_sample</span><span class="s0">, </span><span class="s1">seed=seed)</span>
        <span class="s1">assert_allclose(samp1</span><span class="s0">, </span><span class="s1">samp2</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-13</span><span class="s1">)</span>
        <span class="s2"># Use RandomState</span>
        <span class="s1">rstate1 = np.random.RandomState(seed=</span><span class="s3">138</span><span class="s1">)</span>
        <span class="s1">samp1 = gkde_trail.resample(n_sample</span><span class="s0">, </span><span class="s1">seed=rstate1)</span>
        <span class="s1">rstate2 = np.random.RandomState(seed=</span><span class="s3">138</span><span class="s1">)</span>
        <span class="s1">samp2 = gkde_trail.resample(n_sample</span><span class="s0">, </span><span class="s1">seed=rstate2)</span>
        <span class="s1">assert_allclose(samp1</span><span class="s0">, </span><span class="s1">samp2</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-13</span><span class="s1">)</span>

        <span class="s2"># check that np.random.Generator can be used (numpy &gt;= 1.17)</span>
        <span class="s0">if </span><span class="s1">hasattr(np.random</span><span class="s0">, </span><span class="s5">'default_rng'</span><span class="s1">):</span>
            <span class="s2"># obtain a np.random.Generator object</span>
            <span class="s1">rng = np.random.default_rng(</span><span class="s3">1234</span><span class="s1">)</span>
            <span class="s1">gkde_trail.resample(n_sample</span><span class="s0">, </span><span class="s1">seed=rng)</span>

    <span class="s1">np.random.seed(</span><span class="s3">8765678</span><span class="s1">)</span>
    <span class="s1">n_basesample = </span><span class="s3">500</span>
    <span class="s1">wn = np.random.rand(n_basesample)</span>
    <span class="s2"># Test 1D case</span>
    <span class="s1">xn_1d = np.random.randn(n_basesample)</span>

    <span class="s1">gkde_1d = stats.gaussian_kde(xn_1d)</span>
    <span class="s1">test_seed_sub(gkde_1d)</span>
    <span class="s1">gkde_1d_weighted = stats.gaussian_kde(xn_1d</span><span class="s0">, </span><span class="s1">weights=wn)</span>
    <span class="s1">test_seed_sub(gkde_1d_weighted)</span>

    <span class="s2"># Test 2D case</span>
    <span class="s1">mean = np.array([</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s1">])</span>
    <span class="s1">covariance = np.array([[</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">6.0</span><span class="s1">]])</span>
    <span class="s1">xn_2d = np.random.multivariate_normal(mean</span><span class="s0">, </span><span class="s1">covariance</span><span class="s0">, </span><span class="s1">size=n_basesample).T</span>

    <span class="s1">gkde_2d = stats.gaussian_kde(xn_2d)</span>
    <span class="s1">test_seed_sub(gkde_2d)</span>
    <span class="s1">gkde_2d_weighted = stats.gaussian_kde(xn_2d</span><span class="s0">, </span><span class="s1">weights=wn)</span>
    <span class="s1">test_seed_sub(gkde_2d_weighted)</span>


<span class="s0">def </span><span class="s1">test_singular_data_covariance_gh10205():</span>
    <span class="s2"># When the data lie in a lower-dimensional subspace and this causes</span>
    <span class="s2"># and exception, check that the error message is informative.</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">2321583144339784787</span><span class="s1">)</span>
    <span class="s1">mu = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">20</span><span class="s1">])</span>
    <span class="s1">sigma = np.array([[</span><span class="s3">4</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">25</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">100</span><span class="s1">]])</span>
    <span class="s1">data = rng.multivariate_normal(mu</span><span class="s0">, </span><span class="s1">sigma</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">)</span>
    <span class="s0">try</span><span class="s1">:  </span><span class="s2"># doesn't raise any error on some platforms, and that's OK</span>
        <span class="s1">stats.gaussian_kde(data.T)</span>
    <span class="s0">except </span><span class="s1">linalg.LinAlgError:</span>
        <span class="s1">msg = </span><span class="s5">&quot;The data appears to lie in a lower-dimensional subspace...&quot;</span>
        <span class="s0">with </span><span class="s1">assert_raises(linalg.LinAlgError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">stats.gaussian_kde(data.T)</span>


<span class="s0">def </span><span class="s1">test_fewer_points_than_dimensions_gh17436():</span>
    <span class="s2"># When the number of points is fewer than the number of dimensions, the</span>
    <span class="s2"># the covariance matrix would be singular, and the exception tested in</span>
    <span class="s2"># test_singular_data_covariance_gh10205 would occur. However, sometimes</span>
    <span class="s2"># this occurs when the user passes in the transpose of what `gaussian_kde`</span>
    <span class="s2"># expects. This can result in a huge covariance matrix, so bail early.</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">2046127537594925772</span><span class="s1">)</span>
    <span class="s1">rvs = rng.multivariate_normal(np.zeros(</span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.eye(</span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">message = </span><span class="s5">&quot;Number of dimensions is greater than number of samples...&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">stats.gaussian_kde(rvs)</span>
</pre>
</body>
</html>
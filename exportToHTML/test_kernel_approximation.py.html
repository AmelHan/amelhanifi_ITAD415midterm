<html>
<head>
<title>test_kernel_approximation.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_kernel_approximation.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">re</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">csr_matrix</span>

<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">make_classification</span>
<span class="s0">from </span><span class="s1">sklearn.kernel_approximation </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">AdditiveChi2Sampler</span><span class="s0">,</span>
    <span class="s1">Nystroem</span><span class="s0">,</span>
    <span class="s1">PolynomialCountSketch</span><span class="s0">,</span>
    <span class="s1">RBFSampler</span><span class="s0">,</span>
    <span class="s1">SkewedChi2Sampler</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.metrics.pairwise </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">chi2_kernel</span><span class="s0">,</span>
    <span class="s1">kernel_metrics</span><span class="s0">,</span>
    <span class="s1">polynomial_kernel</span><span class="s0">,</span>
    <span class="s1">rbf_kernel</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
<span class="s1">)</span>

<span class="s2"># generate data</span>
<span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
<span class="s1">X = rng.random_sample(size=(</span><span class="s3">300</span><span class="s0">, </span><span class="s3">50</span><span class="s1">))</span>
<span class="s1">Y = rng.random_sample(size=(</span><span class="s3">300</span><span class="s0">, </span><span class="s3">50</span><span class="s1">))</span>
<span class="s1">X /= X.sum(axis=</span><span class="s3">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
<span class="s1">Y /= Y.sum(axis=</span><span class="s3">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;gamma&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;degree, n_components&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">500</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">500</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5000</span><span class="s1">)])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;coef0&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_polynomial_count_sketch(gamma</span><span class="s0">, </span><span class="s1">degree</span><span class="s0">, </span><span class="s1">coef0</span><span class="s0">, </span><span class="s1">n_components):</span>
    <span class="s2"># test that PolynomialCountSketch approximates polynomial</span>
    <span class="s2"># kernel on random data</span>

    <span class="s2"># compute exact kernel</span>
    <span class="s1">kernel = polynomial_kernel(X</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">gamma=gamma</span><span class="s0">, </span><span class="s1">degree=degree</span><span class="s0">, </span><span class="s1">coef0=coef0)</span>

    <span class="s2"># approximate kernel mapping</span>
    <span class="s1">ps_transform = PolynomialCountSketch(</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">gamma=gamma</span><span class="s0">,</span>
        <span class="s1">coef0=coef0</span><span class="s0">,</span>
        <span class="s1">degree=degree</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">42</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">X_trans = ps_transform.fit_transform(X)</span>
    <span class="s1">Y_trans = ps_transform.transform(Y)</span>
    <span class="s1">kernel_approx = np.dot(X_trans</span><span class="s0">, </span><span class="s1">Y_trans.T)</span>

    <span class="s1">error = kernel - kernel_approx</span>
    <span class="s0">assert </span><span class="s1">np.abs(np.mean(error)) &lt;= </span><span class="s3">0.05  </span><span class="s2"># close to unbiased</span>
    <span class="s1">np.abs(error</span><span class="s0">, </span><span class="s1">out=error)</span>
    <span class="s0">assert </span><span class="s1">np.max(error) &lt;= </span><span class="s3">0.1  </span><span class="s2"># nothing too far off</span>
    <span class="s0">assert </span><span class="s1">np.mean(error) &lt;= </span><span class="s3">0.05  </span><span class="s2"># mean is fairly close</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;gamma&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;degree&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;coef0&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_polynomial_count_sketch_dense_sparse(gamma</span><span class="s0">, </span><span class="s1">degree</span><span class="s0">, </span><span class="s1">coef0):</span>
    <span class="s5">&quot;&quot;&quot;Check that PolynomialCountSketch results are the same for dense and sparse 
    input. 
    &quot;&quot;&quot;</span>
    <span class="s1">ps_dense = PolynomialCountSketch(</span>
        <span class="s1">n_components=</span><span class="s3">500</span><span class="s0">, </span><span class="s1">gamma=gamma</span><span class="s0">, </span><span class="s1">degree=degree</span><span class="s0">, </span><span class="s1">coef0=coef0</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span>
    <span class="s1">)</span>
    <span class="s1">Xt_dense = ps_dense.fit_transform(X)</span>
    <span class="s1">Yt_dense = ps_dense.transform(Y)</span>

    <span class="s1">ps_sparse = PolynomialCountSketch(</span>
        <span class="s1">n_components=</span><span class="s3">500</span><span class="s0">, </span><span class="s1">gamma=gamma</span><span class="s0">, </span><span class="s1">degree=degree</span><span class="s0">, </span><span class="s1">coef0=coef0</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span>
    <span class="s1">)</span>
    <span class="s1">Xt_sparse = ps_sparse.fit_transform(csr_matrix(X))</span>
    <span class="s1">Yt_sparse = ps_sparse.transform(csr_matrix(Y))</span>

    <span class="s1">assert_allclose(Xt_dense</span><span class="s0">, </span><span class="s1">Xt_sparse)</span>
    <span class="s1">assert_allclose(Yt_dense</span><span class="s0">, </span><span class="s1">Yt_sparse)</span>


<span class="s0">def </span><span class="s1">_linear_kernel(X</span><span class="s0">, </span><span class="s1">Y):</span>
    <span class="s0">return </span><span class="s1">np.dot(X</span><span class="s0">, </span><span class="s1">Y.T)</span>


<span class="s0">def </span><span class="s1">test_additive_chi2_sampler():</span>
    <span class="s2"># test that AdditiveChi2Sampler approximates kernel on random data</span>

    <span class="s2"># compute exact kernel</span>
    <span class="s2"># abbreviations for easier formula</span>
    <span class="s1">X_ = X[:</span><span class="s0">, </span><span class="s1">np.newaxis</span><span class="s0">, </span><span class="s1">:]</span>
    <span class="s1">Y_ = Y[np.newaxis</span><span class="s0">, </span><span class="s1">:</span><span class="s0">, </span><span class="s1">:]</span>

    <span class="s1">large_kernel = </span><span class="s3">2 </span><span class="s1">* X_ * Y_ / (X_ + Y_)</span>

    <span class="s2"># reduce to n_samples_x x n_samples_y by summing over features</span>
    <span class="s1">kernel = large_kernel.sum(axis=</span><span class="s3">2</span><span class="s1">)</span>

    <span class="s2"># approximate kernel mapping</span>
    <span class="s1">transform = AdditiveChi2Sampler(sample_steps=</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">X_trans = transform.fit_transform(X)</span>
    <span class="s1">Y_trans = transform.transform(Y)</span>

    <span class="s1">kernel_approx = np.dot(X_trans</span><span class="s0">, </span><span class="s1">Y_trans.T)</span>

    <span class="s1">assert_array_almost_equal(kernel</span><span class="s0">, </span><span class="s1">kernel_approx</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s1">X_sp_trans = transform.fit_transform(csr_matrix(X))</span>
    <span class="s1">Y_sp_trans = transform.transform(csr_matrix(Y))</span>

    <span class="s1">assert_array_equal(X_trans</span><span class="s0">, </span><span class="s1">X_sp_trans.toarray())</span>
    <span class="s1">assert_array_equal(Y_trans</span><span class="s0">, </span><span class="s1">Y_sp_trans.toarray())</span>

    <span class="s2"># test error is raised on negative input</span>
    <span class="s1">Y_neg = Y.copy()</span>
    <span class="s1">Y_neg[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = -</span><span class="s3">1</span>
    <span class="s1">msg = </span><span class="s4">&quot;Negative values in data passed to&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">transform.fit(Y_neg)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">&quot;fit&quot;</span><span class="s0">, </span><span class="s4">&quot;fit_transform&quot;</span><span class="s0">, </span><span class="s4">&quot;transform&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;sample_steps&quot;</span><span class="s0">, </span><span class="s1">range(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_additive_chi2_sampler_sample_steps(method</span><span class="s0">, </span><span class="s1">sample_steps):</span>
    <span class="s5">&quot;&quot;&quot;Check that the input sample step doesn't raise an error 
    and that sample interval doesn't change after fit. 
    &quot;&quot;&quot;</span>
    <span class="s1">transformer = AdditiveChi2Sampler(sample_steps=sample_steps)</span>
    <span class="s1">getattr(transformer</span><span class="s0">, </span><span class="s1">method)(X)</span>

    <span class="s1">sample_interval = </span><span class="s3">0.5</span>
    <span class="s1">transformer = AdditiveChi2Sampler(</span>
        <span class="s1">sample_steps=sample_steps</span><span class="s0">,</span>
        <span class="s1">sample_interval=sample_interval</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">getattr(transformer</span><span class="s0">, </span><span class="s1">method)(X)</span>
    <span class="s1">transformer.sample_interval == sample_interval</span>


<span class="s2"># TODO(1.5): remove</span>
<span class="s0">def </span><span class="s1">test_additive_chi2_sampler_future_warnings():</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise a FutureWarning when accessing to `sample_interval_`.&quot;&quot;&quot;</span>
    <span class="s1">transformer = AdditiveChi2Sampler()</span>
    <span class="s1">transformer.fit(X)</span>
    <span class="s1">msg = re.escape(</span>
        <span class="s4">&quot;The ``sample_interval_`` attribute was deprecated in version 1.3 and &quot;</span>
        <span class="s4">&quot;will be removed 1.5.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s0">assert </span><span class="s1">transformer.sample_interval_ </span><span class="s0">is not None</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">&quot;fit&quot;</span><span class="s0">, </span><span class="s4">&quot;fit_transform&quot;</span><span class="s0">, </span><span class="s4">&quot;transform&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_additive_chi2_sampler_wrong_sample_steps(method):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise a ValueError on invalid sample_steps&quot;&quot;&quot;</span>
    <span class="s1">transformer = AdditiveChi2Sampler(sample_steps=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">msg = re.escape(</span>
        <span class="s4">&quot;If sample_steps is not in [1, 2, 3], you need to provide sample_interval&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">getattr(transformer</span><span class="s0">, </span><span class="s1">method)(X)</span>


<span class="s0">def </span><span class="s1">test_skewed_chi2_sampler():</span>
    <span class="s2"># test that RBFSampler approximates kernel on random data</span>

    <span class="s2"># compute exact kernel</span>
    <span class="s1">c = </span><span class="s3">0.03</span>
    <span class="s2"># set on negative component but greater than c to ensure that the kernel</span>
    <span class="s2"># approximation is valid on the group (-c; +\infty) endowed with the skewed</span>
    <span class="s2"># multiplication.</span>
    <span class="s1">Y[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = -c / </span><span class="s3">2.0</span>

    <span class="s2"># abbreviations for easier formula</span>
    <span class="s1">X_c = (X + c)[:</span><span class="s0">, </span><span class="s1">np.newaxis</span><span class="s0">, </span><span class="s1">:]</span>
    <span class="s1">Y_c = (Y + c)[np.newaxis</span><span class="s0">, </span><span class="s1">:</span><span class="s0">, </span><span class="s1">:]</span>

    <span class="s2"># we do it in log-space in the hope that it's more stable</span>
    <span class="s2"># this array is n_samples_x x n_samples_y big x n_features</span>
    <span class="s1">log_kernel = (</span>
        <span class="s1">(np.log(X_c) / </span><span class="s3">2.0</span><span class="s1">) + (np.log(Y_c) / </span><span class="s3">2.0</span><span class="s1">) + np.log(</span><span class="s3">2.0</span><span class="s1">) - np.log(X_c + Y_c)</span>
    <span class="s1">)</span>
    <span class="s2"># reduce to n_samples_x x n_samples_y by summing over features in log-space</span>
    <span class="s1">kernel = np.exp(log_kernel.sum(axis=</span><span class="s3">2</span><span class="s1">))</span>

    <span class="s2"># approximate kernel mapping</span>
    <span class="s1">transform = SkewedChi2Sampler(skewedness=c</span><span class="s0">, </span><span class="s1">n_components=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X_trans = transform.fit_transform(X)</span>
    <span class="s1">Y_trans = transform.transform(Y)</span>

    <span class="s1">kernel_approx = np.dot(X_trans</span><span class="s0">, </span><span class="s1">Y_trans.T)</span>
    <span class="s1">assert_array_almost_equal(kernel</span><span class="s0">, </span><span class="s1">kernel_approx</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.isfinite(kernel).all()</span><span class="s0">, </span><span class="s4">&quot;NaNs found in the Gram matrix&quot;</span>
    <span class="s0">assert </span><span class="s1">np.isfinite(kernel_approx).all()</span><span class="s0">, </span><span class="s4">&quot;NaNs found in the approximate Gram matrix&quot;</span>

    <span class="s2"># test error is raised on when inputs contains values smaller than -c</span>
    <span class="s1">Y_neg = Y.copy()</span>
    <span class="s1">Y_neg[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = -c * </span><span class="s3">2.0</span>
    <span class="s1">msg = </span><span class="s4">&quot;X may not contain entries smaller than -skewedness&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">transform.transform(Y_neg)</span>


<span class="s0">def </span><span class="s1">test_additive_chi2_sampler_exceptions():</span>
    <span class="s5">&quot;&quot;&quot;Ensures correct error message&quot;&quot;&quot;</span>
    <span class="s1">transformer = AdditiveChi2Sampler()</span>
    <span class="s1">X_neg = X.copy()</span>
    <span class="s1">X_neg[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = -</span><span class="s3">1</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;X in AdditiveChi2Sampler.fit&quot;</span><span class="s1">):</span>
        <span class="s1">transformer.fit(X_neg)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;X in AdditiveChi2Sampler.transform&quot;</span><span class="s1">):</span>
        <span class="s1">transformer.fit(X)</span>
        <span class="s1">transformer.transform(X_neg)</span>


<span class="s0">def </span><span class="s1">test_rbf_sampler():</span>
    <span class="s2"># test that RBFSampler approximates kernel on random data</span>
    <span class="s2"># compute exact kernel</span>
    <span class="s1">gamma = </span><span class="s3">10.0</span>
    <span class="s1">kernel = rbf_kernel(X</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">gamma=gamma)</span>

    <span class="s2"># approximate kernel mapping</span>
    <span class="s1">rbf_transform = RBFSampler(gamma=gamma</span><span class="s0">, </span><span class="s1">n_components=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X_trans = rbf_transform.fit_transform(X)</span>
    <span class="s1">Y_trans = rbf_transform.transform(Y)</span>
    <span class="s1">kernel_approx = np.dot(X_trans</span><span class="s0">, </span><span class="s1">Y_trans.T)</span>

    <span class="s1">error = kernel - kernel_approx</span>
    <span class="s0">assert </span><span class="s1">np.abs(np.mean(error)) &lt;= </span><span class="s3">0.01  </span><span class="s2"># close to unbiased</span>
    <span class="s1">np.abs(error</span><span class="s0">, </span><span class="s1">out=error)</span>
    <span class="s0">assert </span><span class="s1">np.max(error) &lt;= </span><span class="s3">0.1  </span><span class="s2"># nothing too far off</span>
    <span class="s0">assert </span><span class="s1">np.mean(error) &lt;= </span><span class="s3">0.05  </span><span class="s2"># mean is fairly close</span>


<span class="s0">def </span><span class="s1">test_rbf_sampler_fitted_attributes_dtype(global_dtype):</span>
    <span class="s5">&quot;&quot;&quot;Check that the fitted attributes are stored accordingly to the 
    data type of X.&quot;&quot;&quot;</span>
    <span class="s1">rbf = RBFSampler()</span>

    <span class="s1">X = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=global_dtype)</span>

    <span class="s1">rbf.fit(X)</span>

    <span class="s0">assert </span><span class="s1">rbf.random_offset_.dtype == global_dtype</span>
    <span class="s0">assert </span><span class="s1">rbf.random_weights_.dtype == global_dtype</span>


<span class="s0">def </span><span class="s1">test_rbf_sampler_dtype_equivalence():</span>
    <span class="s5">&quot;&quot;&quot;Check the equivalence of the results with 32 and 64 bits input.&quot;&quot;&quot;</span>
    <span class="s1">rbf32 = RBFSampler(random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X32 = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float32)</span>
    <span class="s1">rbf32.fit(X32)</span>

    <span class="s1">rbf64 = RBFSampler(random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X64 = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">rbf64.fit(X64)</span>

    <span class="s1">assert_allclose(rbf32.random_offset_</span><span class="s0">, </span><span class="s1">rbf64.random_offset_)</span>
    <span class="s1">assert_allclose(rbf32.random_weights_</span><span class="s0">, </span><span class="s1">rbf64.random_weights_)</span>


<span class="s0">def </span><span class="s1">test_rbf_sampler_gamma_scale():</span>
    <span class="s5">&quot;&quot;&quot;Check the inner value computed when `gamma='scale'`.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = [[</span><span class="s3">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">rbf = RBFSampler(gamma=</span><span class="s4">&quot;scale&quot;</span><span class="s1">)</span>
    <span class="s1">rbf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">rbf._gamma == pytest.approx(</span><span class="s3">4</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_skewed_chi2_sampler_fitted_attributes_dtype(global_dtype):</span>
    <span class="s5">&quot;&quot;&quot;Check that the fitted attributes are stored accordingly to the 
    data type of X.&quot;&quot;&quot;</span>
    <span class="s1">skewed_chi2_sampler = SkewedChi2Sampler()</span>

    <span class="s1">X = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=global_dtype)</span>

    <span class="s1">skewed_chi2_sampler.fit(X)</span>

    <span class="s0">assert </span><span class="s1">skewed_chi2_sampler.random_offset_.dtype == global_dtype</span>
    <span class="s0">assert </span><span class="s1">skewed_chi2_sampler.random_weights_.dtype == global_dtype</span>


<span class="s0">def </span><span class="s1">test_skewed_chi2_sampler_dtype_equivalence():</span>
    <span class="s5">&quot;&quot;&quot;Check the equivalence of the results with 32 and 64 bits input.&quot;&quot;&quot;</span>
    <span class="s1">skewed_chi2_sampler_32 = SkewedChi2Sampler(random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X_32 = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float32)</span>
    <span class="s1">skewed_chi2_sampler_32.fit(X_32)</span>

    <span class="s1">skewed_chi2_sampler_64 = SkewedChi2Sampler(random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X_64 = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">skewed_chi2_sampler_64.fit(X_64)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">skewed_chi2_sampler_32.random_offset_</span><span class="s0">, </span><span class="s1">skewed_chi2_sampler_64.random_offset_</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">skewed_chi2_sampler_32.random_weights_</span><span class="s0">, </span><span class="s1">skewed_chi2_sampler_64.random_weights_</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_input_validation():</span>
    <span class="s2"># Regression test: kernel approx. transformers should work on lists</span>
    <span class="s2"># No assertions; the old versions would simply crash</span>
    <span class="s1">X = [[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">]]</span>
    <span class="s1">AdditiveChi2Sampler().fit(X).transform(X)</span>
    <span class="s1">SkewedChi2Sampler().fit(X).transform(X)</span>
    <span class="s1">RBFSampler().fit(X).transform(X)</span>

    <span class="s1">X = csr_matrix(X)</span>
    <span class="s1">RBFSampler().fit(X).transform(X)</span>


<span class="s0">def </span><span class="s1">test_nystroem_approximation():</span>
    <span class="s2"># some basic tests</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.uniform(size=(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s2"># With n_components = n_samples this is exact</span>
    <span class="s1">X_transformed = Nystroem(n_components=X.shape[</span><span class="s3">0</span><span class="s1">]).fit_transform(X)</span>
    <span class="s1">K = rbf_kernel(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T)</span><span class="s0">, </span><span class="s1">K)</span>

    <span class="s1">trans = Nystroem(n_components=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">random_state=rnd)</span>
    <span class="s1">X_transformed = trans.fit(X).transform(X)</span>
    <span class="s0">assert </span><span class="s1">X_transformed.shape == (X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s2"># test callable kernel</span>
    <span class="s1">trans = Nystroem(n_components=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">kernel=_linear_kernel</span><span class="s0">, </span><span class="s1">random_state=rnd)</span>
    <span class="s1">X_transformed = trans.fit(X).transform(X)</span>
    <span class="s0">assert </span><span class="s1">X_transformed.shape == (X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s2"># test that available kernels fit and transform</span>
    <span class="s1">kernels_available = kernel_metrics()</span>
    <span class="s0">for </span><span class="s1">kern </span><span class="s0">in </span><span class="s1">kernels_available:</span>
        <span class="s1">trans = Nystroem(n_components=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">kernel=kern</span><span class="s0">, </span><span class="s1">random_state=rnd)</span>
        <span class="s1">X_transformed = trans.fit(X).transform(X)</span>
        <span class="s0">assert </span><span class="s1">X_transformed.shape == (X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_nystroem_default_parameters():</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X = rnd.uniform(size=(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s2"># rbf kernel should behave as gamma=None by default</span>
    <span class="s2"># aka gamma = 1 / n_features</span>
    <span class="s1">nystroem = Nystroem(n_components=</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">X_transformed = nystroem.fit_transform(X)</span>
    <span class="s1">K = rbf_kernel(X</span><span class="s0">, </span><span class="s1">gamma=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">K2 = np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T)</span>
    <span class="s1">assert_array_almost_equal(K</span><span class="s0">, </span><span class="s1">K2)</span>

    <span class="s2"># chi2 kernel should behave as gamma=1 by default</span>
    <span class="s1">nystroem = Nystroem(kernel=</span><span class="s4">&quot;chi2&quot;</span><span class="s0">, </span><span class="s1">n_components=</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">X_transformed = nystroem.fit_transform(X)</span>
    <span class="s1">K = chi2_kernel(X</span><span class="s0">, </span><span class="s1">gamma=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">K2 = np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T)</span>
    <span class="s1">assert_array_almost_equal(K</span><span class="s0">, </span><span class="s1">K2)</span>


<span class="s0">def </span><span class="s1">test_nystroem_singular_kernel():</span>
    <span class="s2"># test that nystroem works with singular kernel matrix</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rng.rand(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">20</span><span class="s1">)</span>
    <span class="s1">X = np.vstack([X] * </span><span class="s3">2</span><span class="s1">)  </span><span class="s2"># duplicate samples</span>

    <span class="s1">gamma = </span><span class="s3">100</span>
    <span class="s1">N = Nystroem(gamma=gamma</span><span class="s0">, </span><span class="s1">n_components=X.shape[</span><span class="s3">0</span><span class="s1">]).fit(X)</span>
    <span class="s1">X_transformed = N.transform(X)</span>

    <span class="s1">K = rbf_kernel(X</span><span class="s0">, </span><span class="s1">gamma=gamma)</span>

    <span class="s1">assert_array_almost_equal(K</span><span class="s0">, </span><span class="s1">np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T))</span>
    <span class="s0">assert </span><span class="s1">np.all(np.isfinite(Y))</span>


<span class="s0">def </span><span class="s1">test_nystroem_poly_kernel_params():</span>
    <span class="s2"># Non-regression: Nystroem should pass other parameters beside gamma.</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">37</span><span class="s1">)</span>
    <span class="s1">X = rnd.uniform(size=(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s1">K = polynomial_kernel(X</span><span class="s0">, </span><span class="s1">degree=</span><span class="s3">3.1</span><span class="s0">, </span><span class="s1">coef0=</span><span class="s3">0.1</span><span class="s1">)</span>
    <span class="s1">nystroem = Nystroem(</span>
        <span class="s1">kernel=</span><span class="s4">&quot;polynomial&quot;</span><span class="s0">, </span><span class="s1">n_components=X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">degree=</span><span class="s3">3.1</span><span class="s0">, </span><span class="s1">coef0=</span><span class="s3">0.1</span>
    <span class="s1">)</span>
    <span class="s1">X_transformed = nystroem.fit_transform(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T)</span><span class="s0">, </span><span class="s1">K)</span>


<span class="s0">def </span><span class="s1">test_nystroem_callable():</span>
    <span class="s2"># Test Nystroem on a callable.</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_samples = </span><span class="s3">10</span>
    <span class="s1">X = rnd.uniform(size=(n_samples</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">logging_histogram_kernel(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">log):</span>
        <span class="s5">&quot;&quot;&quot;Histogram kernel that writes to a log.&quot;&quot;&quot;</span>
        <span class="s1">log.append(</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">np.minimum(x</span><span class="s0">, </span><span class="s1">y).sum()</span>

    <span class="s1">kernel_log = []</span>
    <span class="s1">X = list(X)  </span><span class="s2"># test input validation</span>
    <span class="s1">Nystroem(</span>
        <span class="s1">kernel=logging_histogram_kernel</span><span class="s0">,</span>
        <span class="s1">n_components=(n_samples - </span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">kernel_params={</span><span class="s4">&quot;log&quot;</span><span class="s1">: kernel_log}</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">len(kernel_log) == n_samples * (n_samples - </span><span class="s3">1</span><span class="s1">) / </span><span class="s3">2</span>

    <span class="s2"># if degree, gamma or coef0 is passed, we raise a ValueError</span>
    <span class="s1">msg = </span><span class="s4">&quot;Don't pass gamma, coef0 or degree to Nystroem&quot;</span>
    <span class="s1">params = ({</span><span class="s4">&quot;gamma&quot;</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s4">&quot;coef0&quot;</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s4">&quot;degree&quot;</span><span class="s1">: </span><span class="s3">2</span><span class="s1">})</span>
    <span class="s0">for </span><span class="s1">param </span><span class="s0">in </span><span class="s1">params:</span>
        <span class="s1">ny = Nystroem(kernel=_linear_kernel</span><span class="s0">, </span><span class="s1">n_components=(n_samples - </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**param)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">ny.fit(X)</span>


<span class="s0">def </span><span class="s1">test_nystroem_precomputed_kernel():</span>
    <span class="s2"># Non-regression: test Nystroem on precomputed kernel.</span>
    <span class="s2"># PR - 14706</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">12</span><span class="s1">)</span>
    <span class="s1">X = rnd.uniform(size=(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s1">K = polynomial_kernel(X</span><span class="s0">, </span><span class="s1">degree=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">coef0=</span><span class="s3">0.1</span><span class="s1">)</span>
    <span class="s1">nystroem = Nystroem(kernel=</span><span class="s4">&quot;precomputed&quot;</span><span class="s0">, </span><span class="s1">n_components=X.shape[</span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">X_transformed = nystroem.fit_transform(K)</span>
    <span class="s1">assert_array_almost_equal(np.dot(X_transformed</span><span class="s0">, </span><span class="s1">X_transformed.T)</span><span class="s0">, </span><span class="s1">K)</span>

    <span class="s2"># if degree, gamma or coef0 is passed, we raise a ValueError</span>
    <span class="s1">msg = </span><span class="s4">&quot;Don't pass gamma, coef0 or degree to Nystroem&quot;</span>
    <span class="s1">params = ({</span><span class="s4">&quot;gamma&quot;</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s4">&quot;coef0&quot;</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s4">&quot;degree&quot;</span><span class="s1">: </span><span class="s3">2</span><span class="s1">})</span>
    <span class="s0">for </span><span class="s1">param </span><span class="s0">in </span><span class="s1">params:</span>
        <span class="s1">ny = Nystroem(kernel=</span><span class="s4">&quot;precomputed&quot;</span><span class="s0">, </span><span class="s1">n_components=X.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">**param)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">ny.fit(K)</span>


<span class="s0">def </span><span class="s1">test_nystroem_component_indices():</span>
    <span class="s5">&quot;&quot;&quot;Check that `component_indices_` corresponds to the subset of 
    training points used to construct the feature map. 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/20474 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">_ = make_classification(n_samples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">20</span><span class="s1">)</span>
    <span class="s1">feature_map_nystroem = Nystroem(</span>
        <span class="s1">n_components=</span><span class="s3">10</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">feature_map_nystroem.fit(X)</span>
    <span class="s0">assert </span><span class="s1">feature_map_nystroem.component_indices_.shape == (</span><span class="s3">10</span><span class="s0">,</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;Estimator&quot;</span><span class="s0">, </span><span class="s1">[PolynomialCountSketch</span><span class="s0">, </span><span class="s1">RBFSampler</span><span class="s0">, </span><span class="s1">SkewedChi2Sampler</span><span class="s0">, </span><span class="s1">Nystroem]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_get_feature_names_out(Estimator):</span>
    <span class="s5">&quot;&quot;&quot;Check get_feature_names_out&quot;&quot;&quot;</span>
    <span class="s1">est = Estimator().fit(X)</span>
    <span class="s1">X_trans = est.transform(X)</span>

    <span class="s1">names_out = est.get_feature_names_out()</span>
    <span class="s1">class_name = Estimator.__name__.lower()</span>
    <span class="s1">expected_names = [</span><span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">class_name</span><span class="s0">}{</span><span class="s1">i</span><span class="s0">}</span><span class="s4">&quot; </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(X_trans.shape[</span><span class="s3">1</span><span class="s1">])]</span>
    <span class="s1">assert_array_equal(names_out</span><span class="s0">, </span><span class="s1">expected_names)</span>


<span class="s0">def </span><span class="s1">test_additivechi2sampler_get_feature_names_out():</span>
    <span class="s5">&quot;&quot;&quot;Check get_feature_names_out for AdditiveChi2Sampler.&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rng.random_sample(size=(</span><span class="s3">300</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>

    <span class="s1">chi2_sampler = AdditiveChi2Sampler(sample_steps=</span><span class="s3">3</span><span class="s1">).fit(X)</span>
    <span class="s1">input_names = [</span><span class="s4">&quot;f0&quot;</span><span class="s0">, </span><span class="s4">&quot;f1&quot;</span><span class="s0">, </span><span class="s4">&quot;f2&quot;</span><span class="s1">]</span>
    <span class="s1">suffixes = [</span>
        <span class="s4">&quot;f0_sqrt&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f1_sqrt&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f2_sqrt&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f0_cos1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f1_cos1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f2_cos1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f0_sin1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f1_sin1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f2_sin1&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f0_cos2&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f1_cos2&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f2_cos2&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f0_sin2&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f1_sin2&quot;</span><span class="s0">,</span>
        <span class="s4">&quot;f2_sin2&quot;</span><span class="s0">,</span>
    <span class="s1">]</span>

    <span class="s1">names_out = chi2_sampler.get_feature_names_out(input_features=input_names)</span>
    <span class="s1">expected_names = [</span><span class="s4">f&quot;additivechi2sampler_</span><span class="s0">{</span><span class="s1">suffix</span><span class="s0">}</span><span class="s4">&quot; </span><span class="s0">for </span><span class="s1">suffix </span><span class="s0">in </span><span class="s1">suffixes]</span>
    <span class="s1">assert_array_equal(names_out</span><span class="s0">, </span><span class="s1">expected_names)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_target.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_target.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">datasets</span>
<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">BaseEstimator</span><span class="s0">, </span><span class="s1">TransformerMixin</span><span class="s0">, </span><span class="s1">clone</span>
<span class="s0">from </span><span class="s1">sklearn.compose </span><span class="s0">import </span><span class="s1">TransformedTargetRegressor</span>
<span class="s0">from </span><span class="s1">sklearn.dummy </span><span class="s0">import </span><span class="s1">DummyRegressor</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LinearRegression</span><span class="s0">, </span><span class="s1">OrthogonalMatchingPursuit</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">Pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">FunctionTransformer</span><span class="s0">, </span><span class="s1">StandardScaler</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_no_warnings</span>

<span class="s1">friedman = datasets.make_friedman1(random_state=</span><span class="s2">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_error():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s3"># provide a transformer and functions at the same time</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">,</span>
        <span class="s1">transformer=StandardScaler()</span><span class="s0">,</span>
        <span class="s1">func=np.exp</span><span class="s0">,</span>
        <span class="s1">inverse_func=np.log</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(</span>
        <span class="s1">ValueError</span><span class="s0">,</span>
        <span class="s1">match=</span><span class="s4">&quot;'transformer' and functions 'func'/'inverse_func' cannot both be set.&quot;</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s3"># fit with sample_weight with a regressor which does not support it</span>
    <span class="s1">sample_weight = np.ones((y.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=OrthogonalMatchingPursuit()</span><span class="s0">, </span><span class="s1">transformer=StandardScaler()</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(</span>
        <span class="s1">TypeError</span><span class="s0">,</span>
        <span class="s1">match=</span><span class="s4">r&quot;fit\(\) got an unexpected &quot; &quot;keyword argument 'sample_weight'&quot;</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
    <span class="s3"># func is given but inverse_func is not</span>
    <span class="s1">regr = TransformedTargetRegressor(func=np.exp)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(</span>
        <span class="s1">ValueError</span><span class="s0">,</span>
        <span class="s1">match=</span><span class="s4">&quot;When 'func' is provided, 'inverse_func' must also be provided&quot;</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_invertible():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">,</span>
        <span class="s1">func=np.sqrt</span><span class="s0">,</span>
        <span class="s1">inverse_func=np.log</span><span class="s0">,</span>
        <span class="s1">check_inverse=</span><span class="s0">True,</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(</span>
        <span class="s1">UserWarning</span><span class="s0">,</span>
        <span class="s1">match=(</span>
            <span class="s4">&quot;The provided functions or&quot;</span>
            <span class="s4">&quot; transformer are not strictly inverse of each other.&quot;</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">func=np.sqrt</span><span class="s0">, </span><span class="s1">inverse_func=np.log</span>
    <span class="s1">)</span>
    <span class="s1">regr.set_params(check_inverse=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">assert_no_warnings(regr.fit</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s0">def </span><span class="s1">_check_standard_scaled(y</span><span class="s0">, </span><span class="s1">y_pred):</span>
    <span class="s1">y_mean = np.mean(y</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">y_std = np.std(y</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose((y - y_mean) / y_std</span><span class="s0">, </span><span class="s1">y_pred)</span>


<span class="s0">def </span><span class="s1">_check_shifted_by_one(y</span><span class="s0">, </span><span class="s1">y_pred):</span>
    <span class="s1">assert_allclose(y + </span><span class="s2">1</span><span class="s0">, </span><span class="s1">y_pred)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_functions():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">func=np.log</span><span class="s0">, </span><span class="s1">inverse_func=np.exp</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s3"># check the transformer output</span>
    <span class="s1">y_tran = regr.transformer_.transform(y.reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)).squeeze()</span>
    <span class="s1">assert_allclose(np.log(y)</span><span class="s0">, </span><span class="s1">y_tran)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">regr.transformer_.inverse_transform(y_tran.reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)).squeeze()</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s1">assert_allclose(y_pred</span><span class="s0">, </span><span class="s1">regr.inverse_func(regr.regressor_.predict(X)))</span>
    <span class="s3"># check the regressor output</span>
    <span class="s1">lr = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">regr.func(y))</span>
    <span class="s1">assert_allclose(regr.regressor_.coef_.ravel()</span><span class="s0">, </span><span class="s1">lr.coef_.ravel())</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_functions_multioutput():</span>
    <span class="s1">X = friedman[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">y = np.vstack((friedman[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">friedman[</span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)).T</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">func=np.log</span><span class="s0">, </span><span class="s1">inverse_func=np.exp</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s3"># check the transformer output</span>
    <span class="s1">y_tran = regr.transformer_.transform(y)</span>
    <span class="s1">assert_allclose(np.log(y)</span><span class="s0">, </span><span class="s1">y_tran)</span>
    <span class="s1">assert_allclose(y</span><span class="s0">, </span><span class="s1">regr.transformer_.inverse_transform(y_tran))</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s1">assert_allclose(y_pred</span><span class="s0">, </span><span class="s1">regr.inverse_func(regr.regressor_.predict(X)))</span>
    <span class="s3"># check the regressor output</span>
    <span class="s1">lr = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">regr.func(y))</span>
    <span class="s1">assert_allclose(regr.regressor_.coef_.ravel()</span><span class="s0">, </span><span class="s1">lr.coef_.ravel())</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;X,y&quot;</span><span class="s0">, </span><span class="s1">[friedman</span><span class="s0">, </span><span class="s1">(friedman[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.vstack((friedman[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">friedman[</span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)).T)]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_transform_target_regressor_1d_transformer(X</span><span class="s0">, </span><span class="s1">y):</span>
    <span class="s3"># All transformer in scikit-learn expect 2D data. FunctionTransformer with</span>
    <span class="s3"># validate=False lift this constraint without checking that the input is a</span>
    <span class="s3"># 2D vector. We check the consistency of the data shape using a 1D and 2D y</span>
    <span class="s3"># array.</span>
    <span class="s1">transformer = FunctionTransformer(</span>
        <span class="s1">func=</span><span class="s0">lambda </span><span class="s1">x: x + </span><span class="s2">1</span><span class="s0">, </span><span class="s1">inverse_func=</span><span class="s0">lambda </span><span class="s1">x: x - </span><span class="s2">1</span>
    <span class="s1">)</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">transformer=transformer</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency forward transform</span>
    <span class="s1">y_tran = regr.transformer_.transform(y)</span>
    <span class="s1">_check_shifted_by_one(y</span><span class="s0">, </span><span class="s1">y_tran)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency inverse transform</span>
    <span class="s1">assert_allclose(y</span><span class="s0">, </span><span class="s1">regr.transformer_.inverse_transform(y_tran).squeeze())</span>
    <span class="s3"># consistency of the regressor</span>
    <span class="s1">lr = LinearRegression()</span>
    <span class="s1">transformer2 = clone(transformer)</span>
    <span class="s1">lr.fit(X</span><span class="s0">, </span><span class="s1">transformer2.fit_transform(y))</span>
    <span class="s1">y_lr_pred = lr.predict(X)</span>
    <span class="s1">assert_allclose(y_pred</span><span class="s0">, </span><span class="s1">transformer2.inverse_transform(y_lr_pred))</span>
    <span class="s1">assert_allclose(regr.regressor_.coef_</span><span class="s0">, </span><span class="s1">lr.coef_)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;X,y&quot;</span><span class="s0">, </span><span class="s1">[friedman</span><span class="s0">, </span><span class="s1">(friedman[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.vstack((friedman[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">friedman[</span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)).T)]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_transform_target_regressor_2d_transformer(X</span><span class="s0">, </span><span class="s1">y):</span>
    <span class="s3"># Check consistency with transformer accepting only 2D array and a 1D/2D y</span>
    <span class="s3"># array.</span>
    <span class="s1">transformer = StandardScaler()</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">transformer=transformer</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency forward transform</span>
    <span class="s0">if </span><span class="s1">y.ndim == </span><span class="s2">1</span><span class="s1">:  </span><span class="s3"># create a 2D array and squeeze results</span>
        <span class="s1">y_tran = regr.transformer_.transform(y.reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">y_tran = regr.transformer_.transform(y)</span>
    <span class="s1">_check_standard_scaled(y</span><span class="s0">, </span><span class="s1">y_tran.squeeze())</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency inverse transform</span>
    <span class="s1">assert_allclose(y</span><span class="s0">, </span><span class="s1">regr.transformer_.inverse_transform(y_tran).squeeze())</span>
    <span class="s3"># consistency of the regressor</span>
    <span class="s1">lr = LinearRegression()</span>
    <span class="s1">transformer2 = clone(transformer)</span>
    <span class="s0">if </span><span class="s1">y.ndim == </span><span class="s2">1</span><span class="s1">:  </span><span class="s3"># create a 2D array and squeeze results</span>
        <span class="s1">lr.fit(X</span><span class="s0">, </span><span class="s1">transformer2.fit_transform(y.reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)).squeeze())</span>
        <span class="s1">y_lr_pred = lr.predict(X).reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">y_pred2 = transformer2.inverse_transform(y_lr_pred).squeeze()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">lr.fit(X</span><span class="s0">, </span><span class="s1">transformer2.fit_transform(y))</span>
        <span class="s1">y_lr_pred = lr.predict(X)</span>
        <span class="s1">y_pred2 = transformer2.inverse_transform(y_lr_pred)</span>

    <span class="s1">assert_allclose(y_pred</span><span class="s0">, </span><span class="s1">y_pred2)</span>
    <span class="s1">assert_allclose(regr.regressor_.coef_</span><span class="s0">, </span><span class="s1">lr.coef_)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_2d_transformer_multioutput():</span>
    <span class="s3"># Check consistency with transformer accepting only 2D array and a 2D y</span>
    <span class="s3"># array.</span>
    <span class="s1">X = friedman[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">y = np.vstack((friedman[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">friedman[</span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)).T</span>
    <span class="s1">transformer = StandardScaler()</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">transformer=transformer</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency forward transform</span>
    <span class="s1">y_tran = regr.transformer_.transform(y)</span>
    <span class="s1">_check_standard_scaled(y</span><span class="s0">, </span><span class="s1">y_tran)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>
    <span class="s3"># consistency inverse transform</span>
    <span class="s1">assert_allclose(y</span><span class="s0">, </span><span class="s1">regr.transformer_.inverse_transform(y_tran).squeeze())</span>
    <span class="s3"># consistency of the regressor</span>
    <span class="s1">lr = LinearRegression()</span>
    <span class="s1">transformer2 = clone(transformer)</span>
    <span class="s1">lr.fit(X</span><span class="s0">, </span><span class="s1">transformer2.fit_transform(y))</span>
    <span class="s1">y_lr_pred = lr.predict(X)</span>
    <span class="s1">assert_allclose(y_pred</span><span class="s0">, </span><span class="s1">transformer2.inverse_transform(y_lr_pred))</span>
    <span class="s1">assert_allclose(regr.regressor_.coef_</span><span class="s0">, </span><span class="s1">lr.coef_)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_3d_target():</span>
    <span class="s3"># Non-regression test for:</span>
    <span class="s3"># https://github.com/scikit-learn/scikit-learn/issues/18866</span>
    <span class="s3"># Check with a 3D target with a transformer that reshapes the target</span>
    <span class="s1">X = friedman[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">y = np.tile(friedman[</span><span class="s2">1</span><span class="s1">].reshape(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">3</span><span class="s0">, </span><span class="s2">2</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">flatten_data(data):</span>
        <span class="s0">return </span><span class="s1">data.reshape(data.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">unflatten_data(data):</span>
        <span class="s0">return </span><span class="s1">data.reshape(data.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>

    <span class="s1">transformer = FunctionTransformer(func=flatten_data</span><span class="s0">, </span><span class="s1">inverse_func=unflatten_data)</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=LinearRegression()</span><span class="s0">, </span><span class="s1">transformer=transformer</span>
    <span class="s1">)</span>
    <span class="s1">y_pred = regr.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X)</span>
    <span class="s0">assert </span><span class="s1">y.shape == y_pred.shape</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_multi_to_single():</span>
    <span class="s1">X = friedman[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">y = np.transpose([friedman[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">(friedman[</span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)])</span>

    <span class="s0">def </span><span class="s1">func(y):</span>
        <span class="s1">out = np.sqrt(y[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ y[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">out[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>

    <span class="s0">def </span><span class="s1">inverse_func(y):</span>
        <span class="s0">return </span><span class="s1">y</span>

    <span class="s1">tt = TransformedTargetRegressor(</span>
        <span class="s1">func=func</span><span class="s0">, </span><span class="s1">inverse_func=inverse_func</span><span class="s0">, </span><span class="s1">check_inverse=</span><span class="s0">False</span>
    <span class="s1">)</span>
    <span class="s1">tt.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred_2d_func = tt.predict(X)</span>
    <span class="s0">assert </span><span class="s1">y_pred_2d_func.shape == (</span><span class="s2">100</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>

    <span class="s3"># force that the function only return a 1D array</span>
    <span class="s0">def </span><span class="s1">func(y):</span>
        <span class="s0">return </span><span class="s1">np.sqrt(y[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] ** </span><span class="s2">2 </span><span class="s1">+ y[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] ** </span><span class="s2">2</span><span class="s1">)</span>

    <span class="s1">tt = TransformedTargetRegressor(</span>
        <span class="s1">func=func</span><span class="s0">, </span><span class="s1">inverse_func=inverse_func</span><span class="s0">, </span><span class="s1">check_inverse=</span><span class="s0">False</span>
    <span class="s1">)</span>
    <span class="s1">tt.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred_1d_func = tt.predict(X)</span>
    <span class="s0">assert </span><span class="s1">y_pred_1d_func.shape == (</span><span class="s2">100</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>

    <span class="s1">assert_allclose(y_pred_1d_func</span><span class="s0">, </span><span class="s1">y_pred_2d_func)</span>


<span class="s0">class </span><span class="s1">DummyCheckerArrayTransformer(TransformerMixin</span><span class="s0">, </span><span class="s1">BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s0">assert </span><span class="s1">isinstance(X</span><span class="s0">, </span><span class="s1">np.ndarray)</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">transform(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">assert </span><span class="s1">isinstance(X</span><span class="s0">, </span><span class="s1">np.ndarray)</span>
        <span class="s0">return </span><span class="s1">X</span>

    <span class="s0">def </span><span class="s1">inverse_transform(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">assert </span><span class="s1">isinstance(X</span><span class="s0">, </span><span class="s1">np.ndarray)</span>
        <span class="s0">return </span><span class="s1">X</span>


<span class="s0">class </span><span class="s1">DummyCheckerListRegressor(DummyRegressor):</span>
    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s0">assert </span><span class="s1">isinstance(X</span><span class="s0">, </span><span class="s1">list)</span>
        <span class="s0">return </span><span class="s1">super().fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight)</span>

    <span class="s0">def </span><span class="s1">predict(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">assert </span><span class="s1">isinstance(X</span><span class="s0">, </span><span class="s1">list)</span>
        <span class="s0">return </span><span class="s1">super().predict(X)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_ensure_y_array():</span>
    <span class="s3"># check that the target ``y`` passed to the transformer will always be a</span>
    <span class="s3"># numpy array. Similarly, if ``X`` is passed as a list, we check that the</span>
    <span class="s3"># predictor receive as it is.</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">tt = TransformedTargetRegressor(</span>
        <span class="s1">transformer=DummyCheckerArrayTransformer()</span><span class="s0">,</span>
        <span class="s1">regressor=DummyCheckerListRegressor()</span><span class="s0">,</span>
        <span class="s1">check_inverse=</span><span class="s0">False,</span>
    <span class="s1">)</span>
    <span class="s1">tt.fit(X.tolist()</span><span class="s0">, </span><span class="s1">y.tolist())</span>
    <span class="s1">tt.predict(X.tolist())</span>
    <span class="s0">with </span><span class="s1">pytest.raises(AssertionError):</span>
        <span class="s1">tt.fit(X</span><span class="s0">, </span><span class="s1">y.tolist())</span>
    <span class="s0">with </span><span class="s1">pytest.raises(AssertionError):</span>
        <span class="s1">tt.predict(X)</span>


<span class="s0">class </span><span class="s1">DummyTransformer(TransformerMixin</span><span class="s0">, </span><span class="s1">BaseEstimator):</span>
    <span class="s5">&quot;&quot;&quot;Dummy transformer which count how many time fit was called.&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">fit_counter=</span><span class="s2">0</span><span class="s1">):</span>
        <span class="s1">self.fit_counter = fit_counter</span>

    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">self.fit_counter += </span><span class="s2">1</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">transform(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">return </span><span class="s1">X</span>

    <span class="s0">def </span><span class="s1">inverse_transform(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">return </span><span class="s1">X</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;check_inverse&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_transform_target_regressor_count_fit(check_inverse):</span>
    <span class="s3"># regression test for gh-issue #11618</span>
    <span class="s3"># check that we only call a single time fit for the transformer</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">ttr = TransformedTargetRegressor(</span>
        <span class="s1">transformer=DummyTransformer()</span><span class="s0">, </span><span class="s1">check_inverse=check_inverse</span>
    <span class="s1">)</span>
    <span class="s1">ttr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">ttr.transformer_.fit_counter == </span><span class="s2">1</span>


<span class="s0">class </span><span class="s1">DummyRegressorWithExtraFitParams(DummyRegressor):</span>
    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=</span><span class="s0">None, </span><span class="s1">check_input=</span><span class="s0">True</span><span class="s1">):</span>
        <span class="s3"># on the test below we force this to false, we make sure this is</span>
        <span class="s3"># actually passed to the regressor</span>
        <span class="s0">assert not </span><span class="s1">check_input</span>
        <span class="s0">return </span><span class="s1">super().fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_pass_fit_parameters():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=DummyRegressorWithExtraFitParams()</span><span class="s0">, </span><span class="s1">transformer=DummyTransformer()</span>
    <span class="s1">)</span>

    <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">check_input=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">regr.transformer_.fit_counter == </span><span class="s2">1</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_route_pipeline():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>

    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=DummyRegressorWithExtraFitParams()</span><span class="s0">, </span><span class="s1">transformer=DummyTransformer()</span>
    <span class="s1">)</span>
    <span class="s1">estimators = [(</span><span class="s4">&quot;normalize&quot;</span><span class="s0">, </span><span class="s1">StandardScaler())</span><span class="s0">, </span><span class="s1">(</span><span class="s4">&quot;est&quot;</span><span class="s0">, </span><span class="s1">regr)]</span>

    <span class="s1">pip = Pipeline(estimators)</span>
    <span class="s1">pip.fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">**{</span><span class="s4">&quot;est__check_input&quot;</span><span class="s1">: </span><span class="s0">False</span><span class="s1">})</span>

    <span class="s0">assert </span><span class="s1">regr.transformer_.fit_counter == </span><span class="s2">1</span>


<span class="s0">class </span><span class="s1">DummyRegressorWithExtraPredictParams(DummyRegressor):</span>
    <span class="s0">def </span><span class="s1">predict(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">check_input=</span><span class="s0">True</span><span class="s1">):</span>
        <span class="s3"># In the test below we make sure that the check input parameter is</span>
        <span class="s3"># passed as false</span>
        <span class="s1">self.predict_called = </span><span class="s0">True</span>
        <span class="s0">assert not </span><span class="s1">check_input</span>
        <span class="s0">return </span><span class="s1">super().predict(X)</span>


<span class="s0">def </span><span class="s1">test_transform_target_regressor_pass_extra_predict_parameters():</span>
    <span class="s3"># Checks that predict kwargs are passed to regressor.</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = friedman</span>
    <span class="s1">regr = TransformedTargetRegressor(</span>
        <span class="s1">regressor=DummyRegressorWithExtraPredictParams()</span><span class="s0">, </span><span class="s1">transformer=DummyTransformer()</span>
    <span class="s1">)</span>

    <span class="s1">regr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">regr.predict(X</span><span class="s0">, </span><span class="s1">check_input=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">regr.regressor_.predict_called</span>
</pre>
</body>
</html>
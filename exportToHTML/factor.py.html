<html>
<head>
<title>factor.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
factor.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>

<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">numpy.linalg </span><span class="s2">import </span><span class="s1">eigh</span><span class="s2">, </span><span class="s1">inv</span><span class="s2">, </span><span class="s1">norm</span><span class="s2">, </span><span class="s1">matrix_rank</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">minimize</span>

<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>
<span class="s2">from </span><span class="s1">statsmodels.base.model </span><span class="s2">import </span><span class="s1">Model</span>
<span class="s2">from </span><span class="s1">statsmodels.iolib </span><span class="s2">import </span><span class="s1">summary2</span>
<span class="s2">from </span><span class="s1">statsmodels.graphics.utils </span><span class="s2">import </span><span class="s1">_import_mpl</span>

<span class="s2">from </span><span class="s1">.factor_rotation </span><span class="s2">import </span><span class="s1">rotate_factors</span><span class="s2">, </span><span class="s1">promax</span>


<span class="s1">_opt_defaults = {</span><span class="s3">'gtol'</span><span class="s1">: </span><span class="s4">1e-7</span><span class="s1">}</span>


<span class="s2">def </span><span class="s1">_check_args_1(endog</span><span class="s2">, </span><span class="s1">n_factor</span><span class="s2">, </span><span class="s1">corr</span><span class="s2">, </span><span class="s1">nobs):</span>

    <span class="s1">msg = </span><span class="s3">&quot;Either endog or corr must be provided.&quot;</span>
    <span class="s2">if </span><span class="s1">endog </span><span class="s2">is not None and </span><span class="s1">corr </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
    <span class="s2">if </span><span class="s1">endog </span><span class="s2">is None and </span><span class="s1">corr </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">warnings.warn(</span><span class="s3">'Both endog and corr are provided, ' </span><span class="s1">+</span>
                      <span class="s3">'corr will be used for factor analysis.'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">n_factor &lt;= </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'n_factor must be larger than 0! %d &lt; 0' </span><span class="s1">%</span>
                         <span class="s1">(n_factor))</span>

    <span class="s2">if </span><span class="s1">nobs </span><span class="s2">is not None and </span><span class="s1">endog </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">warnings.warn(</span><span class="s3">&quot;nobs is ignored when endog is provided&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_check_args_2(endog</span><span class="s2">, </span><span class="s1">n_factor</span><span class="s2">, </span><span class="s1">corr</span><span class="s2">, </span><span class="s1">nobs</span><span class="s2">, </span><span class="s1">k_endog):</span>

    <span class="s2">if </span><span class="s1">n_factor &gt; k_endog:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'n_factor cannot be greater than the number'</span>
                         <span class="s3">' of variables! %d &gt; %d' </span><span class="s1">%</span>
                         <span class="s1">(n_factor</span><span class="s2">, </span><span class="s1">k_endog))</span>

    <span class="s2">if </span><span class="s1">np.max(np.abs(np.diag(corr) - </span><span class="s4">1</span><span class="s1">)) &gt; </span><span class="s4">1e-10</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;corr must be a correlation matrix&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">corr.shape[</span><span class="s4">0</span><span class="s1">] != corr.shape[</span><span class="s4">1</span><span class="s1">]:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Correlation matrix corr must be a square '</span>
                         <span class="s3">'(rows %d != cols %d)' </span><span class="s1">% corr.shape)</span>


<span class="s2">class </span><span class="s1">Factor(Model):</span>
    <span class="s5">&quot;&quot;&quot; 
    Factor analysis 
 
    Parameters 
    ---------- 
    endog : array_like 
        Variables in columns, observations in rows.  May be `None` if 
        `corr` is not `None`. 
    n_factor : int 
        The number of factors to extract 
    corr : array_like 
        Directly specify the correlation matrix instead of estimating 
        it from `endog`.  If provided, `endog` is not used for the 
        factor analysis, it may be used in post-estimation. 
    method : str 
        The method to extract factors, currently must be either 'pa' 
        for principal axis factor analysis or 'ml' for maximum 
        likelihood estimation. 
    smc : True or False 
        Whether or not to apply squared multiple correlations (method='pa') 
    endog_names : str 
        Names of endogenous variables.  If specified, it will be used 
        instead of the column names in endog 
    nobs : int 
        The number of observations, not used if endog is present. Needs to 
        be provided for inference if endog is None. 
    missing : 'none', 'drop', or 'raise' 
        Missing value handling for endog, default is row-wise deletion 'drop' 
        If 'none', no nan checking is done. If 'drop', any observations with 
        nans are dropped. If 'raise', an error is raised. 
 
 
    Notes 
    ----- 
    **Experimental** 
 
    Supported rotations: 'varimax', 'quartimax', 'biquartimax', 
    'equamax', 'oblimin', 'parsimax', 'parsimony', 'biquartimin', 
    'promax' 
 
    If method='ml', the factors are rotated to satisfy condition IC3 
    of Bai and Li (2012).  This means that the scores have covariance 
    I, so the model for the covariance matrix is L * L' + diag(U), 
    where L are the loadings and U are the uniquenesses.  In addition, 
    L' * diag(U)^{-1} L must be diagonal. 
 
    References 
    ---------- 
    .. [*] Hofacker, C. (2004). Exploratory Factor Analysis, Mathematical 
       Marketing. http://www.openaccesstexts.org/pdf/Quant_Chapter_11_efa.pdf 
    .. [*] J Bai, K Li (2012).  Statistical analysis of factor models of high 
       dimension.  Annals of Statistics. https://arxiv.org/pdf/1205.6617.pdf 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog=</span><span class="s2">None, </span><span class="s1">n_factor=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">corr=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'pa'</span><span class="s2">,</span>
                 <span class="s1">smc=</span><span class="s2">True, </span><span class="s1">endog_names=</span><span class="s2">None, </span><span class="s1">nobs=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s3">'drop'</span><span class="s1">):</span>

        <span class="s1">_check_args_1(endog</span><span class="s2">, </span><span class="s1">n_factor</span><span class="s2">, </span><span class="s1">corr</span><span class="s2">, </span><span class="s1">nobs)</span>

        <span class="s2">if </span><span class="s1">endog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">super(Factor</span><span class="s2">, </span><span class="s1">self).__init__(endog</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">missing=missing)</span>
            <span class="s1">endog = self.endog   </span><span class="s0"># after preprocessing like missing, asarray</span>
            <span class="s1">k_endog = endog.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">nobs = endog.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">corr = self.corr = np.corrcoef(endog</span><span class="s2">, </span><span class="s1">rowvar=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">corr </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">corr = self.corr = np.asarray(corr)</span>
            <span class="s1">k_endog = self.corr.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">self.endog = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;Either endog or corr must be provided.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s1">_check_args_2(endog</span><span class="s2">, </span><span class="s1">n_factor</span><span class="s2">, </span><span class="s1">corr</span><span class="s2">, </span><span class="s1">nobs</span><span class="s2">, </span><span class="s1">k_endog)</span>

        <span class="s1">self.n_factor = n_factor</span>
        <span class="s1">self.loadings = </span><span class="s2">None</span>
        <span class="s1">self.communality = </span><span class="s2">None</span>
        <span class="s1">self.method = method</span>
        <span class="s1">self.smc = smc</span>
        <span class="s1">self.nobs = nobs</span>
        <span class="s1">self.method = method</span>
        <span class="s1">self.corr = corr</span>
        <span class="s1">self.k_endog = k_endog</span>

        <span class="s2">if </span><span class="s1">endog_names </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">hasattr(corr</span><span class="s2">, </span><span class="s3">'index'</span><span class="s1">):</span>
                <span class="s1">endog_names = corr.index</span>
            <span class="s2">if </span><span class="s1">hasattr(corr</span><span class="s2">, </span><span class="s3">'columns'</span><span class="s1">):</span>
                <span class="s1">endog_names = corr.columns</span>
        <span class="s1">self.endog_names = endog_names</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">endog_names(self):</span>
        <span class="s5">&quot;&quot;&quot;Names of endogenous variables&quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._endog_names </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._endog_names</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.endog </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self.data.ynames</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">d = </span><span class="s4">0</span>
                <span class="s1">n = self.corr.shape[</span><span class="s4">0</span><span class="s1">] - </span><span class="s4">1</span>
                <span class="s2">while </span><span class="s1">n &gt; </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">d += </span><span class="s4">1</span>
                    <span class="s1">n //= </span><span class="s4">10</span>
                <span class="s2">return </span><span class="s1">[(</span><span class="s3">'var%0' </span><span class="s1">+ str(d) + </span><span class="s3">'d'</span><span class="s1">) % i</span>
                        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.corr.shape[</span><span class="s4">0</span><span class="s1">])]</span>

    <span class="s1">@endog_names.setter</span>
    <span class="s2">def </span><span class="s1">endog_names(self</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s0"># Check validity of endog_names:</span>
        <span class="s2">if </span><span class="s1">value </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(value) != self.corr.shape[</span><span class="s4">0</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'The length of `endog_names` must '</span>
                                 <span class="s3">'equal the number of variables.'</span><span class="s1">)</span>
            <span class="s1">self._endog_names = np.asarray(value)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._endog_names = </span><span class="s2">None</span>

    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">50</span><span class="s2">, </span><span class="s1">tol=</span><span class="s4">1e-8</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">opt_method=</span><span class="s3">'BFGS'</span><span class="s2">,</span>
            <span class="s1">opt=</span><span class="s2">None, </span><span class="s1">em_iter=</span><span class="s4">3</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Estimate factor model parameters. 
 
        Parameters 
        ---------- 
        maxiter : int 
            Maximum number of iterations for iterative estimation algorithms 
        tol : float 
            Stopping criteria (error tolerance) for iterative estimation 
            algorithms 
        start : array_like 
            Starting values, currently only used for ML estimation 
        opt_method : str 
            Optimization method for ML estimation 
        opt : dict-like 
            Keyword arguments passed to optimizer, only used for ML estimation 
        em_iter : int 
            The number of EM iterations before starting gradient optimization, 
            only used for ML estimation. 
 
        Returns 
        ------- 
        FactorResults 
            Results class instance. 
        &quot;&quot;&quot;</span>
        <span class="s1">method = self.method.lower()</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s3">'pa'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._fit_pa(maxiter=maxiter</span><span class="s2">, </span><span class="s1">tol=tol)</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'ml'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._fit_ml(start</span><span class="s2">, </span><span class="s1">em_iter</span><span class="s2">, </span><span class="s1">opt_method</span><span class="s2">, </span><span class="s1">opt)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;Unknown factor extraction approach '%s'&quot; </span><span class="s1">% self.method</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

    <span class="s2">def </span><span class="s1">_fit_pa(self</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">50</span><span class="s2">, </span><span class="s1">tol=</span><span class="s4">1e-8</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Extract factors using the iterative principal axis method 
 
        Parameters 
        ---------- 
        maxiter : int 
            Maximum number of iterations for communality estimation 
        tol : float 
            If `norm(communality - last_communality)  &lt; tolerance`, 
            estimation stops 
 
        Returns 
        ------- 
        results : FactorResults instance 
        &quot;&quot;&quot;</span>

        <span class="s1">R = self.corr.copy()  </span><span class="s0"># inplace modification below</span>

        <span class="s0"># Parameter validation</span>
        <span class="s1">self.n_comp = matrix_rank(R)</span>
        <span class="s2">if </span><span class="s1">self.n_factor &gt; self.n_comp:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'n_factor must be smaller or equal to the rank'</span>
                             <span class="s3">' of endog! %d &gt; %d' </span><span class="s1">%</span>
                             <span class="s1">(self.n_factor</span><span class="s2">, </span><span class="s1">self.n_comp))</span>
        <span class="s2">if </span><span class="s1">maxiter &lt;= </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'n_max_iter must be larger than 0! %d &lt; 0' </span><span class="s1">%</span>
                             <span class="s1">(maxiter))</span>
        <span class="s2">if </span><span class="s1">tol &lt;= </span><span class="s4">0 </span><span class="s2">or </span><span class="s1">tol &gt; </span><span class="s4">0.01</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'tolerance must be larger than 0 and smaller than'</span>
                             <span class="s3">' 0.01! Got %f instead' </span><span class="s1">% (tol))</span>

        <span class="s0">#  Initial communality estimation</span>
        <span class="s2">if </span><span class="s1">self.smc:</span>
            <span class="s1">c = </span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1 </span><span class="s1">/ np.diag(inv(R))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">c = np.ones(len(R))</span>

        <span class="s0"># Iterative communality estimation</span>
        <span class="s1">eigenvals = </span><span class="s2">None</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(maxiter):</span>
            <span class="s0"># Get eigenvalues/eigenvectors of R with diag replaced by</span>
            <span class="s0"># communality</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(len(R)):</span>
                <span class="s1">R[j</span><span class="s2">, </span><span class="s1">j] = c[j]</span>
            <span class="s1">L</span><span class="s2">, </span><span class="s1">V = eigh(R</span><span class="s2">, </span><span class="s1">UPLO=</span><span class="s3">'U'</span><span class="s1">)</span>
            <span class="s1">c_last = np.array(c)</span>
            <span class="s1">ind = np.argsort(L)</span>
            <span class="s1">ind = ind[::-</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">L = L[ind]</span>
            <span class="s1">n_pos = (L &gt; </span><span class="s4">0</span><span class="s1">).sum()</span>
            <span class="s1">V = V[:</span><span class="s2">, </span><span class="s1">ind]</span>
            <span class="s1">eigenvals = np.array(L)</span>

            <span class="s0"># Select eigenvectors with positive eigenvalues</span>
            <span class="s1">n = np.min([n_pos</span><span class="s2">, </span><span class="s1">self.n_factor])</span>
            <span class="s1">sL = np.diag(np.sqrt(L[:n]))</span>
            <span class="s1">V = V[:</span><span class="s2">, </span><span class="s1">:n]</span>

            <span class="s0"># Calculate new loadings and communality</span>
            <span class="s1">A = V.dot(sL)</span>
            <span class="s1">c = np.power(A</span><span class="s2">, </span><span class="s4">2</span><span class="s1">).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">norm(c_last - c) &lt; tol:</span>
                <span class="s2">break</span>

        <span class="s1">self.eigenvals = eigenvals</span>
        <span class="s1">self.communality = c</span>
        <span class="s1">self.uniqueness = </span><span class="s4">1 </span><span class="s1">- c</span>
        <span class="s1">self.loadings = A</span>
        <span class="s2">return </span><span class="s1">FactorResults(self)</span>

    <span class="s0"># Unpacks the model parameters from a flat vector, used for ML</span>
    <span class="s0"># estimation.  The first k_endog elements of par are the square</span>
    <span class="s0"># roots of the uniquenesses.  The remaining elements are the</span>
    <span class="s0"># factor loadings, packed one factor at a time.</span>
    <span class="s2">def </span><span class="s1">_unpack(self</span><span class="s2">, </span><span class="s1">par):</span>
        <span class="s2">return </span><span class="s1">(par[</span><span class="s4">0</span><span class="s1">:self.k_endog]**</span><span class="s4">2</span><span class="s2">,</span>
                <span class="s1">np.reshape(par[self.k_endog:]</span><span class="s2">, </span><span class="s1">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self.k_endog)).T)</span>

    <span class="s0"># Packs the model parameters into a flat parameter, used for ML</span>
    <span class="s0"># estimation.</span>
    <span class="s2">def </span><span class="s1">_pack(self</span><span class="s2">, </span><span class="s1">load</span><span class="s2">, </span><span class="s1">uniq):</span>
        <span class="s2">return </span><span class="s1">np.concatenate((np.sqrt(uniq)</span><span class="s2">, </span><span class="s1">load.T.flat))</span>

    <span class="s2">def </span><span class="s1">loglike(self</span><span class="s2">, </span><span class="s1">par):</span>
        <span class="s5">&quot;&quot;&quot; 
        Evaluate the log-likelihood function. 
 
        Parameters 
        ---------- 
        par : ndarray or tuple of 2 ndarray's 
            The model parameters, either a packed representation of 
            the model parameters or a 2-tuple containing a `k_endog x 
            n_factor` matrix of factor loadings and a `k_endog` vector 
            of uniquenesses. 
 
        Returns 
        ------- 
        float 
            The value of the log-likelihood evaluated at par. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">type(par) </span><span class="s2">is </span><span class="s1">np.ndarray:</span>
            <span class="s1">uniq</span><span class="s2">, </span><span class="s1">load = self._unpack(par)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">load</span><span class="s2">, </span><span class="s1">uniq = par[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">par[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s1">loadu = load / uniq[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">lul = np.dot(load.T</span><span class="s2">, </span><span class="s1">loadu)</span>

        <span class="s0"># log|GG' + S|</span>
        <span class="s0"># Using matrix determinant lemma:</span>
        <span class="s0"># |GG' + S| = |I + G'S^{-1}G|*|S|</span>
        <span class="s1">lul.flat[::lul.shape[</span><span class="s4">0</span><span class="s1">]+</span><span class="s4">1</span><span class="s1">] += </span><span class="s4">1</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">ld = np.linalg.slogdet(lul)</span>
        <span class="s1">v = np.sum(np.log(uniq)) + ld</span>

        <span class="s0"># tr((GG' + S)^{-1}C)</span>
        <span class="s0"># Using Sherman-Morrison-Woodbury</span>
        <span class="s1">w = np.sum(</span><span class="s4">1 </span><span class="s1">/ uniq)</span>
        <span class="s1">b = np.dot(load.T</span><span class="s2">, </span><span class="s1">self.corr / uniq[:</span><span class="s2">, None</span><span class="s1">])</span>
        <span class="s1">b = np.linalg.solve(lul</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">b = np.dot(loadu</span><span class="s2">, </span><span class="s1">b)</span>
        <span class="s1">w -= np.trace(b)</span>

        <span class="s0"># Scaled log-likelihood</span>
        <span class="s2">return </span><span class="s1">-(v + w) / (</span><span class="s4">2</span><span class="s1">*self.k_endog)</span>

    <span class="s2">def </span><span class="s1">score(self</span><span class="s2">, </span><span class="s1">par):</span>
        <span class="s5">&quot;&quot;&quot; 
        Evaluate the score function (first derivative of loglike). 
 
        Parameters 
        ---------- 
        par : ndarray or tuple of 2 ndarray's 
            The model parameters, either a packed representation of 
            the model parameters or a 2-tuple containing a `k_endog x 
            n_factor` matrix of factor loadings and a `k_endog` vector 
            of uniquenesses. 
 
        Returns 
        ------- 
        ndarray 
            The score function evaluated at par. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">type(par) </span><span class="s2">is </span><span class="s1">np.ndarray:</span>
            <span class="s1">uniq</span><span class="s2">, </span><span class="s1">load = self._unpack(par)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">load</span><span class="s2">, </span><span class="s1">uniq = par[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">par[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s0"># Center term of SMW</span>
        <span class="s1">loadu = load / uniq[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">c = np.dot(load.T</span><span class="s2">, </span><span class="s1">loadu)</span>
        <span class="s1">c.flat[::c.shape[</span><span class="s4">0</span><span class="s1">]+</span><span class="s4">1</span><span class="s1">] += </span><span class="s4">1</span>
        <span class="s1">d = np.linalg.solve(c</span><span class="s2">, </span><span class="s1">load.T)</span>

        <span class="s0"># Precompute these terms</span>
        <span class="s1">lud = np.dot(loadu</span><span class="s2">, </span><span class="s1">d)</span>
        <span class="s1">cu = (self.corr / uniq) / uniq[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">r = np.dot(cu</span><span class="s2">, </span><span class="s1">load)</span>
        <span class="s1">lul = np.dot(lud.T</span><span class="s2">, </span><span class="s1">load)</span>
        <span class="s1">luz = np.dot(cu</span><span class="s2">, </span><span class="s1">lul)</span>

        <span class="s0"># First term</span>
        <span class="s1">du = </span><span class="s4">2</span><span class="s1">*np.sqrt(uniq) * (</span><span class="s4">1</span><span class="s1">/uniq - (d * load.T).sum(</span><span class="s4">0</span><span class="s1">) / uniq**</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">dl = </span><span class="s4">2</span><span class="s1">*(loadu - np.dot(lud</span><span class="s2">, </span><span class="s1">loadu))</span>

        <span class="s0"># Second term</span>
        <span class="s1">h = np.dot(lud</span><span class="s2">, </span><span class="s1">cu)</span>
        <span class="s1">f = np.dot(h</span><span class="s2">, </span><span class="s1">lud.T)</span>
        <span class="s1">du -= </span><span class="s4">2</span><span class="s1">*np.sqrt(uniq) * (np.diag(cu) - </span><span class="s4">2</span><span class="s1">*np.diag(h) + np.diag(f))</span>
        <span class="s1">dl -= </span><span class="s4">2</span><span class="s1">*r</span>
        <span class="s1">dl += </span><span class="s4">2</span><span class="s1">*np.dot(lud</span><span class="s2">, </span><span class="s1">r)</span>
        <span class="s1">dl += </span><span class="s4">2</span><span class="s1">*luz</span>
        <span class="s1">dl -= </span><span class="s4">2</span><span class="s1">*np.dot(lud</span><span class="s2">, </span><span class="s1">luz)</span>

        <span class="s0"># Cannot use _pack because we are working with the square root</span>
        <span class="s0"># uniquenesses directly.</span>
        <span class="s2">return </span><span class="s1">-np.concatenate((du</span><span class="s2">, </span><span class="s1">dl.T.flat)) / (</span><span class="s4">2</span><span class="s1">*self.k_endog)</span>

    <span class="s0"># Maximum likelihood factor analysis.</span>
    <span class="s2">def </span><span class="s1">_fit_ml(self</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">em_iter</span><span class="s2">, </span><span class="s1">opt_method</span><span class="s2">, </span><span class="s1">opt):</span>
        <span class="s5">&quot;&quot;&quot;estimate Factor model using Maximum Likelihood 
        &quot;&quot;&quot;</span>

        <span class="s0"># Starting values</span>
        <span class="s2">if </span><span class="s1">start </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">load</span><span class="s2">, </span><span class="s1">uniq = self._fit_ml_em(em_iter)</span>
            <span class="s1">start = self._pack(load</span><span class="s2">, </span><span class="s1">uniq)</span>
        <span class="s2">elif </span><span class="s1">len(start) == </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(start[</span><span class="s4">1</span><span class="s1">]) != start[</span><span class="s4">0</span><span class="s1">].shape[</span><span class="s4">0</span><span class="s1">]:</span>
                <span class="s1">msg = </span><span class="s3">&quot;Starting values have incompatible dimensions&quot;</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
            <span class="s1">start = self._pack(start[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">start[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Invalid starting values&quot;</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">nloglike(par):</span>
            <span class="s2">return </span><span class="s1">-self.loglike(par)</span>

        <span class="s2">def </span><span class="s1">nscore(par):</span>
            <span class="s2">return </span><span class="s1">-self.score(par)</span>

        <span class="s0"># Do the optimization</span>
        <span class="s2">if </span><span class="s1">opt </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">opt = _opt_defaults</span>
        <span class="s1">r = minimize(nloglike</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">jac=nscore</span><span class="s2">, </span><span class="s1">method=opt_method</span><span class="s2">,</span>
                     <span class="s1">options=opt)</span>
        <span class="s2">if not </span><span class="s1">r.success:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;Fitting did not converge&quot;</span><span class="s1">)</span>
        <span class="s1">par = r.x</span>
        <span class="s1">uniq</span><span class="s2">, </span><span class="s1">load = self._unpack(par)</span>

        <span class="s2">if </span><span class="s1">uniq.min() &lt; </span><span class="s4">1e-10</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;Some uniquenesses are nearly zero&quot;</span><span class="s1">)</span>

        <span class="s0"># Rotate solution to satisfy IC3 of Bai and Li</span>
        <span class="s1">load = self._rotate(load</span><span class="s2">, </span><span class="s1">uniq)</span>

        <span class="s1">self.uniqueness = uniq</span>
        <span class="s1">self.communality = </span><span class="s4">1 </span><span class="s1">- uniq</span>
        <span class="s1">self.loadings = load</span>
        <span class="s1">self.mle_retvals = r</span>

        <span class="s2">return </span><span class="s1">FactorResults(self)</span>

    <span class="s2">def </span><span class="s1">_fit_ml_em(self</span><span class="s2">, </span><span class="s1">iter</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot;estimate Factor model using EM algorithm 
        &quot;&quot;&quot;</span>
        <span class="s0"># Starting values</span>
        <span class="s2">if </span><span class="s1">random_state </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">random_state = np.random.RandomState(</span><span class="s4">3427</span><span class="s1">)</span>
        <span class="s1">load = </span><span class="s4">0.1 </span><span class="s1">* random_state.standard_normal(size=(self.k_endog</span><span class="s2">, </span><span class="s1">self.n_factor))</span>
        <span class="s1">uniq = </span><span class="s4">0.5 </span><span class="s1">* np.ones(self.k_endog)</span>

        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(iter):</span>

            <span class="s1">loadu = load / uniq[:</span><span class="s2">, None</span><span class="s1">]</span>

            <span class="s1">f = np.dot(load.T</span><span class="s2">, </span><span class="s1">loadu)</span>
            <span class="s1">f.flat[::f.shape[</span><span class="s4">0</span><span class="s1">]+</span><span class="s4">1</span><span class="s1">] += </span><span class="s4">1</span>

            <span class="s1">r = np.linalg.solve(f</span><span class="s2">, </span><span class="s1">loadu.T)</span>
            <span class="s1">q = np.dot(loadu.T</span><span class="s2">, </span><span class="s1">load)</span>
            <span class="s1">h = np.dot(r</span><span class="s2">, </span><span class="s1">load)</span>

            <span class="s1">c = load - np.dot(load</span><span class="s2">, </span><span class="s1">h)</span>
            <span class="s1">c /= uniq[:</span><span class="s2">, None</span><span class="s1">]</span>

            <span class="s1">g = np.dot(q</span><span class="s2">, </span><span class="s1">r)</span>
            <span class="s1">e = np.dot(g</span><span class="s2">, </span><span class="s1">self.corr)</span>
            <span class="s1">d = np.dot(loadu.T</span><span class="s2">, </span><span class="s1">self.corr) - e</span>

            <span class="s1">a = np.dot(d</span><span class="s2">, </span><span class="s1">c)</span>
            <span class="s1">a -= np.dot(load.T</span><span class="s2">, </span><span class="s1">c)</span>
            <span class="s1">a.flat[::a.shape[</span><span class="s4">0</span><span class="s1">]+</span><span class="s4">1</span><span class="s1">] += </span><span class="s4">1</span>

            <span class="s1">b = np.dot(self.corr</span><span class="s2">, </span><span class="s1">c)</span>

            <span class="s1">load = np.linalg.solve(a</span><span class="s2">, </span><span class="s1">b.T).T</span>
            <span class="s1">uniq = np.diag(self.corr) - (load * d.T).sum(</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">load</span><span class="s2">, </span><span class="s1">uniq</span>

    <span class="s2">def </span><span class="s1">_rotate(self</span><span class="s2">, </span><span class="s1">load</span><span class="s2">, </span><span class="s1">uniq):</span>
        <span class="s5">&quot;&quot;&quot;rotate loadings for MLE 
        &quot;&quot;&quot;</span>
        <span class="s0"># Rotations used in ML estimation.</span>
        <span class="s1">load</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">_ = np.linalg.svd(load</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">load *= s</span>

        <span class="s2">if </span><span class="s1">self.nobs </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">nobs = </span><span class="s4">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">nobs = self.nobs</span>

        <span class="s1">cm = np.dot(load.T</span><span class="s2">, </span><span class="s1">load / uniq[:</span><span class="s2">, None</span><span class="s1">]) / nobs</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">f = np.linalg.eig(cm)</span>
        <span class="s1">load = np.dot(load</span><span class="s2">, </span><span class="s1">f)</span>
        <span class="s2">return </span><span class="s1">load</span>


<span class="s2">class </span><span class="s1">FactorResults:</span>
    <span class="s5">&quot;&quot;&quot; 
    Factor results class 
 
    For result summary, scree/loading plots and factor rotations 
 
    Parameters 
    ---------- 
    factor : Factor 
        Fitted Factor class 
 
    Attributes 
    ---------- 
    uniqueness : ndarray 
        The uniqueness (variance of uncorrelated errors unique to 
        each variable) 
    communality : ndarray 
        1 - uniqueness 
    loadings : ndarray 
        Each column is the loading vector for one factor 
    loadings_no_rot : ndarray 
        Unrotated loadings, not available under maximum likelihood 
        analysis. 
    eigenvals : ndarray 
        The eigenvalues for a factor analysis obtained using 
        principal components; not available under ML estimation. 
    n_comp : int 
        Number of components (factors) 
    nbs : int 
        Number of observations 
    fa_method : str 
        The method used to obtain the decomposition, either 'pa' for 
        'principal axes' or 'ml' for maximum likelihood. 
    df : int 
        Degrees of freedom of the factor model. 
 
    Notes 
    ----- 
    Under ML estimation, the default rotation (used for `loadings`) is 
    condition IC3 of Bai and Li (2012).  Under this rotation, the 
    factor scores are iid and standardized.  If `G` is the canonical 
    loadings and `U` is the vector of uniquenesses, then the 
    covariance matrix implied by the factor analysis is `GG' + 
    diag(U)`. 
 
    Status: experimental, Some refactoring will be necessary when new 
        features are added. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">factor):</span>
        <span class="s1">self.model = factor</span>
        <span class="s1">self.endog_names = factor.endog_names</span>
        <span class="s1">self.loadings_no_rot = factor.loadings</span>
        <span class="s2">if </span><span class="s1">hasattr(factor</span><span class="s2">, </span><span class="s3">&quot;eigenvals&quot;</span><span class="s1">):</span>
            <span class="s1">self.eigenvals = factor.eigenvals</span>

        <span class="s1">self.communality = factor.communality</span>
        <span class="s1">self.uniqueness = factor.uniqueness</span>
        <span class="s1">self.rotation_method = </span><span class="s2">None</span>
        <span class="s1">self.fa_method = factor.method</span>
        <span class="s1">self.n_comp = factor.loadings.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">self.nobs = factor.nobs</span>
        <span class="s1">self._factor = factor</span>
        <span class="s2">if </span><span class="s1">hasattr(factor</span><span class="s2">, </span><span class="s3">&quot;mle_retvals&quot;</span><span class="s1">):</span>
            <span class="s1">self.mle_retvals = factor.mle_retvals</span>

        <span class="s1">p</span><span class="s2">, </span><span class="s1">k = self.loadings_no_rot.shape</span>
        <span class="s1">self.df = ((p - k)**</span><span class="s4">2 </span><span class="s1">- (p + k)) // </span><span class="s4">2</span>

        <span class="s0"># no rotation, overwritten in `rotate`</span>
        <span class="s1">self.loadings = factor.loadings</span>
        <span class="s1">self.rotation_matrix = np.eye(self.n_comp)</span>


    <span class="s2">def </span><span class="s1">__str__(self):</span>
        <span class="s2">return </span><span class="s1">self.summary().__str__()</span>

    <span class="s2">def </span><span class="s1">rotate(self</span><span class="s2">, </span><span class="s1">method):</span>
        <span class="s5">&quot;&quot;&quot; 
        Apply rotation, inplace modification of this Results instance 
 
        Parameters 
        ---------- 
        method : str 
            Rotation to be applied.  Allowed methods are varimax, 
            quartimax, biquartimax, equamax, oblimin, parsimax, 
            parsimony, biquartimin, promax. 
 
        Returns 
        ------- 
        None : nothing returned, modifications are inplace 
 
 
        Notes 
        ----- 
        Warning: 'varimax', 'quartimax' and 'oblimin' are verified against R or 
        Stata. Some rotation methods such as promax do not produce the same 
        results as the R or Stata default functions. 
 
        See Also 
        -------- 
        factor_rotation : subpackage that implements rotation methods 
        &quot;&quot;&quot;</span>
        <span class="s1">self.rotation_method = method</span>
        <span class="s2">if </span><span class="s1">method </span><span class="s2">not in </span><span class="s1">[</span><span class="s3">'varimax'</span><span class="s2">, </span><span class="s3">'quartimax'</span><span class="s2">, </span><span class="s3">'biquartimax'</span><span class="s2">,</span>
                          <span class="s3">'equamax'</span><span class="s2">, </span><span class="s3">'oblimin'</span><span class="s2">, </span><span class="s3">'parsimax'</span><span class="s2">, </span><span class="s3">'parsimony'</span><span class="s2">,</span>
                          <span class="s3">'biquartimin'</span><span class="s2">, </span><span class="s3">'promax'</span><span class="s1">]:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Unknown rotation method %s' </span><span class="s1">% (method))</span>

        <span class="s2">if </span><span class="s1">method </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'varimax'</span><span class="s2">, </span><span class="s3">'quartimax'</span><span class="s2">, </span><span class="s3">'biquartimax'</span><span class="s2">, </span><span class="s3">'equamax'</span><span class="s2">,</span>
                      <span class="s3">'parsimax'</span><span class="s2">, </span><span class="s3">'parsimony'</span><span class="s2">, </span><span class="s3">'biquartimin'</span><span class="s1">]:</span>
            <span class="s1">self.loadings</span><span class="s2">, </span><span class="s1">T = rotate_factors(self.loadings_no_rot</span><span class="s2">, </span><span class="s1">method)</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'oblimin'</span><span class="s1">:</span>
            <span class="s1">self.loadings</span><span class="s2">, </span><span class="s1">T = rotate_factors(self.loadings_no_rot</span><span class="s2">,</span>
                                              <span class="s3">'quartimin'</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'promax'</span><span class="s1">:</span>
            <span class="s1">self.loadings</span><span class="s2">, </span><span class="s1">T = promax(self.loadings_no_rot)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'rotation method not recognized'</span><span class="s1">)</span>

        <span class="s1">self.rotation_matrix = T</span>

    <span class="s2">def </span><span class="s1">_corr_factors(self):</span>
        <span class="s5">&quot;&quot;&quot;correlation of factors implied by rotation 
 
        If the rotation is oblique, then the factors are correlated. 
 
        currently not cached 
 
        Returns 
        ------- 
        corr_f : ndarray 
            correlation matrix of rotated factors, assuming initial factors are 
            orthogonal 
        &quot;&quot;&quot;</span>
        <span class="s1">T = self.rotation_matrix</span>
        <span class="s1">corr_f = T.T.dot(T)</span>
        <span class="s2">return </span><span class="s1">corr_f</span>

    <span class="s2">def </span><span class="s1">factor_score_params(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'bartlett'</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Compute factor scoring coefficient matrix 
 
        The coefficient matrix is not cached. 
 
        Parameters 
        ---------- 
        method : 'bartlett' or 'regression' 
            Method to use for factor scoring. 
            'regression' can be abbreviated to `reg` 
 
        Returns 
        ------- 
        coeff_matrix : ndarray 
            matrix s to compute factors f from a standardized endog ys. 
            ``f = ys dot s`` 
 
        Notes 
        ----- 
        The `regression` method follows the Stata definition. 
        Method bartlett and regression are verified against Stats. 
        Two unofficial methods, 'ols' and 'gls', produce similar factor scores 
        but are not verified. 
 
        See Also 
        -------- 
        statsmodels.multivariate.factor.FactorResults.factor_scoring 
        &quot;&quot;&quot;</span>
        <span class="s1">L = self.loadings</span>
        <span class="s1">T = self.rotation_matrix.T</span>
        <span class="s0">#TODO: check row versus column convention for T</span>
        <span class="s1">uni = </span><span class="s4">1 </span><span class="s1">- self.communality </span><span class="s0">#self.uniqueness</span>

        <span class="s2">if </span><span class="s1">method == </span><span class="s3">'bartlett'</span><span class="s1">:</span>
            <span class="s1">s_mat = np.linalg.inv(L.T.dot(L/(uni[:</span><span class="s2">,None</span><span class="s1">]))).dot((L.T / uni)).T</span>
        <span class="s2">elif </span><span class="s1">method.startswith(</span><span class="s3">'reg'</span><span class="s1">):</span>
            <span class="s1">corr = self.model.corr</span>
            <span class="s1">corr_f = self._corr_factors()</span>
            <span class="s0"># if orthogonal then corr_f is just eye</span>
            <span class="s1">s_mat = corr_f.dot(L.T.dot(np.linalg.inv(corr))).T</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'ols'</span><span class="s1">:</span>
            <span class="s0"># not verified</span>
            <span class="s1">corr = self.model.corr</span>
            <span class="s1">corr_f = self._corr_factors()</span>
            <span class="s1">s_mat = corr_f.dot(np.linalg.pinv(L)).T</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'gls'</span><span class="s1">:</span>
            <span class="s0"># not verified</span>
            <span class="s0">#s_mat = np.linalg.inv(1*np.eye(L.shape[1]) + L.T.dot(L/(uni[:,None])))</span>
            <span class="s1">corr = self.model.corr</span>
            <span class="s1">corr_f = self._corr_factors()</span>
            <span class="s1">s_mat = np.linalg.inv(np.linalg.inv(corr_f) + L.T.dot(L/(uni[:</span><span class="s2">,None</span><span class="s1">])))</span>
            <span class="s1">s_mat = s_mat.dot(L.T / uni).T</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'method not available, use &quot;bartlett ' </span><span class="s1">+</span>
                             <span class="s3">'or &quot;regression&quot;'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">s_mat</span>

    <span class="s2">def </span><span class="s1">factor_scoring(self</span><span class="s2">, </span><span class="s1">endog=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'bartlett'</span><span class="s2">, </span><span class="s1">transform=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        factor scoring: compute factors for endog 
 
        If endog was not provided when creating the factor class, then 
        a standarized endog needs to be provided here. 
 
        Parameters 
        ---------- 
        method : 'bartlett' or 'regression' 
            Method to use for factor scoring. 
            'regression' can be abbreviated to `reg` 
        transform : bool 
            If transform is true and endog is provided, then it will be 
            standardized using mean and scale of original data, which has to 
            be available in this case. 
            If transform is False, then a provided endog will be used unchanged. 
            The original endog in the Factor class will 
            always be standardized if endog is None, independently of `transform`. 
 
        Returns 
        ------- 
        factor_score : ndarray 
            estimated factors using scoring matrix s and standarized endog ys 
            ``f = ys dot s`` 
 
        Notes 
        ----- 
        Status: transform option is experimental and might change. 
 
        See Also 
        -------- 
        statsmodels.multivariate.factor.FactorResults.factor_score_params 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">transform </span><span class="s2">is False and </span><span class="s1">endog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># no transformation in this case</span>
            <span class="s1">endog = np.asarray(endog)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># we need to standardize with the original mean and scale</span>
            <span class="s2">if </span><span class="s1">self.model.endog </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">m = self.model.endog.mean(</span><span class="s4">0</span><span class="s1">)</span>
                <span class="s1">s = self.model.endog.std(ddof=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
                <span class="s2">if </span><span class="s1">endog </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">endog = self.model.endog</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">endog = np.asarray(endog)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'If transform is True, then `endog` needs ' </span><span class="s1">+</span>
                                 <span class="s3">'to be available in the Factor instance.'</span><span class="s1">)</span>

            <span class="s1">endog = (endog - m) / s</span>

        <span class="s1">s_mat = self.factor_score_params(method=method)</span>
        <span class="s1">factors = endog.dot(s_mat)</span>
        <span class="s2">return </span><span class="s1">factors</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s5">&quot;&quot;&quot;Summary&quot;&quot;&quot;</span>
        <span class="s1">summ = summary2.Summary()</span>
        <span class="s1">summ.add_title(</span><span class="s3">'Factor analysis results'</span><span class="s1">)</span>
        <span class="s1">loadings_no_rot = pd.DataFrame(</span>
            <span class="s1">self.loadings_no_rot</span><span class="s2">,</span>
            <span class="s1">columns=[</span><span class="s3">&quot;factor %d&quot; </span><span class="s1">% (i)</span>
                     <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.loadings_no_rot.shape[</span><span class="s4">1</span><span class="s1">])]</span><span class="s2">,</span>
            <span class="s1">index=self.endog_names</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">&quot;eigenvals&quot;</span><span class="s1">):</span>
            <span class="s0"># eigenvals not available for ML method</span>
            <span class="s1">eigenvals = pd.DataFrame(</span>
                <span class="s1">[self.eigenvals]</span><span class="s2">, </span><span class="s1">columns=self.endog_names</span><span class="s2">, </span><span class="s1">index=[</span><span class="s3">''</span><span class="s1">])</span>
            <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">'Eigenvalues'</span><span class="s1">})</span>
            <span class="s1">summ.add_df(eigenvals)</span>
        <span class="s1">communality = pd.DataFrame([self.communality]</span><span class="s2">,</span>
                                   <span class="s1">columns=self.endog_names</span><span class="s2">, </span><span class="s1">index=[</span><span class="s3">''</span><span class="s1">])</span>
        <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">''</span><span class="s1">})</span>
        <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">'Communality'</span><span class="s1">})</span>
        <span class="s1">summ.add_df(communality)</span>
        <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">''</span><span class="s1">})</span>
        <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">'Pre-rotated loadings'</span><span class="s1">})</span>
        <span class="s1">summ.add_df(loadings_no_rot)</span>
        <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">''</span><span class="s1">})</span>
        <span class="s2">if </span><span class="s1">self.rotation_method </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">loadings = pd.DataFrame(</span>
                <span class="s1">self.loadings</span><span class="s2">,</span>
                <span class="s1">columns=[</span><span class="s3">&quot;factor %d&quot; </span><span class="s1">% (i)</span>
                         <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.loadings.shape[</span><span class="s4">1</span><span class="s1">])]</span><span class="s2">,</span>
                <span class="s1">index=self.endog_names</span>
            <span class="s1">)</span>
            <span class="s1">summ.add_dict({</span><span class="s3">''</span><span class="s1">: </span><span class="s3">'%s rotated loadings' </span><span class="s1">% (self.rotation_method)})</span>
            <span class="s1">summ.add_df(loadings)</span>
        <span class="s2">return </span><span class="s1">summ</span>

    <span class="s2">def </span><span class="s1">get_loadings_frame(self</span><span class="s2">, </span><span class="s1">style=</span><span class="s3">'display'</span><span class="s2">, </span><span class="s1">sort_=</span><span class="s2">True, </span><span class="s1">threshold=</span><span class="s4">0.3</span><span class="s2">,</span>
                           <span class="s1">highlight_max=</span><span class="s2">True, </span><span class="s1">color_max=</span><span class="s3">'yellow'</span><span class="s2">,</span>
                           <span class="s1">decimals=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot;get loadings matrix as DataFrame or pandas Styler 
 
        Parameters 
        ---------- 
        style : 'display' (default), 'raw' or 'strings' 
            Style to use for display 
 
            * 'raw' returns just a DataFrame of the loadings matrix, no options are 
               applied 
            * 'display' add sorting and styling as defined by other keywords 
            * 'strings' returns a DataFrame with string elements with optional sorting 
               and suppressing small loading coefficients. 
 
        sort_ : bool 
            If True, then the rows of the DataFrame is sorted by contribution of each 
            factor. applies if style is either 'display' or 'strings' 
        threshold : float 
            If the threshold is larger than zero, then loading coefficients are 
            either colored white (if style is 'display') or replace by empty 
            string (if style is 'strings'). 
        highlight_max : bool 
            This add a background color to the largest coefficient in each row. 
        color_max : html color 
            default is 'yellow'. color for background of row maximum 
        decimals : None or int 
            If None, then pandas default precision applies. Otherwise values are 
            rounded to the specified decimals. If style is 'display', then the 
            underlying dataframe is not changed. If style is 'strings', then 
            values are rounded before conversion to strings. 
 
        Returns 
        ------- 
        loadings : DataFrame or pandas Styler instance 
            The return is a pandas Styler instance, if style is 'display' and 
            at least one of highlight_max, threshold or decimals is applied. 
            Otherwise, the returned loadings is a DataFrame. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; mod = Factor(df, 3, smc=True) 
        &gt;&gt;&gt; res = mod.fit() 
        &gt;&gt;&gt; res.get_loadings_frame(style='display', decimals=3, threshold=0.2) 
 
        To get a sorted DataFrame, all styling options need to be turned off: 
 
        &gt;&gt;&gt; df_sorted = res.get_loadings_frame(style='display', 
        ...             highlight_max=False, decimals=None, threshold=0) 
 
        Options except for highlighting are available for plain test or Latex 
        usage: 
 
        &gt;&gt;&gt; lds = res_u.get_loadings_frame(style='strings', decimals=3, 
        ...                                threshold=0.3) 
        &gt;&gt;&gt; print(lds.to_latex()) 
        &quot;&quot;&quot;</span>

        <span class="s1">loadings_df = pd.DataFrame(</span>
                <span class="s1">self.loadings</span><span class="s2">,</span>
                <span class="s1">columns=[</span><span class="s3">&quot;factor %d&quot; </span><span class="s1">% (i)</span>
                         <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.loadings.shape[</span><span class="s4">1</span><span class="s1">])]</span><span class="s2">,</span>
                <span class="s1">index=self.endog_names</span>
                <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">style </span><span class="s2">not in </span><span class="s1">[</span><span class="s3">'raw'</span><span class="s2">, </span><span class="s3">'display'</span><span class="s2">, </span><span class="s3">'strings'</span><span class="s1">]:</span>
            <span class="s1">msg = </span><span class="s3">&quot;style has to be one of 'raw', 'display', 'strings'&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">if </span><span class="s1">style == </span><span class="s3">'raw'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">loadings_df</span>

        <span class="s0"># add sorting and some formatting</span>
        <span class="s2">if </span><span class="s1">sort_ </span><span class="s2">is True</span><span class="s1">:</span>
            <span class="s1">loadings_df2 = loadings_df.copy()</span>
            <span class="s1">n_f = len(loadings_df2)</span>
            <span class="s1">high = np.abs(loadings_df2.values).argmax(</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">loadings_df2[</span><span class="s3">'high'</span><span class="s1">] = high</span>
            <span class="s1">loadings_df2[</span><span class="s3">'largest'</span><span class="s1">] = np.abs(loadings_df.values[np.arange(n_f)</span><span class="s2">, </span><span class="s1">high])</span>
            <span class="s1">loadings_df2.sort_values(by=[</span><span class="s3">'high'</span><span class="s2">, </span><span class="s3">'largest'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ascending=[</span><span class="s2">True, False</span><span class="s1">]</span><span class="s2">, </span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">loadings_df = loadings_df2.drop([</span><span class="s3">'high'</span><span class="s2">, </span><span class="s3">'largest'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">style == </span><span class="s3">'display'</span><span class="s1">:</span>
            <span class="s1">sty = </span><span class="s2">None</span>
            <span class="s2">if </span><span class="s1">threshold &gt; </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">def </span><span class="s1">color_white_small(val):</span>
                    <span class="s5">&quot;&quot;&quot; 
                    Takes a scalar and returns a string with 
                    the css property `'color: white'` for small values, black otherwise. 
 
                    takes threshold from outer scope 
                    &quot;&quot;&quot;</span>
                    <span class="s1">color = </span><span class="s3">'white' </span><span class="s2">if </span><span class="s1">np.abs(val) &lt; threshold </span><span class="s2">else </span><span class="s3">'black'</span>
                    <span class="s2">return </span><span class="s3">'color: %s' </span><span class="s1">% color</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">sty = loadings_df.style.map(color_white_small)</span>
                <span class="s2">except </span><span class="s1">AttributeError:</span>
                    <span class="s0"># Deprecated in pandas 2.1</span>
                    <span class="s1">sty = loadings_df.style.applymap(color_white_small)</span>

            <span class="s2">if </span><span class="s1">highlight_max </span><span class="s2">is True</span><span class="s1">:</span>
                <span class="s2">def </span><span class="s1">highlight_max(s):</span>
                    <span class="s5">''' 
                    highlight the maximum in a Series yellow. 
                    '''</span>
                    <span class="s1">s = np.abs(s)</span>
                    <span class="s1">is_max = s == s.max()</span>
                    <span class="s2">return </span><span class="s1">[</span><span class="s3">'background-color: '</span><span class="s1">+ color_max </span><span class="s2">if </span><span class="s1">v </span><span class="s2">else </span><span class="s3">'' </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">is_max]</span>

                <span class="s2">if </span><span class="s1">sty </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">sty = loadings_df.style</span>

                <span class="s1">sty = sty.apply(highlight_max</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">decimals </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">sty </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">sty = loadings_df.style</span>

                <span class="s1">sty.format(</span><span class="s3">&quot;{:.%sf}&quot; </span><span class="s1">% decimals)</span>

            <span class="s2">if </span><span class="s1">sty </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">loadings_df</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">sty</span>

        <span class="s2">if </span><span class="s1">style == </span><span class="s3">'strings'</span><span class="s1">:</span>
            <span class="s1">ld = loadings_df</span>
            <span class="s2">if </span><span class="s1">decimals </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">ld = ld.round(decimals)</span>
            <span class="s1">ld = ld.astype(str)</span>
            <span class="s2">if </span><span class="s1">threshold &gt; </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">ld[loadings_df.abs() &lt; threshold] = </span><span class="s3">''</span>
            <span class="s2">return </span><span class="s1">ld</span>

    <span class="s2">def </span><span class="s1">plot_scree(self</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Plot of the ordered eigenvalues and variance explained for the loadings 
 
        Parameters 
        ---------- 
        ncomp : int, optional 
            Number of loadings to include in the plot.  If None, will 
            included the same as the number of maximum possible loadings 
 
        Returns 
        ------- 
        Figure 
            Handle to the figure. 
        &quot;&quot;&quot;</span>
        <span class="s1">_import_mpl()</span>
        <span class="s2">from </span><span class="s1">.plots </span><span class="s2">import </span><span class="s1">plot_scree</span>
        <span class="s2">return </span><span class="s1">plot_scree(self.eigenvals</span><span class="s2">, </span><span class="s1">self.n_comp</span><span class="s2">, </span><span class="s1">ncomp)</span>

    <span class="s2">def </span><span class="s1">plot_loadings(self</span><span class="s2">, </span><span class="s1">loading_pairs=</span><span class="s2">None, </span><span class="s1">plot_prerotated=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Plot factor loadings in 2-d plots 
 
        Parameters 
        ---------- 
        loading_pairs : None or a list of tuples 
            Specify plots. Each tuple (i, j) represent one figure, i and j is 
            the loading number for x-axis and y-axis, respectively. If `None`, 
            all combinations of the loadings will be plotted. 
        plot_prerotated : True or False 
            If True, the loadings before rotation applied will be plotted. If 
            False, rotated loadings will be plotted. 
 
        Returns 
        ------- 
        figs : a list of figure handles 
        &quot;&quot;&quot;</span>
        <span class="s1">_import_mpl()</span>
        <span class="s2">from </span><span class="s1">.plots </span><span class="s2">import </span><span class="s1">plot_loadings</span>

        <span class="s2">if </span><span class="s1">self.rotation_method </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">plot_prerotated = </span><span class="s2">True</span>
        <span class="s1">loadings = self.loadings_no_rot </span><span class="s2">if </span><span class="s1">plot_prerotated </span><span class="s2">else </span><span class="s1">self.loadings</span>
        <span class="s2">if </span><span class="s1">plot_prerotated:</span>
            <span class="s1">title = </span><span class="s3">'Prerotated Factor Pattern'</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">title = </span><span class="s3">'%s Rotated Factor Pattern' </span><span class="s1">% (self.rotation_method)</span>
        <span class="s1">var_explained = self.eigenvals / self.n_comp * </span><span class="s4">100</span>

        <span class="s2">return </span><span class="s1">plot_loadings(loadings</span><span class="s2">, </span><span class="s1">loading_pairs=loading_pairs</span><span class="s2">,</span>
                             <span class="s1">title=title</span><span class="s2">, </span><span class="s1">row_names=self.endog_names</span><span class="s2">,</span>
                             <span class="s1">percent_variance=var_explained)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">fitted_cov(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        Returns the fitted covariance matrix. 
        &quot;&quot;&quot;</span>

        <span class="s1">c = np.dot(self.loadings</span><span class="s2">, </span><span class="s1">self.loadings.T)</span>
        <span class="s1">c.flat[::c.shape[</span><span class="s4">0</span><span class="s1">]+</span><span class="s4">1</span><span class="s1">] += self.uniqueness</span>
        <span class="s2">return </span><span class="s1">c</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">uniq_stderr(self</span><span class="s2">, </span><span class="s1">kurt=</span><span class="s4">0</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        The standard errors of the uniquenesses. 
 
        Parameters 
        ---------- 
        kurt : float 
            Excess kurtosis 
 
        Notes 
        ----- 
        If excess kurtosis is known, provide as `kurt`.  Standard 
        errors are only available if the model was fit using maximum 
        likelihood.  If `endog` is not provided, `nobs` must be 
        provided to obtain standard errors. 
 
        These are asymptotic standard errors.  See Bai and Li (2012) 
        for conditions under which the standard errors are valid. 
 
        The standard errors are only applicable to the original, 
        unrotated maximum likelihood solution. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.fa_method.lower() != </span><span class="s3">&quot;ml&quot;</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;Standard errors only available under ML estimation&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">if </span><span class="s1">self.nobs </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;nobs is required to obtain standard errors.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s1">v = self.uniqueness**</span><span class="s4">2 </span><span class="s1">* (</span><span class="s4">2 </span><span class="s1">+ kurt)</span>
        <span class="s2">return </span><span class="s1">np.sqrt(v / self.nobs)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">load_stderr(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        The standard errors of the loadings. 
 
        Standard errors are only available if the model was fit using 
        maximum likelihood.  If `endog` is not provided, `nobs` must be 
        provided to obtain standard errors. 
 
        These are asymptotic standard errors.  See Bai and Li (2012) 
        for conditions under which the standard errors are valid. 
 
        The standard errors are only applicable to the original, 
        unrotated maximum likelihood solution. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.fa_method.lower() != </span><span class="s3">&quot;ml&quot;</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;Standard errors only available under ML estimation&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">if </span><span class="s1">self.nobs </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s3">&quot;nobs is required to obtain standard errors.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s1">v = np.outer(self.uniqueness</span><span class="s2">, </span><span class="s1">np.ones(self.loadings.shape[</span><span class="s4">1</span><span class="s1">]))</span>
        <span class="s2">return </span><span class="s1">np.sqrt(v / self.nobs)</span>
</pre>
</body>
</html>
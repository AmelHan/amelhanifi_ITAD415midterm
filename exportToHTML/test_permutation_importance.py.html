<html>
<head>
<title>test_permutation_importance.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_permutation_importance.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>

<span class="s0">from </span><span class="s1">sklearn.compose </span><span class="s0">import </span><span class="s1">ColumnTransformer</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">load_diabetes</span><span class="s0">,</span>
    <span class="s1">load_iris</span><span class="s0">,</span>
    <span class="s1">make_classification</span><span class="s0">,</span>
    <span class="s1">make_regression</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.dummy </span><span class="s0">import </span><span class="s1">DummyClassifier</span>
<span class="s0">from </span><span class="s1">sklearn.ensemble </span><span class="s0">import </span><span class="s1">RandomForestClassifier</span><span class="s0">, </span><span class="s1">RandomForestRegressor</span>
<span class="s0">from </span><span class="s1">sklearn.impute </span><span class="s0">import </span><span class="s1">SimpleImputer</span>
<span class="s0">from </span><span class="s1">sklearn.inspection </span><span class="s0">import </span><span class="s1">permutation_importance</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LinearRegression</span><span class="s0">, </span><span class="s1">LogisticRegression</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">get_scorer</span><span class="s0">,</span>
    <span class="s1">mean_squared_error</span><span class="s0">,</span>
    <span class="s1">r2_score</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.model_selection </span><span class="s0">import </span><span class="s1">train_test_split</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">KBinsDiscretizer</span><span class="s0">, </span><span class="s1">OneHotEncoder</span><span class="s0">, </span><span class="s1">StandardScaler</span><span class="s0">, </span><span class="s1">scale</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">parallel_backend</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">_convert_container</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;n_jobs&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;max_samples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_correlated_feature_regression(n_jobs</span><span class="s0">, </span><span class="s1">max_samples):</span>
    <span class="s4"># Make sure that feature highly correlated to the target have a higher</span>
    <span class="s4"># importance</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_repeats = </span><span class="s3">5</span>

    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = load_diabetes(return_X_y=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">y_with_little_noise = (y + rng.normal(scale=</span><span class="s3">0.001</span><span class="s0">, </span><span class="s1">size=y.shape[</span><span class="s3">0</span><span class="s1">])).reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s1">X = np.hstack([X</span><span class="s0">, </span><span class="s1">y_with_little_noise])</span>

    <span class="s1">clf = RandomForestRegressor(n_estimators=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">result = permutation_importance(</span>
        <span class="s1">clf</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">n_repeats=n_repeats</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">n_jobs=n_jobs</span><span class="s0">,</span>
        <span class="s1">max_samples=max_samples</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">result.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>

    <span class="s4"># the correlated feature with y was added as the last column and should</span>
    <span class="s4"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np.all(result.importances_mean[-</span><span class="s3">1</span><span class="s1">] &gt; result.importances_mean[:-</span><span class="s3">1</span><span class="s1">])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;n_jobs&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;max_samples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_correlated_feature_regression_pandas(</span>
    <span class="s1">n_jobs</span><span class="s0">, </span><span class="s1">max_samples</span>
<span class="s1">):</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s2">&quot;pandas&quot;</span><span class="s1">)</span>

    <span class="s4"># Make sure that feature highly correlated to the target have a higher</span>
    <span class="s4"># importance</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_repeats = </span><span class="s3">5</span>

    <span class="s1">dataset = load_iris()</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = dataset.data</span><span class="s0">, </span><span class="s1">dataset.target</span>
    <span class="s1">y_with_little_noise = (y + rng.normal(scale=</span><span class="s3">0.001</span><span class="s0">, </span><span class="s1">size=y.shape[</span><span class="s3">0</span><span class="s1">])).reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s4"># Adds feature correlated with y as the last column</span>
    <span class="s1">X = pd.DataFrame(X</span><span class="s0">, </span><span class="s1">columns=dataset.feature_names)</span>
    <span class="s1">X[</span><span class="s2">&quot;correlated_feature&quot;</span><span class="s1">] = y_with_little_noise</span>

    <span class="s1">clf = RandomForestClassifier(n_estimators=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">result = permutation_importance(</span>
        <span class="s1">clf</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">n_repeats=n_repeats</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">n_jobs=n_jobs</span><span class="s0">,</span>
        <span class="s1">max_samples=max_samples</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">result.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>

    <span class="s4"># the correlated feature with y was added as the last column and should</span>
    <span class="s4"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np.all(result.importances_mean[-</span><span class="s3">1</span><span class="s1">] &gt; result.importances_mean[:-</span><span class="s3">1</span><span class="s1">])</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;n_jobs&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;max_samples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_robustness_to_high_cardinality_noisy_feature(n_jobs</span><span class="s0">, </span><span class="s1">max_samples</span><span class="s0">, </span><span class="s1">seed=</span><span class="s3">42</span><span class="s1">):</span>
    <span class="s4"># Permutation variable importance should not be affected by the high</span>
    <span class="s4"># cardinality bias of traditional feature importances, especially when</span>
    <span class="s4"># computed on a held-out test set:</span>
    <span class="s1">rng = np.random.RandomState(seed)</span>
    <span class="s1">n_repeats = </span><span class="s3">5</span>
    <span class="s1">n_samples = </span><span class="s3">1000</span>
    <span class="s1">n_classes = </span><span class="s3">5</span>
    <span class="s1">n_informative_features = </span><span class="s3">2</span>
    <span class="s1">n_noise_features = </span><span class="s3">1</span>
    <span class="s1">n_features = n_informative_features + n_noise_features</span>

    <span class="s4"># Generate a multiclass classification dataset and a set of informative</span>
    <span class="s4"># binary features that can be used to predict some classes of y exactly</span>
    <span class="s4"># while leaving some classes unexplained to make the problem harder.</span>
    <span class="s1">classes = np.arange(n_classes)</span>
    <span class="s1">y = rng.choice(classes</span><span class="s0">, </span><span class="s1">size=n_samples)</span>
    <span class="s1">X = np.hstack([(y == c).reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">) </span><span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">classes[:n_informative_features]])</span>
    <span class="s1">X = X.astype(np.float32)</span>

    <span class="s4"># Not all target classes are explained by the binary class indicator</span>
    <span class="s4"># features:</span>
    <span class="s0">assert </span><span class="s1">n_informative_features &lt; n_classes</span>

    <span class="s4"># Add 10 other noisy features with high cardinality (numerical) values</span>
    <span class="s4"># that can be used to overfit the training data.</span>
    <span class="s1">X = np.concatenate([X</span><span class="s0">, </span><span class="s1">rng.randn(n_samples</span><span class="s0">, </span><span class="s1">n_noise_features)]</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">X.shape == (n_samples</span><span class="s0">, </span><span class="s1">n_features)</span>

    <span class="s4"># Split the dataset to be able to evaluate on a held-out test set. The</span>
    <span class="s4"># Test size should be large enough for importance measurements to be</span>
    <span class="s4"># stable:</span>
    <span class="s1">X_train</span><span class="s0">, </span><span class="s1">X_test</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">test_size=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">random_state=rng</span>
    <span class="s1">)</span>
    <span class="s1">clf = RandomForestClassifier(n_estimators=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">clf.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

    <span class="s4"># Variable importances computed by impurity decrease on the tree node</span>
    <span class="s4"># splits often use the noisy features in splits. This can give misleading</span>
    <span class="s4"># impression that high cardinality noisy variables are the most important:</span>
    <span class="s1">tree_importances = clf.feature_importances_</span>
    <span class="s1">informative_tree_importances = tree_importances[:n_informative_features]</span>
    <span class="s1">noisy_tree_importances = tree_importances[n_informative_features:]</span>
    <span class="s0">assert </span><span class="s1">informative_tree_importances.max() &lt; noisy_tree_importances.min()</span>

    <span class="s4"># Let's check that permutation-based feature importances do not have this</span>
    <span class="s4"># problem.</span>
    <span class="s1">r = permutation_importance(</span>
        <span class="s1">clf</span><span class="s0">,</span>
        <span class="s1">X_test</span><span class="s0">,</span>
        <span class="s1">y_test</span><span class="s0">,</span>
        <span class="s1">n_repeats=n_repeats</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">n_jobs=n_jobs</span><span class="s0">,</span>
        <span class="s1">max_samples=max_samples</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">r.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>

    <span class="s4"># Split the importances between informative and noisy features</span>
    <span class="s1">informative_importances = r.importances_mean[:n_informative_features]</span>
    <span class="s1">noisy_importances = r.importances_mean[n_informative_features:]</span>

    <span class="s4"># Because we do not have a binary variable explaining each target classes,</span>
    <span class="s4"># the RF model will have to use the random variable to make some</span>
    <span class="s4"># (overfitting) splits (as max_depth is not set). Therefore the noisy</span>
    <span class="s4"># variables will be non-zero but with small values oscillating around</span>
    <span class="s4"># zero:</span>
    <span class="s0">assert </span><span class="s1">max(np.abs(noisy_importances)) &gt; </span><span class="s3">1e-7</span>
    <span class="s0">assert </span><span class="s1">noisy_importances.max() &lt; </span><span class="s3">0.05</span>

    <span class="s4"># The binary features correlated with y should have a higher importance</span>
    <span class="s4"># than the high cardinality noisy features.</span>
    <span class="s4"># The maximum test accuracy is 2 / 5 == 0.4, each informative feature</span>
    <span class="s4"># contributing approximately a bit more than 0.2 of accuracy.</span>
    <span class="s0">assert </span><span class="s1">informative_importances.min() &gt; </span><span class="s3">0.15</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_mixed_types():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_repeats = </span><span class="s3">4</span>

    <span class="s4"># Last column is correlated with y</span>
    <span class="s1">X = np.array([[</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s0">, </span><span class="s1">np.nan]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]]).T</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">clf = make_pipeline(SimpleImputer()</span><span class="s0">, </span><span class="s1">LogisticRegression(solver=</span><span class="s2">&quot;lbfgs&quot;</span><span class="s1">))</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">result = permutation_importance(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=n_repeats</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s0">assert </span><span class="s1">result.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>

    <span class="s4"># the correlated feature with y is the last column and should</span>
    <span class="s4"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np.all(result.importances_mean[-</span><span class="s3">1</span><span class="s1">] &gt; result.importances_mean[:-</span><span class="s3">1</span><span class="s1">])</span>

    <span class="s4"># use another random state</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">result2 = permutation_importance(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=n_repeats</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s0">assert </span><span class="s1">result2.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>

    <span class="s0">assert not </span><span class="s1">np.allclose(result.importances</span><span class="s0">, </span><span class="s1">result2.importances)</span>

    <span class="s4"># the correlated feature with y is the last column and should</span>
    <span class="s4"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np.all(result2.importances_mean[-</span><span class="s3">1</span><span class="s1">] &gt; result2.importances_mean[:-</span><span class="s3">1</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_mixed_types_pandas():</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s2">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">n_repeats = </span><span class="s3">5</span>

    <span class="s4"># Last column is correlated with y</span>
    <span class="s1">X = pd.DataFrame({</span><span class="s2">&quot;col1&quot;</span><span class="s1">: [</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s0">, </span><span class="s1">np.nan]</span><span class="s0">, </span><span class="s2">&quot;col2&quot;</span><span class="s1">: [</span><span class="s2">&quot;a&quot;</span><span class="s0">, </span><span class="s2">&quot;b&quot;</span><span class="s0">, </span><span class="s2">&quot;a&quot;</span><span class="s0">, </span><span class="s2">&quot;b&quot;</span><span class="s1">]})</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">num_preprocess = make_pipeline(SimpleImputer()</span><span class="s0">, </span><span class="s1">StandardScaler())</span>
    <span class="s1">preprocess = ColumnTransformer(</span>
        <span class="s1">[(</span><span class="s2">&quot;num&quot;</span><span class="s0">, </span><span class="s1">num_preprocess</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;col1&quot;</span><span class="s1">])</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;cat&quot;</span><span class="s0">, </span><span class="s1">OneHotEncoder()</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;col2&quot;</span><span class="s1">])]</span>
    <span class="s1">)</span>
    <span class="s1">clf = make_pipeline(preprocess</span><span class="s0">, </span><span class="s1">LogisticRegression(solver=</span><span class="s2">&quot;lbfgs&quot;</span><span class="s1">))</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">result = permutation_importance(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=n_repeats</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s0">assert </span><span class="s1">result.importances.shape == (X.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_repeats)</span>
    <span class="s4"># the correlated feature with y is the last column and should</span>
    <span class="s4"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np.all(result.importances_mean[-</span><span class="s3">1</span><span class="s1">] &gt; result.importances_mean[:-</span><span class="s3">1</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_linear_regresssion():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">500</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">X = scale(X)</span>
    <span class="s1">y = scale(y)</span>

    <span class="s1">lr = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s4"># this relationship can be computed in closed form</span>
    <span class="s1">expected_importances = </span><span class="s3">2 </span><span class="s1">* lr.coef_**</span><span class="s3">2</span>
    <span class="s1">results = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">50</span><span class="s0">, </span><span class="s1">scoring=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">expected_importances</span><span class="s0">, </span><span class="s1">results.importances_mean</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-1</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-6</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;max_samples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">500</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_equivalence_sequential_parallel(max_samples):</span>
    <span class="s4"># regression test to make sure that sequential and parallel calls will</span>
    <span class="s4"># output the same results.</span>
    <span class="s4"># Also tests that max_samples equal to number of samples is equivalent to 1.0</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">500</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">lr = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">importance_sequential = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">max_samples=max_samples</span>
    <span class="s1">)</span>

    <span class="s4"># First check that the problem is structured enough and that the model is</span>
    <span class="s4"># complex enough to not yield trivial, constant importances:</span>
    <span class="s1">imp_min = importance_sequential[</span><span class="s2">&quot;importances&quot;</span><span class="s1">].min()</span>
    <span class="s1">imp_max = importance_sequential[</span><span class="s2">&quot;importances&quot;</span><span class="s1">].max()</span>
    <span class="s0">assert </span><span class="s1">imp_max - imp_min &gt; </span><span class="s3">0.3</span>

    <span class="s4"># The actually check that parallelism does not impact the results</span>
    <span class="s4"># either with shared memory (threading) or without isolated memory</span>
    <span class="s4"># via process-based parallelism using the default backend</span>
    <span class="s4"># ('loky' or 'multiprocessing') depending on the joblib version:</span>

    <span class="s4"># process-based parallelism (by default):</span>
    <span class="s1">importance_processes = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s3">2</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">importance_processes[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">importance_sequential[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>

    <span class="s4"># thread-based parallelism:</span>
    <span class="s0">with </span><span class="s1">parallel_backend(</span><span class="s2">&quot;threading&quot;</span><span class="s1">):</span>
        <span class="s1">importance_threading = permutation_importance(</span>
            <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s3">2</span>
        <span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">importance_threading[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">importance_sequential[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;n_jobs&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">None, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;max_samples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_equivalence_array_dataframe(n_jobs</span><span class="s0">, </span><span class="s1">max_samples):</span>
    <span class="s4"># This test checks that the column shuffling logic has the same behavior</span>
    <span class="s4"># both a dataframe and a simple numpy array.</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s2">&quot;pandas&quot;</span><span class="s1">)</span>

    <span class="s4"># regression test to make sure that sequential and parallel calls will</span>
    <span class="s4"># output the same results.</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X_df = pd.DataFrame(X)</span>

    <span class="s4"># Add a categorical feature that is statistically linked to y:</span>
    <span class="s1">binner = KBinsDiscretizer(n_bins=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">encode=</span><span class="s2">&quot;ordinal&quot;</span><span class="s1">)</span>
    <span class="s1">cat_column = binner.fit_transform(y.reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>

    <span class="s4"># Concatenate the extra column to the numpy array: integers will be</span>
    <span class="s4"># cast to float values</span>
    <span class="s1">X = np.hstack([X</span><span class="s0">, </span><span class="s1">cat_column])</span>
    <span class="s0">assert </span><span class="s1">X.dtype.kind == </span><span class="s2">&quot;f&quot;</span>

    <span class="s4"># Insert extra column as a non-numpy-native dtype (while keeping backward</span>
    <span class="s4"># compat for old pandas versions):</span>
    <span class="s0">if </span><span class="s1">hasattr(pd</span><span class="s0">, </span><span class="s2">&quot;Categorical&quot;</span><span class="s1">):</span>
        <span class="s1">cat_column = pd.Categorical(cat_column.ravel())</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">cat_column = cat_column.ravel()</span>
    <span class="s1">new_col_idx = len(X_df.columns)</span>
    <span class="s1">X_df[new_col_idx] = cat_column</span>
    <span class="s0">assert </span><span class="s1">X_df[new_col_idx].dtype == cat_column.dtype</span>

    <span class="s4"># Stich an arbitrary index to the dataframe:</span>
    <span class="s1">X_df.index = np.arange(len(X_df)).astype(str)</span>

    <span class="s1">rf = RandomForestRegressor(n_estimators=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">max_depth=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">rf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">n_repeats = </span><span class="s3">3</span>
    <span class="s1">importance_array = permutation_importance(</span>
        <span class="s1">rf</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">n_repeats=n_repeats</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">,</span>
        <span class="s1">n_jobs=n_jobs</span><span class="s0">,</span>
        <span class="s1">max_samples=max_samples</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s4"># First check that the problem is structured enough and that the model is</span>
    <span class="s4"># complex enough to not yield trivial, constant importances:</span>
    <span class="s1">imp_min = importance_array[</span><span class="s2">&quot;importances&quot;</span><span class="s1">].min()</span>
    <span class="s1">imp_max = importance_array[</span><span class="s2">&quot;importances&quot;</span><span class="s1">].max()</span>
    <span class="s0">assert </span><span class="s1">imp_max - imp_min &gt; </span><span class="s3">0.3</span>

    <span class="s4"># Now check that importances computed on dataframe matche the values</span>
    <span class="s4"># of those computed on the array with the same data.</span>
    <span class="s1">importance_dataframe = permutation_importance(</span>
        <span class="s1">rf</span><span class="s0">,</span>
        <span class="s1">X_df</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">n_repeats=n_repeats</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">,</span>
        <span class="s1">n_jobs=n_jobs</span><span class="s0">,</span>
        <span class="s1">max_samples=max_samples</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">importance_array[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">importance_dataframe[</span><span class="s2">&quot;importances&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;input_type&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;array&quot;</span><span class="s0">, </span><span class="s2">&quot;dataframe&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_large_memmaped_data(input_type):</span>
    <span class="s4"># Smoke, non-regression test for:</span>
    <span class="s4"># https://github.com/scikit-learn/scikit-learn/issues/15810</span>
    <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features = int(</span><span class="s3">5e4</span><span class="s1">)</span><span class="s0">, </span><span class="s3">4</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(</span>
        <span class="s1">n_samples=n_samples</span><span class="s0">, </span><span class="s1">n_features=n_features</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">X.nbytes &gt; </span><span class="s3">1e6  </span><span class="s4"># trigger joblib memmaping</span>

    <span class="s1">X = _convert_container(X</span><span class="s0">, </span><span class="s1">input_type)</span>
    <span class="s1">clf = DummyClassifier(strategy=</span><span class="s2">&quot;prior&quot;</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s4"># Actual smoke test: should not raise any error:</span>
    <span class="s1">n_repeats = </span><span class="s3">5</span>
    <span class="s1">r = permutation_importance(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">n_repeats=n_repeats</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s3">2</span><span class="s1">)</span>

    <span class="s4"># Auxiliary check: DummyClassifier is feature independent:</span>
    <span class="s4"># permutating feature should not change the predictions</span>
    <span class="s1">expected_importances = np.zeros((n_features</span><span class="s0">, </span><span class="s1">n_repeats))</span>
    <span class="s1">assert_allclose(expected_importances</span><span class="s0">, </span><span class="s1">r.importances)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_sample_weight():</span>
    <span class="s4"># Creating data with 2 features and 1000 samples, where the target</span>
    <span class="s4"># variable is a linear combination of the two features, such that</span>
    <span class="s4"># in half of the samples the impact of feature 1 is twice the impact of</span>
    <span class="s4"># feature 2, and vice versa on the other half of the samples.</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">n_samples = </span><span class="s3">1000</span>
    <span class="s1">n_features = </span><span class="s3">2</span>
    <span class="s1">n_half_samples = n_samples // </span><span class="s3">2</span>
    <span class="s1">x = rng.normal(</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">0.001</span><span class="s0">, </span><span class="s1">(n_samples</span><span class="s0">, </span><span class="s1">n_features))</span>
    <span class="s1">y = np.zeros(n_samples)</span>
    <span class="s1">y[:n_half_samples] = </span><span class="s3">2 </span><span class="s1">* x[:n_half_samples</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] + x[:n_half_samples</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">y[n_half_samples:] = x[n_half_samples:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] + </span><span class="s3">2 </span><span class="s1">* x[n_half_samples:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>

    <span class="s4"># Fitting linear regression with perfect prediction</span>
    <span class="s1">lr = LinearRegression(fit_intercept=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">lr.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s4"># When all samples are weighted with the same weights, the ratio of</span>
    <span class="s4"># the two features importance should equal to 1 on expectation (when using</span>
    <span class="s4"># mean absolutes error as the loss function).</span>
    <span class="s1">pi = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scoring=</span><span class="s2">&quot;neg_mean_absolute_error&quot;</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">200</span>
    <span class="s1">)</span>
    <span class="s1">x1_x2_imp_ratio_w_none = pi.importances_mean[</span><span class="s3">0</span><span class="s1">] / pi.importances_mean[</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w_none == pytest.approx(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.01</span><span class="s1">)</span>

    <span class="s4"># When passing a vector of ones as the sample_weight, results should be</span>
    <span class="s4"># the same as in the case that sample_weight=None.</span>
    <span class="s1">w = np.ones(n_samples)</span>
    <span class="s1">pi = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">1</span><span class="s0">,</span>
        <span class="s1">scoring=</span><span class="s2">&quot;neg_mean_absolute_error&quot;</span><span class="s0">,</span>
        <span class="s1">n_repeats=</span><span class="s3">200</span><span class="s0">,</span>
        <span class="s1">sample_weight=w</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">x1_x2_imp_ratio_w_ones = pi.importances_mean[</span><span class="s3">0</span><span class="s1">] / pi.importances_mean[</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w_ones == pytest.approx(x1_x2_imp_ratio_w_none</span><span class="s0">, </span><span class="s3">0.01</span><span class="s1">)</span>

    <span class="s4"># When the ratio between the weights of the first half of the samples and</span>
    <span class="s4"># the second half of the samples approaches to infinity, the ratio of</span>
    <span class="s4"># the two features importance should equal to 2 on expectation (when using</span>
    <span class="s4"># mean absolutes error as the loss function).</span>
    <span class="s1">w = np.hstack(</span>
        <span class="s1">[np.repeat(</span><span class="s3">10.0</span><span class="s1">**</span><span class="s3">10</span><span class="s0">, </span><span class="s1">n_half_samples)</span><span class="s0">, </span><span class="s1">np.repeat(</span><span class="s3">1.0</span><span class="s0">, </span><span class="s1">n_half_samples)]</span>
    <span class="s1">)</span>
    <span class="s1">lr.fit(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">w)</span>
    <span class="s1">pi = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">1</span><span class="s0">,</span>
        <span class="s1">scoring=</span><span class="s2">&quot;neg_mean_absolute_error&quot;</span><span class="s0">,</span>
        <span class="s1">n_repeats=</span><span class="s3">200</span><span class="s0">,</span>
        <span class="s1">sample_weight=w</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">x1_x2_imp_ratio_w = pi.importances_mean[</span><span class="s3">0</span><span class="s1">] / pi.importances_mean[</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w / x1_x2_imp_ratio_w_none == pytest.approx(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0.01</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_no_weights_scoring_function():</span>
    <span class="s4"># Creating a scorer function that does not takes sample_weight</span>
    <span class="s0">def </span><span class="s1">my_scorer(estimator</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s0">return </span><span class="s3">1</span>

    <span class="s4"># Creating some data and estimator for the permutation test</span>
    <span class="s1">x = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]])</span>
    <span class="s1">y = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s1">w = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">lr = LinearRegression()</span>
    <span class="s1">lr.fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s4"># test that permutation_importance does not return error when</span>
    <span class="s4"># sample_weight is None</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">permutation_importance(lr</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scoring=my_scorer</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">except </span><span class="s1">TypeError:</span>
        <span class="s1">pytest.fail(</span>
            <span class="s2">&quot;permutation_test raised an error when using a scorer &quot;</span>
            <span class="s2">&quot;function that does not accept sample_weight even though &quot;</span>
            <span class="s2">&quot;sample_weight was None&quot;</span>
        <span class="s1">)</span>

    <span class="s4"># test that permutation_importance raise exception when sample_weight is</span>
    <span class="s4"># not None</span>
    <span class="s0">with </span><span class="s1">pytest.raises(TypeError):</span>
        <span class="s1">permutation_importance(</span>
            <span class="s1">lr</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scoring=my_scorer</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">sample_weight=w</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;list_single_scorer, multi_scorer&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s2">&quot;r2&quot;</span><span class="s0">, </span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;r2&quot;</span><span class="s0">, </span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s2">&quot;r2&quot;</span><span class="s0">, </span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">{</span>
                <span class="s2">&quot;r2&quot;</span><span class="s1">: get_scorer(</span><span class="s2">&quot;r2&quot;</span><span class="s1">)</span><span class="s0">,</span>
                <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">: get_scorer(</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">)</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s2">&quot;r2&quot;</span><span class="s0">, </span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">lambda </span><span class="s1">estimator</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y: {</span>
                <span class="s2">&quot;r2&quot;</span><span class="s1">: r2_score(y</span><span class="s0">, </span><span class="s1">estimator.predict(X))</span><span class="s0">,</span>
                <span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="s1">: -mean_squared_error(y</span><span class="s0">, </span><span class="s1">estimator.predict(X))</span><span class="s0">,</span>
            <span class="s1">}</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_multi_metric(list_single_scorer</span><span class="s0">, </span><span class="s1">multi_scorer):</span>
    <span class="s4"># Test permutation importance when scoring contains multiple scorers</span>

    <span class="s4"># Creating some data and estimator for the permutation test</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">y = make_regression(n_samples=</span><span class="s3">500</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">lr = LinearRegression().fit(x</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">multi_importance = permutation_importance(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scoring=multi_scorer</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">2</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">set(multi_importance.keys()) == set(list_single_scorer)</span>

    <span class="s0">for </span><span class="s1">scorer </span><span class="s0">in </span><span class="s1">list_single_scorer:</span>
        <span class="s1">multi_result = multi_importance[scorer]</span>
        <span class="s1">single_result = permutation_importance(</span>
            <span class="s1">lr</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scoring=scorer</span><span class="s0">, </span><span class="s1">n_repeats=</span><span class="s3">2</span>
        <span class="s1">)</span>

        <span class="s1">assert_allclose(multi_result.importances</span><span class="s0">, </span><span class="s1">single_result.importances)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_max_samples_error():</span>
    <span class="s5">&quot;&quot;&quot;Check that a proper error message is raised when `max_samples` is not 
    set to a valid input value. 
    &quot;&quot;&quot;</span>
    <span class="s1">X = np.array([(</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">3.0</span><span class="s0">, </span><span class="s3">4.0</span><span class="s1">)]).T</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">clf = LogisticRegression()</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">err_msg = </span><span class="s2">r&quot;max_samples must be &lt;= n_samples&quot;</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">permutation_importance(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">max_samples=</span><span class="s3">5</span><span class="s1">)</span>
</pre>
</body>
</html>
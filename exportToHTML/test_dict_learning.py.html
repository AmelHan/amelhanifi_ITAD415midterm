<html>
<head>
<title>test_dict_learning.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_dict_learning.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">itertools</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">import </span><span class="s1">sklearn</span>
<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">clone</span>
<span class="s0">from </span><span class="s1">sklearn.decomposition </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">DictionaryLearning</span><span class="s0">,</span>
    <span class="s1">MiniBatchDictionaryLearning</span><span class="s0">,</span>
    <span class="s1">SparseCoder</span><span class="s0">,</span>
    <span class="s1">dict_learning</span><span class="s0">,</span>
    <span class="s1">dict_learning_online</span><span class="s0">,</span>
    <span class="s1">sparse_encode</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.decomposition._dict_learning </span><span class="s0">import </span><span class="s1">_update_dict</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">check_array</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">TempMemmap</span><span class="s0">,</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
    <span class="s1">ignore_warnings</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils.estimator_checks </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">check_transformer_data_not_an_array</span><span class="s0">,</span>
    <span class="s1">check_transformer_general</span><span class="s0">,</span>
    <span class="s1">check_transformers_unfitted</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils.parallel </span><span class="s0">import </span><span class="s1">Parallel</span>

<span class="s1">rng_global = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
<span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features = </span><span class="s2">10</span><span class="s0">, </span><span class="s2">8</span>
<span class="s1">X = rng_global.randn(n_samples</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_sparse_encode_shapes_omp():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">algorithms = [</span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s1">]</span>
    <span class="s0">for </span><span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_samples </span><span class="s0">in </span><span class="s1">itertools.product([</span><span class="s2">1</span><span class="s0">, </span><span class="s2">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">9</span><span class="s1">]):</span>
        <span class="s1">X_ = rng.randn(n_samples</span><span class="s0">, </span><span class="s1">n_features)</span>
        <span class="s1">dictionary = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
        <span class="s0">for </span><span class="s1">algorithm</span><span class="s0">, </span><span class="s1">n_jobs </span><span class="s0">in </span><span class="s1">itertools.product(algorithms</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]):</span>
            <span class="s1">code = sparse_encode(X_</span><span class="s0">, </span><span class="s1">dictionary</span><span class="s0">, </span><span class="s1">algorithm=algorithm</span><span class="s0">, </span><span class="s1">n_jobs=n_jobs)</span>
            <span class="s0">assert </span><span class="s1">code.shape == (n_samples</span><span class="s0">, </span><span class="s1">n_components)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_shapes():</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = DictionaryLearning(n_components</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span><span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>

    <span class="s1">n_components = </span><span class="s2">1</span>
    <span class="s1">dico = DictionaryLearning(n_components</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span><span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s0">assert </span><span class="s1">dico.transform(X).shape == (X.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_components)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_overcomplete():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">dico = DictionaryLearning(n_components</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span><span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_max_iter():</span>
    <span class="s0">def </span><span class="s1">ricker_function(resolution</span><span class="s0">, </span><span class="s1">center</span><span class="s0">, </span><span class="s1">width):</span>
        <span class="s4">&quot;&quot;&quot;Discrete sub-sampled Ricker (Mexican hat) wavelet&quot;&quot;&quot;</span>
        <span class="s1">x = np.linspace(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">resolution - </span><span class="s2">1</span><span class="s0">, </span><span class="s1">resolution)</span>
        <span class="s1">x = (</span>
            <span class="s1">(</span><span class="s2">2 </span><span class="s1">/ (np.sqrt(</span><span class="s2">3 </span><span class="s1">* width) * np.pi**</span><span class="s2">0.25</span><span class="s1">))</span>
            <span class="s1">* (</span><span class="s2">1 </span><span class="s1">- (x - center) ** </span><span class="s2">2 </span><span class="s1">/ width**</span><span class="s2">2</span><span class="s1">)</span>
            <span class="s1">* np.exp(-((x - center) ** </span><span class="s2">2</span><span class="s1">) / (</span><span class="s2">2 </span><span class="s1">* width**</span><span class="s2">2</span><span class="s1">))</span>
        <span class="s1">)</span>
        <span class="s0">return </span><span class="s1">x</span>

    <span class="s0">def </span><span class="s1">ricker_matrix(width</span><span class="s0">, </span><span class="s1">resolution</span><span class="s0">, </span><span class="s1">n_components):</span>
        <span class="s4">&quot;&quot;&quot;Dictionary of Ricker (Mexican hat) wavelets&quot;&quot;&quot;</span>
        <span class="s1">centers = np.linspace(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">resolution - </span><span class="s2">1</span><span class="s0">, </span><span class="s1">n_components)</span>
        <span class="s1">D = np.empty((n_components</span><span class="s0">, </span><span class="s1">resolution))</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">center </span><span class="s0">in </span><span class="s1">enumerate(centers):</span>
            <span class="s1">D[i] = ricker_function(resolution</span><span class="s0">, </span><span class="s1">center</span><span class="s0">, </span><span class="s1">width)</span>
        <span class="s1">D /= np.sqrt(np.sum(D**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">))[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
        <span class="s0">return </span><span class="s1">D</span>

    <span class="s1">transform_algorithm = </span><span class="s3">&quot;lasso_cd&quot;</span>
    <span class="s1">resolution = </span><span class="s2">1024</span>
    <span class="s1">subsampling = </span><span class="s2">3  </span><span class="s5"># subsampling factor</span>
    <span class="s1">n_components = resolution // subsampling</span>

    <span class="s5"># Compute a wavelet dictionary</span>
    <span class="s1">D_multi = np.r_[</span>
        <span class="s1">tuple(</span>
            <span class="s1">ricker_matrix(</span>
                <span class="s1">width=w</span><span class="s0">, </span><span class="s1">resolution=resolution</span><span class="s0">, </span><span class="s1">n_components=n_components // </span><span class="s2">5</span>
            <span class="s1">)</span>
            <span class="s0">for </span><span class="s1">w </span><span class="s0">in </span><span class="s1">(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">50</span><span class="s0">, </span><span class="s2">100</span><span class="s0">, </span><span class="s2">500</span><span class="s0">, </span><span class="s2">1000</span><span class="s1">)</span>
        <span class="s1">)</span>
    <span class="s1">]</span>

    <span class="s1">X = np.linspace(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">resolution - </span><span class="s2">1</span><span class="s0">, </span><span class="s1">resolution)</span>
    <span class="s1">first_quarter = X &lt; resolution / </span><span class="s2">4</span>
    <span class="s1">X[first_quarter] = </span><span class="s2">3.0</span>
    <span class="s1">X[np.logical_not(first_quarter)] = -</span><span class="s2">1.0</span>
    <span class="s1">X = X.reshape(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">)</span>

    <span class="s5"># check that the underlying model fails to converge</span>
    <span class="s0">with </span><span class="s1">pytest.warns(ConvergenceWarning):</span>
        <span class="s1">model = SparseCoder(</span>
            <span class="s1">D_multi</span><span class="s0">, </span><span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">, </span><span class="s1">transform_max_iter=</span><span class="s2">1</span>
        <span class="s1">)</span>
        <span class="s1">model.fit_transform(X)</span>

    <span class="s5"># check that the underlying model converges w/o warnings</span>
    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;error&quot;</span><span class="s0">, </span><span class="s1">ConvergenceWarning)</span>
        <span class="s1">model = SparseCoder(</span>
            <span class="s1">D_multi</span><span class="s0">, </span><span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">, </span><span class="s1">transform_max_iter=</span><span class="s2">2000</span>
        <span class="s1">)</span>
        <span class="s1">model.fit_transform(X)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_lars_positive_parameter():</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">alpha = </span><span class="s2">1</span>
    <span class="s1">err_msg = </span><span class="s3">&quot;Positive constraint not supported for 'lars' coding method.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">dict_learning(X</span><span class="s0">, </span><span class="s1">n_components</span><span class="s0">, </span><span class="s1">alpha=alpha</span><span class="s0">, </span><span class="s1">positive_code=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;transform_algorithm&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s3">&quot;lasso_lars&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;lasso_cd&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;threshold&quot;</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_code&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_dict&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_dict_learning_positivity(transform_algorithm</span><span class="s0">, </span><span class="s1">positive_code</span><span class="s0">, </span><span class="s1">positive_dict):</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">positive_code=positive_code</span><span class="s0">,</span>
        <span class="s1">positive_dict=positive_dict</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s1">code = dico.transform(X)</span>
    <span class="s0">if </span><span class="s1">positive_dict:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &lt; </span><span class="s2">0</span><span class="s1">).any()</span>
    <span class="s0">if </span><span class="s1">positive_code:</span>
        <span class="s0">assert </span><span class="s1">(code &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(code &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_dict&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_dict_learning_lars_dict_positivity(positive_dict):</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=</span><span class="s3">&quot;lars&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">positive_dict=positive_dict</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s0">if </span><span class="s1">positive_dict:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s0">def </span><span class="s1">test_dict_learning_lars_code_positivity():</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=</span><span class="s3">&quot;lars&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">positive_code=</span><span class="s0">True,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s1">err_msg = </span><span class="s3">&quot;Positive constraint not supported for '{}' coding method.&quot;</span>
    <span class="s1">err_msg = err_msg.format(</span><span class="s3">&quot;lars&quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">dico.transform(X)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_reconstruction():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">transform_algorithm=</span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s1">transform_alpha=</span><span class="s2">0.001</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">)</span>
    <span class="s1">code = dico.fit(X).transform(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(code</span><span class="s0">, </span><span class="s1">dico.components_)</span><span class="s0">, </span><span class="s1">X)</span>

    <span class="s1">dico.set_params(transform_algorithm=</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s1">)</span>
    <span class="s1">code = dico.transform(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(code</span><span class="s0">, </span><span class="s1">dico.components_)</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>

    <span class="s5"># used to test lars here too, but there's no guarantee the number of</span>
    <span class="s5"># nonzero atoms is right.</span>


<span class="s0">def </span><span class="s1">test_dict_learning_reconstruction_parallel():</span>
    <span class="s5"># regression test that parallel reconstruction works with n_jobs&gt;1</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=</span><span class="s3">&quot;omp&quot;</span><span class="s0">,</span>
        <span class="s1">transform_alpha=</span><span class="s2">0.001</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">n_jobs=</span><span class="s2">4</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">code = dico.fit(X).transform(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(code</span><span class="s0">, </span><span class="s1">dico.components_)</span><span class="s0">, </span><span class="s1">X)</span>

    <span class="s1">dico.set_params(transform_algorithm=</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s1">)</span>
    <span class="s1">code = dico.transform(X)</span>
    <span class="s1">assert_array_almost_equal(np.dot(code</span><span class="s0">, </span><span class="s1">dico.components_)</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_lassocd_readonly_data():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s0">with </span><span class="s1">TempMemmap(X) </span><span class="s0">as </span><span class="s1">X_read_only:</span>
        <span class="s1">dico = DictionaryLearning(</span>
            <span class="s1">n_components</span><span class="s0">,</span>
            <span class="s1">transform_algorithm=</span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">,</span>
            <span class="s1">transform_alpha=</span><span class="s2">0.001</span><span class="s0">,</span>
            <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
            <span class="s1">n_jobs=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
            <span class="s1">code = dico.fit(X_read_only).transform(X_read_only)</span>
        <span class="s1">assert_array_almost_equal(</span>
            <span class="s1">np.dot(code</span><span class="s0">, </span><span class="s1">dico.components_)</span><span class="s0">, </span><span class="s1">X_read_only</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_nonzero_coefs():</span>
    <span class="s1">n_components = </span><span class="s2">4</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=</span><span class="s3">&quot;lars&quot;</span><span class="s0">,</span>
        <span class="s1">transform_n_nonzero_coefs=</span><span class="s2">3</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">code = dico.fit(X).transform(X[np.newaxis</span><span class="s0">, </span><span class="s2">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">len(np.flatnonzero(code)) == </span><span class="s2">3</span>

    <span class="s1">dico.set_params(transform_algorithm=</span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
    <span class="s1">code = dico.transform(X[np.newaxis</span><span class="s0">, </span><span class="s2">1</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">len(np.flatnonzero(code)) == </span><span class="s2">3</span>


<span class="s0">def </span><span class="s1">test_dict_learning_split():</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = DictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">transform_algorithm=</span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">)</span>
    <span class="s1">code = dico.fit(X).transform(X)</span>
    <span class="s1">dico.split_sign = </span><span class="s0">True</span>
    <span class="s1">split_code = dico.transform(X)</span>

    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">split_code[:</span><span class="s0">, </span><span class="s1">:n_components] - split_code[:</span><span class="s0">, </span><span class="s1">n_components:]</span><span class="s0">, </span><span class="s1">code</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_shapes():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">n_components = </span><span class="s2">8</span>

    <span class="s1">code</span><span class="s0">, </span><span class="s1">dictionary = dict_learning_online(</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">return_code=</span><span class="s0">True,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">code.shape == (n_samples</span><span class="s0">, </span><span class="s1">n_components)</span>
    <span class="s0">assert </span><span class="s1">dictionary.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s0">assert </span><span class="s1">np.dot(code</span><span class="s0">, </span><span class="s1">dictionary).shape == X.shape</span>

    <span class="s1">dictionary = dict_learning_online(</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">return_code=</span><span class="s0">False,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">dictionary.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_lars_positive_parameter():</span>
    <span class="s1">err_msg = </span><span class="s3">&quot;Positive constraint not supported for 'lars' coding method.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">dict_learning_online(X</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">, </span><span class="s1">positive_code=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;transform_algorithm&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s3">&quot;lasso_lars&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;lasso_cd&quot;</span><span class="s0">,</span>
        <span class="s3">&quot;threshold&quot;</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_code&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_dict&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_minibatch_dictionary_learning_positivity(</span>
    <span class="s1">transform_algorithm</span><span class="s0">, </span><span class="s1">positive_code</span><span class="s0">, </span><span class="s1">positive_dict</span>
<span class="s1">):</span>
    <span class="s1">n_components = </span><span class="s2">8</span>
    <span class="s1">dico = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">positive_code=positive_code</span><span class="s0">,</span>
        <span class="s1">positive_dict=positive_dict</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s1">code = dico.transform(X)</span>
    <span class="s0">if </span><span class="s1">positive_dict:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &lt; </span><span class="s2">0</span><span class="s1">).any()</span>
    <span class="s0">if </span><span class="s1">positive_code:</span>
        <span class="s0">assert </span><span class="s1">(code &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(code &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_dict&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_minibatch_dictionary_learning_lars(positive_dict):</span>
    <span class="s1">n_components = </span><span class="s2">8</span>

    <span class="s1">dico = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=</span><span class="s3">&quot;lars&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">positive_dict=positive_dict</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s0">if </span><span class="s1">positive_dict:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(dico.components_ &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_code&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive_dict&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_dict_learning_online_positivity(positive_code</span><span class="s0">, </span><span class="s1">positive_dict):</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">n_components = </span><span class="s2">8</span>

    <span class="s1">code</span><span class="s0">, </span><span class="s1">dictionary = dict_learning_online(</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
        <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">positive_dict=positive_dict</span><span class="s0">,</span>
        <span class="s1">positive_code=positive_code</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">positive_dict:</span>
        <span class="s0">assert </span><span class="s1">(dictionary &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(dictionary &lt; </span><span class="s2">0</span><span class="s1">).any()</span>
    <span class="s0">if </span><span class="s1">positive_code:</span>
        <span class="s0">assert </span><span class="s1">(code &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(code &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_verbosity():</span>
    <span class="s5"># test verbosity for better coverage</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s0">import </span><span class="s1">sys</span>
    <span class="s0">from </span><span class="s1">io </span><span class="s0">import </span><span class="s1">StringIO</span>

    <span class="s1">old_stdout = sys.stdout</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">sys.stdout = StringIO()</span>

        <span class="s5"># convergence monitoring verbosity</span>
        <span class="s1">dico = MiniBatchDictionaryLearning(</span>
            <span class="s1">n_components</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">verbose=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">tol=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
        <span class="s1">)</span>
        <span class="s1">dico.fit(X)</span>
        <span class="s1">dico = MiniBatchDictionaryLearning(</span>
            <span class="s1">n_components</span><span class="s0">,</span>
            <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
            <span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">,</span>
            <span class="s1">verbose=</span><span class="s2">1</span><span class="s0">,</span>
            <span class="s1">max_no_improvement=</span><span class="s2">2</span><span class="s0">,</span>
            <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">dico.fit(X)</span>
        <span class="s5"># higher verbosity level</span>
        <span class="s1">dico = MiniBatchDictionaryLearning(</span>
            <span class="s1">n_components</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">verbose=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
        <span class="s1">)</span>
        <span class="s1">dico.fit(X)</span>

        <span class="s5"># function API verbosity</span>
        <span class="s1">dict_learning_online(</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">n_components=n_components</span><span class="s0">,</span>
            <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
            <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
            <span class="s1">verbose=</span><span class="s2">1</span><span class="s0">,</span>
            <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">dict_learning_online(</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">n_components=n_components</span><span class="s0">,</span>
            <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
            <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
            <span class="s1">verbose=</span><span class="s2">2</span><span class="s0">,</span>
            <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">finally</span><span class="s1">:</span>
        <span class="s1">sys.stdout = old_stdout</span>

    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_estimator_shapes():</span>
    <span class="s1">n_components = </span><span class="s2">5</span>
    <span class="s1">dico = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">)</span>
    <span class="s1">dico.fit(X)</span>
    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_overcomplete():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">dico = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">dico.components_.shape == (n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_initialization():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">dico = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">dict_init=V</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">).fit(X)</span>
    <span class="s1">assert_array_equal(dico.components_</span><span class="s0">, </span><span class="s1">V)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_readonly_initialization():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">V.setflags(write=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">dict_init=V</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">shuffle=</span><span class="s0">False,</span>
    <span class="s1">).fit(X)</span>


<span class="s0">def </span><span class="s1">test_dict_learning_online_partial_fit():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">dict1 = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">shuffle=</span><span class="s0">False,</span>
        <span class="s1">dict_init=V</span><span class="s0">,</span>
        <span class="s1">max_no_improvement=</span><span class="s0">None,</span>
        <span class="s1">tol=</span><span class="s2">0.0</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
    <span class="s1">).fit(X)</span>
    <span class="s1">dict2 = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">dict_init=V</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">10</span><span class="s1">):</span>
        <span class="s0">for </span><span class="s1">sample </span><span class="s0">in </span><span class="s1">X:</span>
            <span class="s1">dict2.partial_fit(sample[np.newaxis</span><span class="s0">, </span><span class="s1">:])</span>

    <span class="s0">assert not </span><span class="s1">np.all(sparse_encode(X</span><span class="s0">, </span><span class="s1">dict1.components_</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">1</span><span class="s1">) == </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(dict1.components_</span><span class="s0">, </span><span class="s1">dict2.components_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>

    <span class="s5"># partial_fit should ignore max_iter (#17433)</span>
    <span class="s0">assert </span><span class="s1">dict1.n_steps_ == dict2.n_steps_ == </span><span class="s2">100</span>


<span class="s0">def </span><span class="s1">test_sparse_encode_shapes():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s0">for </span><span class="s1">algo </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s1">):</span>
        <span class="s1">code = sparse_encode(X</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">algorithm=algo)</span>
        <span class="s0">assert </span><span class="s1">code.shape == (n_samples</span><span class="s0">, </span><span class="s1">n_components)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;algo&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;positive&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_sparse_encode_positivity(algo</span><span class="s0">, </span><span class="s1">positive):</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">code = sparse_encode(X</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">algorithm=algo</span><span class="s0">, </span><span class="s1">positive=positive)</span>
    <span class="s0">if </span><span class="s1">positive:</span>
        <span class="s0">assert </span><span class="s1">(code &gt;= </span><span class="s2">0</span><span class="s1">).all()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">(code &lt; </span><span class="s2">0</span><span class="s1">).any()</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;algo&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_sparse_encode_unavailable_positivity(algo):</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">err_msg = </span><span class="s3">&quot;Positive constraint not supported for '{}' coding method.&quot;</span>
    <span class="s1">err_msg = err_msg.format(algo)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">sparse_encode(X</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">algorithm=algo</span><span class="s0">, </span><span class="s1">positive=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sparse_encode_input():</span>
    <span class="s1">n_components = </span><span class="s2">100</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">Xf = check_array(X</span><span class="s0">, </span><span class="s1">order=</span><span class="s3">&quot;F&quot;</span><span class="s1">)</span>
    <span class="s0">for </span><span class="s1">algo </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s1">):</span>
        <span class="s1">a = sparse_encode(X</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">algorithm=algo)</span>
        <span class="s1">b = sparse_encode(Xf</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">algorithm=algo)</span>
        <span class="s1">assert_array_almost_equal(a</span><span class="s0">, </span><span class="s1">b)</span>


<span class="s0">def </span><span class="s1">test_sparse_encode_error():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">code = sparse_encode(X</span><span class="s0">, </span><span class="s1">V</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0.001</span><span class="s1">)</span>
    <span class="s0">assert not </span><span class="s1">np.all(code == </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.sqrt(np.sum((np.dot(code</span><span class="s0">, </span><span class="s1">V) - X) ** </span><span class="s2">2</span><span class="s1">)) &lt; </span><span class="s2">0.1</span>


<span class="s0">def </span><span class="s1">test_sparse_encode_error_default_sparsity():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">X = rng.randn(</span><span class="s2">100</span><span class="s0">, </span><span class="s2">64</span><span class="s1">)</span>
    <span class="s1">D = rng.randn(</span><span class="s2">2</span><span class="s0">, </span><span class="s2">64</span><span class="s1">)</span>
    <span class="s1">code = ignore_warnings(sparse_encode)(X</span><span class="s0">, </span><span class="s1">D</span><span class="s0">, </span><span class="s1">algorithm=</span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s1">n_nonzero_coefs=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">code.shape == (</span><span class="s2">100</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sparse_coder_estimator():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">coder = SparseCoder(</span>
        <span class="s1">dictionary=V</span><span class="s0">, </span><span class="s1">transform_algorithm=</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s1">transform_alpha=</span><span class="s2">0.001</span>
    <span class="s1">).transform(X)</span>
    <span class="s0">assert not </span><span class="s1">np.all(coder == </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.sqrt(np.sum((np.dot(coder</span><span class="s0">, </span><span class="s1">V) - X) ** </span><span class="s2">2</span><span class="s1">)) &lt; </span><span class="s2">0.1</span>


<span class="s0">def </span><span class="s1">test_sparse_coder_estimator_clone():</span>
    <span class="s1">n_components = </span><span class="s2">12</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)  </span><span class="s5"># random init</span>
    <span class="s1">V /= np.sum(V**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, </span><span class="s1">np.newaxis]</span>
    <span class="s1">coder = SparseCoder(</span>
        <span class="s1">dictionary=V</span><span class="s0">, </span><span class="s1">transform_algorithm=</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s1">transform_alpha=</span><span class="s2">0.001</span>
    <span class="s1">)</span>
    <span class="s1">cloned = clone(coder)</span>
    <span class="s0">assert </span><span class="s1">id(cloned) != id(coder)</span>
    <span class="s1">np.testing.assert_allclose(cloned.dictionary</span><span class="s0">, </span><span class="s1">coder.dictionary)</span>
    <span class="s0">assert </span><span class="s1">id(cloned.dictionary) != id(coder.dictionary)</span>
    <span class="s0">assert </span><span class="s1">cloned.n_components_ == coder.n_components_</span>
    <span class="s0">assert </span><span class="s1">cloned.n_features_in_ == coder.n_features_in_</span>
    <span class="s1">data = np.random.rand(n_samples</span><span class="s0">, </span><span class="s1">n_features).astype(np.float32)</span>
    <span class="s1">np.testing.assert_allclose(cloned.transform(data)</span><span class="s0">, </span><span class="s1">coder.transform(data))</span>


<span class="s0">def </span><span class="s1">test_sparse_coder_parallel_mmap():</span>
    <span class="s5"># Non-regression test for:</span>
    <span class="s5"># https://github.com/scikit-learn/scikit-learn/issues/5956</span>
    <span class="s5"># Test that SparseCoder does not error by passing reading only</span>
    <span class="s5"># arrays to child processes</span>

    <span class="s1">rng = np.random.RandomState(</span><span class="s2">777</span><span class="s1">)</span>
    <span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features = </span><span class="s2">40</span><span class="s0">, </span><span class="s2">64</span>
    <span class="s1">init_dict = rng.rand(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s5"># Ensure that `data` is &gt;2M. Joblib memory maps arrays</span>
    <span class="s5"># if they are larger than 1MB. The 4 accounts for float32</span>
    <span class="s5"># data type</span>
    <span class="s1">n_samples = int(</span><span class="s2">2e6</span><span class="s1">) // (</span><span class="s2">4 </span><span class="s1">* n_features)</span>
    <span class="s1">data = np.random.rand(n_samples</span><span class="s0">, </span><span class="s1">n_features).astype(np.float32)</span>

    <span class="s1">sc = SparseCoder(init_dict</span><span class="s0">, </span><span class="s1">transform_algorithm=</span><span class="s3">&quot;omp&quot;</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">sc.fit_transform(data)</span>


<span class="s0">def </span><span class="s1">test_sparse_coder_common_transformer():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">777</span><span class="s1">)</span>
    <span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features = </span><span class="s2">40</span><span class="s0">, </span><span class="s2">3</span>
    <span class="s1">init_dict = rng.rand(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>

    <span class="s1">sc = SparseCoder(init_dict)</span>

    <span class="s1">check_transformer_data_not_an_array(sc.__class__.__name__</span><span class="s0">, </span><span class="s1">sc)</span>
    <span class="s1">check_transformer_general(sc.__class__.__name__</span><span class="s0">, </span><span class="s1">sc)</span>
    <span class="s1">check_transformer_general_memmap = partial(</span>
        <span class="s1">check_transformer_general</span><span class="s0">, </span><span class="s1">readonly_memmap=</span><span class="s0">True</span>
    <span class="s1">)</span>
    <span class="s1">check_transformer_general_memmap(sc.__class__.__name__</span><span class="s0">, </span><span class="s1">sc)</span>
    <span class="s1">check_transformers_unfitted(sc.__class__.__name__</span><span class="s0">, </span><span class="s1">sc)</span>


<span class="s0">def </span><span class="s1">test_sparse_coder_n_features_in():</span>
    <span class="s1">d = np.array([[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]])</span>
    <span class="s1">sc = SparseCoder(d)</span>
    <span class="s0">assert </span><span class="s1">sc.n_features_in_ == d.shape[</span><span class="s2">1</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">test_minibatch_dict_learning_n_iter_deprecated():</span>
    <span class="s5"># check the deprecation warning of n_iter</span>
    <span class="s5"># TODO(1.4) remove</span>
    <span class="s1">depr_msg = (</span>
        <span class="s3">&quot;'n_iter' is deprecated in version 1.1 and will be removed in version 1.4&quot;</span>
    <span class="s1">)</span>
    <span class="s1">est = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">n_iter=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s0">, </span><span class="s1">match=depr_msg):</span>
        <span class="s1">est.fit(X)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;arg, val&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">&quot;iter_offset&quot;</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;inner_stats&quot;</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;return_inner_stats&quot;</span><span class="s0">, False</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;return_n_iter&quot;</span><span class="s0">, False</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;n_iter&quot;</span><span class="s0">, </span><span class="s2">5</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_dict_learning_online_deprecated_args(arg</span><span class="s0">, </span><span class="s1">val):</span>
    <span class="s5"># check the deprecation warning for the deprecated args of</span>
    <span class="s5"># dict_learning_online</span>
    <span class="s5"># TODO(1.4) remove</span>
    <span class="s1">depr_msg = (</span>
        <span class="s3">f&quot;'</span><span class="s0">{</span><span class="s1">arg</span><span class="s0">}</span><span class="s3">' is deprecated in version 1.1 and will be removed in version 1.4.&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s0">, </span><span class="s1">match=depr_msg):</span>
        <span class="s1">dict_learning_online(</span>
            <span class="s1">X</span><span class="s0">, </span><span class="s1">n_components=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">**{arg: val}</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_update_dict():</span>
    <span class="s5"># Check the dict update in batch mode vs online mode</span>
    <span class="s5"># Non-regression test for #4866</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>

    <span class="s1">code = np.array([[</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.1</span><span class="s0">, </span><span class="s2">0.9</span><span class="s1">]])</span>
    <span class="s1">dictionary = np.array([[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.6</span><span class="s0">, </span><span class="s2">0.8</span><span class="s1">]])</span>

    <span class="s1">X = np.dot(code</span><span class="s0">, </span><span class="s1">dictionary) + rng.randn(</span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>

    <span class="s5"># full batch update</span>
    <span class="s1">newd_batch = dictionary.copy()</span>
    <span class="s1">_update_dict(newd_batch</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">code)</span>

    <span class="s5"># online update</span>
    <span class="s1">A = np.dot(code.T</span><span class="s0">, </span><span class="s1">code)</span>
    <span class="s1">B = np.dot(X.T</span><span class="s0">, </span><span class="s1">code)</span>
    <span class="s1">newd_online = dictionary.copy()</span>
    <span class="s1">_update_dict(newd_online</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">code</span><span class="s0">, </span><span class="s1">A</span><span class="s0">, </span><span class="s1">B)</span>

    <span class="s1">assert_allclose(newd_batch</span><span class="s0">, </span><span class="s1">newd_online)</span>


<span class="s5"># TODO(1.4) remove</span>
<span class="s0">def </span><span class="s1">test_dict_learning_online_n_iter_deprecated():</span>
    <span class="s5"># Check that an error is raised when a deprecated argument is set when max_iter</span>
    <span class="s5"># is also set.</span>
    <span class="s1">msg = </span><span class="s3">&quot;The following arguments are incompatible with 'max_iter'&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">dict_learning_online(X</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">10</span><span class="s0">, </span><span class="s1">return_inner_stats=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;data_type&quot;</span><span class="s0">, </span><span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float64))</span>
<span class="s5"># Note: do not check integer input because `lasso_lars` and `lars` fail with</span>
<span class="s5"># `ValueError` in `_lars_path_solver`</span>
<span class="s0">def </span><span class="s1">test_sparse_encode_dtype_match(data_type</span><span class="s0">, </span><span class="s1">algorithm):</span>
    <span class="s1">n_components = </span><span class="s2">6</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">dictionary = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">code = sparse_encode(</span>
        <span class="s1">X.astype(data_type)</span><span class="s0">, </span><span class="s1">dictionary.astype(data_type)</span><span class="s0">, </span><span class="s1">algorithm=algorithm</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">code.dtype == data_type</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_sparse_encode_numerical_consistency(algorithm):</span>
    <span class="s5"># verify numerical consistency among np.float32 and np.float64</span>
    <span class="s1">rtol = </span><span class="s2">1e-4</span>
    <span class="s1">n_components = </span><span class="s2">6</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">dictionary = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">code_32 = sparse_encode(</span>
        <span class="s1">X.astype(np.float32)</span><span class="s0">, </span><span class="s1">dictionary.astype(np.float32)</span><span class="s0">, </span><span class="s1">algorithm=algorithm</span>
    <span class="s1">)</span>
    <span class="s1">code_64 = sparse_encode(</span>
        <span class="s1">X.astype(np.float64)</span><span class="s0">, </span><span class="s1">dictionary.astype(np.float64)</span><span class="s0">, </span><span class="s1">algorithm=algorithm</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(code_32</span><span class="s0">, </span><span class="s1">code_64</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;transform_algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;data_type&quot;</span><span class="s0">, </span><span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float64))</span>
<span class="s5"># Note: do not check integer input because `lasso_lars` and `lars` fail with</span>
<span class="s5"># `ValueError` in `_lars_path_solver`</span>
<span class="s0">def </span><span class="s1">test_sparse_coder_dtype_match(data_type</span><span class="s0">, </span><span class="s1">transform_algorithm):</span>
    <span class="s5"># Verify preserving dtype for transform in sparse coder</span>
    <span class="s1">n_components = </span><span class="s2">6</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">dictionary = rng.randn(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">coder = SparseCoder(</span>
        <span class="s1">dictionary.astype(data_type)</span><span class="s0">, </span><span class="s1">transform_algorithm=transform_algorithm</span>
    <span class="s1">)</span>
    <span class="s1">code = coder.transform(X.astype(data_type))</span>
    <span class="s0">assert </span><span class="s1">code.dtype == data_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;fit_algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;transform_algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;data_type, expected_type&quot;</span><span class="s0">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float32)</span><span class="s0">,</span>
        <span class="s1">(np.float64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_dictionary_learning_dtype_match(</span>
    <span class="s1">data_type</span><span class="s0">,</span>
    <span class="s1">expected_type</span><span class="s0">,</span>
    <span class="s1">fit_algorithm</span><span class="s0">,</span>
    <span class="s1">transform_algorithm</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5"># Verify preserving dtype for fit and transform in dictionary learning class</span>
    <span class="s1">dict_learner = DictionaryLearning(</span>
        <span class="s1">n_components=</span><span class="s2">8</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=fit_algorithm</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">dict_learner.fit(X.astype(data_type))</span>
    <span class="s0">assert </span><span class="s1">dict_learner.components_.dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dict_learner.transform(X.astype(data_type)).dtype == expected_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;fit_algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;transform_algorithm&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lasso_lars&quot;</span><span class="s0">, </span><span class="s3">&quot;lasso_cd&quot;</span><span class="s0">, </span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;threshold&quot;</span><span class="s0">, </span><span class="s3">&quot;omp&quot;</span><span class="s1">)</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;data_type, expected_type&quot;</span><span class="s0">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float32)</span><span class="s0">,</span>
        <span class="s1">(np.float64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_minibatch_dictionary_learning_dtype_match(</span>
    <span class="s1">data_type</span><span class="s0">,</span>
    <span class="s1">expected_type</span><span class="s0">,</span>
    <span class="s1">fit_algorithm</span><span class="s0">,</span>
    <span class="s1">transform_algorithm</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5"># Verify preserving dtype for fit and transform in minibatch dictionary learning</span>
    <span class="s1">dict_learner = MiniBatchDictionaryLearning(</span>
        <span class="s1">n_components=</span><span class="s2">8</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=fit_algorithm</span><span class="s0">,</span>
        <span class="s1">transform_algorithm=transform_algorithm</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">100</span><span class="s0">,</span>
        <span class="s1">tol=</span><span class="s2">1e-1</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">dict_learner.fit(X.astype(data_type))</span>

    <span class="s0">assert </span><span class="s1">dict_learner.components_.dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dict_learner.transform(X.astype(data_type)).dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dict_learner._A.dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dict_learner._B.dtype == expected_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;method&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;data_type, expected_type&quot;</span><span class="s0">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float32)</span><span class="s0">,</span>
        <span class="s1">(np.float64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_dict_learning_dtype_match(data_type</span><span class="s0">, </span><span class="s1">expected_type</span><span class="s0">, </span><span class="s1">method):</span>
    <span class="s5"># Verify output matrix dtype</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">n_components = </span><span class="s2">8</span>
    <span class="s1">code</span><span class="s0">, </span><span class="s1">dictionary</span><span class="s0">, </span><span class="s1">_ = dict_learning(</span>
        <span class="s1">X.astype(data_type)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">code.dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dictionary.dtype == expected_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;method&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_dict_learning_numerical_consistency(method):</span>
    <span class="s5"># verify numerically consistent among np.float32 and np.float64</span>
    <span class="s1">rtol = </span><span class="s2">1e-6</span>
    <span class="s1">n_components = </span><span class="s2">4</span>
    <span class="s1">alpha = </span><span class="s2">2</span>

    <span class="s1">U_64</span><span class="s0">, </span><span class="s1">V_64</span><span class="s0">, </span><span class="s1">_ = dict_learning(</span>
        <span class="s1">X.astype(np.float64)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">U_32</span><span class="s0">, </span><span class="s1">V_32</span><span class="s0">, </span><span class="s1">_ = dict_learning(</span>
        <span class="s1">X.astype(np.float32)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s5"># Optimal solution (U*, V*) is not unique.</span>
    <span class="s5"># If (U*, V*) is optimal solution, (-U*,-V*) is also optimal,</span>
    <span class="s5"># and (column permutated U*, row permutated V*) are also optional</span>
    <span class="s5"># as long as holding UV.</span>
    <span class="s5"># So here UV, ||U||_1,1 and sum(||V_k||_2^2) are verified</span>
    <span class="s5"># instead of comparing directly U and V.</span>
    <span class="s1">assert_allclose(np.matmul(U_64</span><span class="s0">, </span><span class="s1">V_64)</span><span class="s0">, </span><span class="s1">np.matmul(U_32</span><span class="s0">, </span><span class="s1">V_32)</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s1">assert_allclose(np.sum(np.abs(U_64))</span><span class="s0">, </span><span class="s1">np.sum(np.abs(U_32))</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s1">assert_allclose(np.sum(V_64**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.sum(V_32**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s5"># verify an obtained solution is not degenerate</span>
    <span class="s0">assert </span><span class="s1">np.mean(U_64 != </span><span class="s2">0.0</span><span class="s1">) &gt; </span><span class="s2">0.05</span>
    <span class="s0">assert </span><span class="s1">np.count_nonzero(U_64 != </span><span class="s2">0.0</span><span class="s1">) == np.count_nonzero(U_32 != </span><span class="s2">0.0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;method&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;data_type, expected_type&quot;</span><span class="s0">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float32)</span><span class="s0">,</span>
        <span class="s1">(np.float64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_dict_learning_online_dtype_match(data_type</span><span class="s0">, </span><span class="s1">expected_type</span><span class="s0">, </span><span class="s1">method):</span>
    <span class="s5"># Verify output matrix dtype</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">n_components = </span><span class="s2">8</span>
    <span class="s1">code</span><span class="s0">, </span><span class="s1">dictionary = dict_learning_online(</span>
        <span class="s1">X.astype(data_type)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">random_state=rng</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">code.dtype == expected_type</span>
    <span class="s0">assert </span><span class="s1">dictionary.dtype == expected_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;method&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;lars&quot;</span><span class="s0">, </span><span class="s3">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_dict_learning_online_numerical_consistency(method):</span>
    <span class="s5"># verify numerically consistent among np.float32 and np.float64</span>
    <span class="s1">rtol = </span><span class="s2">1e-4</span>
    <span class="s1">n_components = </span><span class="s2">4</span>
    <span class="s1">alpha = </span><span class="s2">1</span>

    <span class="s1">U_64</span><span class="s0">, </span><span class="s1">V_64 = dict_learning_online(</span>
        <span class="s1">X.astype(np.float64)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">U_32</span><span class="s0">, </span><span class="s1">V_32 = dict_learning_online(</span>
        <span class="s1">X.astype(np.float32)</span><span class="s0">,</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">batch_size=</span><span class="s2">10</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s5"># Optimal solution (U*, V*) is not unique.</span>
    <span class="s5"># If (U*, V*) is optimal solution, (-U*,-V*) is also optimal,</span>
    <span class="s5"># and (column permutated U*, row permutated V*) are also optional</span>
    <span class="s5"># as long as holding UV.</span>
    <span class="s5"># So here UV, ||U||_1,1 and sum(||V_k||_2) are verified</span>
    <span class="s5"># instead of comparing directly U and V.</span>
    <span class="s1">assert_allclose(np.matmul(U_64</span><span class="s0">, </span><span class="s1">V_64)</span><span class="s0">, </span><span class="s1">np.matmul(U_32</span><span class="s0">, </span><span class="s1">V_32)</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s1">assert_allclose(np.sum(np.abs(U_64))</span><span class="s0">, </span><span class="s1">np.sum(np.abs(U_32))</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s1">assert_allclose(np.sum(V_64**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.sum(V_32**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">rtol=rtol)</span>
    <span class="s5"># verify an obtained solution is not degenerate</span>
    <span class="s0">assert </span><span class="s1">np.mean(U_64 != </span><span class="s2">0.0</span><span class="s1">) &gt; </span><span class="s2">0.05</span>
    <span class="s0">assert </span><span class="s1">np.count_nonzero(U_64 != </span><span class="s2">0.0</span><span class="s1">) == np.count_nonzero(U_32 != </span><span class="s2">0.0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;estimator&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">SparseCoder(X.T)</span><span class="s0">,</span>
        <span class="s1">DictionaryLearning()</span><span class="s0">,</span>
        <span class="s1">MiniBatchDictionaryLearning(batch_size=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">10</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
    <span class="s1">ids=</span><span class="s0">lambda </span><span class="s1">x: x.__class__.__name__</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_get_feature_names_out(estimator):</span>
    <span class="s4">&quot;&quot;&quot;Check feature names for dict learning estimators.&quot;&quot;&quot;</span>
    <span class="s1">estimator.fit(X)</span>
    <span class="s1">n_components = X.shape[</span><span class="s2">1</span><span class="s1">]</span>

    <span class="s1">feature_names_out = estimator.get_feature_names_out()</span>
    <span class="s1">estimator_name = estimator.__class__.__name__.lower()</span>
    <span class="s1">assert_array_equal(</span>
        <span class="s1">feature_names_out</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">estimator_name</span><span class="s0">}{</span><span class="s1">i</span><span class="s0">}</span><span class="s3">&quot; </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n_components)]</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_cd_work_on_joblib_memmapped_data(monkeypatch):</span>
    <span class="s1">monkeypatch.setattr(</span>
        <span class="s1">sklearn.decomposition._dict_learning</span><span class="s0">,</span>
        <span class="s3">&quot;Parallel&quot;</span><span class="s0">,</span>
        <span class="s1">partial(Parallel</span><span class="s0">, </span><span class="s1">max_nbytes=</span><span class="s2">100</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">rng = np.random.RandomState(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">X_train = rng.randn(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s1">)</span>

    <span class="s1">dict_learner = DictionaryLearning(</span>
        <span class="s1">n_components=</span><span class="s2">5</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
        <span class="s1">n_jobs=</span><span class="s2">2</span><span class="s0">,</span>
        <span class="s1">fit_algorithm=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s2">50</span><span class="s0">,</span>
        <span class="s1">verbose=</span><span class="s0">True,</span>
    <span class="s1">)</span>

    <span class="s5"># This must run and complete without error.</span>
    <span class="s1">dict_learner.fit(X_train)</span>


<span class="s5"># TODO(1.4) remove</span>
<span class="s0">def </span><span class="s1">test_minibatch_dictionary_learning_warns_and_ignore_n_iter():</span>
    <span class="s4">&quot;&quot;&quot;Check that we always raise a warning when `n_iter` is set even if it is 
    ignored if `max_iter` is set. 
    &quot;&quot;&quot;</span>
    <span class="s1">warn_msg = </span><span class="s3">&quot;'n_iter' is deprecated in version 1.1&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s0">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">model = MiniBatchDictionaryLearning(batch_size=</span><span class="s2">256</span><span class="s0">, </span><span class="s1">n_iter=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">2</span><span class="s1">).fit(X)</span>
    <span class="s0">assert </span><span class="s1">model.n_iter_ == </span><span class="s2">2</span>
</pre>
</body>
</html>
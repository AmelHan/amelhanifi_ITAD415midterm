<html>
<head>
<title>test_nca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_nca.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Testing for Neighborhood Component Analysis module (sklearn.neighbors.nca) 
&quot;&quot;&quot;</span>

<span class="s2"># Authors: William de Vazelhes &lt;wdevazelhes@gmail.com&gt;</span>
<span class="s2">#          John Chiotellis &lt;ioannis.chiotellis@in.tum.de&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">re</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pytest</span>
<span class="s3">from </span><span class="s1">numpy.testing </span><span class="s3">import </span><span class="s1">assert_array_almost_equal</span><span class="s3">, </span><span class="s1">assert_array_equal</span>
<span class="s3">from </span><span class="s1">scipy.optimize </span><span class="s3">import </span><span class="s1">check_grad</span>

<span class="s3">from </span><span class="s1">sklearn </span><span class="s3">import </span><span class="s1">clone</span>
<span class="s3">from </span><span class="s1">sklearn.datasets </span><span class="s3">import </span><span class="s1">load_iris</span><span class="s3">, </span><span class="s1">make_blobs</span><span class="s3">, </span><span class="s1">make_classification</span>
<span class="s3">from </span><span class="s1">sklearn.exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>
<span class="s3">from </span><span class="s1">sklearn.metrics </span><span class="s3">import </span><span class="s1">pairwise_distances</span>
<span class="s3">from </span><span class="s1">sklearn.neighbors </span><span class="s3">import </span><span class="s1">NeighborhoodComponentsAnalysis</span>
<span class="s3">from </span><span class="s1">sklearn.preprocessing </span><span class="s3">import </span><span class="s1">LabelEncoder</span>
<span class="s3">from </span><span class="s1">sklearn.utils </span><span class="s3">import </span><span class="s1">check_random_state</span>

<span class="s1">rng = check_random_state(</span><span class="s4">0</span><span class="s1">)</span>
<span class="s2"># load and shuffle iris dataset</span>
<span class="s1">iris = load_iris()</span>
<span class="s1">perm = rng.permutation(iris.target.size)</span>
<span class="s1">iris_data = iris.data[perm]</span>
<span class="s1">iris_target = iris.target[perm]</span>
<span class="s1">EPS = np.finfo(float).eps</span>


<span class="s3">def </span><span class="s1">test_simple_example():</span>
    <span class="s0">&quot;&quot;&quot;Test on a simple example. 
 
    Puts four points in the input space where the opposite labels points are 
    next to each other. After transform the samples from the same class 
    should be next to each other. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">X = np.array([[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">y = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(</span>
        <span class="s1">n_components=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">init=</span><span class="s5">&quot;identity&quot;</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">42</span>
    <span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">X_t = nca.transform(X)</span>
    <span class="s1">assert_array_equal(pairwise_distances(X_t).argsort()[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">np.array([</span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]))</span>


<span class="s3">def </span><span class="s1">test_toy_example_collapse_points():</span>
    <span class="s0">&quot;&quot;&quot;Test on a toy example of three points that should collapse 
 
    We build a simple example: two points from the same class and a point from 
    a different class in the middle of them. On this simple example, the new 
    (transformed) points should all collapse into one single point. Indeed, the 
    objective is 2/(1 + exp(d/2)), with d the euclidean distance between the 
    two samples from the same class. This is maximized for d=0 (because d&gt;=0), 
    with an objective equal to 1 (loss=-1.). 
 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">input_dim = </span><span class="s4">5</span>
    <span class="s1">two_points = rng.randn(</span><span class="s4">2</span><span class="s3">, </span><span class="s1">input_dim)</span>
    <span class="s1">X = np.vstack([two_points</span><span class="s3">, </span><span class="s1">two_points.mean(axis=</span><span class="s4">0</span><span class="s1">)[np.newaxis</span><span class="s3">, </span><span class="s1">:]])</span>
    <span class="s1">y = [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span>

    <span class="s3">class </span><span class="s1">LossStorer:</span>
        <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
            <span class="s1">self.loss = np.inf  </span><span class="s2"># initialize the loss to very high</span>
            <span class="s2"># Initialize a fake NCA and variables needed to compute the loss:</span>
            <span class="s1">self.fake_nca = NeighborhoodComponentsAnalysis()</span>
            <span class="s1">self.fake_nca.n_iter_ = np.inf</span>
            <span class="s1">self.X</span><span class="s3">, </span><span class="s1">y = self.fake_nca._validate_data(X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">ensure_min_samples=</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">y = LabelEncoder().fit_transform(y)</span>
            <span class="s1">self.same_class_mask = y[:</span><span class="s3">, </span><span class="s1">np.newaxis] == y[np.newaxis</span><span class="s3">, </span><span class="s1">:]</span>

        <span class="s3">def </span><span class="s1">callback(self</span><span class="s3">, </span><span class="s1">transformation</span><span class="s3">, </span><span class="s1">n_iter):</span>
            <span class="s0">&quot;&quot;&quot;Stores the last value of the loss function&quot;&quot;&quot;</span>
            <span class="s1">self.loss</span><span class="s3">, </span><span class="s1">_ = self.fake_nca._loss_grad_lbfgs(</span>
                <span class="s1">transformation</span><span class="s3">, </span><span class="s1">self.X</span><span class="s3">, </span><span class="s1">self.same_class_mask</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1.0</span>
            <span class="s1">)</span>

    <span class="s1">loss_storer = LossStorer(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(random_state=</span><span class="s4">42</span><span class="s3">, </span><span class="s1">callback=loss_storer.callback)</span>
    <span class="s1">X_t = nca.fit_transform(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">print(X_t)</span>
    <span class="s2"># test that points are collapsed into one point</span>
    <span class="s1">assert_array_almost_equal(X_t - X_t[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">0.0</span><span class="s1">)</span>
    <span class="s3">assert </span><span class="s1">abs(loss_storer.loss + </span><span class="s4">1</span><span class="s1">) &lt; </span><span class="s4">1e-10</span>


<span class="s3">def </span><span class="s1">test_finite_differences(global_random_seed):</span>
    <span class="s0">&quot;&quot;&quot;Test gradient of loss function 
 
    Assert that the gradient is almost equal to its finite differences 
    approximation. 
    &quot;&quot;&quot;</span>
    <span class="s2"># Initialize the transformation `M`, as well as `X` and `y` and `NCA`</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = make_classification(random_state=global_random_seed)</span>
    <span class="s1">M = rng.randn(rng.randint(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis()</span>
    <span class="s1">nca.n_iter_ = </span><span class="s4">0</span>
    <span class="s1">mask = y[:</span><span class="s3">, </span><span class="s1">np.newaxis] == y[np.newaxis</span><span class="s3">, </span><span class="s1">:]</span>

    <span class="s3">def </span><span class="s1">fun(M):</span>
        <span class="s3">return </span><span class="s1">nca._loss_grad_lbfgs(M</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">mask)[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s3">def </span><span class="s1">grad(M):</span>
        <span class="s3">return </span><span class="s1">nca._loss_grad_lbfgs(M</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">mask)[</span><span class="s4">1</span><span class="s1">]</span>

    <span class="s2"># compare the gradient to a finite difference approximation</span>
    <span class="s1">diff = check_grad(fun</span><span class="s3">, </span><span class="s1">grad</span><span class="s3">, </span><span class="s1">M.ravel())</span>
    <span class="s3">assert </span><span class="s1">diff == pytest.approx(</span><span class="s4">0.0</span><span class="s3">, </span><span class="s1">abs=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_params_validation():</span>
    <span class="s2"># Test that invalid parameters raise value error</span>
    <span class="s1">X = np.arange(</span><span class="s4">12</span><span class="s1">).reshape(</span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">y = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">NCA = NeighborhoodComponentsAnalysis</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>

    <span class="s1">init = rng.rand(</span><span class="s4">5</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">msg = (</span>
        <span class="s5">f&quot;The output dimensionality (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">}</span><span class="s5">) &quot;</span>
        <span class="s5">&quot;of the given linear transformation `init` cannot be &quot;</span>
        <span class="s5">f&quot;greater than its input dimensionality (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">NCA(init=init).fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">n_components = </span><span class="s4">10</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;The preferred dimensionality of the projected space &quot;</span>
        <span class="s5">f&quot;`n_components` (</span><span class="s3">{</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) cannot be greater &quot;</span>
        <span class="s5">f&quot;than the given data dimensionality (</span><span class="s3">{</span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">NCA(n_components=n_components).fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s3">def </span><span class="s1">test_transformation_dimensions():</span>
    <span class="s1">X = np.arange(</span><span class="s4">12</span><span class="s1">).reshape(</span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">y = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>

    <span class="s2"># Fail if transformation input dimension does not match inputs dimensions</span>
    <span class="s1">transformation = np.array([[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]])</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">NeighborhoodComponentsAnalysis(init=transformation).fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Fail if transformation output dimension is larger than</span>
    <span class="s2"># transformation input dimension</span>
    <span class="s1">transformation = np.array([[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">5</span><span class="s3">, </span><span class="s4">6</span><span class="s1">]])</span>
    <span class="s2"># len(transformation) &gt; len(transformation[0])</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">NeighborhoodComponentsAnalysis(init=transformation).fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Pass otherwise</span>
    <span class="s1">transformation = np.arange(</span><span class="s4">9</span><span class="s1">).reshape(</span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">NeighborhoodComponentsAnalysis(init=transformation).fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s3">def </span><span class="s1">test_n_components():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">X = np.arange(</span><span class="s4">12</span><span class="s1">).reshape(</span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">y = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>

    <span class="s1">init = rng.rand(X.shape[</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">1</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>

    <span class="s2"># n_components = X.shape[1] != transformation.shape[0]</span>
    <span class="s1">n_components = X.shape[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init</span><span class="s3">, </span><span class="s1">n_components=n_components)</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;The preferred dimensionality of the projected space &quot;</span>
        <span class="s5">f&quot;`n_components` (</span><span class="s3">{</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) does not match the output &quot;</span>
        <span class="s5">&quot;dimensionality of the given linear transformation &quot;</span>
        <span class="s5">f&quot;`init` (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># n_components &gt; X.shape[1]</span>
    <span class="s1">n_components = X.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">2</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init</span><span class="s3">, </span><span class="s1">n_components=n_components)</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;The preferred dimensionality of the projected space &quot;</span>
        <span class="s5">f&quot;`n_components` (</span><span class="s3">{</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) cannot be greater than &quot;</span>
        <span class="s5">f&quot;the given data dimensionality (</span><span class="s3">{</span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># n_components &lt; X.shape[1]</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(n_components=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">init=</span><span class="s5">&quot;identity&quot;</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s3">def </span><span class="s1">test_init_transformation():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">30</span><span class="s3">, </span><span class="s1">centers=</span><span class="s4">6</span><span class="s3">, </span><span class="s1">n_features=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s2"># Start learning from scratch</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;identity&quot;</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Initialize with random</span>
    <span class="s1">nca_random = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;random&quot;</span><span class="s1">)</span>
    <span class="s1">nca_random.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Initialize with auto</span>
    <span class="s1">nca_auto = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s1">nca_auto.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Initialize with PCA</span>
    <span class="s1">nca_pca = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;pca&quot;</span><span class="s1">)</span>
    <span class="s1">nca_pca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Initialize with LDA</span>
    <span class="s1">nca_lda = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;lda&quot;</span><span class="s1">)</span>
    <span class="s1">nca_lda.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s1">init = rng.rand(X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># init.shape[1] must match X.shape[1]</span>
    <span class="s1">init = rng.rand(X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init)</span>
    <span class="s1">msg = (</span>
        <span class="s5">f&quot;The input dimensionality (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">) of the given &quot;</span>
        <span class="s5">&quot;linear transformation `init` must match the &quot;</span>
        <span class="s5">f&quot;dimensionality of the given inputs `X` (</span><span class="s3">{</span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># init.shape[0] must be &lt;= init.shape[1]</span>
    <span class="s1">init = rng.rand(X.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init)</span>
    <span class="s1">msg = (</span>
        <span class="s5">f&quot;The output dimensionality (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">}</span><span class="s5">) of the given &quot;</span>
        <span class="s5">&quot;linear transformation `init` cannot be &quot;</span>
        <span class="s5">f&quot;greater than its input dimensionality (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># init.shape[0] must match n_components</span>
    <span class="s1">init = rng.rand(X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">n_components = X.shape[</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">2</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=init</span><span class="s3">, </span><span class="s1">n_components=n_components)</span>
    <span class="s1">msg = (</span>
        <span class="s5">&quot;The preferred dimensionality of the &quot;</span>
        <span class="s5">f&quot;projected space `n_components` (</span><span class="s3">{</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) &quot;</span>
        <span class="s5">&quot;does not match the output dimensionality of the given &quot;</span>
        <span class="s5">f&quot;linear transformation `init` (</span><span class="s3">{</span><span class="s1">init.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n_samples&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">11</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n_features&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">11</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n_classes&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">5</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">11</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s5">&quot;n_components&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">11</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_auto_init(n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">, </span><span class="s1">n_components):</span>
    <span class="s2"># Test that auto choose the init as expected with every configuration</span>
    <span class="s2"># of order of n_samples, n_features, n_classes and n_components.</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">nca_base = NeighborhoodComponentsAnalysis(</span>
        <span class="s1">init=</span><span class="s5">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">n_components=n_components</span><span class="s3">, </span><span class="s1">max_iter=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">random_state=rng</span>
    <span class="s1">)</span>
    <span class="s3">if </span><span class="s1">n_classes &gt;= n_samples:</span>
        <span class="s3">pass</span>
        <span class="s2"># n_classes &gt; n_samples is impossible, and n_classes == n_samples</span>
        <span class="s2"># throws an error from lda but is an absurd case</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">X = rng.randn(n_samples</span><span class="s3">, </span><span class="s1">n_features)</span>
        <span class="s1">y = np.tile(range(n_classes)</span><span class="s3">, </span><span class="s1">n_samples // n_classes + </span><span class="s4">1</span><span class="s1">)[:n_samples]</span>
        <span class="s3">if </span><span class="s1">n_components &gt; n_features:</span>
            <span class="s2"># this would return a ValueError, which is already tested in</span>
            <span class="s2"># test_params_validation</span>
            <span class="s3">pass</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">nca = clone(nca_base)</span>
            <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
            <span class="s3">if </span><span class="s1">n_components &lt;= min(n_classes - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n_features):</span>
                <span class="s1">nca_other = clone(nca_base).set_params(init=</span><span class="s5">&quot;lda&quot;</span><span class="s1">)</span>
            <span class="s3">elif </span><span class="s1">n_components &lt; min(n_features</span><span class="s3">, </span><span class="s1">n_samples):</span>
                <span class="s1">nca_other = clone(nca_base).set_params(init=</span><span class="s5">&quot;pca&quot;</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">nca_other = clone(nca_base).set_params(init=</span><span class="s5">&quot;identity&quot;</span><span class="s1">)</span>
            <span class="s1">nca_other.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
            <span class="s1">assert_array_almost_equal(nca.components_</span><span class="s3">, </span><span class="s1">nca_other.components_)</span>


<span class="s3">def </span><span class="s1">test_warm_start_validation():</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = make_classification(</span>
        <span class="s1">n_samples=</span><span class="s4">30</span><span class="s3">,</span>
        <span class="s1">n_features=</span><span class="s4">5</span><span class="s3">,</span>
        <span class="s1">n_classes=</span><span class="s4">4</span><span class="s3">,</span>
        <span class="s1">n_redundant=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">n_informative=</span><span class="s4">5</span><span class="s3">,</span>
        <span class="s1">random_state=</span><span class="s4">0</span><span class="s3">,</span>
    <span class="s1">)</span>

    <span class="s1">nca = NeighborhoodComponentsAnalysis(warm_start=</span><span class="s3">True, </span><span class="s1">max_iter=</span><span class="s4">5</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s1">X_less_features</span><span class="s3">, </span><span class="s1">y = make_classification(</span>
        <span class="s1">n_samples=</span><span class="s4">30</span><span class="s3">,</span>
        <span class="s1">n_features=</span><span class="s4">4</span><span class="s3">,</span>
        <span class="s1">n_classes=</span><span class="s4">4</span><span class="s3">,</span>
        <span class="s1">n_redundant=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">n_informative=</span><span class="s4">4</span><span class="s3">,</span>
        <span class="s1">random_state=</span><span class="s4">0</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">msg = (</span>
        <span class="s5">f&quot;The new inputs dimensionality (</span><span class="s3">{</span><span class="s1">X_less_features.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">) &quot;</span>
        <span class="s5">&quot;does not match the input dimensionality of the previously learned &quot;</span>
        <span class="s5">f&quot;transformation (</span><span class="s3">{</span><span class="s1">nca.components_.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
    <span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(X_less_features</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s3">def </span><span class="s1">test_warm_start_effectiveness():</span>
    <span class="s2"># A 1-iteration second fit on same data should give almost same result</span>
    <span class="s2"># with warm starting, and quite different result without warm starting.</span>

    <span class="s1">nca_warm = NeighborhoodComponentsAnalysis(warm_start=</span><span class="s3">True, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">nca_warm.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">transformation_warm = nca_warm.components_</span>
    <span class="s1">nca_warm.max_iter = </span><span class="s4">1</span>
    <span class="s1">nca_warm.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">transformation_warm_plus_one = nca_warm.components_</span>

    <span class="s1">nca_cold = NeighborhoodComponentsAnalysis(warm_start=</span><span class="s3">False, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">nca_cold.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">transformation_cold = nca_cold.components_</span>
    <span class="s1">nca_cold.max_iter = </span><span class="s4">1</span>
    <span class="s1">nca_cold.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">transformation_cold_plus_one = nca_cold.components_</span>

    <span class="s1">diff_warm = np.sum(np.abs(transformation_warm_plus_one - transformation_warm))</span>
    <span class="s1">diff_cold = np.sum(np.abs(transformation_cold_plus_one - transformation_cold))</span>
    <span class="s3">assert </span><span class="s1">diff_warm &lt; </span><span class="s4">3.0</span><span class="s3">, </span><span class="s1">(</span>
        <span class="s5">&quot;Transformer changed significantly after one &quot;</span>
        <span class="s5">&quot;iteration even though it was warm-started.&quot;</span>
    <span class="s1">)</span>

    <span class="s3">assert </span><span class="s1">diff_cold &gt; diff_warm</span><span class="s3">, </span><span class="s1">(</span>
        <span class="s5">&quot;Cold-started transformer changed less &quot;</span>
        <span class="s5">&quot;significantly than warm-started &quot;</span>
        <span class="s5">&quot;transformer after one iteration.&quot;</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;init_name&quot;</span><span class="s3">, </span><span class="s1">[</span><span class="s5">&quot;pca&quot;</span><span class="s3">, </span><span class="s5">&quot;lda&quot;</span><span class="s3">, </span><span class="s5">&quot;identity&quot;</span><span class="s3">, </span><span class="s5">&quot;random&quot;</span><span class="s3">, </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_verbose(init_name</span><span class="s3">, </span><span class="s1">capsys):</span>
    <span class="s2"># assert there is proper output when verbose = 1, for every initialization</span>
    <span class="s2"># except auto because auto will call one of the others</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s4">42</span><span class="s1">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">30</span><span class="s3">, </span><span class="s1">centers=</span><span class="s4">6</span><span class="s3">, </span><span class="s1">n_features=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">regexp_init = </span><span class="s5">r&quot;... done in \ *\d+\.\d{2}s&quot;</span>
    <span class="s1">msgs = {</span>
        <span class="s5">&quot;pca&quot;</span><span class="s1">: </span><span class="s5">&quot;Finding principal components&quot; </span><span class="s1">+ regexp_init</span><span class="s3">,</span>
        <span class="s5">&quot;lda&quot;</span><span class="s1">: </span><span class="s5">&quot;Finding most discriminative components&quot; </span><span class="s1">+ regexp_init</span><span class="s3">,</span>
    <span class="s1">}</span>
    <span class="s3">if </span><span class="s1">init_name == </span><span class="s5">&quot;precomputed&quot;</span><span class="s1">:</span>
        <span class="s1">init = rng.randn(X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">X.shape[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">init = init_name</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(verbose=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">init=init)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">out</span><span class="s3">, </span><span class="s1">_ = capsys.readouterr()</span>

    <span class="s2"># check output</span>
    <span class="s1">lines = re.split(</span><span class="s5">&quot;</span><span class="s3">\n</span><span class="s5">+&quot;</span><span class="s3">, </span><span class="s1">out)</span>
    <span class="s2"># if pca or lda init, an additional line is printed, so we test</span>
    <span class="s2"># it and remove it to test the rest equally among initializations</span>
    <span class="s3">if </span><span class="s1">init_name </span><span class="s3">in </span><span class="s1">[</span><span class="s5">&quot;pca&quot;</span><span class="s3">, </span><span class="s5">&quot;lda&quot;</span><span class="s1">]:</span>
        <span class="s3">assert </span><span class="s1">re.match(msgs[init_name]</span><span class="s3">, </span><span class="s1">lines[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">lines = lines[</span><span class="s4">1</span><span class="s1">:]</span>
    <span class="s3">assert </span><span class="s1">lines[</span><span class="s4">0</span><span class="s1">] == </span><span class="s5">&quot;[NeighborhoodComponentsAnalysis]&quot;</span>
    <span class="s1">header = </span><span class="s5">&quot;{:&gt;10} {:&gt;20} {:&gt;10}&quot;</span><span class="s1">.format(</span><span class="s5">&quot;Iteration&quot;</span><span class="s3">, </span><span class="s5">&quot;Objective Value&quot;</span><span class="s3">, </span><span class="s5">&quot;Time(s)&quot;</span><span class="s1">)</span>
    <span class="s3">assert </span><span class="s1">lines[</span><span class="s4">1</span><span class="s1">] == </span><span class="s5">&quot;[NeighborhoodComponentsAnalysis] {}&quot;</span><span class="s1">.format(header)</span>
    <span class="s3">assert </span><span class="s1">lines[</span><span class="s4">2</span><span class="s1">] == </span><span class="s5">&quot;[NeighborhoodComponentsAnalysis] {}&quot;</span><span class="s1">.format(</span><span class="s5">&quot;-&quot; </span><span class="s1">* len(header))</span>
    <span class="s3">for </span><span class="s1">line </span><span class="s3">in </span><span class="s1">lines[</span><span class="s4">3</span><span class="s1">:-</span><span class="s4">2</span><span class="s1">]:</span>
        <span class="s2"># The following regex will match for instance:</span>
        <span class="s2"># '[NeighborhoodComponentsAnalysis]  0    6.988936e+01   0.01'</span>
        <span class="s3">assert </span><span class="s1">re.match(</span>
            <span class="s5">r&quot;\[NeighborhoodComponentsAnalysis\] *\d+ *\d\.\d{6}e&quot;</span>
            <span class="s5">r&quot;[+|-]\d+\ *\d+\.\d{2}&quot;</span><span class="s3">,</span>
            <span class="s1">line</span><span class="s3">,</span>
        <span class="s1">)</span>
    <span class="s3">assert </span><span class="s1">re.match(</span>
        <span class="s5">r&quot;\[NeighborhoodComponentsAnalysis\] Training took\ *&quot; r&quot;\d+\.\d{2}s\.&quot;</span><span class="s3">,</span>
        <span class="s1">lines[-</span><span class="s4">2</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s3">assert </span><span class="s1">lines[-</span><span class="s4">1</span><span class="s1">] == </span><span class="s5">&quot;&quot;</span>


<span class="s3">def </span><span class="s1">test_no_verbose(capsys):</span>
    <span class="s2"># assert by default there is no output (verbose=0)</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis()</span>
    <span class="s1">nca.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">out</span><span class="s3">, </span><span class="s1">_ = capsys.readouterr()</span>
    <span class="s2"># check output</span>
    <span class="s3">assert </span><span class="s1">out == </span><span class="s5">&quot;&quot;</span>


<span class="s3">def </span><span class="s1">test_singleton_class():</span>
    <span class="s1">X = iris_data</span>
    <span class="s1">y = iris_target</span>

    <span class="s2"># one singleton class</span>
    <span class="s1">singleton_class = </span><span class="s4">1</span>
    <span class="s1">(ind_singleton</span><span class="s3">,</span><span class="s1">) = np.where(y == singleton_class)</span>
    <span class="s1">y[ind_singleton] = </span><span class="s4">2</span>
    <span class="s1">y[ind_singleton[</span><span class="s4">0</span><span class="s1">]] = singleton_class</span>

    <span class="s1">nca = NeighborhoodComponentsAnalysis(max_iter=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># One non-singleton class</span>
    <span class="s1">(ind_1</span><span class="s3">,</span><span class="s1">) = np.where(y == </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">(ind_2</span><span class="s3">,</span><span class="s1">) = np.where(y == </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">y[ind_1] = </span><span class="s4">0</span>
    <span class="s1">y[ind_1[</span><span class="s4">0</span><span class="s1">]] = </span><span class="s4">1</span>
    <span class="s1">y[ind_2] = </span><span class="s4">0</span>
    <span class="s1">y[ind_2[</span><span class="s4">0</span><span class="s1">]] = </span><span class="s4">2</span>

    <span class="s1">nca = NeighborhoodComponentsAnalysis(max_iter=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>

    <span class="s2"># Only singleton classes</span>
    <span class="s1">(ind_0</span><span class="s3">,</span><span class="s1">) = np.where(y == </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">(ind_1</span><span class="s3">,</span><span class="s1">) = np.where(y == </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">(ind_2</span><span class="s3">,</span><span class="s1">) = np.where(y == </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">X = X[[ind_0[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ind_1[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ind_2[</span><span class="s4">0</span><span class="s1">]]]</span>
    <span class="s1">y = y[[ind_0[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ind_1[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ind_2[</span><span class="s4">0</span><span class="s1">]]]</span>

    <span class="s1">nca = NeighborhoodComponentsAnalysis(init=</span><span class="s5">&quot;identity&quot;</span><span class="s3">, </span><span class="s1">max_iter=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(X</span><span class="s3">, </span><span class="s1">nca.transform(X))</span>


<span class="s3">def </span><span class="s1">test_one_class():</span>
    <span class="s1">X = iris_data[iris_target == </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">y = iris_target[iris_target == </span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">nca = NeighborhoodComponentsAnalysis(</span>
        <span class="s1">max_iter=</span><span class="s4">30</span><span class="s3">, </span><span class="s1">n_components=X.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">init=</span><span class="s5">&quot;identity&quot;</span>
    <span class="s1">)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(X</span><span class="s3">, </span><span class="s1">nca.transform(X))</span>


<span class="s3">def </span><span class="s1">test_callback(capsys):</span>
    <span class="s1">max_iter = </span><span class="s4">10</span>

    <span class="s3">def </span><span class="s1">my_cb(transformation</span><span class="s3">, </span><span class="s1">n_iter):</span>
        <span class="s3">assert </span><span class="s1">transformation.shape == (iris_data.shape[</span><span class="s4">1</span><span class="s1">] ** </span><span class="s4">2</span><span class="s3">,</span><span class="s1">)</span>
        <span class="s1">rem_iter = max_iter - n_iter</span>
        <span class="s1">print(</span><span class="s5">&quot;{} iterations remaining...&quot;</span><span class="s1">.format(rem_iter))</span>

    <span class="s2"># assert that my_cb is called</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(max_iter=max_iter</span><span class="s3">, </span><span class="s1">callback=my_cb</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">nca.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>
    <span class="s1">out</span><span class="s3">, </span><span class="s1">_ = capsys.readouterr()</span>

    <span class="s2"># check output</span>
    <span class="s3">assert </span><span class="s5">&quot;{} iterations remaining...&quot;</span><span class="s1">.format(max_iter - </span><span class="s4">1</span><span class="s1">) </span><span class="s3">in </span><span class="s1">out</span>


<span class="s3">def </span><span class="s1">test_expected_transformation_shape():</span>
    <span class="s0">&quot;&quot;&quot;Test that the transformation has the expected shape.&quot;&quot;&quot;</span>
    <span class="s1">X = iris_data</span>
    <span class="s1">y = iris_target</span>

    <span class="s3">class </span><span class="s1">TransformationStorer:</span>
        <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
            <span class="s2"># Initialize a fake NCA and variables needed to call the loss</span>
            <span class="s2"># function:</span>
            <span class="s1">self.fake_nca = NeighborhoodComponentsAnalysis()</span>
            <span class="s1">self.fake_nca.n_iter_ = np.inf</span>
            <span class="s1">self.X</span><span class="s3">, </span><span class="s1">y = self.fake_nca._validate_data(X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">ensure_min_samples=</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">y = LabelEncoder().fit_transform(y)</span>
            <span class="s1">self.same_class_mask = y[:</span><span class="s3">, </span><span class="s1">np.newaxis] == y[np.newaxis</span><span class="s3">, </span><span class="s1">:]</span>

        <span class="s3">def </span><span class="s1">callback(self</span><span class="s3">, </span><span class="s1">transformation</span><span class="s3">, </span><span class="s1">n_iter):</span>
            <span class="s0">&quot;&quot;&quot;Stores the last value of the transformation taken as input by 
            the optimizer&quot;&quot;&quot;</span>
            <span class="s1">self.transformation = transformation</span>

    <span class="s1">transformation_storer = TransformationStorer(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">cb = transformation_storer.callback</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(max_iter=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">callback=cb)</span>
    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s3">assert </span><span class="s1">transformation_storer.transformation.size == X.shape[</span><span class="s4">1</span><span class="s1">] ** </span><span class="s4">2</span>


<span class="s3">def </span><span class="s1">test_convergence_warning():</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(max_iter=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">cls_name = nca.__class__.__name__</span>
    <span class="s1">msg = </span><span class="s5">&quot;[{}] NCA did not converge&quot;</span><span class="s1">.format(cls_name)</span>
    <span class="s3">with </span><span class="s1">pytest.warns(ConvergenceWarning</span><span class="s3">, </span><span class="s1">match=re.escape(msg)):</span>
        <span class="s1">nca.fit(iris_data</span><span class="s3">, </span><span class="s1">iris_target)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s5">&quot;param, value&quot;</span><span class="s3">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s5">&quot;n_components&quot;</span><span class="s3">, </span><span class="s1">np.int32(</span><span class="s4">3</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;max_iter&quot;</span><span class="s3">, </span><span class="s1">np.int32(</span><span class="s4">100</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">(</span><span class="s5">&quot;tol&quot;</span><span class="s3">, </span><span class="s1">np.float32(</span><span class="s4">0.0001</span><span class="s1">))</span><span class="s3">,</span>
    <span class="s1">]</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_parameters_valid_types(param</span><span class="s3">, </span><span class="s1">value):</span>
    <span class="s2"># check that no error is raised when parameters have numpy integer or</span>
    <span class="s2"># floating types.</span>
    <span class="s1">nca = NeighborhoodComponentsAnalysis(**{param: value})</span>

    <span class="s1">X = iris_data</span>
    <span class="s1">y = iris_target</span>

    <span class="s1">nca.fit(X</span><span class="s3">, </span><span class="s1">y)</span>


<span class="s3">def </span><span class="s1">test_nca_feature_names_out():</span>
    <span class="s0">&quot;&quot;&quot;Check `get_feature_names_out` for `NeighborhoodComponentsAnalysis`.&quot;&quot;&quot;</span>

    <span class="s1">X = iris_data</span>
    <span class="s1">y = iris_target</span>

    <span class="s1">est = NeighborhoodComponentsAnalysis().fit(X</span><span class="s3">, </span><span class="s1">y)</span>
    <span class="s1">names_out = est.get_feature_names_out()</span>

    <span class="s1">class_name_lower = est.__class__.__name__.lower()</span>
    <span class="s1">expected_names_out = np.array(</span>
        <span class="s1">[</span><span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">class_name_lower</span><span class="s3">}{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">&quot; </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(est.components_.shape[</span><span class="s4">1</span><span class="s1">])]</span><span class="s3">,</span>
        <span class="s1">dtype=object</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_equal(names_out</span><span class="s3">, </span><span class="s1">expected_names_out)</span>
</pre>
</body>
</html>
<html>
<head>
<title>_variation.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_variation.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.core.multiarray </span><span class="s0">import </span><span class="s1">normalize_axis_index</span>
<span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">_nan_allsame</span><span class="s0">, </span><span class="s1">_contains_nan</span>
<span class="s0">from </span><span class="s1">._stats_py </span><span class="s0">import </span><span class="s1">_chk_asarray</span>


<span class="s0">def </span><span class="s1">_nanvariation(a</span><span class="s0">, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Private version of `variation` that ignores nan. 
 
    `a` must be a numpy array. 
    `axis` is assumed to be normalized, i.e. 0 &lt;= axis &lt; a.ndim. 
    &quot;&quot;&quot;</span>
    <span class="s4">#</span>
    <span class="s4"># In theory, this should be as simple as something like</span>
    <span class="s4">#     nanstd(a, ddof=ddof, axis=axis, keepdims=keepdims) /</span>
    <span class="s4">#     nanmean(a, axis=axis, keepdims=keepdims)</span>
    <span class="s4"># In practice, annoying issues arise.  Specifically, numpy</span>
    <span class="s4"># generates warnings in certain edge cases that we don't want</span>
    <span class="s4"># to propagate to the user.  Unfortunately, there does not</span>
    <span class="s4"># appear to be a thread-safe way to filter out the warnings,</span>
    <span class="s4"># so we have to do the calculation in a way that doesn't</span>
    <span class="s4"># generate numpy warnings.</span>
    <span class="s4">#</span>
    <span class="s4"># Let N be the number of non-nan inputs in a slice.</span>
    <span class="s4"># Conditions that generate nan:</span>
    <span class="s4">#   * empty input (i.e. N = 0)</span>
    <span class="s4">#   * All non-nan values 0</span>
    <span class="s4">#   * N &lt; ddof</span>
    <span class="s4">#   * N == ddof and the input is constant</span>
    <span class="s4"># Conditions that generate inf:</span>
    <span class="s4">#   * non-constant input and either</span>
    <span class="s4">#       * the mean is 0, or</span>
    <span class="s4">#       * N == ddof</span>
    <span class="s4">#</span>
    <span class="s1">a_isnan = np.isnan(a)</span>
    <span class="s1">all_nan = a_isnan.all(axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">all_nan_full = np.broadcast_to(all_nan</span><span class="s0">, </span><span class="s1">a.shape)</span>
    <span class="s1">all_zero = (a_isnan | (a == </span><span class="s2">0</span><span class="s1">)).all(axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">) &amp; ~all_nan</span>

    <span class="s4"># ngood is the number of non-nan values in each slice.</span>
    <span class="s1">ngood = (a.shape[axis] -</span>
             <span class="s1">np.expand_dims(np.count_nonzero(a_isnan</span><span class="s0">, </span><span class="s1">axis=axis)</span><span class="s0">, </span><span class="s1">axis))</span>
    <span class="s4"># The return value is nan where ddof &gt; ngood.</span>
    <span class="s1">ddof_too_big = ddof &gt; ngood</span>
    <span class="s4"># If ddof == ngood, the return value is nan where the input is constant and</span>
    <span class="s4"># inf otherwise.</span>
    <span class="s1">ddof_equal_n = ddof == ngood</span>

    <span class="s1">is_const = _nan_allsame(a</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s1">a2 = a.copy()</span>
    <span class="s4"># If an entire slice is nan, `np.nanmean` will generate a warning,</span>
    <span class="s4"># so we replace those nan's with 1.0 before computing the mean.</span>
    <span class="s4"># We'll fix the corresponding output later.</span>
    <span class="s1">a2[all_nan_full] = </span><span class="s2">1.0</span>
    <span class="s1">mean_a = np.nanmean(a2</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s4"># If ddof &gt;= ngood (the number of non-nan values in the slice), `np.nanstd`</span>
    <span class="s4"># will generate a warning, so set all the values in such a slice to 1.0.</span>
    <span class="s4"># We'll fix the corresponding output later.</span>
    <span class="s1">a2[np.broadcast_to(ddof_too_big</span><span class="s0">, </span><span class="s1">a2.shape) | ddof_equal_n] = </span><span class="s2">1.0</span>
    <span class="s0">with </span><span class="s1">np.errstate(invalid=</span><span class="s5">'ignore'</span><span class="s1">):</span>
        <span class="s1">std_a = np.nanstd(a2</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">ddof=ddof</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">del </span><span class="s1">a2</span>

    <span class="s1">sum_zero = np.nansum(a</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">) == </span><span class="s2">0</span>

    <span class="s4"># Where the sum along the axis is 0, replace mean_a with 1.  This avoids</span>
    <span class="s4"># division by zero.  We'll fix the corresponding output later.</span>
    <span class="s1">mean_a[sum_zero] = </span><span class="s2">1.0</span>

    <span class="s4"># Here--finally!--is the calculation of the variation.</span>
    <span class="s1">result = std_a / mean_a</span>

    <span class="s4"># Now fix the values that were given fake data to avoid warnings.</span>
    <span class="s1">result[~is_const &amp; sum_zero] = np.inf</span>
    <span class="s1">signed_inf_mask = ~is_const &amp; ddof_equal_n</span>
    <span class="s1">result[signed_inf_mask] = np.sign(mean_a[signed_inf_mask]) * np.inf</span>
    <span class="s1">nan_mask = all_zero | all_nan | ddof_too_big | (ddof_equal_n &amp; is_const)</span>
    <span class="s1">result[nan_mask] = np.nan</span>

    <span class="s0">if not </span><span class="s1">keepdims:</span>
        <span class="s1">result = np.squeeze(result</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s0">if </span><span class="s1">result.shape == ():</span>
            <span class="s1">result = result[()]</span>

    <span class="s0">return </span><span class="s1">result</span>


<span class="s0">def </span><span class="s1">variation(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">nan_policy=</span><span class="s5">'propagate'</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Compute the coefficient of variation. 
 
    The coefficient of variation is the standard deviation divided by the 
    mean.  This function is equivalent to:: 
 
        np.std(x, axis=axis, ddof=ddof) / np.mean(x) 
 
    The default for ``ddof`` is 0, but many definitions of the coefficient 
    of variation use the square root of the unbiased sample variance 
    for the sample standard deviation, which corresponds to ``ddof=1``. 
 
    The function does not take the absolute value of the mean of the data, 
    so the return value is negative if the mean is negative. 
 
    Parameters 
    ---------- 
    a : array_like 
        Input array. 
    axis : int or None, optional 
        Axis along which to calculate the coefficient of variation. 
        Default is 0. If None, compute over the whole array `a`. 
    nan_policy : {'propagate', 'raise', 'omit'}, optional 
        Defines how to handle when input contains ``nan``. 
        The following options are available: 
 
          * 'propagate': return ``nan`` 
          * 'raise': raise an exception 
          * 'omit': perform the calculation with ``nan`` values omitted 
 
        The default is 'propagate'. 
    ddof : int, optional 
        Gives the &quot;Delta Degrees Of Freedom&quot; used when computing the 
        standard deviation.  The divisor used in the calculation of the 
        standard deviation is ``N - ddof``, where ``N`` is the number of 
        elements.  `ddof` must be less than ``N``; if it isn't, the result 
        will be ``nan`` or ``inf``, depending on ``N`` and the values in 
        the array.  By default `ddof` is zero for backwards compatibility, 
        but it is recommended to use ``ddof=1`` to ensure that the sample 
        standard deviation is computed as the square root of the unbiased 
        sample variance. 
    keepdims : bool, optional 
        If this is set to True, the axes which are reduced are left in the 
        result as dimensions with size one. With this option, the result 
        will broadcast correctly against the input array. 
 
    Returns 
    ------- 
    variation : ndarray 
        The calculated variation along the requested axis. 
 
    Notes 
    ----- 
    There are several edge cases that are handled without generating a 
    warning: 
 
    * If both the mean and the standard deviation are zero, ``nan`` 
      is returned. 
    * If the mean is zero and the standard deviation is nonzero, ``inf`` 
      is returned. 
    * If the input has length zero (either because the array has zero 
      length, or all the input values are ``nan`` and ``nan_policy`` is 
      ``'omit'``), ``nan`` is returned. 
    * If the input contains ``inf``, ``nan`` is returned. 
 
    References 
    ---------- 
    .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard 
       Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New 
       York. 2000. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import variation 
    &gt;&gt;&gt; variation([1, 2, 3, 4, 5], ddof=1) 
    0.5270462766947299 
 
    Compute the variation along a given dimension of an array that contains 
    a few ``nan`` values: 
 
    &gt;&gt;&gt; x = np.array([[  10.0, np.nan, 11.0, 19.0, 23.0, 29.0, 98.0], 
    ...               [  29.0,   30.0, 32.0, 33.0, 35.0, 56.0, 57.0], 
    ...               [np.nan, np.nan, 12.0, 13.0, 16.0, 16.0, 17.0]]) 
    &gt;&gt;&gt; variation(x, axis=1, ddof=1, nan_policy='omit') 
    array([1.05109361, 0.31428986, 0.146483  ]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">a</span><span class="s0">, </span><span class="s1">axis = _chk_asarray(a</span><span class="s0">, </span><span class="s1">axis)</span>
    <span class="s1">axis = normalize_axis_index(axis</span><span class="s0">, </span><span class="s1">ndim=a.ndim)</span>
    <span class="s1">n = a.shape[axis]</span>

    <span class="s1">contains_nan</span><span class="s0">, </span><span class="s1">nan_policy = _contains_nan(a</span><span class="s0">, </span><span class="s1">nan_policy)</span>
    <span class="s0">if </span><span class="s1">contains_nan </span><span class="s0">and </span><span class="s1">nan_policy == </span><span class="s5">'omit'</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">_nanvariation(a</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">ddof=ddof</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>

    <span class="s0">if </span><span class="s1">a.size == </span><span class="s2">0 </span><span class="s0">or </span><span class="s1">ddof &gt; n:</span>
        <span class="s4"># Handle as a special case to avoid spurious warnings.</span>
        <span class="s4"># The return values, if any, are all nan.</span>
        <span class="s1">shp = list(a.shape)</span>
        <span class="s0">if </span><span class="s1">keepdims:</span>
            <span class="s1">shp[axis] = </span><span class="s2">1</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">del </span><span class="s1">shp[axis]</span>
        <span class="s0">if </span><span class="s1">len(shp) == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">result = np.nan</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">result = np.full(shp</span><span class="s0">, </span><span class="s1">fill_value=np.nan)</span>

        <span class="s0">return </span><span class="s1">result</span>

    <span class="s1">mean_a = a.mean(axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">ddof == n:</span>
        <span class="s4"># Another special case.  Result is either inf or nan.</span>
        <span class="s1">std_a = a.std(axis=axis</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">result = np.full_like(std_a</span><span class="s0">, </span><span class="s1">fill_value=np.nan)</span>
        <span class="s1">result.flat[std_a.flat &gt; </span><span class="s2">0</span><span class="s1">] = (np.sign(mean_a) * np.inf).flat</span>
        <span class="s0">if </span><span class="s1">result.shape == ():</span>
            <span class="s1">result = result[()]</span>
        <span class="s0">return </span><span class="s1">result</span>

    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s5">'ignore'</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s5">'ignore'</span><span class="s1">):</span>
        <span class="s1">std_a = a.std(axis</span><span class="s0">, </span><span class="s1">ddof=ddof</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">result = std_a / mean_a</span>

    <span class="s0">if not </span><span class="s1">keepdims:</span>
        <span class="s1">result = np.squeeze(result</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s0">if </span><span class="s1">result.shape == ():</span>
            <span class="s1">result = result[()]</span>

    <span class="s0">return </span><span class="s1">result</span>
</pre>
</body>
</html>
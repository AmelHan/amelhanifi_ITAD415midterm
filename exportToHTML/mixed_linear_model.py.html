<html>
<head>
<title>mixed_linear_model.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
mixed_linear_model.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Linear mixed effects models are regression models for dependent data. 
They can be used to estimate regression relationships involving both 
means and variances. 
 
These models are also known as multilevel linear models, and 
hierarchical linear models. 
 
The MixedLM class fits linear mixed effects models to data, and 
provides support for some common post-estimation tasks.  This is a 
group-based implementation that is most efficient for models in which 
the data can be partitioned into independent groups.  Some models with 
crossed effects can be handled by specifying a model with a single 
group. 
 
The data are partitioned into disjoint groups.  The probability model 
for group i is: 
 
Y = X*beta + Z*gamma + epsilon 
 
where 
 
* n_i is the number of observations in group i 
 
* Y is a n_i dimensional response vector (called endog in MixedLM) 
 
* X is a n_i x k_fe dimensional design matrix for the fixed effects 
  (called exog in MixedLM) 
 
* beta is a k_fe-dimensional vector of fixed effects parameters 
  (called fe_params in MixedLM) 
 
* Z is a design matrix for the random effects with n_i rows (called 
  exog_re in MixedLM).  The number of columns in Z can vary by group 
  as discussed below. 
 
* gamma is a random vector with mean 0.  The covariance matrix for the 
  first `k_re` elements of `gamma` (called cov_re in MixedLM) is 
  common to all groups.  The remaining elements of `gamma` are 
  variance components as discussed in more detail below. Each group 
  receives its own independent realization of gamma. 
 
* epsilon is a n_i dimensional vector of iid normal 
  errors with mean 0 and variance sigma^2; the epsilon 
  values are independent both within and between groups 
 
Y, X and Z must be entirely observed.  beta, Psi, and sigma^2 are 
estimated using ML or REML estimation, and gamma and epsilon are 
random so define the probability model. 
 
The marginal mean structure is E[Y | X, Z] = X*beta.  If only the mean 
structure is of interest, GEE is an alternative to using linear mixed 
models. 
 
Two types of random effects are supported.  Standard random effects 
are correlated with each other in arbitrary ways.  Every group has the 
same number (`k_re`) of standard random effects, with the same joint 
distribution (but with independent realizations across the groups). 
 
Variance components are uncorrelated with each other, and with the 
standard random effects.  Each variance component has mean zero, and 
all realizations of a given variance component have the same variance 
parameter.  The number of realized variance components per variance 
parameter can differ across the groups. 
 
The primary reference for the implementation details is: 
 
MJ Lindstrom, DM Bates (1988).  &quot;Newton Raphson and EM algorithms for 
linear mixed effects models for repeated measures data&quot;.  Journal of 
the American Statistical Association. Volume 83, Issue 404, pages 
1014-1022. 
 
See also this more recent document: 
 
http://econ.ucsb.edu/~doug/245a/Papers/Mixed%20Effects%20Implement.pdf 
 
All the likelihood, gradient, and Hessian calculations closely follow 
Lindstrom and Bates 1988, adapted to support variance components. 
 
The following two documents are written more from the perspective of 
users: 
 
http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf 
 
http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/3Longitudinal-4.pdf 
 
Notation: 
 
* `cov_re` is the random effects covariance matrix (referred to above 
  as Psi) and `scale` is the (scalar) error variance.  For a single 
  group, the marginal covariance matrix of endog given exog is scale*I 
  + Z * cov_re * Z', where Z is the design matrix for the random 
  effects in one group. 
 
* `vcomp` is a vector of variance parameters.  The length of `vcomp` 
  is determined by the number of keys in either the `exog_vc` argument 
  to ``MixedLM``, or the `vc_formula` argument when using formulas to 
  fit a model. 
 
Notes: 
 
1. Three different parameterizations are used in different places. 
The regression slopes (usually called `fe_params`) are identical in 
all three parameterizations, but the variance parameters differ.  The 
parameterizations are: 
 
* The &quot;user parameterization&quot; in which cov(endog) = scale*I + Z * 
  cov_re * Z', as described above.  This is the main parameterization 
  visible to the user. 
 
* The &quot;profile parameterization&quot; in which cov(endog) = I + 
  Z * cov_re1 * Z'.  This is the parameterization of the profile 
  likelihood that is maximized to produce parameter estimates. 
  (see Lindstrom and Bates for details).  The &quot;user&quot; cov_re is 
  equal to the &quot;profile&quot; cov_re1 times the scale. 
 
* The &quot;square root parameterization&quot; in which we work with the Cholesky 
  factor of cov_re1 instead of cov_re directly.  This is hidden from the 
  user. 
 
All three parameterizations can be packed into a vector by 
(optionally) concatenating `fe_params` together with the lower 
triangle or Cholesky square root of the dependence structure, followed 
by the variance parameters for the variance components.  The are 
stored as square roots if (and only if) the random effects covariance 
matrix is stored as its Cholesky factor.  Note that when unpacking, it 
is important to either square or reflect the dependence structure 
depending on which parameterization is being used. 
 
Two score methods are implemented.  One takes the score with respect 
to the elements of the random effects covariance matrix (used for 
inference once the MLE is reached), and the other takes the score with 
respect to the parameters of the Cholesky square root of the random 
effects covariance matrix (used for optimization). 
 
The numerical optimization uses GLS to avoid explicitly optimizing 
over the fixed effects parameters.  The likelihood that is optimized 
is profiled over both the scale parameter (a scalar) and the fixed 
effects parameters (if any).  As a result of this profiling, it is 
difficult and unnecessary to calculate the Hessian of the profiled log 
likelihood function, so that calculation is not implemented here. 
Therefore, optimization methods requiring the Hessian matrix such as 
the Newton-Raphson algorithm cannot be used for model fitting. 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">patsy</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">sparse</span>
<span class="s2">from </span><span class="s1">scipy.stats.distributions </span><span class="s2">import </span><span class="s1">norm</span>

<span class="s2">from </span><span class="s1">statsmodels.base._penalties </span><span class="s2">import </span><span class="s1">Penalty</span>
<span class="s2">import </span><span class="s1">statsmodels.base.model </span><span class="s2">as </span><span class="s1">base</span>
<span class="s2">from </span><span class="s1">statsmodels.tools </span><span class="s2">import </span><span class="s1">data </span><span class="s2">as </span><span class="s1">data_tools</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">ConvergenceWarning</span>

<span class="s1">_warn_cov_sing = </span><span class="s3">&quot;The random effects covariance matrix is singular.&quot;</span>


<span class="s2">def </span><span class="s1">_dot(x</span><span class="s2">, </span><span class="s1">y):</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns the dot product of the arrays, works for sparse and dense. 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">np.ndarray) </span><span class="s2">and </span><span class="s1">isinstance(y</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
        <span class="s2">return </span><span class="s1">np.dot(x</span><span class="s2">, </span><span class="s1">y)</span>
    <span class="s2">elif </span><span class="s1">sparse.issparse(x):</span>
        <span class="s2">return </span><span class="s1">x.dot(y)</span>
    <span class="s2">elif </span><span class="s1">sparse.issparse(y):</span>
        <span class="s2">return </span><span class="s1">y.T.dot(x.T).T</span>


<span class="s4"># From numpy, adapted to work with sparse and dense arrays.</span>
<span class="s2">def </span><span class="s1">_multi_dot_three(A</span><span class="s2">, </span><span class="s1">B</span><span class="s2">, </span><span class="s1">C):</span>
    <span class="s0">&quot;&quot;&quot; 
    Find best ordering for three arrays and do the multiplication. 
 
    Doing in manually instead of using dynamic programing is 
    approximately 15 times faster. 
    &quot;&quot;&quot;</span>
    <span class="s4"># cost1 = cost((AB)C)</span>
    <span class="s1">cost1 = (A.shape[</span><span class="s5">0</span><span class="s1">] * A.shape[</span><span class="s5">1</span><span class="s1">] * B.shape[</span><span class="s5">1</span><span class="s1">] +  </span><span class="s4"># (AB)</span>
             <span class="s1">A.shape[</span><span class="s5">0</span><span class="s1">] * B.shape[</span><span class="s5">1</span><span class="s1">] * C.shape[</span><span class="s5">1</span><span class="s1">])   </span><span class="s4"># (--)C</span>
    <span class="s4"># cost2 = cost((AB)C)</span>
    <span class="s1">cost2 = (B.shape[</span><span class="s5">0</span><span class="s1">] * B.shape[</span><span class="s5">1</span><span class="s1">] * C.shape[</span><span class="s5">1</span><span class="s1">] +  </span><span class="s4"># (BC)</span>
             <span class="s1">A.shape[</span><span class="s5">0</span><span class="s1">] * A.shape[</span><span class="s5">1</span><span class="s1">] * C.shape[</span><span class="s5">1</span><span class="s1">])   </span><span class="s4"># A(--)</span>

    <span class="s2">if </span><span class="s1">cost1 &lt; cost2:</span>
        <span class="s2">return </span><span class="s1">_dot(_dot(A</span><span class="s2">, </span><span class="s1">B)</span><span class="s2">, </span><span class="s1">C)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">_dot(A</span><span class="s2">, </span><span class="s1">_dot(B</span><span class="s2">, </span><span class="s1">C))</span>


<span class="s2">def </span><span class="s1">_dotsum(x</span><span class="s2">, </span><span class="s1">y):</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns sum(x * y), where '*' is the pointwise product, computed 
    efficiently for dense and sparse matrices. 
    &quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">sparse.issparse(x):</span>
        <span class="s2">return </span><span class="s1">x.multiply(y).sum()</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s4"># This way usually avoids allocating a temporary.</span>
        <span class="s2">return </span><span class="s1">np.dot(x.ravel()</span><span class="s2">, </span><span class="s1">y.ravel())</span>


<span class="s2">class </span><span class="s1">VCSpec:</span>
    <span class="s0">&quot;&quot;&quot; 
    Define the variance component structure of a multilevel model. 
 
    An instance of the class contains three attributes: 
 
    - names : names[k] is the name of variance component k. 
 
    - mats : mats[k][i] is the design matrix for group index 
      i in variance component k. 
 
    - colnames : colnames[k][i] is the list of column names for 
      mats[k][i]. 
 
    The groups in colnames and mats must be in sorted order. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">names</span><span class="s2">, </span><span class="s1">colnames</span><span class="s2">, </span><span class="s1">mats):</span>
        <span class="s1">self.names = names</span>
        <span class="s1">self.colnames = colnames</span>
        <span class="s1">self.mats = mats</span>


<span class="s2">def </span><span class="s1">_get_exog_re_names(self</span><span class="s2">, </span><span class="s1">exog_re):</span>
    <span class="s0">&quot;&quot;&quot; 
    Passes through if given a list of names. Otherwise, gets pandas names 
    or creates some generic variable names as needed. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">self.k_re == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">[]</span>
    <span class="s2">if </span><span class="s1">isinstance(exog_re</span><span class="s2">, </span><span class="s1">pd.DataFrame):</span>
        <span class="s2">return </span><span class="s1">exog_re.columns.tolist()</span>
    <span class="s2">elif </span><span class="s1">isinstance(exog_re</span><span class="s2">, </span><span class="s1">pd.Series) </span><span class="s2">and </span><span class="s1">exog_re.name </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">[exog_re.name]</span>
    <span class="s2">elif </span><span class="s1">isinstance(exog_re</span><span class="s2">, </span><span class="s1">list):</span>
        <span class="s2">return </span><span class="s1">exog_re</span>

    <span class="s4"># Default names</span>
    <span class="s1">defnames = [</span><span class="s3">&quot;x_re{0:1d}&quot;</span><span class="s1">.format(k + </span><span class="s5">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(exog_re.shape[</span><span class="s5">1</span><span class="s1">])]</span>
    <span class="s2">return </span><span class="s1">defnames</span>


<span class="s2">class </span><span class="s1">MixedLMParams:</span>
    <span class="s0">&quot;&quot;&quot; 
    This class represents a parameter state for a mixed linear model. 
 
    Parameters 
    ---------- 
    k_fe : int 
        The number of covariates with fixed effects. 
    k_re : int 
        The number of covariates with random coefficients (excluding 
        variance components). 
    k_vc : int 
        The number of variance components parameters. 
 
    Notes 
    ----- 
    This object represents the parameter state for the model in which 
    the scale parameter has been profiled out. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">k_vc):</span>

        <span class="s1">self.k_fe = k_fe</span>
        <span class="s1">self.k_re = k_re</span>
        <span class="s1">self.k_re2 = k_re * (k_re + </span><span class="s5">1</span><span class="s1">) // </span><span class="s5">2</span>
        <span class="s1">self.k_vc = k_vc</span>
        <span class="s1">self.k_tot = self.k_fe + self.k_re2 + self.k_vc</span>
        <span class="s1">self._ix = np.tril_indices(self.k_re)</span>

    <span class="s2">def </span><span class="s1">from_packed(params</span><span class="s2">, </span><span class="s1">k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">use_sqrt</span><span class="s2">, </span><span class="s1">has_fe):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create a MixedLMParams object from packed parameter vector. 
 
        Parameters 
        ---------- 
        params : array_like 
            The mode parameters packed into a single vector. 
        k_fe : int 
            The number of covariates with fixed effects 
        k_re : int 
            The number of covariates with random effects (excluding 
            variance components). 
        use_sqrt : bool 
            If True, the random effects covariance matrix is provided 
            as its Cholesky factor, otherwise the lower triangle of 
            the covariance matrix is stored. 
        has_fe : bool 
            If True, `params` contains fixed effects parameters. 
            Otherwise, the fixed effects parameters are set to zero. 
 
        Returns 
        ------- 
        A MixedLMParams object. 
        &quot;&quot;&quot;</span>
        <span class="s1">k_re2 = int(k_re * (k_re + </span><span class="s5">1</span><span class="s1">) / </span><span class="s5">2</span><span class="s1">)</span>

        <span class="s4"># The number of covariance parameters.</span>
        <span class="s2">if </span><span class="s1">has_fe:</span>
            <span class="s1">k_vc = len(params) - k_fe - k_re2</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">k_vc = len(params) - k_re2</span>

        <span class="s1">pa = MixedLMParams(k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">k_vc)</span>

        <span class="s1">cov_re = np.zeros((k_re</span><span class="s2">, </span><span class="s1">k_re))</span>
        <span class="s1">ix = pa._ix</span>
        <span class="s2">if </span><span class="s1">has_fe:</span>
            <span class="s1">pa.fe_params = params[</span><span class="s5">0</span><span class="s1">:k_fe]</span>
            <span class="s1">cov_re[ix] = params[k_fe:k_fe+k_re2]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">pa.fe_params = np.zeros(k_fe)</span>
            <span class="s1">cov_re[ix] = params[</span><span class="s5">0</span><span class="s1">:k_re2]</span>

        <span class="s2">if </span><span class="s1">use_sqrt:</span>
            <span class="s1">cov_re = np.dot(cov_re</span><span class="s2">, </span><span class="s1">cov_re.T)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cov_re = (cov_re + cov_re.T) - np.diag(np.diag(cov_re))</span>

        <span class="s1">pa.cov_re = cov_re</span>
        <span class="s2">if </span><span class="s1">k_vc &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">use_sqrt:</span>
                <span class="s1">pa.vcomp = params[-k_vc:]**</span><span class="s5">2</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">pa.vcomp = params[-k_vc:]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">pa.vcomp = np.array([])</span>

        <span class="s2">return </span><span class="s1">pa</span>

    <span class="s1">from_packed = staticmethod(from_packed)</span>

    <span class="s2">def </span><span class="s1">from_components(fe_params=</span><span class="s2">None, </span><span class="s1">cov_re=</span><span class="s2">None, </span><span class="s1">cov_re_sqrt=</span><span class="s2">None,</span>
                        <span class="s1">vcomp=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create a MixedLMParams object from each parameter component. 
 
        Parameters 
        ---------- 
        fe_params : array_like 
            The fixed effects parameter (a 1-dimensional array).  If 
            None, there are no fixed effects. 
        cov_re : array_like 
            The random effects covariance matrix (a square, symmetric 
            2-dimensional array). 
        cov_re_sqrt : array_like 
            The Cholesky (lower triangular) square root of the random 
            effects covariance matrix. 
        vcomp : array_like 
            The variance component parameters.  If None, there are no 
            variance components. 
 
        Returns 
        ------- 
        A MixedLMParams object. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">vcomp </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">vcomp = np.empty(</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">fe_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">fe_params = np.empty(</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">cov_re </span><span class="s2">is None and </span><span class="s1">cov_re_sqrt </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov_re = np.empty((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>

        <span class="s1">k_fe = len(fe_params)</span>
        <span class="s1">k_vc = len(vcomp)</span>
        <span class="s1">k_re = cov_re.shape[</span><span class="s5">0</span><span class="s1">] </span><span class="s2">if </span><span class="s1">cov_re </span><span class="s2">is not None else </span><span class="s1">cov_re_sqrt.shape[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">pa = MixedLMParams(k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">k_vc)</span>
        <span class="s1">pa.fe_params = fe_params</span>
        <span class="s2">if </span><span class="s1">cov_re_sqrt </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">pa.cov_re = np.dot(cov_re_sqrt</span><span class="s2">, </span><span class="s1">cov_re_sqrt.T)</span>
        <span class="s2">elif </span><span class="s1">cov_re </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">pa.cov_re = cov_re</span>

        <span class="s1">pa.vcomp = vcomp</span>

        <span class="s2">return </span><span class="s1">pa</span>

    <span class="s1">from_components = staticmethod(from_components)</span>

    <span class="s2">def </span><span class="s1">copy(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a copy of the object. 
        &quot;&quot;&quot;</span>
        <span class="s1">obj = MixedLMParams(self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.k_vc)</span>
        <span class="s1">obj.fe_params = self.fe_params.copy()</span>
        <span class="s1">obj.cov_re = self.cov_re.copy()</span>
        <span class="s1">obj.vcomp = self.vcomp.copy()</span>
        <span class="s2">return </span><span class="s1">obj</span>

    <span class="s2">def </span><span class="s1">get_packed(self</span><span class="s2">, </span><span class="s1">use_sqrt</span><span class="s2">, </span><span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the model parameters packed into a single vector. 
 
        Parameters 
        ---------- 
        use_sqrt : bool 
            If True, the Cholesky square root of `cov_re` is 
            included in the packed result.  Otherwise the 
            lower triangle of `cov_re` is included. 
        has_fe : bool 
            If True, the fixed effects parameters are included 
            in the packed result, otherwise they are omitted. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">use_sqrt:</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">L = np.linalg.cholesky(self.cov_re)</span>
                <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                    <span class="s1">L = np.diag(np.sqrt(np.diag(self.cov_re)))</span>
                <span class="s1">cpa = L[self._ix]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">cpa = self.cov_re[self._ix]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cpa = np.zeros(</span><span class="s5">0</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">use_sqrt:</span>
            <span class="s1">vcomp = np.sqrt(self.vcomp)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">vcomp = self.vcomp</span>

        <span class="s2">if </span><span class="s1">has_fe:</span>
            <span class="s1">pa = np.concatenate((self.fe_params</span><span class="s2">, </span><span class="s1">cpa</span><span class="s2">, </span><span class="s1">vcomp))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">pa = np.concatenate((cpa</span><span class="s2">, </span><span class="s1">vcomp))</span>

        <span class="s2">return </span><span class="s1">pa</span>


<span class="s2">def </span><span class="s1">_smw_solver(s</span><span class="s2">, </span><span class="s1">A</span><span class="s2">, </span><span class="s1">AtA</span><span class="s2">, </span><span class="s1">Qi</span><span class="s2">, </span><span class="s1">di):</span>
    <span class="s0">r&quot;&quot;&quot; 
    Returns a solver for the linear system: 
 
    .. math:: 
 
        (sI + ABA^\prime) y = x 
 
    The returned function f satisfies f(x) = y as defined above. 
 
    B and its inverse matrix are block diagonal.  The upper left block 
    of :math:`B^{-1}` is Qi and its lower right block is diag(di). 
 
    Parameters 
    ---------- 
    s : scalar 
        See above for usage 
    A : ndarray 
        p x q matrix, in general q &lt;&lt; p, may be sparse. 
    AtA : square ndarray 
        :math:`A^\prime  A`, a q x q matrix. 
    Qi : square symmetric ndarray 
        The matrix `B` is q x q, where q = r + d.  `B` consists of a r 
        x r diagonal block whose inverse is `Qi`, and a d x d diagonal 
        block, whose inverse is diag(di). 
    di : 1d array_like 
        See documentation for Qi. 
 
    Returns 
    ------- 
    A function for solving a linear system, as documented above. 
 
    Notes 
    ----- 
    Uses Sherman-Morrison-Woodbury identity: 
        https://en.wikipedia.org/wiki/Woodbury_matrix_identity 
    &quot;&quot;&quot;</span>

    <span class="s4"># Use SMW identity</span>
    <span class="s1">qmat = AtA / s</span>
    <span class="s1">m = Qi.shape[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">qmat[</span><span class="s5">0</span><span class="s1">:m</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:m] += Qi</span>

    <span class="s2">if </span><span class="s1">sparse.issparse(A):</span>
        <span class="s1">qmat[m:</span><span class="s2">, </span><span class="s1">m:] += sparse.diags(di)</span>

        <span class="s2">def </span><span class="s1">solver(rhs):</span>
            <span class="s1">ql = A.T.dot(rhs)</span>
            <span class="s4"># Based on profiling, the next line can be the</span>
            <span class="s4"># majority of the entire run time of fitting the model.</span>
            <span class="s1">ql = sparse.linalg.spsolve(qmat</span><span class="s2">, </span><span class="s1">ql)</span>
            <span class="s2">if </span><span class="s1">ql.ndim &lt; rhs.ndim:</span>
                <span class="s4"># spsolve squeezes nx1 rhs</span>
                <span class="s1">ql = ql[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s1">ql = A.dot(ql)</span>
            <span class="s2">return </span><span class="s1">rhs / s - ql / s**</span><span class="s5">2</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">d = qmat.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">qmat.flat[m*(d+</span><span class="s5">1</span><span class="s1">)::d+</span><span class="s5">1</span><span class="s1">] += di</span>
        <span class="s1">qmati = np.linalg.solve(qmat</span><span class="s2">, </span><span class="s1">A.T)</span>

        <span class="s2">def </span><span class="s1">solver(rhs):</span>
            <span class="s4"># A is tall and qmati is wide, so we want</span>
            <span class="s4"># A * (qmati * rhs) not (A * qmati) * rhs</span>
            <span class="s1">ql = np.dot(qmati</span><span class="s2">, </span><span class="s1">rhs)</span>
            <span class="s1">ql = np.dot(A</span><span class="s2">, </span><span class="s1">ql)</span>
            <span class="s2">return </span><span class="s1">rhs / s - ql / s**</span><span class="s5">2</span>

    <span class="s2">return </span><span class="s1">solver</span>


<span class="s2">def </span><span class="s1">_smw_logdet(s</span><span class="s2">, </span><span class="s1">A</span><span class="s2">, </span><span class="s1">AtA</span><span class="s2">, </span><span class="s1">Qi</span><span class="s2">, </span><span class="s1">di</span><span class="s2">, </span><span class="s1">B_logdet):</span>
    <span class="s0">r&quot;&quot;&quot; 
    Returns the log determinant of 
 
    .. math:: 
 
        sI + ABA^\prime 
 
    Uses the matrix determinant lemma to accelerate the calculation. 
    B is assumed to be positive definite, and s &gt; 0, therefore the 
    determinant is positive. 
 
    Parameters 
    ---------- 
    s : positive scalar 
        See above for usage 
    A : ndarray 
        p x q matrix, in general q &lt;&lt; p. 
    AtA : square ndarray 
        :math:`A^\prime  A`, a q x q matrix. 
    Qi : square symmetric ndarray 
        The matrix `B` is q x q, where q = r + d.  `B` consists of a r 
        x r diagonal block whose inverse is `Qi`, and a d x d diagonal 
        block, whose inverse is diag(di). 
    di : 1d array_like 
        See documentation for Qi. 
    B_logdet : real 
        The log determinant of B 
 
    Returns 
    ------- 
    The log determinant of s*I + A*B*A'. 
 
    Notes 
    ----- 
    Uses the matrix determinant lemma: 
        https://en.wikipedia.org/wiki/Matrix_determinant_lemma 
    &quot;&quot;&quot;</span>

    <span class="s1">p = A.shape[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">ld = p * np.log(s)</span>
    <span class="s1">qmat = AtA / s</span>
    <span class="s1">m = Qi.shape[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">qmat[</span><span class="s5">0</span><span class="s1">:m</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:m] += Qi</span>

    <span class="s2">if </span><span class="s1">sparse.issparse(qmat):</span>
        <span class="s1">qmat[m:</span><span class="s2">, </span><span class="s1">m:] += sparse.diags(di)</span>

        <span class="s4"># There are faster but much more difficult ways to do this</span>
        <span class="s4"># https://stackoverflow.com/questions/19107617</span>
        <span class="s1">lu = sparse.linalg.splu(qmat)</span>
        <span class="s1">dl = lu.L.diagonal().astype(np.complex128)</span>
        <span class="s1">du = lu.U.diagonal().astype(np.complex128)</span>
        <span class="s1">ld1 = np.log(dl).sum() + np.log(du).sum()</span>
        <span class="s1">ld1 = ld1.real</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">d = qmat.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">qmat.flat[m*(d+</span><span class="s5">1</span><span class="s1">)::d+</span><span class="s5">1</span><span class="s1">] += di</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">ld1 = np.linalg.slogdet(qmat)</span>

    <span class="s2">return </span><span class="s1">B_logdet + ld + ld1</span>


<span class="s2">def </span><span class="s1">_convert_vc(exog_vc):</span>

    <span class="s1">vc_names = []</span>
    <span class="s1">vc_colnames = []</span>
    <span class="s1">vc_mats = []</span>

    <span class="s4"># Get the groups in sorted order</span>
    <span class="s1">groups = set()</span>
    <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">exog_vc.items():</span>
        <span class="s1">groups |= set(v.keys())</span>
    <span class="s1">groups = list(groups)</span>
    <span class="s1">groups.sort()</span>

    <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">exog_vc.items():</span>
        <span class="s1">vc_names.append(k)</span>
        <span class="s1">colnames</span><span class="s2">, </span><span class="s1">mats = []</span><span class="s2">, </span><span class="s1">[]</span>
        <span class="s2">for </span><span class="s1">g </span><span class="s2">in </span><span class="s1">groups:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">colnames.append(v[g].columns)</span>
            <span class="s2">except </span><span class="s1">AttributeError:</span>
                <span class="s1">colnames.append([str(j) </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(v[g].shape[</span><span class="s5">1</span><span class="s1">])])</span>
            <span class="s1">mats.append(v[g])</span>
        <span class="s1">vc_colnames.append(colnames)</span>
        <span class="s1">vc_mats.append(mats)</span>

    <span class="s1">ii = np.argsort(vc_names)</span>
    <span class="s1">vc_names = [vc_names[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">ii]</span>
    <span class="s1">vc_colnames = [vc_colnames[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">ii]</span>
    <span class="s1">vc_mats = [vc_mats[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">ii]</span>

    <span class="s2">return </span><span class="s1">VCSpec(vc_names</span><span class="s2">, </span><span class="s1">vc_colnames</span><span class="s2">, </span><span class="s1">vc_mats)</span>


<span class="s2">class </span><span class="s1">MixedLM(base.LikelihoodModel):</span>
    <span class="s0">&quot;&quot;&quot; 
    Linear Mixed Effects Model 
 
    Parameters 
    ---------- 
    endog : 1d array_like 
        The dependent variable 
    exog : 2d array_like 
        A matrix of covariates used to determine the 
        mean structure (the &quot;fixed effects&quot; covariates). 
    groups : 1d array_like 
        A vector of labels determining the groups -- data from 
        different groups are independent 
    exog_re : 2d array_like 
        A matrix of covariates used to determine the variance and 
        covariance structure (the &quot;random effects&quot; covariates).  If 
        None, defaults to a random intercept for each group. 
    exog_vc : VCSpec instance or dict-like (deprecated) 
        A VCSPec instance defines the structure of the variance 
        components in the model.  Alternatively, see notes below 
        for a dictionary-based format.  The dictionary format is 
        deprecated and may be removed at some point in the future. 
    use_sqrt : bool 
        If True, optimization is carried out using the lower 
        triangle of the square root of the random effects 
        covariance matrix, otherwise it is carried out using the 
        lower triangle of the random effects covariance matrix. 
    missing : str 
        The approach to missing data handling 
 
    Notes 
    ----- 
    If `exog_vc` is not a `VCSpec` instance, then it must be a 
    dictionary of dictionaries.  Specifically, `exog_vc[a][g]` is a 
    matrix whose columns are linearly combined using independent 
    random coefficients.  This random term then contributes to the 
    variance structure of the data for group `g`.  The random 
    coefficients all have mean zero, and have the same variance.  The 
    matrix must be `m x k`, where `m` is the number of observations in 
    group `g`.  The number of columns may differ among the top-level 
    groups. 
 
    The covariates in `exog`, `exog_re` and `exog_vc` may (but need 
    not) partially or wholly overlap. 
 
    `use_sqrt` should almost always be set to True.  The main use case 
    for use_sqrt=False is when complicated patterns of fixed values in 
    the covariance structure are set (using the `free` argument to 
    `fit`) that cannot be expressed in terms of the Cholesky factor L. 
 
    Examples 
    -------- 
    A basic mixed model with fixed effects for the columns of 
    ``exog`` and a random intercept for each distinct value of 
    ``group``: 
 
    &gt;&gt;&gt; model = sm.MixedLM(endog, exog, groups) 
    &gt;&gt;&gt; result = model.fit() 
 
    A mixed model with fixed effects for the columns of ``exog`` and 
    correlated random coefficients for the columns of ``exog_re``: 
 
    &gt;&gt;&gt; model = sm.MixedLM(endog, exog, groups, exog_re=exog_re) 
    &gt;&gt;&gt; result = model.fit() 
 
    A mixed model with fixed effects for the columns of ``exog`` and 
    independent random coefficients for the columns of ``exog_re``: 
 
    &gt;&gt;&gt; free = MixedLMParams.from_components( 
                     fe_params=np.ones(exog.shape[1]), 
                     cov_re=np.eye(exog_re.shape[1])) 
    &gt;&gt;&gt; model = sm.MixedLM(endog, exog, groups, exog_re=exog_re) 
    &gt;&gt;&gt; result = model.fit(free=free) 
 
    A different way to specify independent random coefficients for the 
    columns of ``exog_re``.  In this example ``groups`` must be a 
    Pandas Series with compatible indexing with ``exog_re``, and 
    ``exog_re`` has two columns. 
 
    &gt;&gt;&gt; g = pd.groupby(groups, by=groups).groups 
    &gt;&gt;&gt; vc = {} 
    &gt;&gt;&gt; vc['1'] = {k : exog_re.loc[g[k], 0] for k in g} 
    &gt;&gt;&gt; vc['2'] = {k : exog_re.loc[g[k], 1] for k in g} 
    &gt;&gt;&gt; model = sm.MixedLM(endog, exog, groups, vcomp=vc) 
    &gt;&gt;&gt; result = model.fit() 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">exog_re=</span><span class="s2">None,</span>
                 <span class="s1">exog_vc=</span><span class="s2">None, </span><span class="s1">use_sqrt=</span><span class="s2">True, </span><span class="s1">missing=</span><span class="s3">'none'</span><span class="s2">,</span>
                 <span class="s1">**kwargs):</span>

        <span class="s1">_allowed_kwargs = [</span><span class="s3">&quot;missing_idx&quot;</span><span class="s2">, </span><span class="s3">&quot;design_info&quot;</span><span class="s2">, </span><span class="s3">&quot;formula&quot;</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">kwargs.keys():</span>
            <span class="s2">if </span><span class="s1">x </span><span class="s2">not in </span><span class="s1">_allowed_kwargs:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;argument %s not permitted for MixedLM initialization&quot; </span><span class="s1">% x)</span>

        <span class="s1">self.use_sqrt = use_sqrt</span>

        <span class="s4"># Some defaults</span>
        <span class="s1">self.reml = </span><span class="s2">True</span>
        <span class="s1">self.fe_pen = </span><span class="s2">None</span>
        <span class="s1">self.re_pen = </span><span class="s2">None</span>

        <span class="s2">if </span><span class="s1">isinstance(exog_vc</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;Using deprecated variance components format&quot;</span><span class="s1">)</span>
            <span class="s4"># Convert from old to new representation</span>
            <span class="s1">exog_vc = _convert_vc(exog_vc)</span>

        <span class="s2">if </span><span class="s1">exog_vc </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.k_vc = len(exog_vc.names)</span>
            <span class="s1">self.exog_vc = exog_vc</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.k_vc = </span><span class="s5">0</span>
            <span class="s1">self.exog_vc = VCSpec([]</span><span class="s2">, </span><span class="s1">[]</span><span class="s2">, </span><span class="s1">[])</span>

        <span class="s4"># If there is one covariate, it may be passed in as a column</span>
        <span class="s4"># vector, convert these to 2d arrays.</span>
        <span class="s4"># TODO: Can this be moved up in the class hierarchy?</span>
        <span class="s4">#       yes, it should be done up the hierarchy</span>
        <span class="s2">if </span><span class="s1">(exog </span><span class="s2">is not None and</span>
                <span class="s1">data_tools._is_using_ndarray_type(exog</span><span class="s2">, None</span><span class="s1">) </span><span class="s2">and</span>
                <span class="s1">exog.ndim == </span><span class="s5">1</span><span class="s1">):</span>
            <span class="s1">exog = exog[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">(exog_re </span><span class="s2">is not None and</span>
                <span class="s1">data_tools._is_using_ndarray_type(exog_re</span><span class="s2">, None</span><span class="s1">) </span><span class="s2">and</span>
                <span class="s1">exog_re.ndim == </span><span class="s5">1</span><span class="s1">):</span>
            <span class="s1">exog_re = exog_re[:</span><span class="s2">, None</span><span class="s1">]</span>

        <span class="s4"># Calling super creates self.endog, etc. as ndarrays and the</span>
        <span class="s4"># original exog, endog, etc. are self.data.endog, etc.</span>
        <span class="s1">super(MixedLM</span><span class="s2">, </span><span class="s1">self).__init__(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups=groups</span><span class="s2">,</span>
                                      <span class="s1">exog_re=exog_re</span><span class="s2">, </span><span class="s1">missing=missing</span><span class="s2">,</span>
                                      <span class="s1">**kwargs)</span>

        <span class="s1">self._init_keys.extend([</span><span class="s3">&quot;use_sqrt&quot;</span><span class="s2">, </span><span class="s3">&quot;exog_vc&quot;</span><span class="s1">])</span>

        <span class="s4"># Number of fixed effects parameters</span>
        <span class="s1">self.k_fe = exog.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">exog_re </span><span class="s2">is None and </span><span class="s1">len(self.exog_vc.names) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># Default random effects structure (random intercepts).</span>
            <span class="s1">self.k_re = </span><span class="s5">1</span>
            <span class="s1">self.k_re2 = </span><span class="s5">1</span>
            <span class="s1">self.exog_re = np.ones((len(endog)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
            <span class="s1">self.data.exog_re = self.exog_re</span>
            <span class="s1">names = [</span><span class="s3">'Group Var'</span><span class="s1">]</span>
            <span class="s1">self.data.param_names = self.exog_names + names</span>
            <span class="s1">self.data.exog_re_names = names</span>
            <span class="s1">self.data.exog_re_names_full = names</span>

        <span class="s2">elif </span><span class="s1">exog_re </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s4"># Process exog_re the same way that exog is handled</span>
            <span class="s4"># upstream</span>
            <span class="s4"># TODO: this is wrong and should be handled upstream wholly</span>
            <span class="s1">self.data.exog_re = exog_re</span>
            <span class="s1">self.exog_re = np.asarray(exog_re)</span>
            <span class="s2">if </span><span class="s1">self.exog_re.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">self.exog_re = self.exog_re[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s4"># Model dimensions</span>
            <span class="s4"># Number of random effect covariates</span>
            <span class="s1">self.k_re = self.exog_re.shape[</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s4"># Number of covariance parameters</span>
            <span class="s1">self.k_re2 = self.k_re * (self.k_re + </span><span class="s5">1</span><span class="s1">) // </span><span class="s5">2</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># All random effects are variance components</span>
            <span class="s1">self.k_re = </span><span class="s5">0</span>
            <span class="s1">self.k_re2 = </span><span class="s5">0</span>

        <span class="s2">if not </span><span class="s1">self.data._param_names:</span>
            <span class="s4"># HACK: could have been set in from_formula already</span>
            <span class="s4"># needs refactor</span>
            <span class="s1">(param_names</span><span class="s2">, </span><span class="s1">exog_re_names</span><span class="s2">,</span>
             <span class="s1">exog_re_names_full) = self._make_param_names(exog_re)</span>
            <span class="s1">self.data.param_names = param_names</span>
            <span class="s1">self.data.exog_re_names = exog_re_names</span>
            <span class="s1">self.data.exog_re_names_full = exog_re_names_full</span>

        <span class="s1">self.k_params = self.k_fe + self.k_re2</span>

        <span class="s4"># Convert the data to the internal representation, which is a</span>
        <span class="s4"># list of arrays, corresponding to the groups.</span>
        <span class="s1">group_labels = list(set(groups))</span>
        <span class="s1">group_labels.sort()</span>
        <span class="s1">row_indices = dict((s</span><span class="s2">, </span><span class="s1">[]) </span><span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">group_labels)</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">g </span><span class="s2">in </span><span class="s1">enumerate(groups):</span>
            <span class="s1">row_indices[g].append(i)</span>
        <span class="s1">self.row_indices = row_indices</span>
        <span class="s1">self.group_labels = group_labels</span>
        <span class="s1">self.n_groups = len(self.group_labels)</span>

        <span class="s4"># Split the data by groups</span>
        <span class="s1">self.endog_li = self.group_list(self.endog)</span>
        <span class="s1">self.exog_li = self.group_list(self.exog)</span>
        <span class="s1">self.exog_re_li = self.group_list(self.exog_re)</span>

        <span class="s4"># Precompute this.</span>
        <span class="s2">if </span><span class="s1">self.exog_re </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.exog_re2_li = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.exog_re2_li = [np.dot(x.T</span><span class="s2">, </span><span class="s1">x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.exog_re_li]</span>

        <span class="s4"># The total number of observations, summed over all groups</span>
        <span class="s1">self.nobs = len(self.endog)</span>
        <span class="s1">self.n_totobs = self.nobs</span>

        <span class="s4"># Set the fixed effects parameter names</span>
        <span class="s2">if </span><span class="s1">self.exog_names </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.exog_names = [</span><span class="s3">&quot;FE%d&quot; </span><span class="s1">% (k + </span><span class="s5">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in</span>
                               <span class="s1">range(self.exog.shape[</span><span class="s5">1</span><span class="s1">])]</span>

        <span class="s4"># Precompute this</span>
        <span class="s1">self._aex_r = []</span>
        <span class="s1">self._aex_r2 = []</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.n_groups):</span>
            <span class="s1">a = self._augment_exog(i)</span>
            <span class="s1">self._aex_r.append(a)</span>

            <span class="s1">ma = _dot(a.T</span><span class="s2">, </span><span class="s1">a)</span>
            <span class="s1">self._aex_r2.append(ma)</span>

        <span class="s4"># Precompute this</span>
        <span class="s1">self._lin</span><span class="s2">, </span><span class="s1">self._quad = self._reparam()</span>

    <span class="s2">def </span><span class="s1">_make_param_names(self</span><span class="s2">, </span><span class="s1">exog_re):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the full parameter names list, just the exogenous random 
        effects variables, and the exogenous random effects variables with 
        the interaction terms. 
        &quot;&quot;&quot;</span>
        <span class="s1">exog_names = list(self.exog_names)</span>
        <span class="s1">exog_re_names = _get_exog_re_names(self</span><span class="s2">, </span><span class="s1">exog_re)</span>
        <span class="s1">param_names = []</span>

        <span class="s1">jj = self.k_fe</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(exog_re_names)):</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(i + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s2">if </span><span class="s1">i == j:</span>
                    <span class="s1">param_names.append(exog_re_names[i] + </span><span class="s3">&quot; Var&quot;</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">param_names.append(exog_re_names[j] + </span><span class="s3">&quot; x &quot; </span><span class="s1">+</span>
                                       <span class="s1">exog_re_names[i] + </span><span class="s3">&quot; Cov&quot;</span><span class="s1">)</span>
                <span class="s1">jj += </span><span class="s5">1</span>

        <span class="s1">vc_names = [x + </span><span class="s3">&quot; Var&quot; </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.exog_vc.names]</span>

        <span class="s2">return </span><span class="s1">exog_names + param_names + vc_names</span><span class="s2">, </span><span class="s1">exog_re_names</span><span class="s2">, </span><span class="s1">param_names</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">from_formula(cls</span><span class="s2">, </span><span class="s1">formula</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">re_formula=</span><span class="s2">None, </span><span class="s1">vc_formula=</span><span class="s2">None,</span>
                     <span class="s1">subset=</span><span class="s2">None, </span><span class="s1">use_sparse=</span><span class="s2">False, </span><span class="s1">missing=</span><span class="s3">'none'</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">,</span>
                     <span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create a Model from a formula and dataframe. 
 
        Parameters 
        ---------- 
        formula : str or generic Formula object 
            The formula specifying the model 
        data : array_like 
            The data for the model. See Notes. 
        re_formula : str 
            A one-sided formula defining the variance structure of the 
            model.  The default gives a random intercept for each 
            group. 
        vc_formula : dict-like 
            Formulas describing variance components.  `vc_formula[vc]` is 
            the formula for the component with variance parameter named 
            `vc`.  The formula is processed into a matrix, and the columns 
            of this matrix are linearly combined with independent random 
            coefficients having mean zero and a common variance. 
        subset : array_like 
            An array-like object of booleans, integers, or index 
            values that indicate the subset of df to use in the 
            model. Assumes df is a `pandas.DataFrame` 
        missing : str 
            Either 'none' or 'drop' 
        args : extra arguments 
            These are passed to the model 
        kwargs : extra keyword arguments 
            These are passed to the model with one exception. The 
            ``eval_env`` keyword is passed to patsy. It can be either a 
            :class:`patsy:patsy.EvalEnvironment` object or an integer 
            indicating the depth of the namespace to use. For example, the 
            default ``eval_env=0`` uses the calling namespace. If you wish 
            to use a &quot;clean&quot; environment set ``eval_env=-1``. 
 
        Returns 
        ------- 
        model : Model instance 
 
        Notes 
        ----- 
        `data` must define __getitem__ with the keys in the formula 
        terms args and kwargs are passed on to the model 
        instantiation. E.g., a numpy structured or rec array, a 
        dictionary, or a pandas DataFrame. 
 
        If the variance component is intended to produce random 
        intercepts for disjoint subsets of a group, specified by 
        string labels or a categorical data value, always use '0 +' in 
        the formula so that no overall intercept is included. 
 
        If the variance components specify random slopes and you do 
        not also want a random group-level intercept in the model, 
        then use '0 +' in the formula to exclude the intercept. 
 
        The variance components formulas are processed separately for 
        each group.  If a variable is categorical the results will not 
        be affected by whether the group labels are distinct or 
        re-used over the top-level groups. 
 
        Examples 
        -------- 
        Suppose we have data from an educational study with students 
        nested in classrooms nested in schools.  The students take a 
        test, and we want to relate the test scores to the students' 
        ages, while accounting for the effects of classrooms and 
        schools.  The school will be the top-level group, and the 
        classroom is a nested group that is specified as a variance 
        component.  Note that the schools may have different number of 
        classrooms, and the classroom labels may (but need not be) 
        different across the schools. 
 
        &gt;&gt;&gt; vc = {'classroom': '0 + C(classroom)'} 
        &gt;&gt;&gt; MixedLM.from_formula('test_score ~ age', vc_formula=vc, \ 
                                  re_formula='1', groups='school', data=data) 
 
        Now suppose we also have a previous test score called 
        'pretest'.  If we want the relationship between pretest 
        scores and the current test to vary by classroom, we can 
        specify a random slope for the pretest score 
 
        &gt;&gt;&gt; vc = {'classroom': '0 + C(classroom)', 'pretest': '0 + pretest'} 
        &gt;&gt;&gt; MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc, \ 
                                  re_formula='1', groups='school', data=data) 
 
        The following model is almost equivalent to the previous one, 
        but here the classroom random intercept and pretest slope may 
        be correlated. 
 
        &gt;&gt;&gt; vc = {'classroom': '0 + C(classroom)'} 
        &gt;&gt;&gt; MixedLM.from_formula('test_score ~ age + pretest', vc_formula=vc, \ 
                                  re_formula='1 + pretest', groups='school', \ 
                                  data=data) 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s3">&quot;groups&quot; </span><span class="s2">not in </span><span class="s1">kwargs.keys():</span>
            <span class="s2">raise </span><span class="s1">AttributeError(</span><span class="s3">&quot;'groups' is a required keyword argument &quot; </span><span class="s1">+</span>
                                 <span class="s3">&quot;in MixedLM.from_formula&quot;</span><span class="s1">)</span>
        <span class="s1">groups = kwargs[</span><span class="s3">&quot;groups&quot;</span><span class="s1">]</span>

        <span class="s4"># If `groups` is a variable name, retrieve the data for the</span>
        <span class="s4"># groups variable.</span>
        <span class="s1">group_name = </span><span class="s3">&quot;Group&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(groups</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">group_name = groups</span>
            <span class="s1">groups = np.asarray(data[groups])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">groups = np.asarray(groups)</span>
        <span class="s2">del </span><span class="s1">kwargs[</span><span class="s3">&quot;groups&quot;</span><span class="s1">]</span>

        <span class="s4"># Bypass all upstream missing data handling to properly handle</span>
        <span class="s4"># variance components</span>
        <span class="s2">if </span><span class="s1">missing == </span><span class="s3">'drop'</span><span class="s1">:</span>
            <span class="s1">data</span><span class="s2">, </span><span class="s1">groups = _handle_missing(data</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">formula</span><span class="s2">, </span><span class="s1">re_formula</span><span class="s2">,</span>
                                           <span class="s1">vc_formula)</span>
            <span class="s1">missing = </span><span class="s3">'none'</span>

        <span class="s2">if </span><span class="s1">re_formula </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">re_formula.strip() == </span><span class="s3">&quot;1&quot;</span><span class="s1">:</span>
                <span class="s4"># Work around Patsy bug, fixed by 0.3.</span>
                <span class="s1">exog_re = np.ones((data.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
                <span class="s1">exog_re_names = [group_name]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">eval_env = kwargs.get(</span><span class="s3">'eval_env'</span><span class="s2">, None</span><span class="s1">)</span>
                <span class="s2">if </span><span class="s1">eval_env </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">eval_env = </span><span class="s5">1</span>
                <span class="s2">elif </span><span class="s1">eval_env == -</span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s2">from </span><span class="s1">patsy </span><span class="s2">import </span><span class="s1">EvalEnvironment</span>
                    <span class="s1">eval_env = EvalEnvironment({})</span>
                <span class="s1">exog_re = patsy.dmatrix(re_formula</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">eval_env=eval_env)</span>
                <span class="s1">exog_re_names = exog_re.design_info.column_names</span>
                <span class="s1">exog_re_names = [x.replace(</span><span class="s3">&quot;Intercept&quot;</span><span class="s2">, </span><span class="s1">group_name)</span>
                                 <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">exog_re_names]</span>
                <span class="s1">exog_re = np.asarray(exog_re)</span>
            <span class="s2">if </span><span class="s1">exog_re.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">exog_re = exog_re[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">exog_re = </span><span class="s2">None</span>
            <span class="s2">if </span><span class="s1">vc_formula </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">exog_re_names = [group_name]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">exog_re_names = []</span>

        <span class="s2">if </span><span class="s1">vc_formula </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">eval_env = kwargs.get(</span><span class="s3">'eval_env'</span><span class="s2">, None</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">eval_env </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">eval_env = </span><span class="s5">1</span>
            <span class="s2">elif </span><span class="s1">eval_env == -</span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">from </span><span class="s1">patsy </span><span class="s2">import </span><span class="s1">EvalEnvironment</span>
                <span class="s1">eval_env = EvalEnvironment({})</span>

            <span class="s1">vc_mats = []</span>
            <span class="s1">vc_colnames = []</span>
            <span class="s1">vc_names = []</span>
            <span class="s1">gb = data.groupby(groups)</span>
            <span class="s1">kylist = sorted(gb.groups.keys())</span>
            <span class="s1">vcf = sorted(vc_formula.keys())</span>
            <span class="s2">for </span><span class="s1">vc_name </span><span class="s2">in </span><span class="s1">vcf:</span>
                <span class="s1">md = patsy.ModelDesc.from_formula(vc_formula[vc_name])</span>
                <span class="s1">vc_names.append(vc_name)</span>
                <span class="s1">evc_mats</span><span class="s2">, </span><span class="s1">evc_colnames = []</span><span class="s2">, </span><span class="s1">[]</span>
                <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(kylist):</span>
                    <span class="s1">ii = gb.groups[group]</span>
                    <span class="s1">mat = patsy.dmatrix(</span>
                             <span class="s1">md</span><span class="s2">,</span>
                             <span class="s1">data.loc[ii</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">,</span>
                             <span class="s1">eval_env=eval_env</span><span class="s2">,</span>
                             <span class="s1">return_type=</span><span class="s3">'dataframe'</span><span class="s1">)</span>
                    <span class="s1">evc_colnames.append(mat.columns.tolist())</span>
                    <span class="s2">if </span><span class="s1">use_sparse:</span>
                        <span class="s1">evc_mats.append(sparse.csr_matrix(mat))</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">evc_mats.append(np.asarray(mat))</span>
                <span class="s1">vc_mats.append(evc_mats)</span>
                <span class="s1">vc_colnames.append(evc_colnames)</span>
            <span class="s1">exog_vc = VCSpec(vc_names</span><span class="s2">, </span><span class="s1">vc_colnames</span><span class="s2">, </span><span class="s1">vc_mats)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">exog_vc = VCSpec([]</span><span class="s2">, </span><span class="s1">[]</span><span class="s2">, </span><span class="s1">[])</span>

        <span class="s1">kwargs[</span><span class="s3">&quot;subset&quot;</span><span class="s1">] = </span><span class="s2">None</span>
        <span class="s1">kwargs[</span><span class="s3">&quot;exog_re&quot;</span><span class="s1">] = exog_re</span>
        <span class="s1">kwargs[</span><span class="s3">&quot;exog_vc&quot;</span><span class="s1">] = exog_vc</span>
        <span class="s1">kwargs[</span><span class="s3">&quot;groups&quot;</span><span class="s1">] = groups</span>
        <span class="s1">mod = super(MixedLM</span><span class="s2">, </span><span class="s1">cls).from_formula(</span>
            <span class="s1">formula</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s4"># expand re names to account for pairs of RE</span>
        <span class="s1">(param_names</span><span class="s2">,</span>
         <span class="s1">exog_re_names</span><span class="s2">,</span>
         <span class="s1">exog_re_names_full) = mod._make_param_names(exog_re_names)</span>

        <span class="s1">mod.data.param_names = param_names</span>
        <span class="s1">mod.data.exog_re_names = exog_re_names</span>
        <span class="s1">mod.data.exog_re_names_full = exog_re_names_full</span>

        <span class="s2">if </span><span class="s1">vc_formula </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">mod.data.vcomp_names = mod.exog_vc.names</span>

        <span class="s2">return </span><span class="s1">mod</span>

    <span class="s2">def </span><span class="s1">predict(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return predicted values from a design matrix. 
 
        Parameters 
        ---------- 
        params : array_like 
            Parameters of a mixed linear model.  Can be either a 
            MixedLMParams instance, or a vector containing the packed 
            model parameters in which the fixed effects parameters are 
            at the beginning of the vector, or a vector containing 
            only the fixed effects parameters. 
        exog : array_like, optional 
            Design / exogenous data for the fixed effects. Model exog 
            is used if None. 
 
        Returns 
        ------- 
        An array of fitted values.  Note that these predicted values 
        only reflect the fixed effects mean structure of the model. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">exog </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog = self.exog</span>

        <span class="s2">if </span><span class="s1">isinstance(params</span><span class="s2">, </span><span class="s1">MixedLMParams):</span>
            <span class="s1">params = params.fe_params</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">params = params[</span><span class="s5">0</span><span class="s1">:self.k_fe]</span>

        <span class="s2">return </span><span class="s1">np.dot(exog</span><span class="s2">, </span><span class="s1">params)</span>

    <span class="s2">def </span><span class="s1">group_list(self</span><span class="s2">, </span><span class="s1">array):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns `array` split into subarrays corresponding to the 
        grouping structure. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">array </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">return None</span>

        <span class="s2">if </span><span class="s1">array.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">[np.array(array[self.row_indices[k]])</span>
                    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">self.group_labels]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">[np.array(array[self.row_indices[k]</span><span class="s2">, </span><span class="s1">:])</span>
                    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">self.group_labels]</span>

    <span class="s2">def </span><span class="s1">fit_regularized(self</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'l1'</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">0</span><span class="s2">,</span>
                        <span class="s1">ceps=</span><span class="s5">1e-4</span><span class="s2">, </span><span class="s1">ptol=</span><span class="s5">1e-6</span><span class="s2">, </span><span class="s1">maxit=</span><span class="s5">200</span><span class="s2">, </span><span class="s1">**fit_kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit a model in which the fixed effects parameters are 
        penalized.  The dependence parameters are held fixed at their 
        estimated values in the unpenalized model. 
 
        Parameters 
        ---------- 
        method : str of Penalty object 
            Method for regularization.  If a string, must be 'l1'. 
        alpha : array_like 
            Scalar or vector of penalty weights.  If a scalar, the 
            same weight is applied to all coefficients; if a vector, 
            it contains a weight for each coefficient.  If method is a 
            Penalty object, the weights are scaled by alpha.  For L1 
            regularization, the weights are used directly. 
        ceps : positive real scalar 
            Fixed effects parameters smaller than this value 
            in magnitude are treated as being zero. 
        ptol : positive real scalar 
            Convergence occurs when the sup norm difference 
            between successive values of `fe_params` is less than 
            `ptol`. 
        maxit : int 
            The maximum number of iterations. 
        **fit_kwargs 
            Additional keyword arguments passed to fit. 
 
        Returns 
        ------- 
        A MixedLMResults instance containing the results. 
 
        Notes 
        ----- 
        The covariance structure is not updated as the fixed effects 
        parameters are varied. 
 
        The algorithm used here for L1 regularization is a&quot;shooting&quot; 
        or cyclic coordinate descent algorithm. 
 
        If method is 'l1', then `fe_pen` and `cov_pen` are used to 
        obtain the covariance structure, but are ignored during the 
        L1-penalized fitting. 
 
        References 
        ---------- 
        Friedman, J. H., Hastie, T. and Tibshirani, R. Regularized 
        Paths for Generalized Linear Models via Coordinate 
        Descent. Journal of Statistical Software, 33(1) (2008) 
        http://www.jstatsoft.org/v33/i01/paper 
 
        http://statweb.stanford.edu/~tibs/stat315a/Supplements/fuse.pdf 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">isinstance(method</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">and </span><span class="s1">(method.lower() != </span><span class="s3">'l1'</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Invalid regularization method&quot;</span><span class="s1">)</span>

        <span class="s4"># If method is a smooth penalty just optimize directly.</span>
        <span class="s2">if </span><span class="s1">isinstance(method</span><span class="s2">, </span><span class="s1">Penalty):</span>
            <span class="s4"># Scale the penalty weights by alpha</span>
            <span class="s1">method.alpha = alpha</span>
            <span class="s1">fit_kwargs.update({</span><span class="s3">&quot;fe_pen&quot;</span><span class="s1">: method})</span>
            <span class="s2">return </span><span class="s1">self.fit(**fit_kwargs)</span>

        <span class="s2">if </span><span class="s1">np.isscalar(alpha):</span>
            <span class="s1">alpha = alpha * np.ones(self.k_fe</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s4"># Fit the unpenalized model to get the dependence structure.</span>
        <span class="s1">mdf = self.fit(**fit_kwargs)</span>
        <span class="s1">fe_params = mdf.fe_params</span>
        <span class="s1">cov_re = mdf.cov_re</span>
        <span class="s1">vcomp = mdf.vcomp</span>
        <span class="s1">scale = mdf.scale</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">cov_re_inv = </span><span class="s2">None</span>

        <span class="s2">for </span><span class="s1">itr </span><span class="s2">in </span><span class="s1">range(maxit):</span>

            <span class="s1">fe_params_s = fe_params.copy()</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_fe):</span>

                <span class="s2">if </span><span class="s1">abs(fe_params[j]) &lt; ceps:</span>
                    <span class="s2">continue</span>

                <span class="s4"># The residuals</span>
                <span class="s1">fe_params[j] = </span><span class="s5">0.</span>
                <span class="s1">expval = np.dot(self.exog</span><span class="s2">, </span><span class="s1">fe_params)</span>
                <span class="s1">resid_all = self.endog - expval</span>

                <span class="s4"># The loss function has the form</span>
                <span class="s4"># a*x^2 + b*x + pwt*|x|</span>
                <span class="s1">a</span><span class="s2">, </span><span class="s1">b = </span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span>
                <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>

                    <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>

                    <span class="s1">exog = self.exog_li[group_ix]</span>
                    <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>

                    <span class="s1">resid = resid_all[self.row_indices[group]]</span>
                    <span class="s1">solver = _smw_solver(scale</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">,</span>
                                         <span class="s5">1 </span><span class="s1">/ vc_var)</span>

                    <span class="s1">x = exog[:</span><span class="s2">, </span><span class="s1">j]</span>
                    <span class="s1">u = solver(x)</span>
                    <span class="s1">a += np.dot(u</span><span class="s2">, </span><span class="s1">x)</span>
                    <span class="s1">b -= </span><span class="s5">2 </span><span class="s1">* np.dot(u</span><span class="s2">, </span><span class="s1">resid)</span>

                <span class="s1">pwt1 = alpha[j]</span>
                <span class="s2">if </span><span class="s1">b &gt; pwt1:</span>
                    <span class="s1">fe_params[j] = -(b - pwt1) / (</span><span class="s5">2 </span><span class="s1">* a)</span>
                <span class="s2">elif </span><span class="s1">b &lt; -pwt1:</span>
                    <span class="s1">fe_params[j] = -(b + pwt1) / (</span><span class="s5">2 </span><span class="s1">* a)</span>

            <span class="s2">if </span><span class="s1">np.abs(fe_params_s - fe_params).max() &lt; ptol:</span>
                <span class="s2">break</span>

        <span class="s4"># Replace the fixed effects estimates with their penalized</span>
        <span class="s4"># values, leave the dependence parameters in their unpenalized</span>
        <span class="s4"># state.</span>
        <span class="s1">params_prof = mdf.params.copy()</span>
        <span class="s1">params_prof[</span><span class="s5">0</span><span class="s1">:self.k_fe] = fe_params</span>

        <span class="s1">scale = self.get_scale(fe_params</span><span class="s2">, </span><span class="s1">mdf.cov_re_unscaled</span><span class="s2">, </span><span class="s1">mdf.vcomp)</span>

        <span class="s4"># Get the Hessian including only the nonzero fixed effects,</span>
        <span class="s4"># then blow back up to the full size after inverting.</span>
        <span class="s1">hess</span><span class="s2">, </span><span class="s1">sing = self.hessian(params_prof)</span>
        <span class="s2">if </span><span class="s1">sing:</span>
            <span class="s1">warnings.warn(_warn_cov_sing)</span>

        <span class="s1">pcov = np.nan * np.ones_like(hess)</span>
        <span class="s1">ii = np.abs(params_prof) &gt; ceps</span>
        <span class="s1">ii[self.k_fe:] = </span><span class="s2">True</span>
        <span class="s1">ii = np.flatnonzero(ii)</span>
        <span class="s1">hess1 = hess[ii</span><span class="s2">, </span><span class="s1">:][:</span><span class="s2">, </span><span class="s1">ii]</span>
        <span class="s1">pcov[np.ix_(ii</span><span class="s2">, </span><span class="s1">ii)] = np.linalg.inv(-hess1)</span>

        <span class="s1">params_object = MixedLMParams.from_components(fe_params</span><span class="s2">, </span><span class="s1">cov_re=cov_re)</span>

        <span class="s1">results = MixedLMResults(self</span><span class="s2">, </span><span class="s1">params_prof</span><span class="s2">, </span><span class="s1">pcov / scale)</span>
        <span class="s1">results.params_object = params_object</span>
        <span class="s1">results.fe_params = fe_params</span>
        <span class="s1">results.cov_re = cov_re</span>
        <span class="s1">results.vcomp = vcomp</span>
        <span class="s1">results.scale = scale</span>
        <span class="s1">results.cov_re_unscaled = mdf.cov_re_unscaled</span>
        <span class="s1">results.method = mdf.method</span>
        <span class="s1">results.converged = </span><span class="s2">True</span>
        <span class="s1">results.cov_pen = self.cov_pen</span>
        <span class="s1">results.k_fe = self.k_fe</span>
        <span class="s1">results.k_re = self.k_re</span>
        <span class="s1">results.k_re2 = self.k_re2</span>
        <span class="s1">results.k_vc = self.k_vc</span>

        <span class="s2">return </span><span class="s1">MixedLMResultsWrapper(results)</span>

    <span class="s2">def </span><span class="s1">get_fe_params(self</span><span class="s2">, </span><span class="s1">cov_re</span><span class="s2">, </span><span class="s1">vcomp</span><span class="s2">, </span><span class="s1">tol=</span><span class="s5">1e-10</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Use GLS to update the fixed effects parameter estimates. 
 
        Parameters 
        ---------- 
        cov_re : array_like (2d) 
            The covariance matrix of the random effects. 
        vcomp : array_like (1d) 
            The variance components. 
        tol : float 
            A tolerance parameter to determine when covariances 
            are singular. 
 
        Returns 
        ------- 
        params : ndarray 
            The GLS estimates of the fixed effects parameters. 
        singular : bool 
            True if the covariance is singular 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.k_fe == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.array([])</span><span class="s2">, False</span>

        <span class="s1">sing = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">self.k_re == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.empty((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">w</span><span class="s2">, </span><span class="s1">v = np.linalg.eigh(cov_re)</span>
            <span class="s2">if </span><span class="s1">w.min() &lt; tol:</span>
                <span class="s4"># Singular, use pseudo-inverse</span>
                <span class="s1">sing = </span><span class="s2">True</span>
                <span class="s1">ii = np.flatnonzero(w &gt;= tol)</span>
                <span class="s2">if </span><span class="s1">len(ii) == </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">cov_re_inv = np.zeros_like(cov_re)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">vi = v[:</span><span class="s2">, </span><span class="s1">ii]</span>
                    <span class="s1">wi = w[ii]</span>
                    <span class="s1">cov_re_inv = np.dot(vi / wi</span><span class="s2">, </span><span class="s1">vi.T)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>

        <span class="s4"># Cache these quantities that do not change.</span>
        <span class="s2">if not </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">&quot;_endex_li&quot;</span><span class="s1">):</span>
            <span class="s1">self._endex_li = []</span>
            <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>
                <span class="s1">mat = np.concatenate(</span>
                    <span class="s1">(self.exog_li[group_ix]</span><span class="s2">,</span>
                     <span class="s1">self.endog_li[group_ix][:</span><span class="s2">, None</span><span class="s1">])</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">self._endex_li.append(mat)</span>

        <span class="s1">xtxy = </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>
            <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>
            <span class="s2">if </span><span class="s1">vc_var.size &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">vc_var.min() &lt; tol:</span>
                    <span class="s4"># Pseudo-inverse</span>
                    <span class="s1">sing = </span><span class="s2">True</span>
                    <span class="s1">ii = np.flatnonzero(vc_var &gt;= tol)</span>
                    <span class="s1">vc_vari = np.zeros_like(vc_var)</span>
                    <span class="s1">vc_vari[ii] = </span><span class="s5">1 </span><span class="s1">/ vc_var[ii]</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">vc_vari = </span><span class="s5">1 </span><span class="s1">/ vc_var</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">vc_vari = np.empty(</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">exog = self.exog_li[group_ix]</span>
            <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>
            <span class="s1">solver = _smw_solver(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s1">vc_vari)</span>
            <span class="s1">u = solver(self._endex_li[group_ix])</span>
            <span class="s1">xtxy += np.dot(exog.T</span><span class="s2">, </span><span class="s1">u)</span>

        <span class="s2">if </span><span class="s1">sing:</span>
            <span class="s1">fe_params = np.dot(np.linalg.pinv(xtxy[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">xtxy[:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fe_params = np.linalg.solve(xtxy[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">xtxy[:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">])</span>

        <span class="s2">return </span><span class="s1">fe_params</span><span class="s2">, </span><span class="s1">sing</span>

    <span class="s2">def </span><span class="s1">_reparam(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns parameters of the map converting parameters from the 
        form used in optimization to the form returned to the user. 
 
        Returns 
        ------- 
        lin : list-like 
            Linear terms of the map 
        quad : list-like 
            Quadratic terms of the map 
 
        Notes 
        ----- 
        If P are the standard form parameters and R are the 
        transformed parameters (i.e. with the Cholesky square root 
        covariance and square root transformed variance components), 
        then P[i] = lin[i] * R + R' * quad[i] * R 
        &quot;&quot;&quot;</span>

        <span class="s1">k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">k_re2</span><span class="s2">, </span><span class="s1">k_vc = self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.k_re2</span><span class="s2">, </span><span class="s1">self.k_vc</span>
        <span class="s1">k_tot = k_fe + k_re2 + k_vc</span>
        <span class="s1">ix = np.tril_indices(self.k_re)</span>

        <span class="s1">lin = []</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(k_fe):</span>
            <span class="s1">e = np.zeros(k_tot)</span>
            <span class="s1">e[k] = </span><span class="s5">1</span>
            <span class="s1">lin.append(e)</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(k_re2):</span>
            <span class="s1">lin.append(np.zeros(k_tot))</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(k_vc):</span>
            <span class="s1">lin.append(np.zeros(k_tot))</span>

        <span class="s1">quad = []</span>
        <span class="s4"># Quadratic terms for fixed effects.</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(k_tot):</span>
            <span class="s1">quad.append(np.zeros((k_tot</span><span class="s2">, </span><span class="s1">k_tot)))</span>

        <span class="s4"># Quadratic terms for random effects covariance.</span>
        <span class="s1">ii = np.tril_indices(k_re)</span>
        <span class="s1">ix = [(a</span><span class="s2">, </span><span class="s1">b) </span><span class="s2">for </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b </span><span class="s2">in </span><span class="s1">zip(ii[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ii[</span><span class="s5">1</span><span class="s1">])]</span>
        <span class="s2">for </span><span class="s1">i1 </span><span class="s2">in </span><span class="s1">range(k_re2):</span>
            <span class="s2">for </span><span class="s1">i2 </span><span class="s2">in </span><span class="s1">range(k_re2):</span>
                <span class="s1">ix1 = ix[i1]</span>
                <span class="s1">ix2 = ix[i2]</span>
                <span class="s2">if </span><span class="s1">(ix1[</span><span class="s5">1</span><span class="s1">] == ix2[</span><span class="s5">1</span><span class="s1">]) </span><span class="s2">and </span><span class="s1">(ix1[</span><span class="s5">0</span><span class="s1">] &lt;= ix2[</span><span class="s5">0</span><span class="s1">]):</span>
                    <span class="s1">ii = (ix2[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix1[</span><span class="s5">0</span><span class="s1">])</span>
                    <span class="s1">k = ix.index(ii)</span>
                    <span class="s1">quad[k_fe+k][k_fe+i2</span><span class="s2">, </span><span class="s1">k_fe+i1] += </span><span class="s5">1</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(k_tot):</span>
            <span class="s1">quad[k] = </span><span class="s5">0.5</span><span class="s1">*(quad[k] + quad[k].T)</span>

        <span class="s4"># Quadratic terms for variance components.</span>
        <span class="s1">km = k_fe + k_re2</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(km</span><span class="s2">, </span><span class="s1">km+k_vc):</span>
            <span class="s1">quad[k][k</span><span class="s2">, </span><span class="s1">k] = </span><span class="s5">1</span>

        <span class="s2">return </span><span class="s1">lin</span><span class="s2">, </span><span class="s1">quad</span>

    <span class="s2">def </span><span class="s1">_expand_vcomp(self</span><span class="s2">, </span><span class="s1">vcomp</span><span class="s2">, </span><span class="s1">group_ix):</span>
        <span class="s0">&quot;&quot;&quot; 
        Replicate variance parameters to match a group's design. 
 
        Parameters 
        ---------- 
        vcomp : array_like 
            The variance parameters for the variance components. 
        group_ix : int 
            The group index 
 
        Returns an expanded version of vcomp, in which each variance 
        parameter is copied as many times as there are independent 
        realizations of the variance component in the given group. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">len(vcomp) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.empty(</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">vc_var = []</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(len(self.exog_vc.names)):</span>
            <span class="s1">d = self.exog_vc.mats[j][group_ix].shape[</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">vc_var.append(vcomp[j] * np.ones(d))</span>
        <span class="s2">if </span><span class="s1">len(vc_var) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.concatenate(vc_var)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># Cannot reach here?</span>
            <span class="s2">return </span><span class="s1">np.empty(</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_augment_exog(self</span><span class="s2">, </span><span class="s1">group_ix):</span>
        <span class="s0">&quot;&quot;&quot; 
        Concatenate the columns for variance components to the columns 
        for other random effects to obtain a single random effects 
        exog matrix for a given group. 
        &quot;&quot;&quot;</span>
        <span class="s1">ex_r = self.exog_re_li[group_ix] </span><span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0 </span><span class="s2">else None</span>
        <span class="s2">if </span><span class="s1">self.k_vc == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">ex_r</span>

        <span class="s1">ex = [ex_r] </span><span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">[]</span>
        <span class="s1">any_sparse = </span><span class="s2">False</span>
        <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">enumerate(self.exog_vc.names):</span>
            <span class="s1">ex.append(self.exog_vc.mats[j][group_ix])</span>
            <span class="s1">any_sparse |= sparse.issparse(ex[-</span><span class="s5">1</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">any_sparse:</span>
            <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">enumerate(ex):</span>
                <span class="s2">if not </span><span class="s1">sparse.issparse(x):</span>
                    <span class="s1">ex[j] = sparse.csr_matrix(x)</span>
            <span class="s1">ex = sparse.hstack(ex)</span>
            <span class="s1">ex = sparse.csr_matrix(ex)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">ex = np.concatenate(ex</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">ex</span>

    <span class="s2">def </span><span class="s1">loglike(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">profile_fe=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evaluate the (profile) log-likelihood of the linear mixed 
        effects model. 
 
        Parameters 
        ---------- 
        params : MixedLMParams, or array_like. 
            The parameter value.  If array-like, must be a packed 
            parameter vector containing only the covariance 
            parameters. 
        profile_fe : bool 
            If True, replace the provided value of `fe_params` with 
            the GLS estimates. 
 
        Returns 
        ------- 
        The log-likelihood value at `params`. 
 
        Notes 
        ----- 
        The scale parameter `scale` is always profiled out of the 
        log-likelihood.  In addition, if `profile_fe` is true the 
        fixed effects parameters are also profiled out. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">type(params) </span><span class="s2">is not </span><span class="s1">MixedLMParams:</span>
            <span class="s1">params = MixedLMParams.from_packed(params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">,</span>
                                               <span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.use_sqrt</span><span class="s2">,</span>
                                               <span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s1">cov_re = params.cov_re</span>
        <span class="s1">vcomp = params.vcomp</span>

        <span class="s4"># Move to the profile set</span>
        <span class="s2">if </span><span class="s1">profile_fe:</span>
            <span class="s1">fe_params</span><span class="s2">, </span><span class="s1">sing = self.get_fe_params(cov_re</span><span class="s2">, </span><span class="s1">vcomp)</span>
            <span class="s2">if </span><span class="s1">sing:</span>
                <span class="s1">self._cov_sing += </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fe_params = params.fe_params</span>

        <span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>
            <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                <span class="s1">cov_re_inv = np.linalg.pinv(cov_re)</span>
                <span class="s1">self._cov_sing += </span><span class="s5">1</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">cov_re_logdet = np.linalg.slogdet(cov_re)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.zeros((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
            <span class="s1">cov_re_logdet = </span><span class="s5">0</span>

        <span class="s4"># The residuals</span>
        <span class="s1">expval = np.dot(self.exog</span><span class="s2">, </span><span class="s1">fe_params)</span>
        <span class="s1">resid_all = self.endog - expval</span>

        <span class="s1">likeval = </span><span class="s5">0.</span>

        <span class="s4"># Handle the covariance penalty</span>
        <span class="s2">if </span><span class="s1">(self.cov_pen </span><span class="s2">is not None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(self.k_re &gt; </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s1">likeval -= self.cov_pen.func(cov_re</span><span class="s2">, </span><span class="s1">cov_re_inv)</span>

        <span class="s4"># Handle the fixed effects penalty</span>
        <span class="s2">if </span><span class="s1">(self.fe_pen </span><span class="s2">is not None</span><span class="s1">):</span>
            <span class="s1">likeval -= self.fe_pen.func(fe_params)</span>

        <span class="s1">xvx</span><span class="s2">, </span><span class="s1">qf = </span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>

            <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>
            <span class="s1">cov_aug_logdet = cov_re_logdet + np.sum(np.log(vc_var))</span>

            <span class="s1">exog = self.exog_li[group_ix]</span>
            <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>
            <span class="s1">solver = _smw_solver(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">/ vc_var)</span>

            <span class="s1">resid = resid_all[self.row_indices[group]]</span>

            <span class="s4"># Part 1 of the log likelihood (for both ML and REML)</span>
            <span class="s1">ld = _smw_logdet(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">/ vc_var</span><span class="s2">,</span>
                             <span class="s1">cov_aug_logdet)</span>
            <span class="s1">likeval -= ld / </span><span class="s5">2.</span>

            <span class="s4"># Part 2 of the log likelihood (for both ML and REML)</span>
            <span class="s1">u = solver(resid)</span>
            <span class="s1">qf += np.dot(resid</span><span class="s2">, </span><span class="s1">u)</span>

            <span class="s4"># Adjustment for REML</span>
            <span class="s2">if </span><span class="s1">self.reml:</span>
                <span class="s1">mat = solver(exog)</span>
                <span class="s1">xvx += np.dot(exog.T</span><span class="s2">, </span><span class="s1">mat)</span>

        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">likeval -= (self.n_totobs - self.k_fe) * np.log(qf) / </span><span class="s5">2.</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">ld = np.linalg.slogdet(xvx)</span>
            <span class="s1">likeval -= ld / </span><span class="s5">2.</span>
            <span class="s1">likeval -= (self.n_totobs - self.k_fe) * np.log(</span><span class="s5">2 </span><span class="s1">* np.pi) / </span><span class="s5">2.</span>
            <span class="s1">likeval += ((self.n_totobs - self.k_fe) *</span>
                        <span class="s1">np.log(self.n_totobs - self.k_fe) / </span><span class="s5">2.</span><span class="s1">)</span>
            <span class="s1">likeval -= (self.n_totobs - self.k_fe) / </span><span class="s5">2.</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">likeval -= self.n_totobs * np.log(qf) / </span><span class="s5">2.</span>
            <span class="s1">likeval -= self.n_totobs * np.log(</span><span class="s5">2 </span><span class="s1">* np.pi) / </span><span class="s5">2.</span>
            <span class="s1">likeval += self.n_totobs * np.log(self.n_totobs) / </span><span class="s5">2.</span>
            <span class="s1">likeval -= self.n_totobs / </span><span class="s5">2.</span>

        <span class="s2">return </span><span class="s1">likeval</span>

    <span class="s2">def </span><span class="s1">_gen_dV_dPar(self</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">max_ix=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        A generator that yields the element-wise derivative of the 
        marginal covariance matrix with respect to the random effects 
        variance and covariance parameters. 
 
        ex_r : array_like 
            The random effects design matrix 
        solver : function 
            A function that given x returns V^{-1}x, where V 
            is the group's marginal covariance matrix. 
        group_ix : int 
            The group index 
        max_ix : {int, None} 
            If not None, the generator ends when this index 
            is reached. 
        &quot;&quot;&quot;</span>

        <span class="s1">axr = solver(ex_r)</span>

        <span class="s4"># Regular random effects</span>
        <span class="s1">jj = </span><span class="s5">0</span>
        <span class="s2">for </span><span class="s1">j1 </span><span class="s2">in </span><span class="s1">range(self.k_re):</span>
            <span class="s2">for </span><span class="s1">j2 </span><span class="s2">in </span><span class="s1">range(j1 + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s2">if </span><span class="s1">max_ix </span><span class="s2">is not None and </span><span class="s1">jj &gt; max_ix:</span>
                    <span class="s2">return</span>
                <span class="s4"># Need 2d</span>
                <span class="s1">mat_l</span><span class="s2">, </span><span class="s1">mat_r = ex_r[:</span><span class="s2">, </span><span class="s1">j1:j1+</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ex_r[:</span><span class="s2">, </span><span class="s1">j2:j2+</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">vsl</span><span class="s2">, </span><span class="s1">vsr = axr[:</span><span class="s2">, </span><span class="s1">j1:j1+</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">axr[:</span><span class="s2">, </span><span class="s1">j2:j2+</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s2">yield </span><span class="s1">jj</span><span class="s2">, </span><span class="s1">mat_l</span><span class="s2">, </span><span class="s1">mat_r</span><span class="s2">, </span><span class="s1">vsl</span><span class="s2">, </span><span class="s1">vsr</span><span class="s2">, </span><span class="s1">j1 == j2</span>
                <span class="s1">jj += </span><span class="s5">1</span>

        <span class="s4"># Variance components</span>
        <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">enumerate(self.exog_vc.names):</span>
            <span class="s2">if </span><span class="s1">max_ix </span><span class="s2">is not None and </span><span class="s1">jj &gt; max_ix:</span>
                <span class="s2">return</span>
            <span class="s1">mat = self.exog_vc.mats[j][group_ix]</span>
            <span class="s1">axmat = solver(mat)</span>
            <span class="s2">yield </span><span class="s1">jj</span><span class="s2">, </span><span class="s1">mat</span><span class="s2">, </span><span class="s1">mat</span><span class="s2">, </span><span class="s1">axmat</span><span class="s2">, </span><span class="s1">axmat</span><span class="s2">, True</span>
            <span class="s1">jj += </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">score(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">profile_fe=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the score vector of the profile log-likelihood. 
 
        Notes 
        ----- 
        The score vector that is returned is computed with respect to 
        the parameterization defined by this model instance's 
        `use_sqrt` attribute. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">type(params) </span><span class="s2">is not </span><span class="s1">MixedLMParams:</span>
            <span class="s1">params = MixedLMParams.from_packed(</span>
                <span class="s1">params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.use_sqrt</span><span class="s2">,</span>
                <span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">profile_fe:</span>
            <span class="s1">params.fe_params</span><span class="s2">, </span><span class="s1">sing = \</span>
                <span class="s1">self.get_fe_params(params.cov_re</span><span class="s2">, </span><span class="s1">params.vcomp)</span>

            <span class="s2">if </span><span class="s1">sing:</span>
                <span class="s1">msg = </span><span class="s3">&quot;Random effects covariance is singular&quot;</span>
                <span class="s1">warnings.warn(msg)</span>

        <span class="s2">if </span><span class="s1">self.use_sqrt:</span>
            <span class="s1">score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc = self.score_sqrt(</span>
                <span class="s1">params</span><span class="s2">, </span><span class="s1">calc_fe=</span><span class="s2">not </span><span class="s1">profile_fe)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc = self.score_full(</span>
                <span class="s1">params</span><span class="s2">, </span><span class="s1">calc_fe=</span><span class="s2">not </span><span class="s1">profile_fe)</span>

        <span class="s2">if </span><span class="s1">self._freepat </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">score_fe *= self._freepat.fe_params</span>
            <span class="s1">score_re *= self._freepat.cov_re[self._freepat._ix]</span>
            <span class="s1">score_vc *= self._freepat.vcomp</span>

        <span class="s2">if </span><span class="s1">profile_fe:</span>
            <span class="s2">return </span><span class="s1">np.concatenate((score_re</span><span class="s2">, </span><span class="s1">score_vc))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.concatenate((score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc))</span>

    <span class="s2">def </span><span class="s1">score_full(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">calc_fe):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the score with respect to untransformed parameters. 
 
        Calculates the score vector for the profiled log-likelihood of 
        the mixed effects model with respect to the parameterization 
        in which the random effects covariance matrix is represented 
        in its full form (not using the Cholesky factor). 
 
        Parameters 
        ---------- 
        params : MixedLMParams or array_like 
            The parameter at which the score function is evaluated. 
            If array-like, must contain the packed random effects 
            parameters (cov_re and vcomp) without fe_params. 
        calc_fe : bool 
            If True, calculate the score vector for the fixed effects 
            parameters.  If False, this vector is not calculated, and 
            a vector of zeros is returned in its place. 
 
        Returns 
        ------- 
        score_fe : array_like 
            The score vector with respect to the fixed effects 
            parameters. 
        score_re : array_like 
            The score vector with respect to the random effects 
            parameters (excluding variance components parameters). 
        score_vc : array_like 
            The score vector with respect to variance components 
            parameters. 
 
        Notes 
        ----- 
        `score_re` is taken with respect to the parameterization in 
        which `cov_re` is represented through its lower triangle 
        (without taking the Cholesky square root). 
        &quot;&quot;&quot;</span>

        <span class="s1">fe_params = params.fe_params</span>
        <span class="s1">cov_re = params.cov_re</span>
        <span class="s1">vcomp = params.vcomp</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">cov_re_inv = np.linalg.pinv(cov_re)</span>
            <span class="s1">self._cov_sing += </span><span class="s5">1</span>

        <span class="s1">score_fe = np.zeros(self.k_fe)</span>
        <span class="s1">score_re = np.zeros(self.k_re2)</span>
        <span class="s1">score_vc = np.zeros(self.k_vc)</span>

        <span class="s4"># Handle the covariance penalty.</span>
        <span class="s2">if </span><span class="s1">self.cov_pen </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">score_re -= self.cov_pen.deriv(cov_re</span><span class="s2">, </span><span class="s1">cov_re_inv)</span>

        <span class="s4"># Handle the fixed effects penalty.</span>
        <span class="s2">if </span><span class="s1">calc_fe </span><span class="s2">and </span><span class="s1">(self.fe_pen </span><span class="s2">is not None</span><span class="s1">):</span>
            <span class="s1">score_fe -= self.fe_pen.deriv(fe_params)</span>

        <span class="s4"># resid' V^{-1} resid, summed over the groups (a scalar)</span>
        <span class="s1">rvir = </span><span class="s5">0.</span>

        <span class="s4"># exog' V^{-1} resid, summed over the groups (a k_fe</span>
        <span class="s4"># dimensional vector)</span>
        <span class="s1">xtvir = </span><span class="s5">0.</span>

        <span class="s4"># exog' V^{_1} exog, summed over the groups (a k_fe x k_fe</span>
        <span class="s4"># matrix)</span>
        <span class="s1">xtvix = </span><span class="s5">0.</span>

        <span class="s4"># V^{-1} exog' dV/dQ_jj exog V^{-1}, where Q_jj is the jj^th</span>
        <span class="s4"># covariance parameter.</span>
        <span class="s1">xtax = [</span><span class="s5">0.</span><span class="s2">, </span><span class="s1">] * (self.k_re2 + self.k_vc)</span>

        <span class="s4"># Temporary related to the gradient of log |V|</span>
        <span class="s1">dlv = np.zeros(self.k_re2 + self.k_vc)</span>

        <span class="s4"># resid' V^{-1} dV/dQ_jj V^{-1} resid (a scalar)</span>
        <span class="s1">rvavr = np.zeros(self.k_re2 + self.k_vc)</span>

        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>

            <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>

            <span class="s1">exog = self.exog_li[group_ix]</span>
            <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>
            <span class="s1">solver = _smw_solver(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">/ vc_var)</span>

            <span class="s4"># The residuals</span>
            <span class="s1">resid = self.endog_li[group_ix]</span>
            <span class="s2">if </span><span class="s1">self.k_fe &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">expval = np.dot(exog</span><span class="s2">, </span><span class="s1">fe_params)</span>
                <span class="s1">resid = resid - expval</span>

            <span class="s2">if </span><span class="s1">self.reml:</span>
                <span class="s1">viexog = solver(exog)</span>
                <span class="s1">xtvix += np.dot(exog.T</span><span class="s2">, </span><span class="s1">viexog)</span>

            <span class="s4"># Contributions to the covariance parameter gradient</span>
            <span class="s1">vir = solver(resid)</span>
            <span class="s2">for </span><span class="s1">(jj</span><span class="s2">, </span><span class="s1">matl</span><span class="s2">, </span><span class="s1">matr</span><span class="s2">, </span><span class="s1">vsl</span><span class="s2">, </span><span class="s1">vsr</span><span class="s2">, </span><span class="s1">sym) </span><span class="s2">in</span><span class="s1">\</span>
                    <span class="s1">self._gen_dV_dPar(ex_r</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">group_ix):</span>
                <span class="s1">dlv[jj] = _dotsum(matr</span><span class="s2">, </span><span class="s1">vsl)</span>
                <span class="s2">if not </span><span class="s1">sym:</span>
                    <span class="s1">dlv[jj] += _dotsum(matl</span><span class="s2">, </span><span class="s1">vsr)</span>

                <span class="s1">ul = _dot(vir</span><span class="s2">, </span><span class="s1">matl)</span>
                <span class="s1">ur = ul.T </span><span class="s2">if </span><span class="s1">sym </span><span class="s2">else </span><span class="s1">_dot(matr.T</span><span class="s2">, </span><span class="s1">vir)</span>
                <span class="s1">ulr = np.dot(ul</span><span class="s2">, </span><span class="s1">ur)</span>
                <span class="s1">rvavr[jj] += ulr</span>
                <span class="s2">if not </span><span class="s1">sym:</span>
                    <span class="s1">rvavr[jj] += ulr.T</span>

                <span class="s2">if </span><span class="s1">self.reml:</span>
                    <span class="s1">ul = _dot(viexog.T</span><span class="s2">, </span><span class="s1">matl)</span>
                    <span class="s1">ur = ul.T </span><span class="s2">if </span><span class="s1">sym </span><span class="s2">else </span><span class="s1">_dot(matr.T</span><span class="s2">, </span><span class="s1">viexog)</span>
                    <span class="s1">ulr = np.dot(ul</span><span class="s2">, </span><span class="s1">ur)</span>
                    <span class="s1">xtax[jj] += ulr</span>
                    <span class="s2">if not </span><span class="s1">sym:</span>
                        <span class="s1">xtax[jj] += ulr.T</span>

            <span class="s4"># Contribution of log|V| to the covariance parameter</span>
            <span class="s4"># gradient.</span>
            <span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">score_re -= </span><span class="s5">0.5 </span><span class="s1">* dlv[</span><span class="s5">0</span><span class="s1">:self.k_re2]</span>
            <span class="s2">if </span><span class="s1">self.k_vc &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">score_vc -= </span><span class="s5">0.5 </span><span class="s1">* dlv[self.k_re2:]</span>

            <span class="s1">rvir += np.dot(resid</span><span class="s2">, </span><span class="s1">vir)</span>

            <span class="s2">if </span><span class="s1">calc_fe:</span>
                <span class="s1">xtvir += np.dot(exog.T</span><span class="s2">, </span><span class="s1">vir)</span>

        <span class="s1">fac = self.n_totobs</span>
        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">fac -= self.k_fe</span>

        <span class="s2">if </span><span class="s1">calc_fe </span><span class="s2">and </span><span class="s1">self.k_fe &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">score_fe += fac * xtvir / rvir</span>

        <span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">score_re += </span><span class="s5">0.5 </span><span class="s1">* fac * rvavr[</span><span class="s5">0</span><span class="s1">:self.k_re2] / rvir</span>
        <span class="s2">if </span><span class="s1">self.k_vc &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">score_vc += </span><span class="s5">0.5 </span><span class="s1">* fac * rvavr[self.k_re2:] / rvir</span>

        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">xtvixi = np.linalg.inv(xtvix)</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_re2):</span>
                <span class="s1">score_re[j] += </span><span class="s5">0.5 </span><span class="s1">* _dotsum(xtvixi.T</span><span class="s2">, </span><span class="s1">xtax[j])</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_vc):</span>
                <span class="s1">score_vc[j] += </span><span class="s5">0.5 </span><span class="s1">* _dotsum(xtvixi.T</span><span class="s2">, </span><span class="s1">xtax[self.k_re2 + j])</span>

        <span class="s2">return </span><span class="s1">score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc</span>

    <span class="s2">def </span><span class="s1">score_sqrt(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">calc_fe=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the score with respect to transformed parameters. 
 
        Calculates the score vector with respect to the 
        parameterization in which the random effects covariance matrix 
        is represented through its Cholesky square root. 
 
        Parameters 
        ---------- 
        params : MixedLMParams or array_like 
            The model parameters.  If array-like must contain packed 
            parameters that are compatible with this model instance. 
        calc_fe : bool 
            If True, calculate the score vector for the fixed effects 
            parameters.  If False, this vector is not calculated, and 
            a vector of zeros is returned in its place. 
 
        Returns 
        ------- 
        score_fe : array_like 
            The score vector with respect to the fixed effects 
            parameters. 
        score_re : array_like 
            The score vector with respect to the random effects 
            parameters (excluding variance components parameters). 
        score_vc : array_like 
            The score vector with respect to variance components 
            parameters. 
        &quot;&quot;&quot;</span>

        <span class="s1">score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc = self.score_full(params</span><span class="s2">, </span><span class="s1">calc_fe=calc_fe)</span>
        <span class="s1">params_vec = params.get_packed(use_sqrt=</span><span class="s2">True, </span><span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s1">score_full = np.concatenate((score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc))</span>
        <span class="s1">scr = </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(params_vec)):</span>
            <span class="s1">v = self._lin[i] + </span><span class="s5">2 </span><span class="s1">* np.dot(self._quad[i]</span><span class="s2">, </span><span class="s1">params_vec)</span>
            <span class="s1">scr += score_full[i] * v</span>
        <span class="s1">score_fe = scr[</span><span class="s5">0</span><span class="s1">:self.k_fe]</span>
        <span class="s1">score_re = scr[self.k_fe:self.k_fe + self.k_re2]</span>
        <span class="s1">score_vc = scr[self.k_fe + self.k_re2:]</span>

        <span class="s2">return </span><span class="s1">score_fe</span><span class="s2">, </span><span class="s1">score_re</span><span class="s2">, </span><span class="s1">score_vc</span>

    <span class="s2">def </span><span class="s1">hessian(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the model's Hessian matrix. 
 
        Calculates the Hessian matrix for the linear mixed effects 
        model with respect to the parameterization in which the 
        covariance matrix is represented directly (without square-root 
        transformation). 
 
        Parameters 
        ---------- 
        params : MixedLMParams or array_like 
            The model parameters at which the Hessian is calculated. 
            If array-like, must contain the packed parameters in a 
            form that is compatible with this model instance. 
 
        Returns 
        ------- 
        hess : 2d ndarray 
            The Hessian matrix, evaluated at `params`. 
        sing : boolean 
            If True, the covariance matrix is singular and a 
            pseudo-inverse is returned. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">type(params) </span><span class="s2">is not </span><span class="s1">MixedLMParams:</span>
            <span class="s1">params = MixedLMParams.from_packed(params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">,</span>
                                               <span class="s1">use_sqrt=self.use_sqrt</span><span class="s2">,</span>
                                               <span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s1">fe_params = params.fe_params</span>
        <span class="s1">vcomp = params.vcomp</span>
        <span class="s1">cov_re = params.cov_re</span>
        <span class="s1">sing = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">self.k_re &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>
            <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                <span class="s1">cov_re_inv = np.linalg.pinv(cov_re)</span>
                <span class="s1">sing = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.empty((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>

        <span class="s4"># Blocks for the fixed and random effects parameters.</span>
        <span class="s1">hess_fe = </span><span class="s5">0.</span>
        <span class="s1">hess_re = np.zeros((self.k_re2 + self.k_vc</span><span class="s2">, </span><span class="s1">self.k_re2 + self.k_vc))</span>
        <span class="s1">hess_fere = np.zeros((self.k_re2 + self.k_vc</span><span class="s2">, </span><span class="s1">self.k_fe))</span>

        <span class="s1">fac = self.n_totobs</span>
        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">fac -= self.exog.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">rvir = </span><span class="s5">0.</span>
        <span class="s1">xtvix = </span><span class="s5">0.</span>
        <span class="s1">xtax = [</span><span class="s5">0.</span><span class="s2">, </span><span class="s1">] * (self.k_re2 + self.k_vc)</span>
        <span class="s1">m = self.k_re2 + self.k_vc</span>
        <span class="s1">B = np.zeros(m)</span>
        <span class="s1">D = np.zeros((m</span><span class="s2">, </span><span class="s1">m))</span>
        <span class="s1">F = [[</span><span class="s5">0.</span><span class="s1">] * m </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(m)]</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>

            <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>
            <span class="s1">vc_vari = np.zeros_like(vc_var)</span>
            <span class="s1">ii = np.flatnonzero(vc_var &gt;= </span><span class="s5">1e-10</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">len(ii) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">vc_vari[ii] = </span><span class="s5">1 </span><span class="s1">/ vc_var[ii]</span>
            <span class="s2">if </span><span class="s1">len(ii) &lt; len(vc_var):</span>
                <span class="s1">sing = </span><span class="s2">True</span>

            <span class="s1">exog = self.exog_li[group_ix]</span>
            <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>
            <span class="s1">solver = _smw_solver(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s1">vc_vari)</span>

            <span class="s4"># The residuals</span>
            <span class="s1">resid = self.endog_li[group_ix]</span>
            <span class="s2">if </span><span class="s1">self.k_fe &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">expval = np.dot(exog</span><span class="s2">, </span><span class="s1">fe_params)</span>
                <span class="s1">resid = resid - expval</span>

            <span class="s1">viexog = solver(exog)</span>
            <span class="s1">xtvix += np.dot(exog.T</span><span class="s2">, </span><span class="s1">viexog)</span>
            <span class="s1">vir = solver(resid)</span>
            <span class="s1">rvir += np.dot(resid</span><span class="s2">, </span><span class="s1">vir)</span>

            <span class="s2">for </span><span class="s1">(jj1</span><span class="s2">, </span><span class="s1">matl1</span><span class="s2">, </span><span class="s1">matr1</span><span class="s2">, </span><span class="s1">vsl1</span><span class="s2">, </span><span class="s1">vsr1</span><span class="s2">, </span><span class="s1">sym1) </span><span class="s2">in</span><span class="s1">\</span>
                    <span class="s1">self._gen_dV_dPar(ex_r</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">group_ix):</span>

                <span class="s1">ul = _dot(viexog.T</span><span class="s2">, </span><span class="s1">matl1)</span>
                <span class="s1">ur = _dot(matr1.T</span><span class="s2">, </span><span class="s1">vir)</span>
                <span class="s1">hess_fere[jj1</span><span class="s2">, </span><span class="s1">:] += np.dot(ul</span><span class="s2">, </span><span class="s1">ur)</span>
                <span class="s2">if not </span><span class="s1">sym1:</span>
                    <span class="s1">ul = _dot(viexog.T</span><span class="s2">, </span><span class="s1">matr1)</span>
                    <span class="s1">ur = _dot(matl1.T</span><span class="s2">, </span><span class="s1">vir)</span>
                    <span class="s1">hess_fere[jj1</span><span class="s2">, </span><span class="s1">:] += np.dot(ul</span><span class="s2">, </span><span class="s1">ur)</span>

                <span class="s2">if </span><span class="s1">self.reml:</span>
                    <span class="s1">ul = _dot(viexog.T</span><span class="s2">, </span><span class="s1">matl1)</span>
                    <span class="s1">ur = ul </span><span class="s2">if </span><span class="s1">sym1 </span><span class="s2">else </span><span class="s1">np.dot(viexog.T</span><span class="s2">, </span><span class="s1">matr1)</span>
                    <span class="s1">ulr = _dot(ul</span><span class="s2">, </span><span class="s1">ur.T)</span>
                    <span class="s1">xtax[jj1] += ulr</span>
                    <span class="s2">if not </span><span class="s1">sym1:</span>
                        <span class="s1">xtax[jj1] += ulr.T</span>

                <span class="s1">ul = _dot(vir</span><span class="s2">, </span><span class="s1">matl1)</span>
                <span class="s1">ur = ul </span><span class="s2">if </span><span class="s1">sym1 </span><span class="s2">else </span><span class="s1">_dot(vir</span><span class="s2">, </span><span class="s1">matr1)</span>
                <span class="s1">B[jj1] += np.dot(ul</span><span class="s2">, </span><span class="s1">ur) * (</span><span class="s5">1 </span><span class="s2">if </span><span class="s1">sym1 </span><span class="s2">else </span><span class="s5">2</span><span class="s1">)</span>

                <span class="s4"># V^{-1} * dV/d_theta</span>
                <span class="s1">E = [(vsl1</span><span class="s2">, </span><span class="s1">matr1)]</span>
                <span class="s2">if not </span><span class="s1">sym1:</span>
                    <span class="s1">E.append((vsr1</span><span class="s2">, </span><span class="s1">matl1))</span>

                <span class="s2">for </span><span class="s1">(jj2</span><span class="s2">, </span><span class="s1">matl2</span><span class="s2">, </span><span class="s1">matr2</span><span class="s2">, </span><span class="s1">vsl2</span><span class="s2">, </span><span class="s1">vsr2</span><span class="s2">, </span><span class="s1">sym2) </span><span class="s2">in</span><span class="s1">\</span>
                        <span class="s1">self._gen_dV_dPar(ex_r</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">jj1):</span>

                    <span class="s1">re = sum([_multi_dot_three(matr2.T</span><span class="s2">, </span><span class="s1">x[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x[</span><span class="s5">1</span><span class="s1">].T)</span>
                              <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">E])</span>
                    <span class="s1">vt = </span><span class="s5">2 </span><span class="s1">* _dot(_multi_dot_three(vir[</span><span class="s2">None, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">matl2</span><span class="s2">, </span><span class="s1">re)</span><span class="s2">,</span>
                                  <span class="s1">vir[:</span><span class="s2">, None</span><span class="s1">])</span>

                    <span class="s2">if not </span><span class="s1">sym2:</span>
                        <span class="s1">le = sum([_multi_dot_three(matl2.T</span><span class="s2">, </span><span class="s1">x[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x[</span><span class="s5">1</span><span class="s1">].T)</span>
                                  <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">E])</span>
                        <span class="s1">vt += </span><span class="s5">2 </span><span class="s1">* _dot(_multi_dot_three(</span>
                            <span class="s1">vir[</span><span class="s2">None, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">matr2</span><span class="s2">, </span><span class="s1">le)</span><span class="s2">, </span><span class="s1">vir[:</span><span class="s2">, None</span><span class="s1">])</span>

                    <span class="s1">D[jj1</span><span class="s2">, </span><span class="s1">jj2] += np.squeeze(vt)</span>
                    <span class="s2">if </span><span class="s1">jj1 != jj2:</span>
                        <span class="s1">D[jj2</span><span class="s2">, </span><span class="s1">jj1] += np.squeeze(vt)</span>

                    <span class="s1">rt = _dotsum(vsl2</span><span class="s2">, </span><span class="s1">re.T) / </span><span class="s5">2</span>
                    <span class="s2">if not </span><span class="s1">sym2:</span>
                        <span class="s1">rt += _dotsum(vsr2</span><span class="s2">, </span><span class="s1">le.T) / </span><span class="s5">2</span>

                    <span class="s1">hess_re[jj1</span><span class="s2">, </span><span class="s1">jj2] += rt</span>
                    <span class="s2">if </span><span class="s1">jj1 != jj2:</span>
                        <span class="s1">hess_re[jj2</span><span class="s2">, </span><span class="s1">jj1] += rt</span>

                    <span class="s2">if </span><span class="s1">self.reml:</span>
                        <span class="s1">ev = sum([_dot(x[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">_dot(x[</span><span class="s5">1</span><span class="s1">].T</span><span class="s2">, </span><span class="s1">viexog)) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">E])</span>
                        <span class="s1">u1 = _dot(viexog.T</span><span class="s2">, </span><span class="s1">matl2)</span>
                        <span class="s1">u2 = _dot(matr2.T</span><span class="s2">, </span><span class="s1">ev)</span>
                        <span class="s1">um = np.dot(u1</span><span class="s2">, </span><span class="s1">u2)</span>
                        <span class="s1">F[jj1][jj2] += um + um.T</span>
                        <span class="s2">if not </span><span class="s1">sym2:</span>
                            <span class="s1">u1 = np.dot(viexog.T</span><span class="s2">, </span><span class="s1">matr2)</span>
                            <span class="s1">u2 = np.dot(matl2.T</span><span class="s2">, </span><span class="s1">ev)</span>
                            <span class="s1">um = np.dot(u1</span><span class="s2">, </span><span class="s1">u2)</span>
                            <span class="s1">F[jj1][jj2] += um + um.T</span>

        <span class="s1">hess_fe -= fac * xtvix / rvir</span>
        <span class="s1">hess_re = hess_re - </span><span class="s5">0.5 </span><span class="s1">* fac * (D/rvir - np.outer(B</span><span class="s2">, </span><span class="s1">B) / rvir**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">hess_fere = -fac * hess_fere / rvir</span>

        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">QL = [np.linalg.solve(xtvix</span><span class="s2">, </span><span class="s1">x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">xtax]</span>
            <span class="s2">for </span><span class="s1">j1 </span><span class="s2">in </span><span class="s1">range(self.k_re2 + self.k_vc):</span>
                <span class="s2">for </span><span class="s1">j2 </span><span class="s2">in </span><span class="s1">range(j1 + </span><span class="s5">1</span><span class="s1">):</span>
                    <span class="s1">a = _dotsum(QL[j1].T</span><span class="s2">, </span><span class="s1">QL[j2])</span>
                    <span class="s1">a -= np.trace(np.linalg.solve(xtvix</span><span class="s2">, </span><span class="s1">F[j1][j2]))</span>
                    <span class="s1">a *= </span><span class="s5">0.5</span>
                    <span class="s1">hess_re[j1</span><span class="s2">, </span><span class="s1">j2] += a</span>
                    <span class="s2">if </span><span class="s1">j1 &gt; j2:</span>
                        <span class="s1">hess_re[j2</span><span class="s2">, </span><span class="s1">j1] += a</span>

        <span class="s4"># Put the blocks together to get the Hessian.</span>
        <span class="s1">m = self.k_fe + self.k_re2 + self.k_vc</span>
        <span class="s1">hess = np.zeros((m</span><span class="s2">, </span><span class="s1">m))</span>
        <span class="s1">hess[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:self.k_fe] = hess_fe</span>
        <span class="s1">hess[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s1">self.k_fe:] = hess_fere.T</span>
        <span class="s1">hess[self.k_fe:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:self.k_fe] = hess_fere</span>
        <span class="s1">hess[self.k_fe:</span><span class="s2">, </span><span class="s1">self.k_fe:] = hess_re</span>

        <span class="s2">return </span><span class="s1">hess</span><span class="s2">, </span><span class="s1">sing</span>

    <span class="s2">def </span><span class="s1">get_scale(self</span><span class="s2">, </span><span class="s1">fe_params</span><span class="s2">, </span><span class="s1">cov_re</span><span class="s2">, </span><span class="s1">vcomp):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the estimated error variance based on given estimates 
        of the slopes and random effects covariance matrix. 
 
        Parameters 
        ---------- 
        fe_params : array_like 
            The regression slope estimates 
        cov_re : 2d array_like 
            Estimate of the random effects covariance matrix 
        vcomp : array_like 
            Estimate of the variance components 
 
        Returns 
        ------- 
        scale : float 
            The estimated error variance. 
        &quot;&quot;&quot;</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.linalg.inv(cov_re)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">cov_re_inv = np.linalg.pinv(cov_re)</span>
            <span class="s1">warnings.warn(_warn_cov_sing)</span>

        <span class="s1">qf = </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.group_labels):</span>

            <span class="s1">vc_var = self._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>

            <span class="s1">exog = self.exog_li[group_ix]</span>
            <span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r = self._aex_r[group_ix]</span><span class="s2">, </span><span class="s1">self._aex_r2[group_ix]</span>

            <span class="s1">solver = _smw_solver(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">/ vc_var)</span>

            <span class="s4"># The residuals</span>
            <span class="s1">resid = self.endog_li[group_ix]</span>
            <span class="s2">if </span><span class="s1">self.k_fe &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">expval = np.dot(exog</span><span class="s2">, </span><span class="s1">fe_params)</span>
                <span class="s1">resid = resid - expval</span>

            <span class="s1">mat = solver(resid)</span>
            <span class="s1">qf += np.dot(resid</span><span class="s2">, </span><span class="s1">mat)</span>

        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s1">qf /= (self.n_totobs - self.k_fe)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">qf /= self.n_totobs</span>

        <span class="s2">return </span><span class="s1">qf</span>

    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None, </span><span class="s1">reml=</span><span class="s2">True, </span><span class="s1">niter_sa=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">do_cg=</span><span class="s2">True, </span><span class="s1">fe_pen=</span><span class="s2">None, </span><span class="s1">cov_pen=</span><span class="s2">None, </span><span class="s1">free=</span><span class="s2">None,</span>
            <span class="s1">full_output=</span><span class="s2">False, </span><span class="s1">method=</span><span class="s2">None, </span><span class="s1">**fit_kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit a linear mixed model to the data. 
 
        Parameters 
        ---------- 
        start_params : array_like or MixedLMParams 
            Starting values for the profile log-likelihood.  If not a 
            `MixedLMParams` instance, this should be an array 
            containing the packed parameters for the profile 
            log-likelihood, including the fixed effects 
            parameters. 
        reml : bool 
            If true, fit according to the REML likelihood, else 
            fit the standard likelihood using ML. 
        niter_sa : int 
            Currently this argument is ignored and has no effect 
            on the results. 
        cov_pen : CovariancePenalty object 
            A penalty for the random effects covariance matrix 
        do_cg : bool, defaults to True 
            If False, the optimization is skipped and a results 
            object at the given (or default) starting values is 
            returned. 
        fe_pen : Penalty object 
            A penalty on the fixed effects 
        free : MixedLMParams object 
            If not `None`, this is a mask that allows parameters to be 
            held fixed at specified values.  A 1 indicates that the 
            corresponding parameter is estimated, a 0 indicates that 
            it is fixed at its starting value.  Setting the `cov_re` 
            component to the identity matrix fits a model with 
            independent random effects.  Note that some optimization 
            methods do not respect this constraint (bfgs and lbfgs both 
            work). 
        full_output : bool 
            If true, attach iteration history to results 
        method : str 
            Optimization method.  Can be a scipy.optimize method name, 
            or a list of such names to be tried in sequence. 
        **fit_kwargs 
            Additional keyword arguments passed to fit. 
 
        Returns 
        ------- 
        A MixedLMResults instance. 
        &quot;&quot;&quot;</span>

        <span class="s1">_allowed_kwargs = [</span><span class="s3">'gtol'</span><span class="s2">, </span><span class="s3">'maxiter'</span><span class="s2">, </span><span class="s3">'eps'</span><span class="s2">, </span><span class="s3">'maxcor'</span><span class="s2">, </span><span class="s3">'ftol'</span><span class="s2">,</span>
                           <span class="s3">'tol'</span><span class="s2">, </span><span class="s3">'disp'</span><span class="s2">, </span><span class="s3">'maxls'</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">fit_kwargs.keys():</span>
            <span class="s2">if </span><span class="s1">x </span><span class="s2">not in </span><span class="s1">_allowed_kwargs:</span>
                <span class="s1">warnings.warn(</span><span class="s3">&quot;Argument %s not used by MixedLM.fit&quot; </span><span class="s1">% x)</span>

        <span class="s2">if </span><span class="s1">method </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">method = [</span><span class="s3">'bfgs'</span><span class="s2">, </span><span class="s3">'lbfgs'</span><span class="s2">, </span><span class="s3">'cg'</span><span class="s1">]</span>
        <span class="s2">elif </span><span class="s1">isinstance(method</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">method = [method]</span>

        <span class="s2">for </span><span class="s1">meth </span><span class="s2">in </span><span class="s1">method:</span>
            <span class="s2">if </span><span class="s1">meth.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">&quot;newton&quot;</span><span class="s2">, </span><span class="s3">&quot;ncg&quot;</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;method %s not available for MixedLM&quot; </span><span class="s1">% meth)</span>

        <span class="s1">self.reml = reml</span>
        <span class="s1">self.cov_pen = cov_pen</span>
        <span class="s1">self.fe_pen = fe_pen</span>
        <span class="s1">self._cov_sing = </span><span class="s5">0</span>
        <span class="s1">self._freepat = free</span>

        <span class="s2">if </span><span class="s1">full_output:</span>
            <span class="s1">hist = []</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">hist = </span><span class="s2">None</span>

        <span class="s2">if </span><span class="s1">start_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">params = MixedLMParams(self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.k_vc)</span>
            <span class="s1">params.fe_params = np.zeros(self.k_fe)</span>
            <span class="s1">params.cov_re = np.eye(self.k_re)</span>
            <span class="s1">params.vcomp = np.ones(self.k_vc)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(start_params</span><span class="s2">, </span><span class="s1">MixedLMParams):</span>
                <span class="s1">params = start_params</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s4"># It's a packed array</span>
                <span class="s2">if </span><span class="s1">len(start_params) == self.k_fe + self.k_re2 + self.k_vc:</span>
                    <span class="s1">params = MixedLMParams.from_packed(</span>
                        <span class="s1">start_params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.use_sqrt</span><span class="s2">,</span>
                        <span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s2">elif </span><span class="s1">len(start_params) == self.k_re2 + self.k_vc:</span>
                    <span class="s1">params = MixedLMParams.from_packed(</span>
                        <span class="s1">start_params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">self.use_sqrt</span><span class="s2">,</span>
                        <span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;invalid start_params&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">do_cg:</span>
            <span class="s1">fit_kwargs[</span><span class="s3">&quot;retall&quot;</span><span class="s1">] = hist </span><span class="s2">is not None</span>
            <span class="s2">if </span><span class="s3">&quot;disp&quot; </span><span class="s2">not in </span><span class="s1">fit_kwargs:</span>
                <span class="s1">fit_kwargs[</span><span class="s3">&quot;disp&quot;</span><span class="s1">] = </span><span class="s2">False</span>
            <span class="s1">packed = params.get_packed(use_sqrt=self.use_sqrt</span><span class="s2">, </span><span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">niter_sa &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">warnings.warn(</span><span class="s3">&quot;niter_sa is currently ignored&quot;</span><span class="s1">)</span>

            <span class="s4"># Try optimizing one or more times</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(len(method)):</span>
                <span class="s1">rslt = super(MixedLM</span><span class="s2">, </span><span class="s1">self).fit(start_params=packed</span><span class="s2">,</span>
                                                <span class="s1">skip_hessian=</span><span class="s2">True,</span>
                                                <span class="s1">method=method[j]</span><span class="s2">,</span>
                                                <span class="s1">**fit_kwargs)</span>
                <span class="s2">if </span><span class="s1">rslt.mle_retvals[</span><span class="s3">'converged'</span><span class="s1">]:</span>
                    <span class="s2">break</span>
                <span class="s1">packed = rslt.params</span>
                <span class="s2">if </span><span class="s1">j + </span><span class="s5">1 </span><span class="s1">&lt; len(method):</span>
                    <span class="s1">next_method = method[j + </span><span class="s5">1</span><span class="s1">]</span>
                    <span class="s1">warnings.warn(</span>
                        <span class="s3">&quot;Retrying MixedLM optimization with %s&quot; </span><span class="s1">% next_method</span><span class="s2">,</span>
                        <span class="s1">ConvergenceWarning)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">msg = (</span><span class="s3">&quot;MixedLM optimization failed, &quot; </span><span class="s1">+</span>
                           <span class="s3">&quot;trying a different optimizer may help.&quot;</span><span class="s1">)</span>
                    <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>

            <span class="s4"># The optimization succeeded</span>
            <span class="s1">params = np.atleast_1d(rslt.params)</span>
            <span class="s2">if </span><span class="s1">hist </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">hist.append(rslt.mle_retvals)</span>

        <span class="s1">converged = rslt.mle_retvals[</span><span class="s3">'converged'</span><span class="s1">]</span>
        <span class="s2">if not </span><span class="s1">converged:</span>
            <span class="s1">gn = self.score(rslt.params)</span>
            <span class="s1">gn = np.sqrt(np.sum(gn**</span><span class="s5">2</span><span class="s1">))</span>
            <span class="s1">msg = </span><span class="s3">&quot;Gradient optimization failed, |grad| = %f&quot; </span><span class="s1">% gn</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>

        <span class="s4"># Convert to the final parameterization (i.e. undo the square</span>
        <span class="s4"># root transform of the covariance matrix, and the profiling</span>
        <span class="s4"># over the error variance).</span>
        <span class="s1">params = MixedLMParams.from_packed(</span>
            <span class="s1">params</span><span class="s2">, </span><span class="s1">self.k_fe</span><span class="s2">, </span><span class="s1">self.k_re</span><span class="s2">, </span><span class="s1">use_sqrt=self.use_sqrt</span><span class="s2">, </span><span class="s1">has_fe=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">cov_re_unscaled = params.cov_re</span>
        <span class="s1">vcomp_unscaled = params.vcomp</span>
        <span class="s1">fe_params</span><span class="s2">, </span><span class="s1">sing = self.get_fe_params(cov_re_unscaled</span><span class="s2">, </span><span class="s1">vcomp_unscaled)</span>
        <span class="s1">params.fe_params = fe_params</span>
        <span class="s1">scale = self.get_scale(fe_params</span><span class="s2">, </span><span class="s1">cov_re_unscaled</span><span class="s2">, </span><span class="s1">vcomp_unscaled)</span>
        <span class="s1">cov_re = scale * cov_re_unscaled</span>
        <span class="s1">vcomp = scale * vcomp_unscaled</span>

        <span class="s1">f1 = (self.k_re &gt; </span><span class="s5">0</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(np.min(np.abs(np.diag(cov_re))) &lt; </span><span class="s5">0.01</span><span class="s1">)</span>
        <span class="s1">f2 = (self.k_vc &gt; </span><span class="s5">0</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(np.min(np.abs(vcomp)) &lt; </span><span class="s5">0.01</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">f1 </span><span class="s2">or </span><span class="s1">f2:</span>
            <span class="s1">msg = </span><span class="s3">&quot;The MLE may be on the boundary of the parameter space.&quot;</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>

        <span class="s4"># Compute the Hessian at the MLE.  Note that this is the</span>
        <span class="s4"># Hessian with respect to the random effects covariance matrix</span>
        <span class="s4"># (not its square root).  It is used for obtaining standard</span>
        <span class="s4"># errors, not for optimization.</span>
        <span class="s1">hess</span><span class="s2">, </span><span class="s1">sing = self.hessian(params)</span>
        <span class="s2">if </span><span class="s1">sing:</span>
            <span class="s1">warnings.warn(_warn_cov_sing)</span>

        <span class="s1">hess_diag = np.diag(hess)</span>
        <span class="s2">if </span><span class="s1">free </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">pcov = np.zeros_like(hess)</span>
            <span class="s1">pat = self._freepat.get_packed(use_sqrt=</span><span class="s2">False, </span><span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">ii = np.flatnonzero(pat)</span>
            <span class="s1">hess_diag = hess_diag[ii]</span>
            <span class="s2">if </span><span class="s1">len(ii) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">hess1 = hess[np.ix_(ii</span><span class="s2">, </span><span class="s1">ii)]</span>
                <span class="s1">pcov[np.ix_(ii</span><span class="s2">, </span><span class="s1">ii)] = np.linalg.inv(-hess1)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">pcov = np.linalg.inv(-hess)</span>
        <span class="s2">if </span><span class="s1">np.any(hess_diag &gt;= </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s1">msg = (</span><span class="s3">&quot;The Hessian matrix at the estimated parameter values &quot; </span><span class="s1">+</span>
                   <span class="s3">&quot;is not positive definite.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>

        <span class="s4"># Prepare a results class instance</span>
        <span class="s1">params_packed = params.get_packed(use_sqrt=</span><span class="s2">False, </span><span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">results = MixedLMResults(self</span><span class="s2">, </span><span class="s1">params_packed</span><span class="s2">, </span><span class="s1">pcov / scale)</span>
        <span class="s1">results.params_object = params</span>
        <span class="s1">results.fe_params = fe_params</span>
        <span class="s1">results.cov_re = cov_re</span>
        <span class="s1">results.vcomp = vcomp</span>
        <span class="s1">results.scale = scale</span>
        <span class="s1">results.cov_re_unscaled = cov_re_unscaled</span>
        <span class="s1">results.method = </span><span class="s3">&quot;REML&quot; </span><span class="s2">if </span><span class="s1">self.reml </span><span class="s2">else </span><span class="s3">&quot;ML&quot;</span>
        <span class="s1">results.converged = converged</span>
        <span class="s1">results.hist = hist</span>
        <span class="s1">results.reml = self.reml</span>
        <span class="s1">results.cov_pen = self.cov_pen</span>
        <span class="s1">results.k_fe = self.k_fe</span>
        <span class="s1">results.k_re = self.k_re</span>
        <span class="s1">results.k_re2 = self.k_re2</span>
        <span class="s1">results.k_vc = self.k_vc</span>
        <span class="s1">results.use_sqrt = self.use_sqrt</span>
        <span class="s1">results.freepat = self._freepat</span>

        <span class="s2">return </span><span class="s1">MixedLMResultsWrapper(results)</span>

    <span class="s2">def </span><span class="s1">get_distribution(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">, </span><span class="s1">exog):</span>
        <span class="s2">return </span><span class="s1">_mixedlm_distribution(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">, </span><span class="s1">exog)</span>


<span class="s2">class </span><span class="s1">_mixedlm_distribution:</span>
    <span class="s0">&quot;&quot;&quot; 
    A private class for simulating data from a given mixed linear model. 
 
    Parameters 
    ---------- 
    model : MixedLM instance 
        A mixed linear model 
    params : array_like 
        A parameter vector defining a mixed linear model.  See 
        notes for more information. 
    scale : scalar 
        The unexplained variance 
    exog : array_like 
        An array of fixed effect covariates.  If None, model.exog 
        is used. 
 
    Notes 
    ----- 
    The params array is a vector containing fixed effects parameters, 
    random effects parameters, and variance component parameters, in 
    that order.  The lower triangle of the random effects covariance 
    matrix is stored.  The random effects and variance components 
    parameters are divided by the scale parameter. 
 
    This class is used in Mediation, and possibly elsewhere. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">, </span><span class="s1">exog):</span>

        <span class="s1">self.model = model</span>
        <span class="s1">self.exog = exog </span><span class="s2">if </span><span class="s1">exog </span><span class="s2">is not None else </span><span class="s1">model.exog</span>

        <span class="s1">po = MixedLMParams.from_packed(</span>
                <span class="s1">params</span><span class="s2">, </span><span class="s1">model.k_fe</span><span class="s2">, </span><span class="s1">model.k_re</span><span class="s2">, False, True</span><span class="s1">)</span>

        <span class="s1">self.fe_params = po.fe_params</span>
        <span class="s1">self.cov_re = scale * po.cov_re</span>
        <span class="s1">self.vcomp = scale * po.vcomp</span>
        <span class="s1">self.scale = scale</span>

        <span class="s1">group_idx = np.zeros(model.nobs</span><span class="s2">, </span><span class="s1">dtype=int)</span>
        <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">g </span><span class="s2">in </span><span class="s1">enumerate(model.group_labels):</span>
            <span class="s1">group_idx[model.row_indices[g]] = k</span>
        <span class="s1">self.group_idx = group_idx</span>

    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a vector of simulated values from a mixed linear 
        model. 
 
        The parameter n is ignored, but required by the interface 
        &quot;&quot;&quot;</span>

        <span class="s1">model = self.model</span>

        <span class="s4"># Fixed effects</span>
        <span class="s1">y = np.dot(self.exog</span><span class="s2">, </span><span class="s1">self.fe_params)</span>

        <span class="s4"># Random effects</span>
        <span class="s1">u = np.random.normal(size=(model.n_groups</span><span class="s2">, </span><span class="s1">model.k_re))</span>
        <span class="s1">u = np.dot(u</span><span class="s2">, </span><span class="s1">np.linalg.cholesky(self.cov_re).T)</span>
        <span class="s1">y += (u[self.group_idx</span><span class="s2">, </span><span class="s1">:] * model.exog_re).sum(</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Variance components</span>
        <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">enumerate(model.exog_vc.names):</span>
            <span class="s1">ex = model.exog_vc.mats[j]</span>
            <span class="s1">v = self.vcomp[j]</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">g </span><span class="s2">in </span><span class="s1">enumerate(model.group_labels):</span>
                <span class="s1">exg = ex[i]</span>
                <span class="s1">ii = model.row_indices[g]</span>
                <span class="s1">u = np.random.normal(size=exg.shape[</span><span class="s5">1</span><span class="s1">])</span>
                <span class="s1">y[ii] += np.sqrt(v) * np.dot(exg</span><span class="s2">, </span><span class="s1">u)</span>

        <span class="s4"># Residual variance</span>
        <span class="s1">y += np.sqrt(self.scale) * np.random.normal(size=len(y))</span>

        <span class="s2">return </span><span class="s1">y</span>


<span class="s2">class </span><span class="s1">MixedLMResults(base.LikelihoodModelResults</span><span class="s2">, </span><span class="s1">base.ResultMixin):</span>
    <span class="s0">''' 
    Class to contain results of fitting a linear mixed effects model. 
 
    MixedLMResults inherits from statsmodels.LikelihoodModelResults 
 
    Parameters 
    ---------- 
    See statsmodels.LikelihoodModelResults 
 
    Attributes 
    ---------- 
    model : class instance 
        Pointer to MixedLM model instance that called fit. 
    normalized_cov_params : ndarray 
        The sampling covariance matrix of the estimates 
    params : ndarray 
        A packed parameter vector for the profile parameterization. 
        The first `k_fe` elements are the estimated fixed effects 
        coefficients.  The remaining elements are the estimated 
        variance parameters.  The variance parameters are all divided 
        by `scale` and are not the variance parameters shown 
        in the summary. 
    fe_params : ndarray 
        The fitted fixed-effects coefficients 
    cov_re : ndarray 
        The fitted random-effects covariance matrix 
    bse_fe : ndarray 
        The standard errors of the fitted fixed effects coefficients 
    bse_re : ndarray 
        The standard errors of the fitted random effects covariance 
        matrix and variance components.  The first `k_re * (k_re + 1)` 
        parameters are the standard errors for the lower triangle of 
        `cov_re`, the remaining elements are the standard errors for 
        the variance components. 
 
    See Also 
    -------- 
    statsmodels.LikelihoodModelResults 
    '''</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">cov_params):</span>

        <span class="s1">super(MixedLMResults</span><span class="s2">, </span><span class="s1">self).__init__(model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">,</span>
                                             <span class="s1">normalized_cov_params=cov_params)</span>
        <span class="s1">self.nobs = self.model.nobs</span>
        <span class="s1">self.df_resid = self.nobs - np.linalg.matrix_rank(self.model.exog)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">fittedvalues(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the fitted values for the model. 
 
        The fitted values reflect the mean structure specified by the 
        fixed effects and the predicted random effects. 
        &quot;&quot;&quot;</span>
        <span class="s1">fit = np.dot(self.model.exog</span><span class="s2">, </span><span class="s1">self.fe_params)</span>
        <span class="s1">re = self.random_effects</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.model.group_labels):</span>
            <span class="s1">ix = self.model.row_indices[group]</span>

            <span class="s1">mat = []</span>
            <span class="s2">if </span><span class="s1">self.model.exog_re_li </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">mat.append(self.model.exog_re_li[group_ix])</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_vc):</span>
                <span class="s1">mat.append(self.model.exog_vc.mats[j][group_ix])</span>
            <span class="s1">mat = np.concatenate(mat</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">fit[ix] += np.dot(mat</span><span class="s2">, </span><span class="s1">re[group])</span>

        <span class="s2">return </span><span class="s1">fit</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the residuals for the model. 
 
        The residuals reflect the mean structure specified by the 
        fixed effects and the predicted random effects. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.endog - self.fittedvalues</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bse_fe(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the standard errors of the fixed effect regression 
        coefficients. 
        &quot;&quot;&quot;</span>
        <span class="s1">p = self.model.exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">np.sqrt(np.diag(self.cov_params())[</span><span class="s5">0</span><span class="s1">:p])</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bse_re(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the standard errors of the variance parameters. 
 
        The first `k_re x (k_re + 1)` elements of the returned array 
        are the standard errors of the lower triangle of `cov_re`. 
        The remaining elements are the standard errors of the variance 
        components. 
 
        Note that the sampling distribution of variance parameters is 
        strongly skewed unless the sample size is large, so these 
        standard errors may not give meaningful confidence intervals 
        or p-values if used in the usual way. 
        &quot;&quot;&quot;</span>
        <span class="s1">p = self.model.exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">np.sqrt(self.scale * np.diag(self.cov_params())[p:])</span>

    <span class="s2">def </span><span class="s1">_expand_re_names(self</span><span class="s2">, </span><span class="s1">group_ix):</span>
        <span class="s1">names = list(self.model.data.exog_re_names)</span>

        <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">enumerate(self.model.exog_vc.names):</span>
            <span class="s1">vg = self.model.exog_vc.colnames[j][group_ix]</span>
            <span class="s1">na = [</span><span class="s3">&quot;%s[%s]&quot; </span><span class="s1">% (v</span><span class="s2">, </span><span class="s1">s) </span><span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">vg]</span>
            <span class="s1">names.extend(na)</span>

        <span class="s2">return </span><span class="s1">names</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">random_effects(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        The conditional means of random effects given the data. 
 
        Returns 
        ------- 
        random_effects : dict 
            A dictionary mapping the distinct `group` values to the 
            conditional means of the random effects for the group 
            given the data. 
        &quot;&quot;&quot;</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.linalg.inv(self.cov_re)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Cannot predict random effects from &quot; </span><span class="s1">+</span>
                             <span class="s3">&quot;singular covariance structure.&quot;</span><span class="s1">)</span>

        <span class="s1">vcomp = self.vcomp</span>
        <span class="s1">k_re = self.k_re</span>

        <span class="s1">ranef_dict = {}</span>
        <span class="s2">for </span><span class="s1">group_ix</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">enumerate(self.model.group_labels):</span>

            <span class="s1">endog = self.model.endog_li[group_ix]</span>
            <span class="s1">exog = self.model.exog_li[group_ix]</span>
            <span class="s1">ex_r = self.model._aex_r[group_ix]</span>
            <span class="s1">ex2_r = self.model._aex_r2[group_ix]</span>
            <span class="s1">vc_var = self.model._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>

            <span class="s4"># Get the residuals relative to fixed effects</span>
            <span class="s1">resid = endog</span>
            <span class="s2">if </span><span class="s1">self.k_fe &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">expval = np.dot(exog</span><span class="s2">, </span><span class="s1">self.fe_params)</span>
                <span class="s1">resid = resid - expval</span>

            <span class="s1">solver = _smw_solver(self.scale</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">,</span>
                                 <span class="s5">1 </span><span class="s1">/ vc_var)</span>
            <span class="s1">vir = solver(resid)</span>

            <span class="s1">xtvir = _dot(ex_r.T</span><span class="s2">, </span><span class="s1">vir)</span>

            <span class="s1">xtvir[</span><span class="s5">0</span><span class="s1">:k_re] = np.dot(self.cov_re</span><span class="s2">, </span><span class="s1">xtvir[</span><span class="s5">0</span><span class="s1">:k_re])</span>
            <span class="s1">xtvir[k_re:] *= vc_var</span>
            <span class="s1">ranef_dict[group] = pd.Series(</span>
                <span class="s1">xtvir</span><span class="s2">, </span><span class="s1">index=self._expand_re_names(group_ix))</span>

        <span class="s2">return </span><span class="s1">ranef_dict</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">random_effects_cov(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the conditional covariance matrix of the random 
        effects for each group given the data. 
 
        Returns 
        ------- 
        random_effects_cov : dict 
            A dictionary mapping the distinct values of the `group` 
            variable to the conditional covariance matrix of the 
            random effects given the data. 
        &quot;&quot;&quot;</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">cov_re_inv = np.linalg.inv(self.cov_re)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">cov_re_inv = </span><span class="s2">None</span>

        <span class="s1">vcomp = self.vcomp</span>

        <span class="s1">ranef_dict = {}</span>
        <span class="s2">for </span><span class="s1">group_ix </span><span class="s2">in </span><span class="s1">range(self.model.n_groups):</span>

            <span class="s1">ex_r = self.model._aex_r[group_ix]</span>
            <span class="s1">ex2_r = self.model._aex_r2[group_ix]</span>
            <span class="s1">label = self.model.group_labels[group_ix]</span>
            <span class="s1">vc_var = self.model._expand_vcomp(vcomp</span><span class="s2">, </span><span class="s1">group_ix)</span>

            <span class="s1">solver = _smw_solver(self.scale</span><span class="s2">, </span><span class="s1">ex_r</span><span class="s2">, </span><span class="s1">ex2_r</span><span class="s2">, </span><span class="s1">cov_re_inv</span><span class="s2">,</span>
                                 <span class="s5">1 </span><span class="s1">/ vc_var)</span>

            <span class="s1">n = ex_r.shape[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">m = self.cov_re.shape[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">mat1 = np.empty((n</span><span class="s2">, </span><span class="s1">m + len(vc_var)))</span>
            <span class="s1">mat1[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:m] = np.dot(ex_r[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:m]</span><span class="s2">, </span><span class="s1">self.cov_re)</span>
            <span class="s1">mat1[:</span><span class="s2">, </span><span class="s1">m:] = np.dot(ex_r[:</span><span class="s2">, </span><span class="s1">m:]</span><span class="s2">, </span><span class="s1">np.diag(vc_var))</span>
            <span class="s1">mat2 = solver(mat1)</span>
            <span class="s1">mat2 = np.dot(mat1.T</span><span class="s2">, </span><span class="s1">mat2)</span>

            <span class="s1">v = -mat2</span>
            <span class="s1">v[</span><span class="s5">0</span><span class="s1">:m</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:m] += self.cov_re</span>
            <span class="s1">ix = np.arange(m</span><span class="s2">, </span><span class="s1">v.shape[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s1">v[ix</span><span class="s2">, </span><span class="s1">ix] += vc_var</span>
            <span class="s1">na = self._expand_re_names(group_ix)</span>
            <span class="s1">v = pd.DataFrame(v</span><span class="s2">, </span><span class="s1">index=na</span><span class="s2">, </span><span class="s1">columns=na)</span>
            <span class="s1">ranef_dict[label] = v</span>

        <span class="s2">return </span><span class="s1">ranef_dict</span>

    <span class="s4"># Need to override since t-tests are only used for fixed effects</span>
    <span class="s4"># parameters.</span>
    <span class="s2">def </span><span class="s1">t_test(self</span><span class="s2">, </span><span class="s1">r_matrix</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute a t-test for a each linear hypothesis of the form Rb = q 
 
        Parameters 
        ---------- 
        r_matrix : array_like 
            If an array is given, a p x k 2d array or length k 1d 
            array specifying the linear restrictions. It is assumed 
            that the linear combination is equal to zero. 
        scale : float, optional 
            An optional `scale` to use.  Default is the scale specified 
            by the model fit. 
        use_t : bool, optional 
            If use_t is None, then the default of the model is used. 
            If use_t is True, then the p-values are based on the t 
            distribution. 
            If use_t is False, then the p-values are based on the normal 
            distribution. 
 
        Returns 
        ------- 
        res : ContrastResults instance 
            The results for the test are attributes of this results instance. 
            The available results have the same elements as the parameter table 
            in `summary()`. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">r_matrix.shape[</span><span class="s5">1</span><span class="s1">] != self.k_fe:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;r_matrix for t-test should have %d columns&quot;</span>
                             <span class="s1">% self.k_fe)</span>

        <span class="s1">d = self.k_re2 + self.k_vc</span>
        <span class="s1">z0 = np.zeros((r_matrix.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">d))</span>
        <span class="s1">r_matrix = np.concatenate((r_matrix</span><span class="s2">, </span><span class="s1">z0)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">tst_rslt = super(MixedLMResults</span><span class="s2">, </span><span class="s1">self).t_test(r_matrix</span><span class="s2">, </span><span class="s1">use_t=use_t)</span>
        <span class="s2">return </span><span class="s1">tst_rslt</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">yname=</span><span class="s2">None, </span><span class="s1">xname_fe=</span><span class="s2">None, </span><span class="s1">xname_re=</span><span class="s2">None,</span>
                <span class="s1">title=</span><span class="s2">None, </span><span class="s1">alpha=</span><span class="s5">.05</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Summarize the mixed model regression results. 
 
        Parameters 
        ---------- 
        yname : str, optional 
            Default is `y` 
        xname_fe : list[str], optional 
            Fixed effects covariate names 
        xname_re : list[str], optional 
            Random effects covariate names 
        title : str, optional 
            Title for the top table. If not None, then this replaces 
            the default title 
        alpha : float 
            significance level for the confidence intervals 
 
        Returns 
        ------- 
        smry : Summary instance 
            this holds the summary tables and text, which can be 
            printed or converted to various output formats. 
 
        See Also 
        -------- 
        statsmodels.iolib.summary2.Summary : class to hold summary results 
        &quot;&quot;&quot;</span>

        <span class="s2">from </span><span class="s1">statsmodels.iolib </span><span class="s2">import </span><span class="s1">summary2</span>
        <span class="s1">smry = summary2.Summary()</span>

        <span class="s1">info = {}</span>
        <span class="s1">info[</span><span class="s3">&quot;Model:&quot;</span><span class="s1">] = </span><span class="s3">&quot;MixedLM&quot;</span>
        <span class="s2">if </span><span class="s1">yname </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">yname = self.model.endog_names</span>

        <span class="s1">param_names = self.model.data.param_names[:]</span>
        <span class="s1">k_fe_params = len(self.fe_params)</span>
        <span class="s1">k_re_params = len(param_names) - len(self.fe_params)</span>

        <span class="s2">if </span><span class="s1">xname_fe </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(xname_fe) != k_fe_params:</span>
                <span class="s1">msg = </span><span class="s3">&quot;xname_fe should be a list of length %d&quot; </span><span class="s1">% k_fe_params</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
            <span class="s1">param_names[:k_fe_params] = xname_fe</span>

        <span class="s2">if </span><span class="s1">xname_re </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(xname_re) != k_re_params:</span>
                <span class="s1">msg = </span><span class="s3">&quot;xname_re should be a list of length %d&quot; </span><span class="s1">% k_re_params</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
            <span class="s1">param_names[k_fe_params:] = xname_re</span>

        <span class="s1">info[</span><span class="s3">&quot;No. Observations:&quot;</span><span class="s1">] = str(self.model.n_totobs)</span>
        <span class="s1">info[</span><span class="s3">&quot;No. Groups:&quot;</span><span class="s1">] = str(self.model.n_groups)</span>

        <span class="s1">gs = np.array([len(x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.model.endog_li])</span>
        <span class="s1">info[</span><span class="s3">&quot;Min. group size:&quot;</span><span class="s1">] = </span><span class="s3">&quot;%.0f&quot; </span><span class="s1">% min(gs)</span>
        <span class="s1">info[</span><span class="s3">&quot;Max. group size:&quot;</span><span class="s1">] = </span><span class="s3">&quot;%.0f&quot; </span><span class="s1">% max(gs)</span>
        <span class="s1">info[</span><span class="s3">&quot;Mean group size:&quot;</span><span class="s1">] = </span><span class="s3">&quot;%.1f&quot; </span><span class="s1">% np.mean(gs)</span>

        <span class="s1">info[</span><span class="s3">&quot;Dependent Variable:&quot;</span><span class="s1">] = yname</span>
        <span class="s1">info[</span><span class="s3">&quot;Method:&quot;</span><span class="s1">] = self.method</span>
        <span class="s1">info[</span><span class="s3">&quot;Scale:&quot;</span><span class="s1">] = self.scale</span>
        <span class="s1">info[</span><span class="s3">&quot;Log-Likelihood:&quot;</span><span class="s1">] = self.llf</span>
        <span class="s1">info[</span><span class="s3">&quot;Converged:&quot;</span><span class="s1">] = </span><span class="s3">&quot;Yes&quot; </span><span class="s2">if </span><span class="s1">self.converged </span><span class="s2">else </span><span class="s3">&quot;No&quot;</span>
        <span class="s1">smry.add_dict(info)</span>
        <span class="s1">smry.add_title(</span><span class="s3">&quot;Mixed Linear Model Regression Results&quot;</span><span class="s1">)</span>

        <span class="s1">float_fmt = </span><span class="s3">&quot;%.3f&quot;</span>

        <span class="s1">sdf = np.nan * np.ones((self.k_fe + self.k_re2 + self.k_vc</span><span class="s2">, </span><span class="s5">6</span><span class="s1">))</span>

        <span class="s4"># Coefficient estimates</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = self.fe_params</span>

        <span class="s4"># Standard errors</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = np.sqrt(np.diag(self.cov_params()[</span><span class="s5">0</span><span class="s1">:self.k_fe]))</span>

        <span class="s4"># Z-scores</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">2</span><span class="s1">] = sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] / sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s4"># p-values</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">3</span><span class="s1">] = </span><span class="s5">2 </span><span class="s1">* norm.cdf(-np.abs(sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]))</span>

        <span class="s4"># Confidence intervals</span>
        <span class="s1">qm = -norm.ppf(alpha / </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">4</span><span class="s1">] = sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] - qm * sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">5</span><span class="s1">] = sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] + qm * sdf[</span><span class="s5">0</span><span class="s1">:self.k_fe</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s4"># All random effects variances and covariances</span>
        <span class="s1">jj = self.k_fe</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_re):</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(i + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s1">sdf[jj</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = self.cov_re[i</span><span class="s2">, </span><span class="s1">j]</span>
                <span class="s1">sdf[jj</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = np.sqrt(self.scale) * self.bse[jj]</span>
                <span class="s1">jj += </span><span class="s5">1</span>

        <span class="s4"># Variance components</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_vc):</span>
            <span class="s1">sdf[jj</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = self.vcomp[i]</span>
            <span class="s1">sdf[jj</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = np.sqrt(self.scale) * self.bse[jj]</span>
            <span class="s1">jj += </span><span class="s5">1</span>

        <span class="s1">sdf = pd.DataFrame(index=param_names</span><span class="s2">, </span><span class="s1">data=sdf)</span>
        <span class="s1">sdf.columns = [</span><span class="s3">'Coef.'</span><span class="s2">, </span><span class="s3">'Std.Err.'</span><span class="s2">, </span><span class="s3">'z'</span><span class="s2">, </span><span class="s3">'P&gt;|z|'</span><span class="s2">,</span>
                       <span class="s3">'[' </span><span class="s1">+ str(alpha/</span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">str(</span><span class="s5">1</span><span class="s1">-alpha/</span><span class="s5">2</span><span class="s1">) + </span><span class="s3">']'</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">sdf.columns:</span>
            <span class="s1">sdf[col] = [float_fmt % x </span><span class="s2">if </span><span class="s1">np.isfinite(x) </span><span class="s2">else </span><span class="s3">&quot;&quot;</span>
                        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">sdf[col]]</span>

        <span class="s1">smry.add_df(sdf</span><span class="s2">, </span><span class="s1">align=</span><span class="s3">'r'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">smry</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">llf(self):</span>
        <span class="s2">return </span><span class="s1">self.model.loglike(self.params_object</span><span class="s2">, </span><span class="s1">profile_fe=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">aic(self):</span>
        <span class="s0">&quot;&quot;&quot;Akaike information criterion&quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s2">return </span><span class="s1">np.nan</span>
        <span class="s2">if </span><span class="s1">self.freepat </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">df = self.freepat.get_packed(use_sqrt=</span><span class="s2">False, </span><span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">).sum() + </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">df = self.params.size + </span><span class="s5">1</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">2 </span><span class="s1">* (self.llf - df)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bic(self):</span>
        <span class="s0">&quot;&quot;&quot;Bayesian information criterion&quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.reml:</span>
            <span class="s2">return </span><span class="s1">np.nan</span>
        <span class="s2">if </span><span class="s1">self.freepat </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">df = self.freepat.get_packed(use_sqrt=</span><span class="s2">False, </span><span class="s1">has_fe=</span><span class="s2">True</span><span class="s1">).sum() + </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">df = self.params.size + </span><span class="s5">1</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">2 </span><span class="s1">* self.llf + np.log(self.nobs) * df</span>

    <span class="s2">def </span><span class="s1">profile_re(self</span><span class="s2">, </span><span class="s1">re_ix</span><span class="s2">, </span><span class="s1">vtype</span><span class="s2">, </span><span class="s1">num_low=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">dist_low=</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">num_high=</span><span class="s5">5</span><span class="s2">,</span>
                   <span class="s1">dist_high=</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">**fit_kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Profile-likelihood inference for variance parameters. 
 
        Parameters 
        ---------- 
        re_ix : int 
            If vtype is `re`, this value is the index of the variance 
            parameter for which to construct a profile likelihood.  If 
            `vtype` is 'vc' then `re_ix` is the name of the variance 
            parameter to be profiled. 
        vtype : str 
            Either 're' or 'vc', depending on whether the profile 
            analysis is for a random effect or a variance component. 
        num_low : int 
            The number of points at which to calculate the likelihood 
            below the MLE of the parameter of interest. 
        dist_low : float 
            The distance below the MLE of the parameter of interest to 
            begin calculating points on the profile likelihood. 
        num_high : int 
            The number of points at which to calculate the likelihood 
            above the MLE of the parameter of interest. 
        dist_high : float 
            The distance above the MLE of the parameter of interest to 
            begin calculating points on the profile likelihood. 
        **fit_kwargs 
            Additional keyword arguments passed to fit. 
 
        Returns 
        ------- 
        An array with two columns.  The first column contains the 
        values to which the parameter of interest is constrained.  The 
        second column contains the corresponding likelihood values. 
 
        Notes 
        ----- 
        Only variance parameters can be profiled. 
        &quot;&quot;&quot;</span>

        <span class="s1">pmodel = self.model</span>
        <span class="s1">k_fe = pmodel.k_fe</span>
        <span class="s1">k_re = pmodel.k_re</span>
        <span class="s1">k_vc = pmodel.k_vc</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog = pmodel.endog</span><span class="s2">, </span><span class="s1">pmodel.exog</span>

        <span class="s4"># Need to permute the columns of the random effects design</span>
        <span class="s4"># matrix so that the profiled variable is in the first column.</span>
        <span class="s2">if </span><span class="s1">vtype == </span><span class="s3">'re'</span><span class="s1">:</span>
            <span class="s1">ix = np.arange(k_re)</span>
            <span class="s1">ix[</span><span class="s5">0</span><span class="s1">] = re_ix</span>
            <span class="s1">ix[re_ix] = </span><span class="s5">0</span>
            <span class="s1">exog_re = pmodel.exog_re.copy()[:</span><span class="s2">, </span><span class="s1">ix]</span>

            <span class="s4"># Permute the covariance structure to match the permuted</span>
            <span class="s4"># design matrix.</span>
            <span class="s1">params = self.params_object.copy()</span>
            <span class="s1">cov_re_unscaled = params.cov_re</span>
            <span class="s1">cov_re_unscaled = cov_re_unscaled[np.ix_(ix</span><span class="s2">, </span><span class="s1">ix)]</span>
            <span class="s1">params.cov_re = cov_re_unscaled</span>
            <span class="s1">ru0 = cov_re_unscaled[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>

            <span class="s4"># Convert dist_low and dist_high to the profile</span>
            <span class="s4"># parameterization</span>
            <span class="s1">cov_re = self.scale * cov_re_unscaled</span>
            <span class="s1">low = (cov_re[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] - dist_low) / self.scale</span>
            <span class="s1">high = (cov_re[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] + dist_high) / self.scale</span>

        <span class="s2">elif </span><span class="s1">vtype == </span><span class="s3">'vc'</span><span class="s1">:</span>
            <span class="s1">re_ix = self.model.exog_vc.names.index(re_ix)</span>
            <span class="s1">params = self.params_object.copy()</span>
            <span class="s1">vcomp = self.vcomp</span>
            <span class="s1">low = (vcomp[re_ix] - dist_low) / self.scale</span>
            <span class="s1">high = (vcomp[re_ix] + dist_high) / self.scale</span>
            <span class="s1">ru0 = vcomp[re_ix] / self.scale</span>

        <span class="s4"># Define the sequence of values to which the parameter of</span>
        <span class="s4"># interest will be constrained.</span>
        <span class="s2">if </span><span class="s1">low &lt;= </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;dist_low is too large and would result in a &quot;</span>
                             <span class="s3">&quot;negative variance. Try a smaller value.&quot;</span><span class="s1">)</span>
        <span class="s1">left = np.linspace(low</span><span class="s2">, </span><span class="s1">ru0</span><span class="s2">, </span><span class="s1">num_low + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">right = np.linspace(ru0</span><span class="s2">, </span><span class="s1">high</span><span class="s2">, </span><span class="s1">num_high+</span><span class="s5">1</span><span class="s1">)[</span><span class="s5">1</span><span class="s1">:]</span>
        <span class="s1">rvalues = np.concatenate((left</span><span class="s2">, </span><span class="s1">right))</span>

        <span class="s4"># Indicators of which parameters are free and fixed.</span>
        <span class="s1">free = MixedLMParams(k_fe</span><span class="s2">, </span><span class="s1">k_re</span><span class="s2">, </span><span class="s1">k_vc)</span>
        <span class="s2">if </span><span class="s1">self.freepat </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">free.fe_params = np.ones(k_fe)</span>
            <span class="s1">vcomp = np.ones(k_vc)</span>
            <span class="s1">mat = np.ones((k_re</span><span class="s2">, </span><span class="s1">k_re))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># If a freepat already has been specified, we add the</span>
            <span class="s4"># constraint to it.</span>
            <span class="s1">free.fe_params = self.freepat.fe_params</span>
            <span class="s1">vcomp = self.freepat.vcomp</span>
            <span class="s1">mat = self.freepat.cov_re</span>
            <span class="s2">if </span><span class="s1">vtype == </span><span class="s3">'re'</span><span class="s1">:</span>
                <span class="s1">mat = mat[np.ix_(ix</span><span class="s2">, </span><span class="s1">ix)]</span>
        <span class="s2">if </span><span class="s1">vtype == </span><span class="s3">'re'</span><span class="s1">:</span>
            <span class="s1">mat[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">vcomp[re_ix] = </span><span class="s5">0</span>
        <span class="s1">free.cov_re = mat</span>
        <span class="s1">free.vcomp = vcomp</span>

        <span class="s1">klass = self.model.__class__</span>
        <span class="s1">init_kwargs = pmodel._get_init_kwds()</span>
        <span class="s2">if </span><span class="s1">vtype == </span><span class="s3">'re'</span><span class="s1">:</span>
            <span class="s1">init_kwargs[</span><span class="s3">'exog_re'</span><span class="s1">] = exog_re</span>

        <span class="s1">likev = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rvalues:</span>

            <span class="s1">model = klass(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">**init_kwargs)</span>

            <span class="s2">if </span><span class="s1">vtype == </span><span class="s3">'re'</span><span class="s1">:</span>
                <span class="s1">cov_re = params.cov_re.copy()</span>
                <span class="s1">cov_re[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = x</span>
                <span class="s1">params.cov_re = cov_re</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">params.vcomp[re_ix] = x</span>

            <span class="s4"># TODO should use fit_kwargs</span>
            <span class="s1">rslt = model.fit(start_params=params</span><span class="s2">, </span><span class="s1">free=free</span><span class="s2">,</span>
                             <span class="s1">reml=self.reml</span><span class="s2">, </span><span class="s1">cov_pen=self.cov_pen</span><span class="s2">,</span>
                             <span class="s1">**fit_kwargs)._results</span>
            <span class="s1">likev.append([x * rslt.scale</span><span class="s2">, </span><span class="s1">rslt.llf])</span>

        <span class="s1">likev = np.asarray(likev)</span>

        <span class="s2">return </span><span class="s1">likev</span>


<span class="s2">class </span><span class="s1">MixedLMResultsWrapper(base.LikelihoodResultsWrapper):</span>
    <span class="s1">_attrs = {</span><span class="s3">'bse_re'</span><span class="s1">: (</span><span class="s3">'generic_columns'</span><span class="s2">, </span><span class="s3">'exog_re_names_full'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s3">'fe_params'</span><span class="s1">: (</span><span class="s3">'generic_columns'</span><span class="s2">, </span><span class="s3">'xnames'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s3">'bse_fe'</span><span class="s1">: (</span><span class="s3">'generic_columns'</span><span class="s2">, </span><span class="s3">'xnames'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s3">'cov_re'</span><span class="s1">: (</span><span class="s3">'generic_columns_2d'</span><span class="s2">, </span><span class="s3">'exog_re_names'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s3">'cov_re_unscaled'</span><span class="s1">: (</span><span class="s3">'generic_columns_2d'</span><span class="s2">, </span><span class="s3">'exog_re_names'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">}</span>
    <span class="s1">_upstream_attrs = base.LikelihoodResultsWrapper._wrap_attrs</span>
    <span class="s1">_wrap_attrs = base.wrap.union_dicts(_attrs</span><span class="s2">, </span><span class="s1">_upstream_attrs)</span>

    <span class="s1">_methods = {}</span>
    <span class="s1">_upstream_methods = base.LikelihoodResultsWrapper._wrap_methods</span>
    <span class="s1">_wrap_methods = base.wrap.union_dicts(_methods</span><span class="s2">, </span><span class="s1">_upstream_methods)</span>


<span class="s2">def </span><span class="s1">_handle_missing(data</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">formula</span><span class="s2">, </span><span class="s1">re_formula</span><span class="s2">, </span><span class="s1">vc_formula):</span>

    <span class="s1">tokens = set()</span>

    <span class="s1">forms = [formula]</span>
    <span class="s2">if </span><span class="s1">re_formula </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">forms.append(re_formula)</span>
    <span class="s2">if </span><span class="s1">vc_formula </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">forms.extend(vc_formula.values())</span>

    <span class="s2">from </span><span class="s1">statsmodels.compat.python </span><span class="s2">import </span><span class="s1">asunicode</span>

    <span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">StringIO</span>
    <span class="s2">import </span><span class="s1">tokenize</span>
    <span class="s1">skiptoks = {</span><span class="s3">&quot;(&quot;</span><span class="s2">, </span><span class="s3">&quot;)&quot;</span><span class="s2">, </span><span class="s3">&quot;*&quot;</span><span class="s2">, </span><span class="s3">&quot;:&quot;</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s3">&quot;-&quot;</span><span class="s2">, </span><span class="s3">&quot;**&quot;</span><span class="s2">, </span><span class="s3">&quot;/&quot;</span><span class="s1">}</span>

    <span class="s2">for </span><span class="s1">fml </span><span class="s2">in </span><span class="s1">forms:</span>
        <span class="s4"># Unicode conversion is for Py2 compatability</span>
        <span class="s1">rl = StringIO(fml)</span>

        <span class="s2">def </span><span class="s1">rlu():</span>
            <span class="s1">line = rl.readline()</span>
            <span class="s2">return </span><span class="s1">asunicode(line</span><span class="s2">, </span><span class="s3">'ascii'</span><span class="s1">)</span>
        <span class="s1">g = tokenize.generate_tokens(rlu)</span>
        <span class="s2">for </span><span class="s1">tok </span><span class="s2">in </span><span class="s1">g:</span>
            <span class="s2">if </span><span class="s1">tok </span><span class="s2">not in </span><span class="s1">skiptoks:</span>
                <span class="s1">tokens.add(tok.string)</span>
    <span class="s1">tokens = sorted(tokens &amp; set(data.columns))</span>

    <span class="s1">data = data[tokens]</span>
    <span class="s1">ii = pd.notnull(data).all(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">type(groups) != </span><span class="s3">&quot;str&quot;</span><span class="s1">:</span>
        <span class="s1">ii &amp;= pd.notnull(groups)</span>

    <span class="s2">return </span><span class="s1">data.loc[ii</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">groups[np.asarray(ii)]</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_pca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_pca.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">statsmodels.compat.platform </span><span class="s0">import </span><span class="s1">PLATFORM_WIN32</span>

<span class="s0">import </span><span class="s1">warnings</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_equal</span><span class="s0">, </span><span class="s1">assert_raises</span>

<span class="s0">from </span><span class="s1">statsmodels.multivariate.pca </span><span class="s0">import </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">pca</span>
<span class="s0">from </span><span class="s1">statsmodels.multivariate.tests.results.datamlw </span><span class="s0">import </span><span class="s1">(data</span><span class="s0">, </span><span class="s1">princomp1</span><span class="s0">,</span>
                                                            <span class="s1">princomp2)</span>
<span class="s0">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s0">import </span><span class="s1">EstimationWarning</span>

<span class="s1">DECIMAL_5 = </span><span class="s2">.00001</span>


<span class="s0">class </span><span class="s1">TestPCA:</span>
    <span class="s1">@classmethod</span>
    <span class="s0">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">rs = np.random.RandomState()</span>
        <span class="s1">rs.seed(</span><span class="s2">1234</span><span class="s1">)</span>
        <span class="s1">k = </span><span class="s2">3</span>
        <span class="s1">n = </span><span class="s2">100</span>
        <span class="s1">t = </span><span class="s2">200</span>
        <span class="s1">lam = </span><span class="s2">2</span>

        <span class="s1">norm_rng = rs.standard_normal</span>
        <span class="s1">e = norm_rng((t</span><span class="s0">, </span><span class="s1">n))</span>
        <span class="s1">f = norm_rng((t</span><span class="s0">, </span><span class="s1">k))</span>
        <span class="s1">b = rs.standard_gamma(lam</span><span class="s0">, </span><span class="s1">size=(k</span><span class="s0">, </span><span class="s1">n)) / lam</span>
        <span class="s1">cls.x = f.dot(b) + e</span>
        <span class="s1">cls.x_copy = cls.x + </span><span class="s2">0.0</span>
        <span class="s1">cls.rs = rs</span>

        <span class="s1">k = </span><span class="s2">3</span>
        <span class="s1">n = </span><span class="s2">300</span>
        <span class="s1">t = </span><span class="s2">200</span>
        <span class="s1">lam = </span><span class="s2">2</span>

        <span class="s1">norm_rng = rs.standard_normal</span>
        <span class="s1">e = norm_rng((t</span><span class="s0">, </span><span class="s1">n))</span>
        <span class="s1">f = norm_rng((t</span><span class="s0">, </span><span class="s1">k))</span>
        <span class="s1">b = rs.standard_gamma(lam</span><span class="s0">, </span><span class="s1">size=(k</span><span class="s0">, </span><span class="s1">n)) / lam</span>
        <span class="s1">cls.x_wide = f.dot(b) + e</span>

    <span class="s1">@pytest.mark.smoke</span>
    <span class="s1">@pytest.mark.matplotlib</span>
    <span class="s0">def </span><span class="s1">test_smoke_plot_and_repr(self</span><span class="s0">, </span><span class="s1">close_figures):</span>
        <span class="s1">pc = PCA(self.x)</span>
        <span class="s1">fig = pc.plot_scree()</span>
        <span class="s1">fig = pc.plot_scree(ncomp=</span><span class="s2">10</span><span class="s1">)</span>
        <span class="s1">fig = pc.plot_scree(log_scale=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">fig = pc.plot_scree(cumulative=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">fig = pc.plot_rsquare()</span>
        <span class="s1">fig = pc.plot_rsquare(ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s3"># Additional smoke test</span>
        <span class="s1">pc.__repr__()</span>
        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">pc.__repr__()</span>
        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">pc.__repr__()</span>
        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s4">&quot;GLS&quot; </span><span class="s0">in </span><span class="s1">pc.__repr__()</span>
        <span class="s3"># Check data for no changes</span>
        <span class="s1">assert_equal(self.x</span><span class="s0">, </span><span class="s1">pc.data)</span>

    <span class="s0">def </span><span class="s1">test_eig_svd_equiv(self):</span>
        <span class="s3"># Test leading components since the tail end can differ</span>
        <span class="s1">pc_eig = PCA(self.x)</span>
        <span class="s1">pc_svd = PCA(self.x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'svd'</span><span class="s1">)</span>

        <span class="s1">assert_allclose(pc_eig.projection</span><span class="s0">, </span><span class="s1">pc_svd.projection)</span>
        <span class="s1">assert_allclose(np.abs(pc_eig.factors[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">2</span><span class="s1">])</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.factors[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">2</span><span class="s1">]))</span>
        <span class="s1">assert_allclose(np.abs(pc_eig.coeff[:</span><span class="s2">2</span><span class="s0">, </span><span class="s1">:])</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.coeff[:</span><span class="s2">2</span><span class="s0">, </span><span class="s1">:]))</span>
        <span class="s1">assert_allclose(pc_eig.eigenvals</span><span class="s0">,</span>
                        <span class="s1">pc_svd.eigenvals)</span>
        <span class="s1">assert_allclose(np.abs(pc_eig.eigenvecs[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">2</span><span class="s1">])</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.eigenvecs[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">2</span><span class="s1">]))</span>

        <span class="s1">pc_svd = PCA(self.x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'svd'</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s1">pc_nipals = PCA(self.x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'nipals'</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s1">assert_allclose(np.abs(pc_nipals.factors)</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.factors)</span><span class="s0">,</span>
                        <span class="s1">atol=DECIMAL_5)</span>
        <span class="s1">assert_allclose(np.abs(pc_nipals.coeff)</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.coeff)</span><span class="s0">,</span>
                        <span class="s1">atol=DECIMAL_5)</span>
        <span class="s1">assert_allclose(pc_nipals.eigenvals</span><span class="s0">,</span>
                        <span class="s1">pc_svd.eigenvals</span><span class="s0">,</span>
                        <span class="s1">atol=DECIMAL_5)</span>
        <span class="s1">assert_allclose(np.abs(pc_nipals.eigenvecs)</span><span class="s0">,</span>
                        <span class="s1">np.abs(pc_svd.eigenvecs)</span><span class="s0">,</span>
                        <span class="s1">atol=DECIMAL_5)</span>
        <span class="s3"># Check data for no changes</span>
        <span class="s1">assert_equal(self.x</span><span class="s0">, </span><span class="s1">pc_svd.data)</span>
        <span class="s3"># Check data for no changes</span>
        <span class="s1">assert_equal(self.x</span><span class="s0">, </span><span class="s1">pc_eig.data)</span>
        <span class="s3"># Check data for no changes</span>
        <span class="s1">assert_equal(self.x</span><span class="s0">, </span><span class="s1">pc_nipals.data)</span>

    <span class="s0">def </span><span class="s1">test_options(self):</span>
        <span class="s1">pc = PCA(self.x)</span>
        <span class="s1">pc_no_norm = PCA(self.x</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.factors.dot(pc.coeff)</span><span class="s0">,</span>
                        <span class="s1">pc_no_norm.factors.dot(pc_no_norm.coeff))</span>
        <span class="s1">princomp = pc.factors</span>
        <span class="s1">assert_allclose(princomp.T.dot(princomp)</span><span class="s0">, </span><span class="s1">np.eye(</span><span class="s2">100</span><span class="s1">)</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>
        <span class="s1">weights = pc_no_norm.coeff</span>
        <span class="s1">assert_allclose(weights.T.dot(weights)</span><span class="s0">, </span><span class="s1">np.eye(</span><span class="s2">100</span><span class="s1">)</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>

        <span class="s1">pc_10 = PCA(self.x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">10</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.factors[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">10</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pc_10.factors)</span>
        <span class="s1">assert_allclose(pc.coeff[:</span><span class="s2">10</span><span class="s0">, </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">pc_10.coeff)</span>
        <span class="s1">assert_allclose(pc.rsquare[:(</span><span class="s2">10 </span><span class="s1">+ </span><span class="s2">1</span><span class="s1">)]</span><span class="s0">, </span><span class="s1">pc_10.rsquare)</span>
        <span class="s1">assert_allclose(pc.eigenvals[:</span><span class="s2">10</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pc_10.eigenvals)</span>
        <span class="s1">assert_allclose(pc.eigenvecs[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">10</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pc_10.eigenvecs)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">normalize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">mu = self.x.mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">xdm = self.x - mu</span>
        <span class="s1">xpx = xdm.T.dot(xdm)</span>
        <span class="s1">val</span><span class="s0">, </span><span class="s1">vec = np.linalg.eigh(xpx)</span>
        <span class="s1">ind = np.argsort(val)</span>
        <span class="s1">ind = ind[::-</span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">val = val[ind]</span>
        <span class="s1">vec = vec[:</span><span class="s0">, </span><span class="s1">ind]</span>
        <span class="s1">assert_allclose(xdm</span><span class="s0">, </span><span class="s1">pc.transformed_data)</span>
        <span class="s1">assert_allclose(val</span><span class="s0">, </span><span class="s1">pc.eigenvals)</span>
        <span class="s1">assert_allclose(np.abs(vec)</span><span class="s0">, </span><span class="s1">np.abs(pc.eigenvecs))</span>
        <span class="s1">assert_allclose(np.abs(pc.factors)</span><span class="s0">, </span><span class="s1">np.abs(xdm.dot(vec)))</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">xdm + mu)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False, </span><span class="s1">normalize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">x = self.x</span>
        <span class="s1">xpx = x.T.dot(x)</span>
        <span class="s1">val</span><span class="s0">, </span><span class="s1">vec = np.linalg.eigh(xpx)</span>
        <span class="s1">ind = np.argsort(val)</span>
        <span class="s1">ind = ind[::-</span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">val = val[ind]</span>
        <span class="s1">vec = vec[:</span><span class="s0">, </span><span class="s1">ind]</span>
        <span class="s1">assert_allclose(x</span><span class="s0">, </span><span class="s1">pc.transformed_data)</span>
        <span class="s1">assert_allclose(val</span><span class="s0">, </span><span class="s1">pc.eigenvals)</span>
        <span class="s1">assert_allclose(np.abs(vec)</span><span class="s0">, </span><span class="s1">np.abs(pc.eigenvecs))</span>
        <span class="s1">assert_allclose(np.abs(pc.factors)</span><span class="s0">, </span><span class="s1">np.abs(x.dot(vec)))</span>

    <span class="s0">def </span><span class="s1">test_against_reference(self):</span>
        <span class="s3"># Test against MATLAB, which by default demeans but does not standardize</span>
        <span class="s1">x = data.xo / </span><span class="s2">1000.0</span>
        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">False, </span><span class="s1">standardize=</span><span class="s0">False</span><span class="s1">)</span>

        <span class="s1">ref = princomp1</span>
        <span class="s1">assert_allclose(np.abs(pc.factors)</span><span class="s0">, </span><span class="s1">np.abs(ref.factors))</span>
        <span class="s1">assert_allclose(pc.factors.dot(pc.coeff) + x.mean(</span><span class="s2">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">x)</span>
        <span class="s1">assert_allclose(np.abs(pc.coeff)</span><span class="s0">, </span><span class="s1">np.abs(ref.coef.T))</span>
        <span class="s1">assert_allclose(pc.factors.dot(pc.coeff)</span><span class="s0">,</span>
                        <span class="s1">ref.factors.dot(ref.coef.T))</span>

        <span class="s1">pc = PCA(x[:</span><span class="s2">20</span><span class="s1">]</span><span class="s0">, </span><span class="s1">normalize=</span><span class="s0">False, </span><span class="s1">standardize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">mu = x[:</span><span class="s2">20</span><span class="s1">].mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">ref = princomp2</span>
        <span class="s1">assert_allclose(np.abs(pc.factors)</span><span class="s0">, </span><span class="s1">np.abs(ref.factors))</span>
        <span class="s1">assert_allclose(pc.factors.dot(pc.coeff) + mu</span><span class="s0">, </span><span class="s1">x[:</span><span class="s2">20</span><span class="s1">])</span>
        <span class="s1">assert_allclose(np.abs(pc.coeff)</span><span class="s0">, </span><span class="s1">np.abs(ref.coef.T))</span>
        <span class="s1">assert_allclose(pc.factors.dot(pc.coeff)</span><span class="s0">,</span>
                        <span class="s1">ref.factors.dot(ref.coef.T))</span>

    <span class="s0">def </span><span class="s1">test_warnings_and_errors(self):</span>
        <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">w:</span>
            <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">300</span><span class="s1">)</span>
            <span class="s1">assert_equal(len(w)</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>

        <span class="s0">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">w:</span>
            <span class="s1">rs = self.rs</span>
            <span class="s1">x = rs.standard_normal((</span><span class="s2">200</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)) * np.ones(</span><span class="s2">200</span><span class="s1">)</span>
            <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'eig'</span><span class="s1">)</span>
            <span class="s1">assert_equal(len(w)</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>

        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">self.x</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'unknown'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">self.x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'unknown'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">self.x</span><span class="s0">, </span><span class="s1">tol=</span><span class="s2">2.0</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">np.nan * np.ones((</span><span class="s2">200</span><span class="s0">, </span><span class="s2">100</span><span class="s1">))</span><span class="s0">, </span><span class="s1">tol=</span><span class="s2">2.0</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.matplotlib</span>
    <span class="s0">def </span><span class="s1">test_pandas(self</span><span class="s0">, </span><span class="s1">close_figures):</span>
        <span class="s1">pc = PCA(pd.DataFrame(self.x))</span>
        <span class="s1">pc1 = PCA(self.x)</span>
        <span class="s1">assert_allclose(pc.factors.values</span><span class="s0">, </span><span class="s1">pc1.factors)</span>
        <span class="s1">fig = pc.plot_scree()</span>
        <span class="s1">fig = pc.plot_scree(ncomp=</span><span class="s2">10</span><span class="s1">)</span>
        <span class="s1">fig = pc.plot_scree(log_scale=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">fig = pc.plot_rsquare()</span>
        <span class="s1">fig = pc.plot_rsquare(ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">proj = pc.project(</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s1">PCA(pd.DataFrame(self.x)</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">PCA(pd.DataFrame(self.x)</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">4</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_gls_and_weights(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">self.x</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">self.x</span><span class="s0">, </span><span class="s1">weights=np.array([</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">]))</span>

        <span class="s3"># Pre-standardize to make comparison simple</span>
        <span class="s1">x = (self.x - self.x.mean(</span><span class="s2">0</span><span class="s1">))</span>
        <span class="s1">x = x / (x ** </span><span class="s2">2.0</span><span class="s1">).mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">pc_gls = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">errors = x - pc.projection</span>
        <span class="s1">var = (errors ** </span><span class="s2">2.0</span><span class="s1">).mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">weights = </span><span class="s2">1.0 </span><span class="s1">/ var</span>
        <span class="s1">weights = weights / np.sqrt((weights ** </span><span class="s2">2.0</span><span class="s1">).mean())</span>

        <span class="s1">assert_allclose(weights</span><span class="s0">, </span><span class="s1">pc_gls.weights)</span>
        <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">pc_gls.data)</span>
        <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">pc.data)</span>

        <span class="s1">pc_weights = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False, </span><span class="s1">weights=weights)</span>

        <span class="s1">assert_allclose(weights</span><span class="s0">, </span><span class="s1">pc_weights.weights)</span>
        <span class="s1">assert_allclose(np.abs(pc_weights.factors)</span><span class="s0">, </span><span class="s1">np.abs(pc_gls.factors))</span>

    <span class="s1">@pytest.mark.slow</span>
    <span class="s0">def </span><span class="s1">test_wide(self):</span>
        <span class="s1">pc = PCA(self.x_wide)</span>
        <span class="s1">assert_equal(pc.factors.shape[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">self.x_wide.shape[</span><span class="s2">0</span><span class="s1">])</span>
        <span class="s1">assert_equal(pc.eigenvecs.shape[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">min(np.array(self.x_wide.shape)))</span>

        <span class="s1">pc = PCA(pd.DataFrame(self.x_wide))</span>
        <span class="s1">assert_equal(pc.factors.shape[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">self.x_wide.shape[</span><span class="s2">0</span><span class="s1">])</span>
        <span class="s1">assert_equal(pc.eigenvecs.shape[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">min(np.array(self.x_wide.shape)))</span>

    <span class="s0">def </span><span class="s1">test_projection(self):</span>
        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">mu = self.x.mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">demean_x = self.x - mu</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(demean_x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct + mu)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(demean_x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct + mu)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(self.x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">mu = self.x.mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">demean_x = self.x - mu</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(demean_x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct + mu)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(demean_x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct + mu)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">coef = np.linalg.pinv(pc.factors).dot(self.x)</span>
        <span class="s1">direct = pc.factors.dot(coef)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">direct)</span>

        <span class="s3"># Test error for too many factors</span>
        <span class="s1">project = pc.project</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">project</span><span class="s0">, </span><span class="s2">6</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.skipif(PLATFORM_WIN32</span><span class="s0">, </span><span class="s1">reason=</span><span class="s4">'Windows 32-bit'</span><span class="s1">)</span>
    <span class="s0">def </span><span class="s1">test_replace_missing(self):</span>
        <span class="s1">x = self.x.copy()</span>
        <span class="s1">x[::</span><span class="s2">5</span><span class="s0">, </span><span class="s1">::</span><span class="s2">7</span><span class="s1">] = np.nan</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-row'</span><span class="s1">)</span>
        <span class="s1">x_dropped_row = x[np.logical_not(np.any(np.isnan(x)</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))]</span>
        <span class="s1">pc_dropped = PCA(x_dropped_row)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection)</span>
        <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">pc.data)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-col'</span><span class="s1">)</span>
        <span class="s1">x_dropped_col = x[:</span><span class="s0">, </span><span class="s1">np.logical_not(np.any(np.isnan(x)</span><span class="s0">, </span><span class="s2">0</span><span class="s1">))]</span>
        <span class="s1">pc_dropped = PCA(x_dropped_col)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection)</span>
        <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">pc.data)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-min'</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">x_dropped_row.size &gt; x_dropped_col.size:</span>
            <span class="s1">x_dropped_min = x_dropped_row</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">x_dropped_min = x_dropped_col</span>
        <span class="s1">pc_dropped = PCA(x_dropped_min)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection)</span>
        <span class="s1">assert_equal(x</span><span class="s0">, </span><span class="s1">pc.data)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'fill-em'</span><span class="s1">)</span>
        <span class="s1">missing = np.isnan(x)</span>
        <span class="s1">mu = np.nanmean(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">errors = x - mu</span>
        <span class="s1">sigma = np.sqrt(np.nanmean(errors ** </span><span class="s2">2</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">))</span>
        <span class="s1">x_std = errors / sigma</span>
        <span class="s1">x_std[missing] = </span><span class="s2">0.0</span>
        <span class="s1">last = x_std[missing]</span>
        <span class="s1">delta = </span><span class="s2">1.0</span>
        <span class="s1">count = </span><span class="s2">0</span>
        <span class="s0">while </span><span class="s1">delta &gt; </span><span class="s2">5e-8</span><span class="s1">:</span>
            <span class="s1">pc_temp = PCA(x_std</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">x_std[missing] = pc_temp.projection[missing]</span>
            <span class="s1">current = x_std[missing]</span>
            <span class="s1">diff = current - last</span>
            <span class="s1">delta = np.sqrt(np.sum(diff ** </span><span class="s2">2</span><span class="s1">)) / np.sqrt(np.sum(current ** </span><span class="s2">2</span><span class="s1">))</span>
            <span class="s1">last = current</span>
            <span class="s1">count += </span><span class="s2">1</span>
        <span class="s1">x = self.x + </span><span class="s2">0.0</span>
        <span class="s1">projection = pc_temp.projection * sigma + mu</span>
        <span class="s1">x[missing] = projection[missing]</span>
        <span class="s1">assert_allclose(pc._adjusted_data</span><span class="s0">, </span><span class="s1">x)</span>
        <span class="s3"># Check data for no changes</span>
        <span class="s1">assert_equal(self.x</span><span class="s0">, </span><span class="s1">self.x_copy)</span>

        <span class="s1">x = self.x</span>
        <span class="s1">pc = PCA(x)</span>
        <span class="s1">pc_dropped = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-row'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection</span><span class="s0">, </span><span class="s1">atol=DECIMAL_5)</span>

        <span class="s1">pc_dropped = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-col'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection</span><span class="s0">, </span><span class="s1">atol=DECIMAL_5)</span>

        <span class="s1">pc_dropped = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-min'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection</span><span class="s0">, </span><span class="s1">atol=DECIMAL_5)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s1">)</span>
        <span class="s1">pc_dropped = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'fill-em'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.projection</span><span class="s0">, </span><span class="s1">pc_dropped.projection</span><span class="s0">, </span><span class="s1">atol=DECIMAL_5)</span>

        <span class="s3"># Test too many missing for missing='fill-em'</span>
        <span class="s1">x = self.x.copy()</span>
        <span class="s1">x[:</span><span class="s0">, </span><span class="s1">:] = np.nan</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-row'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-col'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-min'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">PCA</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'fill-em'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_rsquare(self):</span>
        <span class="s1">x = self.x + </span><span class="s2">0.0</span>
        <span class="s1">mu = x.mean(</span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">x_demean = x - mu</span>
        <span class="s1">std = np.std(x</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">x_std = x_demean / std</span>

        <span class="s1">pc = PCA(self.x)</span>
        <span class="s1">nvar = x.shape[</span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">rsquare = np.zeros(nvar + </span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">tss = np.sum(x_std ** </span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(nvar + </span><span class="s2">1</span><span class="s1">):</span>
            <span class="s1">errors = x_std - pc.project(i</span><span class="s0">, </span><span class="s1">transform=</span><span class="s0">False, </span><span class="s1">unweight=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">rsquare[i] = </span><span class="s2">1.0 </span><span class="s1">- np.sum(errors ** </span><span class="s2">2</span><span class="s1">) / tss</span>
        <span class="s1">assert_allclose(rsquare</span><span class="s0">, </span><span class="s1">pc.rsquare)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">tss = np.sum(x_demean ** </span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(nvar + </span><span class="s2">1</span><span class="s1">):</span>
            <span class="s1">errors = x_demean - pc.project(i</span><span class="s0">, </span><span class="s1">transform=</span><span class="s0">False, </span><span class="s1">unweight=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">rsquare[i] = </span><span class="s2">1.0 </span><span class="s1">- np.sum(errors ** </span><span class="s2">2</span><span class="s1">) / tss</span>
        <span class="s1">assert_allclose(rsquare</span><span class="s0">, </span><span class="s1">pc.rsquare)</span>

        <span class="s1">pc = PCA(self.x</span><span class="s0">, </span><span class="s1">standardize=</span><span class="s0">False, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">tss = np.sum(x ** </span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(nvar + </span><span class="s2">1</span><span class="s1">):</span>
            <span class="s1">errors = x - pc.project(i</span><span class="s0">, </span><span class="s1">transform=</span><span class="s0">False, </span><span class="s1">unweight=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">rsquare[i] = </span><span class="s2">1.0 </span><span class="s1">- np.sum(errors ** </span><span class="s2">2</span><span class="s1">) / tss</span>
        <span class="s1">assert_allclose(rsquare</span><span class="s0">, </span><span class="s1">pc.rsquare)</span>

    <span class="s1">@pytest.mark.slow</span>
    <span class="s0">def </span><span class="s1">test_missing_dataframe(self):</span>
        <span class="s1">x = self.x.copy()</span>
        <span class="s1">x[::</span><span class="s2">5</span><span class="s0">, </span><span class="s1">::</span><span class="s2">7</span><span class="s1">] = np.nan</span>
        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'fill-em'</span><span class="s1">)</span>

        <span class="s1">x = pd.DataFrame(x)</span>
        <span class="s1">pc_df = PCA(x</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'fill-em'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.coeff</span><span class="s0">, </span><span class="s1">pc_df.coeff)</span>
        <span class="s1">assert_allclose(pc.factors</span><span class="s0">, </span><span class="s1">pc_df.factors)</span>

        <span class="s1">pc_df_nomissing = PCA(pd.DataFrame(self.x.copy())</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">3</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">isinstance(pc_df.coeff</span><span class="s0">, </span><span class="s1">type(pc_df_nomissing.coeff))</span>
        <span class="s0">assert </span><span class="s1">isinstance(pc_df.data</span><span class="s0">, </span><span class="s1">type(pc_df_nomissing.data))</span>
        <span class="s0">assert </span><span class="s1">isinstance(pc_df.eigenvals</span><span class="s0">, </span><span class="s1">type(pc_df_nomissing.eigenvals))</span>
        <span class="s0">assert </span><span class="s1">isinstance(pc_df.eigenvecs</span><span class="s0">, </span><span class="s1">type(pc_df_nomissing.eigenvecs))</span>

        <span class="s1">x = self.x.copy()</span>
        <span class="s1">x[::</span><span class="s2">5</span><span class="s0">, </span><span class="s1">::</span><span class="s2">7</span><span class="s1">] = np.nan</span>
        <span class="s1">x_df = pd.DataFrame(x)</span>
        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-row'</span><span class="s1">)</span>
        <span class="s1">pc_df = PCA(x_df</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-row'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.coeff</span><span class="s0">, </span><span class="s1">pc_df.coeff)</span>
        <span class="s1">assert_allclose(pc.factors</span><span class="s0">, </span><span class="s1">pc_df.factors)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-col'</span><span class="s1">)</span>
        <span class="s1">pc_df = PCA(x_df</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-col'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.coeff</span><span class="s0">, </span><span class="s1">pc_df.coeff)</span>
        <span class="s1">assert_allclose(pc.factors</span><span class="s0">, </span><span class="s1">pc_df.factors)</span>

        <span class="s1">pc = PCA(x</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-min'</span><span class="s1">)</span>
        <span class="s1">pc_df = PCA(x_df</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">'drop-min'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(pc.coeff</span><span class="s0">, </span><span class="s1">pc_df.coeff)</span>
        <span class="s1">assert_allclose(pc.factors</span><span class="s0">, </span><span class="s1">pc_df.factors)</span>

    <span class="s0">def </span><span class="s1">test_equivalence(self):</span>
        <span class="s1">x = self.x.copy()</span>
        <span class="s1">assert_allclose(PCA(x).factors</span><span class="s0">, </span><span class="s1">pca(x)[</span><span class="s2">0</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">test_equivalence_full_matrices(self):</span>
        <span class="s1">x = self.x.copy()</span>
        <span class="s1">svd_full_matrices_true = PCA(x</span><span class="s0">, </span><span class="s1">svd_full_matrices=</span><span class="s0">True</span><span class="s1">).factors</span>
        <span class="s1">svd_full_matrices_false = PCA(x).factors</span>
        <span class="s1">assert_allclose(svd_full_matrices_true</span><span class="s0">, </span><span class="s1">svd_full_matrices_false)</span>


<span class="s0">def </span><span class="s1">test_missing():</span>
    <span class="s1">data = np.empty((</span><span class="s2">200</span><span class="s0">, </span><span class="s2">50</span><span class="s1">))</span>
    <span class="s1">data[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] = np.nan</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;data contains non-finite values&quot;</span><span class="s1">):</span>
        <span class="s1">PCA(data)</span>


<span class="s0">def </span><span class="s1">test_too_many_missing(reset_randomstate):</span>
    <span class="s1">data = np.random.standard_normal((</span><span class="s2">200</span><span class="s0">, </span><span class="s2">50</span><span class="s1">))</span>
    <span class="s1">data[</span><span class="s2">0</span><span class="s0">, </span><span class="s1">:-</span><span class="s2">3</span><span class="s1">] = np.nan</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">PCA(data</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">5</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">&quot;drop-col&quot;</span><span class="s1">)</span>
    <span class="s1">p = PCA(data</span><span class="s0">, </span><span class="s1">missing=</span><span class="s4">&quot;drop-min&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">max(p.factors.shape) == max(data.shape) - </span><span class="s2">1</span>


<span class="s0">def </span><span class="s1">test_gls_warning(reset_randomstate):</span>
    <span class="s1">data = np.random.standard_normal((</span><span class="s2">400</span><span class="s0">, </span><span class="s2">200</span><span class="s1">))</span>
    <span class="s1">data[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:] = data[:</span><span class="s0">, </span><span class="s1">:</span><span class="s2">1</span><span class="s1">] + </span><span class="s2">.01 </span><span class="s1">* data[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:]</span>
    <span class="s0">with </span><span class="s1">pytest.warns(EstimationWarning</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;Many series are being down weighted&quot;</span><span class="s1">):</span>
        <span class="s1">factors = PCA(data</span><span class="s0">, </span><span class="s1">ncomp=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">gls=</span><span class="s0">True</span><span class="s1">).factors</span>
    <span class="s0">assert </span><span class="s1">factors.shape == (data.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_sparse_coordinate_descent.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_sparse_coordinate_descent.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">scipy.sparse </span><span class="s0">as </span><span class="s1">sp</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>

<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">make_regression</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">ElasticNet</span><span class="s0">, </span><span class="s1">ElasticNetCV</span><span class="s0">, </span><span class="s1">Lasso</span><span class="s0">, </span><span class="s1">LassoCV</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">create_memmap_backed_data</span><span class="s0">,</span>
    <span class="s1">ignore_warnings</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sparse_coef():</span>
    <span class="s2"># Check that the sparse_coef property works</span>
    <span class="s1">clf = ElasticNet()</span>
    <span class="s1">clf.coef_ = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span>

    <span class="s0">assert </span><span class="s1">sp.issparse(clf.sparse_coef_)</span>
    <span class="s0">assert </span><span class="s1">clf.sparse_coef_.toarray().tolist()[</span><span class="s3">0</span><span class="s1">] == clf.coef_</span>


<span class="s0">def </span><span class="s1">test_lasso_zero():</span>
    <span class="s2"># Check that the sparse lasso can handle zero data without crashing</span>
    <span class="s1">X = sp.csc_matrix((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">y = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">T = np.array([[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s1">]])</span>
    <span class="s1">clf = Lasso().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;with_sample_weight&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_enet_toy_list_input(with_sample_weight):</span>
    <span class="s2"># Test ElasticNet for various values of alpha and l1_ratio with list X</span>

    <span class="s1">X = np.array([[-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">]])</span>
    <span class="s1">X = sp.csc_matrix(X)</span>
    <span class="s1">Y = [-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]  </span><span class="s2"># just a straight line</span>
    <span class="s1">T = np.array([[</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">4</span><span class="s1">]])  </span><span class="s2"># test sample</span>
    <span class="s0">if </span><span class="s1">with_sample_weight:</span>
        <span class="s1">sw = np.array([</span><span class="s3">2.0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">sw = </span><span class="s0">None</span>

    <span class="s2"># this should be the same as unregularized least squares</span>
    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s2"># catch warning about alpha=0.</span>
    <span class="s2"># this is discouraged but should work.</span>
    <span class="s1">ignore_warnings(clf.fit)(X</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">sample_weight=sw)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">0.3</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">sample_weight=sw)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.50819</span><span class="s1">]</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.0163</span><span class="s0">, </span><span class="s3">1.5245</span><span class="s0">, </span><span class="s3">2.0327</span><span class="s1">]</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">0.5</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">sample_weight=sw)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.45454</span><span class="s1">]</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.9090</span><span class="s0">, </span><span class="s3">1.3636</span><span class="s0">, </span><span class="s3">1.8181</span><span class="s1">]</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_enet_toy_explicit_sparse_input():</span>
    <span class="s2"># Test ElasticNet for various values of alpha and l1_ratio with sparse X</span>
    <span class="s1">f = ignore_warnings</span>
    <span class="s2"># training samples</span>
    <span class="s1">X = sp.lil_matrix((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">X[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = -</span><span class="s3">1</span>
    <span class="s2"># X[1, 0] = 0</span>
    <span class="s1">X[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = </span><span class="s3">1</span>
    <span class="s1">Y = [-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]  </span><span class="s2"># just a straight line (the identity function)</span>

    <span class="s2"># test samples</span>
    <span class="s1">T = sp.lil_matrix((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">T[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = </span><span class="s3">2</span>
    <span class="s1">T[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = </span><span class="s3">3</span>
    <span class="s1">T[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = </span><span class="s3">4</span>

    <span class="s2"># this should be the same as lasso</span>
    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">1.0</span><span class="s1">)</span>
    <span class="s1">f(clf.fit)(X</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">])</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">0.3</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.50819</span><span class="s1">]</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.0163</span><span class="s0">, </span><span class="s3">1.5245</span><span class="s0">, </span><span class="s3">2.0327</span><span class="s1">]</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">l1_ratio=</span><span class="s3">0.5</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">pred = clf.predict(T)</span>
    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.45454</span><span class="s1">]</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.9090</span><span class="s0">, </span><span class="s3">1.3636</span><span class="s0">, </span><span class="s3">1.8181</span><span class="s1">]</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">make_sparse_data(</span>
    <span class="s1">n_samples=</span><span class="s3">100</span><span class="s0">,</span>
    <span class="s1">n_features=</span><span class="s3">100</span><span class="s0">,</span>
    <span class="s1">n_informative=</span><span class="s3">10</span><span class="s0">,</span>
    <span class="s1">seed=</span><span class="s3">42</span><span class="s0">,</span>
    <span class="s1">positive=</span><span class="s0">False,</span>
    <span class="s1">n_targets=</span><span class="s3">1</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s1">random_state = np.random.RandomState(seed)</span>

    <span class="s2"># build an ill-posed linear regression problem with many noisy features and</span>
    <span class="s2"># comparatively few samples</span>

    <span class="s2"># generate a ground truth model</span>
    <span class="s1">w = random_state.randn(n_features</span><span class="s0">, </span><span class="s1">n_targets)</span>
    <span class="s1">w[n_informative:] = </span><span class="s3">0.0  </span><span class="s2"># only the top features are impacting the model</span>
    <span class="s0">if </span><span class="s1">positive:</span>
        <span class="s1">w = np.abs(w)</span>

    <span class="s1">X = random_state.randn(n_samples</span><span class="s0">, </span><span class="s1">n_features)</span>
    <span class="s1">rnd = random_state.uniform(size=(n_samples</span><span class="s0">, </span><span class="s1">n_features))</span>
    <span class="s1">X[rnd &gt; </span><span class="s3">0.5</span><span class="s1">] = </span><span class="s3">0.0  </span><span class="s2"># 50% of zeros in input signal</span>

    <span class="s2"># generate training ground truth labels</span>
    <span class="s1">y = np.dot(X</span><span class="s0">, </span><span class="s1">w)</span>
    <span class="s1">X = sp.csc_matrix(X)</span>
    <span class="s0">if </span><span class="s1">n_targets == </span><span class="s3">1</span><span class="s1">:</span>
        <span class="s1">y = np.ravel(y)</span>
    <span class="s0">return </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span>


<span class="s0">def </span><span class="s1">_test_sparse_enet_not_as_toy_dataset(alpha</span><span class="s0">, </span><span class="s1">fit_intercept</span><span class="s0">, </span><span class="s1">positive):</span>
    <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">max_iter = </span><span class="s3">100</span><span class="s0">, </span><span class="s3">100</span><span class="s0">, </span><span class="s3">1000</span>
    <span class="s1">n_informative = </span><span class="s3">10</span>

    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_sparse_data(n_samples</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">n_informative</span><span class="s0">, </span><span class="s1">positive=positive)</span>

    <span class="s1">X_train</span><span class="s0">, </span><span class="s1">X_test = X[n_samples // </span><span class="s3">2 </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">X[: n_samples // </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s1">y_train</span><span class="s0">, </span><span class="s1">y_test = y[n_samples // </span><span class="s3">2 </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">y[: n_samples // </span><span class="s3">2</span><span class="s1">]</span>

    <span class="s1">s_clf = ElasticNet(</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">l1_ratio=</span><span class="s3">0.8</span><span class="s0">,</span>
        <span class="s1">fit_intercept=fit_intercept</span><span class="s0">,</span>
        <span class="s1">max_iter=max_iter</span><span class="s0">,</span>
        <span class="s1">tol=</span><span class="s3">1e-7</span><span class="s0">,</span>
        <span class="s1">positive=positive</span><span class="s0">,</span>
        <span class="s1">warm_start=</span><span class="s0">True,</span>
    <span class="s1">)</span>
    <span class="s1">s_clf.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

    <span class="s1">assert_almost_equal(s_clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s_clf.score(X_test</span><span class="s0">, </span><span class="s1">y_test) &gt; </span><span class="s3">0.85</span>

    <span class="s2"># check the convergence is the same as the dense version</span>
    <span class="s1">d_clf = ElasticNet(</span>
        <span class="s1">alpha=alpha</span><span class="s0">,</span>
        <span class="s1">l1_ratio=</span><span class="s3">0.8</span><span class="s0">,</span>
        <span class="s1">fit_intercept=fit_intercept</span><span class="s0">,</span>
        <span class="s1">max_iter=max_iter</span><span class="s0">,</span>
        <span class="s1">tol=</span><span class="s3">1e-7</span><span class="s0">,</span>
        <span class="s1">positive=positive</span><span class="s0">,</span>
        <span class="s1">warm_start=</span><span class="s0">True,</span>
    <span class="s1">)</span>
    <span class="s1">d_clf.fit(X_train.toarray()</span><span class="s0">, </span><span class="s1">y_train)</span>

    <span class="s1">assert_almost_equal(d_clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">d_clf.score(X_test</span><span class="s0">, </span><span class="s1">y_test) &gt; </span><span class="s3">0.85</span>

    <span class="s1">assert_almost_equal(s_clf.coef_</span><span class="s0">, </span><span class="s1">d_clf.coef_</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(s_clf.intercept_</span><span class="s0">, </span><span class="s1">d_clf.intercept_</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>

    <span class="s2"># check that the coefs are sparse</span>
    <span class="s0">assert </span><span class="s1">np.sum(s_clf.coef_ != </span><span class="s3">0.0</span><span class="s1">) &lt; </span><span class="s3">2 </span><span class="s1">* n_informative</span>


<span class="s0">def </span><span class="s1">test_sparse_enet_not_as_toy_dataset():</span>
    <span class="s1">_test_sparse_enet_not_as_toy_dataset(alpha=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">False, </span><span class="s1">positive=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">_test_sparse_enet_not_as_toy_dataset(alpha=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">True, </span><span class="s1">positive=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">_test_sparse_enet_not_as_toy_dataset(alpha=</span><span class="s3">1e-3</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">False, </span><span class="s1">positive=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">_test_sparse_enet_not_as_toy_dataset(alpha=</span><span class="s3">1e-3</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">True, </span><span class="s1">positive=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sparse_lasso_not_as_toy_dataset():</span>
    <span class="s1">n_samples = </span><span class="s3">100</span>
    <span class="s1">max_iter = </span><span class="s3">1000</span>
    <span class="s1">n_informative = </span><span class="s3">10</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_sparse_data(n_samples=n_samples</span><span class="s0">, </span><span class="s1">n_informative=n_informative)</span>

    <span class="s1">X_train</span><span class="s0">, </span><span class="s1">X_test = X[n_samples // </span><span class="s3">2 </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">X[: n_samples // </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s1">y_train</span><span class="s0">, </span><span class="s1">y_test = y[n_samples // </span><span class="s3">2 </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">y[: n_samples // </span><span class="s3">2</span><span class="s1">]</span>

    <span class="s1">s_clf = Lasso(alpha=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">False, </span><span class="s1">max_iter=max_iter</span><span class="s0">, </span><span class="s1">tol=</span><span class="s3">1e-7</span><span class="s1">)</span>
    <span class="s1">s_clf.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>
    <span class="s1">assert_almost_equal(s_clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">s_clf.score(X_test</span><span class="s0">, </span><span class="s1">y_test) &gt; </span><span class="s3">0.85</span>

    <span class="s2"># check the convergence is the same as the dense version</span>
    <span class="s1">d_clf = Lasso(alpha=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">False, </span><span class="s1">max_iter=max_iter</span><span class="s0">, </span><span class="s1">tol=</span><span class="s3">1e-7</span><span class="s1">)</span>
    <span class="s1">d_clf.fit(X_train.toarray()</span><span class="s0">, </span><span class="s1">y_train)</span>
    <span class="s1">assert_almost_equal(d_clf.dual_gap_</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">d_clf.score(X_test</span><span class="s0">, </span><span class="s1">y_test) &gt; </span><span class="s3">0.85</span>

    <span class="s2"># check that the coefs are sparse</span>
    <span class="s0">assert </span><span class="s1">np.sum(s_clf.coef_ != </span><span class="s3">0.0</span><span class="s1">) == n_informative</span>


<span class="s0">def </span><span class="s1">test_enet_multitarget():</span>
    <span class="s1">n_targets = </span><span class="s3">3</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_sparse_data(n_targets=n_targets)</span>

    <span class="s1">estimator = ElasticNet(alpha=</span><span class="s3">0.01</span><span class="s0">, </span><span class="s1">precompute=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s2"># XXX: There is a bug when precompute is not False!</span>
    <span class="s1">estimator.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">coef</span><span class="s0">, </span><span class="s1">intercept</span><span class="s0">, </span><span class="s1">dual_gap = (</span>
        <span class="s1">estimator.coef_</span><span class="s0">,</span>
        <span class="s1">estimator.intercept_</span><span class="s0">,</span>
        <span class="s1">estimator.dual_gap_</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(n_targets):</span>
        <span class="s1">estimator.fit(X</span><span class="s0">, </span><span class="s1">y[:</span><span class="s0">, </span><span class="s1">k])</span>
        <span class="s1">assert_array_almost_equal(coef[k</span><span class="s0">, </span><span class="s1">:]</span><span class="s0">, </span><span class="s1">estimator.coef_)</span>
        <span class="s1">assert_array_almost_equal(intercept[k]</span><span class="s0">, </span><span class="s1">estimator.intercept_)</span>
        <span class="s1">assert_array_almost_equal(dual_gap[k]</span><span class="s0">, </span><span class="s1">estimator.dual_gap_)</span>


<span class="s0">def </span><span class="s1">test_path_parameters():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_sparse_data()</span>
    <span class="s1">max_iter = </span><span class="s3">50</span>
    <span class="s1">n_alphas = </span><span class="s3">10</span>
    <span class="s1">clf = ElasticNetCV(</span>
        <span class="s1">n_alphas=n_alphas</span><span class="s0">,</span>
        <span class="s1">eps=</span><span class="s3">1e-3</span><span class="s0">,</span>
        <span class="s1">max_iter=max_iter</span><span class="s0">,</span>
        <span class="s1">l1_ratio=</span><span class="s3">0.5</span><span class="s0">,</span>
        <span class="s1">fit_intercept=</span><span class="s0">False,</span>
    <span class="s1">)</span>
    <span class="s1">ignore_warnings(clf.fit)(X</span><span class="s0">, </span><span class="s1">y)  </span><span class="s2"># new params</span>
    <span class="s1">assert_almost_equal(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">clf.l1_ratio)</span>
    <span class="s0">assert </span><span class="s1">n_alphas == clf.n_alphas</span>
    <span class="s0">assert </span><span class="s1">n_alphas == len(clf.alphas_)</span>
    <span class="s1">sparse_mse_path = clf.mse_path_</span>
    <span class="s1">ignore_warnings(clf.fit)(X.toarray()</span><span class="s0">, </span><span class="s1">y)  </span><span class="s2"># compare with dense data</span>
    <span class="s1">assert_almost_equal(clf.mse_path_</span><span class="s0">, </span><span class="s1">sparse_mse_path)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;Model&quot;</span><span class="s0">, </span><span class="s1">[Lasso</span><span class="s0">, </span><span class="s1">ElasticNet</span><span class="s0">, </span><span class="s1">LassoCV</span><span class="s0">, </span><span class="s1">ElasticNetCV])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;fit_intercept&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">False, True</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;n_samples, n_features&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">24</span><span class="s0">, </span><span class="s3">6</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">6</span><span class="s0">, </span><span class="s3">24</span><span class="s1">)])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;with_sample_weight&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_sparse_dense_equality(</span>
    <span class="s1">Model</span><span class="s0">, </span><span class="s1">fit_intercept</span><span class="s0">, </span><span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">with_sample_weight</span>
<span class="s1">):</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_regression(</span>
        <span class="s1">n_samples=n_samples</span><span class="s0">,</span>
        <span class="s1">n_features=n_features</span><span class="s0">,</span>
        <span class="s1">effective_rank=n_features // </span><span class="s3">2</span><span class="s0">,</span>
        <span class="s1">n_informative=n_features // </span><span class="s3">2</span><span class="s0">,</span>
        <span class="s1">bias=</span><span class="s3">4 </span><span class="s1">* fit_intercept</span><span class="s0">,</span>
        <span class="s1">noise=</span><span class="s3">1</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s3">42</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">with_sample_weight:</span>
        <span class="s1">sw = np.abs(np.random.RandomState(</span><span class="s3">42</span><span class="s1">).normal(scale=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">size=y.shape))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">sw = </span><span class="s0">None</span>
    <span class="s1">Xs = sp.csc_matrix(X)</span>
    <span class="s1">params = {</span><span class="s4">&quot;fit_intercept&quot;</span><span class="s1">: fit_intercept}</span>
    <span class="s1">reg_dense = Model(**params).fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sw)</span>
    <span class="s1">reg_sparse = Model(**params).fit(Xs</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=sw)</span>
    <span class="s0">if </span><span class="s1">fit_intercept:</span>
        <span class="s0">assert </span><span class="s1">reg_sparse.intercept_ == pytest.approx(reg_dense.intercept_)</span>
        <span class="s2"># balance property</span>
        <span class="s0">assert </span><span class="s1">np.average(reg_sparse.predict(X)</span><span class="s0">, </span><span class="s1">weights=sw) == pytest.approx(</span>
            <span class="s1">np.average(y</span><span class="s0">, </span><span class="s1">weights=sw)</span>
        <span class="s1">)</span>
    <span class="s1">assert_allclose(reg_sparse.coef_</span><span class="s0">, </span><span class="s1">reg_dense.coef_)</span>


<span class="s0">def </span><span class="s1">test_same_output_sparse_dense_lasso_and_enet_cv():</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_sparse_data(n_samples=</span><span class="s3">40</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">clfs = ElasticNetCV(max_iter=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">clfs.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">clfd = ElasticNetCV(max_iter=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">clfd.fit(X.toarray()</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_almost_equal(clfs.alpha_</span><span class="s0">, </span><span class="s1">clfd.alpha_</span><span class="s0">, </span><span class="s3">7</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clfs.intercept_</span><span class="s0">, </span><span class="s1">clfd.intercept_</span><span class="s0">, </span><span class="s3">7</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(clfs.mse_path_</span><span class="s0">, </span><span class="s1">clfd.mse_path_)</span>
    <span class="s1">assert_array_almost_equal(clfs.alphas_</span><span class="s0">, </span><span class="s1">clfd.alphas_)</span>

    <span class="s1">clfs = LassoCV(max_iter=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">cv=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">clfs.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">clfd = LassoCV(max_iter=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">cv=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">clfd.fit(X.toarray()</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_almost_equal(clfs.alpha_</span><span class="s0">, </span><span class="s1">clfd.alpha_</span><span class="s0">, </span><span class="s3">7</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clfs.intercept_</span><span class="s0">, </span><span class="s1">clfd.intercept_</span><span class="s0">, </span><span class="s3">7</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(clfs.mse_path_</span><span class="s0">, </span><span class="s1">clfd.mse_path_)</span>
    <span class="s1">assert_array_almost_equal(clfs.alphas_</span><span class="s0">, </span><span class="s1">clfd.alphas_)</span>


<span class="s0">def </span><span class="s1">test_same_multiple_output_sparse_dense():</span>
    <span class="s1">l = ElasticNet()</span>
    <span class="s1">X = [</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">11</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">13</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">13</span><span class="s0">, </span><span class="s3">14</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">y = [</span>
        <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">12</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">13</span><span class="s0">, </span><span class="s3">14</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">13</span><span class="s0">, </span><span class="s3">14</span><span class="s0">, </span><span class="s3">15</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">l.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">sample = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]).reshape(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">predict_dense = l.predict(sample)</span>

    <span class="s1">l_sp = ElasticNet()</span>
    <span class="s1">X_sp = sp.coo_matrix(X)</span>
    <span class="s1">l_sp.fit(X_sp</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">sample_sparse = sp.coo_matrix(sample)</span>
    <span class="s1">predict_sparse = l_sp.predict(sample_sparse)</span>

    <span class="s1">assert_array_almost_equal(predict_sparse</span><span class="s0">, </span><span class="s1">predict_dense)</span>


<span class="s0">def </span><span class="s1">test_sparse_enet_coordinate_descent():</span>
    <span class="s5">&quot;&quot;&quot;Test that a warning is issued if model does not converge&quot;&quot;&quot;</span>
    <span class="s1">clf = Lasso(max_iter=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">n_samples = </span><span class="s3">5</span>
    <span class="s1">n_features = </span><span class="s3">2</span>
    <span class="s1">X = sp.csc_matrix((n_samples</span><span class="s0">, </span><span class="s1">n_features)) * </span><span class="s3">1e50</span>
    <span class="s1">y = np.ones(n_samples)</span>
    <span class="s1">warning_message = (</span>
        <span class="s4">&quot;Objective did not converge. You might want &quot;</span>
        <span class="s4">&quot;to increase the number of iterations.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(ConvergenceWarning</span><span class="s0">, </span><span class="s1">match=warning_message):</span>
        <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;copy_X&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s0">True, False</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_sparse_read_only_buffer(copy_X):</span>
    <span class="s5">&quot;&quot;&quot;Test that sparse coordinate descent works for read-only buffers&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">clf = ElasticNet(alpha=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">copy_X=copy_X</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">X = sp.random(</span><span class="s3">100</span><span class="s0">, </span><span class="s3">20</span><span class="s0">, </span><span class="s1">format=</span><span class="s4">&quot;csc&quot;</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s2"># Make X.data read-only</span>
    <span class="s1">X.data = create_memmap_backed_data(X.data)</span>

    <span class="s1">y = rng.rand(</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
</pre>
</body>
</html>
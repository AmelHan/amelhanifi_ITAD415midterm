<html>
<head>
<title>_mstats_extras.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #cc7832;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_mstats_extras.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Additional statistics functions with support for masked arrays. 
 
&quot;&quot;&quot;</span>

<span class="s2"># Original author (2007): Pierre GF Gerard-Marchant</span>


<span class="s1">__all__ = [</span><span class="s3">'compare_medians_ms'</span><span class="s4">,</span>
           <span class="s3">'hdquantiles'</span><span class="s4">, </span><span class="s3">'hdmedian'</span><span class="s4">, </span><span class="s3">'hdquantiles_sd'</span><span class="s4">,</span>
           <span class="s3">'idealfourths'</span><span class="s4">,</span>
           <span class="s3">'median_cihs'</span><span class="s4">,</span><span class="s3">'mjci'</span><span class="s4">,</span><span class="s3">'mquantiles_cimj'</span><span class="s4">,</span>
           <span class="s3">'rsh'</span><span class="s4">,</span>
           <span class="s3">'trimmed_mean_ci'</span><span class="s4">,</span><span class="s1">]</span>


<span class="s4">import </span><span class="s1">numpy </span><span class="s4">as </span><span class="s1">np</span>
<span class="s4">from </span><span class="s1">numpy </span><span class="s4">import </span><span class="s1">float_</span><span class="s4">, </span><span class="s1">int_</span><span class="s4">, </span><span class="s1">ndarray</span>

<span class="s4">import </span><span class="s1">numpy.ma </span><span class="s4">as </span><span class="s1">ma</span>
<span class="s4">from </span><span class="s1">numpy.ma </span><span class="s4">import </span><span class="s1">MaskedArray</span>

<span class="s4">from </span><span class="s1">. </span><span class="s4">import </span><span class="s1">_mstats_basic </span><span class="s4">as </span><span class="s1">mstats</span>

<span class="s4">from </span><span class="s1">scipy.stats.distributions </span><span class="s4">import </span><span class="s1">norm</span><span class="s4">, </span><span class="s1">beta</span><span class="s4">, </span><span class="s1">t</span><span class="s4">, </span><span class="s1">binom</span>


<span class="s4">def </span><span class="s1">hdquantiles(data</span><span class="s4">, </span><span class="s1">prob=list([</span><span class="s5">.25</span><span class="s4">,</span><span class="s5">.5</span><span class="s4">,</span><span class="s5">.75</span><span class="s1">])</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None, </span><span class="s1">var=</span><span class="s4">False,</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Computes quantile estimates with the Harrell-Davis method. 
 
    The quantile estimates are calculated as a weighted linear combination 
    of order statistics. 
 
    Parameters 
    ---------- 
    data : array_like 
        Data array. 
    prob : sequence, optional 
        Sequence of quantiles to compute. 
    axis : int or None, optional 
        Axis along which to compute the quantiles. If None, use a flattened 
        array. 
    var : bool, optional 
        Whether to return the variance of the estimate. 
 
    Returns 
    ------- 
    hdquantiles : MaskedArray 
        A (p,) array of quantiles (if `var` is False), or a (2,p) array of 
        quantiles and variances (if `var` is True), where ``p`` is the 
        number of quantiles. 
 
    See Also 
    -------- 
    hdquantiles_sd 
 
    &quot;&quot;&quot;</span>
    <span class="s4">def </span><span class="s1">_hd_1D(data</span><span class="s4">,</span><span class="s1">prob</span><span class="s4">,</span><span class="s1">var):</span>
        <span class="s0">&quot;Computes the HD quantiles for a 1D array. Returns nan for invalid data.&quot;</span>
        <span class="s1">xsorted = np.squeeze(np.sort(data.compressed().view(ndarray)))</span>
        <span class="s2"># Don't use length here, in case we have a numpy scalar</span>
        <span class="s1">n = xsorted.size</span>

        <span class="s1">hd = np.empty((</span><span class="s5">2</span><span class="s4">,</span><span class="s1">len(prob))</span><span class="s4">, </span><span class="s1">float_)</span>
        <span class="s4">if </span><span class="s1">n &lt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">hd.flat = np.nan</span>
            <span class="s4">if </span><span class="s1">var:</span>
                <span class="s4">return </span><span class="s1">hd</span>
            <span class="s4">return </span><span class="s1">hd[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">v = np.arange(n+</span><span class="s5">1</span><span class="s1">) / float(n)</span>
        <span class="s1">betacdf = beta.cdf</span>
        <span class="s4">for </span><span class="s1">(i</span><span class="s4">,</span><span class="s1">p) </span><span class="s4">in </span><span class="s1">enumerate(prob):</span>
            <span class="s1">_w = betacdf(v</span><span class="s4">, </span><span class="s1">(n+</span><span class="s5">1</span><span class="s1">)*p</span><span class="s4">, </span><span class="s1">(n+</span><span class="s5">1</span><span class="s1">)*(</span><span class="s5">1</span><span class="s1">-p))</span>
            <span class="s1">w = _w[</span><span class="s5">1</span><span class="s1">:] - _w[:-</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">hd_mean = np.dot(w</span><span class="s4">, </span><span class="s1">xsorted)</span>
            <span class="s1">hd[</span><span class="s5">0</span><span class="s4">,</span><span class="s1">i] = hd_mean</span>
            <span class="s2">#</span>
            <span class="s1">hd[</span><span class="s5">1</span><span class="s4">,</span><span class="s1">i] = np.dot(w</span><span class="s4">, </span><span class="s1">(xsorted-hd_mean)**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">#</span>
        <span class="s1">hd[</span><span class="s5">0</span><span class="s4">, </span><span class="s1">prob == </span><span class="s5">0</span><span class="s1">] = xsorted[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">hd[</span><span class="s5">0</span><span class="s4">, </span><span class="s1">prob == </span><span class="s5">1</span><span class="s1">] = xsorted[-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s4">if </span><span class="s1">var:</span>
            <span class="s1">hd[</span><span class="s5">1</span><span class="s4">, </span><span class="s1">prob == </span><span class="s5">0</span><span class="s1">] = hd[</span><span class="s5">1</span><span class="s4">, </span><span class="s1">prob == </span><span class="s5">1</span><span class="s1">] = np.nan</span>
            <span class="s4">return </span><span class="s1">hd</span>
        <span class="s4">return </span><span class="s1">hd[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s2"># Initialization &amp; checks</span>
    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">dtype=float_)</span>
    <span class="s1">p = np.array(prob</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2"># Computes quantiles along axis (or globally)</span>
    <span class="s4">if </span><span class="s1">(axis </span><span class="s4">is None</span><span class="s1">) </span><span class="s4">or </span><span class="s1">(data.ndim == </span><span class="s5">1</span><span class="s1">):</span>
        <span class="s1">result = _hd_1D(data</span><span class="s4">, </span><span class="s1">p</span><span class="s4">, </span><span class="s1">var)</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s4">if </span><span class="s1">data.ndim &gt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s4">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Array 'data' must be at most two dimensional, &quot;</span>
                             <span class="s3">&quot;but got data.ndim = %d&quot; </span><span class="s1">% data.ndim)</span>
        <span class="s1">result = ma.apply_along_axis(_hd_1D</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">, </span><span class="s1">data</span><span class="s4">, </span><span class="s1">p</span><span class="s4">, </span><span class="s1">var)</span>

    <span class="s4">return </span><span class="s1">ma.fix_invalid(result</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">)</span>


<span class="s4">def </span><span class="s1">hdmedian(data</span><span class="s4">, </span><span class="s1">axis=-</span><span class="s5">1</span><span class="s4">, </span><span class="s1">var=</span><span class="s4">False</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns the Harrell-Davis estimate of the median along the given axis. 
 
    Parameters 
    ---------- 
    data : ndarray 
        Data array. 
    axis : int, optional 
        Axis along which to compute the quantiles. If None, use a flattened 
        array. 
    var : bool, optional 
        Whether to return the variance of the estimate. 
 
    Returns 
    ------- 
    hdmedian : MaskedArray 
        The median values.  If ``var=True``, the variance is returned inside 
        the masked array.  E.g. for a 1-D array the shape change from (1,) to 
        (2,). 
 
    &quot;&quot;&quot;</span>
    <span class="s1">result = hdquantiles(data</span><span class="s4">,</span><span class="s1">[</span><span class="s5">0.5</span><span class="s1">]</span><span class="s4">, </span><span class="s1">axis=axis</span><span class="s4">, </span><span class="s1">var=var)</span>
    <span class="s4">return </span><span class="s1">result.squeeze()</span>


<span class="s4">def </span><span class="s1">hdquantiles_sd(data</span><span class="s4">, </span><span class="s1">prob=list([</span><span class="s5">.25</span><span class="s4">,</span><span class="s5">.5</span><span class="s4">,</span><span class="s5">.75</span><span class="s1">])</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    The standard error of the Harrell-Davis quantile estimates by jackknife. 
 
    Parameters 
    ---------- 
    data : array_like 
        Data array. 
    prob : sequence, optional 
        Sequence of quantiles to compute. 
    axis : int, optional 
        Axis along which to compute the quantiles. If None, use a flattened 
        array. 
 
    Returns 
    ------- 
    hdquantiles_sd : MaskedArray 
        Standard error of the Harrell-Davis quantile estimates. 
 
    See Also 
    -------- 
    hdquantiles 
 
    &quot;&quot;&quot;</span>
    <span class="s4">def </span><span class="s1">_hdsd_1D(data</span><span class="s4">, </span><span class="s1">prob):</span>
        <span class="s0">&quot;Computes the std error for 1D arrays.&quot;</span>
        <span class="s1">xsorted = np.sort(data.compressed())</span>
        <span class="s1">n = len(xsorted)</span>

        <span class="s1">hdsd = np.empty(len(prob)</span><span class="s4">, </span><span class="s1">float_)</span>
        <span class="s4">if </span><span class="s1">n &lt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">hdsd.flat = np.nan</span>

        <span class="s1">vv = np.arange(n) / float(n-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">betacdf = beta.cdf</span>

        <span class="s4">for </span><span class="s1">(i</span><span class="s4">,</span><span class="s1">p) </span><span class="s4">in </span><span class="s1">enumerate(prob):</span>
            <span class="s1">_w = betacdf(vv</span><span class="s4">, </span><span class="s1">n*p</span><span class="s4">, </span><span class="s1">n*(</span><span class="s5">1</span><span class="s1">-p))</span>
            <span class="s1">w = _w[</span><span class="s5">1</span><span class="s1">:] - _w[:-</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s2"># cumulative sum of weights and data points if</span>
            <span class="s2"># ith point is left out for jackknife</span>
            <span class="s1">mx_ = np.zeros_like(xsorted)</span>
            <span class="s1">mx_[</span><span class="s5">1</span><span class="s1">:] = np.cumsum(w * xsorted[:-</span><span class="s5">1</span><span class="s1">])</span>
            <span class="s2"># similar but from the right</span>
            <span class="s1">mx_[:-</span><span class="s5">1</span><span class="s1">] += np.cumsum(w[::-</span><span class="s5">1</span><span class="s1">] * xsorted[:</span><span class="s5">0</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">])[::-</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">hdsd[i] = np.sqrt(mx_.var() * (n - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s4">return </span><span class="s1">hdsd</span>

    <span class="s2"># Initialization &amp; checks</span>
    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">dtype=float_)</span>
    <span class="s1">p = np.array(prob</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2"># Computes quantiles along axis (or globally)</span>
    <span class="s4">if </span><span class="s1">(axis </span><span class="s4">is None</span><span class="s1">):</span>
        <span class="s1">result = _hdsd_1D(data</span><span class="s4">, </span><span class="s1">p)</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s4">if </span><span class="s1">data.ndim &gt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s4">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Array 'data' must be at most two dimensional, &quot;</span>
                             <span class="s3">&quot;but got data.ndim = %d&quot; </span><span class="s1">% data.ndim)</span>
        <span class="s1">result = ma.apply_along_axis(_hdsd_1D</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">, </span><span class="s1">data</span><span class="s4">, </span><span class="s1">p)</span>

    <span class="s4">return </span><span class="s1">ma.fix_invalid(result</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">).ravel()</span>


<span class="s4">def </span><span class="s1">trimmed_mean_ci(data</span><span class="s4">, </span><span class="s1">limits=(</span><span class="s5">0.2</span><span class="s4">,</span><span class="s5">0.2</span><span class="s1">)</span><span class="s4">, </span><span class="s1">inclusive=(</span><span class="s4">True,True</span><span class="s1">)</span><span class="s4">,</span>
                    <span class="s1">alpha=</span><span class="s5">0.05</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Selected confidence interval of the trimmed mean along the given axis. 
 
    Parameters 
    ---------- 
    data : array_like 
        Input data. 
    limits : {None, tuple}, optional 
        None or a two item tuple. 
        Tuple of the percentages to cut on each side of the array, with respect 
        to the number of unmasked data, as floats between 0. and 1. If ``n`` 
        is the number of unmasked data before trimming, then 
        (``n * limits[0]``)th smallest data and (``n * limits[1]``)th 
        largest data are masked.  The total number of unmasked data after 
        trimming is ``n * (1. - sum(limits))``. 
        The value of one limit can be set to None to indicate an open interval. 
 
        Defaults to (0.2, 0.2). 
    inclusive : (2,) tuple of boolean, optional 
        If relative==False, tuple indicating whether values exactly equal to 
        the absolute limits are allowed. 
        If relative==True, tuple indicating whether the number of data being 
        masked on each side should be rounded (True) or truncated (False). 
 
        Defaults to (True, True). 
    alpha : float, optional 
        Confidence level of the intervals. 
 
        Defaults to 0.05. 
    axis : int, optional 
        Axis along which to cut. If None, uses a flattened version of `data`. 
 
        Defaults to None. 
 
    Returns 
    ------- 
    trimmed_mean_ci : (2,) ndarray 
        The lower and upper confidence intervals of the trimmed data. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">)</span>
    <span class="s1">trimmed = mstats.trimr(data</span><span class="s4">, </span><span class="s1">limits=limits</span><span class="s4">, </span><span class="s1">inclusive=inclusive</span><span class="s4">, </span><span class="s1">axis=axis)</span>
    <span class="s1">tmean = trimmed.mean(axis)</span>
    <span class="s1">tstde = mstats.trimmed_stde(data</span><span class="s4">,</span><span class="s1">limits=limits</span><span class="s4">,</span><span class="s1">inclusive=inclusive</span><span class="s4">,</span><span class="s1">axis=axis)</span>
    <span class="s1">df = trimmed.count(axis) - </span><span class="s5">1</span>
    <span class="s1">tppf = t.ppf(</span><span class="s5">1</span><span class="s1">-alpha/</span><span class="s5">2.</span><span class="s4">,</span><span class="s1">df)</span>
    <span class="s4">return </span><span class="s1">np.array((tmean - tppf*tstde</span><span class="s4">, </span><span class="s1">tmean+tppf*tstde))</span>


<span class="s4">def </span><span class="s1">mjci(data</span><span class="s4">, </span><span class="s1">prob=[</span><span class="s5">0.25</span><span class="s4">,</span><span class="s5">0.5</span><span class="s4">,</span><span class="s5">0.75</span><span class="s1">]</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns the Maritz-Jarrett estimators of the standard error of selected 
    experimental quantiles of the data. 
 
    Parameters 
    ---------- 
    data : ndarray 
        Data array. 
    prob : sequence, optional 
        Sequence of quantiles to compute. 
    axis : int or None, optional 
        Axis along which to compute the quantiles. If None, use a flattened 
        array. 
 
    &quot;&quot;&quot;</span>
    <span class="s4">def </span><span class="s1">_mjci_1D(data</span><span class="s4">, </span><span class="s1">p):</span>
        <span class="s1">data = np.sort(data.compressed())</span>
        <span class="s1">n = data.size</span>
        <span class="s1">prob = (np.array(p) * n + </span><span class="s5">0.5</span><span class="s1">).astype(int_)</span>
        <span class="s1">betacdf = beta.cdf</span>

        <span class="s1">mj = np.empty(len(prob)</span><span class="s4">, </span><span class="s1">float_)</span>
        <span class="s1">x = np.arange(</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n+</span><span class="s5">1</span><span class="s4">, </span><span class="s1">dtype=float_) / n</span>
        <span class="s1">y = x - </span><span class="s5">1.</span><span class="s1">/n</span>
        <span class="s4">for </span><span class="s1">(i</span><span class="s4">,</span><span class="s1">m) </span><span class="s4">in </span><span class="s1">enumerate(prob):</span>
            <span class="s1">W = betacdf(x</span><span class="s4">,</span><span class="s1">m-</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n-m) - betacdf(y</span><span class="s4">,</span><span class="s1">m-</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n-m)</span>
            <span class="s1">C1 = np.dot(W</span><span class="s4">,</span><span class="s1">data)</span>
            <span class="s1">C2 = np.dot(W</span><span class="s4">,</span><span class="s1">data**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">mj[i] = np.sqrt(C2 - C1**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s4">return </span><span class="s1">mj</span>

    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">)</span>
    <span class="s4">if </span><span class="s1">data.ndim &gt; </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s4">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Array 'data' must be at most two dimensional, &quot;</span>
                         <span class="s3">&quot;but got data.ndim = %d&quot; </span><span class="s1">% data.ndim)</span>

    <span class="s1">p = np.array(prob</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2"># Computes quantiles along axis (or globally)</span>
    <span class="s4">if </span><span class="s1">(axis </span><span class="s4">is None</span><span class="s1">):</span>
        <span class="s4">return </span><span class="s1">_mjci_1D(data</span><span class="s4">, </span><span class="s1">p)</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s4">return </span><span class="s1">ma.apply_along_axis(_mjci_1D</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">, </span><span class="s1">data</span><span class="s4">, </span><span class="s1">p)</span>


<span class="s4">def </span><span class="s1">mquantiles_cimj(data</span><span class="s4">, </span><span class="s1">prob=[</span><span class="s5">0.25</span><span class="s4">,</span><span class="s5">0.50</span><span class="s4">,</span><span class="s5">0.75</span><span class="s1">]</span><span class="s4">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Computes the alpha confidence interval for the selected quantiles of the 
    data, with Maritz-Jarrett estimators. 
 
    Parameters 
    ---------- 
    data : ndarray 
        Data array. 
    prob : sequence, optional 
        Sequence of quantiles to compute. 
    alpha : float, optional 
        Confidence level of the intervals. 
    axis : int or None, optional 
        Axis along which to compute the quantiles. 
        If None, use a flattened array. 
 
    Returns 
    ------- 
    ci_lower : ndarray 
        The lower boundaries of the confidence interval.  Of the same length as 
        `prob`. 
    ci_upper : ndarray 
        The upper boundaries of the confidence interval.  Of the same length as 
        `prob`. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">alpha = min(alpha</span><span class="s4">, </span><span class="s5">1 </span><span class="s1">- alpha)</span>
    <span class="s1">z = norm.ppf(</span><span class="s5">1 </span><span class="s1">- alpha/</span><span class="s5">2.</span><span class="s1">)</span>
    <span class="s1">xq = mstats.mquantiles(data</span><span class="s4">, </span><span class="s1">prob</span><span class="s4">, </span><span class="s1">alphap=</span><span class="s5">0</span><span class="s4">, </span><span class="s1">betap=</span><span class="s5">0</span><span class="s4">, </span><span class="s1">axis=axis)</span>
    <span class="s1">smj = mjci(data</span><span class="s4">, </span><span class="s1">prob</span><span class="s4">, </span><span class="s1">axis=axis)</span>
    <span class="s4">return </span><span class="s1">(xq - z * smj</span><span class="s4">, </span><span class="s1">xq + z * smj)</span>


<span class="s4">def </span><span class="s1">median_cihs(data</span><span class="s4">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Computes the alpha-level confidence interval for the median of the data. 
 
    Uses the Hettmasperger-Sheather method. 
 
    Parameters 
    ---------- 
    data : array_like 
        Input data. Masked values are discarded. The input should be 1D only, 
        or `axis` should be set to None. 
    alpha : float, optional 
        Confidence level of the intervals. 
    axis : int or None, optional 
        Axis along which to compute the quantiles. If None, use a flattened 
        array. 
 
    Returns 
    ------- 
    median_cihs 
        Alpha level confidence interval. 
 
    &quot;&quot;&quot;</span>
    <span class="s4">def </span><span class="s1">_cihs_1D(data</span><span class="s4">, </span><span class="s1">alpha):</span>
        <span class="s1">data = np.sort(data.compressed())</span>
        <span class="s1">n = len(data)</span>
        <span class="s1">alpha = min(alpha</span><span class="s4">, </span><span class="s5">1</span><span class="s1">-alpha)</span>
        <span class="s1">k = int(binom._ppf(alpha/</span><span class="s5">2.</span><span class="s4">, </span><span class="s1">n</span><span class="s4">, </span><span class="s5">0.5</span><span class="s1">))</span>
        <span class="s1">gk = binom.cdf(n-k</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">) - binom.cdf(k-</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s4">if </span><span class="s1">gk &lt; </span><span class="s5">1</span><span class="s1">-alpha:</span>
            <span class="s1">k -= </span><span class="s5">1</span>
            <span class="s1">gk = binom.cdf(n-k</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">) - binom.cdf(k-</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s1">gkk = binom.cdf(n-k-</span><span class="s5">1</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">) - binom.cdf(k</span><span class="s4">,</span><span class="s1">n</span><span class="s4">,</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s1">I = (gk - </span><span class="s5">1 </span><span class="s1">+ alpha)/(gk - gkk)</span>
        <span class="s1">lambd = (n-k) * I / float(k + (n-</span><span class="s5">2</span><span class="s1">*k)*I)</span>
        <span class="s1">lims = (lambd*data[k] + (</span><span class="s5">1</span><span class="s1">-lambd)*data[k-</span><span class="s5">1</span><span class="s1">]</span><span class="s4">,</span>
                <span class="s1">lambd*data[n-k-</span><span class="s5">1</span><span class="s1">] + (</span><span class="s5">1</span><span class="s1">-lambd)*data[n-k])</span>
        <span class="s4">return </span><span class="s1">lims</span>
    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">)</span>
    <span class="s2"># Computes quantiles along axis (or globally)</span>
    <span class="s4">if </span><span class="s1">(axis </span><span class="s4">is None</span><span class="s1">):</span>
        <span class="s1">result = _cihs_1D(data</span><span class="s4">, </span><span class="s1">alpha)</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s4">if </span><span class="s1">data.ndim &gt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s4">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Array 'data' must be at most two dimensional, &quot;</span>
                             <span class="s3">&quot;but got data.ndim = %d&quot; </span><span class="s1">% data.ndim)</span>
        <span class="s1">result = ma.apply_along_axis(_cihs_1D</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">, </span><span class="s1">data</span><span class="s4">, </span><span class="s1">alpha)</span>

    <span class="s4">return </span><span class="s1">result</span>


<span class="s4">def </span><span class="s1">compare_medians_ms(group_1</span><span class="s4">, </span><span class="s1">group_2</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Compares the medians from two independent groups along the given axis. 
 
    The comparison is performed using the McKean-Schrader estimate of the 
    standard error of the medians. 
 
    Parameters 
    ---------- 
    group_1 : array_like 
        First dataset.  Has to be of size &gt;=7. 
    group_2 : array_like 
        Second dataset.  Has to be of size &gt;=7. 
    axis : int, optional 
        Axis along which the medians are estimated. If None, the arrays are 
        flattened.  If `axis` is not None, then `group_1` and `group_2` 
        should have the same shape. 
 
    Returns 
    ------- 
    compare_medians_ms : {float, ndarray} 
        If `axis` is None, then returns a float, otherwise returns a 1-D 
        ndarray of floats with a length equal to the length of `group_1` 
        along `axis`. 
 
    Examples 
    -------- 
 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6, 7] 
    &gt;&gt;&gt; b = [8, 9, 10, 11, 12, 13, 14] 
    &gt;&gt;&gt; stats.mstats.compare_medians_ms(a, b, axis=None) 
    1.0693225866553746e-05 
 
    The function is vectorized to compute along a given axis. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; x = rng.random(size=(3, 7)) 
    &gt;&gt;&gt; y = rng.random(size=(3, 8)) 
    &gt;&gt;&gt; stats.mstats.compare_medians_ms(x, y, axis=1) 
    array([0.36908985, 0.36092538, 0.2765313 ]) 
 
    References 
    ---------- 
    .. [1] McKean, Joseph W., and Ronald M. Schrader. &quot;A comparison of methods 
       for studentizing the sample median.&quot; Communications in 
       Statistics-Simulation and Computation 13.6 (1984): 751-773. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">(med_1</span><span class="s4">, </span><span class="s1">med_2) = (ma.median(group_1</span><span class="s4">,</span><span class="s1">axis=axis)</span><span class="s4">, </span><span class="s1">ma.median(group_2</span><span class="s4">,</span><span class="s1">axis=axis))</span>
    <span class="s1">(std_1</span><span class="s4">, </span><span class="s1">std_2) = (mstats.stde_median(group_1</span><span class="s4">, </span><span class="s1">axis=axis)</span><span class="s4">,</span>
                      <span class="s1">mstats.stde_median(group_2</span><span class="s4">, </span><span class="s1">axis=axis))</span>
    <span class="s1">W = np.abs(med_1 - med_2) / ma.sqrt(std_1**</span><span class="s5">2 </span><span class="s1">+ std_2**</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s4">return </span><span class="s5">1 </span><span class="s1">- norm.cdf(W)</span>


<span class="s4">def </span><span class="s1">idealfourths(data</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns an estimate of the lower and upper quartiles. 
 
    Uses the ideal fourths algorithm. 
 
    Parameters 
    ---------- 
    data : array_like 
        Input array. 
    axis : int, optional 
        Axis along which the quartiles are estimated. If None, the arrays are 
        flattened. 
 
    Returns 
    ------- 
    idealfourths : {list of floats, masked array} 
        Returns the two internal values that divide `data` into four parts 
        using the ideal fourths algorithm either along the flattened array 
        (if `axis` is None) or along `axis` of `data`. 
 
    &quot;&quot;&quot;</span>
    <span class="s4">def </span><span class="s1">_idf(data):</span>
        <span class="s1">x = data.compressed()</span>
        <span class="s1">n = len(x)</span>
        <span class="s4">if </span><span class="s1">n &lt; </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s4">return </span><span class="s1">[np.nan</span><span class="s4">,</span><span class="s1">np.nan]</span>
        <span class="s1">(j</span><span class="s4">,</span><span class="s1">h) = divmod(n/</span><span class="s5">4. </span><span class="s1">+ </span><span class="s5">5</span><span class="s1">/</span><span class="s5">12.</span><span class="s4">,</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">j = int(j)</span>
        <span class="s1">qlo = (</span><span class="s5">1</span><span class="s1">-h)*x[j-</span><span class="s5">1</span><span class="s1">] + h*x[j]</span>
        <span class="s1">k = n - j</span>
        <span class="s1">qup = (</span><span class="s5">1</span><span class="s1">-h)*x[k] + h*x[k-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s4">return </span><span class="s1">[qlo</span><span class="s4">, </span><span class="s1">qup]</span>
    <span class="s1">data = ma.sort(data</span><span class="s4">, </span><span class="s1">axis=axis).view(MaskedArray)</span>
    <span class="s4">if </span><span class="s1">(axis </span><span class="s4">is None</span><span class="s1">):</span>
        <span class="s4">return </span><span class="s1">_idf(data)</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s4">return </span><span class="s1">ma.apply_along_axis(_idf</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">, </span><span class="s1">data)</span>


<span class="s4">def </span><span class="s1">rsh(data</span><span class="s4">, </span><span class="s1">points=</span><span class="s4">None</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Evaluates Rosenblatt's shifted histogram estimators for each data point. 
 
    Rosenblatt's estimator is a centered finite-difference approximation to the 
    derivative of the empirical cumulative distribution function. 
 
    Parameters 
    ---------- 
    data : sequence 
        Input data, should be 1-D. Masked values are ignored. 
    points : sequence or None, optional 
        Sequence of points where to evaluate Rosenblatt shifted histogram. 
        If None, use the data. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">data = ma.array(data</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False</span><span class="s1">)</span>
    <span class="s4">if </span><span class="s1">points </span><span class="s4">is None</span><span class="s1">:</span>
        <span class="s1">points = data</span>
    <span class="s4">else</span><span class="s1">:</span>
        <span class="s1">points = np.array(points</span><span class="s4">, </span><span class="s1">copy=</span><span class="s4">False, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4">if </span><span class="s1">data.ndim != </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s4">raise </span><span class="s1">AttributeError(</span><span class="s3">&quot;The input array should be 1D only !&quot;</span><span class="s1">)</span>

    <span class="s1">n = data.count()</span>
    <span class="s1">r = idealfourths(data</span><span class="s4">, </span><span class="s1">axis=</span><span class="s4">None</span><span class="s1">)</span>
    <span class="s1">h = </span><span class="s5">1.2 </span><span class="s1">* (r[-</span><span class="s5">1</span><span class="s1">]-r[</span><span class="s5">0</span><span class="s1">]) / n**(</span><span class="s5">1.</span><span class="s1">/</span><span class="s5">5</span><span class="s1">)</span>
    <span class="s1">nhi = (data[:</span><span class="s4">,None</span><span class="s1">] &lt;= points[</span><span class="s4">None,</span><span class="s1">:] + h).sum(</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">nlo = (data[:</span><span class="s4">,None</span><span class="s1">] &lt; points[</span><span class="s4">None,</span><span class="s1">:] - h).sum(</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s4">return </span><span class="s1">(nhi-nlo) / (</span><span class="s5">2.</span><span class="s1">*n*h)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_sparse_pca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_sparse_pca.py</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Vlad Niculae</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">sys</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">assert_array_equal</span>

<span class="s2">from </span><span class="s1">sklearn.decomposition </span><span class="s2">import </span><span class="s1">PCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA</span><span class="s2">, </span><span class="s1">SparsePCA</span>
<span class="s2">from </span><span class="s1">sklearn.utils </span><span class="s2">import </span><span class="s1">check_random_state</span>
<span class="s2">from </span><span class="s1">sklearn.utils._testing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s2">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">,</span>
    <span class="s1">if_safe_multiprocessing_with_blas</span><span class="s2">,</span>
<span class="s1">)</span>


<span class="s2">def </span><span class="s1">generate_toy_data(n_components</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">image_size</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s1">n_features = image_size[</span><span class="s3">0</span><span class="s1">] * image_size[</span><span class="s3">1</span><span class="s1">]</span>

    <span class="s1">rng = check_random_state(random_state)</span>
    <span class="s1">U = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_components)</span>
    <span class="s1">V = rng.randn(n_components</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">centers = [(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s3">6</span><span class="s2">, </span><span class="s3">7</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)]</span>
    <span class="s1">sz = [</span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(n_components):</span>
        <span class="s1">img = np.zeros(image_size)</span>
        <span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax = centers[k][</span><span class="s3">0</span><span class="s1">] - sz[k]</span><span class="s2">, </span><span class="s1">centers[k][</span><span class="s3">0</span><span class="s1">] + sz[k]</span>
        <span class="s1">ymin</span><span class="s2">, </span><span class="s1">ymax = centers[k][</span><span class="s3">1</span><span class="s1">] - sz[k]</span><span class="s2">, </span><span class="s1">centers[k][</span><span class="s3">1</span><span class="s1">] + sz[k]</span>
        <span class="s1">img[xmin:xmax][:</span><span class="s2">, </span><span class="s1">ymin:ymax] = </span><span class="s3">1.0</span>
        <span class="s1">V[k</span><span class="s2">, </span><span class="s1">:] = img.ravel()</span>

    <span class="s0"># Y is defined by : Y = UV + noise</span>
    <span class="s1">Y = np.dot(U</span><span class="s2">, </span><span class="s1">V)</span>
    <span class="s1">Y += </span><span class="s3">0.1 </span><span class="s1">* rng.randn(Y.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">Y.shape[</span><span class="s3">1</span><span class="s1">])  </span><span class="s0"># Add noise</span>
    <span class="s2">return </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">U</span><span class="s2">, </span><span class="s1">V</span>


<span class="s0"># SparsePCA can be a bit slow. To avoid having test times go up, we</span>
<span class="s0"># test different aspects of the code in the same test</span>


<span class="s2">def </span><span class="s1">test_correct_shapes():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rng.randn(</span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">spca = SparsePCA(n_components=</span><span class="s3">8</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U = spca.fit_transform(X)</span>
    <span class="s2">assert </span><span class="s1">spca.components_.shape == (</span><span class="s3">8</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">U.shape == (</span><span class="s3">12</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span>
    <span class="s0"># test overcomplete decomposition</span>
    <span class="s1">spca = SparsePCA(n_components=</span><span class="s3">13</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U = spca.fit_transform(X)</span>
    <span class="s2">assert </span><span class="s1">spca.components_.shape == (</span><span class="s3">13</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">U.shape == (</span><span class="s3">12</span><span class="s2">, </span><span class="s3">13</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_fit_transform():</span>
    <span class="s1">alpha = </span><span class="s3">1</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)  </span><span class="s0"># wide array</span>
    <span class="s1">spca_lars = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">spca_lars.fit(Y)</span>

    <span class="s0"># Test that CD gives similar results</span>
    <span class="s1">spca_lasso = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;cd&quot;</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">alpha=alpha)</span>
    <span class="s1">spca_lasso.fit(Y)</span>
    <span class="s1">assert_array_almost_equal(spca_lasso.components_</span><span class="s2">, </span><span class="s1">spca_lars.components_)</span>


<span class="s1">@if_safe_multiprocessing_with_blas</span>
<span class="s2">def </span><span class="s1">test_fit_transform_parallel():</span>
    <span class="s1">alpha = </span><span class="s3">1</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)  </span><span class="s0"># wide array</span>
    <span class="s1">spca_lars = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">spca_lars.fit(Y)</span>
    <span class="s1">U1 = spca_lars.transform(Y)</span>
    <span class="s0"># Test multiple CPUs</span>
    <span class="s1">spca = SparsePCA(</span>
        <span class="s1">n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">n_jobs=</span><span class="s3">2</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">).fit(Y)</span>
    <span class="s1">U2 = spca.transform(Y)</span>
    <span class="s2">assert not </span><span class="s1">np.all(spca_lars.components_ == </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(U1</span><span class="s2">, </span><span class="s1">U2)</span>


<span class="s2">def </span><span class="s1">test_transform_nan():</span>
    <span class="s0"># Test that SparsePCA won't return NaN when there is 0 feature in all</span>
    <span class="s0"># samples.</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)  </span><span class="s0"># wide array</span>
    <span class="s1">Y[:</span><span class="s2">, </span><span class="s3">0</span><span class="s1">] = </span><span class="s3">0</span>
    <span class="s1">estimator = SparsePCA(n_components=</span><span class="s3">8</span><span class="s1">)</span>
    <span class="s2">assert not </span><span class="s1">np.any(np.isnan(estimator.fit_transform(Y)))</span>


<span class="s2">def </span><span class="s1">test_fit_transform_tall():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">65</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)  </span><span class="s0"># tall array</span>
    <span class="s1">spca_lars = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U1 = spca_lars.fit_transform(Y)</span>
    <span class="s1">spca_lasso = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;cd&quot;</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U2 = spca_lasso.fit(Y).transform(Y)</span>
    <span class="s1">assert_array_almost_equal(U1</span><span class="s2">, </span><span class="s1">U2)</span>


<span class="s2">def </span><span class="s1">test_initialization():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">U_init = rng.randn(</span><span class="s3">5</span><span class="s2">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">V_init = rng.randn(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">model = SparsePCA(</span>
        <span class="s1">n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">U_init=U_init</span><span class="s2">, </span><span class="s1">V_init=V_init</span><span class="s2">, </span><span class="s1">max_iter=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">random_state=rng</span>
    <span class="s1">)</span>
    <span class="s1">model.fit(rng.randn(</span><span class="s3">5</span><span class="s2">, </span><span class="s3">4</span><span class="s1">))</span>
    <span class="s1">assert_allclose(model.components_</span><span class="s2">, </span><span class="s1">V_init / np.linalg.norm(V_init</span><span class="s2">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)[:</span><span class="s2">, None</span><span class="s1">])</span>


<span class="s2">def </span><span class="s1">test_mini_batch_correct_shapes():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rng.randn(</span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s1">pca = MiniBatchSparsePCA(n_components=</span><span class="s3">8</span><span class="s2">, </span><span class="s1">max_iter=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U = pca.fit_transform(X)</span>
    <span class="s2">assert </span><span class="s1">pca.components_.shape == (</span><span class="s3">8</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">U.shape == (</span><span class="s3">12</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span>
    <span class="s0"># test overcomplete decomposition</span>
    <span class="s1">pca = MiniBatchSparsePCA(n_components=</span><span class="s3">13</span><span class="s2">, </span><span class="s1">max_iter=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">U = pca.fit_transform(X)</span>
    <span class="s2">assert </span><span class="s1">pca.components_.shape == (</span><span class="s3">13</span><span class="s2">, </span><span class="s3">10</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">U.shape == (</span><span class="s3">12</span><span class="s2">, </span><span class="s3">13</span><span class="s1">)</span>


<span class="s0"># XXX: test always skipped</span>
<span class="s1">@pytest.mark.skipif(</span><span class="s2">True, </span><span class="s1">reason=</span><span class="s4">&quot;skipping mini_batch_fit_transform.&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_mini_batch_fit_transform():</span>
    <span class="s1">alpha = </span><span class="s3">1</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)  </span><span class="s0"># wide array</span>
    <span class="s1">spca_lars = MiniBatchSparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">alpha=alpha).fit(Y)</span>
    <span class="s1">U1 = spca_lars.transform(Y)</span>
    <span class="s0"># Test multiple CPUs</span>
    <span class="s2">if </span><span class="s1">sys.platform == </span><span class="s4">&quot;win32&quot;</span><span class="s1">:  </span><span class="s0"># fake parallelism for win32</span>
        <span class="s2">import </span><span class="s1">joblib</span>

        <span class="s1">_mp = joblib.parallel.multiprocessing</span>
        <span class="s1">joblib.parallel.multiprocessing = </span><span class="s2">None</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">spca = MiniBatchSparsePCA(</span>
                <span class="s1">n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">n_jobs=</span><span class="s3">2</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
            <span class="s1">)</span>
            <span class="s1">U2 = spca.fit(Y).transform(Y)</span>
        <span class="s2">finally</span><span class="s1">:</span>
            <span class="s1">joblib.parallel.multiprocessing = _mp</span>
    <span class="s2">else</span><span class="s1">:  </span><span class="s0"># we can efficiently use parallelism</span>
        <span class="s1">spca = MiniBatchSparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">n_jobs=</span><span class="s3">2</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">U2 = spca.fit(Y).transform(Y)</span>
    <span class="s2">assert not </span><span class="s1">np.all(spca_lars.components_ == </span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(U1</span><span class="s2">, </span><span class="s1">U2)</span>
    <span class="s0"># Test that CD gives similar results</span>
    <span class="s1">spca_lasso = MiniBatchSparsePCA(</span>
        <span class="s1">n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;cd&quot;</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">).fit(Y)</span>
    <span class="s1">assert_array_almost_equal(spca_lasso.components_</span><span class="s2">, </span><span class="s1">spca_lars.components_)</span>


<span class="s2">def </span><span class="s1">test_scaling_fit_transform():</span>
    <span class="s1">alpha = </span><span class="s3">1</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">1000</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">spca_lars = SparsePCA(n_components=</span><span class="s3">3</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">results_train = spca_lars.fit_transform(Y)</span>
    <span class="s1">results_test = spca_lars.transform(Y[:</span><span class="s3">10</span><span class="s1">])</span>
    <span class="s1">assert_allclose(results_train[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">results_test[</span><span class="s3">0</span><span class="s1">])</span>


<span class="s2">def </span><span class="s1">test_pca_vs_spca():</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">1000</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">Z</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = generate_toy_data(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s1">(</span><span class="s3">8</span><span class="s2">, </span><span class="s3">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">spca = SparsePCA(alpha=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">ridge_alpha=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">n_components=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">pca = PCA(n_components=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">pca.fit(Y)</span>
    <span class="s1">spca.fit(Y)</span>
    <span class="s1">results_test_pca = pca.transform(Z)</span>
    <span class="s1">results_test_spca = spca.transform(Z)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">np.abs(spca.components_.dot(pca.components_.T))</span><span class="s2">, </span><span class="s1">np.eye(</span><span class="s3">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">1e-5</span>
    <span class="s1">)</span>
    <span class="s1">results_test_pca *= np.sign(results_test_pca[</span><span class="s3">0</span><span class="s2">, </span><span class="s1">:])</span>
    <span class="s1">results_test_spca *= np.sign(results_test_spca[</span><span class="s3">0</span><span class="s2">, </span><span class="s1">:])</span>
    <span class="s1">assert_allclose(results_test_pca</span><span class="s2">, </span><span class="s1">results_test_spca)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;SPCA&quot;</span><span class="s2">, </span><span class="s1">[SparsePCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;n_components&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s2">None, </span><span class="s3">3</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">test_spca_n_components_(SPCA</span><span class="s2">, </span><span class="s1">n_components):</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">model = SPCA(n_components=n_components).fit(X)</span>

    <span class="s2">if </span><span class="s1">n_components </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">assert </span><span class="s1">model.n_components_ == n_components</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">assert </span><span class="s1">model.n_components_ == n_features</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;SPCA&quot;</span><span class="s2">, </span><span class="s1">(SparsePCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA))</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;method&quot;</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s4">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;data_type, expected_type&quot;</span><span class="s2">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s2">, </span><span class="s1">np.float32)</span><span class="s2">,</span>
        <span class="s1">(np.float64</span><span class="s2">, </span><span class="s1">np.float64)</span><span class="s2">,</span>
        <span class="s1">(np.int32</span><span class="s2">, </span><span class="s1">np.float64)</span><span class="s2">,</span>
        <span class="s1">(np.int64</span><span class="s2">, </span><span class="s1">np.float64)</span><span class="s2">,</span>
    <span class="s1">)</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">def </span><span class="s1">test_sparse_pca_dtype_match(SPCA</span><span class="s2">, </span><span class="s1">method</span><span class="s2">, </span><span class="s1">data_type</span><span class="s2">, </span><span class="s1">expected_type):</span>
    <span class="s0"># Verify output matrix dtype</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_components = </span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s3">3</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">input_array = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features).astype(data_type)</span>
    <span class="s1">model = SPCA(n_components=n_components</span><span class="s2">, </span><span class="s1">method=method)</span>
    <span class="s1">transformed = model.fit_transform(input_array)</span>

    <span class="s2">assert </span><span class="s1">transformed.dtype == expected_type</span>
    <span class="s2">assert </span><span class="s1">model.components_.dtype == expected_type</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;SPCA&quot;</span><span class="s2">, </span><span class="s1">(SparsePCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA))</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;method&quot;</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;lars&quot;</span><span class="s2">, </span><span class="s4">&quot;cd&quot;</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">test_sparse_pca_numerical_consistency(SPCA</span><span class="s2">, </span><span class="s1">method):</span>
    <span class="s0"># Verify numericall consistentency among np.float32 and np.float64</span>
    <span class="s1">rtol = </span><span class="s3">1e-3</span>
    <span class="s1">alpha = </span><span class="s3">2</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_components = </span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span><span class="s2">, </span><span class="s3">3</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">input_array = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">model_32 = SPCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s1">transformed_32 = model_32.fit_transform(input_array.astype(np.float32))</span>

    <span class="s1">model_64 = SPCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s1">transformed_64 = model_64.fit_transform(input_array.astype(np.float64))</span>

    <span class="s1">assert_allclose(transformed_64</span><span class="s2">, </span><span class="s1">transformed_32</span><span class="s2">, </span><span class="s1">rtol=rtol)</span>
    <span class="s1">assert_allclose(model_64.components_</span><span class="s2">, </span><span class="s1">model_32.components_</span><span class="s2">, </span><span class="s1">rtol=rtol)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;SPCA&quot;</span><span class="s2">, </span><span class="s1">[SparsePCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA])</span>
<span class="s2">def </span><span class="s1">test_spca_feature_names_out(SPCA):</span>
    <span class="s5">&quot;&quot;&quot;Check feature names out for *SparsePCA.&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">model = SPCA(n_components=</span><span class="s3">4</span><span class="s1">).fit(X)</span>
    <span class="s1">names = model.get_feature_names_out()</span>

    <span class="s1">estimator_name = SPCA.__name__.lower()</span>
    <span class="s1">assert_array_equal([</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">estimator_name</span><span class="s2">}{</span><span class="s1">i</span><span class="s2">}</span><span class="s4">&quot; </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s3">4</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">names)</span>


<span class="s0"># TODO (1.4): remove this test</span>
<span class="s2">def </span><span class="s1">test_spca_n_iter_deprecation():</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise a warning for the deprecation of `n_iter` and it is ignored 
    when `max_iter` is specified. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">12</span><span class="s2">, </span><span class="s3">10</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">warn_msg = </span><span class="s4">&quot;'n_iter' is deprecated in version 1.1 and will be removed&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s2">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">MiniBatchSparsePCA(n_iter=</span><span class="s3">2</span><span class="s1">).fit(X)</span>

    <span class="s1">n_iter</span><span class="s2">, </span><span class="s1">max_iter = </span><span class="s3">1</span><span class="s2">, </span><span class="s3">100</span>
    <span class="s2">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s2">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">model = MiniBatchSparsePCA(</span>
            <span class="s1">n_iter=n_iter</span><span class="s2">, </span><span class="s1">max_iter=max_iter</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
        <span class="s1">).fit(X)</span>
    <span class="s2">assert </span><span class="s1">model.n_iter_ &gt; </span><span class="s3">1</span>
    <span class="s2">assert </span><span class="s1">model.n_iter_ &lt;= max_iter</span>


<span class="s2">def </span><span class="s1">test_pca_n_features_deprecation():</span>
    <span class="s1">X = np.array([[-</span><span class="s3">1</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[-</span><span class="s3">2</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[-</span><span class="s3">3</span><span class="s2">, </span><span class="s1">-</span><span class="s3">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">2</span><span class="s2">, </span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">3</span><span class="s2">, </span><span class="s3">2</span><span class="s1">]])</span>
    <span class="s1">pca = PCA(n_components=</span><span class="s3">2</span><span class="s1">).fit(X)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s2">, </span><span class="s1">match=</span><span class="s4">&quot;`n_features_` was deprecated&quot;</span><span class="s1">):</span>
        <span class="s1">pca.n_features_</span>


<span class="s2">def </span><span class="s1">test_spca_early_stopping(global_random_seed):</span>
    <span class="s5">&quot;&quot;&quot;Check that `tol` and `max_no_improvement` act as early stopping.&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">50</span><span class="s2">, </span><span class="s3">10</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s0"># vary the tolerance to force the early stopping of one of the model</span>
    <span class="s1">model_early_stopped = MiniBatchSparsePCA(</span>
        <span class="s1">max_iter=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">0.5</span><span class="s2">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">).fit(X)</span>
    <span class="s1">model_not_early_stopped = MiniBatchSparsePCA(</span>
        <span class="s1">max_iter=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-3</span><span class="s2">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">).fit(X)</span>
    <span class="s2">assert </span><span class="s1">model_early_stopped.n_iter_ &lt; model_not_early_stopped.n_iter_</span>

    <span class="s0"># force the max number of no improvement to a large value to check that</span>
    <span class="s0"># it does help to early stop</span>
    <span class="s1">model_early_stopped = MiniBatchSparsePCA(</span>
        <span class="s1">max_iter=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-6</span><span class="s2">, </span><span class="s1">max_no_improvement=</span><span class="s3">2</span><span class="s2">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">).fit(X)</span>
    <span class="s1">model_not_early_stopped = MiniBatchSparsePCA(</span>
        <span class="s1">max_iter=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">tol=</span><span class="s3">1e-6</span><span class="s2">, </span><span class="s1">max_no_improvement=</span><span class="s3">100</span><span class="s2">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">).fit(X)</span>
    <span class="s2">assert </span><span class="s1">model_early_stopped.n_iter_ &lt; model_not_early_stopped.n_iter_</span>


<span class="s2">def </span><span class="s1">test_equivalence_components_pca_spca(global_random_seed):</span>
    <span class="s5">&quot;&quot;&quot;Check the equivalence of the components found by PCA and SparsePCA. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/23932 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">X = rng.randn(</span><span class="s3">50</span><span class="s2">, </span><span class="s3">4</span><span class="s1">)</span>

    <span class="s1">n_components = </span><span class="s3">2</span>
    <span class="s1">pca = PCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">,</span>
        <span class="s1">svd_solver=</span><span class="s4">&quot;randomized&quot;</span><span class="s2">,</span>
        <span class="s1">random_state=</span><span class="s3">0</span><span class="s2">,</span>
    <span class="s1">).fit(X)</span>
    <span class="s1">spca = SparsePCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">,</span>
        <span class="s1">method=</span><span class="s4">&quot;lars&quot;</span><span class="s2">,</span>
        <span class="s1">ridge_alpha=</span><span class="s3">0</span><span class="s2">,</span>
        <span class="s1">alpha=</span><span class="s3">0</span><span class="s2">,</span>
        <span class="s1">random_state=</span><span class="s3">0</span><span class="s2">,</span>
    <span class="s1">).fit(X)</span>

    <span class="s1">assert_allclose(pca.components_</span><span class="s2">, </span><span class="s1">spca.components_)</span>


<span class="s2">def </span><span class="s1">test_sparse_pca_inverse_transform():</span>
    <span class="s5">&quot;&quot;&quot;Check that `inverse_transform` in `SparsePCA` and `PCA` are similar.&quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">10</span><span class="s2">, </span><span class="s3">5</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">n_components = </span><span class="s3">2</span>
    <span class="s1">spca = SparsePCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">1e-12</span><span class="s2">, </span><span class="s1">ridge_alpha=</span><span class="s3">1e-12</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s1">pca = PCA(n_components=n_components</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X_trans_spca = spca.fit_transform(X)</span>
    <span class="s1">X_trans_pca = pca.fit_transform(X)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">spca.inverse_transform(X_trans_spca)</span><span class="s2">, </span><span class="s1">pca.inverse_transform(X_trans_pca)</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;SPCA&quot;</span><span class="s2">, </span><span class="s1">[SparsePCA</span><span class="s2">, </span><span class="s1">MiniBatchSparsePCA])</span>
<span class="s2">def </span><span class="s1">test_transform_inverse_transform_round_trip(SPCA):</span>
    <span class="s5">&quot;&quot;&quot;Check the `transform` and `inverse_transform` round trip with no loss of 
    information. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = </span><span class="s3">10</span><span class="s2">, </span><span class="s3">5</span>
    <span class="s1">X = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s1">n_components = n_features</span>
    <span class="s1">spca = SPCA(</span>
        <span class="s1">n_components=n_components</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s3">1e-12</span><span class="s2">, </span><span class="s1">ridge_alpha=</span><span class="s3">1e-12</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s1">X_trans_spca = spca.fit_transform(X)</span>
    <span class="s1">assert_allclose(spca.inverse_transform(X_trans_spca)</span><span class="s2">, </span><span class="s1">X)</span>
</pre>
</body>
</html>
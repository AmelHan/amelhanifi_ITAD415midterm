<html>
<head>
<title>try_mlecov.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
try_mlecov.py</font>
</center></td></tr></table>
<pre><span class="s0">'''Multivariate Normal Model with full covariance matrix 
 
toeplitz structure is not exploited, need cholesky or inv for toeplitz 
 
Author: josef-pktd 
'''</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">linalg</span>
<span class="s2">from </span><span class="s1">scipy.linalg </span><span class="s2">import </span><span class="s1">toeplitz</span>

<span class="s2">from </span><span class="s1">statsmodels.base.model </span><span class="s2">import </span><span class="s1">GenericLikelihoodModel</span>
<span class="s2">from </span><span class="s1">statsmodels.datasets </span><span class="s2">import </span><span class="s1">sunspots</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.arima_process </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ArmaProcess</span><span class="s2">,</span>
    <span class="s1">arma_acovf</span><span class="s2">,</span>
    <span class="s1">arma_generate_sample</span><span class="s2">,</span>
<span class="s1">)</span>


<span class="s2">def </span><span class="s1">mvn_loglike_sum(x</span><span class="s2">, </span><span class="s1">sigma):</span>
    <span class="s0">'''loglike multivariate normal 
 
    copied from GLS and adjusted names 
    not sure why this differes from mvn_loglike 
    '''</span>
    <span class="s1">nobs = len(x)</span>
    <span class="s1">nobs2 = nobs / </span><span class="s3">2.0</span>
    <span class="s1">SSR = (x**</span><span class="s3">2</span><span class="s1">).sum()</span>
    <span class="s1">llf = -np.log(SSR) * nobs2      </span><span class="s4"># concentrated likelihood</span>
    <span class="s1">llf -= (</span><span class="s3">1</span><span class="s1">+np.log(np.pi/nobs2))*nobs2  </span><span class="s4"># with likelihood constant</span>
    <span class="s2">if </span><span class="s1">np.any(sigma) </span><span class="s2">and </span><span class="s1">sigma.ndim == </span><span class="s3">2</span><span class="s1">:</span>
    <span class="s4">#FIXME: robust-enough check?  unneeded if _det_sigma gets defined</span>
        <span class="s1">llf -= </span><span class="s3">.5</span><span class="s1">*np.log(np.linalg.det(sigma))</span>
    <span class="s2">return </span><span class="s1">llf</span>

<span class="s2">def </span><span class="s1">mvn_loglike(x</span><span class="s2">, </span><span class="s1">sigma):</span>
    <span class="s0">'''loglike multivariate normal 
 
    assumes x is 1d, (nobs,) and sigma is 2d (nobs, nobs) 
 
    brute force from formula 
    no checking of correct inputs 
    use of inv and log-det should be replace with something more efficient 
    '''</span>
    <span class="s4">#see numpy thread</span>
    <span class="s4">#Sturla: sqmahal = (cx*cho_solve(cho_factor(S),cx.T).T).sum(axis=1)</span>
    <span class="s1">sigmainv = linalg.inv(sigma)</span>
    <span class="s1">logdetsigma = np.log(np.linalg.det(sigma))</span>
    <span class="s1">nobs = len(x)</span>

    <span class="s1">llf = - np.dot(x</span><span class="s2">, </span><span class="s1">np.dot(sigmainv</span><span class="s2">, </span><span class="s1">x))</span>
    <span class="s1">llf -= nobs * np.log(</span><span class="s3">2 </span><span class="s1">* np.pi)</span>
    <span class="s1">llf -= logdetsigma</span>
    <span class="s1">llf *= </span><span class="s3">0.5</span>
    <span class="s2">return </span><span class="s1">llf</span>

<span class="s2">def </span><span class="s1">mvn_loglike_chol(x</span><span class="s2">, </span><span class="s1">sigma):</span>
    <span class="s0">'''loglike multivariate normal 
 
    assumes x is 1d, (nobs,) and sigma is 2d (nobs, nobs) 
 
    brute force from formula 
    no checking of correct inputs 
    use of inv and log-det should be replace with something more efficient 
    '''</span>
    <span class="s4">#see numpy thread</span>
    <span class="s4">#Sturla: sqmahal = (cx*cho_solve(cho_factor(S),cx.T).T).sum(axis=1)</span>
    <span class="s1">sigmainv = np.linalg.inv(sigma)</span>
    <span class="s1">cholsigmainv = np.linalg.cholesky(sigmainv).T</span>
    <span class="s1">x_whitened = np.dot(cholsigmainv</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s1">logdetsigma = np.log(np.linalg.det(sigma))</span>
    <span class="s1">nobs = len(x)</span>
    <span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>
    <span class="s1">print(</span><span class="s5">'scipy.stats'</span><span class="s1">)</span>
    <span class="s1">print(np.log(stats.norm.pdf(x_whitened)).sum())</span>

    <span class="s1">llf = - np.dot(x_whitened.T</span><span class="s2">, </span><span class="s1">x_whitened)</span>
    <span class="s1">llf -= nobs * np.log(</span><span class="s3">2 </span><span class="s1">* np.pi)</span>
    <span class="s1">llf -= logdetsigma</span>
    <span class="s1">llf *= </span><span class="s3">0.5</span>
    <span class="s2">return </span><span class="s1">llf</span><span class="s2">, </span><span class="s1">logdetsigma</span><span class="s2">, </span><span class="s3">2 </span><span class="s1">* np.sum(np.log(np.diagonal(cholsigmainv)))</span>
<span class="s4">#0.5 * np.dot(x_whitened.T, x_whitened) + nobs * np.log(2 * np.pi) + logdetsigma)</span>

<span class="s2">def </span><span class="s1">mvn_nloglike_obs(x</span><span class="s2">, </span><span class="s1">sigma):</span>
    <span class="s0">'''loglike multivariate normal 
 
    assumes x is 1d, (nobs,) and sigma is 2d (nobs, nobs) 
 
    brute force from formula 
    no checking of correct inputs 
    use of inv and log-det should be replace with something more efficient 
    '''</span>
    <span class="s4">#see numpy thread</span>
    <span class="s4">#Sturla: sqmahal = (cx*cho_solve(cho_factor(S),cx.T).T).sum(axis=1)</span>

    <span class="s4">#Still wasteful to calculate pinv first</span>
    <span class="s1">sigmainv = np.linalg.inv(sigma)</span>
    <span class="s1">cholsigmainv = np.linalg.cholesky(sigmainv).T</span>
    <span class="s4">#2 * np.sum(np.log(np.diagonal(np.linalg.cholesky(A)))) #Dag mailinglist</span>
    <span class="s4"># logdet not needed ???</span>
    <span class="s4">#logdetsigma = 2 * np.sum(np.log(np.diagonal(cholsigmainv)))</span>
    <span class="s1">x_whitened = np.dot(cholsigmainv</span><span class="s2">, </span><span class="s1">x)</span>

    <span class="s4">#sigmainv = linalg.cholesky(sigma)</span>
    <span class="s1">logdetsigma = np.log(np.linalg.det(sigma))</span>

    <span class="s1">sigma2 = </span><span class="s3">1. </span><span class="s4"># error variance is included in sigma</span>

    <span class="s1">llike  =  </span><span class="s3">0.5 </span><span class="s1">* (np.log(sigma2) - </span><span class="s3">2.</span><span class="s1">* np.log(np.diagonal(cholsigmainv))</span>
                          <span class="s1">+ (x_whitened**</span><span class="s3">2</span><span class="s1">)/sigma2</span>
                          <span class="s1">+  np.log(</span><span class="s3">2</span><span class="s1">*np.pi))</span>

    <span class="s2">return </span><span class="s1">llike</span>


<span class="s2">def </span><span class="s1">invertibleroots(ma):</span>
    <span class="s1">proc = ArmaProcess(ma=ma)</span>
    <span class="s2">return </span><span class="s1">proc.invertroots(retnew=</span><span class="s2">False</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">getpoly(self</span><span class="s2">, </span><span class="s1">params):</span>
    <span class="s1">ar = np.r_[[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">-params[:self.nar]]</span>
    <span class="s1">ma = np.r_[[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[-self.nma:]]</span>
    <span class="s2">import </span><span class="s1">numpy.polynomial </span><span class="s2">as </span><span class="s1">poly</span>
    <span class="s2">return </span><span class="s1">poly.Polynomial(ar)</span><span class="s2">, </span><span class="s1">poly.Polynomial(ma)</span>

<span class="s2">class </span><span class="s1">MLEGLS(GenericLikelihoodModel):</span>
    <span class="s0">'''ARMA model with exact loglikelhood for short time series 
 
    Inverts (nobs, nobs) matrix, use only for nobs &lt;= 200 or so. 
 
    This class is a pattern for small sample GLS-like models. Intended use 
    for loglikelihood of initial observations for ARMA. 
 
 
 
    TODO: 
    This might be missing the error variance. Does it assume error is 
       distributed N(0,1) 
    Maybe extend to mean handling, or assume it is already removed. 
    '''</span>


    <span class="s2">def </span><span class="s1">_params2cov(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">nobs):</span>
        <span class="s0">'''get autocovariance matrix from ARMA regression parameter 
 
        ar parameters are assumed to have rhs parameterization 
 
        '''</span>
        <span class="s1">ar = np.r_[[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">-params[:self.nar]]</span>
        <span class="s1">ma = np.r_[[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[-self.nma:]]</span>
        <span class="s4">#print('ar', ar</span>
        <span class="s4">#print('ma', ma</span>
        <span class="s4">#print('nobs', nobs</span>
        <span class="s1">autocov = arma_acovf(ar</span><span class="s2">, </span><span class="s1">ma</span><span class="s2">, </span><span class="s1">nobs=nobs)</span>
        <span class="s4">#print('arma_acovf(%r, %r, nobs=%d)' % (ar, ma, nobs)</span>
        <span class="s4">#print(autocov.shape</span>
        <span class="s4">#something is strange  fixed in aram_acovf</span>
        <span class="s1">autocov = autocov[:nobs]</span>
        <span class="s1">sigma = toeplitz(autocov)</span>
        <span class="s2">return </span><span class="s1">sigma</span>

    <span class="s2">def </span><span class="s1">loglike(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s1">sig = self._params2cov(params[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.nobs)</span>
        <span class="s1">sig = sig * params[-</span><span class="s3">1</span><span class="s1">]**</span><span class="s3">2</span>
        <span class="s1">loglik = mvn_loglike(self.endog</span><span class="s2">, </span><span class="s1">sig)</span>
        <span class="s2">return </span><span class="s1">loglik</span>

    <span class="s2">def </span><span class="s1">fit_invertible(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwds):</span>
        <span class="s1">res = self.fit(*args</span><span class="s2">, </span><span class="s1">**kwds)</span>
        <span class="s1">ma = np.r_[[</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">res.params[self.nar: self.nar+self.nma]]</span>
        <span class="s1">mainv</span><span class="s2">, </span><span class="s1">wasinvertible = invertibleroots(ma)</span>
        <span class="s2">if not </span><span class="s1">wasinvertible:</span>
            <span class="s1">start_params = res.params.copy()</span>
            <span class="s1">start_params[self.nar: self.nar+self.nma] = mainv[</span><span class="s3">1</span><span class="s1">:]</span>
            <span class="s4">#need to add args kwds</span>
            <span class="s1">res = self.fit(start_params=start_params)</span>
        <span class="s2">return </span><span class="s1">res</span>



<span class="s2">if </span><span class="s1">__name__ == </span><span class="s5">'__main__'</span><span class="s1">:</span>
    <span class="s1">nobs = </span><span class="s3">50</span>
    <span class="s1">ar = [</span><span class="s3">1.0</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.8</span><span class="s2">, </span><span class="s3">0.1</span><span class="s1">]</span>
    <span class="s1">ma = [</span><span class="s3">1.0</span><span class="s2">,  </span><span class="s3">0.1</span><span class="s2">,  </span><span class="s3">0.2</span><span class="s1">]</span>
    <span class="s4">#ma = [1]</span>
    <span class="s1">np.random.seed(</span><span class="s3">9875789</span><span class="s1">)</span>
    <span class="s1">y = arma_generate_sample(ar</span><span class="s2">,</span><span class="s1">ma</span><span class="s2">,</span><span class="s1">nobs</span><span class="s2">,</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">y -= y.mean() </span><span class="s4">#I have not checked treatment of mean yet, so remove</span>
    <span class="s1">mod = MLEGLS(y)</span>
    <span class="s1">mod.nar</span><span class="s2">, </span><span class="s1">mod.nma = </span><span class="s3">2</span><span class="s2">, </span><span class="s3">2   </span><span class="s4">#needs to be added, no init method</span>
    <span class="s1">mod.nobs = len(y)</span>
    <span class="s1">res = mod.fit(start_params=[</span><span class="s3">0.1</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.8</span><span class="s2">, </span><span class="s3">0.2</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">1.</span><span class="s1">])</span>
    <span class="s1">print(</span><span class="s5">'DGP'</span><span class="s2">, </span><span class="s1">ar</span><span class="s2">, </span><span class="s1">ma)</span>
    <span class="s1">print(res.params)</span>
    <span class="s2">from </span><span class="s1">statsmodels.regression </span><span class="s2">import </span><span class="s1">yule_walker</span>
    <span class="s1">print(yule_walker(y</span><span class="s2">, </span><span class="s3">2</span><span class="s1">))</span>
    <span class="s4">#resi = mod.fit_invertible(start_params=[0.1,0,0.2,0, 0.5])</span>
    <span class="s4">#print(resi.params</span>

    <span class="s1">arpoly</span><span class="s2">, </span><span class="s1">mapoly = getpoly(mod</span><span class="s2">, </span><span class="s1">res.params[:-</span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">data = sunspots.load()</span>
    <span class="s4">#ys = data.endog[-100:]</span>
<span class="s4">##    ys = data.endog[12:]-data.endog[:-12]</span>
<span class="s4">##    ys -= ys.mean()</span>
<span class="s4">##    mods = MLEGLS(ys)</span>
<span class="s4">##    mods.nar, mods.nma = 13, 1   #needs to be added, no init method</span>
<span class="s4">##    mods.nobs = len(ys)</span>
<span class="s4">##    ress = mods.fit(start_params=np.r_[0.4, np.zeros(12), [0.2, 5.]],maxiter=200)</span>
<span class="s4">##    print(ress.params</span>
<span class="s4">##    import matplotlib.pyplot as plt</span>
<span class="s4">##    plt.plot(data.endog[1])</span>
<span class="s4">##    #plt.show()</span>

    <span class="s1">sigma = mod._params2cov(res.params[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">nobs) * res.params[-</span><span class="s3">1</span><span class="s1">]**</span><span class="s3">2</span>
    <span class="s1">print(mvn_loglike(y</span><span class="s2">, </span><span class="s1">sigma))</span>
    <span class="s1">llo = mvn_nloglike_obs(y</span><span class="s2">, </span><span class="s1">sigma)</span>
    <span class="s1">print(llo.sum()</span><span class="s2">, </span><span class="s1">llo.shape)</span>
    <span class="s1">print(mvn_loglike_chol(y</span><span class="s2">, </span><span class="s1">sigma))</span>
    <span class="s1">print(mvn_loglike_sum(y</span><span class="s2">, </span><span class="s1">sigma))</span>
</pre>
</body>
</html>
<html>
<head>
<title>_label.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_label.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="s0">#          Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="s0">#          Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="s0">#          Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="s0">#          Joel Nothman &lt;joel.nothman@gmail.com&gt;</span>
<span class="s0">#          Hamzeh Alsalhi &lt;ha258@cornell.edu&gt;</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">array</span>
<span class="s2">import </span><span class="s1">itertools</span>
<span class="s2">import </span><span class="s1">warnings</span>
<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">defaultdict</span>
<span class="s2">from </span><span class="s1">numbers </span><span class="s2">import </span><span class="s1">Integral</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">scipy.sparse </span><span class="s2">as </span><span class="s1">sp</span>

<span class="s2">from </span><span class="s1">..base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s2">, </span><span class="s1">TransformerMixin</span><span class="s2">, </span><span class="s1">_fit_context</span>
<span class="s2">from </span><span class="s1">..utils </span><span class="s2">import </span><span class="s1">column_or_1d</span>
<span class="s2">from </span><span class="s1">..utils._encode </span><span class="s2">import </span><span class="s1">_encode</span><span class="s2">, </span><span class="s1">_unique</span>
<span class="s2">from </span><span class="s1">..utils._param_validation </span><span class="s2">import </span><span class="s1">Interval</span><span class="s2">, </span><span class="s1">validate_params</span>
<span class="s2">from </span><span class="s1">..utils.multiclass </span><span class="s2">import </span><span class="s1">type_of_target</span><span class="s2">, </span><span class="s1">unique_labels</span>
<span class="s2">from </span><span class="s1">..utils.sparsefuncs </span><span class="s2">import </span><span class="s1">min_max_axis</span>
<span class="s2">from </span><span class="s1">..utils.validation </span><span class="s2">import </span><span class="s1">_num_samples</span><span class="s2">, </span><span class="s1">check_array</span><span class="s2">, </span><span class="s1">check_is_fitted</span>

<span class="s1">__all__ = [</span>
    <span class="s3">&quot;label_binarize&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;LabelBinarizer&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;LabelEncoder&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;MultiLabelBinarizer&quot;</span><span class="s2">,</span>
<span class="s1">]</span>


<span class="s2">class </span><span class="s1">LabelEncoder(TransformerMixin</span><span class="s2">, </span><span class="s1">BaseEstimator</span><span class="s2">, </span><span class="s1">auto_wrap_output_keys=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Encode target labels with value between 0 and n_classes-1. 
 
    This transformer should be used to encode target values, *i.e.* `y`, and 
    not the input `X`. 
 
    Read more in the :ref:`User Guide &lt;preprocessing_targets&gt;`. 
 
    .. versionadded:: 0.12 
 
    Attributes 
    ---------- 
    classes_ : ndarray of shape (n_classes,) 
        Holds the label for each class. 
 
    See Also 
    -------- 
    OrdinalEncoder : Encode categorical features using an ordinal encoding 
        scheme. 
    OneHotEncoder : Encode categorical features as a one-hot numeric array. 
 
    Examples 
    -------- 
    `LabelEncoder` can be used to normalize labels. 
 
    &gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder 
    &gt;&gt;&gt; le = LabelEncoder() 
    &gt;&gt;&gt; le.fit([1, 2, 2, 6]) 
    LabelEncoder() 
    &gt;&gt;&gt; le.classes_ 
    array([1, 2, 6]) 
    &gt;&gt;&gt; le.transform([1, 1, 2, 6]) 
    array([0, 0, 1, 2]...) 
    &gt;&gt;&gt; le.inverse_transform([0, 0, 1, 2]) 
    array([1, 1, 2, 6]) 
 
    It can also be used to transform non-numerical labels (as long as they are 
    hashable and comparable) to numerical labels. 
 
    &gt;&gt;&gt; le = LabelEncoder() 
    &gt;&gt;&gt; le.fit([&quot;paris&quot;, &quot;paris&quot;, &quot;tokyo&quot;, &quot;amsterdam&quot;]) 
    LabelEncoder() 
    &gt;&gt;&gt; list(le.classes_) 
    ['amsterdam', 'paris', 'tokyo'] 
    &gt;&gt;&gt; le.transform([&quot;tokyo&quot;, &quot;tokyo&quot;, &quot;paris&quot;]) 
    array([2, 2, 1]...) 
    &gt;&gt;&gt; list(le.inverse_transform([2, 2, 1])) 
    ['tokyo', 'tokyo', 'paris'] 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit label encoder. 
 
        Parameters 
        ---------- 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        self : returns an instance of self. 
            Fitted label encoder. 
        &quot;&quot;&quot;</span>
        <span class="s1">y = column_or_1d(y</span><span class="s2">, </span><span class="s1">warn=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">self.classes_ = _unique(y)</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">fit_transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit label encoder and return encoded labels. 
 
        Parameters 
        ---------- 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        y : array-like of shape (n_samples,) 
            Encoded labels. 
        &quot;&quot;&quot;</span>
        <span class="s1">y = column_or_1d(y</span><span class="s2">, </span><span class="s1">warn=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">self.classes_</span><span class="s2">, </span><span class="s1">y = _unique(y</span><span class="s2">, </span><span class="s1">return_inverse=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">y</span>

    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Transform labels to normalized encoding. 
 
        Parameters 
        ---------- 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        y : array-like of shape (n_samples,) 
            Labels as normalized encodings. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>
        <span class="s1">y = column_or_1d(y</span><span class="s2">, </span><span class="s1">dtype=self.classes_.dtype</span><span class="s2">, </span><span class="s1">warn=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s0"># transform of empty array is empty array</span>
        <span class="s2">if </span><span class="s1">_num_samples(y) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.array([])</span>

        <span class="s2">return </span><span class="s1">_encode(y</span><span class="s2">, </span><span class="s1">uniques=self.classes_)</span>

    <span class="s2">def </span><span class="s1">inverse_transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Transform labels back to original encoding. 
 
        Parameters 
        ---------- 
        y : ndarray of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        y : ndarray of shape (n_samples,) 
            Original encoding. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>
        <span class="s1">y = column_or_1d(y</span><span class="s2">, </span><span class="s1">warn=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s0"># inverse transform of empty array is empty array</span>
        <span class="s2">if </span><span class="s1">_num_samples(y) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.array([])</span>

        <span class="s1">diff = np.setdiff1d(y</span><span class="s2">, </span><span class="s1">np.arange(len(self.classes_)))</span>
        <span class="s2">if </span><span class="s1">len(diff):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;y contains previously unseen labels: %s&quot; </span><span class="s1">% str(diff))</span>
        <span class="s1">y = np.asarray(y)</span>
        <span class="s2">return </span><span class="s1">self.classes_[y]</span>

    <span class="s2">def </span><span class="s1">_more_tags(self):</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s3">&quot;X_types&quot;</span><span class="s1">: [</span><span class="s3">&quot;1dlabels&quot;</span><span class="s1">]}</span>


<span class="s2">class </span><span class="s1">LabelBinarizer(TransformerMixin</span><span class="s2">, </span><span class="s1">BaseEstimator</span><span class="s2">, </span><span class="s1">auto_wrap_output_keys=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Binarize labels in a one-vs-all fashion. 
 
    Several regression and binary classification algorithms are 
    available in scikit-learn. A simple way to extend these algorithms 
    to the multi-class classification case is to use the so-called 
    one-vs-all scheme. 
 
    At learning time, this simply consists in learning one regressor 
    or binary classifier per class. In doing so, one needs to convert 
    multi-class labels to binary labels (belong or does not belong 
    to the class). `LabelBinarizer` makes this process easy with the 
    transform method. 
 
    At prediction time, one assigns the class for which the corresponding 
    model gave the greatest confidence. `LabelBinarizer` makes this easy 
    with the :meth:`inverse_transform` method. 
 
    Read more in the :ref:`User Guide &lt;preprocessing_targets&gt;`. 
 
    Parameters 
    ---------- 
    neg_label : int, default=0 
        Value with which negative labels must be encoded. 
 
    pos_label : int, default=1 
        Value with which positive labels must be encoded. 
 
    sparse_output : bool, default=False 
        True if the returned array from transform is desired to be in sparse 
        CSR format. 
 
    Attributes 
    ---------- 
    classes_ : ndarray of shape (n_classes,) 
        Holds the label for each class. 
 
    y_type_ : str 
        Represents the type of the target data as evaluated by 
        :func:`~sklearn.utils.multiclass.type_of_target`. Possible type are 
        'continuous', 'continuous-multioutput', 'binary', 'multiclass', 
        'multiclass-multioutput', 'multilabel-indicator', and 'unknown'. 
 
    sparse_input_ : bool 
        `True` if the input data to transform is given as a sparse matrix, 
         `False` otherwise. 
 
    See Also 
    -------- 
    label_binarize : Function to perform the transform operation of 
        LabelBinarizer with fixed classes. 
    OneHotEncoder : Encode categorical features using a one-hot aka one-of-K 
        scheme. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.preprocessing import LabelBinarizer 
    &gt;&gt;&gt; lb = LabelBinarizer() 
    &gt;&gt;&gt; lb.fit([1, 2, 6, 4, 2]) 
    LabelBinarizer() 
    &gt;&gt;&gt; lb.classes_ 
    array([1, 2, 4, 6]) 
    &gt;&gt;&gt; lb.transform([1, 6]) 
    array([[1, 0, 0, 0], 
           [0, 0, 0, 1]]) 
 
    Binary targets transform to a column vector 
 
    &gt;&gt;&gt; lb = LabelBinarizer() 
    &gt;&gt;&gt; lb.fit_transform(['yes', 'no', 'no', 'yes']) 
    array([[1], 
           [0], 
           [0], 
           [1]]) 
 
    Passing a 2D matrix for multilabel classification 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; lb.fit(np.array([[0, 1, 1], [1, 0, 0]])) 
    LabelBinarizer() 
    &gt;&gt;&gt; lb.classes_ 
    array([0, 1, 2]) 
    &gt;&gt;&gt; lb.transform([0, 1, 2, 1]) 
    array([[1, 0, 0], 
           [0, 1, 0], 
           [0, 0, 1], 
           [0, 1, 0]]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints: dict = {</span>
        <span class="s3">&quot;neg_label&quot;</span><span class="s1">: [Integral]</span><span class="s2">,</span>
        <span class="s3">&quot;pos_label&quot;</span><span class="s1">: [Integral]</span><span class="s2">,</span>
        <span class="s3">&quot;sparse_output&quot;</span><span class="s1">: [</span><span class="s3">&quot;boolean&quot;</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">}</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">neg_label=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">pos_label=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">sparse_output=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s1">self.neg_label = neg_label</span>
        <span class="s1">self.pos_label = pos_label</span>
        <span class="s1">self.sparse_output = sparse_output</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit label binarizer. 
 
        Parameters 
        ---------- 
        y : ndarray of shape (n_samples,) or (n_samples, n_classes) 
            Target values. The 2-d matrix should only contain 0 and 1, 
            represents multilabel classification. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.neg_label &gt;= self.pos_label:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">f&quot;neg_label=</span><span class="s2">{</span><span class="s1">self.neg_label</span><span class="s2">} </span><span class="s3">must be strictly less than &quot;</span>
                <span class="s3">f&quot;pos_label=</span><span class="s2">{</span><span class="s1">self.pos_label</span><span class="s2">}</span><span class="s3">.&quot;</span>
            <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self.sparse_output </span><span class="s2">and </span><span class="s1">(self.pos_label == </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">self.neg_label != </span><span class="s5">0</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Sparse binarization is only supported with non &quot;</span>
                <span class="s3">&quot;zero pos_label and zero neg_label, got &quot;</span>
                <span class="s3">f&quot;pos_label=</span><span class="s2">{</span><span class="s1">self.pos_label</span><span class="s2">} </span><span class="s3">and neg_label=</span><span class="s2">{</span><span class="s1">self.neg_label</span><span class="s2">}</span><span class="s3">&quot;</span>
            <span class="s1">)</span>

        <span class="s1">self.y_type_ = type_of_target(y</span><span class="s2">, </span><span class="s1">input_name=</span><span class="s3">&quot;y&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s3">&quot;multioutput&quot; </span><span class="s2">in </span><span class="s1">self.y_type_:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Multioutput target data is not supported with label binarization&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">_num_samples(y) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;y has 0 samples: %r&quot; </span><span class="s1">% y)</span>

        <span class="s1">self.sparse_input_ = sp.issparse(y)</span>
        <span class="s1">self.classes_ = unique_labels(y)</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">fit_transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit label binarizer/transform multi-class labels to binary labels. 
 
        The output of transform is sometimes referred to as 
        the 1-of-K coding scheme. 
 
        Parameters 
        ---------- 
        y : {ndarray, sparse matrix} of shape (n_samples,) or \ 
                (n_samples, n_classes) 
            Target values. The 2-d matrix should only contain 0 and 1, 
            represents multilabel classification. Sparse matrix can be 
            CSR, CSC, COO, DOK, or LIL. 
 
        Returns 
        ------- 
        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
            Shape will be (n_samples, 1) for binary problems. Sparse matrix 
            will be of CSR format. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.fit(y).transform(y)</span>

    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Transform multi-class labels to binary labels. 
 
        The output of transform is sometimes referred to by some authors as 
        the 1-of-K coding scheme. 
 
        Parameters 
        ---------- 
        y : {array, sparse matrix} of shape (n_samples,) or \ 
                (n_samples, n_classes) 
            Target values. The 2-d matrix should only contain 0 and 1, 
            represents multilabel classification. Sparse matrix can be 
            CSR, CSC, COO, DOK, or LIL. 
 
        Returns 
        ------- 
        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
            Shape will be (n_samples, 1) for binary problems. Sparse matrix 
            will be of CSR format. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s1">y_is_multilabel = type_of_target(y).startswith(</span><span class="s3">&quot;multilabel&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">y_is_multilabel </span><span class="s2">and not </span><span class="s1">self.y_type_.startswith(</span><span class="s3">&quot;multilabel&quot;</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;The object was not fitted with multilabel input.&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">label_binarize(</span>
            <span class="s1">y</span><span class="s2">,</span>
            <span class="s1">classes=self.classes_</span><span class="s2">,</span>
            <span class="s1">pos_label=self.pos_label</span><span class="s2">,</span>
            <span class="s1">neg_label=self.neg_label</span><span class="s2">,</span>
            <span class="s1">sparse_output=self.sparse_output</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">inverse_transform(self</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot;Transform binary labels back to multi-class labels. 
 
        Parameters 
        ---------- 
        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
            Target values. All sparse matrices are converted to CSR before 
            inverse transformation. 
 
        threshold : float, default=None 
            Threshold used in the binary and multi-label cases. 
 
            Use 0 when ``Y`` contains the output of :term:`decision_function` 
            (classifier). 
            Use 0.5 when ``Y`` contains the output of :term:`predict_proba`. 
 
            If None, the threshold is assumed to be half way between 
            neg_label and pos_label. 
 
        Returns 
        ------- 
        y : {ndarray, sparse matrix} of shape (n_samples,) 
            Target values. Sparse matrix will be of CSR format. 
 
        Notes 
        ----- 
        In the case when the binary labels are fractional 
        (probabilistic), :meth:`inverse_transform` chooses the class with the 
        greatest value. Typically, this allows to use the output of a 
        linear model's :term:`decision_function` method directly as the input 
        of :meth:`inverse_transform`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s2">if </span><span class="s1">threshold </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">threshold = (self.pos_label + self.neg_label) / </span><span class="s5">2.0</span>

        <span class="s2">if </span><span class="s1">self.y_type_ == </span><span class="s3">&quot;multiclass&quot;</span><span class="s1">:</span>
            <span class="s1">y_inv = _inverse_binarize_multiclass(Y</span><span class="s2">, </span><span class="s1">self.classes_)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">y_inv = _inverse_binarize_thresholding(</span>
                <span class="s1">Y</span><span class="s2">, </span><span class="s1">self.y_type_</span><span class="s2">, </span><span class="s1">self.classes_</span><span class="s2">, </span><span class="s1">threshold</span>
            <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self.sparse_input_:</span>
            <span class="s1">y_inv = sp.csr_matrix(y_inv)</span>
        <span class="s2">elif </span><span class="s1">sp.issparse(y_inv):</span>
            <span class="s1">y_inv = y_inv.toarray()</span>

        <span class="s2">return </span><span class="s1">y_inv</span>

    <span class="s2">def </span><span class="s1">_more_tags(self):</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s3">&quot;X_types&quot;</span><span class="s1">: [</span><span class="s3">&quot;1dlabels&quot;</span><span class="s1">]}</span>


<span class="s1">@validate_params(</span>
    <span class="s1">{</span>
        <span class="s3">&quot;y&quot;</span><span class="s1">: [</span><span class="s3">&quot;array-like&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s3">&quot;classes&quot;</span><span class="s1">: [</span><span class="s3">&quot;array-like&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s3">&quot;neg_label&quot;</span><span class="s1">: [Interval(Integral</span><span class="s2">, None, None, </span><span class="s1">closed=</span><span class="s3">&quot;neither&quot;</span><span class="s1">)]</span><span class="s2">,</span>
        <span class="s3">&quot;pos_label&quot;</span><span class="s1">: [Interval(Integral</span><span class="s2">, None, None, </span><span class="s1">closed=</span><span class="s3">&quot;neither&quot;</span><span class="s1">)]</span><span class="s2">,</span>
        <span class="s3">&quot;sparse_output&quot;</span><span class="s1">: [</span><span class="s3">&quot;boolean&quot;</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">}</span><span class="s2">,</span>
    <span class="s1">prefer_skip_nested_validation=</span><span class="s2">True,</span>
<span class="s1">)</span>
<span class="s2">def </span><span class="s1">label_binarize(y</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">, </span><span class="s1">neg_label=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">pos_label=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">sparse_output=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Binarize labels in a one-vs-all fashion. 
 
    Several regression and binary classification algorithms are 
    available in scikit-learn. A simple way to extend these algorithms 
    to the multi-class classification case is to use the so-called 
    one-vs-all scheme. 
 
    This function makes it possible to compute this transformation for a 
    fixed set of class labels known ahead of time. 
 
    Parameters 
    ---------- 
    y : array-like 
        Sequence of integer labels or multilabel data to encode. 
 
    classes : array-like of shape (n_classes,) 
        Uniquely holds the label for each class. 
 
    neg_label : int, default=0 
        Value with which negative labels must be encoded. 
 
    pos_label : int, default=1 
        Value with which positive labels must be encoded. 
 
    sparse_output : bool, default=False, 
        Set to true if output binary array is desired in CSR sparse format. 
 
    Returns 
    ------- 
    Y : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
        Shape will be (n_samples, 1) for binary problems. Sparse matrix will 
        be of CSR format. 
 
    See Also 
    -------- 
    LabelBinarizer : Class used to wrap the functionality of label_binarize and 
        allow for fitting to classes independently of the transform operation. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.preprocessing import label_binarize 
    &gt;&gt;&gt; label_binarize([1, 6], classes=[1, 2, 4, 6]) 
    array([[1, 0, 0, 0], 
           [0, 0, 0, 1]]) 
 
    The class ordering is preserved: 
 
    &gt;&gt;&gt; label_binarize([1, 6], classes=[1, 6, 4, 2]) 
    array([[1, 0, 0, 0], 
           [0, 1, 0, 0]]) 
 
    Binary targets transform to a column vector 
 
    &gt;&gt;&gt; label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes']) 
    array([[1], 
           [0], 
           [0], 
           [1]]) 
    &quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">isinstance(y</span><span class="s2">, </span><span class="s1">list):</span>
        <span class="s0"># XXX Workaround that will be removed when list of list format is</span>
        <span class="s0"># dropped</span>
        <span class="s1">y = check_array(</span>
            <span class="s1">y</span><span class="s2">, </span><span class="s1">input_name=</span><span class="s3">&quot;y&quot;</span><span class="s2">, </span><span class="s1">accept_sparse=</span><span class="s3">&quot;csr&quot;</span><span class="s2">, </span><span class="s1">ensure_2d=</span><span class="s2">False, </span><span class="s1">dtype=</span><span class="s2">None</span>
        <span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">_num_samples(y) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;y has 0 samples: %r&quot; </span><span class="s1">% y)</span>
    <span class="s2">if </span><span class="s1">neg_label &gt;= pos_label:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s3">&quot;neg_label={0} must be strictly less than pos_label={1}.&quot;</span><span class="s1">.format(</span>
                <span class="s1">neg_label</span><span class="s2">, </span><span class="s1">pos_label</span>
            <span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">sparse_output </span><span class="s2">and </span><span class="s1">(pos_label == </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">neg_label != </span><span class="s5">0</span><span class="s1">):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s3">&quot;Sparse binarization is only supported with non &quot;</span>
            <span class="s3">&quot;zero pos_label and zero neg_label, got &quot;</span>
            <span class="s3">&quot;pos_label={0} and neg_label={1}&quot;</span>
            <span class="s3">&quot;&quot;</span><span class="s1">.format(pos_label</span><span class="s2">, </span><span class="s1">neg_label)</span>
        <span class="s1">)</span>

    <span class="s0"># To account for pos_label == 0 in the dense case</span>
    <span class="s1">pos_switch = pos_label == </span><span class="s5">0</span>
    <span class="s2">if </span><span class="s1">pos_switch:</span>
        <span class="s1">pos_label = -neg_label</span>

    <span class="s1">y_type = type_of_target(y)</span>
    <span class="s2">if </span><span class="s3">&quot;multioutput&quot; </span><span class="s2">in </span><span class="s1">y_type:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s3">&quot;Multioutput target data is not supported with label binarization&quot;</span>
        <span class="s1">)</span>
    <span class="s2">if </span><span class="s1">y_type == </span><span class="s3">&quot;unknown&quot;</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;The type of target data is not known&quot;</span><span class="s1">)</span>

    <span class="s1">n_samples = y.shape[</span><span class="s5">0</span><span class="s1">] </span><span class="s2">if </span><span class="s1">sp.issparse(y) </span><span class="s2">else </span><span class="s1">len(y)</span>
    <span class="s1">n_classes = len(classes)</span>
    <span class="s1">classes = np.asarray(classes)</span>

    <span class="s2">if </span><span class="s1">y_type == </span><span class="s3">&quot;binary&quot;</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">n_classes == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">sparse_output:</span>
                <span class="s2">return </span><span class="s1">sp.csr_matrix((n_samples</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=int)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">Y = np.zeros((len(y)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=int)</span>
                <span class="s1">Y += neg_label</span>
                <span class="s2">return </span><span class="s1">Y</span>
        <span class="s2">elif </span><span class="s1">len(classes) &gt;= </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s1">y_type = </span><span class="s3">&quot;multiclass&quot;</span>

    <span class="s1">sorted_class = np.sort(classes)</span>
    <span class="s2">if </span><span class="s1">y_type == </span><span class="s3">&quot;multilabel-indicator&quot;</span><span class="s1">:</span>
        <span class="s1">y_n_classes = y.shape[</span><span class="s5">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">hasattr(y</span><span class="s2">, </span><span class="s3">&quot;shape&quot;</span><span class="s1">) </span><span class="s2">else </span><span class="s1">len(y[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">classes.size != y_n_classes:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;classes {0} mismatch with the labels {1} found in the data&quot;</span><span class="s1">.format(</span>
                    <span class="s1">classes</span><span class="s2">, </span><span class="s1">unique_labels(y)</span>
                <span class="s1">)</span>
            <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">y_type </span><span class="s2">in </span><span class="s1">(</span><span class="s3">&quot;binary&quot;</span><span class="s2">, </span><span class="s3">&quot;multiclass&quot;</span><span class="s1">):</span>
        <span class="s1">y = column_or_1d(y)</span>

        <span class="s0"># pick out the known labels from y</span>
        <span class="s1">y_in_classes = np.isin(y</span><span class="s2">, </span><span class="s1">classes)</span>
        <span class="s1">y_seen = y[y_in_classes]</span>
        <span class="s1">indices = np.searchsorted(sorted_class</span><span class="s2">, </span><span class="s1">y_seen)</span>
        <span class="s1">indptr = np.hstack((</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.cumsum(y_in_classes)))</span>

        <span class="s1">data = np.empty_like(indices)</span>
        <span class="s1">data.fill(pos_label)</span>
        <span class="s1">Y = sp.csr_matrix((data</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">indptr)</span><span class="s2">, </span><span class="s1">shape=(n_samples</span><span class="s2">, </span><span class="s1">n_classes))</span>
    <span class="s2">elif </span><span class="s1">y_type == </span><span class="s3">&quot;multilabel-indicator&quot;</span><span class="s1">:</span>
        <span class="s1">Y = sp.csr_matrix(y)</span>
        <span class="s2">if </span><span class="s1">pos_label != </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">data = np.empty_like(Y.data)</span>
            <span class="s1">data.fill(pos_label)</span>
            <span class="s1">Y.data = data</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s3">&quot;%s target data is not supported with label binarization&quot; </span><span class="s1">% y_type</span>
        <span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">sparse_output:</span>
        <span class="s1">Y = Y.toarray()</span>
        <span class="s1">Y = Y.astype(int</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">neg_label != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">Y[Y == </span><span class="s5">0</span><span class="s1">] = neg_label</span>

        <span class="s2">if </span><span class="s1">pos_switch:</span>
            <span class="s1">Y[Y == pos_label] = </span><span class="s5">0</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">Y.data = Y.data.astype(int</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s0"># preserve label ordering</span>
    <span class="s2">if </span><span class="s1">np.any(classes != sorted_class):</span>
        <span class="s1">indices = np.searchsorted(sorted_class</span><span class="s2">, </span><span class="s1">classes)</span>
        <span class="s1">Y = Y[:</span><span class="s2">, </span><span class="s1">indices]</span>

    <span class="s2">if </span><span class="s1">y_type == </span><span class="s3">&quot;binary&quot;</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">sparse_output:</span>
            <span class="s1">Y = Y.getcol(-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">Y = Y[:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">].reshape((-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">return </span><span class="s1">Y</span>


<span class="s2">def </span><span class="s1">_inverse_binarize_multiclass(y</span><span class="s2">, </span><span class="s1">classes):</span>
    <span class="s4">&quot;&quot;&quot;Inverse label binarization transformation for multiclass. 
 
    Multiclass uses the maximal score instead of a threshold. 
    &quot;&quot;&quot;</span>
    <span class="s1">classes = np.asarray(classes)</span>

    <span class="s2">if </span><span class="s1">sp.issparse(y):</span>
        <span class="s0"># Find the argmax for each row in y where y is a CSR matrix</span>

        <span class="s1">y = y.tocsr()</span>
        <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_outputs = y.shape</span>
        <span class="s1">outputs = np.arange(n_outputs)</span>
        <span class="s1">row_max = min_max_axis(y</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">row_nnz = np.diff(y.indptr)</span>

        <span class="s1">y_data_repeated_max = np.repeat(row_max</span><span class="s2">, </span><span class="s1">row_nnz)</span>
        <span class="s0"># picks out all indices obtaining the maximum per row</span>
        <span class="s1">y_i_all_argmax = np.flatnonzero(y_data_repeated_max == y.data)</span>

        <span class="s0"># For corner case where last row has a max of 0</span>
        <span class="s2">if </span><span class="s1">row_max[-</span><span class="s5">1</span><span class="s1">] == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">y_i_all_argmax = np.append(y_i_all_argmax</span><span class="s2">, </span><span class="s1">[len(y.data)])</span>

        <span class="s0"># Gets the index of the first argmax in each row from y_i_all_argmax</span>
        <span class="s1">index_first_argmax = np.searchsorted(y_i_all_argmax</span><span class="s2">, </span><span class="s1">y.indptr[:-</span><span class="s5">1</span><span class="s1">])</span>
        <span class="s0"># first argmax of each row</span>
        <span class="s1">y_ind_ext = np.append(y.indices</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">y_i_argmax = y_ind_ext[y_i_all_argmax[index_first_argmax]]</span>
        <span class="s0"># Handle rows of all 0</span>
        <span class="s1">y_i_argmax[np.where(row_nnz == </span><span class="s5">0</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]] = </span><span class="s5">0</span>

        <span class="s0"># Handles rows with max of 0 that contain negative numbers</span>
        <span class="s1">samples = np.arange(n_samples)[(row_nnz &gt; </span><span class="s5">0</span><span class="s1">) &amp; (row_max.ravel() == </span><span class="s5">0</span><span class="s1">)]</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">samples:</span>
            <span class="s1">ind = y.indices[y.indptr[i] : y.indptr[i + </span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s1">y_i_argmax[i] = classes[np.setdiff1d(outputs</span><span class="s2">, </span><span class="s1">ind)][</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s2">return </span><span class="s1">classes[y_i_argmax]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">classes.take(y.argmax(axis=</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">mode=</span><span class="s3">&quot;clip&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_inverse_binarize_thresholding(y</span><span class="s2">, </span><span class="s1">output_type</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">, </span><span class="s1">threshold):</span>
    <span class="s4">&quot;&quot;&quot;Inverse label binarization transformation using thresholding.&quot;&quot;&quot;</span>

    <span class="s2">if </span><span class="s1">output_type == </span><span class="s3">&quot;binary&quot; </span><span class="s2">and </span><span class="s1">y.ndim == </span><span class="s5">2 </span><span class="s2">and </span><span class="s1">y.shape[</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;output_type='binary', but y.shape = {0}&quot;</span><span class="s1">.format(y.shape))</span>

    <span class="s2">if </span><span class="s1">output_type != </span><span class="s3">&quot;binary&quot; </span><span class="s2">and </span><span class="s1">y.shape[</span><span class="s5">1</span><span class="s1">] != len(classes):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span>
            <span class="s3">&quot;The number of class is not equal to the number of dimension of y.&quot;</span>
        <span class="s1">)</span>

    <span class="s1">classes = np.asarray(classes)</span>

    <span class="s0"># Perform thresholding</span>
    <span class="s2">if </span><span class="s1">sp.issparse(y):</span>
        <span class="s2">if </span><span class="s1">threshold &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">y.format </span><span class="s2">not in </span><span class="s1">(</span><span class="s3">&quot;csr&quot;</span><span class="s2">, </span><span class="s3">&quot;csc&quot;</span><span class="s1">):</span>
                <span class="s1">y = y.tocsr()</span>
            <span class="s1">y.data = np.array(y.data &gt; threshold</span><span class="s2">, </span><span class="s1">dtype=int)</span>
            <span class="s1">y.eliminate_zeros()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">y = np.array(y.toarray() &gt; threshold</span><span class="s2">, </span><span class="s1">dtype=int)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">y = np.array(y &gt; threshold</span><span class="s2">, </span><span class="s1">dtype=int)</span>

    <span class="s0"># Inverse transform data</span>
    <span class="s2">if </span><span class="s1">output_type == </span><span class="s3">&quot;binary&quot;</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">sp.issparse(y):</span>
            <span class="s1">y = y.toarray()</span>
        <span class="s2">if </span><span class="s1">y.ndim == </span><span class="s5">2 </span><span class="s2">and </span><span class="s1">y.shape[</span><span class="s5">1</span><span class="s1">] == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">classes[y[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(classes) == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">np.repeat(classes[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">len(y))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">classes[y.ravel()]</span>

    <span class="s2">elif </span><span class="s1">output_type == </span><span class="s3">&quot;multilabel-indicator&quot;</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">y</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;{0} format is not supported&quot;</span><span class="s1">.format(output_type))</span>


<span class="s2">class </span><span class="s1">MultiLabelBinarizer(TransformerMixin</span><span class="s2">, </span><span class="s1">BaseEstimator</span><span class="s2">, </span><span class="s1">auto_wrap_output_keys=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Transform between iterable of iterables and a multilabel format. 
 
    Although a list of sets or tuples is a very intuitive format for multilabel 
    data, it is unwieldy to process. This transformer converts between this 
    intuitive format and the supported multilabel format: a (samples x classes) 
    binary matrix indicating the presence of a class label. 
 
    Parameters 
    ---------- 
    classes : array-like of shape (n_classes,), default=None 
        Indicates an ordering for the class labels. 
        All entries should be unique (cannot contain duplicate classes). 
 
    sparse_output : bool, default=False 
        Set to True if output binary array is desired in CSR sparse format. 
 
    Attributes 
    ---------- 
    classes_ : ndarray of shape (n_classes,) 
        A copy of the `classes` parameter when provided. 
        Otherwise it corresponds to the sorted set of classes found 
        when fitting. 
 
    See Also 
    -------- 
    OneHotEncoder : Encode categorical features using a one-hot aka one-of-K 
        scheme. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.preprocessing import MultiLabelBinarizer 
    &gt;&gt;&gt; mlb = MultiLabelBinarizer() 
    &gt;&gt;&gt; mlb.fit_transform([(1, 2), (3,)]) 
    array([[1, 1, 0], 
           [0, 0, 1]]) 
    &gt;&gt;&gt; mlb.classes_ 
    array([1, 2, 3]) 
 
    &gt;&gt;&gt; mlb.fit_transform([{'sci-fi', 'thriller'}, {'comedy'}]) 
    array([[0, 1, 1], 
           [1, 0, 0]]) 
    &gt;&gt;&gt; list(mlb.classes_) 
    ['comedy', 'sci-fi', 'thriller'] 
 
    A common mistake is to pass in a list, which leads to the following issue: 
 
    &gt;&gt;&gt; mlb = MultiLabelBinarizer() 
    &gt;&gt;&gt; mlb.fit(['sci-fi', 'thriller', 'comedy']) 
    MultiLabelBinarizer() 
    &gt;&gt;&gt; mlb.classes_ 
    array(['-', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'o', 'r', 's', 't', 
        'y'], dtype=object) 
 
    To correct this, the list of labels should be passed in as: 
 
    &gt;&gt;&gt; mlb = MultiLabelBinarizer() 
    &gt;&gt;&gt; mlb.fit([['sci-fi', 'thriller', 'comedy']]) 
    MultiLabelBinarizer() 
    &gt;&gt;&gt; mlb.classes_ 
    array(['comedy', 'sci-fi', 'thriller'], dtype=object) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints: dict = {</span>
        <span class="s3">&quot;classes&quot;</span><span class="s1">: [</span><span class="s3">&quot;array-like&quot;</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s3">&quot;sparse_output&quot;</span><span class="s1">: [</span><span class="s3">&quot;boolean&quot;</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">}</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">classes=</span><span class="s2">None, </span><span class="s1">sparse_output=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s1">self.classes = classes</span>
        <span class="s1">self.sparse_output = sparse_output</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit the label sets binarizer, storing :term:`classes_`. 
 
        Parameters 
        ---------- 
        y : iterable of iterables 
            A set of labels (any orderable and hashable object) for each 
            sample. If the `classes` parameter is set, `y` will not be 
            iterated. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._cached_dict = </span><span class="s2">None</span>

        <span class="s2">if </span><span class="s1">self.classes </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">classes = sorted(set(itertools.chain.from_iterable(y)))</span>
        <span class="s2">elif </span><span class="s1">len(set(self.classes)) &lt; len(self.classes):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;The classes argument contains duplicate &quot;</span>
                <span class="s3">&quot;classes. Remove these duplicates before passing &quot;</span>
                <span class="s3">&quot;them to MultiLabelBinarizer.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">classes = self.classes</span>
        <span class="s1">dtype = int </span><span class="s2">if </span><span class="s1">all(isinstance(c</span><span class="s2">, </span><span class="s1">int) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">classes) </span><span class="s2">else </span><span class="s1">object</span>
        <span class="s1">self.classes_ = np.empty(len(classes)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
        <span class="s1">self.classes_[:] = classes</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">fit_transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Fit the label sets binarizer and transform the given label sets. 
 
        Parameters 
        ---------- 
        y : iterable of iterables 
            A set of labels (any orderable and hashable object) for each 
            sample. If the `classes` parameter is set, `y` will not be 
            iterated. 
 
        Returns 
        ------- 
        y_indicator : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
            A matrix such that `y_indicator[i, j] = 1` iff `classes_[j]` 
            is in `y[i]`, and 0 otherwise. Sparse matrix will be of CSR 
            format. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.classes </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.fit(y).transform(y)</span>

        <span class="s1">self._cached_dict = </span><span class="s2">None</span>

        <span class="s0"># Automatically increment on new class</span>
        <span class="s1">class_mapping = defaultdict(int)</span>
        <span class="s1">class_mapping.default_factory = class_mapping.__len__</span>
        <span class="s1">yt = self._transform(y</span><span class="s2">, </span><span class="s1">class_mapping)</span>

        <span class="s0"># sort classes and reorder columns</span>
        <span class="s1">tmp = sorted(class_mapping</span><span class="s2">, </span><span class="s1">key=class_mapping.get)</span>

        <span class="s0"># (make safe for tuples)</span>
        <span class="s1">dtype = int </span><span class="s2">if </span><span class="s1">all(isinstance(c</span><span class="s2">, </span><span class="s1">int) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">tmp) </span><span class="s2">else </span><span class="s1">object</span>
        <span class="s1">class_mapping = np.empty(len(tmp)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
        <span class="s1">class_mapping[:] = tmp</span>
        <span class="s1">self.classes_</span><span class="s2">, </span><span class="s1">inverse = np.unique(class_mapping</span><span class="s2">, </span><span class="s1">return_inverse=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s0"># ensure yt.indices keeps its current dtype</span>
        <span class="s1">yt.indices = np.array(inverse[yt.indices]</span><span class="s2">, </span><span class="s1">dtype=yt.indices.dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">self.sparse_output:</span>
            <span class="s1">yt = yt.toarray()</span>

        <span class="s2">return </span><span class="s1">yt</span>

    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s4">&quot;&quot;&quot;Transform the given label sets. 
 
        Parameters 
        ---------- 
        y : iterable of iterables 
            A set of labels (any orderable and hashable object) for each 
            sample. If the `classes` parameter is set, `y` will not be 
            iterated. 
 
        Returns 
        ------- 
        y_indicator : array or CSR matrix, shape (n_samples, n_classes) 
            A matrix such that `y_indicator[i, j] = 1` iff `classes_[j]` is in 
            `y[i]`, and 0 otherwise. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s1">class_to_index = self._build_cache()</span>
        <span class="s1">yt = self._transform(y</span><span class="s2">, </span><span class="s1">class_to_index)</span>

        <span class="s2">if not </span><span class="s1">self.sparse_output:</span>
            <span class="s1">yt = yt.toarray()</span>

        <span class="s2">return </span><span class="s1">yt</span>

    <span class="s2">def </span><span class="s1">_build_cache(self):</span>
        <span class="s2">if </span><span class="s1">self._cached_dict </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._cached_dict = dict(zip(self.classes_</span><span class="s2">, </span><span class="s1">range(len(self.classes_))))</span>

        <span class="s2">return </span><span class="s1">self._cached_dict</span>

    <span class="s2">def </span><span class="s1">_transform(self</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">class_mapping):</span>
        <span class="s4">&quot;&quot;&quot;Transforms the label sets with a given mapping. 
 
        Parameters 
        ---------- 
        y : iterable of iterables 
            A set of labels (any orderable and hashable object) for each 
            sample. If the `classes` parameter is set, `y` will not be 
            iterated. 
 
        class_mapping : Mapping 
            Maps from label to column index in label indicator matrix. 
 
        Returns 
        ------- 
        y_indicator : sparse matrix of shape (n_samples, n_classes) 
            Label indicator matrix. Will be of CSR format. 
        &quot;&quot;&quot;</span>
        <span class="s1">indices = array.array(</span><span class="s3">&quot;i&quot;</span><span class="s1">)</span>
        <span class="s1">indptr = array.array(</span><span class="s3">&quot;i&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">unknown = set()</span>
        <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">y:</span>
            <span class="s1">index = set()</span>
            <span class="s2">for </span><span class="s1">label </span><span class="s2">in </span><span class="s1">labels:</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">index.add(class_mapping[label])</span>
                <span class="s2">except </span><span class="s1">KeyError:</span>
                    <span class="s1">unknown.add(label)</span>
            <span class="s1">indices.extend(index)</span>
            <span class="s1">indptr.append(len(indices))</span>
        <span class="s2">if </span><span class="s1">unknown:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;unknown class(es) {0} will be ignored&quot;</span><span class="s1">.format(sorted(unknown</span><span class="s2">, </span><span class="s1">key=str))</span>
            <span class="s1">)</span>
        <span class="s1">data = np.ones(len(indices)</span><span class="s2">, </span><span class="s1">dtype=int)</span>

        <span class="s2">return </span><span class="s1">sp.csr_matrix(</span>
            <span class="s1">(data</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">indptr)</span><span class="s2">, </span><span class="s1">shape=(len(indptr) - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">len(class_mapping))</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">inverse_transform(self</span><span class="s2">, </span><span class="s1">yt):</span>
        <span class="s4">&quot;&quot;&quot;Transform the given indicator matrix into label sets. 
 
        Parameters 
        ---------- 
        yt : {ndarray, sparse matrix} of shape (n_samples, n_classes) 
            A matrix containing only 1s ands 0s. 
 
        Returns 
        ------- 
        y : list of tuples 
            The set of labels for each sample such that `y[i]` consists of 
            `classes_[j]` for each `yt[i, j] == 1`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s2">if </span><span class="s1">yt.shape[</span><span class="s5">1</span><span class="s1">] != len(self.classes_):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Expected indicator for {0} classes, but got {1}&quot;</span><span class="s1">.format(</span>
                    <span class="s1">len(self.classes_)</span><span class="s2">, </span><span class="s1">yt.shape[</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">)</span>
            <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">sp.issparse(yt):</span>
            <span class="s1">yt = yt.tocsr()</span>
            <span class="s2">if </span><span class="s1">len(yt.data) != </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">len(np.setdiff1d(yt.data</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Expected only 0s and 1s in label indicator.&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">[</span>
                <span class="s1">tuple(self.classes_.take(yt.indices[start:end]))</span>
                <span class="s2">for </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end </span><span class="s2">in </span><span class="s1">zip(yt.indptr[:-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">yt.indptr[</span><span class="s5">1</span><span class="s1">:])</span>
            <span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">unexpected = np.setdiff1d(yt</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])</span>
            <span class="s2">if </span><span class="s1">len(unexpected) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;Expected only 0s and 1s in label indicator. Also got {0}&quot;</span><span class="s1">.format(</span>
                        <span class="s1">unexpected</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">[tuple(self.classes_.compress(indicators)) </span><span class="s2">for </span><span class="s1">indicators </span><span class="s2">in </span><span class="s1">yt]</span>

    <span class="s2">def </span><span class="s1">_more_tags(self):</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s3">&quot;X_types&quot;</span><span class="s1">: [</span><span class="s3">&quot;2dlabels&quot;</span><span class="s1">]}</span>
</pre>
</body>
</html>
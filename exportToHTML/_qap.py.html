<html>
<head>
<title>_qap.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_qap.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">operator</span>
<span class="s0">from </span><span class="s1">. </span><span class="s0">import </span><span class="s1">(linear_sum_assignment</span><span class="s0">, </span><span class="s1">OptimizeResult)</span>
<span class="s0">from </span><span class="s1">._optimize </span><span class="s0">import </span><span class="s1">_check_unknown_options</span>

<span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">check_random_state</span>
<span class="s0">import </span><span class="s1">itertools</span>

<span class="s1">QUADRATIC_ASSIGNMENT_METHODS = [</span><span class="s2">'faq'</span><span class="s0">, </span><span class="s2">'2opt'</span><span class="s1">]</span>

<span class="s0">def </span><span class="s1">quadratic_assignment(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;faq&quot;</span><span class="s0">, </span><span class="s1">options=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">r&quot;&quot;&quot; 
    Approximates solution to the quadratic assignment problem and 
    the graph matching problem. 
 
    Quadratic assignment solves problems of the following form: 
 
    .. math:: 
 
        \min_P &amp; \ {\ \text{trace}(A^T P B P^T)}\\ 
        \mbox{s.t. } &amp; {P \ \epsilon \ \mathcal{P}}\\ 
 
    where :math:`\mathcal{P}` is the set of all permutation matrices, 
    and :math:`A` and :math:`B` are square matrices. 
 
    Graph matching tries to *maximize* the same objective function. 
    This algorithm can be thought of as finding the alignment of the 
    nodes of two graphs that minimizes the number of induced edge 
    disagreements, or, in the case of weighted graphs, the sum of squared 
    edge weight differences. 
 
    Note that the quadratic assignment problem is NP-hard. The results given 
    here are approximations and are not guaranteed to be optimal. 
 
 
    Parameters 
    ---------- 
    A : 2-D array, square 
        The square matrix :math:`A` in the objective function above. 
 
    B : 2-D array, square 
        The square matrix :math:`B` in the objective function above. 
 
    method :  str in {'faq', '2opt'} (default: 'faq') 
        The algorithm used to solve the problem. 
        :ref:`'faq' &lt;optimize.qap-faq&gt;` (default) and 
        :ref:`'2opt' &lt;optimize.qap-2opt&gt;` are available. 
 
    options : dict, optional 
        A dictionary of solver options. All solvers support the following: 
 
        maximize : bool (default: False) 
            Maximizes the objective function if ``True``. 
 
        partial_match : 2-D array of integers, optional (default: None) 
            Fixes part of the matching. Also known as a &quot;seed&quot; [2]_. 
 
            Each row of `partial_match` specifies a pair of matched nodes: 
            node ``partial_match[i, 0]`` of `A` is matched to node 
            ``partial_match[i, 1]`` of `B`. The array has shape ``(m, 2)``, 
            where ``m`` is not greater than the number of nodes, :math:`n`. 
 
        rng : {None, int, `numpy.random.Generator`, 
               `numpy.random.RandomState`}, optional 
 
            If `seed` is None (or `np.random`), the `numpy.random.RandomState` 
            singleton is used. 
            If `seed` is an int, a new ``RandomState`` instance is used, 
            seeded with `seed`. 
            If `seed` is already a ``Generator`` or ``RandomState`` instance then 
            that instance is used. 
 
        For method-specific options, see 
        :func:`show_options('quadratic_assignment') &lt;show_options&gt;`. 
 
    Returns 
    ------- 
    res : OptimizeResult 
        `OptimizeResult` containing the following fields. 
 
        col_ind : 1-D array 
            Column indices corresponding to the best permutation found of the 
            nodes of `B`. 
        fun : float 
            The objective value of the solution. 
        nit : int 
            The number of iterations performed during optimization. 
 
    Notes 
    ----- 
    The default method :ref:`'faq' &lt;optimize.qap-faq&gt;` uses the Fast 
    Approximate QAP algorithm [1]_; it typically offers the best combination of 
    speed and accuracy. 
    Method :ref:`'2opt' &lt;optimize.qap-2opt&gt;` can be computationally expensive, 
    but may be a useful alternative, or it can be used to refine the solution 
    returned by another method. 
 
    References 
    ---------- 
    .. [1] J.T. Vogelstein, J.M. Conroy, V. Lyzinski, L.J. Podrazik, 
           S.G. Kratzer, E.T. Harley, D.E. Fishkind, R.J. Vogelstein, and 
           C.E. Priebe, &quot;Fast approximate quadratic programming for graph 
           matching,&quot; PLOS one, vol. 10, no. 4, p. e0121002, 2015, 
           :doi:`10.1371/journal.pone.0121002` 
 
    .. [2] D. Fishkind, S. Adali, H. Patsolic, L. Meng, D. Singh, V. Lyzinski, 
           C. Priebe, &quot;Seeded graph matching&quot;, Pattern Recognit. 87 (2019): 
           203-215, :doi:`10.1016/j.patcog.2018.09.014` 
 
    .. [3] &quot;2-opt,&quot; Wikipedia. 
           https://en.wikipedia.org/wiki/2-opt 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.optimize import quadratic_assignment 
    &gt;&gt;&gt; A = np.array([[0, 80, 150, 170], [80, 0, 130, 100], 
    ...               [150, 130, 0, 120], [170, 100, 120, 0]]) 
    &gt;&gt;&gt; B = np.array([[0, 5, 2, 7], [0, 0, 3, 8], 
    ...               [0, 0, 0, 3], [0, 0, 0, 0]]) 
    &gt;&gt;&gt; res = quadratic_assignment(A, B) 
    &gt;&gt;&gt; print(res) 
         fun: 3260 
     col_ind: [0 3 2 1] 
         nit: 9 
 
    The see the relationship between the returned ``col_ind`` and ``fun``, 
    use ``col_ind`` to form the best permutation matrix found, then evaluate 
    the objective function :math:`f(P) = trace(A^T P B P^T )`. 
 
    &gt;&gt;&gt; perm = res['col_ind'] 
    &gt;&gt;&gt; P = np.eye(len(A), dtype=int)[perm] 
    &gt;&gt;&gt; fun = np.trace(A.T @ P @ B @ P.T) 
    &gt;&gt;&gt; print(fun) 
    3260 
 
    Alternatively, to avoid constructing the permutation matrix explicitly, 
    directly permute the rows and columns of the distance matrix. 
 
    &gt;&gt;&gt; fun = np.trace(A.T @ B[perm][:, perm]) 
    &gt;&gt;&gt; print(fun) 
    3260 
 
    Although not guaranteed in general, ``quadratic_assignment`` happens to 
    have found the globally optimal solution. 
 
    &gt;&gt;&gt; from itertools import permutations 
    &gt;&gt;&gt; perm_opt, fun_opt = None, np.inf 
    &gt;&gt;&gt; for perm in permutations([0, 1, 2, 3]): 
    ...     perm = np.array(perm) 
    ...     fun = np.trace(A.T @ B[perm][:, perm]) 
    ...     if fun &lt; fun_opt: 
    ...         fun_opt, perm_opt = fun, perm 
    &gt;&gt;&gt; print(np.array_equal(perm_opt, res['col_ind'])) 
    True 
 
    Here is an example for which the default method, 
    :ref:`'faq' &lt;optimize.qap-faq&gt;`, does not find the global optimum. 
 
    &gt;&gt;&gt; A = np.array([[0, 5, 8, 6], [5, 0, 5, 1], 
    ...               [8, 5, 0, 2], [6, 1, 2, 0]]) 
    &gt;&gt;&gt; B = np.array([[0, 1, 8, 4], [1, 0, 5, 2], 
    ...               [8, 5, 0, 5], [4, 2, 5, 0]]) 
    &gt;&gt;&gt; res = quadratic_assignment(A, B) 
    &gt;&gt;&gt; print(res) 
         fun: 178 
     col_ind: [1 0 3 2] 
         nit: 13 
 
    If accuracy is important, consider using  :ref:`'2opt' &lt;optimize.qap-2opt&gt;` 
    to refine the solution. 
 
    &gt;&gt;&gt; guess = np.array([np.arange(len(A)), res.col_ind]).T 
    &gt;&gt;&gt; res = quadratic_assignment(A, B, method=&quot;2opt&quot;, 
    ...                            options = {'partial_guess': guess}) 
    &gt;&gt;&gt; print(res) 
         fun: 176 
     col_ind: [1 2 3 0] 
         nit: 17 
 
    &quot;&quot;&quot;</span>

    <span class="s0">if </span><span class="s1">options </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">options = {}</span>

    <span class="s1">method = method.lower()</span>
    <span class="s1">methods = {</span><span class="s2">&quot;faq&quot;</span><span class="s1">: _quadratic_assignment_faq</span><span class="s0">,</span>
               <span class="s2">&quot;2opt&quot;</span><span class="s1">: _quadratic_assignment_2opt}</span>
    <span class="s0">if </span><span class="s1">method </span><span class="s0">not in </span><span class="s1">methods:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">f&quot;method </span><span class="s0">{</span><span class="s1">method</span><span class="s0">} </span><span class="s2">must be in </span><span class="s0">{</span><span class="s1">methods</span><span class="s0">}</span><span class="s2">.&quot;</span><span class="s1">)</span>
    <span class="s1">res = methods[method](A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">**options)</span>
    <span class="s0">return </span><span class="s1">res</span>


<span class="s0">def </span><span class="s1">_calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">perm):</span>
    <span class="s4"># equivalent to objective function but avoids matmul</span>
    <span class="s0">return </span><span class="s1">np.sum(A * B[perm][:</span><span class="s0">, </span><span class="s1">perm])</span>


<span class="s0">def </span><span class="s1">_common_input_validation(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match):</span>
    <span class="s1">A = np.atleast_2d(A)</span>
    <span class="s1">B = np.atleast_2d(B)</span>

    <span class="s0">if </span><span class="s1">partial_match </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">partial_match = np.array([[]</span><span class="s0">, </span><span class="s1">[]]).T</span>
    <span class="s1">partial_match = np.atleast_2d(partial_match).astype(int)</span>

    <span class="s1">msg = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">A.shape[</span><span class="s5">0</span><span class="s1">] != A.shape[</span><span class="s5">1</span><span class="s1">]:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`A` must be square&quot;</span>
    <span class="s0">elif </span><span class="s1">B.shape[</span><span class="s5">0</span><span class="s1">] != B.shape[</span><span class="s5">1</span><span class="s1">]:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`B` must be square&quot;</span>
    <span class="s0">elif </span><span class="s1">A.ndim != </span><span class="s5">2 </span><span class="s0">or </span><span class="s1">B.ndim != </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`A` and `B` must have exactly two dimensions&quot;</span>
    <span class="s0">elif </span><span class="s1">A.shape != B.shape:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`A` and `B` matrices must be of equal size&quot;</span>
    <span class="s0">elif </span><span class="s1">partial_match.shape[</span><span class="s5">0</span><span class="s1">] &gt; A.shape[</span><span class="s5">0</span><span class="s1">]:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` can have only as many seeds as there are nodes&quot;</span>
    <span class="s0">elif </span><span class="s1">partial_match.shape[</span><span class="s5">1</span><span class="s1">] != </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` must have two columns&quot;</span>
    <span class="s0">elif </span><span class="s1">partial_match.ndim != </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` must have exactly two dimensions&quot;</span>
    <span class="s0">elif </span><span class="s1">(partial_match &lt; </span><span class="s5">0</span><span class="s1">).any():</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` must contain only positive indices&quot;</span>
    <span class="s0">elif </span><span class="s1">(partial_match &gt;= len(A)).any():</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` entries must be less than number of nodes&quot;</span>
    <span class="s0">elif </span><span class="s1">(</span><span class="s0">not </span><span class="s1">len(set(partial_match[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">])) == len(partial_match[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">]) </span><span class="s0">or</span>
          <span class="s0">not </span><span class="s1">len(set(partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])) == len(partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])):</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_match` column entries must be unique&quot;</span>

    <span class="s0">if </span><span class="s1">msg </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(msg)</span>

    <span class="s0">return </span><span class="s1">A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match</span>


<span class="s0">def </span><span class="s1">_quadratic_assignment_faq(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">,</span>
                              <span class="s1">maximize=</span><span class="s0">False, </span><span class="s1">partial_match=</span><span class="s0">None, </span><span class="s1">rng=</span><span class="s0">None,</span>
                              <span class="s1">P0=</span><span class="s2">&quot;barycenter&quot;</span><span class="s0">, </span><span class="s1">shuffle_input=</span><span class="s0">False, </span><span class="s1">maxiter=</span><span class="s5">30</span><span class="s0">,</span>
                              <span class="s1">tol=</span><span class="s5">0.03</span><span class="s0">, </span><span class="s1">**unknown_options):</span>
    <span class="s3">r&quot;&quot;&quot;Solve the quadratic assignment problem (approximately). 
 
    This function solves the Quadratic Assignment Problem (QAP) and the 
    Graph Matching Problem (GMP) using the Fast Approximate QAP Algorithm 
    (FAQ) [1]_. 
 
    Quadratic assignment solves problems of the following form: 
 
    .. math:: 
 
        \min_P &amp; \ {\ \text{trace}(A^T P B P^T)}\\ 
        \mbox{s.t. } &amp; {P \ \epsilon \ \mathcal{P}}\\ 
 
    where :math:`\mathcal{P}` is the set of all permutation matrices, 
    and :math:`A` and :math:`B` are square matrices. 
 
    Graph matching tries to *maximize* the same objective function. 
    This algorithm can be thought of as finding the alignment of the 
    nodes of two graphs that minimizes the number of induced edge 
    disagreements, or, in the case of weighted graphs, the sum of squared 
    edge weight differences. 
 
    Note that the quadratic assignment problem is NP-hard. The results given 
    here are approximations and are not guaranteed to be optimal. 
 
    Parameters 
    ---------- 
    A : 2-D array, square 
        The square matrix :math:`A` in the objective function above. 
    B : 2-D array, square 
        The square matrix :math:`B` in the objective function above. 
    method :  str in {'faq', '2opt'} (default: 'faq') 
        The algorithm used to solve the problem. This is the method-specific 
        documentation for 'faq'. 
        :ref:`'2opt' &lt;optimize.qap-2opt&gt;` is also available. 
 
    Options 
    ------- 
    maximize : bool (default: False) 
        Maximizes the objective function if ``True``. 
    partial_match : 2-D array of integers, optional (default: None) 
        Fixes part of the matching. Also known as a &quot;seed&quot; [2]_. 
 
        Each row of `partial_match` specifies a pair of matched nodes: 
        node ``partial_match[i, 0]`` of `A` is matched to node 
        ``partial_match[i, 1]`` of `B`. The array has shape ``(m, 2)``, where 
        ``m`` is not greater than the number of nodes, :math:`n`. 
 
    rng : {None, int, `numpy.random.Generator`, 
           `numpy.random.RandomState`}, optional 
 
        If `seed` is None (or `np.random`), the `numpy.random.RandomState` 
        singleton is used. 
        If `seed` is an int, a new ``RandomState`` instance is used, 
        seeded with `seed`. 
        If `seed` is already a ``Generator`` or ``RandomState`` instance then 
        that instance is used. 
    P0 : 2-D array, &quot;barycenter&quot;, or &quot;randomized&quot; (default: &quot;barycenter&quot;) 
        Initial position. Must be a doubly-stochastic matrix [3]_. 
 
        If the initial position is an array, it must be a doubly stochastic 
        matrix of size :math:`m' \times m'` where :math:`m' = n - m`. 
 
        If ``&quot;barycenter&quot;`` (default), the initial position is the barycenter 
        of the Birkhoff polytope (the space of doubly stochastic matrices). 
        This is a :math:`m' \times m'` matrix with all entries equal to 
        :math:`1 / m'`. 
 
        If ``&quot;randomized&quot;`` the initial search position is 
        :math:`P_0 = (J + K) / 2`, where :math:`J` is the barycenter and 
        :math:`K` is a random doubly stochastic matrix. 
    shuffle_input : bool (default: False) 
        Set to `True` to resolve degenerate gradients randomly. For 
        non-degenerate gradients this option has no effect. 
    maxiter : int, positive (default: 30) 
        Integer specifying the max number of Frank-Wolfe iterations performed. 
    tol : float (default: 0.03) 
        Tolerance for termination. Frank-Wolfe iteration terminates when 
        :math:`\frac{||P_{i}-P_{i+1}||_F}{\sqrt{m')}} \leq tol`, 
        where :math:`i` is the iteration number. 
 
    Returns 
    ------- 
    res : OptimizeResult 
        `OptimizeResult` containing the following fields. 
 
        col_ind : 1-D array 
            Column indices corresponding to the best permutation found of the 
            nodes of `B`. 
        fun : float 
            The objective value of the solution. 
        nit : int 
            The number of Frank-Wolfe iterations performed. 
 
    Notes 
    ----- 
    The algorithm may be sensitive to the initial permutation matrix (or 
    search &quot;position&quot;) due to the possibility of several local minima 
    within the feasible region. A barycenter initialization is more likely to 
    result in a better solution than a single random initialization. However, 
    calling ``quadratic_assignment`` several times with different random 
    initializations may result in a better optimum at the cost of longer 
    total execution time. 
 
    Examples 
    -------- 
    As mentioned above, a barycenter initialization often results in a better 
    solution than a single random initialization. 
 
    &gt;&gt;&gt; from numpy.random import default_rng 
    &gt;&gt;&gt; rng = default_rng() 
    &gt;&gt;&gt; n = 15 
    &gt;&gt;&gt; A = rng.random((n, n)) 
    &gt;&gt;&gt; B = rng.random((n, n)) 
    &gt;&gt;&gt; res = quadratic_assignment(A, B)  # FAQ is default method 
    &gt;&gt;&gt; print(res.fun) 
    46.871483385480545  # may vary 
 
    &gt;&gt;&gt; options = {&quot;P0&quot;: &quot;randomized&quot;}  # use randomized initialization 
    &gt;&gt;&gt; res = quadratic_assignment(A, B, options=options) 
    &gt;&gt;&gt; print(res.fun) 
    47.224831071310625 # may vary 
 
    However, consider running from several randomized initializations and 
    keeping the best result. 
 
    &gt;&gt;&gt; res = min([quadratic_assignment(A, B, options=options) 
    ...            for i in range(30)], key=lambda x: x.fun) 
    &gt;&gt;&gt; print(res.fun) 
    46.671852533681516 # may vary 
 
    The '2-opt' method can be used to further refine the results. 
 
    &gt;&gt;&gt; options = {&quot;partial_guess&quot;: np.array([np.arange(n), res.col_ind]).T} 
    &gt;&gt;&gt; res = quadratic_assignment(A, B, method=&quot;2opt&quot;, options=options) 
    &gt;&gt;&gt; print(res.fun) 
    46.47160735721583 # may vary 
 
    References 
    ---------- 
    .. [1] J.T. Vogelstein, J.M. Conroy, V. Lyzinski, L.J. Podrazik, 
           S.G. Kratzer, E.T. Harley, D.E. Fishkind, R.J. Vogelstein, and 
           C.E. Priebe, &quot;Fast approximate quadratic programming for graph 
           matching,&quot; PLOS one, vol. 10, no. 4, p. e0121002, 2015, 
           :doi:`10.1371/journal.pone.0121002` 
 
    .. [2] D. Fishkind, S. Adali, H. Patsolic, L. Meng, D. Singh, V. Lyzinski, 
           C. Priebe, &quot;Seeded graph matching&quot;, Pattern Recognit. 87 (2019): 
           203-215, :doi:`10.1016/j.patcog.2018.09.014` 
 
    .. [3] &quot;Doubly stochastic Matrix,&quot; Wikipedia. 
           https://en.wikipedia.org/wiki/Doubly_stochastic_matrix 
 
    &quot;&quot;&quot;</span>

    <span class="s1">_check_unknown_options(unknown_options)</span>

    <span class="s1">maxiter = operator.index(maxiter)</span>

    <span class="s4"># ValueError check</span>
    <span class="s1">A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match = _common_input_validation(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match)</span>

    <span class="s1">msg = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">isinstance(P0</span><span class="s0">, </span><span class="s1">str) </span><span class="s0">and </span><span class="s1">P0 </span><span class="s0">not in </span><span class="s1">{</span><span class="s2">'barycenter'</span><span class="s0">, </span><span class="s2">'randomized'</span><span class="s1">}:</span>
        <span class="s1">msg = </span><span class="s2">&quot;Invalid 'P0' parameter string&quot;</span>
    <span class="s0">elif </span><span class="s1">maxiter &lt;= </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;'maxiter' must be a positive integer&quot;</span>
    <span class="s0">elif </span><span class="s1">tol &lt;= </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;'tol' must be a positive float&quot;</span>
    <span class="s0">if </span><span class="s1">msg </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(msg)</span>

    <span class="s1">rng = check_random_state(rng)</span>
    <span class="s1">n = len(A)  </span><span class="s4"># number of vertices in graphs</span>
    <span class="s1">n_seeds = len(partial_match)  </span><span class="s4"># number of seeds</span>
    <span class="s1">n_unseed = n - n_seeds</span>

    <span class="s4"># [1] Algorithm 1 Line 1 - choose initialization</span>
    <span class="s0">if not </span><span class="s1">isinstance(P0</span><span class="s0">, </span><span class="s1">str):</span>
        <span class="s1">P0 = np.atleast_2d(P0)</span>
        <span class="s0">if </span><span class="s1">P0.shape != (n_unseed</span><span class="s0">, </span><span class="s1">n_unseed):</span>
            <span class="s1">msg = </span><span class="s2">&quot;`P0` matrix must have shape m' x m', where m'=n-m&quot;</span>
        <span class="s0">elif </span><span class="s1">((P0 &lt; </span><span class="s5">0</span><span class="s1">).any() </span><span class="s0">or not </span><span class="s1">np.allclose(np.sum(P0</span><span class="s0">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span><span class="s0">, </span><span class="s5">1</span><span class="s1">)</span>
              <span class="s0">or not </span><span class="s1">np.allclose(np.sum(P0</span><span class="s0">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span><span class="s0">, </span><span class="s5">1</span><span class="s1">)):</span>
            <span class="s1">msg = </span><span class="s2">&quot;`P0` matrix must be doubly stochastic&quot;</span>
        <span class="s0">if </span><span class="s1">msg </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(msg)</span>
    <span class="s0">elif </span><span class="s1">P0 == </span><span class="s2">'barycenter'</span><span class="s1">:</span>
        <span class="s1">P0 = np.ones((n_unseed</span><span class="s0">, </span><span class="s1">n_unseed)) / n_unseed</span>
    <span class="s0">elif </span><span class="s1">P0 == </span><span class="s2">'randomized'</span><span class="s1">:</span>
        <span class="s1">J = np.ones((n_unseed</span><span class="s0">, </span><span class="s1">n_unseed)) / n_unseed</span>
        <span class="s4"># generate a nxn matrix where each entry is a random number [0, 1]</span>
        <span class="s4"># would use rand, but Generators don't have it</span>
        <span class="s4"># would use random, but old mtrand.RandomStates don't have it</span>
        <span class="s1">K = _doubly_stochastic(rng.uniform(size=(n_unseed</span><span class="s0">, </span><span class="s1">n_unseed)))</span>
        <span class="s1">P0 = (J + K) / </span><span class="s5">2</span>

    <span class="s4"># check trivial cases</span>
    <span class="s0">if </span><span class="s1">n == </span><span class="s5">0 </span><span class="s0">or </span><span class="s1">n_seeds == n:</span>
        <span class="s1">score = _calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])</span>
        <span class="s1">res = {</span><span class="s2">&quot;col_ind&quot;</span><span class="s1">: partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s2">&quot;fun&quot;</span><span class="s1">: score</span><span class="s0">, </span><span class="s2">&quot;nit&quot;</span><span class="s1">: </span><span class="s5">0</span><span class="s1">}</span>
        <span class="s0">return </span><span class="s1">OptimizeResult(res)</span>

    <span class="s1">obj_func_scalar = </span><span class="s5">1</span>
    <span class="s0">if </span><span class="s1">maximize:</span>
        <span class="s1">obj_func_scalar = -</span><span class="s5">1</span>

    <span class="s1">nonseed_B = np.setdiff1d(range(n)</span><span class="s0">, </span><span class="s1">partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])</span>
    <span class="s0">if </span><span class="s1">shuffle_input:</span>
        <span class="s1">nonseed_B = rng.permutation(nonseed_B)</span>

    <span class="s1">nonseed_A = np.setdiff1d(range(n)</span><span class="s0">, </span><span class="s1">partial_match[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">perm_A = np.concatenate([partial_match[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">nonseed_A])</span>
    <span class="s1">perm_B = np.concatenate([partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">nonseed_B])</span>

    <span class="s4"># definitions according to Seeded Graph Matching [2].</span>
    <span class="s1">A11</span><span class="s0">, </span><span class="s1">A12</span><span class="s0">, </span><span class="s1">A21</span><span class="s0">, </span><span class="s1">A22 = _split_matrix(A[perm_A][:</span><span class="s0">, </span><span class="s1">perm_A]</span><span class="s0">, </span><span class="s1">n_seeds)</span>
    <span class="s1">B11</span><span class="s0">, </span><span class="s1">B12</span><span class="s0">, </span><span class="s1">B21</span><span class="s0">, </span><span class="s1">B22 = _split_matrix(B[perm_B][:</span><span class="s0">, </span><span class="s1">perm_B]</span><span class="s0">, </span><span class="s1">n_seeds)</span>
    <span class="s1">const_sum = A21 @ B21.T + A12.T @ B12</span>

    <span class="s1">P = P0</span>
    <span class="s4"># [1] Algorithm 1 Line 2 - loop while stopping criteria not met</span>
    <span class="s0">for </span><span class="s1">n_iter </span><span class="s0">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s0">, </span><span class="s1">maxiter+</span><span class="s5">1</span><span class="s1">):</span>
        <span class="s4"># [1] Algorithm 1 Line 3 - compute the gradient of f(P) = -tr(APB^tP^t)</span>
        <span class="s1">grad_fp = (const_sum + A22 @ P @ B22.T + A22.T @ P @ B22)</span>
        <span class="s4"># [1] Algorithm 1 Line 4 - get direction Q by solving Eq. 8</span>
        <span class="s1">_</span><span class="s0">, </span><span class="s1">cols = linear_sum_assignment(grad_fp</span><span class="s0">, </span><span class="s1">maximize=maximize)</span>
        <span class="s1">Q = np.eye(n_unseed)[cols]</span>

        <span class="s4"># [1] Algorithm 1 Line 5 - compute the step size</span>
        <span class="s4"># Noting that e.g. trace(Ax) = trace(A)*x, expand and re-collect</span>
        <span class="s4"># terms as ax**2 + bx + c. c does not affect location of minimum</span>
        <span class="s4"># and can be ignored. Also, note that trace(A@B) = (A.T*B).sum();</span>
        <span class="s4"># apply where possible for efficiency.</span>
        <span class="s1">R = P - Q</span>
        <span class="s1">b21 = ((R.T @ A21) * B21).sum()</span>
        <span class="s1">b12 = ((R.T @ A12.T) * B12.T).sum()</span>
        <span class="s1">AR22 = A22.T @ R</span>
        <span class="s1">BR22 = B22 @ R.T</span>
        <span class="s1">b22a = (AR22 * B22.T[cols]).sum()</span>
        <span class="s1">b22b = (A22 * BR22[cols]).sum()</span>
        <span class="s1">a = (AR22.T * BR22).sum()</span>
        <span class="s1">b = b21 + b12 + b22a + b22b</span>
        <span class="s4"># critical point of ax^2 + bx + c is at x = -d/(2*e)</span>
        <span class="s4"># if a * obj_func_scalar &gt; 0, it is a minimum</span>
        <span class="s4"># if minimum is not in [0, 1], only endpoints need to be considered</span>
        <span class="s0">if </span><span class="s1">a*obj_func_scalar &gt; </span><span class="s5">0 </span><span class="s0">and </span><span class="s5">0 </span><span class="s1">&lt;= -b/(</span><span class="s5">2</span><span class="s1">*a) &lt;= </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">alpha = -b/(</span><span class="s5">2</span><span class="s1">*a)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">alpha = np.argmin([</span><span class="s5">0</span><span class="s0">, </span><span class="s1">(b + a)*obj_func_scalar])</span>

        <span class="s4"># [1] Algorithm 1 Line 6 - Update P</span>
        <span class="s1">P_i1 = alpha * P + (</span><span class="s5">1 </span><span class="s1">- alpha) * Q</span>
        <span class="s0">if </span><span class="s1">np.linalg.norm(P - P_i1) / np.sqrt(n_unseed) &lt; tol:</span>
            <span class="s1">P = P_i1</span>
            <span class="s0">break</span>
        <span class="s1">P = P_i1</span>
    <span class="s4"># [1] Algorithm 1 Line 7 - end main loop</span>

    <span class="s4"># [1] Algorithm 1 Line 8 - project onto the set of permutation matrices</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">col = linear_sum_assignment(P</span><span class="s0">, </span><span class="s1">maximize=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">perm = np.concatenate((np.arange(n_seeds)</span><span class="s0">, </span><span class="s1">col + n_seeds))</span>

    <span class="s1">unshuffled_perm = np.zeros(n</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">unshuffled_perm[perm_A] = perm_B[perm]</span>

    <span class="s1">score = _calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">unshuffled_perm)</span>
    <span class="s1">res = {</span><span class="s2">&quot;col_ind&quot;</span><span class="s1">: unshuffled_perm</span><span class="s0">, </span><span class="s2">&quot;fun&quot;</span><span class="s1">: score</span><span class="s0">, </span><span class="s2">&quot;nit&quot;</span><span class="s1">: n_iter}</span>
    <span class="s0">return </span><span class="s1">OptimizeResult(res)</span>


<span class="s0">def </span><span class="s1">_split_matrix(X</span><span class="s0">, </span><span class="s1">n):</span>
    <span class="s4"># definitions according to Seeded Graph Matching [2].</span>
    <span class="s1">upper</span><span class="s0">, </span><span class="s1">lower = X[:n]</span><span class="s0">, </span><span class="s1">X[n:]</span>
    <span class="s0">return </span><span class="s1">upper[:</span><span class="s0">, </span><span class="s1">:n]</span><span class="s0">, </span><span class="s1">upper[:</span><span class="s0">, </span><span class="s1">n:]</span><span class="s0">, </span><span class="s1">lower[:</span><span class="s0">, </span><span class="s1">:n]</span><span class="s0">, </span><span class="s1">lower[:</span><span class="s0">, </span><span class="s1">n:]</span>


<span class="s0">def </span><span class="s1">_doubly_stochastic(P</span><span class="s0">, </span><span class="s1">tol=</span><span class="s5">1e-3</span><span class="s1">):</span>
    <span class="s4"># Adapted from @btaba implementation</span>
    <span class="s4"># https://github.com/btaba/sinkhorn_knopp</span>
    <span class="s4"># of Sinkhorn-Knopp algorithm</span>
    <span class="s4"># https://projecteuclid.org/euclid.pjm/1102992505</span>

    <span class="s1">max_iter = </span><span class="s5">1000</span>
    <span class="s1">c = </span><span class="s5">1 </span><span class="s1">/ P.sum(axis=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">r = </span><span class="s5">1 </span><span class="s1">/ (P @ c)</span>
    <span class="s1">P_eps = P</span>

    <span class="s0">for </span><span class="s1">it </span><span class="s0">in </span><span class="s1">range(max_iter):</span>
        <span class="s0">if </span><span class="s1">((np.abs(P_eps.sum(axis=</span><span class="s5">1</span><span class="s1">) - </span><span class="s5">1</span><span class="s1">) &lt; tol).all() </span><span class="s0">and</span>
                <span class="s1">(np.abs(P_eps.sum(axis=</span><span class="s5">0</span><span class="s1">) - </span><span class="s5">1</span><span class="s1">) &lt; tol).all()):</span>
            <span class="s4"># All column/row sums ~= 1 within threshold</span>
            <span class="s0">break</span>

        <span class="s1">c = </span><span class="s5">1 </span><span class="s1">/ (r @ P)</span>
        <span class="s1">r = </span><span class="s5">1 </span><span class="s1">/ (P @ c)</span>
        <span class="s1">P_eps = r[:</span><span class="s0">, None</span><span class="s1">] * P * c</span>

    <span class="s0">return </span><span class="s1">P_eps</span>


<span class="s0">def </span><span class="s1">_quadratic_assignment_2opt(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">maximize=</span><span class="s0">False, </span><span class="s1">rng=</span><span class="s0">None,</span>
                               <span class="s1">partial_match=</span><span class="s0">None,</span>
                               <span class="s1">partial_guess=</span><span class="s0">None,</span>
                               <span class="s1">**unknown_options):</span>
    <span class="s3">r&quot;&quot;&quot;Solve the quadratic assignment problem (approximately). 
 
    This function solves the Quadratic Assignment Problem (QAP) and the 
    Graph Matching Problem (GMP) using the 2-opt algorithm [1]_. 
 
    Quadratic assignment solves problems of the following form: 
 
    .. math:: 
 
        \min_P &amp; \ {\ \text{trace}(A^T P B P^T)}\\ 
        \mbox{s.t. } &amp; {P \ \epsilon \ \mathcal{P}}\\ 
 
    where :math:`\mathcal{P}` is the set of all permutation matrices, 
    and :math:`A` and :math:`B` are square matrices. 
 
    Graph matching tries to *maximize* the same objective function. 
    This algorithm can be thought of as finding the alignment of the 
    nodes of two graphs that minimizes the number of induced edge 
    disagreements, or, in the case of weighted graphs, the sum of squared 
    edge weight differences. 
 
    Note that the quadratic assignment problem is NP-hard. The results given 
    here are approximations and are not guaranteed to be optimal. 
 
    Parameters 
    ---------- 
    A : 2-D array, square 
        The square matrix :math:`A` in the objective function above. 
    B : 2-D array, square 
        The square matrix :math:`B` in the objective function above. 
    method :  str in {'faq', '2opt'} (default: 'faq') 
        The algorithm used to solve the problem. This is the method-specific 
        documentation for '2opt'. 
        :ref:`'faq' &lt;optimize.qap-faq&gt;` is also available. 
 
    Options 
    ------- 
    maximize : bool (default: False) 
        Maximizes the objective function if ``True``. 
    rng : {None, int, `numpy.random.Generator`, 
           `numpy.random.RandomState`}, optional 
 
        If `seed` is None (or `np.random`), the `numpy.random.RandomState` 
        singleton is used. 
        If `seed` is an int, a new ``RandomState`` instance is used, 
        seeded with `seed`. 
        If `seed` is already a ``Generator`` or ``RandomState`` instance then 
        that instance is used. 
    partial_match : 2-D array of integers, optional (default: None) 
        Fixes part of the matching. Also known as a &quot;seed&quot; [2]_. 
 
        Each row of `partial_match` specifies a pair of matched nodes: node 
        ``partial_match[i, 0]`` of `A` is matched to node 
        ``partial_match[i, 1]`` of `B`. The array has shape ``(m, 2)``, 
        where ``m`` is not greater than the number of nodes, :math:`n`. 
    partial_guess : 2-D array of integers, optional (default: None) 
        A guess for the matching between the two matrices. Unlike 
        `partial_match`, `partial_guess` does not fix the indices; they are 
        still free to be optimized. 
 
        Each row of `partial_guess` specifies a pair of matched nodes: node 
        ``partial_guess[i, 0]`` of `A` is matched to node 
        ``partial_guess[i, 1]`` of `B`. The array has shape ``(m, 2)``, 
        where ``m`` is not greater than the number of nodes, :math:`n`. 
 
    Returns 
    ------- 
    res : OptimizeResult 
        `OptimizeResult` containing the following fields. 
 
        col_ind : 1-D array 
            Column indices corresponding to the best permutation found of the 
            nodes of `B`. 
        fun : float 
            The objective value of the solution. 
        nit : int 
            The number of iterations performed during optimization. 
 
    Notes 
    ----- 
    This is a greedy algorithm that works similarly to bubble sort: beginning 
    with an initial permutation, it iteratively swaps pairs of indices to 
    improve the objective function until no such improvements are possible. 
 
    References 
    ---------- 
    .. [1] &quot;2-opt,&quot; Wikipedia. 
           https://en.wikipedia.org/wiki/2-opt 
 
    .. [2] D. Fishkind, S. Adali, H. Patsolic, L. Meng, D. Singh, V. Lyzinski, 
           C. Priebe, &quot;Seeded graph matching&quot;, Pattern Recognit. 87 (2019): 
           203-215, https://doi.org/10.1016/j.patcog.2018.09.014 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_check_unknown_options(unknown_options)</span>
    <span class="s1">rng = check_random_state(rng)</span>
    <span class="s1">A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match = _common_input_validation(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match)</span>

    <span class="s1">N = len(A)</span>
    <span class="s4"># check trivial cases</span>
    <span class="s0">if </span><span class="s1">N == </span><span class="s5">0 </span><span class="s0">or </span><span class="s1">partial_match.shape[</span><span class="s5">0</span><span class="s1">] == N:</span>
        <span class="s1">score = _calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])</span>
        <span class="s1">res = {</span><span class="s2">&quot;col_ind&quot;</span><span class="s1">: partial_match[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s2">&quot;fun&quot;</span><span class="s1">: score</span><span class="s0">, </span><span class="s2">&quot;nit&quot;</span><span class="s1">: </span><span class="s5">0</span><span class="s1">}</span>
        <span class="s0">return </span><span class="s1">OptimizeResult(res)</span>

    <span class="s0">if </span><span class="s1">partial_guess </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">partial_guess = np.array([[]</span><span class="s0">, </span><span class="s1">[]]).T</span>
    <span class="s1">partial_guess = np.atleast_2d(partial_guess).astype(int)</span>

    <span class="s1">msg = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">partial_guess.shape[</span><span class="s5">0</span><span class="s1">] &gt; A.shape[</span><span class="s5">0</span><span class="s1">]:</span>
        <span class="s1">msg = (</span><span class="s2">&quot;`partial_guess` can have only as &quot;</span>
               <span class="s2">&quot;many entries as there are nodes&quot;</span><span class="s1">)</span>
    <span class="s0">elif </span><span class="s1">partial_guess.shape[</span><span class="s5">1</span><span class="s1">] != </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_guess` must have two columns&quot;</span>
    <span class="s0">elif </span><span class="s1">partial_guess.ndim != </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_guess` must have exactly two dimensions&quot;</span>
    <span class="s0">elif </span><span class="s1">(partial_guess &lt; </span><span class="s5">0</span><span class="s1">).any():</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_guess` must contain only positive indices&quot;</span>
    <span class="s0">elif </span><span class="s1">(partial_guess &gt;= len(A)).any():</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_guess` entries must be less than number of nodes&quot;</span>
    <span class="s0">elif </span><span class="s1">(</span><span class="s0">not </span><span class="s1">len(set(partial_guess[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">])) == len(partial_guess[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">]) </span><span class="s0">or</span>
          <span class="s0">not </span><span class="s1">len(set(partial_guess[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])) == len(partial_guess[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])):</span>
        <span class="s1">msg = </span><span class="s2">&quot;`partial_guess` column entries must be unique&quot;</span>
    <span class="s0">if </span><span class="s1">msg </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(msg)</span>

    <span class="s1">fixed_rows = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">partial_match.size </span><span class="s0">or </span><span class="s1">partial_guess.size:</span>
        <span class="s4"># use partial_match and partial_guess for initial permutation,</span>
        <span class="s4"># but randomly permute the rest.</span>
        <span class="s1">guess_rows = np.zeros(N</span><span class="s0">, </span><span class="s1">dtype=bool)</span>
        <span class="s1">guess_cols = np.zeros(N</span><span class="s0">, </span><span class="s1">dtype=bool)</span>
        <span class="s1">fixed_rows = np.zeros(N</span><span class="s0">, </span><span class="s1">dtype=bool)</span>
        <span class="s1">fixed_cols = np.zeros(N</span><span class="s0">, </span><span class="s1">dtype=bool)</span>
        <span class="s1">perm = np.zeros(N</span><span class="s0">, </span><span class="s1">dtype=int)</span>

        <span class="s1">rg</span><span class="s0">, </span><span class="s1">cg = partial_guess.T</span>
        <span class="s1">guess_rows[rg] = </span><span class="s0">True</span>
        <span class="s1">guess_cols[cg] = </span><span class="s0">True</span>
        <span class="s1">perm[guess_rows] = cg</span>

        <span class="s4"># match overrides guess</span>
        <span class="s1">rf</span><span class="s0">, </span><span class="s1">cf = partial_match.T</span>
        <span class="s1">fixed_rows[rf] = </span><span class="s0">True</span>
        <span class="s1">fixed_cols[cf] = </span><span class="s0">True</span>
        <span class="s1">perm[fixed_rows] = cf</span>

        <span class="s1">random_rows = ~fixed_rows &amp; ~guess_rows</span>
        <span class="s1">random_cols = ~fixed_cols &amp; ~guess_cols</span>
        <span class="s1">perm[random_rows] = rng.permutation(np.arange(N)[random_cols])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">perm = rng.permutation(np.arange(N))</span>

    <span class="s1">best_score = _calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">perm)</span>

    <span class="s1">i_free = np.arange(N)</span>
    <span class="s0">if </span><span class="s1">fixed_rows </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">i_free = i_free[~fixed_rows]</span>

    <span class="s1">better = operator.gt </span><span class="s0">if </span><span class="s1">maximize </span><span class="s0">else </span><span class="s1">operator.lt</span>
    <span class="s1">n_iter = </span><span class="s5">0</span>
    <span class="s1">done = </span><span class="s0">False</span>
    <span class="s0">while not </span><span class="s1">done:</span>
        <span class="s4"># equivalent to nested for loops i in range(N), j in range(i, N)</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">j </span><span class="s0">in </span><span class="s1">itertools.combinations_with_replacement(i_free</span><span class="s0">, </span><span class="s5">2</span><span class="s1">):</span>
            <span class="s1">n_iter += </span><span class="s5">1</span>
            <span class="s1">perm[i]</span><span class="s0">, </span><span class="s1">perm[j] = perm[j]</span><span class="s0">, </span><span class="s1">perm[i]</span>
            <span class="s1">score = _calc_score(A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">perm)</span>
            <span class="s0">if </span><span class="s1">better(score</span><span class="s0">, </span><span class="s1">best_score):</span>
                <span class="s1">best_score = score</span>
                <span class="s0">break</span>
            <span class="s4"># faster to swap back than to create a new list every time</span>
            <span class="s1">perm[i]</span><span class="s0">, </span><span class="s1">perm[j] = perm[j]</span><span class="s0">, </span><span class="s1">perm[i]</span>
        <span class="s0">else</span><span class="s1">:  </span><span class="s4"># no swaps made</span>
            <span class="s1">done = </span><span class="s0">True</span>

    <span class="s1">res = {</span><span class="s2">&quot;col_ind&quot;</span><span class="s1">: perm</span><span class="s0">, </span><span class="s2">&quot;fun&quot;</span><span class="s1">: best_score</span><span class="s0">, </span><span class="s2">&quot;nit&quot;</span><span class="s1">: n_iter}</span>
    <span class="s0">return </span><span class="s1">OptimizeResult(res)</span>
</pre>
</body>
</html>
<html>
<head>
<title>_minpack_py.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_minpack_py.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">. </span><span class="s0">import </span><span class="s1">_minpack</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy </span><span class="s0">import </span><span class="s1">(atleast_1d</span><span class="s0">, </span><span class="s1">triu</span><span class="s0">, </span><span class="s1">shape</span><span class="s0">, </span><span class="s1">transpose</span><span class="s0">, </span><span class="s1">zeros</span><span class="s0">, </span><span class="s1">prod</span><span class="s0">, </span><span class="s1">greater</span><span class="s0">,</span>
                   <span class="s1">asarray</span><span class="s0">, </span><span class="s1">inf</span><span class="s0">,</span>
                   <span class="s1">finfo</span><span class="s0">, </span><span class="s1">inexact</span><span class="s0">, </span><span class="s1">issubdtype</span><span class="s0">, </span><span class="s1">dtype)</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">linalg</span>
<span class="s0">from </span><span class="s1">scipy.linalg </span><span class="s0">import </span><span class="s1">svd</span><span class="s0">, </span><span class="s1">cholesky</span><span class="s0">, </span><span class="s1">solve_triangular</span><span class="s0">, </span><span class="s1">LinAlgError</span>
<span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">_asarray_validated</span><span class="s0">, </span><span class="s1">_lazywhere</span><span class="s0">, </span><span class="s1">_contains_nan</span>
<span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">getfullargspec_no_self </span><span class="s0">as </span><span class="s1">_getfullargspec</span>
<span class="s0">from </span><span class="s1">._optimize </span><span class="s0">import </span><span class="s1">OptimizeResult</span><span class="s0">, </span><span class="s1">_check_unknown_options</span><span class="s0">, </span><span class="s1">OptimizeWarning</span>
<span class="s0">from </span><span class="s1">._lsq </span><span class="s0">import </span><span class="s1">least_squares</span>
<span class="s2"># from ._lsq.common import make_strictly_feasible</span>
<span class="s0">from </span><span class="s1">._lsq.least_squares </span><span class="s0">import </span><span class="s1">prepare_bounds</span>
<span class="s0">from </span><span class="s1">scipy.optimize._minimize </span><span class="s0">import </span><span class="s1">Bounds</span>

<span class="s1">error = _minpack.error</span>

<span class="s1">__all__ = [</span><span class="s3">'fsolve'</span><span class="s0">, </span><span class="s3">'leastsq'</span><span class="s0">, </span><span class="s3">'fixed_point'</span><span class="s0">, </span><span class="s3">'curve_fit'</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">_check_func(checker</span><span class="s0">, </span><span class="s1">argname</span><span class="s0">, </span><span class="s1">thefunc</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">numinputs</span><span class="s0">,</span>
                <span class="s1">output_shape=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s1">res = atleast_1d(thefunc(*((x0[:numinputs]</span><span class="s0">,</span><span class="s1">) + args)))</span>
    <span class="s0">if </span><span class="s1">(output_shape </span><span class="s0">is not None</span><span class="s1">) </span><span class="s0">and </span><span class="s1">(shape(res) != output_shape):</span>
        <span class="s0">if </span><span class="s1">(output_shape[</span><span class="s4">0</span><span class="s1">] != </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s0">if </span><span class="s1">len(output_shape) &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">output_shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s0">return </span><span class="s1">shape(res)</span>
            <span class="s1">msg = </span><span class="s3">&quot;{}: there is a mismatch between the input and output &quot; </span><span class="s1">\</span>
                  <span class="s3">&quot;shape of the '{}' argument&quot;</span><span class="s1">.format(checker</span><span class="s0">, </span><span class="s1">argname)</span>
            <span class="s1">func_name = getattr(thefunc</span><span class="s0">, </span><span class="s3">'__name__'</span><span class="s0">, None</span><span class="s1">)</span>
            <span class="s0">if </span><span class="s1">func_name:</span>
                <span class="s1">msg += </span><span class="s3">&quot; '%s'.&quot; </span><span class="s1">% func_name</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">msg += </span><span class="s3">&quot;.&quot;</span>
            <span class="s1">msg += </span><span class="s3">f'Shape should be </span><span class="s0">{</span><span class="s1">output_shape</span><span class="s0">} </span><span class="s3">but it is </span><span class="s0">{</span><span class="s1">shape(res)</span><span class="s0">}</span><span class="s3">.'</span>
            <span class="s0">raise </span><span class="s1">TypeError(msg)</span>
    <span class="s0">if </span><span class="s1">issubdtype(res.dtype</span><span class="s0">, </span><span class="s1">inexact):</span>
        <span class="s1">dt = res.dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = dtype(float)</span>
    <span class="s0">return </span><span class="s1">shape(res)</span><span class="s0">, </span><span class="s1">dt</span>


<span class="s0">def </span><span class="s1">fsolve(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args=()</span><span class="s0">, </span><span class="s1">fprime=</span><span class="s0">None, </span><span class="s1">full_output=</span><span class="s4">0</span><span class="s0">,</span>
           <span class="s1">col_deriv=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">xtol=</span><span class="s4">1.49012e-8</span><span class="s0">, </span><span class="s1">maxfev=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">band=</span><span class="s0">None,</span>
           <span class="s1">epsfcn=</span><span class="s0">None, </span><span class="s1">factor=</span><span class="s4">100</span><span class="s0">, </span><span class="s1">diag=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Find the roots of a function. 
 
    Return the roots of the (non-linear) equations defined by 
    ``func(x) = 0`` given a starting estimate. 
 
    Parameters 
    ---------- 
    func : callable ``f(x, *args)`` 
        A function that takes at least one (possibly vector) argument, 
        and returns a value of the same length. 
    x0 : ndarray 
        The starting estimate for the roots of ``func(x) = 0``. 
    args : tuple, optional 
        Any extra arguments to `func`. 
    fprime : callable ``f(x, *args)``, optional 
        A function to compute the Jacobian of `func` with derivatives 
        across the rows. By default, the Jacobian will be estimated. 
    full_output : bool, optional 
        If True, return optional outputs. 
    col_deriv : bool, optional 
        Specify whether the Jacobian function computes derivatives down 
        the columns (faster, because there is no transpose operation). 
    xtol : float, optional 
        The calculation will terminate if the relative error between two 
        consecutive iterates is at most `xtol`. 
    maxfev : int, optional 
        The maximum number of calls to the function. If zero, then 
        ``100*(N+1)`` is the maximum where N is the number of elements 
        in `x0`. 
    band : tuple, optional 
        If set to a two-sequence containing the number of sub- and 
        super-diagonals within the band of the Jacobi matrix, the 
        Jacobi matrix is considered banded (only for ``fprime=None``). 
    epsfcn : float, optional 
        A suitable step length for the forward-difference 
        approximation of the Jacobian (for ``fprime=None``). If 
        `epsfcn` is less than the machine precision, it is assumed 
        that the relative errors in the functions are of the order of 
        the machine precision. 
    factor : float, optional 
        A parameter determining the initial step bound 
        (``factor * || diag * x||``). Should be in the interval 
        ``(0.1, 100)``. 
    diag : sequence, optional 
        N positive entries that serve as a scale factors for the 
        variables. 
 
    Returns 
    ------- 
    x : ndarray 
        The solution (or the result of the last iteration for 
        an unsuccessful call). 
    infodict : dict 
        A dictionary of optional outputs with the keys: 
 
        ``nfev`` 
            number of function calls 
        ``njev`` 
            number of Jacobian calls 
        ``fvec`` 
            function evaluated at the output 
        ``fjac`` 
            the orthogonal matrix, q, produced by the QR 
            factorization of the final approximate Jacobian 
            matrix, stored column wise 
        ``r`` 
            upper triangular matrix produced by QR factorization 
            of the same matrix 
        ``qtf`` 
            the vector ``(transpose(q) * fvec)`` 
 
    ier : int 
        An integer flag.  Set to 1 if a solution was found, otherwise refer 
        to `mesg` for more information. 
    mesg : str 
        If no solution is found, `mesg` details the cause of failure. 
 
    See Also 
    -------- 
    root : Interface to root finding algorithms for multivariate 
           functions. See the ``method='hybr'`` in particular. 
 
    Notes 
    ----- 
    ``fsolve`` is a wrapper around MINPACK's hybrd and hybrj algorithms. 
 
    Examples 
    -------- 
    Find a solution to the system of equations: 
    ``x0*cos(x1) = 4,  x1*x0 - x1 = 5``. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.optimize import fsolve 
    &gt;&gt;&gt; def func(x): 
    ...     return [x[0] * np.cos(x[1]) - 4, 
    ...             x[1] * x[0] - x[1] - 5] 
    &gt;&gt;&gt; root = fsolve(func, [1, 1]) 
    &gt;&gt;&gt; root 
    array([6.50409711, 0.90841421]) 
    &gt;&gt;&gt; np.isclose(func(root), [0.0, 0.0])  # func(root) should be almost 0.0. 
    array([ True,  True]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">options = {</span><span class="s3">'col_deriv'</span><span class="s1">: col_deriv</span><span class="s0">,</span>
               <span class="s3">'xtol'</span><span class="s1">: xtol</span><span class="s0">,</span>
               <span class="s3">'maxfev'</span><span class="s1">: maxfev</span><span class="s0">,</span>
               <span class="s3">'band'</span><span class="s1">: band</span><span class="s0">,</span>
               <span class="s3">'eps'</span><span class="s1">: epsfcn</span><span class="s0">,</span>
               <span class="s3">'factor'</span><span class="s1">: factor</span><span class="s0">,</span>
               <span class="s3">'diag'</span><span class="s1">: diag}</span>

    <span class="s1">res = _root_hybr(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">jac=fprime</span><span class="s0">, </span><span class="s1">**options)</span>
    <span class="s0">if </span><span class="s1">full_output:</span>
        <span class="s1">x = res[</span><span class="s3">'x'</span><span class="s1">]</span>
        <span class="s1">info = {k: res.get(k)</span>
                    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">(</span><span class="s3">'nfev'</span><span class="s0">, </span><span class="s3">'njev'</span><span class="s0">, </span><span class="s3">'fjac'</span><span class="s0">, </span><span class="s3">'r'</span><span class="s0">, </span><span class="s3">'qtf'</span><span class="s1">) </span><span class="s0">if </span><span class="s1">k </span><span class="s0">in </span><span class="s1">res}</span>
        <span class="s1">info[</span><span class="s3">'fvec'</span><span class="s1">] = res[</span><span class="s3">'fun'</span><span class="s1">]</span>
        <span class="s0">return </span><span class="s1">x</span><span class="s0">, </span><span class="s1">info</span><span class="s0">, </span><span class="s1">res[</span><span class="s3">'status'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">res[</span><span class="s3">'message'</span><span class="s1">]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">status = res[</span><span class="s3">'status'</span><span class="s1">]</span>
        <span class="s1">msg = res[</span><span class="s3">'message'</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s1">status == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">TypeError(msg)</span>
        <span class="s0">elif </span><span class="s1">status == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s0">pass</span>
        <span class="s0">elif </span><span class="s1">status </span><span class="s0">in </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">5</span><span class="s1">]:</span>
            <span class="s1">warnings.warn(msg</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">TypeError(msg)</span>
        <span class="s0">return </span><span class="s1">res[</span><span class="s3">'x'</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">_root_hybr(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args=()</span><span class="s0">, </span><span class="s1">jac=</span><span class="s0">None,</span>
               <span class="s1">col_deriv=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">xtol=</span><span class="s4">1.49012e-08</span><span class="s0">, </span><span class="s1">maxfev=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">band=</span><span class="s0">None, </span><span class="s1">eps=</span><span class="s0">None,</span>
               <span class="s1">factor=</span><span class="s4">100</span><span class="s0">, </span><span class="s1">diag=</span><span class="s0">None, </span><span class="s1">**unknown_options):</span>
    <span class="s5">&quot;&quot;&quot; 
    Find the roots of a multivariate function using MINPACK's hybrd and 
    hybrj routines (modified Powell method). 
 
    Options 
    ------- 
    col_deriv : bool 
        Specify whether the Jacobian function computes derivatives down 
        the columns (faster, because there is no transpose operation). 
    xtol : float 
        The calculation will terminate if the relative error between two 
        consecutive iterates is at most `xtol`. 
    maxfev : int 
        The maximum number of calls to the function. If zero, then 
        ``100*(N+1)`` is the maximum where N is the number of elements 
        in `x0`. 
    band : tuple 
        If set to a two-sequence containing the number of sub- and 
        super-diagonals within the band of the Jacobi matrix, the 
        Jacobi matrix is considered banded (only for ``fprime=None``). 
    eps : float 
        A suitable step length for the forward-difference 
        approximation of the Jacobian (for ``fprime=None``). If 
        `eps` is less than the machine precision, it is assumed 
        that the relative errors in the functions are of the order of 
        the machine precision. 
    factor : float 
        A parameter determining the initial step bound 
        (``factor * || diag * x||``). Should be in the interval 
        ``(0.1, 100)``. 
    diag : sequence 
        N positive entries that serve as a scale factors for the 
        variables. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_check_unknown_options(unknown_options)</span>
    <span class="s1">epsfcn = eps</span>

    <span class="s1">x0 = asarray(x0).flatten()</span>
    <span class="s1">n = len(x0)</span>
    <span class="s0">if not </span><span class="s1">isinstance(args</span><span class="s0">, </span><span class="s1">tuple):</span>
        <span class="s1">args = (args</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s1">shape</span><span class="s0">, </span><span class="s1">dtype = _check_func(</span><span class="s3">'fsolve'</span><span class="s0">, </span><span class="s3">'func'</span><span class="s0">, </span><span class="s1">func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">(n</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s0">if </span><span class="s1">epsfcn </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">epsfcn = finfo(dtype).eps</span>
    <span class="s1">Dfun = jac</span>
    <span class="s0">if </span><span class="s1">Dfun </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">band </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">ml</span><span class="s0">, </span><span class="s1">mu = -</span><span class="s4">10</span><span class="s0">, </span><span class="s1">-</span><span class="s4">10</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">ml</span><span class="s0">, </span><span class="s1">mu = band[:</span><span class="s4">2</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s1">maxfev == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">maxfev = </span><span class="s4">200 </span><span class="s1">* (n + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">retval = _minpack._hybrd(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">maxfev</span><span class="s0">,</span>
                                 <span class="s1">ml</span><span class="s0">, </span><span class="s1">mu</span><span class="s0">, </span><span class="s1">epsfcn</span><span class="s0">, </span><span class="s1">factor</span><span class="s0">, </span><span class="s1">diag)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">_check_func(</span><span class="s3">'fsolve'</span><span class="s0">, </span><span class="s3">'fprime'</span><span class="s0">, </span><span class="s1">Dfun</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">(n</span><span class="s0">, </span><span class="s1">n))</span>
        <span class="s0">if </span><span class="s1">(maxfev == </span><span class="s4">0</span><span class="s1">):</span>
            <span class="s1">maxfev = </span><span class="s4">100 </span><span class="s1">* (n + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">retval = _minpack._hybrj(func</span><span class="s0">, </span><span class="s1">Dfun</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s4">1</span><span class="s0">,</span>
                                 <span class="s1">col_deriv</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">maxfev</span><span class="s0">, </span><span class="s1">factor</span><span class="s0">, </span><span class="s1">diag)</span>

    <span class="s1">x</span><span class="s0">, </span><span class="s1">status = retval[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">retval[-</span><span class="s4">1</span><span class="s1">]</span>

    <span class="s1">errors = {</span><span class="s4">0</span><span class="s1">: </span><span class="s3">&quot;Improper input parameters were entered.&quot;</span><span class="s0">,</span>
              <span class="s4">1</span><span class="s1">: </span><span class="s3">&quot;The solution converged.&quot;</span><span class="s0">,</span>
              <span class="s4">2</span><span class="s1">: </span><span class="s3">&quot;The number of calls to function has &quot;</span>
                  <span class="s3">&quot;reached maxfev = %d.&quot; </span><span class="s1">% maxfev</span><span class="s0">,</span>
              <span class="s4">3</span><span class="s1">: </span><span class="s3">&quot;xtol=%f is too small, no further improvement &quot;</span>
                  <span class="s3">&quot;in the approximate</span><span class="s0">\n  </span><span class="s3">solution &quot;</span>
                  <span class="s3">&quot;is possible.&quot; </span><span class="s1">% xtol</span><span class="s0">,</span>
              <span class="s4">4</span><span class="s1">: </span><span class="s3">&quot;The iteration is not making good progress, as measured &quot;</span>
                  <span class="s3">&quot;by the </span><span class="s0">\n  </span><span class="s3">improvement from the last five &quot;</span>
                  <span class="s3">&quot;Jacobian evaluations.&quot;</span><span class="s0">,</span>
              <span class="s4">5</span><span class="s1">: </span><span class="s3">&quot;The iteration is not making good progress, &quot;</span>
                  <span class="s3">&quot;as measured by the </span><span class="s0">\n  </span><span class="s3">improvement from the last &quot;</span>
                  <span class="s3">&quot;ten iterations.&quot;</span><span class="s0">,</span>
              <span class="s3">'unknown'</span><span class="s1">: </span><span class="s3">&quot;An error occurred.&quot;</span><span class="s1">}</span>

    <span class="s1">info = retval[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">info[</span><span class="s3">'fun'</span><span class="s1">] = info.pop(</span><span class="s3">'fvec'</span><span class="s1">)</span>
    <span class="s1">sol = OptimizeResult(x=x</span><span class="s0">, </span><span class="s1">success=(status == </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">status=status)</span>
    <span class="s1">sol.update(info)</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">sol[</span><span class="s3">'message'</span><span class="s1">] = errors[status]</span>
    <span class="s0">except </span><span class="s1">KeyError:</span>
        <span class="s1">sol[</span><span class="s3">'message'</span><span class="s1">] = errors[</span><span class="s3">'unknown'</span><span class="s1">]</span>

    <span class="s0">return </span><span class="s1">sol</span>


<span class="s1">LEASTSQ_SUCCESS = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]</span>
<span class="s1">LEASTSQ_FAILURE = [</span><span class="s4">5</span><span class="s0">, </span><span class="s4">6</span><span class="s0">, </span><span class="s4">7</span><span class="s0">, </span><span class="s4">8</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">leastsq(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args=()</span><span class="s0">, </span><span class="s1">Dfun=</span><span class="s0">None, </span><span class="s1">full_output=</span><span class="s0">False,</span>
            <span class="s1">col_deriv=</span><span class="s0">False, </span><span class="s1">ftol=</span><span class="s4">1.49012e-8</span><span class="s0">, </span><span class="s1">xtol=</span><span class="s4">1.49012e-8</span><span class="s0">,</span>
            <span class="s1">gtol=</span><span class="s4">0.0</span><span class="s0">, </span><span class="s1">maxfev=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">epsfcn=</span><span class="s0">None, </span><span class="s1">factor=</span><span class="s4">100</span><span class="s0">, </span><span class="s1">diag=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Minimize the sum of squares of a set of equations. 
 
    :: 
 
        x = arg min(sum(func(y)**2,axis=0)) 
                 y 
 
    Parameters 
    ---------- 
    func : callable 
        Should take at least one (possibly length ``N`` vector) argument and 
        returns ``M`` floating point numbers. It must not return NaNs or 
        fitting might fail. ``M`` must be greater than or equal to ``N``. 
    x0 : ndarray 
        The starting estimate for the minimization. 
    args : tuple, optional 
        Any extra arguments to func are placed in this tuple. 
    Dfun : callable, optional 
        A function or method to compute the Jacobian of func with derivatives 
        across the rows. If this is None, the Jacobian will be estimated. 
    full_output : bool, optional 
        If ``True``, return all optional outputs (not just `x` and `ier`). 
    col_deriv : bool, optional 
        If ``True``, specify that the Jacobian function computes derivatives 
        down the columns (faster, because there is no transpose operation). 
    ftol : float, optional 
        Relative error desired in the sum of squares. 
    xtol : float, optional 
        Relative error desired in the approximate solution. 
    gtol : float, optional 
        Orthogonality desired between the function vector and the columns of 
        the Jacobian. 
    maxfev : int, optional 
        The maximum number of calls to the function. If `Dfun` is provided, 
        then the default `maxfev` is 100*(N+1) where N is the number of elements 
        in x0, otherwise the default `maxfev` is 200*(N+1). 
    epsfcn : float, optional 
        A variable used in determining a suitable step length for the forward- 
        difference approximation of the Jacobian (for Dfun=None). 
        Normally the actual step length will be sqrt(epsfcn)*x 
        If epsfcn is less than the machine precision, it is assumed that the 
        relative errors are of the order of the machine precision. 
    factor : float, optional 
        A parameter determining the initial step bound 
        (``factor * || diag * x||``). Should be in interval ``(0.1, 100)``. 
    diag : sequence, optional 
        N positive entries that serve as a scale factors for the variables. 
 
    Returns 
    ------- 
    x : ndarray 
        The solution (or the result of the last iteration for an unsuccessful 
        call). 
    cov_x : ndarray 
        The inverse of the Hessian. `fjac` and `ipvt` are used to construct an 
        estimate of the Hessian. A value of None indicates a singular matrix, 
        which means the curvature in parameters `x` is numerically flat. To 
        obtain the covariance matrix of the parameters `x`, `cov_x` must be 
        multiplied by the variance of the residuals -- see curve_fit. Only 
        returned if `full_output` is ``True``. 
    infodict : dict 
        a dictionary of optional outputs with the keys: 
 
        ``nfev`` 
            The number of function calls 
        ``fvec`` 
            The function evaluated at the output 
        ``fjac`` 
            A permutation of the R matrix of a QR 
            factorization of the final approximate 
            Jacobian matrix, stored column wise. 
            Together with ipvt, the covariance of the 
            estimate can be approximated. 
        ``ipvt`` 
            An integer array of length N which defines 
            a permutation matrix, p, such that 
            fjac*p = q*r, where r is upper triangular 
            with diagonal elements of nonincreasing 
            magnitude. Column j of p is column ipvt(j) 
            of the identity matrix. 
        ``qtf`` 
            The vector (transpose(q) * fvec). 
 
        Only returned if `full_output` is ``True``. 
    mesg : str 
        A string message giving information about the cause of failure. 
        Only returned if `full_output` is ``True``. 
    ier : int 
        An integer flag. If it is equal to 1, 2, 3 or 4, the solution was 
        found. Otherwise, the solution was not found. In either case, the 
        optional output variable 'mesg' gives more information. 
 
    See Also 
    -------- 
    least_squares : Newer interface to solve nonlinear least-squares problems 
        with bounds on the variables. See ``method='lm'`` in particular. 
 
    Notes 
    ----- 
    &quot;leastsq&quot; is a wrapper around MINPACK's lmdif and lmder algorithms. 
 
    cov_x is a Jacobian approximation to the Hessian of the least squares 
    objective function. 
    This approximation assumes that the objective function is based on the 
    difference between some observed target data (ydata) and a (non-linear) 
    function of the parameters `f(xdata, params)` :: 
 
           func(params) = ydata - f(xdata, params) 
 
    so that the objective function is :: 
 
           min   sum((ydata - f(xdata, params))**2, axis=0) 
         params 
 
    The solution, `x`, is always a 1-D array, regardless of the shape of `x0`, 
    or whether `x0` is a scalar. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from scipy.optimize import leastsq 
    &gt;&gt;&gt; def func(x): 
    ...     return 2*(x-3)**2+1 
    &gt;&gt;&gt; leastsq(func, 0) 
    (array([2.99999999]), 1) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">x0 = asarray(x0).flatten()</span>
    <span class="s1">n = len(x0)</span>
    <span class="s0">if not </span><span class="s1">isinstance(args</span><span class="s0">, </span><span class="s1">tuple):</span>
        <span class="s1">args = (args</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s1">shape</span><span class="s0">, </span><span class="s1">dtype = _check_func(</span><span class="s3">'leastsq'</span><span class="s0">, </span><span class="s3">'func'</span><span class="s0">, </span><span class="s1">func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s1">m = shape[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">n &gt; m:</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s3">f&quot;Improper input: func input vector length N=</span><span class="s0">{</span><span class="s1">n</span><span class="s0">} </span><span class="s3">must&quot;</span>
                        <span class="s3">f&quot; not exceed func output vector length M=</span><span class="s0">{</span><span class="s1">m</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">epsfcn </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">epsfcn = finfo(dtype).eps</span>

    <span class="s0">if </span><span class="s1">Dfun </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">maxfev == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">maxfev = </span><span class="s4">200</span><span class="s1">*(n + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">retval = _minpack._lmdif(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">full_output</span><span class="s0">, </span><span class="s1">ftol</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">,</span>
                                 <span class="s1">gtol</span><span class="s0">, </span><span class="s1">maxfev</span><span class="s0">, </span><span class="s1">epsfcn</span><span class="s0">, </span><span class="s1">factor</span><span class="s0">, </span><span class="s1">diag)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">col_deriv:</span>
            <span class="s1">_check_func(</span><span class="s3">'leastsq'</span><span class="s0">, </span><span class="s3">'Dfun'</span><span class="s0">, </span><span class="s1">Dfun</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">(n</span><span class="s0">, </span><span class="s1">m))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">_check_func(</span><span class="s3">'leastsq'</span><span class="s0">, </span><span class="s3">'Dfun'</span><span class="s0">, </span><span class="s1">Dfun</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">(m</span><span class="s0">, </span><span class="s1">n))</span>
        <span class="s0">if </span><span class="s1">maxfev == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">maxfev = </span><span class="s4">100 </span><span class="s1">* (n + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">retval = _minpack._lmder(func</span><span class="s0">, </span><span class="s1">Dfun</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">full_output</span><span class="s0">,</span>
                                 <span class="s1">col_deriv</span><span class="s0">, </span><span class="s1">ftol</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">gtol</span><span class="s0">, </span><span class="s1">maxfev</span><span class="s0">,</span>
                                 <span class="s1">factor</span><span class="s0">, </span><span class="s1">diag)</span>

    <span class="s1">errors = {</span><span class="s4">0</span><span class="s1">: [</span><span class="s3">&quot;Improper input parameters.&quot;</span><span class="s0">, </span><span class="s1">TypeError]</span><span class="s0">,</span>
              <span class="s4">1</span><span class="s1">: [</span><span class="s3">&quot;Both actual and predicted relative reductions &quot;</span>
                  <span class="s3">&quot;in the sum of squares</span><span class="s0">\n  </span><span class="s3">are at most %f&quot; </span><span class="s1">% ftol</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">,</span>
              <span class="s4">2</span><span class="s1">: [</span><span class="s3">&quot;The relative error between two consecutive &quot;</span>
                  <span class="s3">&quot;iterates is at most %f&quot; </span><span class="s1">% xtol</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">,</span>
              <span class="s4">3</span><span class="s1">: [</span><span class="s3">&quot;Both actual and predicted relative reductions in &quot;</span>
                  <span class="s3">&quot;the sum of squares</span><span class="s0">\n  </span><span class="s3">are at most {:f} and the &quot;</span>
                  <span class="s3">&quot;relative error between two consecutive &quot;</span>
                  <span class="s3">&quot;iterates is at </span><span class="s0">\n  </span><span class="s3">most {:f}&quot;</span><span class="s1">.format(ftol</span><span class="s0">, </span><span class="s1">xtol)</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">,</span>
              <span class="s4">4</span><span class="s1">: [</span><span class="s3">&quot;The cosine of the angle between func(x) and any &quot;</span>
                  <span class="s3">&quot;column of the</span><span class="s0">\n  </span><span class="s3">Jacobian is at most %f in &quot;</span>
                  <span class="s3">&quot;absolute value&quot; </span><span class="s1">% gtol</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">,</span>
              <span class="s4">5</span><span class="s1">: [</span><span class="s3">&quot;Number of calls to function has reached &quot;</span>
                  <span class="s3">&quot;maxfev = %d.&quot; </span><span class="s1">% maxfev</span><span class="s0">, </span><span class="s1">ValueError]</span><span class="s0">,</span>
              <span class="s4">6</span><span class="s1">: [</span><span class="s3">&quot;ftol=%f is too small, no further reduction &quot;</span>
                  <span class="s3">&quot;in the sum of squares</span><span class="s0">\n  </span><span class="s3">is possible.&quot; </span><span class="s1">% ftol</span><span class="s0">,</span>
                  <span class="s1">ValueError]</span><span class="s0">,</span>
              <span class="s4">7</span><span class="s1">: [</span><span class="s3">&quot;xtol=%f is too small, no further improvement in &quot;</span>
                  <span class="s3">&quot;the approximate</span><span class="s0">\n  </span><span class="s3">solution is possible.&quot; </span><span class="s1">% xtol</span><span class="s0">,</span>
                  <span class="s1">ValueError]</span><span class="s0">,</span>
              <span class="s4">8</span><span class="s1">: [</span><span class="s3">&quot;gtol=%f is too small, func(x) is orthogonal to the &quot;</span>
                  <span class="s3">&quot;columns of</span><span class="s0">\n  </span><span class="s3">the Jacobian to machine &quot;</span>
                  <span class="s3">&quot;precision.&quot; </span><span class="s1">% gtol</span><span class="s0">, </span><span class="s1">ValueError]}</span>

    <span class="s2"># The FORTRAN return value (possible return values are &gt;= 0 and &lt;= 8)</span>
    <span class="s1">info = retval[-</span><span class="s4">1</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">full_output:</span>
        <span class="s1">cov_x = </span><span class="s0">None</span>
        <span class="s0">if </span><span class="s1">info </span><span class="s0">in </span><span class="s1">LEASTSQ_SUCCESS:</span>
            <span class="s2"># This was</span>
            <span class="s2"># perm = take(eye(n), retval[1]['ipvt'] - 1, 0)</span>
            <span class="s2"># r = triu(transpose(retval[1]['fjac'])[:n, :])</span>
            <span class="s2"># R = dot(r, perm)</span>
            <span class="s2"># cov_x = inv(dot(transpose(R), R))</span>
            <span class="s2"># but the explicit dot product was not necessary and sometimes</span>
            <span class="s2"># the result was not symmetric positive definite. See gh-4555.</span>
            <span class="s1">perm = retval[</span><span class="s4">1</span><span class="s1">][</span><span class="s3">'ipvt'</span><span class="s1">] - </span><span class="s4">1</span>
            <span class="s1">n = len(perm)</span>
            <span class="s1">r = triu(transpose(retval[</span><span class="s4">1</span><span class="s1">][</span><span class="s3">'fjac'</span><span class="s1">])[:n</span><span class="s0">, </span><span class="s1">:])</span>
            <span class="s1">inv_triu = linalg.get_lapack_funcs(</span><span class="s3">'trtri'</span><span class="s0">, </span><span class="s1">(r</span><span class="s0">,</span><span class="s1">))</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s2"># inverse of permuted matrix is a permuation of matrix inverse</span>
                <span class="s1">invR</span><span class="s0">, </span><span class="s1">trtri_info = inv_triu(r)  </span><span class="s2"># default: upper, non-unit diag</span>
                <span class="s0">if </span><span class="s1">trtri_info != </span><span class="s4">0</span><span class="s1">:  </span><span class="s2"># explicit comparison for readability</span>
                    <span class="s0">raise </span><span class="s1">LinAlgError(</span><span class="s3">f'trtri returned info </span><span class="s0">{</span><span class="s1">trtri_info</span><span class="s0">}</span><span class="s3">'</span><span class="s1">)</span>
                <span class="s1">invR[perm] = invR.copy()</span>
                <span class="s1">cov_x = invR @ invR.T</span>
            <span class="s0">except </span><span class="s1">(LinAlgError</span><span class="s0">, </span><span class="s1">ValueError):</span>
                <span class="s0">pass</span>
        <span class="s0">return </span><span class="s1">(retval[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">cov_x) + retval[</span><span class="s4">1</span><span class="s1">:-</span><span class="s4">1</span><span class="s1">] + (errors[info][</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">info)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">info </span><span class="s0">in </span><span class="s1">LEASTSQ_FAILURE:</span>
            <span class="s1">warnings.warn(errors[info][</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
        <span class="s0">elif </span><span class="s1">info == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">errors[info][</span><span class="s4">1</span><span class="s1">](errors[info][</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s0">return </span><span class="s1">retval[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">info</span>


<span class="s0">def </span><span class="s1">_lightweight_memoizer(f):</span>
    <span class="s2"># very shallow memoization - only remember the first set of parameters</span>
    <span class="s2"># and corresponding function value to address gh-13670</span>
    <span class="s0">def </span><span class="s1">_memoized_func(params):</span>
        <span class="s0">if </span><span class="s1">np.all(_memoized_func.last_params == params):</span>
            <span class="s0">return </span><span class="s1">_memoized_func.last_val</span>

        <span class="s1">val = f(params)</span>

        <span class="s0">if </span><span class="s1">_memoized_func.last_params </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">_memoized_func.last_params = np.copy(params)</span>
            <span class="s1">_memoized_func.last_val = val</span>

        <span class="s0">return </span><span class="s1">val</span>

    <span class="s1">_memoized_func.last_params = </span><span class="s0">None</span>
    <span class="s1">_memoized_func.last_val = </span><span class="s0">None</span>
    <span class="s0">return </span><span class="s1">_memoized_func</span>


<span class="s0">def </span><span class="s1">_wrap_func(func</span><span class="s0">, </span><span class="s1">xdata</span><span class="s0">, </span><span class="s1">ydata</span><span class="s0">, </span><span class="s1">transform):</span>
    <span class="s0">if </span><span class="s1">transform </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">def </span><span class="s1">func_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">func(xdata</span><span class="s0">, </span><span class="s1">*params) - ydata</span>
    <span class="s0">elif </span><span class="s1">transform.ndim == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s0">def </span><span class="s1">func_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">transform * (func(xdata</span><span class="s0">, </span><span class="s1">*params) - ydata)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s2"># Chisq = (y - yd)^T C^{-1} (y-yd)</span>
        <span class="s2"># transform = L such that C = L L^T</span>
        <span class="s2"># C^{-1} = L^{-T} L^{-1}</span>
        <span class="s2"># Chisq = (y - yd)^T L^{-T} L^{-1} (y-yd)</span>
        <span class="s2"># Define (y-yd)' = L^{-1} (y-yd)</span>
        <span class="s2"># by solving</span>
        <span class="s2"># L (y-yd)' = (y-yd)</span>
        <span class="s2"># and minimize (y-yd)'^T (y-yd)'</span>
        <span class="s0">def </span><span class="s1">func_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">solve_triangular(transform</span><span class="s0">, </span><span class="s1">func(xdata</span><span class="s0">, </span><span class="s1">*params) - ydata</span><span class="s0">, </span><span class="s1">lower=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">func_wrapped</span>


<span class="s0">def </span><span class="s1">_wrap_jac(jac</span><span class="s0">, </span><span class="s1">xdata</span><span class="s0">, </span><span class="s1">transform):</span>
    <span class="s0">if </span><span class="s1">transform </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">def </span><span class="s1">jac_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">jac(xdata</span><span class="s0">, </span><span class="s1">*params)</span>
    <span class="s0">elif </span><span class="s1">transform.ndim == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s0">def </span><span class="s1">jac_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">transform[:</span><span class="s0">, </span><span class="s1">np.newaxis] * np.asarray(jac(xdata</span><span class="s0">, </span><span class="s1">*params))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">def </span><span class="s1">jac_wrapped(params):</span>
            <span class="s0">return </span><span class="s1">solve_triangular(transform</span><span class="s0">, </span><span class="s1">np.asarray(jac(xdata</span><span class="s0">, </span><span class="s1">*params))</span><span class="s0">, </span><span class="s1">lower=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">jac_wrapped</span>


<span class="s0">def </span><span class="s1">_initialize_feasible(lb</span><span class="s0">, </span><span class="s1">ub):</span>
    <span class="s1">p0 = np.ones_like(lb)</span>
    <span class="s1">lb_finite = np.isfinite(lb)</span>
    <span class="s1">ub_finite = np.isfinite(ub)</span>

    <span class="s1">mask = lb_finite &amp; ub_finite</span>
    <span class="s1">p0[mask] = </span><span class="s4">0.5 </span><span class="s1">* (lb[mask] + ub[mask])</span>

    <span class="s1">mask = lb_finite &amp; ~ub_finite</span>
    <span class="s1">p0[mask] = lb[mask] + </span><span class="s4">1</span>

    <span class="s1">mask = ~lb_finite &amp; ub_finite</span>
    <span class="s1">p0[mask] = ub[mask] - </span><span class="s4">1</span>

    <span class="s0">return </span><span class="s1">p0</span>


<span class="s0">def </span><span class="s1">curve_fit(f</span><span class="s0">, </span><span class="s1">xdata</span><span class="s0">, </span><span class="s1">ydata</span><span class="s0">, </span><span class="s1">p0=</span><span class="s0">None, </span><span class="s1">sigma=</span><span class="s0">None, </span><span class="s1">absolute_sigma=</span><span class="s0">False,</span>
              <span class="s1">check_finite=</span><span class="s0">None, </span><span class="s1">bounds=(-np.inf</span><span class="s0">, </span><span class="s1">np.inf)</span><span class="s0">, </span><span class="s1">method=</span><span class="s0">None,</span>
              <span class="s1">jac=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">full_output=</span><span class="s0">False, </span><span class="s1">nan_policy=</span><span class="s0">None,</span>
              <span class="s1">**kwargs):</span>
    <span class="s3">&quot;&quot;&quot; 
    Use non-linear least squares to fit a function, f, to data. 
 
    Assumes ``ydata = f(xdata, *params) + eps``. 
 
    Parameters 
    ---------- 
    f : callable 
        The model function, f(x, ...). It must take the independent 
        variable as the first argument and the parameters to fit as 
        separate remaining arguments. 
    xdata : array_like 
        The independent variable where the data is measured. 
        Should usually be an M-length sequence or an (k,M)-shaped array for 
        functions with k predictors, and each element should be float 
        convertible if it is an array like object. 
    ydata : array_like 
        The dependent data, a length M array - nominally ``f(xdata, ...)``. 
    p0 : array_like, optional 
        Initial guess for the parameters (length N). If None, then the 
        initial values will all be 1 (if the number of parameters for the 
        function can be determined using introspection, otherwise a 
        ValueError is raised). 
    sigma : None or M-length sequence or MxM array, optional 
        Determines the uncertainty in `ydata`. If we define residuals as 
        ``r = ydata - f(xdata, *popt)``, then the interpretation of `sigma` 
        depends on its number of dimensions: 
 
            - A 1-D `sigma` should contain values of standard deviations of 
              errors in `ydata`. In this case, the optimized function is 
              ``chisq = sum((r / sigma) ** 2)``. 
 
            - A 2-D `sigma` should contain the covariance matrix of 
              errors in `ydata`. In this case, the optimized function is 
              ``chisq = r.T @ inv(sigma) @ r``. 
 
              .. versionadded:: 0.19 
 
        None (default) is equivalent of 1-D `sigma` filled with ones. 
    absolute_sigma : bool, optional 
        If True, `sigma` is used in an absolute sense and the estimated parameter 
        covariance `pcov` reflects these absolute values. 
 
        If False (default), only the relative magnitudes of the `sigma` values matter. 
        The returned parameter covariance matrix `pcov` is based on scaling 
        `sigma` by a constant factor. This constant is set by demanding that the 
        reduced `chisq` for the optimal parameters `popt` when using the 
        *scaled* `sigma` equals unity. In other words, `sigma` is scaled to 
        match the sample variance of the residuals after the fit. Default is False. 
        Mathematically, 
        ``pcov(absolute_sigma=False) = pcov(absolute_sigma=True) * chisq(popt)/(M-N)`` 
    check_finite : bool, optional 
        If True, check that the input arrays do not contain nans of infs, 
        and raise a ValueError if they do. Setting this parameter to 
        False may silently produce nonsensical results if the input arrays 
        do contain nans. Default is True if `nan_policy` is not specified 
        explicitly and False otherwise. 
    bounds : 2-tuple of array_like or `Bounds`, optional 
        Lower and upper bounds on parameters. Defaults to no bounds. 
        There are two ways to specify the bounds: 
 
            - Instance of `Bounds` class. 
 
            - 2-tuple of array_like: Each element of the tuple must be either 
              an array with the length equal to the number of parameters, or a 
              scalar (in which case the bound is taken to be the same for all 
              parameters). Use ``np.inf`` with an appropriate sign to disable 
              bounds on all or some parameters. 
 
    method : {'lm', 'trf', 'dogbox'}, optional 
        Method to use for optimization. See `least_squares` for more details. 
        Default is 'lm' for unconstrained problems and 'trf' if `bounds` are 
        provided. The method 'lm' won't work when the number of observations 
        is less than the number of variables, use 'trf' or 'dogbox' in this 
        case. 
 
        .. versionadded:: 0.17 
    jac : callable, string or None, optional 
        Function with signature ``jac(x, ...)`` which computes the Jacobian 
        matrix of the model function with respect to parameters as a dense 
        array_like structure. It will be scaled according to provided `sigma`. 
        If None (default), the Jacobian will be estimated numerically. 
        String keywords for 'trf' and 'dogbox' methods can be used to select 
        a finite difference scheme, see `least_squares`. 
 
        .. versionadded:: 0.18 
    full_output : boolean, optional 
        If True, this function returns additioal information: `infodict`, 
        `mesg`, and `ier`. 
 
        .. versionadded:: 1.9 
    nan_policy : {'raise', 'omit', None}, optional 
        Defines how to handle when input contains nan. 
        The following options are available (default is None): 
 
          * 'raise': throws an error 
          * 'omit': performs the calculations ignoring nan values 
          * None: no special handling of NaNs is performed 
            (except what is done by check_finite); the behavior when NaNs 
            are present is implementation-dependent and may change. 
 
        Note that if this value is specified explicitly (not None), 
        `check_finite` will be set as False. 
 
        .. versionadded:: 1.11 
    **kwargs 
        Keyword arguments passed to `leastsq` for ``method='lm'`` or 
        `least_squares` otherwise. 
 
    Returns 
    ------- 
    popt : array 
        Optimal values for the parameters so that the sum of the squared 
        residuals of ``f(xdata, *popt) - ydata`` is minimized. 
    pcov : 2-D array 
        The estimated approximate covariance of popt. The diagonals provide 
        the variance of the parameter estimate. To compute one standard 
        deviation errors on the parameters, use 
        ``perr = np.sqrt(np.diag(pcov))``. Note that the relationship between 
        `cov` and parameter error estimates is derived based on a linear 
        approximation to the model function around the optimum [1]. 
        When this approximation becomes inaccurate, `cov` may not provide an 
        accurate measure of uncertainty. 
 
        How the `sigma` parameter affects the estimated covariance 
        depends on `absolute_sigma` argument, as described above. 
 
        If the Jacobian matrix at the solution doesn't have a full rank, then 
        'lm' method returns a matrix filled with ``np.inf``, on the other hand 
        'trf'  and 'dogbox' methods use Moore-Penrose pseudoinverse to compute 
        the covariance matrix. Covariance matrices with large condition numbers 
        (e.g. computed with `numpy.linalg.cond`) may indicate that results are 
        unreliable. 
    infodict : dict (returned only if `full_output` is True) 
        a dictionary of optional outputs with the keys: 
 
        ``nfev`` 
            The number of function calls. Methods 'trf' and 'dogbox' do not 
            count function calls for numerical Jacobian approximation, 
            as opposed to 'lm' method. 
        ``fvec`` 
            The residual values evaluated at the solution, for a 1-D `sigma` 
            this is ``(f(x, *popt) - ydata)/sigma``. 
        ``fjac`` 
            A permutation of the R matrix of a QR 
            factorization of the final approximate 
            Jacobian matrix, stored column wise. 
            Together with ipvt, the covariance of the 
            estimate can be approximated. 
            Method 'lm' only provides this information. 
        ``ipvt`` 
            An integer array of length N which defines 
            a permutation matrix, p, such that 
            fjac*p = q*r, where r is upper triangular 
            with diagonal elements of nonincreasing 
            magnitude. Column j of p is column ipvt(j) 
            of the identity matrix. 
            Method 'lm' only provides this information. 
        ``qtf`` 
            The vector (transpose(q) * fvec). 
            Method 'lm' only provides this information. 
 
        .. versionadded:: 1.9 
    mesg : str (returned only if `full_output` is True) 
        A string message giving information about the solution. 
 
        .. versionadded:: 1.9 
    ier : int (returnned only if `full_output` is True) 
        An integer flag. If it is equal to 1, 2, 3 or 4, the solution was 
        found. Otherwise, the solution was not found. In either case, the 
        optional output variable `mesg` gives more information. 
 
        .. versionadded:: 1.9 
 
    Raises 
    ------ 
    ValueError 
        if either `ydata` or `xdata` contain NaNs, or if incompatible options 
        are used. 
 
    RuntimeError 
        if the least-squares minimization fails. 
 
    OptimizeWarning 
        if covariance of the parameters can not be estimated. 
 
    See Also 
    -------- 
    least_squares : Minimize the sum of squares of nonlinear functions. 
    scipy.stats.linregress : Calculate a linear least squares regression for 
                             two sets of measurements. 
 
    Notes 
    ----- 
    Users should ensure that inputs `xdata`, `ydata`, and the output of `f` 
    are ``float64``, or else the optimization may return incorrect results. 
 
    With ``method='lm'``, the algorithm uses the Levenberg-Marquardt algorithm 
    through `leastsq`. Note that this algorithm can only deal with 
    unconstrained problems. 
 
    Box constraints can be handled by methods 'trf' and 'dogbox'. Refer to 
    the docstring of `least_squares` for more information. 
 
    References 
    ---------- 
    [1] K. Vugrin et al. Confidence region estimation techniques for nonlinear 
        regression in groundwater flow: Three case studies. Water Resources 
        Research, Vol. 43, W03423, :doi:`10.1029/2005WR004804` 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.optimize import curve_fit 
 
    &gt;&gt;&gt; def func(x, a, b, c): 
    ...     return a * np.exp(-b * x) + c 
 
    Define the data to be fit with some noise: 
 
    &gt;&gt;&gt; xdata = np.linspace(0, 4, 50) 
    &gt;&gt;&gt; y = func(xdata, 2.5, 1.3, 0.5) 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; y_noise = 0.2 * rng.normal(size=xdata.size) 
    &gt;&gt;&gt; ydata = y + y_noise 
    &gt;&gt;&gt; plt.plot(xdata, ydata, 'b-', label='data') 
 
    Fit for the parameters a, b, c of the function `func`: 
 
    &gt;&gt;&gt; popt, pcov = curve_fit(func, xdata, ydata) 
    &gt;&gt;&gt; popt 
    array([2.56274217, 1.37268521, 0.47427475]) 
    &gt;&gt;&gt; plt.plot(xdata, func(xdata, *popt), 'r-', 
    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt)) 
 
    Constrain the optimization to the region of ``0 &lt;= a &lt;= 3``, 
    ``0 &lt;= b &lt;= 1`` and ``0 &lt;= c &lt;= 0.5``: 
 
    &gt;&gt;&gt; popt, pcov = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5])) 
    &gt;&gt;&gt; popt 
    array([2.43736712, 1.        , 0.34463856]) 
    &gt;&gt;&gt; plt.plot(xdata, func(xdata, *popt), 'g--', 
    ...          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt)) 
 
    &gt;&gt;&gt; plt.xlabel('x') 
    &gt;&gt;&gt; plt.ylabel('y') 
    &gt;&gt;&gt; plt.legend() 
    &gt;&gt;&gt; plt.show() 
 
    For reliable results, the model `func` should not be overparametrized; 
    redundant parameters can cause unreliable covariance matrices and, in some 
    cases, poorer quality fits. As a quick check of whether the model may be 
    overparameterized, calculate the condition number of the covariance matrix: 
 
    &gt;&gt;&gt; np.linalg.cond(pcov) 
    34.571092161547405  # may vary 
 
    The value is small, so it does not raise much concern. If, however, we were 
    to add a fourth parameter ``d`` to `func` with the same effect as ``a``: 
 
    &gt;&gt;&gt; def func(x, a, b, c, d): 
    ...     return a * d * np.exp(-b * x) + c  # a and d are redundant 
    &gt;&gt;&gt; popt, pcov = curve_fit(func, xdata, ydata) 
    &gt;&gt;&gt; np.linalg.cond(pcov) 
    1.13250718925596e+32  # may vary 
 
    Such a large value is cause for concern. The diagonal elements of the 
    covariance matrix, which is related to uncertainty of the fit, gives more 
    information: 
 
    &gt;&gt;&gt; np.diag(pcov) 
    array([1.48814742e+29, 3.78596560e-02, 5.39253738e-03, 2.76417220e+28])  # may vary 
 
    Note that the first and last terms are much larger than the other elements, 
    suggesting that the optimal values of these parameters are ambiguous and 
    that only one of these parameters is needed in the model. 
 
    &quot;&quot;&quot;  </span><span class="s2"># noqa</span>
    <span class="s0">if </span><span class="s1">p0 </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s2"># determine number of parameters by inspecting the function</span>
        <span class="s1">sig = _getfullargspec(f)</span>
        <span class="s1">args = sig.args</span>
        <span class="s0">if </span><span class="s1">len(args) &lt; </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Unable to determine number of fit parameters.&quot;</span><span class="s1">)</span>
        <span class="s1">n = len(args) - </span><span class="s4">1</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">p0 = np.atleast_1d(p0)</span>
        <span class="s1">n = p0.size</span>

    <span class="s0">if </span><span class="s1">isinstance(bounds</span><span class="s0">, </span><span class="s1">Bounds):</span>
        <span class="s1">lb</span><span class="s0">, </span><span class="s1">ub = bounds.lb</span><span class="s0">, </span><span class="s1">bounds.ub</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">lb</span><span class="s0">, </span><span class="s1">ub = prepare_bounds(bounds</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s0">if </span><span class="s1">p0 </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">p0 = _initialize_feasible(lb</span><span class="s0">, </span><span class="s1">ub)</span>

    <span class="s1">bounded_problem = np.any((lb &gt; -np.inf) | (ub &lt; np.inf))</span>
    <span class="s0">if </span><span class="s1">method </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">bounded_problem:</span>
            <span class="s1">method = </span><span class="s3">'trf'</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">method = </span><span class="s3">'lm'</span>

    <span class="s0">if </span><span class="s1">method == </span><span class="s3">'lm' </span><span class="s0">and </span><span class="s1">bounded_problem:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Method 'lm' only works for unconstrained problems. &quot;</span>
                         <span class="s3">&quot;Use 'trf' or 'dogbox' instead.&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">check_finite </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">check_finite = </span><span class="s0">True if </span><span class="s1">nan_policy </span><span class="s0">is None else False</span>

    <span class="s2"># optimization may produce garbage for float32 inputs, cast them to float64</span>
    <span class="s0">if </span><span class="s1">check_finite:</span>
        <span class="s1">ydata = np.asarray_chkfinite(ydata</span><span class="s0">, </span><span class="s1">float)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">ydata = np.asarray(ydata</span><span class="s0">, </span><span class="s1">float)</span>

    <span class="s0">if </span><span class="s1">isinstance(xdata</span><span class="s0">, </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple</span><span class="s0">, </span><span class="s1">np.ndarray)):</span>
        <span class="s2"># `xdata` is passed straight to the user-defined `f`, so allow</span>
        <span class="s2"># non-array_like `xdata`.</span>
        <span class="s0">if </span><span class="s1">check_finite:</span>
            <span class="s1">xdata = np.asarray_chkfinite(xdata</span><span class="s0">, </span><span class="s1">float)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">xdata = np.asarray(xdata</span><span class="s0">, </span><span class="s1">float)</span>

    <span class="s0">if </span><span class="s1">ydata.size == </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`ydata` must not be empty!&quot;</span><span class="s1">)</span>

    <span class="s2"># nan handling is needed only if check_finite is False because if True,</span>
    <span class="s2"># the x-y data are already checked, and they don't contain nans.</span>
    <span class="s0">if not </span><span class="s1">check_finite </span><span class="s0">and </span><span class="s1">nan_policy </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">nan_policy == </span><span class="s3">&quot;propagate&quot;</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`nan_policy='propagate'` is not supported &quot;</span>
                             <span class="s3">&quot;by this function.&quot;</span><span class="s1">)</span>

        <span class="s1">policies = [</span><span class="s0">None, </span><span class="s3">'raise'</span><span class="s0">, </span><span class="s3">'omit'</span><span class="s1">]</span>
        <span class="s1">x_contains_nan</span><span class="s0">, </span><span class="s1">nan_policy = _contains_nan(xdata</span><span class="s0">, </span><span class="s1">nan_policy</span><span class="s0">,</span>
                                                   <span class="s1">policies=policies)</span>
        <span class="s1">y_contains_nan</span><span class="s0">, </span><span class="s1">nan_policy = _contains_nan(ydata</span><span class="s0">, </span><span class="s1">nan_policy</span><span class="s0">,</span>
                                                   <span class="s1">policies=policies)</span>

        <span class="s0">if </span><span class="s1">(x_contains_nan </span><span class="s0">or </span><span class="s1">y_contains_nan) </span><span class="s0">and </span><span class="s1">nan_policy == </span><span class="s3">'omit'</span><span class="s1">:</span>
            <span class="s2"># ignore NaNs for N dimensional arrays</span>
            <span class="s1">has_nan = np.isnan(xdata)</span>
            <span class="s1">has_nan = has_nan.any(axis=tuple(range(has_nan.ndim-</span><span class="s4">1</span><span class="s1">)))</span>
            <span class="s1">has_nan |= np.isnan(ydata)</span>

            <span class="s1">xdata = xdata[...</span><span class="s0">, </span><span class="s1">~has_nan]</span>
            <span class="s1">ydata = ydata[~has_nan]</span>

    <span class="s2"># Determine type of sigma</span>
    <span class="s0">if </span><span class="s1">sigma </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">sigma = np.asarray(sigma)</span>

        <span class="s2"># if 1-D, sigma are errors, define transform = 1/sigma</span>
        <span class="s0">if </span><span class="s1">sigma.shape == (ydata.size</span><span class="s0">, </span><span class="s1">):</span>
            <span class="s1">transform = </span><span class="s4">1.0 </span><span class="s1">/ sigma</span>
        <span class="s2"># if 2-D, sigma is the covariance matrix,</span>
        <span class="s2"># define transform = L such that L L^T = C</span>
        <span class="s0">elif </span><span class="s1">sigma.shape == (ydata.size</span><span class="s0">, </span><span class="s1">ydata.size):</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s2"># scipy.linalg.cholesky requires lower=True to return L L^T = A</span>
                <span class="s1">transform = cholesky(sigma</span><span class="s0">, </span><span class="s1">lower=</span><span class="s0">True</span><span class="s1">)</span>
            <span class="s0">except </span><span class="s1">LinAlgError </span><span class="s0">as </span><span class="s1">e:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`sigma` must be positive definite.&quot;</span><span class="s1">) </span><span class="s0">from </span><span class="s1">e</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`sigma` has incorrect shape.&quot;</span><span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">transform = </span><span class="s0">None</span>

    <span class="s1">func = _lightweight_memoizer(_wrap_func(f</span><span class="s0">, </span><span class="s1">xdata</span><span class="s0">, </span><span class="s1">ydata</span><span class="s0">, </span><span class="s1">transform))</span>

    <span class="s0">if </span><span class="s1">callable(jac):</span>
        <span class="s1">jac = _lightweight_memoizer(_wrap_jac(jac</span><span class="s0">, </span><span class="s1">xdata</span><span class="s0">, </span><span class="s1">transform))</span>
    <span class="s0">elif </span><span class="s1">jac </span><span class="s0">is None and </span><span class="s1">method != </span><span class="s3">'lm'</span><span class="s1">:</span>
        <span class="s1">jac = </span><span class="s3">'2-point'</span>

    <span class="s0">if </span><span class="s3">'args' </span><span class="s0">in </span><span class="s1">kwargs:</span>
        <span class="s2"># The specification for the model function `f` does not support</span>
        <span class="s2"># additional arguments. Refer to the `curve_fit` docstring for</span>
        <span class="s2"># acceptable call signatures of `f`.</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;'args' is not a supported keyword argument.&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">method == </span><span class="s3">'lm'</span><span class="s1">:</span>
        <span class="s2"># if ydata.size == 1, this might be used for broadcast.</span>
        <span class="s0">if </span><span class="s1">ydata.size != </span><span class="s4">1 </span><span class="s0">and </span><span class="s1">n &gt; ydata.size:</span>
            <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s3">f&quot;The number of func parameters=</span><span class="s0">{</span><span class="s1">n</span><span class="s0">} </span><span class="s3">must not&quot;</span>
                            <span class="s3">f&quot; exceed the number of data points=</span><span class="s0">{</span><span class="s1">ydata.size</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>
        <span class="s1">res = leastsq(func</span><span class="s0">, </span><span class="s1">p0</span><span class="s0">, </span><span class="s1">Dfun=jac</span><span class="s0">, </span><span class="s1">full_output=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">**kwargs)</span>
        <span class="s1">popt</span><span class="s0">, </span><span class="s1">pcov</span><span class="s0">, </span><span class="s1">infodict</span><span class="s0">, </span><span class="s1">errmsg</span><span class="s0">, </span><span class="s1">ier = res</span>
        <span class="s1">ysize = len(infodict[</span><span class="s3">'fvec'</span><span class="s1">])</span>
        <span class="s1">cost = np.sum(infodict[</span><span class="s3">'fvec'</span><span class="s1">] ** </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">ier </span><span class="s0">not in </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">4</span><span class="s1">]:</span>
            <span class="s0">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;Optimal parameters not found: &quot; </span><span class="s1">+ errmsg)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s2"># Rename maxfev (leastsq) to max_nfev (least_squares), if specified.</span>
        <span class="s0">if </span><span class="s3">'max_nfev' </span><span class="s0">not in </span><span class="s1">kwargs:</span>
            <span class="s1">kwargs[</span><span class="s3">'max_nfev'</span><span class="s1">] = kwargs.pop(</span><span class="s3">'maxfev'</span><span class="s0">, None</span><span class="s1">)</span>

        <span class="s1">res = least_squares(func</span><span class="s0">, </span><span class="s1">p0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">, </span><span class="s1">bounds=bounds</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                            <span class="s1">**kwargs)</span>

        <span class="s0">if not </span><span class="s1">res.success:</span>
            <span class="s0">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;Optimal parameters not found: &quot; </span><span class="s1">+ res.message)</span>

        <span class="s1">infodict = dict(nfev=res.nfev</span><span class="s0">, </span><span class="s1">fvec=res.fun)</span>
        <span class="s1">ier = res.status</span>
        <span class="s1">errmsg = res.message</span>

        <span class="s1">ysize = len(res.fun)</span>
        <span class="s1">cost = </span><span class="s4">2 </span><span class="s1">* res.cost  </span><span class="s2"># res.cost is half sum of squares!</span>
        <span class="s1">popt = res.x</span>

        <span class="s2"># Do Moore-Penrose inverse discarding zero singular values.</span>
        <span class="s1">_</span><span class="s0">, </span><span class="s1">s</span><span class="s0">, </span><span class="s1">VT = svd(res.jac</span><span class="s0">, </span><span class="s1">full_matrices=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s1">threshold = np.finfo(float).eps * max(res.jac.shape) * s[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">s = s[s &gt; threshold]</span>
        <span class="s1">VT = VT[:s.size]</span>
        <span class="s1">pcov = np.dot(VT.T / s**</span><span class="s4">2</span><span class="s0">, </span><span class="s1">VT)</span>

    <span class="s1">warn_cov = </span><span class="s0">False</span>
    <span class="s0">if </span><span class="s1">pcov </span><span class="s0">is None or </span><span class="s1">np.isnan(pcov).any():</span>
        <span class="s2"># indeterminate covariance</span>
        <span class="s1">pcov = zeros((len(popt)</span><span class="s0">, </span><span class="s1">len(popt))</span><span class="s0">, </span><span class="s1">dtype=float)</span>
        <span class="s1">pcov.fill(inf)</span>
        <span class="s1">warn_cov = </span><span class="s0">True</span>
    <span class="s0">elif not </span><span class="s1">absolute_sigma:</span>
        <span class="s0">if </span><span class="s1">ysize &gt; p0.size:</span>
            <span class="s1">s_sq = cost / (ysize - p0.size)</span>
            <span class="s1">pcov = pcov * s_sq</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">pcov.fill(inf)</span>
            <span class="s1">warn_cov = </span><span class="s0">True</span>

    <span class="s0">if </span><span class="s1">warn_cov:</span>
        <span class="s1">warnings.warn(</span><span class="s3">'Covariance of the parameters could not be estimated'</span><span class="s0">,</span>
                      <span class="s1">category=OptimizeWarning)</span>

    <span class="s0">if </span><span class="s1">full_output:</span>
        <span class="s0">return </span><span class="s1">popt</span><span class="s0">, </span><span class="s1">pcov</span><span class="s0">, </span><span class="s1">infodict</span><span class="s0">, </span><span class="s1">errmsg</span><span class="s0">, </span><span class="s1">ier</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">popt</span><span class="s0">, </span><span class="s1">pcov</span>


<span class="s0">def </span><span class="s1">check_gradient(fcn</span><span class="s0">, </span><span class="s1">Dfcn</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args=()</span><span class="s0">, </span><span class="s1">col_deriv=</span><span class="s4">0</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Perform a simple check on the gradient for correctness. 
 
    &quot;&quot;&quot;</span>

    <span class="s1">x = atleast_1d(x0)</span>
    <span class="s1">n = len(x)</span>
    <span class="s1">x = x.reshape((n</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">fvec = atleast_1d(fcn(x</span><span class="s0">, </span><span class="s1">*args))</span>
    <span class="s1">m = len(fvec)</span>
    <span class="s1">fvec = fvec.reshape((m</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">ldfjac = m</span>
    <span class="s1">fjac = atleast_1d(Dfcn(x</span><span class="s0">, </span><span class="s1">*args))</span>
    <span class="s1">fjac = fjac.reshape((m</span><span class="s0">, </span><span class="s1">n))</span>
    <span class="s0">if </span><span class="s1">col_deriv == </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s1">fjac = transpose(fjac)</span>

    <span class="s1">xp = zeros((n</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">float)</span>
    <span class="s1">err = zeros((m</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">float)</span>
    <span class="s1">fvecp = </span><span class="s0">None</span>
    <span class="s1">_minpack._chkder(m</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">fvec</span><span class="s0">, </span><span class="s1">fjac</span><span class="s0">, </span><span class="s1">ldfjac</span><span class="s0">, </span><span class="s1">xp</span><span class="s0">, </span><span class="s1">fvecp</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s1">err)</span>

    <span class="s1">fvecp = atleast_1d(fcn(xp</span><span class="s0">, </span><span class="s1">*args))</span>
    <span class="s1">fvecp = fvecp.reshape((m</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">_minpack._chkder(m</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">fvec</span><span class="s0">, </span><span class="s1">fjac</span><span class="s0">, </span><span class="s1">ldfjac</span><span class="s0">, </span><span class="s1">xp</span><span class="s0">, </span><span class="s1">fvecp</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">err)</span>

    <span class="s1">good = (prod(greater(err</span><span class="s0">, </span><span class="s4">0.5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">))</span>

    <span class="s0">return </span><span class="s1">(good</span><span class="s0">, </span><span class="s1">err)</span>


<span class="s0">def </span><span class="s1">_del2(p0</span><span class="s0">, </span><span class="s1">p1</span><span class="s0">, </span><span class="s1">d):</span>
    <span class="s0">return </span><span class="s1">p0 - np.square(p1 - p0) / d</span>


<span class="s0">def </span><span class="s1">_relerr(actual</span><span class="s0">, </span><span class="s1">desired):</span>
    <span class="s0">return </span><span class="s1">(actual - desired) / desired</span>


<span class="s0">def </span><span class="s1">_fixed_point_helper(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">maxiter</span><span class="s0">, </span><span class="s1">use_accel):</span>
    <span class="s1">p0 = x0</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(maxiter):</span>
        <span class="s1">p1 = func(p0</span><span class="s0">, </span><span class="s1">*args)</span>
        <span class="s0">if </span><span class="s1">use_accel:</span>
            <span class="s1">p2 = func(p1</span><span class="s0">, </span><span class="s1">*args)</span>
            <span class="s1">d = p2 - </span><span class="s4">2.0 </span><span class="s1">* p1 + p0</span>
            <span class="s1">p = _lazywhere(d != </span><span class="s4">0</span><span class="s0">, </span><span class="s1">(p0</span><span class="s0">, </span><span class="s1">p1</span><span class="s0">, </span><span class="s1">d)</span><span class="s0">, </span><span class="s1">f=_del2</span><span class="s0">, </span><span class="s1">fillvalue=p2)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">p = p1</span>
        <span class="s1">relerr = _lazywhere(p0 != </span><span class="s4">0</span><span class="s0">, </span><span class="s1">(p</span><span class="s0">, </span><span class="s1">p0)</span><span class="s0">, </span><span class="s1">f=_relerr</span><span class="s0">, </span><span class="s1">fillvalue=p)</span>
        <span class="s0">if </span><span class="s1">np.all(np.abs(relerr) &lt; xtol):</span>
            <span class="s0">return </span><span class="s1">p</span>
        <span class="s1">p0 = p</span>
    <span class="s1">msg = </span><span class="s3">&quot;Failed to converge after %d iterations, value is %s&quot; </span><span class="s1">% (maxiter</span><span class="s0">, </span><span class="s1">p)</span>
    <span class="s0">raise </span><span class="s1">RuntimeError(msg)</span>


<span class="s0">def </span><span class="s1">fixed_point(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args=()</span><span class="s0">, </span><span class="s1">xtol=</span><span class="s4">1e-8</span><span class="s0">, </span><span class="s1">maxiter=</span><span class="s4">500</span><span class="s0">, </span><span class="s1">method=</span><span class="s3">'del2'</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Find a fixed point of the function. 
 
    Given a function of one or more variables and a starting point, find a 
    fixed point of the function: i.e., where ``func(x0) == x0``. 
 
    Parameters 
    ---------- 
    func : function 
        Function to evaluate. 
    x0 : array_like 
        Fixed point of function. 
    args : tuple, optional 
        Extra arguments to `func`. 
    xtol : float, optional 
        Convergence tolerance, defaults to 1e-08. 
    maxiter : int, optional 
        Maximum number of iterations, defaults to 500. 
    method : {&quot;del2&quot;, &quot;iteration&quot;}, optional 
        Method of finding the fixed-point, defaults to &quot;del2&quot;, 
        which uses Steffensen's Method with Aitken's ``Del^2`` 
        convergence acceleration [1]_. The &quot;iteration&quot; method simply iterates 
        the function until convergence is detected, without attempting to 
        accelerate the convergence. 
 
    References 
    ---------- 
    .. [1] Burden, Faires, &quot;Numerical Analysis&quot;, 5th edition, pg. 80 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy import optimize 
    &gt;&gt;&gt; def func(x, c1, c2): 
    ...    return np.sqrt(c1/(x+c2)) 
    &gt;&gt;&gt; c1 = np.array([10,12.]) 
    &gt;&gt;&gt; c2 = np.array([3, 5.]) 
    &gt;&gt;&gt; optimize.fixed_point(func, [1.2, 1.3], args=(c1,c2)) 
    array([ 1.4920333 ,  1.37228132]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">use_accel = {</span><span class="s3">'del2'</span><span class="s1">: </span><span class="s0">True, </span><span class="s3">'iteration'</span><span class="s1">: </span><span class="s0">False</span><span class="s1">}[method]</span>
    <span class="s1">x0 = _asarray_validated(x0</span><span class="s0">, </span><span class="s1">as_inexact=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">_fixed_point_helper(func</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">maxiter</span><span class="s0">, </span><span class="s1">use_accel)</span>
</pre>
</body>
</html>
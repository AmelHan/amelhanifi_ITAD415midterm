<html>
<head>
<title>generalized_estimating_equations.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
generalized_estimating_equations.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Procedures for fitting marginal regression models to dependent data 
using Generalized Estimating Equations. 
 
References 
---------- 
KY Liang and S Zeger. &quot;Longitudinal data analysis using 
generalized linear models&quot;. Biometrika (1986) 73 (1): 13-22. 
 
S Zeger and KY Liang. &quot;Longitudinal Data Analysis for Discrete and 
Continuous Outcomes&quot;. Biometrics Vol. 42, No. 1 (Mar., 1986), 
pp. 121-130 
 
A Rotnitzky and NP Jewell (1990). &quot;Hypothesis testing of regression 
parameters in semiparametric generalized linear models for cluster 
correlated data&quot;, Biometrika, 77, 485-497. 
 
Xu Guo and Wei Pan (2002). &quot;Small sample performance of the score 
test in GEE&quot;. 
http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf 
 
LA Mancl LA, TA DeRouen (2001). A covariance estimator for GEE with 
improved small-sample properties.  Biometrics. 2001 Mar;57(1):126-34. 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">statsmodels.compat.python </span><span class="s2">import </span><span class="s1">lzip</span>
<span class="s2">from </span><span class="s1">statsmodels.compat.pandas </span><span class="s2">import </span><span class="s1">Appender</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">patsy</span>
<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">defaultdict</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>
<span class="s2">import </span><span class="s1">statsmodels.base.model </span><span class="s2">as </span><span class="s1">base</span>
<span class="s3"># used for wrapper:</span>
<span class="s2">import </span><span class="s1">statsmodels.regression.linear_model </span><span class="s2">as </span><span class="s1">lm</span>
<span class="s2">import </span><span class="s1">statsmodels.base.wrapper </span><span class="s2">as </span><span class="s1">wrap</span>

<span class="s2">from </span><span class="s1">statsmodels.genmod </span><span class="s2">import </span><span class="s1">families</span>
<span class="s2">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s2">import </span><span class="s1">GLM</span><span class="s2">, </span><span class="s1">GLMResults</span>
<span class="s2">from </span><span class="s1">statsmodels.genmod </span><span class="s2">import </span><span class="s1">cov_struct </span><span class="s2">as </span><span class="s1">cov_structs</span>

<span class="s2">import </span><span class="s1">statsmodels.genmod.families.varfuncs </span><span class="s2">as </span><span class="s1">varfuncs</span>
<span class="s2">from </span><span class="s1">statsmodels.genmod.families.links </span><span class="s2">import </span><span class="s1">Link</span>

<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">(ConvergenceWarning</span><span class="s2">,</span>
                                             <span class="s1">DomainWarning</span><span class="s2">,</span>
                                             <span class="s1">IterationLimitWarning</span><span class="s2">,</span>
                                             <span class="s1">ValueWarning)</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">from </span><span class="s1">statsmodels.graphics._regressionplots_doc </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_plot_added_variable_doc</span><span class="s2">,</span>
    <span class="s1">_plot_partial_residuals_doc</span><span class="s2">,</span>
    <span class="s1">_plot_ceres_residuals_doc)</span>
<span class="s2">from </span><span class="s1">statsmodels.discrete.discrete_margins </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_get_margeff_exog</span><span class="s2">, </span><span class="s1">_check_margeff_args</span><span class="s2">, </span><span class="s1">_effects_at</span><span class="s2">, </span><span class="s1">margeff_cov_with_se</span><span class="s2">,</span>
    <span class="s1">_check_at_is_all</span><span class="s2">, </span><span class="s1">_transform_names</span><span class="s2">, </span><span class="s1">_check_discrete_args</span><span class="s2">,</span>
    <span class="s1">_get_dummy_index</span><span class="s2">, </span><span class="s1">_get_count_index)</span>


<span class="s2">class </span><span class="s1">ParameterConstraint:</span>
    <span class="s0">&quot;&quot;&quot; 
    A class for managing linear equality constraints for a parameter 
    vector. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">lhs</span><span class="s2">, </span><span class="s1">rhs</span><span class="s2">, </span><span class="s1">exog):</span>
        <span class="s0">&quot;&quot;&quot; 
        Parameters 
        ---------- 
        lhs : ndarray 
           A q x p matrix which is the left hand side of the 
           constraint lhs * param = rhs.  The number of constraints is 
           q &gt;= 1 and p is the dimension of the parameter vector. 
        rhs : ndarray 
          A 1-dimensional vector of length q which is the right hand 
          side of the constraint equation. 
        exog : ndarray 
          The n x p exognenous data for the full model. 
        &quot;&quot;&quot;</span>

        <span class="s3"># In case a row or column vector is passed (patsy linear</span>
        <span class="s3"># constraints passes a column vector).</span>
        <span class="s1">rhs = np.atleast_1d(rhs.squeeze())</span>

        <span class="s2">if </span><span class="s1">rhs.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;The right hand side of the constraint &quot;</span>
                             <span class="s5">&quot;must be a vector.&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">len(rhs) != lhs.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;The number of rows of the left hand &quot;</span>
                             <span class="s5">&quot;side constraint matrix L must equal &quot;</span>
                             <span class="s5">&quot;the length of the right hand side &quot;</span>
                             <span class="s5">&quot;constraint vector R.&quot;</span><span class="s1">)</span>

        <span class="s1">self.lhs = lhs</span>
        <span class="s1">self.rhs = rhs</span>

        <span class="s3"># The columns of lhs0 are an orthogonal basis for the</span>
        <span class="s3"># orthogonal complement to row(lhs), the columns of lhs1 are</span>
        <span class="s3"># an orthogonal basis for row(lhs).  The columns of lhsf =</span>
        <span class="s3"># [lhs0, lhs1] are mutually orthogonal.</span>
        <span class="s1">lhs_u</span><span class="s2">, </span><span class="s1">lhs_s</span><span class="s2">, </span><span class="s1">lhs_vt = np.linalg.svd(lhs.T</span><span class="s2">, </span><span class="s1">full_matrices=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">self.lhs0 = lhs_u[:</span><span class="s2">, </span><span class="s1">len(lhs_s):]</span>
        <span class="s1">self.lhs1 = lhs_u[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">:len(lhs_s)]</span>
        <span class="s1">self.lhsf = np.hstack((self.lhs0</span><span class="s2">, </span><span class="s1">self.lhs1))</span>

        <span class="s3"># param0 is one solution to the underdetermined system</span>
        <span class="s3"># L * param = R.</span>
        <span class="s1">self.param0 = np.dot(self.lhs1</span><span class="s2">, </span><span class="s1">np.dot(lhs_vt</span><span class="s2">, </span><span class="s1">self.rhs) /</span>
                             <span class="s1">lhs_s)</span>

        <span class="s1">self._offset_increment = np.dot(exog</span><span class="s2">, </span><span class="s1">self.param0)</span>

        <span class="s1">self.orig_exog = exog</span>
        <span class="s1">self.exog_fulltrans = np.dot(exog</span><span class="s2">, </span><span class="s1">self.lhsf)</span>

    <span class="s2">def </span><span class="s1">offset_increment(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a vector that should be added to the offset vector to 
        accommodate the constraint. 
 
        Parameters 
        ---------- 
        exog : array_like 
           The exogeneous data for the model. 
        &quot;&quot;&quot;</span>

        <span class="s2">return </span><span class="s1">self._offset_increment</span>

    <span class="s2">def </span><span class="s1">reduced_exog(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a linearly transformed exog matrix whose columns span 
        the constrained model space. 
 
        Parameters 
        ---------- 
        exog : array_like 
           The exogeneous data for the model. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.exog_fulltrans[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">:self.lhs0.shape[</span><span class="s4">1</span><span class="s1">]]</span>

    <span class="s2">def </span><span class="s1">restore_exog(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the full exog matrix before it was reduced to 
        satisfy the constraint. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.orig_exog</span>

    <span class="s2">def </span><span class="s1">unpack_param(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Converts the parameter vector `params` from reduced to full 
        coordinates. 
        &quot;&quot;&quot;</span>

        <span class="s2">return </span><span class="s1">self.param0 + np.dot(self.lhs0</span><span class="s2">, </span><span class="s1">params)</span>

    <span class="s2">def </span><span class="s1">unpack_cov(self</span><span class="s2">, </span><span class="s1">bcov):</span>
        <span class="s0">&quot;&quot;&quot; 
        Converts the covariance matrix `bcov` from reduced to full 
        coordinates. 
        &quot;&quot;&quot;</span>

        <span class="s2">return </span><span class="s1">np.dot(self.lhs0</span><span class="s2">, </span><span class="s1">np.dot(bcov</span><span class="s2">, </span><span class="s1">self.lhs0.T))</span>


<span class="s1">_gee_init_doc = </span><span class="s5">&quot;&quot;&quot; 
    Marginal regression model fit using Generalized Estimating Equations. 
 
    GEE can be used to fit Generalized Linear Models (GLMs) when the 
    data have a grouped structure, and the observations are possibly 
    correlated within groups but not between groups. 
 
    Parameters 
    ---------- 
    endog : array_like 
        1d array of endogenous values (i.e. responses, outcomes, 
        dependent variables, or 'Y' values). 
    exog : array_like 
        2d array of exogeneous values (i.e. covariates, predictors, 
        independent variables, regressors, or 'X' values). A `nobs x 
        k` array where `nobs` is the number of observations and `k` is 
        the number of regressors. An intercept is not included by 
        default and should be added by the user. See 
        `statsmodels.tools.add_constant`. 
    groups : array_like 
        A 1d array of length `nobs` containing the group labels. 
    time : array_like 
        A 2d array of time (or other index) values, used by some 
        dependence structures to define similarity relationships among 
        observations within a cluster. 
    family : family class instance 
%(family_doc)s 
    cov_struct : CovStruct class instance 
        The default is Independence.  To specify an exchangeable 
        structure use cov_struct = Exchangeable().  See 
        statsmodels.genmod.cov_struct.CovStruct for more 
        information. 
    offset : array_like 
        An offset to be included in the fit.  If provided, must be 
        an array whose length is the number of rows in exog. 
    dep_data : array_like 
        Additional data passed to the dependence structure. 
    constraint : (ndarray, ndarray) 
        If provided, the constraint is a tuple (L, R) such that the 
        model parameters are estimated under the constraint L * 
        param = R, where L is a q x p matrix and R is a 
        q-dimensional vector.  If constraint is provided, a score 
        test is performed to compare the constrained model to the 
        unconstrained model. 
    update_dep : bool 
        If true, the dependence parameters are optimized, otherwise 
        they are held fixed at their starting values. 
    weights : array_like 
        An array of case weights to use in the analysis. 
    %(extra_params)s 
 
    See Also 
    -------- 
    statsmodels.genmod.families.family 
    :ref:`families` 
    :ref:`links` 
 
    Notes 
    ----- 
    Only the following combinations make sense for family and link :: 
 
                   + ident log logit probit cloglog pow opow nbinom loglog logc 
      Gaussian     |   x    x                        x 
      inv Gaussian |   x    x                        x 
      binomial     |   x    x    x     x       x     x    x           x      x 
      Poisson      |   x    x                        x 
      neg binomial |   x    x                        x          x 
      gamma        |   x    x                        x 
 
    Not all of these link functions are currently available. 
 
    Endog and exog are references so that if the data they refer 
    to are already arrays and these arrays are changed, endog and 
    exog will change. 
 
    The &quot;robust&quot; covariance type is the standard &quot;sandwich estimator&quot; 
    (e.g. Liang and Zeger (1986)).  It is the default here and in most 
    other packages.  The &quot;naive&quot; estimator gives smaller standard 
    errors, but is only correct if the working correlation structure 
    is correctly specified.  The &quot;bias reduced&quot; estimator of Mancl and 
    DeRouen (Biometrics, 2001) reduces the downward bias of the robust 
    estimator. 
 
    The robust covariance provided here follows Liang and Zeger (1986) 
    and agrees with R's gee implementation.  To obtain the robust 
    standard errors reported in Stata, multiply by sqrt(N / (N - g)), 
    where N is the total sample size, and g is the average group size. 
    %(notes)s 
    Examples 
    -------- 
    %(example)s 
&quot;&quot;&quot;</span>

<span class="s1">_gee_nointercept = </span><span class="s5">&quot;&quot;&quot; 
    The nominal and ordinal GEE models should not have an intercept 
    (either implicit or explicit).  Use &quot;0 + &quot; in a formula to 
    suppress the intercept. 
&quot;&quot;&quot;</span>

<span class="s1">_gee_family_doc = </span><span class="s5">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s5">The default is Gaussian.  To specify the binomial 
        distribution use `family=sm.families.Binomial()`. Each family 
        can take a link instance as an argument.  See 
        statsmodels.genmod.families.family for more information.&quot;&quot;&quot;</span>

<span class="s1">_gee_ordinal_family_doc = </span><span class="s5">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s5">The only family supported is `Binomial`.  The default `Logit` 
        link may be replaced with `probit` if desired.&quot;&quot;&quot;</span>

<span class="s1">_gee_nominal_family_doc = </span><span class="s5">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s5">The default value `None` uses a multinomial logit family 
        specifically designed for use with GEE.  Setting this 
        argument to a non-default value is not currently supported.&quot;&quot;&quot;</span>

<span class="s1">_gee_fit_doc = </span><span class="s5">&quot;&quot;&quot; 
    Fits a marginal regression model using generalized estimating 
    equations (GEE). 
 
    Parameters 
    ---------- 
    maxiter : int 
        The maximum number of iterations 
    ctol : float 
        The convergence criterion for stopping the Gauss-Seidel 
        iterations 
    start_params : array_like 
        A vector of starting values for the regression 
        coefficients.  If None, a default is chosen. 
    params_niter : int 
        The number of Gauss-Seidel updates of the mean structure 
        parameters that take place prior to each update of the 
        dependence structure. 
    first_dep_update : int 
        No dependence structure updates occur before this 
        iteration number. 
    cov_type : str 
        One of &quot;robust&quot;, &quot;naive&quot;, or &quot;bias_reduced&quot;. 
    ddof_scale : scalar or None 
        The scale parameter is estimated as the sum of squared 
        Pearson residuals divided by `N - ddof_scale`, where N 
        is the total sample size.  If `ddof_scale` is None, the 
        number of covariates (including an intercept if present) 
        is used. 
    scaling_factor : scalar 
        The estimated covariance of the parameter estimates is 
        scaled by this value.  Default is 1, Stata uses N / (N - g), 
        where N is the total sample size and g is the average group 
        size. 
    scale : str or float, optional 
        `scale` can be None, 'X2', or a float 
        If a float, its value is used as the scale parameter. 
        The default value is None, which uses `X2` (Pearson's 
        chi-square) for Gamma, Gaussian, and Inverse Gaussian. 
        The default is 1 for the Binomial and Poisson families. 
 
    Returns 
    ------- 
    An instance of the GEEResults class or subclass 
 
    Notes 
    ----- 
    If convergence difficulties occur, increase the values of 
    `first_dep_update` and/or `params_niter`.  Setting 
    `first_dep_update` to a greater value (e.g. ~10-20) causes the 
    algorithm to move close to the GLM solution before attempting 
    to identify the dependence structure. 
 
    For the Gaussian family, there is no benefit to setting 
    `params_niter` to a value greater than 1, since the mean 
    structure parameters converge in one step. 
&quot;&quot;&quot;</span>

<span class="s1">_gee_results_doc = </span><span class="s5">&quot;&quot;&quot; 
    Attributes 
    ---------- 
 
    cov_params_default : ndarray 
        default covariance of the parameter estimates. Is chosen among one 
        of the following three based on `cov_type` 
    cov_robust : ndarray 
        covariance of the parameter estimates that is robust 
    cov_naive : ndarray 
        covariance of the parameter estimates that is not robust to 
        correlation or variance misspecification 
    cov_robust_bc : ndarray 
        covariance of the parameter estimates that is robust and bias 
        reduced 
    converged : bool 
        indicator for convergence of the optimization. 
        True if the norm of the score is smaller than a threshold 
    cov_type : str 
        string indicating whether a &quot;robust&quot;, &quot;naive&quot; or &quot;bias_reduced&quot; 
        covariance is used as default 
    fit_history : dict 
        Contains information about the iterations. 
    fittedvalues : ndarray 
        Linear predicted values for the fitted model. 
        dot(exog, params) 
    model : class instance 
        Pointer to GEE model instance that called `fit`. 
    normalized_cov_params : ndarray 
        See GEE docstring 
    params : ndarray 
        The coefficients of the fitted model.  Note that 
        interpretation of the coefficients often depends on the 
        distribution family and the data. 
    scale : float 
        The estimate of the scale / dispersion for the model fit. 
        See GEE.fit for more information. 
    score_norm : float 
        norm of the score at the end of the iterative estimation. 
    bse : ndarray 
        The standard errors of the fitted GEE parameters. 
&quot;&quot;&quot;</span>

<span class="s1">_gee_example = </span><span class="s5">&quot;&quot;&quot; 
    Logistic regression with autoregressive working dependence: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; family = sm.families.Binomial() 
    &gt;&gt;&gt; va = sm.cov_struct.Autoregressive() 
    &gt;&gt;&gt; model = sm.GEE(endog, exog, group, family=family, cov_struct=va) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
 
    Use formulas to fit a Poisson GLM with independent working 
    dependence: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; fam = sm.families.Poisson() 
    &gt;&gt;&gt; ind = sm.cov_struct.Independence() 
    &gt;&gt;&gt; model = sm.GEE.from_formula(&quot;y ~ age + trt + base&quot;, &quot;subject&quot;, 
                                 data, cov_struct=ind, family=fam) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
 
    Equivalent, using the formula API: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; import statsmodels.formula.api as smf 
    &gt;&gt;&gt; fam = sm.families.Poisson() 
    &gt;&gt;&gt; ind = sm.cov_struct.Independence() 
    &gt;&gt;&gt; model = smf.gee(&quot;y ~ age + trt + base&quot;, &quot;subject&quot;, 
                    data, cov_struct=ind, family=fam) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
&quot;&quot;&quot;</span>

<span class="s1">_gee_ordinal_example = </span><span class="s5">&quot;&quot;&quot; 
    Fit an ordinal regression model using GEE, with &quot;global 
    odds ratio&quot; dependence: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; gor = sm.cov_struct.GlobalOddsRatio(&quot;ordinal&quot;) 
    &gt;&gt;&gt; model = sm.OrdinalGEE(endog, exog, groups, cov_struct=gor) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
 
    Using formulas: 
 
    &gt;&gt;&gt; import statsmodels.formula.api as smf 
    &gt;&gt;&gt; model = smf.ordinal_gee(&quot;y ~ 0 + x1 + x2&quot;, groups, data, 
                                    cov_struct=gor) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
&quot;&quot;&quot;</span>

<span class="s1">_gee_nominal_example = </span><span class="s5">&quot;&quot;&quot; 
    Fit a nominal regression model using GEE: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; import statsmodels.formula.api as smf 
    &gt;&gt;&gt; gor = sm.cov_struct.GlobalOddsRatio(&quot;nominal&quot;) 
    &gt;&gt;&gt; model = sm.NominalGEE(endog, exog, groups, cov_struct=gor) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
 
    Using formulas: 
 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; model = sm.NominalGEE.from_formula(&quot;y ~ 0 + x1 + x2&quot;, groups, 
                     data, cov_struct=gor) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
 
    Using the formula API: 
 
    &gt;&gt;&gt; import statsmodels.formula.api as smf 
    &gt;&gt;&gt; model = smf.nominal_gee(&quot;y ~ 0 + x1 + x2&quot;, groups, data, 
                                cov_struct=gor) 
    &gt;&gt;&gt; result = model.fit() 
    &gt;&gt;&gt; print(result.summary()) 
&quot;&quot;&quot;</span>


<span class="s2">def </span><span class="s1">_check_args(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset</span><span class="s2">, </span><span class="s1">exposure):</span>

    <span class="s2">if </span><span class="s1">endog.size != exog.shape[</span><span class="s4">0</span><span class="s1">]:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Leading dimension of 'exog' should match &quot;</span>
                         <span class="s5">&quot;length of 'endog'&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">groups.size != endog.size:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;'groups' and 'endog' should have the same size&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">time </span><span class="s2">is not None and </span><span class="s1">(time.size != endog.size):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;'time' and 'endog' should have the same size&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">offset </span><span class="s2">is not None and </span><span class="s1">(offset.size != endog.size):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;'offset and 'endog' should have the same size&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">exposure </span><span class="s2">is not None and </span><span class="s1">(exposure.size != endog.size):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;'exposure' and 'endog' should have the same size&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">GEE(GLM):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;    Marginal Regression Model using Generalized Estimating &quot;</span>
        <span class="s5">&quot;Equations.</span><span class="s2">\n</span><span class="s5">&quot; </span><span class="s1">+ _gee_init_doc %</span>
        <span class="s1">{</span><span class="s5">'extra_params'</span><span class="s1">: base._missing_param_doc</span><span class="s2">,</span>
         <span class="s5">'family_doc'</span><span class="s1">: _gee_family_doc</span><span class="s2">,</span>
         <span class="s5">'example'</span><span class="s1">: _gee_example</span><span class="s2">,</span>
         <span class="s5">'notes'</span><span class="s1">: </span><span class="s5">&quot;&quot;</span><span class="s1">})</span>

    <span class="s1">cached_means = </span><span class="s2">None</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time=</span><span class="s2">None, </span><span class="s1">family=</span><span class="s2">None,</span>
                 <span class="s1">cov_struct=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s5">'none'</span><span class="s2">, </span><span class="s1">offset=</span><span class="s2">None,</span>
                 <span class="s1">exposure=</span><span class="s2">None, </span><span class="s1">dep_data=</span><span class="s2">None, </span><span class="s1">constraint=</span><span class="s2">None,</span>
                 <span class="s1">update_dep=</span><span class="s2">True, </span><span class="s1">weights=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>

        <span class="s2">if </span><span class="s1">type(self) </span><span class="s2">is </span><span class="s1">GEE:</span>
            <span class="s1">self._check_kwargs(kwargs)</span>
        <span class="s2">if </span><span class="s1">family </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">isinstance(family.link</span><span class="s2">, </span><span class="s1">tuple(family.safe_links)):</span>
                <span class="s1">msg = (</span><span class="s5">&quot;The {0} link function does not respect the &quot;</span>
                       <span class="s5">&quot;domain of the {1} family.&quot;</span><span class="s1">)</span>
                <span class="s1">warnings.warn(msg.format(family.link.__class__.__name__</span><span class="s2">,</span>
                                         <span class="s1">family.__class__.__name__)</span><span class="s2">,</span>
                              <span class="s1">DomainWarning)</span>

        <span class="s1">groups = np.asarray(groups)  </span><span class="s3"># in case groups is pandas</span>

        <span class="s2">if </span><span class="s5">&quot;missing_idx&quot; </span><span class="s2">in </span><span class="s1">kwargs </span><span class="s2">and </span><span class="s1">kwargs[</span><span class="s5">&quot;missing_idx&quot;</span><span class="s1">] </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># If here, we are entering from super.from_formula; missing</span>
            <span class="s3"># has already been dropped from endog and exog, but not from</span>
            <span class="s3"># the other variables.</span>
            <span class="s1">ii = ~kwargs[</span><span class="s5">&quot;missing_idx&quot;</span><span class="s1">]</span>
            <span class="s1">groups = groups[ii]</span>
            <span class="s2">if </span><span class="s1">time </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">time = time[ii]</span>
            <span class="s2">if </span><span class="s1">offset </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">offset = offset[ii]</span>
            <span class="s2">if </span><span class="s1">exposure </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">exposure = exposure[ii]</span>
            <span class="s2">del </span><span class="s1">kwargs[</span><span class="s5">&quot;missing_idx&quot;</span><span class="s1">]</span>

        <span class="s1">self.missing = missing</span>
        <span class="s1">self.dep_data = dep_data</span>
        <span class="s1">self.constraint = constraint</span>
        <span class="s1">self.update_dep = update_dep</span>

        <span class="s1">self._fit_history = defaultdict(list)</span>

        <span class="s3"># Pass groups, time, offset, and dep_data so they are</span>
        <span class="s3"># processed for missing data along with endog and exog.</span>
        <span class="s3"># Calling super creates self.exog, self.endog, etc. as</span>
        <span class="s3"># ndarrays and the original exog, endog, etc. are</span>
        <span class="s3"># self.data.endog, etc.</span>
        <span class="s1">super(GEE</span><span class="s2">, </span><span class="s1">self).__init__(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups=groups</span><span class="s2">,</span>
                                  <span class="s1">time=time</span><span class="s2">, </span><span class="s1">offset=offset</span><span class="s2">,</span>
                                  <span class="s1">exposure=exposure</span><span class="s2">, </span><span class="s1">weights=weights</span><span class="s2">,</span>
                                  <span class="s1">dep_data=dep_data</span><span class="s2">, </span><span class="s1">missing=missing</span><span class="s2">,</span>
                                  <span class="s1">family=family</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s1">_check_args(</span>
            <span class="s1">self.endog</span><span class="s2">,</span>
            <span class="s1">self.exog</span><span class="s2">,</span>
            <span class="s1">self.groups</span><span class="s2">,</span>
            <span class="s1">self.time</span><span class="s2">,</span>
            <span class="s1">getattr(self</span><span class="s2">, </span><span class="s5">&quot;offset&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">getattr(self</span><span class="s2">, </span><span class="s5">&quot;exposure&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s1">self._init_keys.extend([</span><span class="s5">&quot;update_dep&quot;</span><span class="s2">, </span><span class="s5">&quot;constraint&quot;</span><span class="s2">, </span><span class="s5">&quot;family&quot;</span><span class="s2">,</span>
                                <span class="s5">&quot;cov_struct&quot;</span><span class="s1">])</span>
        <span class="s3"># remove keys added by super that are not supported</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">self._init_keys.remove(</span><span class="s5">&quot;freq_weights&quot;</span><span class="s1">)</span>
            <span class="s1">self._init_keys.remove(</span><span class="s5">&quot;var_weights&quot;</span><span class="s1">)</span>
        <span class="s2">except </span><span class="s1">ValueError:</span>
            <span class="s2">pass</span>

        <span class="s3"># Handle the family argument</span>
        <span class="s2">if </span><span class="s1">family </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">family = families.Gaussian()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">issubclass(family.__class__</span><span class="s2">, </span><span class="s1">families.Family):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;GEE: `family` must be a genmod &quot;</span>
                                 <span class="s5">&quot;family instance&quot;</span><span class="s1">)</span>
        <span class="s1">self.family = family</span>

        <span class="s3"># Handle the cov_struct argument</span>
        <span class="s2">if </span><span class="s1">cov_struct </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov_struct = cov_structs.Independence()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">issubclass(cov_struct.__class__</span><span class="s2">, </span><span class="s1">cov_structs.CovStruct):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;GEE: `cov_struct` must be a genmod &quot;</span>
                                 <span class="s5">&quot;cov_struct instance&quot;</span><span class="s1">)</span>

        <span class="s1">self.cov_struct = cov_struct</span>

        <span class="s3"># Handle the constraint</span>
        <span class="s1">self.constraint = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">constraint </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(constraint) != </span><span class="s4">2</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;GEE: `constraint` must be a 2-tuple.&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">constraint[</span><span class="s4">0</span><span class="s1">].shape[</span><span class="s4">1</span><span class="s1">] != self.exog.shape[</span><span class="s4">1</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;GEE: the left hand side of the constraint must have &quot;</span>
                    <span class="s5">&quot;the same number of columns as the exog matrix.&quot;</span><span class="s1">)</span>
            <span class="s1">self.constraint = ParameterConstraint(constraint[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
                                                  <span class="s1">constraint[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">,</span>
                                                  <span class="s1">self.exog)</span>

            <span class="s2">if </span><span class="s1">self._offset_exposure </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">self._offset_exposure += self.constraint.offset_increment()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self._offset_exposure = (</span>
                    <span class="s1">self.constraint.offset_increment().copy())</span>
            <span class="s1">self.exog = self.constraint.reduced_exog()</span>

        <span class="s3"># Create list of row indices for each group</span>
        <span class="s1">group_labels</span><span class="s2">, </span><span class="s1">ix = np.unique(self.groups</span><span class="s2">, </span><span class="s1">return_inverse=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">se = pd.Series(index=np.arange(len(ix))</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s5">&quot;int&quot;</span><span class="s1">)</span>
        <span class="s1">gb = se.groupby(ix).groups</span>
        <span class="s1">dk = [(lb</span><span class="s2">, </span><span class="s1">np.asarray(gb[k])) </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">enumerate(group_labels)]</span>
        <span class="s1">self.group_indices = dict(dk)</span>
        <span class="s1">self.group_labels = group_labels</span>

        <span class="s3"># Convert the data to the internal representation, which is a</span>
        <span class="s3"># list of arrays, corresponding to the groups.</span>
        <span class="s1">self.endog_li = self.cluster_list(self.endog)</span>
        <span class="s1">self.exog_li = self.cluster_list(self.exog)</span>

        <span class="s2">if </span><span class="s1">self.weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.weights_li = self.cluster_list(self.weights)</span>

        <span class="s1">self.num_group = len(self.endog_li)</span>

        <span class="s3"># Time defaults to a 1d grid with equal spacing</span>
        <span class="s2">if </span><span class="s1">self.time </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.time.ndim == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">self.time = self.time[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s1">self.time_li = self.cluster_list(self.time)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.time_li = \</span>
                <span class="s1">[np.arange(len(y)</span><span class="s2">, </span><span class="s1">dtype=np.float64)[:</span><span class="s2">, None</span><span class="s1">]</span>
                 <span class="s2">for </span><span class="s1">y </span><span class="s2">in </span><span class="s1">self.endog_li]</span>
            <span class="s1">self.time = np.concatenate(self.time_li)</span>

        <span class="s2">if </span><span class="s1">(self._offset_exposure </span><span class="s2">is None or</span>
            <span class="s1">(np.isscalar(self._offset_exposure) </span><span class="s2">and</span>
             <span class="s1">self._offset_exposure == </span><span class="s4">0.</span><span class="s1">)):</span>
            <span class="s1">self.offset_li = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.offset_li = self.cluster_list(self._offset_exposure)</span>
        <span class="s2">if </span><span class="s1">constraint </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.constraint.exog_fulltrans_li = \</span>
                <span class="s1">self.cluster_list(self.constraint.exog_fulltrans)</span>

        <span class="s1">self.family = family</span>

        <span class="s1">self.cov_struct.initialize(self)</span>

        <span class="s3"># Total sample size</span>
        <span class="s1">group_ns = [len(y) </span><span class="s2">for </span><span class="s1">y </span><span class="s2">in </span><span class="s1">self.endog_li]</span>
        <span class="s1">self.nobs = sum(group_ns)</span>
        <span class="s3"># The following are column based, not on rank see #1928</span>
        <span class="s1">self.df_model = self.exog.shape[</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">1  </span><span class="s3"># assumes constant</span>
        <span class="s1">self.df_resid = self.nobs - self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s3"># Skip the covariance updates if all groups have a single</span>
        <span class="s3"># observation (reduces to fitting a GLM).</span>
        <span class="s1">maxgroup = max([len(x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.endog_li])</span>
        <span class="s2">if </span><span class="s1">maxgroup == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">self.update_dep = </span><span class="s2">False</span>

    <span class="s3"># Override to allow groups and time to be passed as variable</span>
    <span class="s3"># names.</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">from_formula(cls</span><span class="s2">, </span><span class="s1">formula</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">subset=</span><span class="s2">None,</span>
                     <span class="s1">time=</span><span class="s2">None, </span><span class="s1">offset=</span><span class="s2">None, </span><span class="s1">exposure=</span><span class="s2">None,</span>
                     <span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s5">&quot;&quot;&quot; 
        Create a GEE model instance from a formula and dataframe. 
 
        Parameters 
        ---------- 
        formula : str or generic Formula object 
            The formula specifying the model 
        groups : array_like or string 
            Array of grouping labels.  If a string, this is the name 
            of a variable in `data` that contains the grouping labels. 
        data : array_like 
            The data for the model. 
        subset : array_like 
            An array-like object of booleans, integers, or index 
            values that indicate the subset of the data to used when 
            fitting the model. 
        time : array_like or string 
            The time values, used for dependence structures involving 
            distances between observations.  If a string, this is the 
            name of a variable in `data` that contains the time 
            values. 
        offset : array_like or string 
            The offset values, added to the linear predictor.  If a 
            string, this is the name of a variable in `data` that 
            contains the offset values. 
        exposure : array_like or string 
            The exposure values, only used if the link function is the 
            logarithm function, in which case the log of `exposure` 
            is added to the offset (if any).  If a string, this is the 
            name of a variable in `data` that contains the offset 
            values. 
        %(missing_param_doc)s 
        args : extra arguments 
            These are passed to the model 
        kwargs : extra keyword arguments 
            These are passed to the model with two exceptions. `dep_data` 
            is processed as described below.  The ``eval_env`` keyword is 
            passed to patsy. It can be either a 
            :class:`patsy:patsy.EvalEnvironment` object or an integer 
            indicating the depth of the namespace to use. For example, the 
            default ``eval_env=0`` uses the calling namespace. 
            If you wish to use a &quot;clean&quot; environment set ``eval_env=-1``. 
 
        Optional arguments 
        ------------------ 
        dep_data : str or array_like 
            Data used for estimating the dependence structure.  See 
            specific dependence structure classes (e.g. Nested) for 
            details.  If `dep_data` is a string, it is interpreted as 
            a formula that is applied to `data`. If it is an array, it 
            must be an array of strings corresponding to column names in 
            `data`.  Otherwise it must be an array-like with the same 
            number of rows as data. 
 
        Returns 
        ------- 
        model : GEE model instance 
 
        Notes 
        ----- 
        `data` must define __getitem__ with the keys in the formula 
        terms args and kwargs are passed on to the model 
        instantiation. E.g., a numpy structured or rec array, a 
        dictionary, or a pandas DataFrame. 
        &quot;&quot;&quot; </span><span class="s1">% {</span><span class="s5">'missing_param_doc'</span><span class="s1">: base._missing_param_doc}</span>

        <span class="s1">groups_name = </span><span class="s5">&quot;Groups&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(groups</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">groups_name = groups</span>
            <span class="s1">groups = data[groups]</span>

        <span class="s2">if </span><span class="s1">isinstance(time</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">time = data[time]</span>

        <span class="s2">if </span><span class="s1">isinstance(offset</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">offset = data[offset]</span>

        <span class="s2">if </span><span class="s1">isinstance(exposure</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">exposure = data[exposure]</span>

        <span class="s1">dep_data = kwargs.get(</span><span class="s5">&quot;dep_data&quot;</span><span class="s1">)</span>
        <span class="s1">dep_data_names = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">dep_data </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(dep_data</span><span class="s2">, </span><span class="s1">str):</span>
                <span class="s1">dep_data = patsy.dmatrix(dep_data</span><span class="s2">, </span><span class="s1">data</span><span class="s2">,</span>
                                         <span class="s1">return_type=</span><span class="s5">'dataframe'</span><span class="s1">)</span>
                <span class="s1">dep_data_names = dep_data.columns.tolist()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">dep_data_names = list(dep_data)</span>
                <span class="s1">dep_data = data[dep_data]</span>
            <span class="s1">kwargs[</span><span class="s5">&quot;dep_data&quot;</span><span class="s1">] = np.asarray(dep_data)</span>

        <span class="s1">family = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s5">&quot;family&quot; </span><span class="s2">in </span><span class="s1">kwargs:</span>
            <span class="s1">family = kwargs[</span><span class="s5">&quot;family&quot;</span><span class="s1">]</span>
            <span class="s2">del </span><span class="s1">kwargs[</span><span class="s5">&quot;family&quot;</span><span class="s1">]</span>

        <span class="s1">model = super(GEE</span><span class="s2">, </span><span class="s1">cls).from_formula(formula</span><span class="s2">, </span><span class="s1">data=data</span><span class="s2">, </span><span class="s1">subset=subset</span><span class="s2">,</span>
                                             <span class="s1">groups=groups</span><span class="s2">, </span><span class="s1">time=time</span><span class="s2">,</span>
                                             <span class="s1">offset=offset</span><span class="s2">,</span>
                                             <span class="s1">exposure=exposure</span><span class="s2">,</span>
                                             <span class="s1">family=family</span><span class="s2">,</span>
                                             <span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">if </span><span class="s1">dep_data_names </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">model._dep_data_names = dep_data_names</span>
        <span class="s1">model._groups_name = groups_name</span>

        <span class="s2">return </span><span class="s1">model</span>

    <span class="s2">def </span><span class="s1">cluster_list(self</span><span class="s2">, </span><span class="s1">array):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns `array` split into subarrays corresponding to the 
        cluster structure. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">array.ndim == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">[np.array(array[self.group_indices[k]])</span>
                    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">self.group_labels]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">[np.array(array[self.group_indices[k]</span><span class="s2">, </span><span class="s1">:])</span>
                    <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">self.group_labels]</span>

    <span class="s2">def </span><span class="s1">compare_score_test(self</span><span class="s2">, </span><span class="s1">submodel):</span>
        <span class="s0">&quot;&quot;&quot; 
        Perform a score test for the given submodel against this model. 
 
        Parameters 
        ---------- 
        submodel : GEEResults instance 
            A fitted GEE model that is a submodel of this model. 
 
        Returns 
        ------- 
        A dictionary with keys &quot;statistic&quot;, &quot;p-value&quot;, and &quot;df&quot;, 
        containing the score test statistic, its chi^2 p-value, 
        and the degrees of freedom used to compute the p-value. 
 
        Notes 
        ----- 
        The score test can be performed without calling 'fit' on the 
        larger model.  The provided submodel must be obtained from a 
        fitted GEE. 
 
        This method performs the same score test as can be obtained by 
        fitting the GEE with a linear constraint and calling `score_test` 
        on the results. 
 
        References 
        ---------- 
        Xu Guo and Wei Pan (2002). &quot;Small sample performance of the score 
        test in GEE&quot;. 
        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf 
        &quot;&quot;&quot;</span>

        <span class="s3"># Since the model has not been fit, its scaletype has not been</span>
        <span class="s3"># set.  So give it the scaletype of the submodel.</span>
        <span class="s1">self.scaletype = submodel.model.scaletype</span>

        <span class="s3"># Check consistency between model and submodel (not a comprehensive</span>
        <span class="s3"># check)</span>
        <span class="s1">submod = submodel.model</span>
        <span class="s2">if </span><span class="s1">self.exog.shape[</span><span class="s4">0</span><span class="s1">] != submod.exog.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s1">msg = </span><span class="s5">&quot;Model and submodel have different numbers of cases.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
        <span class="s2">if </span><span class="s1">self.exog.shape[</span><span class="s4">1</span><span class="s1">] == submod.exog.shape[</span><span class="s4">1</span><span class="s1">]:</span>
            <span class="s1">msg = </span><span class="s5">&quot;Model and submodel have the same number of variables&quot;</span>
            <span class="s1">warnings.warn(msg)</span>
        <span class="s2">if not </span><span class="s1">isinstance(self.family</span><span class="s2">, </span><span class="s1">type(submod.family)):</span>
            <span class="s1">msg = </span><span class="s5">&quot;Model and submodel have different GLM families.&quot;</span>
            <span class="s1">warnings.warn(msg)</span>
        <span class="s2">if not </span><span class="s1">isinstance(self.cov_struct</span><span class="s2">, </span><span class="s1">type(submod.cov_struct)):</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Model and submodel have different GEE covariance &quot;</span>
                          <span class="s5">&quot;structures.&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">np.equal(self.weights</span><span class="s2">, </span><span class="s1">submod.weights).all():</span>
            <span class="s1">msg = </span><span class="s5">&quot;Model and submodel should have the same weights.&quot;</span>
            <span class="s1">warnings.warn(msg)</span>

        <span class="s3"># Get the positions of the submodel variables in the</span>
        <span class="s3"># parent model</span>
        <span class="s1">qm</span><span class="s2">, </span><span class="s1">qc = _score_test_submodel(self</span><span class="s2">, </span><span class="s1">submodel.model)</span>
        <span class="s2">if </span><span class="s1">qm </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s5">&quot;The provided model is not a submodel.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s3"># Embed the submodel params into a params vector for the</span>
        <span class="s3"># parent model</span>
        <span class="s1">params_ex = np.dot(qm</span><span class="s2">, </span><span class="s1">submodel.params)</span>

        <span class="s3"># Attempt to preserve the state of the parent model</span>
        <span class="s1">cov_struct_save = self.cov_struct</span>
        <span class="s2">import </span><span class="s1">copy</span>
        <span class="s1">cached_means_save = copy.deepcopy(self.cached_means)</span>

        <span class="s3"># Get the score vector of the submodel params in</span>
        <span class="s3"># the parent model</span>
        <span class="s1">self.cov_struct = submodel.cov_struct</span>
        <span class="s1">self.update_cached_means(params_ex)</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">score = self._update_mean_params()</span>
        <span class="s2">if </span><span class="s1">score </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">msg = </span><span class="s5">&quot;Singular matrix encountered in GEE score test&quot;</span>
            <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
            <span class="s2">return None</span>

        <span class="s2">if not </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s5">&quot;ddof_scale&quot;</span><span class="s1">):</span>
            <span class="s1">self.ddof_scale = self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s2">if not </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s5">&quot;scaling_factor&quot;</span><span class="s1">):</span>
            <span class="s1">self.scaling_factor = </span><span class="s4">1</span>

        <span class="s1">_</span><span class="s2">, </span><span class="s1">ncov1</span><span class="s2">, </span><span class="s1">cmat = self._covmat()</span>
        <span class="s1">score2 = np.dot(qc.T</span><span class="s2">, </span><span class="s1">score)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">amat = np.linalg.inv(ncov1)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">amat = np.linalg.pinv(ncov1)</span>

        <span class="s1">bmat_11 = np.dot(qm.T</span><span class="s2">, </span><span class="s1">np.dot(cmat</span><span class="s2">, </span><span class="s1">qm))</span>
        <span class="s1">bmat_22 = np.dot(qc.T</span><span class="s2">, </span><span class="s1">np.dot(cmat</span><span class="s2">, </span><span class="s1">qc))</span>
        <span class="s1">bmat_12 = np.dot(qm.T</span><span class="s2">, </span><span class="s1">np.dot(cmat</span><span class="s2">, </span><span class="s1">qc))</span>

        <span class="s1">amat_11 = np.dot(qm.T</span><span class="s2">, </span><span class="s1">np.dot(amat</span><span class="s2">, </span><span class="s1">qm))</span>
        <span class="s1">amat_12 = np.dot(qm.T</span><span class="s2">, </span><span class="s1">np.dot(amat</span><span class="s2">, </span><span class="s1">qc))</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">ab = np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">bmat_12)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">ab = np.dot(np.linalg.pinv(amat_11)</span><span class="s2">, </span><span class="s1">bmat_12)</span>

        <span class="s1">score_cov = bmat_22 - np.dot(amat_12.T</span><span class="s2">, </span><span class="s1">ab)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">aa = np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">amat_12)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">aa = np.dot(np.linalg.pinv(amat_11)</span><span class="s2">, </span><span class="s1">amat_12)</span>

        <span class="s1">score_cov -= np.dot(bmat_12.T</span><span class="s2">, </span><span class="s1">aa)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">ab = np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">bmat_11)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">ab = np.dot(np.linalg.pinv(amat_11)</span><span class="s2">, </span><span class="s1">bmat_11)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">aa = np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">amat_12)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">aa = np.dot(np.linalg.pinv(amat_11)</span><span class="s2">, </span><span class="s1">amat_12)</span>

        <span class="s1">score_cov += np.dot(amat_12.T</span><span class="s2">, </span><span class="s1">np.dot(ab</span><span class="s2">, </span><span class="s1">aa))</span>

        <span class="s3"># Attempt to restore state</span>
        <span class="s1">self.cov_struct = cov_struct_save</span>
        <span class="s1">self.cached_means = cached_means_save</span>

        <span class="s2">from </span><span class="s1">scipy.stats.distributions </span><span class="s2">import </span><span class="s1">chi2</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">sc2 = np.linalg.solve(score_cov</span><span class="s2">, </span><span class="s1">score2)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">sc2 = np.dot(np.linalg.pinv(score_cov)</span><span class="s2">, </span><span class="s1">score2)</span>
        <span class="s1">score_statistic = np.dot(score2</span><span class="s2">, </span><span class="s1">sc2)</span>
        <span class="s1">score_df = len(score2)</span>
        <span class="s1">score_pvalue = </span><span class="s4">1 </span><span class="s1">- chi2.cdf(score_statistic</span><span class="s2">, </span><span class="s1">score_df)</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s5">&quot;statistic&quot;</span><span class="s1">: score_statistic</span><span class="s2">,</span>
                <span class="s5">&quot;df&quot;</span><span class="s1">: score_df</span><span class="s2">,</span>
                <span class="s5">&quot;p-value&quot;</span><span class="s1">: score_pvalue}</span>

    <span class="s2">def </span><span class="s1">estimate_scale(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Estimate the dispersion/scale. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.scaletype </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(self.family</span><span class="s2">, </span><span class="s1">(families.Binomial</span><span class="s2">, </span><span class="s1">families.Poisson</span><span class="s2">,</span>
                                        <span class="s1">families.NegativeBinomial</span><span class="s2">,</span>
                                        <span class="s1">_Multinomial)):</span>
                <span class="s2">return </span><span class="s4">1.</span>
        <span class="s2">elif </span><span class="s1">isinstance(self.scaletype</span><span class="s2">, </span><span class="s1">float):</span>
            <span class="s2">return </span><span class="s1">np.array(self.scaletype)</span>

        <span class="s1">endog = self.endog_li</span>
        <span class="s1">cached_means = self.cached_means</span>
        <span class="s1">nobs = self.nobs</span>
        <span class="s1">varfunc = self.family.variance</span>

        <span class="s1">scale = </span><span class="s4">0.</span>
        <span class="s1">fsum = </span><span class="s4">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s2">if </span><span class="s1">len(endog[i]) == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">continue</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">sdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / sdev</span>

            <span class="s2">if </span><span class="s1">self.weights </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">f = self.weights_li[i]</span>
                <span class="s1">scale += np.sum(f * (resid ** </span><span class="s4">2</span><span class="s1">))</span>
                <span class="s1">fsum += f.sum()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">scale += np.sum(resid ** </span><span class="s4">2</span><span class="s1">)</span>
                <span class="s1">fsum += len(resid)</span>

        <span class="s1">scale /= (fsum * (nobs - self.ddof_scale) / float(nobs))</span>

        <span class="s2">return </span><span class="s1">scale</span>

    <span class="s2">def </span><span class="s1">mean_deriv(self</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">lin_pred):</span>
        <span class="s0">&quot;&quot;&quot; 
        Derivative of the expected endog with respect to the parameters. 
 
        Parameters 
        ---------- 
        exog : array_like 
           The exogeneous data at which the derivative is computed. 
        lin_pred : array_like 
           The values of the linear predictor. 
 
        Returns 
        ------- 
        The value of the derivative of the expected endog with respect 
        to the parameter vector. 
 
        Notes 
        ----- 
        If there is an offset or exposure, it should be added to 
        `lin_pred` prior to calling this function. 
        &quot;&quot;&quot;</span>

        <span class="s1">idl = self.family.link.inverse_deriv(lin_pred)</span>
        <span class="s1">dmat = exog * idl[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">dmat</span>

    <span class="s2">def </span><span class="s1">mean_deriv_exog(self</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">offset_exposure=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Derivative of the expected endog with respect to exog. 
 
        Parameters 
        ---------- 
        exog : array_like 
            Values of the independent variables at which the derivative 
            is calculated. 
        params : array_like 
            Parameter values at which the derivative is calculated. 
        offset_exposure : array_like, optional 
            Combined offset and exposure. 
 
        Returns 
        ------- 
        The derivative of the expected endog with respect to exog. 
        &quot;&quot;&quot;</span>

        <span class="s1">lin_pred = np.dot(exog</span><span class="s2">, </span><span class="s1">params)</span>
        <span class="s2">if </span><span class="s1">offset_exposure </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">lin_pred += offset_exposure</span>

        <span class="s1">idl = self.family.link.inverse_deriv(lin_pred)</span>
        <span class="s1">dmat = np.outer(idl</span><span class="s2">, </span><span class="s1">params)</span>
        <span class="s2">return </span><span class="s1">dmat</span>

    <span class="s2">def </span><span class="s1">_update_mean_params(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns 
        ------- 
        update : array_like 
            The update vector such that params + update is the next 
            iterate when solving the score equations. 
        score : array_like 
            The current value of the score equations, not 
            incorporating the scale parameter.  If desired, 
            multiply this vector by the scale parameter to 
            incorporate the scale. 
        &quot;&quot;&quot;</span>

        <span class="s1">endog = self.endog_li</span>
        <span class="s1">exog = self.exog_li</span>
        <span class="s1">weights = getattr(self</span><span class="s2">, </span><span class="s5">&quot;weights_li&quot;</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">cached_means = self.cached_means</span>

        <span class="s1">varfunc = self.family.variance</span>

        <span class="s1">bmat</span><span class="s2">, </span><span class="s1">score = </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">lpr = cached_means[i]</span>
            <span class="s1">resid = endog[i] - expval</span>
            <span class="s1">dmat = self.mean_deriv(exog[i]</span><span class="s2">, </span><span class="s1">lpr)</span>
            <span class="s1">sdev = np.sqrt(varfunc(expval))</span>

            <span class="s2">if </span><span class="s1">weights </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">w = weights[i]</span>
                <span class="s1">wresid = resid * w</span>
                <span class="s1">wdmat = dmat * w[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">wresid = resid</span>
                <span class="s1">wdmat = dmat</span>

            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                    <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(wdmat</span><span class="s2">, </span><span class="s1">wresid))</span>
            <span class="s2">if </span><span class="s1">rslt </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return None, None</span>
            <span class="s1">vinv_d</span><span class="s2">, </span><span class="s1">vinv_resid = tuple(rslt)</span>

            <span class="s1">bmat += np.dot(dmat.T</span><span class="s2">, </span><span class="s1">vinv_d)</span>
            <span class="s1">score += np.dot(dmat.T</span><span class="s2">, </span><span class="s1">vinv_resid)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">update = np.linalg.solve(bmat</span><span class="s2">, </span><span class="s1">score)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">update = np.dot(np.linalg.pinv(bmat)</span><span class="s2">, </span><span class="s1">score)</span>

        <span class="s1">self._fit_history[</span><span class="s5">&quot;cov_adjust&quot;</span><span class="s1">].append(</span>
            <span class="s1">self.cov_struct.cov_adjust)</span>

        <span class="s2">return </span><span class="s1">update</span><span class="s2">, </span><span class="s1">score</span>

    <span class="s2">def </span><span class="s1">update_cached_means(self</span><span class="s2">, </span><span class="s1">mean_params):</span>
        <span class="s0">&quot;&quot;&quot; 
        cached_means should always contain the most recent calculation 
        of the group-wise mean vectors.  This function should be 
        called every time the regression parameters are changed, to 
        keep the cached means up to date. 
        &quot;&quot;&quot;</span>

        <span class="s1">endog = self.endog_li</span>
        <span class="s1">exog = self.exog_li</span>
        <span class="s1">offset = self.offset_li</span>

        <span class="s1">linkinv = self.family.link.inverse</span>

        <span class="s1">self.cached_means = []</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s2">if </span><span class="s1">len(endog[i]) == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">continue</span>

            <span class="s1">lpr = np.dot(exog[i]</span><span class="s2">, </span><span class="s1">mean_params)</span>
            <span class="s2">if </span><span class="s1">offset </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">lpr += offset[i]</span>
            <span class="s1">expval = linkinv(lpr)</span>

            <span class="s1">self.cached_means.append((expval</span><span class="s2">, </span><span class="s1">lpr))</span>

    <span class="s2">def </span><span class="s1">_covmat(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the sampling covariance matrix of the regression 
        parameters and related quantities. 
 
        Returns 
        ------- 
        cov_robust : array_like 
           The robust, or sandwich estimate of the covariance, which 
           is meaningful even if the working covariance structure is 
           incorrectly specified. 
        cov_naive : array_like 
           The model-based estimate of the covariance, which is 
           meaningful if the covariance structure is correctly 
           specified. 
        cmat : array_like 
           The center matrix of the sandwich expression, used in 
           obtaining score test results. 
        &quot;&quot;&quot;</span>

        <span class="s1">endog = self.endog_li</span>
        <span class="s1">exog = self.exog_li</span>
        <span class="s1">weights = getattr(self</span><span class="s2">, </span><span class="s5">&quot;weights_li&quot;</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">varfunc = self.family.variance</span>
        <span class="s1">cached_means = self.cached_means</span>

        <span class="s3"># Calculate the naive (model-based) and robust (sandwich)</span>
        <span class="s3"># covariances.</span>
        <span class="s1">bmat</span><span class="s2">, </span><span class="s1">cmat = </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">lpr = cached_means[i]</span>
            <span class="s1">resid = endog[i] - expval</span>
            <span class="s1">dmat = self.mean_deriv(exog[i]</span><span class="s2">, </span><span class="s1">lpr)</span>
            <span class="s1">sdev = np.sqrt(varfunc(expval))</span>

            <span class="s2">if </span><span class="s1">weights </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">w = weights[i]</span>
                <span class="s1">wresid = resid * w</span>
                <span class="s1">wdmat = dmat * w[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">wresid = resid</span>
                <span class="s1">wdmat = dmat</span>

            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(wdmat</span><span class="s2">, </span><span class="s1">wresid))</span>
            <span class="s2">if </span><span class="s1">rslt </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return None, None, None, None</span>
            <span class="s1">vinv_d</span><span class="s2">, </span><span class="s1">vinv_resid = tuple(rslt)</span>

            <span class="s1">bmat += np.dot(dmat.T</span><span class="s2">, </span><span class="s1">vinv_d)</span>
            <span class="s1">dvinv_resid = np.dot(dmat.T</span><span class="s2">, </span><span class="s1">vinv_resid)</span>
            <span class="s1">cmat += np.outer(dvinv_resid</span><span class="s2">, </span><span class="s1">dvinv_resid)</span>

        <span class="s1">scale = self.estimate_scale()</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">bmati = np.linalg.inv(bmat)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">bmati = np.linalg.pinv(bmat)</span>

        <span class="s1">cov_naive = bmati * scale</span>
        <span class="s1">cov_robust = np.dot(bmati</span><span class="s2">, </span><span class="s1">np.dot(cmat</span><span class="s2">, </span><span class="s1">bmati))</span>

        <span class="s1">cov_naive *= self.scaling_factor</span>
        <span class="s1">cov_robust *= self.scaling_factor</span>
        <span class="s2">return </span><span class="s1">cov_robust</span><span class="s2">, </span><span class="s1">cov_naive</span><span class="s2">, </span><span class="s1">cmat</span>

    <span class="s3"># Calculate the bias-corrected sandwich estimate of Mancl and</span>
    <span class="s3"># DeRouen.</span>
    <span class="s2">def </span><span class="s1">_bc_covmat(self</span><span class="s2">, </span><span class="s1">cov_naive):</span>

        <span class="s1">cov_naive = cov_naive / self.scaling_factor</span>
        <span class="s1">endog = self.endog_li</span>
        <span class="s1">exog = self.exog_li</span>
        <span class="s1">varfunc = self.family.variance</span>
        <span class="s1">cached_means = self.cached_means</span>
        <span class="s1">scale = self.estimate_scale()</span>

        <span class="s1">bcm = </span><span class="s4">0</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">lpr = cached_means[i]</span>
            <span class="s1">resid = endog[i] - expval</span>
            <span class="s1">dmat = self.mean_deriv(exog[i]</span><span class="s2">, </span><span class="s1">lpr)</span>
            <span class="s1">sdev = np.sqrt(varfunc(expval))</span>

            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(dmat</span><span class="s2">,</span><span class="s1">))</span>
            <span class="s2">if </span><span class="s1">rslt </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return None</span>
            <span class="s1">vinv_d = rslt[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">vinv_d /= scale</span>

            <span class="s1">hmat = np.dot(vinv_d</span><span class="s2">, </span><span class="s1">cov_naive)</span>
            <span class="s1">hmat = np.dot(hmat</span><span class="s2">, </span><span class="s1">dmat.T).T</span>

            <span class="s1">f = self.weights_li[i] </span><span class="s2">if </span><span class="s1">self.weights </span><span class="s2">is not None else </span><span class="s4">1.</span>

            <span class="s1">aresid = np.linalg.solve(np.eye(len(resid)) - hmat</span><span class="s2">, </span><span class="s1">resid)</span>
            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(aresid</span><span class="s2">,</span><span class="s1">))</span>
            <span class="s2">if </span><span class="s1">rslt </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return None</span>
            <span class="s1">srt = rslt[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">srt = f * np.dot(dmat.T</span><span class="s2">, </span><span class="s1">srt) / scale</span>
            <span class="s1">bcm += np.outer(srt</span><span class="s2">, </span><span class="s1">srt)</span>

        <span class="s1">cov_robust_bc = np.dot(cov_naive</span><span class="s2">, </span><span class="s1">np.dot(bcm</span><span class="s2">, </span><span class="s1">cov_naive))</span>
        <span class="s1">cov_robust_bc *= self.scaling_factor</span>

        <span class="s2">return </span><span class="s1">cov_robust_bc</span>

    <span class="s2">def </span><span class="s1">_starting_params(self):</span>

        <span class="s2">if </span><span class="s1">np.isscalar(self._offset_exposure):</span>
            <span class="s1">offset = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">offset = self._offset_exposure</span>

        <span class="s1">model = GLM(self.endog</span><span class="s2">, </span><span class="s1">self.exog</span><span class="s2">, </span><span class="s1">family=self.family</span><span class="s2">,</span>
                    <span class="s1">offset=offset</span><span class="s2">, </span><span class="s1">freq_weights=self.weights)</span>
        <span class="s1">result = model.fit()</span>
        <span class="s2">return </span><span class="s1">result.params</span>

    <span class="s1">@Appender(_gee_fit_doc)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">60</span><span class="s2">, </span><span class="s1">ctol=</span><span class="s4">1e-6</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None,</span>
            <span class="s1">params_niter=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">first_dep_update=</span><span class="s4">0</span><span class="s2">,</span>
            <span class="s1">cov_type=</span><span class="s5">'robust'</span><span class="s2">, </span><span class="s1">ddof_scale=</span><span class="s2">None, </span><span class="s1">scaling_factor=</span><span class="s4">1.</span><span class="s2">,</span>
            <span class="s1">scale=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s1">self.scaletype = scale</span>

        <span class="s3"># Subtract this number from the total sample size when</span>
        <span class="s3"># normalizing the scale parameter estimate.</span>
        <span class="s2">if </span><span class="s1">ddof_scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.ddof_scale = self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">ddof_scale &gt;= </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;ddof_scale must be a non-negative number or None&quot;</span><span class="s1">)</span>
            <span class="s1">self.ddof_scale = ddof_scale</span>

        <span class="s1">self.scaling_factor = scaling_factor</span>

        <span class="s1">self._fit_history = defaultdict(list)</span>

        <span class="s2">if </span><span class="s1">self.weights </span><span class="s2">is not None and </span><span class="s1">cov_type == </span><span class="s5">'naive'</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;when using weights, cov_type may not be naive&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">start_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">mean_params = self._starting_params()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">start_params = np.asarray(start_params)</span>
            <span class="s1">mean_params = start_params.copy()</span>

        <span class="s1">self.update_cached_means(mean_params)</span>

        <span class="s1">del_params = -</span><span class="s4">1.</span>
        <span class="s1">num_assoc_updates = </span><span class="s4">0</span>
        <span class="s2">for </span><span class="s1">itr </span><span class="s2">in </span><span class="s1">range(maxiter):</span>

            <span class="s1">update</span><span class="s2">, </span><span class="s1">score = self._update_mean_params()</span>
            <span class="s2">if </span><span class="s1">update </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">warnings.warn(</span><span class="s5">&quot;Singular matrix encountered in GEE update&quot;</span><span class="s2">,</span>
                              <span class="s1">ConvergenceWarning)</span>
                <span class="s2">break</span>
            <span class="s1">mean_params += update</span>
            <span class="s1">self.update_cached_means(mean_params)</span>

            <span class="s3"># L2 norm of the change in mean structure parameters at</span>
            <span class="s3"># this iteration.</span>
            <span class="s1">del_params = np.sqrt(np.sum(score ** </span><span class="s4">2</span><span class="s1">))</span>

            <span class="s1">self._fit_history[</span><span class="s5">'params'</span><span class="s1">].append(mean_params.copy())</span>
            <span class="s1">self._fit_history[</span><span class="s5">'score'</span><span class="s1">].append(score)</span>
            <span class="s1">self._fit_history[</span><span class="s5">'dep_params'</span><span class="s1">].append(</span>
                <span class="s1">self.cov_struct.dep_params)</span>

            <span class="s3"># Do not exit until the association parameters have been</span>
            <span class="s3"># updated at least once.</span>
            <span class="s2">if </span><span class="s1">(del_params &lt; ctol </span><span class="s2">and</span>
                    <span class="s1">(num_assoc_updates &gt; </span><span class="s4">0 </span><span class="s2">or </span><span class="s1">self.update_dep </span><span class="s2">is False</span><span class="s1">)):</span>
                <span class="s2">break</span>

            <span class="s3"># Update the dependence structure</span>
            <span class="s2">if </span><span class="s1">(self.update_dep </span><span class="s2">and </span><span class="s1">(itr % params_niter) == </span><span class="s4">0</span>
                    <span class="s2">and </span><span class="s1">(itr &gt;= first_dep_update)):</span>
                <span class="s1">self._update_assoc(mean_params)</span>
                <span class="s1">num_assoc_updates += </span><span class="s4">1</span>

        <span class="s2">if </span><span class="s1">del_params &gt;= ctol:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Iteration limit reached prior to convergence&quot;</span><span class="s2">,</span>
                          <span class="s1">IterationLimitWarning)</span>

        <span class="s2">if </span><span class="s1">mean_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Unable to estimate GEE parameters.&quot;</span><span class="s2">,</span>
                          <span class="s1">ConvergenceWarning)</span>
            <span class="s2">return None</span>

        <span class="s1">bcov</span><span class="s2">, </span><span class="s1">ncov</span><span class="s2">, </span><span class="s1">_ = self._covmat()</span>
        <span class="s2">if </span><span class="s1">bcov </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Estimated covariance structure for GEE &quot;</span>
                          <span class="s5">&quot;estimates is singular&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
            <span class="s2">return None</span>
        <span class="s1">bc_cov = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">cov_type == </span><span class="s5">&quot;bias_reduced&quot;</span><span class="s1">:</span>
            <span class="s1">bc_cov = self._bc_covmat(ncov)</span>

        <span class="s2">if </span><span class="s1">self.constraint </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">x = mean_params.copy()</span>
            <span class="s1">mean_params</span><span class="s2">, </span><span class="s1">bcov = self._handle_constraint(mean_params</span><span class="s2">, </span><span class="s1">bcov)</span>
            <span class="s2">if </span><span class="s1">mean_params </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">warnings.warn(</span><span class="s5">&quot;Unable to estimate constrained GEE &quot;</span>
                              <span class="s5">&quot;parameters.&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
                <span class="s2">return None</span>

            <span class="s1">y</span><span class="s2">, </span><span class="s1">ncov = self._handle_constraint(x</span><span class="s2">, </span><span class="s1">ncov)</span>
            <span class="s2">if </span><span class="s1">y </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">warnings.warn(</span><span class="s5">&quot;Unable to estimate constrained GEE &quot;</span>
                              <span class="s5">&quot;parameters.&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
                <span class="s2">return None</span>

            <span class="s2">if </span><span class="s1">bc_cov </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">y</span><span class="s2">, </span><span class="s1">bc_cov = self._handle_constraint(x</span><span class="s2">, </span><span class="s1">bc_cov)</span>
                <span class="s2">if </span><span class="s1">x </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">warnings.warn(</span><span class="s5">&quot;Unable to estimate constrained GEE &quot;</span>
                                  <span class="s5">&quot;parameters.&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
                    <span class="s2">return None</span>

        <span class="s1">scale = self.estimate_scale()</span>

        <span class="s3"># kwargs to add to results instance, need to be available in __init__</span>
        <span class="s1">res_kwds = dict(cov_type=cov_type</span><span class="s2">,</span>
                        <span class="s1">cov_robust=bcov</span><span class="s2">,</span>
                        <span class="s1">cov_naive=ncov</span><span class="s2">,</span>
                        <span class="s1">cov_robust_bc=bc_cov)</span>

        <span class="s3"># The superclass constructor will multiply the covariance</span>
        <span class="s3"># matrix argument bcov by scale, which we do not want, so we</span>
        <span class="s3"># divide bcov by the scale parameter here</span>
        <span class="s1">results = GEEResults(self</span><span class="s2">, </span><span class="s1">mean_params</span><span class="s2">, </span><span class="s1">bcov / scale</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">,</span>
                             <span class="s1">cov_type=cov_type</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False,</span>
                             <span class="s1">attr_kwds=res_kwds)</span>

        <span class="s3"># attributes not needed during results__init__</span>
        <span class="s1">results.fit_history = self._fit_history</span>
        <span class="s1">self.fit_history = defaultdict(list)</span>
        <span class="s1">results.score_norm = del_params</span>
        <span class="s1">results.converged = (del_params &lt; ctol)</span>
        <span class="s1">results.cov_struct = self.cov_struct</span>
        <span class="s1">results.params_niter = params_niter</span>
        <span class="s1">results.first_dep_update = first_dep_update</span>
        <span class="s1">results.ctol = ctol</span>
        <span class="s1">results.maxiter = maxiter</span>

        <span class="s3"># These will be copied over to subclasses when upgrading.</span>
        <span class="s1">results._props = [</span><span class="s5">&quot;cov_type&quot;</span><span class="s2">, </span><span class="s5">&quot;use_t&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;cov_params_default&quot;</span><span class="s2">, </span><span class="s5">&quot;cov_robust&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;cov_naive&quot;</span><span class="s2">, </span><span class="s5">&quot;cov_robust_bc&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;fit_history&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;score_norm&quot;</span><span class="s2">, </span><span class="s5">&quot;converged&quot;</span><span class="s2">, </span><span class="s5">&quot;cov_struct&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;params_niter&quot;</span><span class="s2">, </span><span class="s5">&quot;first_dep_update&quot;</span><span class="s2">, </span><span class="s5">&quot;ctol&quot;</span><span class="s2">,</span>
                          <span class="s5">&quot;maxiter&quot;</span><span class="s1">]</span>

        <span class="s2">return </span><span class="s1">GEEResultsWrapper(results)</span>

    <span class="s2">def </span><span class="s1">_update_regularized(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">pen_wt</span><span class="s2">, </span><span class="s1">scad_param</span><span class="s2">, </span><span class="s1">eps):</span>

        <span class="s1">sn</span><span class="s2">, </span><span class="s1">hm = </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = self.cached_means[i]</span>
            <span class="s1">resid = self.endog_li[i] - expval</span>
            <span class="s1">sdev = np.sqrt(self.family.variance(expval))</span>

            <span class="s1">ex = self.exog_li[i] * sdev[:</span><span class="s2">, None</span><span class="s1">]**</span><span class="s4">2</span>
            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                           <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(resid</span><span class="s2">, </span><span class="s1">ex))</span>
            <span class="s1">sn0 = rslt[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">sn += np.dot(ex.T</span><span class="s2">, </span><span class="s1">sn0)</span>
            <span class="s1">hm0 = rslt[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">hm += np.dot(ex.T</span><span class="s2">, </span><span class="s1">hm0)</span>

        <span class="s3"># Wang et al. divide sn here by num_group, but that</span>
        <span class="s3"># seems to be incorrect</span>

        <span class="s1">ap = np.abs(params)</span>
        <span class="s1">clipped = np.clip(scad_param * pen_wt - ap</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">en = pen_wt * clipped * (ap &gt; pen_wt)</span>
        <span class="s1">en /= (scad_param - </span><span class="s4">1</span><span class="s1">) * pen_wt</span>
        <span class="s1">en += pen_wt * (ap &lt;= pen_wt)</span>
        <span class="s1">en /= eps + ap</span>

        <span class="s1">hm.flat[::hm.shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">] += self.num_group * en</span>
        <span class="s1">sn -= self.num_group * en * params</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">update = np.linalg.solve(hm</span><span class="s2">, </span><span class="s1">sn)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">update = np.dot(np.linalg.pinv(hm)</span><span class="s2">, </span><span class="s1">sn)</span>
            <span class="s1">msg = </span><span class="s5">&quot;Encountered singularity in regularized GEE update&quot;</span>
            <span class="s1">warnings.warn(msg)</span>
        <span class="s1">hm *= self.estimate_scale()</span>

        <span class="s2">return </span><span class="s1">update</span><span class="s2">, </span><span class="s1">hm</span>

    <span class="s2">def </span><span class="s1">_regularized_covmat(self</span><span class="s2">, </span><span class="s1">mean_params):</span>

        <span class="s1">self.update_cached_means(mean_params)</span>

        <span class="s1">ma = </span><span class="s4">0</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = self.cached_means[i]</span>
            <span class="s1">resid = self.endog_li[i] - expval</span>
            <span class="s1">sdev = np.sqrt(self.family.variance(expval))</span>

            <span class="s1">ex = self.exog_li[i] * sdev[:</span><span class="s2">, None</span><span class="s1">]**</span><span class="s4">2</span>
            <span class="s1">rslt = self.cov_struct.covariance_matrix_solve(</span>
                           <span class="s1">expval</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sdev</span><span class="s2">, </span><span class="s1">(resid</span><span class="s2">,</span><span class="s1">))</span>
            <span class="s1">ma0 = np.dot(ex.T</span><span class="s2">, </span><span class="s1">rslt[</span><span class="s4">0</span><span class="s1">])</span>
            <span class="s1">ma += np.outer(ma0</span><span class="s2">, </span><span class="s1">ma0)</span>

        <span class="s2">return </span><span class="s1">ma</span>

    <span class="s2">def </span><span class="s1">fit_regularized(self</span><span class="s2">, </span><span class="s1">pen_wt</span><span class="s2">, </span><span class="s1">scad_param=</span><span class="s4">3.7</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">100</span><span class="s2">,</span>
                        <span class="s1">ddof_scale=</span><span class="s2">None, </span><span class="s1">update_assoc=</span><span class="s4">5</span><span class="s2">,</span>
                        <span class="s1">ctol=</span><span class="s4">1e-5</span><span class="s2">, </span><span class="s1">ztol=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">eps=</span><span class="s4">1e-6</span><span class="s2">, </span><span class="s1">scale=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Regularized estimation for GEE. 
 
        Parameters 
        ---------- 
        pen_wt : float 
            The penalty weight (a non-negative scalar). 
        scad_param : float 
            Non-negative scalar determining the shape of the Scad 
            penalty. 
        maxiter : int 
            The maximum number of iterations. 
        ddof_scale : int 
            Value to subtract from `nobs` when calculating the 
            denominator degrees of freedom for t-statistics, defaults 
            to the number of columns in `exog`. 
        update_assoc : int 
            The dependence parameters are updated every `update_assoc` 
            iterations of the mean structure parameter updates. 
        ctol : float 
            Convergence criterion, default is one order of magnitude 
            smaller than proposed in section 3.1 of Wang et al. 
        ztol : float 
            Coefficients smaller than this value are treated as 
            being zero, default is based on section 5 of Wang et al. 
        eps : non-negative scalar 
            Numerical constant, see section 3.2 of Wang et al. 
        scale : float or string 
            If a float, this value is used as the scale parameter. 
            If &quot;X2&quot;, the scale parameter is always estimated using 
            Pearson's chi-square method (e.g. as in a quasi-Poisson 
            analysis).  If None, the default approach for the family 
            is used to estimate the scale parameter. 
 
        Returns 
        ------- 
        GEEResults instance.  Note that not all methods of the results 
        class make sense when the model has been fit with regularization. 
 
        Notes 
        ----- 
        This implementation assumes that the link is canonical. 
 
        References 
        ---------- 
        Wang L, Zhou J, Qu A. (2012). Penalized generalized estimating 
        equations for high-dimensional longitudinal data analysis. 
        Biometrics. 2012 Jun;68(2):353-60. 
        doi: 10.1111/j.1541-0420.2011.01678.x. 
        https://www.ncbi.nlm.nih.gov/pubmed/21955051 
        http://users.stat.umn.edu/~wangx346/research/GEE_selection.pdf 
        &quot;&quot;&quot;</span>

        <span class="s1">self.scaletype = scale</span>

        <span class="s1">mean_params = np.zeros(self.exog.shape[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">self.update_cached_means(mean_params)</span>
        <span class="s1">converged = </span><span class="s2">False</span>
        <span class="s1">fit_history = defaultdict(list)</span>

        <span class="s3"># Subtract this number from the total sample size when</span>
        <span class="s3"># normalizing the scale parameter estimate.</span>
        <span class="s2">if </span><span class="s1">ddof_scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.ddof_scale = self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">ddof_scale &gt;= </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;ddof_scale must be a non-negative number or None&quot;</span><span class="s1">)</span>
            <span class="s1">self.ddof_scale = ddof_scale</span>

        <span class="s3"># Keep this private for now.  In some cases the early steps are</span>
        <span class="s3"># very small so it seems necessary to ensure a certain minimum</span>
        <span class="s3"># number of iterations before testing for convergence.</span>
        <span class="s1">miniter = </span><span class="s4">20</span>

        <span class="s2">for </span><span class="s1">itr </span><span class="s2">in </span><span class="s1">range(maxiter):</span>

            <span class="s1">update</span><span class="s2">, </span><span class="s1">hm = self._update_regularized(</span>
                              <span class="s1">mean_params</span><span class="s2">, </span><span class="s1">pen_wt</span><span class="s2">, </span><span class="s1">scad_param</span><span class="s2">, </span><span class="s1">eps)</span>
            <span class="s2">if </span><span class="s1">update </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">msg = </span><span class="s5">&quot;Singular matrix encountered in regularized GEE update&quot;</span>
                <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
                <span class="s2">break</span>
            <span class="s2">if </span><span class="s1">itr &gt; miniter </span><span class="s2">and </span><span class="s1">np.sqrt(np.sum(update**</span><span class="s4">2</span><span class="s1">)) &lt; ctol:</span>
                <span class="s1">converged = </span><span class="s2">True</span>
                <span class="s2">break</span>
            <span class="s1">mean_params += update</span>
            <span class="s1">fit_history[</span><span class="s5">'params'</span><span class="s1">].append(mean_params.copy())</span>
            <span class="s1">self.update_cached_means(mean_params)</span>

            <span class="s2">if </span><span class="s1">itr != </span><span class="s4">0 </span><span class="s2">and </span><span class="s1">(itr % update_assoc == </span><span class="s4">0</span><span class="s1">):</span>
                <span class="s1">self._update_assoc(mean_params)</span>

        <span class="s2">if not </span><span class="s1">converged:</span>
            <span class="s1">msg = </span><span class="s5">&quot;GEE.fit_regularized did not converge&quot;</span>
            <span class="s1">warnings.warn(msg)</span>

        <span class="s1">mean_params[np.abs(mean_params) &lt; ztol] = </span><span class="s4">0</span>

        <span class="s1">self._update_assoc(mean_params)</span>
        <span class="s1">ma = self._regularized_covmat(mean_params)</span>
        <span class="s1">cov = np.linalg.solve(hm</span><span class="s2">, </span><span class="s1">ma)</span>
        <span class="s1">cov = np.linalg.solve(hm</span><span class="s2">, </span><span class="s1">cov.T)</span>

        <span class="s3"># kwargs to add to results instance, need to be available in __init__</span>
        <span class="s1">res_kwds = dict(cov_type=</span><span class="s5">&quot;robust&quot;</span><span class="s2">, </span><span class="s1">cov_robust=cov)</span>

        <span class="s1">scale = self.estimate_scale()</span>
        <span class="s1">rslt = GEEResults(self</span><span class="s2">, </span><span class="s1">mean_params</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">,</span>
                          <span class="s1">regularized=</span><span class="s2">True, </span><span class="s1">attr_kwds=res_kwds)</span>
        <span class="s1">rslt.fit_history = fit_history</span>

        <span class="s2">return </span><span class="s1">GEEResultsWrapper(rslt)</span>

    <span class="s2">def </span><span class="s1">_handle_constraint(self</span><span class="s2">, </span><span class="s1">mean_params</span><span class="s2">, </span><span class="s1">bcov):</span>
        <span class="s0">&quot;&quot;&quot; 
        Expand the parameter estimate `mean_params` and covariance matrix 
        `bcov` to the coordinate system of the unconstrained model. 
 
        Parameters 
        ---------- 
        mean_params : array_like 
            A parameter vector estimate for the reduced model. 
        bcov : array_like 
            The covariance matrix of mean_params. 
 
        Returns 
        ------- 
        mean_params : array_like 
            The input parameter vector mean_params, expanded to the 
            coordinate system of the full model 
        bcov : array_like 
            The input covariance matrix bcov, expanded to the 
            coordinate system of the full model 
        &quot;&quot;&quot;</span>

        <span class="s3"># The number of variables in the full model</span>
        <span class="s1">red_p = len(mean_params)</span>
        <span class="s1">full_p = self.constraint.lhs.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">mean_params0 = np.r_[mean_params</span><span class="s2">, </span><span class="s1">np.zeros(full_p - red_p)]</span>

        <span class="s3"># Get the score vector under the full model.</span>
        <span class="s1">save_exog_li = self.exog_li</span>
        <span class="s1">self.exog_li = self.constraint.exog_fulltrans_li</span>
        <span class="s2">import </span><span class="s1">copy</span>
        <span class="s1">save_cached_means = copy.deepcopy(self.cached_means)</span>
        <span class="s1">self.update_cached_means(mean_params0)</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">score = self._update_mean_params()</span>

        <span class="s2">if </span><span class="s1">score </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Singular matrix encountered in GEE score test&quot;</span><span class="s2">,</span>
                          <span class="s1">ConvergenceWarning)</span>
            <span class="s2">return None, None</span>

        <span class="s1">_</span><span class="s2">, </span><span class="s1">ncov1</span><span class="s2">, </span><span class="s1">cmat = self._covmat()</span>
        <span class="s1">scale = self.estimate_scale()</span>
        <span class="s1">cmat = cmat / scale ** </span><span class="s4">2</span>
        <span class="s1">score2 = score[red_p:] / scale</span>
        <span class="s1">amat = np.linalg.inv(ncov1)</span>

        <span class="s1">bmat_11 = cmat[</span><span class="s4">0</span><span class="s1">:red_p</span><span class="s2">, </span><span class="s4">0</span><span class="s1">:red_p]</span>
        <span class="s1">bmat_22 = cmat[red_p:</span><span class="s2">, </span><span class="s1">red_p:]</span>
        <span class="s1">bmat_12 = cmat[</span><span class="s4">0</span><span class="s1">:red_p</span><span class="s2">, </span><span class="s1">red_p:]</span>
        <span class="s1">amat_11 = amat[</span><span class="s4">0</span><span class="s1">:red_p</span><span class="s2">, </span><span class="s4">0</span><span class="s1">:red_p]</span>
        <span class="s1">amat_12 = amat[</span><span class="s4">0</span><span class="s1">:red_p</span><span class="s2">, </span><span class="s1">red_p:]</span>

        <span class="s1">score_cov = bmat_22 - np.dot(amat_12.T</span><span class="s2">,</span>
                                     <span class="s1">np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">bmat_12))</span>
        <span class="s1">score_cov -= np.dot(bmat_12.T</span><span class="s2">,</span>
                            <span class="s1">np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">amat_12))</span>
        <span class="s1">score_cov += np.dot(amat_12.T</span><span class="s2">,</span>
                            <span class="s1">np.dot(np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">bmat_11)</span><span class="s2">,</span>
                                   <span class="s1">np.linalg.solve(amat_11</span><span class="s2">, </span><span class="s1">amat_12)))</span>

        <span class="s2">from </span><span class="s1">scipy.stats.distributions </span><span class="s2">import </span><span class="s1">chi2</span>
        <span class="s1">score_statistic = np.dot(score2</span><span class="s2">,</span>
                                 <span class="s1">np.linalg.solve(score_cov</span><span class="s2">, </span><span class="s1">score2))</span>
        <span class="s1">score_df = len(score2)</span>
        <span class="s1">score_pvalue = </span><span class="s4">1 </span><span class="s1">- chi2.cdf(score_statistic</span><span class="s2">, </span><span class="s1">score_df)</span>
        <span class="s1">self.score_test_results = {</span><span class="s5">&quot;statistic&quot;</span><span class="s1">: score_statistic</span><span class="s2">,</span>
                                   <span class="s5">&quot;df&quot;</span><span class="s1">: score_df</span><span class="s2">,</span>
                                   <span class="s5">&quot;p-value&quot;</span><span class="s1">: score_pvalue}</span>

        <span class="s1">mean_params = self.constraint.unpack_param(mean_params)</span>
        <span class="s1">bcov = self.constraint.unpack_cov(bcov)</span>

        <span class="s1">self.exog_li = save_exog_li</span>
        <span class="s1">self.cached_means = save_cached_means</span>
        <span class="s1">self.exog = self.constraint.restore_exog()</span>

        <span class="s2">return </span><span class="s1">mean_params</span><span class="s2">, </span><span class="s1">bcov</span>

    <span class="s2">def </span><span class="s1">_update_assoc(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Update the association parameters 
        &quot;&quot;&quot;</span>

        <span class="s1">self.cov_struct.update(params)</span>

    <span class="s2">def </span><span class="s1">_derivative_exog(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">transform=</span><span class="s5">'dydx'</span><span class="s2">,</span>
                         <span class="s1">dummy_idx=</span><span class="s2">None, </span><span class="s1">count_idx=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        For computing marginal effects, returns dF(XB) / dX where F(.) 
        is the fitted mean. 
 
        transform can be 'dydx', 'dyex', 'eydx', or 'eyex'. 
 
        Not all of these make sense in the presence of discrete regressors, 
        but checks are done in the results in get_margeff. 
        &quot;&quot;&quot;</span>
        <span class="s3"># This form should be appropriate for group 1 probit, logit,</span>
        <span class="s3"># logistic, cloglog, heckprob, xtprobit.</span>
        <span class="s1">offset_exposure = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">exog </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog = self.exog</span>
            <span class="s1">offset_exposure = self._offset_exposure</span>

        <span class="s1">margeff = self.mean_deriv_exog(exog</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">offset_exposure)</span>

        <span class="s2">if </span><span class="s5">'ex' </span><span class="s2">in </span><span class="s1">transform:</span>
            <span class="s1">margeff *= exog</span>
        <span class="s2">if </span><span class="s5">'ey' </span><span class="s2">in </span><span class="s1">transform:</span>
            <span class="s1">margeff /= self.predict(params</span><span class="s2">, </span><span class="s1">exog)[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">count_idx </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">from </span><span class="s1">statsmodels.discrete.discrete_margins </span><span class="s2">import </span><span class="s1">(</span>
                <span class="s1">_get_count_effects)</span>
            <span class="s1">margeff = _get_count_effects(margeff</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">count_idx</span><span class="s2">, </span><span class="s1">transform</span><span class="s2">,</span>
                                         <span class="s1">self</span><span class="s2">, </span><span class="s1">params)</span>
        <span class="s2">if </span><span class="s1">dummy_idx </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">from </span><span class="s1">statsmodels.discrete.discrete_margins </span><span class="s2">import </span><span class="s1">(</span>
                <span class="s1">_get_dummy_effects)</span>
            <span class="s1">margeff = _get_dummy_effects(margeff</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">dummy_idx</span><span class="s2">, </span><span class="s1">transform</span><span class="s2">,</span>
                                         <span class="s1">self</span><span class="s2">, </span><span class="s1">params)</span>
        <span class="s2">return </span><span class="s1">margeff</span>

    <span class="s2">def </span><span class="s1">qic(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">, </span><span class="s1">cov_params</span><span class="s2">, </span><span class="s1">n_step=</span><span class="s4">1000</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns quasi-information criteria and quasi-likelihood values. 
 
        Parameters 
        ---------- 
        params : array_like 
            The GEE estimates of the regression parameters. 
        scale : scalar 
            Estimated scale parameter 
        cov_params : array_like 
            An estimate of the covariance matrix for the 
            model parameters.  Conventionally this is the robust 
            covariance matrix. 
        n_step : integer 
            The number of points in the trapezoidal approximation 
            to the quasi-likelihood function. 
 
        Returns 
        ------- 
        ql : scalar 
            The quasi-likelihood value 
        qic : scalar 
            A QIC that can be used to compare the mean and covariance 
            structures of the model. 
        qicu : scalar 
            A simplified QIC that can be used to compare mean structures 
            but not covariance structures 
 
        Notes 
        ----- 
        The quasi-likelihood used here is obtained by numerically evaluating 
        Wedderburn's integral representation of the quasi-likelihood function. 
        This approach is valid for all families and  links.  Many other 
        packages use analytical expressions for quasi-likelihoods that are 
        valid in special cases where the link function is canonical.  These 
        analytical expressions may omit additive constants that only depend 
        on the data.  Therefore, the numerical values of our QL and QIC values 
        will differ from the values reported by other packages.  However only 
        the differences between two QIC values calculated for different models 
        using the same data are meaningful.  Our QIC should produce the same 
        QIC differences as other software. 
 
        When using the QIC for models with unknown scale parameter, use a 
        common estimate of the scale parameter for all models being compared. 
 
        References 
        ---------- 
        .. [*] W. Pan (2001).  Akaike's information criterion in generalized 
               estimating equations.  Biometrics (57) 1. 
        &quot;&quot;&quot;</span>

        <span class="s1">varfunc = self.family.variance</span>

        <span class="s1">means = []</span>
        <span class="s1">omega = </span><span class="s4">0.0</span>
        <span class="s3"># omega^-1 is the model-based covariance assuming independence</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_group):</span>
            <span class="s1">expval</span><span class="s2">, </span><span class="s1">lpr = self.cached_means[i]</span>
            <span class="s1">means.append(expval)</span>
            <span class="s1">dmat = self.mean_deriv(self.exog_li[i]</span><span class="s2">, </span><span class="s1">lpr)</span>
            <span class="s1">omega += np.dot(dmat.T</span><span class="s2">, </span><span class="s1">dmat) / scale</span>

        <span class="s1">means = np.concatenate(means)</span>

        <span class="s3"># The quasi-likelihood, use change of variables so the integration is</span>
        <span class="s3"># from -1 to 1.</span>
        <span class="s1">endog_li = np.concatenate(self.endog_li)</span>
        <span class="s1">du = means - endog_li</span>
        <span class="s1">qv = np.empty(n_step)</span>
        <span class="s1">xv = np.linspace(-</span><span class="s4">0.99999</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_step)</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">g </span><span class="s2">in </span><span class="s1">enumerate(xv):</span>
            <span class="s1">u = endog_li + (g + </span><span class="s4">1</span><span class="s1">) * du / </span><span class="s4">2.0</span>
            <span class="s1">vu = varfunc(u)</span>
            <span class="s1">qv[i] = -np.sum(du**</span><span class="s4">2 </span><span class="s1">* (g + </span><span class="s4">1</span><span class="s1">) / vu)</span>
        <span class="s1">qv /= (</span><span class="s4">4 </span><span class="s1">* scale)</span>

        <span class="s2">from </span><span class="s1">scipy.integrate </span><span class="s2">import </span><span class="s1">trapz</span>
        <span class="s1">ql = trapz(qv</span><span class="s2">, </span><span class="s1">dx=xv[</span><span class="s4">1</span><span class="s1">] - xv[</span><span class="s4">0</span><span class="s1">])</span>

        <span class="s1">qicu = -</span><span class="s4">2 </span><span class="s1">* ql + </span><span class="s4">2 </span><span class="s1">* self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">qic = -</span><span class="s4">2 </span><span class="s1">* ql + </span><span class="s4">2 </span><span class="s1">* np.trace(np.dot(omega</span><span class="s2">, </span><span class="s1">cov_params))</span>

        <span class="s2">return </span><span class="s1">ql</span><span class="s2">, </span><span class="s1">qic</span><span class="s2">, </span><span class="s1">qicu</span>


<span class="s2">class </span><span class="s1">GEEResults(GLMResults):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;This class summarizes the fit of a marginal regression model &quot;</span>
        <span class="s5">&quot;using GEE.</span><span class="s2">\n</span><span class="s5">&quot; </span><span class="s1">+ _gee_results_doc)</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">cov_params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">,</span>
                 <span class="s1">cov_type=</span><span class="s5">'robust'</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False, </span><span class="s1">regularized=</span><span class="s2">False,</span>
                 <span class="s1">**kwds):</span>

        <span class="s1">super(GEEResults</span><span class="s2">, </span><span class="s1">self).__init__(</span>
            <span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">normalized_cov_params=cov_params</span><span class="s2">,</span>
            <span class="s1">scale=scale)</span>

        <span class="s3"># not added by super</span>
        <span class="s1">self.df_resid = model.df_resid</span>
        <span class="s1">self.df_model = model.df_model</span>
        <span class="s1">self.family = model.family</span>

        <span class="s1">attr_kwds = kwds.pop(</span><span class="s5">'attr_kwds'</span><span class="s2">, </span><span class="s1">{})</span>
        <span class="s1">self.__dict__.update(attr_kwds)</span>

        <span class="s3"># we do not do this if the cov_type has already been set</span>
        <span class="s3"># subclasses can set it through attr_kwds</span>
        <span class="s2">if not </span><span class="s1">(hasattr(self</span><span class="s2">, </span><span class="s5">'cov_type'</span><span class="s1">) </span><span class="s2">and</span>
                <span class="s1">hasattr(self</span><span class="s2">, </span><span class="s5">'cov_params_default'</span><span class="s1">)):</span>
            <span class="s1">self.cov_type = cov_type  </span><span class="s3"># keep alias</span>
            <span class="s1">covariance_type = self.cov_type.lower()</span>
            <span class="s1">allowed_covariances = [</span><span class="s5">&quot;robust&quot;</span><span class="s2">, </span><span class="s5">&quot;naive&quot;</span><span class="s2">, </span><span class="s5">&quot;bias_reduced&quot;</span><span class="s1">]</span>
            <span class="s2">if </span><span class="s1">covariance_type </span><span class="s2">not in </span><span class="s1">allowed_covariances:</span>
                <span class="s1">msg = (</span><span class="s5">&quot;GEE: `cov_type` must be one of &quot; </span><span class="s1">+</span>
                       <span class="s5">&quot;, &quot;</span><span class="s1">.join(allowed_covariances))</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

            <span class="s2">if </span><span class="s1">cov_type == </span><span class="s5">&quot;robust&quot;</span><span class="s1">:</span>
                <span class="s1">cov = self.cov_robust</span>
            <span class="s2">elif </span><span class="s1">cov_type == </span><span class="s5">&quot;naive&quot;</span><span class="s1">:</span>
                <span class="s1">cov = self.cov_naive</span>
            <span class="s2">elif </span><span class="s1">cov_type == </span><span class="s5">&quot;bias_reduced&quot;</span><span class="s1">:</span>
                <span class="s1">cov = self.cov_robust_bc</span>

            <span class="s1">self.cov_params_default = cov</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.cov_type != cov_type:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">'cov_type in argument is different from '</span>
                                 <span class="s5">'already attached cov_type'</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        The response residuals. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.resid_response</span>

    <span class="s2">def </span><span class="s1">standard_errors(self</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s5">&quot;robust&quot;</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        This is a convenience function that returns the standard 
        errors for any covariance type.  The value of `bse` is the 
        standard errors for whichever covariance type is specified as 
        an argument to `fit` (defaults to &quot;robust&quot;). 
 
        Parameters 
        ---------- 
        cov_type : str 
            One of &quot;robust&quot;, &quot;naive&quot;, or &quot;bias_reduced&quot;.  Determines 
            the covariance used to compute standard errors.  Defaults 
            to &quot;robust&quot;. 
        &quot;&quot;&quot;</span>

        <span class="s3"># Check covariance_type</span>
        <span class="s1">covariance_type = cov_type.lower()</span>
        <span class="s1">allowed_covariances = [</span><span class="s5">&quot;robust&quot;</span><span class="s2">, </span><span class="s5">&quot;naive&quot;</span><span class="s2">, </span><span class="s5">&quot;bias_reduced&quot;</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">covariance_type </span><span class="s2">not in </span><span class="s1">allowed_covariances:</span>
            <span class="s1">msg = (</span><span class="s5">&quot;GEE: `covariance_type` must be one of &quot; </span><span class="s1">+</span>
                   <span class="s5">&quot;, &quot;</span><span class="s1">.join(allowed_covariances))</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">if </span><span class="s1">covariance_type == </span><span class="s5">&quot;robust&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.sqrt(np.diag(self.cov_robust))</span>
        <span class="s2">elif </span><span class="s1">covariance_type == </span><span class="s5">&quot;naive&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.sqrt(np.diag(self.cov_naive))</span>
        <span class="s2">elif </span><span class="s1">covariance_type == </span><span class="s5">&quot;bias_reduced&quot;</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.cov_robust_bc </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;GEE: `bias_reduced` covariance not available&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">np.sqrt(np.diag(self.cov_robust_bc))</span>

    <span class="s3"># Need to override to allow for different covariance types.</span>
    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bse(self):</span>
        <span class="s2">return </span><span class="s1">self.standard_errors(self.cov_type)</span>

    <span class="s2">def </span><span class="s1">score_test(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the results of a score test for a linear constraint. 
 
        Returns 
        ------- 
        Adictionary containing the p-value, the test statistic, 
        and the degrees of freedom for the score test. 
 
        Notes 
        ----- 
        See also GEE.compare_score_test for an alternative way to perform 
        a score test.  GEEResults.score_test is more general, in that it 
        supports testing arbitrary linear equality constraints.   However 
        GEE.compare_score_test might be easier to use when comparing 
        two explicit models. 
 
        References 
        ---------- 
        Xu Guo and Wei Pan (2002). &quot;Small sample performance of the score 
        test in GEE&quot;. 
        http://www.sph.umn.edu/faculty1/wp-content/uploads/2012/11/rr2002-013.pdf 
        &quot;&quot;&quot;</span>

        <span class="s2">if not </span><span class="s1">hasattr(self.model</span><span class="s2">, </span><span class="s5">&quot;score_test_results&quot;</span><span class="s1">):</span>
            <span class="s1">msg = </span><span class="s5">&quot;score_test on results instance only available when &quot;</span>
            <span class="s1">msg += </span><span class="s5">&quot; model was fit with constraints&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">return </span><span class="s1">self.model.score_test_results</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid_split(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the residuals, the endogeneous data minus the fitted 
        values from the model.  The residuals are returned as a list 
        of arrays containing the residuals for each cluster. 
        &quot;&quot;&quot;</span>
        <span class="s1">sresid = []</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.model.group_labels:</span>
            <span class="s1">ii = self.model.group_indices[v]</span>
            <span class="s1">sresid.append(self.resid[ii])</span>
        <span class="s2">return </span><span class="s1">sresid</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid_centered(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the residuals centered within each group. 
        &quot;&quot;&quot;</span>
        <span class="s1">cresid = self.resid.copy()</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.model.group_labels:</span>
            <span class="s1">ii = self.model.group_indices[v]</span>
            <span class="s1">cresid[ii] -= cresid[ii].mean()</span>
        <span class="s2">return </span><span class="s1">cresid</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid_centered_split(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the residuals centered within each group.  The 
        residuals are returned as a list of arrays containing the 
        centered residuals for each cluster. 
        &quot;&quot;&quot;</span>
        <span class="s1">sresid = []</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.model.group_labels:</span>
            <span class="s1">ii = self.model.group_indices[v]</span>
            <span class="s1">sresid.append(self.centered_resid[ii])</span>
        <span class="s2">return </span><span class="s1">sresid</span>

    <span class="s2">def </span><span class="s1">qic(self</span><span class="s2">, </span><span class="s1">scale=</span><span class="s2">None, </span><span class="s1">n_step=</span><span class="s4">1000</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the QIC and QICu information criteria. 
 
        See GEE.qic for documentation. 
        &quot;&quot;&quot;</span>

        <span class="s3"># It is easy to forget to set the scale parameter.  Sometimes</span>
        <span class="s3"># this is intentional, so we warn.</span>
        <span class="s2">if </span><span class="s1">scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;QIC values obtained using scale=None are not &quot;</span>
                          <span class="s5">&quot;appropriate for comparing models&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">scale </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">scale = self.scale</span>

        <span class="s1">_</span><span class="s2">, </span><span class="s1">qic</span><span class="s2">, </span><span class="s1">qicu = self.model.qic(self.params</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">,</span>
                                      <span class="s1">self.cov_params()</span><span class="s2">,</span>
                                      <span class="s1">n_step=n_step)</span>

        <span class="s2">return </span><span class="s1">qic</span><span class="s2">, </span><span class="s1">qicu</span>

    <span class="s3"># FIXME: alias to be removed, temporary backwards compatibility</span>
    <span class="s1">split_resid = resid_split</span>
    <span class="s1">centered_resid = resid_centered</span>
    <span class="s1">split_centered_resid = resid_centered_split</span>

    <span class="s1">@Appender(_plot_added_variable_doc % {</span><span class="s5">'extra_params_doc'</span><span class="s1">: </span><span class="s5">''</span><span class="s1">})</span>
    <span class="s2">def </span><span class="s1">plot_added_variable(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">, </span><span class="s1">resid_type=</span><span class="s2">None,</span>
                            <span class="s1">use_glm_weights=</span><span class="s2">True, </span><span class="s1">fit_kwargs=</span><span class="s2">None,</span>
                            <span class="s1">ax=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics.regressionplots </span><span class="s2">import </span><span class="s1">plot_added_variable</span>

        <span class="s1">fig = plot_added_variable(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">,</span>
                                  <span class="s1">resid_type=resid_type</span><span class="s2">,</span>
                                  <span class="s1">use_glm_weights=use_glm_weights</span><span class="s2">,</span>
                                  <span class="s1">fit_kwargs=fit_kwargs</span><span class="s2">, </span><span class="s1">ax=ax)</span>

        <span class="s2">return </span><span class="s1">fig</span>

    <span class="s1">@Appender(_plot_partial_residuals_doc % {</span><span class="s5">'extra_params_doc'</span><span class="s1">: </span><span class="s5">''</span><span class="s1">})</span>
    <span class="s2">def </span><span class="s1">plot_partial_residuals(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">, </span><span class="s1">ax=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics.regressionplots </span><span class="s2">import </span><span class="s1">plot_partial_residuals</span>

        <span class="s2">return </span><span class="s1">plot_partial_residuals(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">, </span><span class="s1">ax=ax)</span>

    <span class="s1">@Appender(_plot_ceres_residuals_doc % {</span><span class="s5">'extra_params_doc'</span><span class="s1">: </span><span class="s5">''</span><span class="s1">})</span>
    <span class="s2">def </span><span class="s1">plot_ceres_residuals(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">, </span><span class="s1">frac=</span><span class="s4">0.66</span><span class="s2">, </span><span class="s1">cond_means=</span><span class="s2">None,</span>
                             <span class="s1">ax=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics.regressionplots </span><span class="s2">import </span><span class="s1">plot_ceres_residuals</span>

        <span class="s2">return </span><span class="s1">plot_ceres_residuals(self</span><span class="s2">, </span><span class="s1">focus_exog</span><span class="s2">, </span><span class="s1">frac</span><span class="s2">,</span>
                                    <span class="s1">cond_means=cond_means</span><span class="s2">, </span><span class="s1">ax=ax)</span>

    <span class="s2">def </span><span class="s1">conf_int(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s2">, </span><span class="s1">cols=</span><span class="s2">None, </span><span class="s1">cov_type=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns confidence intervals for the fitted parameters. 
 
        Parameters 
        ---------- 
        alpha : float, optional 
             The `alpha` level for the confidence interval.  i.e., The 
             default `alpha` = .05 returns a 95% confidence interval. 
        cols : array_like, optional 
             `cols` specifies which confidence intervals to return 
        cov_type : str 
             The covariance type used for computing standard errors; 
             must be one of 'robust', 'naive', and 'bias reduced'. 
             See `GEE` for details. 
 
        Notes 
        ----- 
        The confidence interval is based on the Gaussian distribution. 
        &quot;&quot;&quot;</span>
        <span class="s3"># super does not allow to specify cov_type and method is not</span>
        <span class="s3"># implemented,</span>
        <span class="s3"># FIXME: remove this method here</span>
        <span class="s2">if </span><span class="s1">cov_type </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">bse = self.bse</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">bse = self.standard_errors(cov_type=cov_type)</span>
        <span class="s1">params = self.params</span>
        <span class="s1">dist = stats.norm</span>
        <span class="s1">q = dist.ppf(</span><span class="s4">1 </span><span class="s1">- alpha / </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">cols </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lower = self.params - q * bse</span>
            <span class="s1">upper = self.params + q * bse</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cols = np.asarray(cols)</span>
            <span class="s1">lower = params[cols] - q * bse[cols]</span>
            <span class="s1">upper = params[cols] + q * bse[cols]</span>
        <span class="s2">return </span><span class="s1">np.asarray(lzip(lower</span><span class="s2">, </span><span class="s1">upper))</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">yname=</span><span class="s2">None, </span><span class="s1">xname=</span><span class="s2">None, </span><span class="s1">title=</span><span class="s2">None, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Summarize the GEE regression results 
 
        Parameters 
        ---------- 
        yname : str, optional 
            Default is `y` 
        xname : list[str], optional 
            Names for the exogenous variables, default is `var_#` for ## in 
            the number of regressors. Must match the number of parameters in 
            the model 
        title : str, optional 
            Title for the top table. If not None, then this replaces 
            the default title 
        alpha : float 
            significance level for the confidence intervals 
        cov_type : str 
            The covariance type used to compute the standard errors; 
            one of 'robust' (the usual robust sandwich-type covariance 
            estimate), 'naive' (ignores dependence), and 'bias 
            reduced' (the Mancl/DeRouen estimate). 
 
        Returns 
        ------- 
        smry : Summary instance 
            this holds the summary tables and text, which can be 
            printed or converted to various output formats. 
 
        See Also 
        -------- 
        statsmodels.iolib.summary.Summary : class to hold summary results 
        &quot;&quot;&quot;</span>

        <span class="s1">top_left = [(</span><span class="s5">'Dep. Variable:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Model:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Method:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">'Generalized'</span><span class="s1">])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">''</span><span class="s2">, </span><span class="s1">[</span><span class="s5">'Estimating Equations'</span><span class="s1">])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Family:'</span><span class="s2">, </span><span class="s1">[self.model.family.__class__.__name__])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Dependence structure:'</span><span class="s2">,</span>
                     <span class="s1">[self.model.cov_struct.__class__.__name__])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Date:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Covariance type: '</span><span class="s2">, </span><span class="s1">[self.cov_type</span><span class="s2">, </span><span class="s1">])</span>
                    <span class="s1">]</span>

        <span class="s1">NY = [len(y) </span><span class="s2">for </span><span class="s1">y </span><span class="s2">in </span><span class="s1">self.model.endog_li]</span>

        <span class="s1">top_right = [(</span><span class="s5">'No. Observations:'</span><span class="s2">, </span><span class="s1">[sum(NY)])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'No. clusters:'</span><span class="s2">, </span><span class="s1">[len(self.model.endog_li)])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Min. cluster size:'</span><span class="s2">, </span><span class="s1">[min(NY)])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Max. cluster size:'</span><span class="s2">, </span><span class="s1">[max(NY)])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Mean cluster size:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%.1f&quot; </span><span class="s1">% np.mean(NY)])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Num. iterations:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">'%d' </span><span class="s1">%</span>
                                           <span class="s1">len(self.fit_history[</span><span class="s5">'params'</span><span class="s1">])])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Scale:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%.3f&quot; </span><span class="s1">% self.scale])</span><span class="s2">,</span>
                     <span class="s1">(</span><span class="s5">'Time:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
                     <span class="s1">]</span>

        <span class="s3"># The skew of the residuals</span>
        <span class="s1">skew1 = stats.skew(self.resid)</span>
        <span class="s1">kurt1 = stats.kurtosis(self.resid)</span>
        <span class="s1">skew2 = stats.skew(self.centered_resid)</span>
        <span class="s1">kurt2 = stats.kurtosis(self.centered_resid)</span>

        <span class="s1">diagn_left = [(</span><span class="s5">'Skew:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%12.4f&quot; </span><span class="s1">% skew1])</span><span class="s2">,</span>
                      <span class="s1">(</span><span class="s5">'Centered skew:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%12.4f&quot; </span><span class="s1">% skew2])]</span>

        <span class="s1">diagn_right = [(</span><span class="s5">'Kurtosis:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%12.4f&quot; </span><span class="s1">% kurt1])</span><span class="s2">,</span>
                       <span class="s1">(</span><span class="s5">'Centered kurtosis:'</span><span class="s2">, </span><span class="s1">[</span><span class="s5">&quot;%12.4f&quot; </span><span class="s1">% kurt2])</span>
                       <span class="s1">]</span>

        <span class="s2">if </span><span class="s1">title </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">title = self.model.__class__.__name__ + </span><span class="s5">' ' </span><span class="s1">+\</span>
                <span class="s5">&quot;Regression Results&quot;</span>

        <span class="s3"># Override the exog variable names if xname is provided as an</span>
        <span class="s3"># argument.</span>
        <span class="s2">if </span><span class="s1">xname </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">xname = self.model.exog_names</span>

        <span class="s2">if </span><span class="s1">yname </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">yname = self.model.endog_names</span>

        <span class="s3"># Create summary table instance</span>
        <span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">Summary</span>
        <span class="s1">smry = Summary()</span>
        <span class="s1">smry.add_table_2cols(self</span><span class="s2">, </span><span class="s1">gleft=top_left</span><span class="s2">, </span><span class="s1">gright=top_right</span><span class="s2">,</span>
                             <span class="s1">yname=yname</span><span class="s2">, </span><span class="s1">xname=xname</span><span class="s2">,</span>
                             <span class="s1">title=title)</span>
        <span class="s1">smry.add_table_params(self</span><span class="s2">, </span><span class="s1">yname=yname</span><span class="s2">, </span><span class="s1">xname=xname</span><span class="s2">,</span>
                              <span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">smry.add_table_2cols(self</span><span class="s2">, </span><span class="s1">gleft=diagn_left</span><span class="s2">,</span>
                             <span class="s1">gright=diagn_right</span><span class="s2">, </span><span class="s1">yname=yname</span><span class="s2">,</span>
                             <span class="s1">xname=xname</span><span class="s2">, </span><span class="s1">title=</span><span class="s5">&quot;&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">smry</span>

    <span class="s2">def </span><span class="s1">get_margeff(self</span><span class="s2">, </span><span class="s1">at=</span><span class="s5">'overall'</span><span class="s2">, </span><span class="s1">method=</span><span class="s5">'dydx'</span><span class="s2">, </span><span class="s1">atexog=</span><span class="s2">None,</span>
                    <span class="s1">dummy=</span><span class="s2">False, </span><span class="s1">count=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot;Get marginal effects of the fitted model. 
 
        Parameters 
        ---------- 
        at : str, optional 
            Options are: 
 
            - 'overall', The average of the marginal effects at each 
              observation. 
            - 'mean', The marginal effects at the mean of each regressor. 
            - 'median', The marginal effects at the median of each regressor. 
            - 'zero', The marginal effects at zero for each regressor. 
            - 'all', The marginal effects at each observation. If `at` is 'all' 
              only margeff will be available. 
 
            Note that if `exog` is specified, then marginal effects for all 
            variables not specified by `exog` are calculated using the `at` 
            option. 
        method : str, optional 
            Options are: 
 
            - 'dydx' - dy/dx - No transformation is made and marginal effects 
              are returned.  This is the default. 
            - 'eyex' - estimate elasticities of variables in `exog` -- 
              d(lny)/d(lnx) 
            - 'dyex' - estimate semi-elasticity -- dy/d(lnx) 
            - 'eydx' - estimate semi-elasticity -- d(lny)/dx 
 
            Note that tranformations are done after each observation is 
            calculated.  Semi-elasticities for binary variables are computed 
            using the midpoint method. 'dyex' and 'eyex' do not make sense 
            for discrete variables. 
        atexog : array_like, optional 
            Optionally, you can provide the exogenous variables over which to 
            get the marginal effects.  This should be a dictionary with the key 
            as the zero-indexed column number and the value of the dictionary. 
            Default is None for all independent variables less the constant. 
        dummy : bool, optional 
            If False, treats binary variables (if present) as continuous.  This 
            is the default.  Else if True, treats binary variables as 
            changing from 0 to 1.  Note that any variable that is either 0 or 1 
            is treated as binary.  Each binary variable is treated separately 
            for now. 
        count : bool, optional 
            If False, treats count variables (if present) as continuous.  This 
            is the default.  Else if True, the marginal effect is the 
            change in probabilities when each observation is increased by one. 
 
        Returns 
        ------- 
        effects : ndarray 
            the marginal effect corresponding to the input options 
 
        Notes 
        ----- 
        When using after Poisson, returns the expected number of events 
        per period, assuming that the model is loglinear. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.model.constraint </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;marginal effects ignore constraints&quot;</span><span class="s2">,</span>
                          <span class="s1">ValueWarning)</span>

        <span class="s2">return </span><span class="s1">GEEMargins(self</span><span class="s2">, </span><span class="s1">(at</span><span class="s2">, </span><span class="s1">method</span><span class="s2">, </span><span class="s1">atexog</span><span class="s2">, </span><span class="s1">dummy</span><span class="s2">, </span><span class="s1">count))</span>

    <span class="s2">def </span><span class="s1">plot_isotropic_dependence(self</span><span class="s2">, </span><span class="s1">ax=</span><span class="s2">None, </span><span class="s1">xpoints=</span><span class="s4">10</span><span class="s2">,</span>
                                  <span class="s1">min_n=</span><span class="s4">50</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create a plot of the pairwise products of within-group 
        residuals against the corresponding time differences.  This 
        plot can be used to assess the possible form of an isotropic 
        covariance structure. 
 
        Parameters 
        ---------- 
        ax : AxesSubplot 
            An axes on which to draw the graph.  If None, new 
            figure and axes objects are created 
        xpoints : scalar or array_like 
            If scalar, the number of points equally spaced points on 
            the time difference axis used to define bins for 
            calculating local means.  If an array, the specific points 
            that define the bins. 
        min_n : int 
            The minimum sample size in a bin for the mean residual 
            product to be included on the plot. 
        &quot;&quot;&quot;</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics </span><span class="s2">import </span><span class="s1">utils </span><span class="s2">as </span><span class="s1">gutils</span>

        <span class="s1">resid = self.model.cluster_list(self.resid)</span>
        <span class="s1">time = self.model.cluster_list(self.model.time)</span>

        <span class="s3"># All within-group pairwise time distances (xdt) and the</span>
        <span class="s3"># corresponding products of scaled residuals (xre).</span>
        <span class="s1">xre</span><span class="s2">, </span><span class="s1">xdt = []</span><span class="s2">, </span><span class="s1">[]</span>
        <span class="s2">for </span><span class="s1">re</span><span class="s2">, </span><span class="s1">ti </span><span class="s2">in </span><span class="s1">zip(resid</span><span class="s2">, </span><span class="s1">time):</span>
            <span class="s1">ix = np.tril_indices(re.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">re = re[ix[</span><span class="s4">0</span><span class="s1">]] * re[ix[</span><span class="s4">1</span><span class="s1">]] / self.scale ** </span><span class="s4">2</span>
            <span class="s1">xre.append(re)</span>
            <span class="s1">dists = np.sqrt(((ti[ix[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">:] - ti[ix[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">:]) ** </span><span class="s4">2</span><span class="s1">).sum(</span><span class="s4">1</span><span class="s1">))</span>
            <span class="s1">xdt.append(dists)</span>

        <span class="s1">xre = np.concatenate(xre)</span>
        <span class="s1">xdt = np.concatenate(xdt)</span>

        <span class="s2">if </span><span class="s1">ax </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">fig</span><span class="s2">, </span><span class="s1">ax = gutils.create_mpl_ax(ax)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fig = ax.get_figure()</span>

        <span class="s3"># Convert to a correlation</span>
        <span class="s1">ii = np.flatnonzero(xdt == </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">v0 = np.mean(xre[ii])</span>
        <span class="s1">xre /= v0</span>

        <span class="s3"># Use the simple average to smooth, since fancier smoothers</span>
        <span class="s3"># that trim and downweight outliers give biased results (we</span>
        <span class="s3"># need the actual mean of a skewed distribution).</span>
        <span class="s2">if </span><span class="s1">np.isscalar(xpoints):</span>
            <span class="s1">xpoints = np.linspace(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">max(xdt)</span><span class="s2">, </span><span class="s1">xpoints)</span>
        <span class="s1">dg = np.digitize(xdt</span><span class="s2">, </span><span class="s1">xpoints)</span>
        <span class="s1">dgu = np.unique(dg)</span>
        <span class="s1">hist = np.asarray([np.sum(dg == k) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">dgu])</span>
        <span class="s1">ii = np.flatnonzero(hist &gt;= min_n)</span>
        <span class="s1">dgu = dgu[ii]</span>
        <span class="s1">dgy = np.asarray([np.mean(xre[dg == k]) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">dgu])</span>
        <span class="s1">dgx = np.asarray([np.mean(xdt[dg == k]) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">dgu])</span>

        <span class="s1">ax.plot(dgx</span><span class="s2">, </span><span class="s1">dgy</span><span class="s2">, </span><span class="s5">'-'</span><span class="s2">, </span><span class="s1">color=</span><span class="s5">'orange'</span><span class="s2">, </span><span class="s1">lw=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">ax.set_xlabel(</span><span class="s5">&quot;Time difference&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_ylabel(</span><span class="s5">&quot;Product of scaled residuals&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>

    <span class="s2">def </span><span class="s1">sensitivity_params(self</span><span class="s2">, </span><span class="s1">dep_params_first</span><span class="s2">,</span>
                           <span class="s1">dep_params_last</span><span class="s2">, </span><span class="s1">num_steps):</span>
        <span class="s0">&quot;&quot;&quot; 
        Refits the GEE model using a sequence of values for the 
        dependence parameters. 
 
        Parameters 
        ---------- 
        dep_params_first : array_like 
            The first dep_params in the sequence 
        dep_params_last : array_like 
            The last dep_params in the sequence 
        num_steps : int 
            The number of dep_params in the sequence 
 
        Returns 
        ------- 
        results : array_like 
            The GEEResults objects resulting from the fits. 
        &quot;&quot;&quot;</span>

        <span class="s1">model = self.model</span>

        <span class="s2">import </span><span class="s1">copy</span>
        <span class="s1">cov_struct = copy.deepcopy(self.model.cov_struct)</span>

        <span class="s3"># We are fixing the dependence structure in each run.</span>
        <span class="s1">update_dep = model.update_dep</span>
        <span class="s1">model.update_dep = </span><span class="s2">False</span>

        <span class="s1">dep_params = []</span>
        <span class="s1">results = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">np.linspace(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">num_steps):</span>

            <span class="s1">dp = x * dep_params_last + (</span><span class="s4">1 </span><span class="s1">- x) * dep_params_first</span>
            <span class="s1">dep_params.append(dp)</span>

            <span class="s1">model.cov_struct = copy.deepcopy(cov_struct)</span>
            <span class="s1">model.cov_struct.dep_params = dp</span>
            <span class="s1">rslt = model.fit(start_params=self.params</span><span class="s2">,</span>
                             <span class="s1">ctol=self.ctol</span><span class="s2">,</span>
                             <span class="s1">params_niter=self.params_niter</span><span class="s2">,</span>
                             <span class="s1">first_dep_update=self.first_dep_update</span><span class="s2">,</span>
                             <span class="s1">cov_type=self.cov_type)</span>
            <span class="s1">results.append(rslt)</span>

        <span class="s1">model.update_dep = update_dep</span>

        <span class="s2">return </span><span class="s1">results</span>

    <span class="s3"># FIXME: alias to be removed, temporary backwards compatibility</span>
    <span class="s1">params_sensitivity = sensitivity_params</span>


<span class="s2">class </span><span class="s1">GEEResultsWrapper(lm.RegressionResultsWrapper):</span>
    <span class="s1">_attrs = {</span>
        <span class="s5">'centered_resid'</span><span class="s1">: </span><span class="s5">'rows'</span><span class="s2">,</span>
    <span class="s1">}</span>
    <span class="s1">_wrap_attrs = wrap.union_dicts(lm.RegressionResultsWrapper._wrap_attrs</span><span class="s2">,</span>
                                   <span class="s1">_attrs)</span>
<span class="s1">wrap.populate_wrapper(GEEResultsWrapper</span><span class="s2">, </span><span class="s1">GEEResults)  </span><span class="s3"># noqa:E305</span>


<span class="s2">class </span><span class="s1">OrdinalGEE(GEE):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;    Ordinal Response Marginal Regression Model using GEE</span><span class="s2">\n</span><span class="s5">&quot; </span><span class="s1">+</span>
        <span class="s1">_gee_init_doc % {</span><span class="s5">'extra_params'</span><span class="s1">: base._missing_param_doc</span><span class="s2">,</span>
                         <span class="s5">'family_doc'</span><span class="s1">: _gee_ordinal_family_doc</span><span class="s2">,</span>
                         <span class="s5">'example'</span><span class="s1">: _gee_ordinal_example</span><span class="s2">,</span>
                         <span class="s5">'notes'</span><span class="s1">: _gee_nointercept})</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time=</span><span class="s2">None, </span><span class="s1">family=</span><span class="s2">None,</span>
                 <span class="s1">cov_struct=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s5">'none'</span><span class="s2">, </span><span class="s1">offset=</span><span class="s2">None,</span>
                 <span class="s1">dep_data=</span><span class="s2">None, </span><span class="s1">constraint=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>

        <span class="s2">if </span><span class="s1">family </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">family = families.Binomial()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">isinstance(family</span><span class="s2">, </span><span class="s1">families.Binomial):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;ordinal GEE must use a Binomial family&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">cov_struct </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov_struct = cov_structs.OrdinalIndependence()</span>

        <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset = self.setup_ordinal(</span>
            <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset)</span>

        <span class="s1">super(OrdinalGEE</span><span class="s2">, </span><span class="s1">self).__init__(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">,</span>
                                         <span class="s1">family</span><span class="s2">, </span><span class="s1">cov_struct</span><span class="s2">, </span><span class="s1">missing</span><span class="s2">,</span>
                                         <span class="s1">offset</span><span class="s2">, </span><span class="s1">dep_data</span><span class="s2">, </span><span class="s1">constraint)</span>

    <span class="s2">def </span><span class="s1">setup_ordinal(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset):</span>
        <span class="s0">&quot;&quot;&quot; 
        Restructure ordinal data as binary indicators so that they can 
        be analyzed using Generalized Estimating Equations. 
        &quot;&quot;&quot;</span>

        <span class="s1">self.endog_orig = endog.copy()</span>
        <span class="s1">self.exog_orig = exog.copy()</span>
        <span class="s1">self.groups_orig = groups.copy()</span>
        <span class="s2">if </span><span class="s1">offset </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.offset_orig = offset.copy()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.offset_orig = </span><span class="s2">None</span>
            <span class="s1">offset = np.zeros(len(endog))</span>
        <span class="s2">if </span><span class="s1">time </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.time_orig = time.copy()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.time_orig = </span><span class="s2">None</span>
            <span class="s1">time = np.zeros((len(endog)</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>

        <span class="s1">exog = np.asarray(exog)</span>
        <span class="s1">endog = np.asarray(endog)</span>
        <span class="s1">groups = np.asarray(groups)</span>
        <span class="s1">time = np.asarray(time)</span>
        <span class="s1">offset = np.asarray(offset)</span>

        <span class="s3"># The unique outcomes, except the greatest one.</span>
        <span class="s1">self.endog_values = np.unique(endog)</span>
        <span class="s1">endog_cuts = self.endog_values[</span><span class="s4">0</span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">ncut = len(endog_cuts)</span>

        <span class="s1">nrows = ncut * len(endog)</span>
        <span class="s1">exog_out = np.zeros((nrows</span><span class="s2">, </span><span class="s1">exog.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s2">,</span>
                            <span class="s1">dtype=np.float64)</span>
        <span class="s1">endog_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">intercepts = np.zeros((nrows</span><span class="s2">, </span><span class="s1">ncut)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">groups_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=groups.dtype)</span>
        <span class="s1">time_out = np.zeros((nrows</span><span class="s2">, </span><span class="s1">time.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s2">,</span>
                            <span class="s1">dtype=np.float64)</span>
        <span class="s1">offset_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s1">jrow = </span><span class="s4">0</span>
        <span class="s1">zipper = zip(exog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset)</span>
        <span class="s2">for </span><span class="s1">(exog_row</span><span class="s2">, </span><span class="s1">endog_value</span><span class="s2">, </span><span class="s1">group_value</span><span class="s2">, </span><span class="s1">time_value</span><span class="s2">,</span>
             <span class="s1">offset_value) </span><span class="s2">in </span><span class="s1">zipper:</span>

            <span class="s3"># Loop over thresholds for the indicators</span>
            <span class="s2">for </span><span class="s1">thresh_ix</span><span class="s2">, </span><span class="s1">thresh </span><span class="s2">in </span><span class="s1">enumerate(endog_cuts):</span>

                <span class="s1">exog_out[jrow</span><span class="s2">, </span><span class="s1">:] = exog_row</span>
                <span class="s1">endog_out[jrow] = int(np.squeeze(endog_value &gt; thresh))</span>
                <span class="s1">intercepts[jrow</span><span class="s2">, </span><span class="s1">thresh_ix] = </span><span class="s4">1</span>
                <span class="s1">groups_out[jrow] = group_value</span>
                <span class="s1">time_out[jrow] = time_value</span>
                <span class="s1">offset_out[jrow] = offset_value</span>
                <span class="s1">jrow += </span><span class="s4">1</span>

        <span class="s1">exog_out = np.concatenate((intercepts</span><span class="s2">, </span><span class="s1">exog_out)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s3"># exog column names, including intercepts</span>
        <span class="s1">xnames = [</span><span class="s5">&quot;I(y&gt;%.1f)&quot; </span><span class="s1">% v </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">endog_cuts]</span>
        <span class="s2">if </span><span class="s1">type(self.exog_orig) == pd.DataFrame:</span>
            <span class="s1">xnames.extend(self.exog_orig.columns)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">xnames.extend([</span><span class="s5">&quot;x%d&quot; </span><span class="s1">% k </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">exog.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)])</span>
        <span class="s1">exog_out = pd.DataFrame(exog_out</span><span class="s2">, </span><span class="s1">columns=xnames)</span>

        <span class="s3"># Preserve the endog name if there is one</span>
        <span class="s2">if </span><span class="s1">type(self.endog_orig) == pd.Series:</span>
            <span class="s1">endog_out = pd.Series(endog_out</span><span class="s2">, </span><span class="s1">name=self.endog_orig.name)</span>

        <span class="s2">return </span><span class="s1">endog_out</span><span class="s2">, </span><span class="s1">exog_out</span><span class="s2">, </span><span class="s1">groups_out</span><span class="s2">, </span><span class="s1">time_out</span><span class="s2">, </span><span class="s1">offset_out</span>

    <span class="s2">def </span><span class="s1">_starting_params(self):</span>
        <span class="s1">exposure = getattr(self</span><span class="s2">, </span><span class="s5">&quot;exposure&quot;</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">model = GEE(self.endog</span><span class="s2">, </span><span class="s1">self.exog</span><span class="s2">, </span><span class="s1">self.groups</span><span class="s2">,</span>
                    <span class="s1">time=self.time</span><span class="s2">, </span><span class="s1">family=families.Binomial()</span><span class="s2">,</span>
                    <span class="s1">offset=self.offset</span><span class="s2">, </span><span class="s1">exposure=exposure)</span>
        <span class="s1">result = model.fit()</span>
        <span class="s2">return </span><span class="s1">result.params</span>

    <span class="s1">@Appender(_gee_fit_doc)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">60</span><span class="s2">, </span><span class="s1">ctol=</span><span class="s4">1e-6</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None,</span>
            <span class="s1">params_niter=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">first_dep_update=</span><span class="s4">0</span><span class="s2">,</span>
            <span class="s1">cov_type=</span><span class="s5">'robust'</span><span class="s1">):</span>

        <span class="s1">rslt = super(OrdinalGEE</span><span class="s2">, </span><span class="s1">self).fit(maxiter</span><span class="s2">, </span><span class="s1">ctol</span><span class="s2">, </span><span class="s1">start_params</span><span class="s2">,</span>
                                           <span class="s1">params_niter</span><span class="s2">, </span><span class="s1">first_dep_update</span><span class="s2">,</span>
                                           <span class="s1">cov_type=cov_type)</span>

        <span class="s1">rslt = rslt._results   </span><span class="s3"># use unwrapped instance</span>
        <span class="s1">res_kwds = dict(((k</span><span class="s2">, </span><span class="s1">getattr(rslt</span><span class="s2">, </span><span class="s1">k)) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">rslt._props))</span>
        <span class="s3"># Convert the GEEResults to an OrdinalGEEResults</span>
        <span class="s1">ord_rslt = OrdinalGEEResults(self</span><span class="s2">, </span><span class="s1">rslt.params</span><span class="s2">,</span>
                                     <span class="s1">rslt.cov_params() / rslt.scale</span><span class="s2">,</span>
                                     <span class="s1">rslt.scale</span><span class="s2">,</span>
                                     <span class="s1">cov_type=cov_type</span><span class="s2">,</span>
                                     <span class="s1">attr_kwds=res_kwds)</span>
        <span class="s3"># for k in rslt._props:</span>
        <span class="s3">#    setattr(ord_rslt, k, getattr(rslt, k))</span>
        <span class="s3"># TODO: document or delete</span>

        <span class="s2">return </span><span class="s1">OrdinalGEEResultsWrapper(ord_rslt)</span>


<span class="s2">class </span><span class="s1">OrdinalGEEResults(GEEResults):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;This class summarizes the fit of a marginal regression model&quot;</span>
        <span class="s5">&quot;for an ordinal response using GEE.</span><span class="s2">\n</span><span class="s5">&quot;</span>
        <span class="s1">+ _gee_results_doc)</span>

    <span class="s2">def </span><span class="s1">plot_distribution(self</span><span class="s2">, </span><span class="s1">ax=</span><span class="s2">None, </span><span class="s1">exog_values=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Plot the fitted probabilities of endog in an ordinal model, 
        for specified values of the predictors. 
 
        Parameters 
        ---------- 
        ax : AxesSubplot 
            An axes on which to draw the graph.  If None, new 
            figure and axes objects are created 
        exog_values : array_like 
            A list of dictionaries, with each dictionary mapping 
            variable names to values at which the variable is held 
            fixed.  The values P(endog=y | exog) are plotted for all 
            possible values of y, at the given exog value.  Variables 
            not included in a dictionary are held fixed at the mean 
            value. 
 
        Example: 
        -------- 
        We have a model with covariates 'age' and 'sex', and wish to 
        plot the probabilities P(endog=y | exog) for males (sex=0) and 
        for females (sex=1), as separate paths on the plot.  Since 
        'age' is not included below in the map, it is held fixed at 
        its mean value. 
 
        &gt;&gt;&gt; ev = [{&quot;sex&quot;: 1}, {&quot;sex&quot;: 0}] 
        &gt;&gt;&gt; rslt.distribution_plot(exog_values=ev) 
        &quot;&quot;&quot;</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics </span><span class="s2">import </span><span class="s1">utils </span><span class="s2">as </span><span class="s1">gutils</span>

        <span class="s2">if </span><span class="s1">ax </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">fig</span><span class="s2">, </span><span class="s1">ax = gutils.create_mpl_ax(ax)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fig = ax.get_figure()</span>

        <span class="s3"># If no covariate patterns are specified, create one with all</span>
        <span class="s3"># variables set to their mean values.</span>
        <span class="s2">if </span><span class="s1">exog_values </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog_values = [{}</span><span class="s2">, </span><span class="s1">]</span>

        <span class="s1">exog_means = self.model.exog.mean(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">ix_icept = [i </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">enumerate(self.model.exog_names) </span><span class="s2">if</span>
                    <span class="s1">x.startswith(</span><span class="s5">&quot;I(&quot;</span><span class="s1">)]</span>

        <span class="s2">for </span><span class="s1">ev </span><span class="s2">in </span><span class="s1">exog_values:</span>

            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">ev.keys():</span>
                <span class="s2">if </span><span class="s1">k </span><span class="s2">not in </span><span class="s1">self.model.exog_names:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;%s is not a variable in the model&quot;</span>
                                     <span class="s1">% k)</span>

            <span class="s3"># Get the fitted probability for each level, at the given</span>
            <span class="s3"># covariate values.</span>
            <span class="s1">pr = []</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">ix_icept:</span>

                <span class="s1">xp = np.zeros_like(self.params)</span>
                <span class="s1">xp[j] = </span><span class="s4">1.</span>
                <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">vn </span><span class="s2">in </span><span class="s1">enumerate(self.model.exog_names):</span>
                    <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">ix_icept:</span>
                        <span class="s2">continue</span>
                    <span class="s3"># User-specified value</span>
                    <span class="s2">if </span><span class="s1">vn </span><span class="s2">in </span><span class="s1">ev:</span>
                        <span class="s1">xp[i] = ev[vn]</span>
                    <span class="s3"># Mean value</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">xp[i] = exog_means[i]</span>

                <span class="s1">p = </span><span class="s4">1 </span><span class="s1">/ (</span><span class="s4">1 </span><span class="s1">+ np.exp(-np.dot(xp</span><span class="s2">, </span><span class="s1">self.params)))</span>
                <span class="s1">pr.append(p)</span>

            <span class="s1">pr.insert(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">pr.append(</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">pr = np.asarray(pr)</span>
            <span class="s1">prd = -np.diff(pr)</span>

            <span class="s1">ax.plot(self.model.endog_values</span><span class="s2">, </span><span class="s1">prd</span><span class="s2">, </span><span class="s5">'o-'</span><span class="s1">)</span>

        <span class="s1">ax.set_xlabel(</span><span class="s5">&quot;Response value&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_ylabel(</span><span class="s5">&quot;Probability&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_ylim(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>


<span class="s2">def </span><span class="s1">_score_test_submodel(par</span><span class="s2">, </span><span class="s1">sub):</span>
    <span class="s0">&quot;&quot;&quot; 
    Return transformation matrices for design matrices. 
 
    Parameters 
    ---------- 
    par : instance 
        The parent model 
    sub : instance 
        The sub-model 
 
    Returns 
    ------- 
    qm : array_like 
        Matrix mapping the design matrix of the parent to the design matrix 
        for the sub-model. 
    qc : array_like 
        Matrix mapping the design matrix of the parent to the orthogonal 
        complement of the columnspace of the submodel in the columnspace 
        of the parent. 
 
    Notes 
    ----- 
    Returns None, None if the provided submodel is not actually a submodel. 
    &quot;&quot;&quot;</span>

    <span class="s1">x1 = par.exog</span>
    <span class="s1">x2 = sub.exog</span>

    <span class="s1">u</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">vt = np.linalg.svd(x1</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">v = vt.T</span>

    <span class="s3"># Get the orthogonal complement of col(x2) in col(x1).</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">_ = np.linalg.qr(x2)</span>
    <span class="s1">a = u - np.dot(a</span><span class="s2">, </span><span class="s1">np.dot(a.T</span><span class="s2">, </span><span class="s1">u))</span>
    <span class="s1">x2c</span><span class="s2">, </span><span class="s1">sb</span><span class="s2">, </span><span class="s1">_ = np.linalg.svd(a</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">x2c = x2c[:</span><span class="s2">, </span><span class="s1">sb &gt; </span><span class="s4">1e-12</span><span class="s1">]</span>

    <span class="s3"># x1 * qm = x2</span>
    <span class="s1">ii = np.flatnonzero(np.abs(s) &gt; </span><span class="s4">1e-12</span><span class="s1">)</span>
    <span class="s1">qm = np.dot(v[:</span><span class="s2">, </span><span class="s1">ii]</span><span class="s2">, </span><span class="s1">np.dot(u[:</span><span class="s2">, </span><span class="s1">ii].T</span><span class="s2">, </span><span class="s1">x2) / s[ii</span><span class="s2">, None</span><span class="s1">])</span>

    <span class="s1">e = np.max(np.abs(x2 - np.dot(x1</span><span class="s2">, </span><span class="s1">qm)))</span>
    <span class="s2">if </span><span class="s1">e &gt; </span><span class="s4">1e-8</span><span class="s1">:</span>
        <span class="s2">return None, None</span>

    <span class="s3"># x1 * qc = x2c</span>
    <span class="s1">qc = np.dot(v[:</span><span class="s2">, </span><span class="s1">ii]</span><span class="s2">, </span><span class="s1">np.dot(u[:</span><span class="s2">, </span><span class="s1">ii].T</span><span class="s2">, </span><span class="s1">x2c) / s[ii</span><span class="s2">, None</span><span class="s1">])</span>

    <span class="s2">return </span><span class="s1">qm</span><span class="s2">, </span><span class="s1">qc</span>


<span class="s2">class </span><span class="s1">OrdinalGEEResultsWrapper(GEEResultsWrapper):</span>
    <span class="s2">pass</span>
<span class="s1">wrap.populate_wrapper(OrdinalGEEResultsWrapper</span><span class="s2">, </span><span class="s1">OrdinalGEEResults)  </span><span class="s3"># noqa:E305</span>


<span class="s2">class </span><span class="s1">NominalGEE(GEE):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;    Nominal Response Marginal Regression Model using GEE.</span><span class="s2">\n</span><span class="s5">&quot; </span><span class="s1">+</span>
        <span class="s1">_gee_init_doc % {</span><span class="s5">'extra_params'</span><span class="s1">: base._missing_param_doc</span><span class="s2">,</span>
                         <span class="s5">'family_doc'</span><span class="s1">: _gee_nominal_family_doc</span><span class="s2">,</span>
                         <span class="s5">'example'</span><span class="s1">: _gee_nominal_example</span><span class="s2">,</span>
                         <span class="s5">'notes'</span><span class="s1">: _gee_nointercept})</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time=</span><span class="s2">None, </span><span class="s1">family=</span><span class="s2">None,</span>
                 <span class="s1">cov_struct=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s5">'none'</span><span class="s2">, </span><span class="s1">offset=</span><span class="s2">None,</span>
                 <span class="s1">dep_data=</span><span class="s2">None, </span><span class="s1">constraint=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>

        <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset = self.setup_nominal(</span>
            <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset)</span>

        <span class="s2">if </span><span class="s1">family </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">family = _Multinomial(self.ncut + </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">cov_struct </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov_struct = cov_structs.NominalIndependence()</span>

        <span class="s1">super(NominalGEE</span><span class="s2">, </span><span class="s1">self).__init__(</span>
            <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">family</span><span class="s2">, </span><span class="s1">cov_struct</span><span class="s2">, </span><span class="s1">missing</span><span class="s2">,</span>
            <span class="s1">offset</span><span class="s2">, </span><span class="s1">dep_data</span><span class="s2">, </span><span class="s1">constraint)</span>

    <span class="s2">def </span><span class="s1">_starting_params(self):</span>
        <span class="s1">exposure = getattr(self</span><span class="s2">, </span><span class="s5">&quot;exposure&quot;</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">model = GEE(self.endog</span><span class="s2">, </span><span class="s1">self.exog</span><span class="s2">, </span><span class="s1">self.groups</span><span class="s2">,</span>
                    <span class="s1">time=self.time</span><span class="s2">, </span><span class="s1">family=families.Binomial()</span><span class="s2">,</span>
                    <span class="s1">offset=self.offset</span><span class="s2">, </span><span class="s1">exposure=exposure)</span>
        <span class="s1">result = model.fit()</span>
        <span class="s2">return </span><span class="s1">result.params</span>

    <span class="s2">def </span><span class="s1">setup_nominal(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset):</span>
        <span class="s0">&quot;&quot;&quot; 
        Restructure nominal data as binary indicators so that they can 
        be analyzed using Generalized Estimating Equations. 
        &quot;&quot;&quot;</span>

        <span class="s1">self.endog_orig = endog.copy()</span>
        <span class="s1">self.exog_orig = exog.copy()</span>
        <span class="s1">self.groups_orig = groups.copy()</span>
        <span class="s2">if </span><span class="s1">offset </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.offset_orig = offset.copy()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.offset_orig = </span><span class="s2">None</span>
            <span class="s1">offset = np.zeros(len(endog))</span>
        <span class="s2">if </span><span class="s1">time </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.time_orig = time.copy()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.time_orig = </span><span class="s2">None</span>
            <span class="s1">time = np.zeros((len(endog)</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>

        <span class="s1">exog = np.asarray(exog)</span>
        <span class="s1">endog = np.asarray(endog)</span>
        <span class="s1">groups = np.asarray(groups)</span>
        <span class="s1">time = np.asarray(time)</span>
        <span class="s1">offset = np.asarray(offset)</span>

        <span class="s3"># The unique outcomes, except the greatest one.</span>
        <span class="s1">self.endog_values = np.unique(endog)</span>
        <span class="s1">endog_cuts = self.endog_values[</span><span class="s4">0</span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">ncut = len(endog_cuts)</span>
        <span class="s1">self.ncut = ncut</span>

        <span class="s1">nrows = len(endog_cuts) * exog.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">ncols = len(endog_cuts) * exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">exog_out = np.zeros((nrows</span><span class="s2">, </span><span class="s1">ncols)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">endog_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">groups_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">time_out = np.zeros((nrows</span><span class="s2">, </span><span class="s1">time.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s2">,</span>
                            <span class="s1">dtype=np.float64)</span>
        <span class="s1">offset_out = np.zeros(nrows</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s1">jrow = </span><span class="s4">0</span>
        <span class="s1">zipper = zip(exog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">, </span><span class="s1">time</span><span class="s2">, </span><span class="s1">offset)</span>
        <span class="s2">for </span><span class="s1">(exog_row</span><span class="s2">, </span><span class="s1">endog_value</span><span class="s2">, </span><span class="s1">group_value</span><span class="s2">, </span><span class="s1">time_value</span><span class="s2">,</span>
             <span class="s1">offset_value) </span><span class="s2">in </span><span class="s1">zipper:</span>

            <span class="s3"># Loop over thresholds for the indicators</span>
            <span class="s2">for </span><span class="s1">thresh_ix</span><span class="s2">, </span><span class="s1">thresh </span><span class="s2">in </span><span class="s1">enumerate(endog_cuts):</span>

                <span class="s1">u = np.zeros(len(endog_cuts)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
                <span class="s1">u[thresh_ix] = </span><span class="s4">1</span>
                <span class="s1">exog_out[jrow</span><span class="s2">, </span><span class="s1">:] = np.kron(u</span><span class="s2">, </span><span class="s1">exog_row)</span>
                <span class="s1">endog_out[jrow] = (int(endog_value == thresh))</span>
                <span class="s1">groups_out[jrow] = group_value</span>
                <span class="s1">time_out[jrow] = time_value</span>
                <span class="s1">offset_out[jrow] = offset_value</span>
                <span class="s1">jrow += </span><span class="s4">1</span>

        <span class="s3"># exog names</span>
        <span class="s2">if </span><span class="s1">isinstance(self.exog_orig</span><span class="s2">, </span><span class="s1">pd.DataFrame):</span>
            <span class="s1">xnames_in = self.exog_orig.columns</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">xnames_in = [</span><span class="s5">&quot;x%d&quot; </span><span class="s1">% k </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">exog.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)]</span>
        <span class="s1">xnames = []</span>
        <span class="s2">for </span><span class="s1">tr </span><span class="s2">in </span><span class="s1">endog_cuts:</span>
            <span class="s1">xnames.extend([</span><span class="s5">&quot;%s[%.1f]&quot; </span><span class="s1">% (v</span><span class="s2">, </span><span class="s1">tr) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">xnames_in])</span>
        <span class="s1">exog_out = pd.DataFrame(exog_out</span><span class="s2">, </span><span class="s1">columns=xnames)</span>
        <span class="s1">exog_out = pd.DataFrame(exog_out</span><span class="s2">, </span><span class="s1">columns=xnames)</span>

        <span class="s3"># Preserve endog name if there is one</span>
        <span class="s2">if </span><span class="s1">isinstance(self.endog_orig</span><span class="s2">, </span><span class="s1">pd.Series):</span>
            <span class="s1">endog_out = pd.Series(endog_out</span><span class="s2">, </span><span class="s1">name=self.endog_orig.name)</span>

        <span class="s2">return </span><span class="s1">endog_out</span><span class="s2">, </span><span class="s1">exog_out</span><span class="s2">, </span><span class="s1">groups_out</span><span class="s2">, </span><span class="s1">time_out</span><span class="s2">, </span><span class="s1">offset_out</span>

    <span class="s2">def </span><span class="s1">mean_deriv(self</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">lin_pred):</span>
        <span class="s0">&quot;&quot;&quot; 
        Derivative of the expected endog with respect to the parameters. 
 
        Parameters 
        ---------- 
        exog : array_like 
           The exogeneous data at which the derivative is computed, 
           number of rows must be a multiple of `ncut`. 
        lin_pred : array_like 
           The values of the linear predictor, length must be multiple 
           of `ncut`. 
 
        Returns 
        ------- 
        The derivative of the expected endog with respect to the 
        parameters. 
        &quot;&quot;&quot;</span>

        <span class="s1">expval = np.exp(lin_pred)</span>

        <span class="s3"># Reshape so that each row contains all the indicators</span>
        <span class="s3"># corresponding to one multinomial observation.</span>
        <span class="s1">expval_m = np.reshape(expval</span><span class="s2">, </span><span class="s1">(len(expval) // self.ncut</span><span class="s2">,</span>
                                       <span class="s1">self.ncut))</span>

        <span class="s3"># The normalizing constant for the multinomial probabilities.</span>
        <span class="s1">denom = </span><span class="s4">1 </span><span class="s1">+ expval_m.sum(</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">denom = np.kron(denom</span><span class="s2">, </span><span class="s1">np.ones(self.ncut</span><span class="s2">, </span><span class="s1">dtype=np.float64))</span>

        <span class="s3"># The multinomial probabilities</span>
        <span class="s1">mprob = expval / denom</span>

        <span class="s3"># First term of the derivative: denom * expval' / denom^2 =</span>
        <span class="s3"># expval' / denom.</span>
        <span class="s1">dmat = mprob[:</span><span class="s2">, None</span><span class="s1">] * exog</span>

        <span class="s3"># Second term of the derivative: -expval * denom' / denom^2</span>
        <span class="s1">ddenom = expval[:</span><span class="s2">, None</span><span class="s1">] * exog</span>
        <span class="s1">dmat -= mprob[:</span><span class="s2">, None</span><span class="s1">] * ddenom / denom[:</span><span class="s2">, None</span><span class="s1">]</span>

        <span class="s2">return </span><span class="s1">dmat</span>

    <span class="s2">def </span><span class="s1">mean_deriv_exog(self</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">offset_exposure=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Derivative of the expected endog with respect to exog for the 
        multinomial model, used in analyzing marginal effects. 
 
        Parameters 
        ---------- 
        exog : array_like 
           The exogeneous data at which the derivative is computed, 
           number of rows must be a multiple of `ncut`. 
        lpr : array_like 
           The linear predictor values, length must be multiple of 
           `ncut`. 
 
        Returns 
        ------- 
        The value of the derivative of the expected endog with respect 
        to exog. 
 
        Notes 
        ----- 
        offset_exposure must be set at None for the multinomial family. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">offset_exposure </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;Offset/exposure ignored for the multinomial family&quot;</span><span class="s2">,</span>
                          <span class="s1">ValueWarning)</span>

        <span class="s1">lpr = np.dot(exog</span><span class="s2">, </span><span class="s1">params)</span>
        <span class="s1">expval = np.exp(lpr)</span>

        <span class="s1">expval_m = np.reshape(expval</span><span class="s2">, </span><span class="s1">(len(expval) // self.ncut</span><span class="s2">,</span>
                                       <span class="s1">self.ncut))</span>

        <span class="s1">denom = </span><span class="s4">1 </span><span class="s1">+ expval_m.sum(</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">denom = np.kron(denom</span><span class="s2">, </span><span class="s1">np.ones(self.ncut</span><span class="s2">, </span><span class="s1">dtype=np.float64))</span>

        <span class="s1">bmat0 = np.outer(np.ones(exog.shape[</span><span class="s4">0</span><span class="s1">])</span><span class="s2">, </span><span class="s1">params)</span>

        <span class="s3"># Masking matrix</span>
        <span class="s1">qmat = []</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.ncut):</span>
            <span class="s1">ee = np.zeros(self.ncut</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
            <span class="s1">ee[j] = </span><span class="s4">1</span>
            <span class="s1">qmat.append(np.kron(ee</span><span class="s2">, </span><span class="s1">np.ones(len(params) // self.ncut)))</span>
        <span class="s1">qmat = np.array(qmat)</span>
        <span class="s1">qmat = np.kron(np.ones((exog.shape[</span><span class="s4">0</span><span class="s1">] // self.ncut</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span><span class="s2">, </span><span class="s1">qmat)</span>
        <span class="s1">bmat = bmat0 * qmat</span>

        <span class="s1">dmat = expval[:</span><span class="s2">, None</span><span class="s1">] * bmat / denom[:</span><span class="s2">, None</span><span class="s1">]</span>

        <span class="s1">expval_mb = np.kron(expval_m</span><span class="s2">, </span><span class="s1">np.ones((self.ncut</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)))</span>
        <span class="s1">expval_mb = np.kron(expval_mb</span><span class="s2">, </span><span class="s1">np.ones((</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self.ncut)))</span>

        <span class="s1">dmat -= expval[:</span><span class="s2">, None</span><span class="s1">] * (bmat * expval_mb) / denom[:</span><span class="s2">, None</span><span class="s1">] ** </span><span class="s4">2</span>

        <span class="s2">return </span><span class="s1">dmat</span>

    <span class="s1">@Appender(_gee_fit_doc)</span>
    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">60</span><span class="s2">, </span><span class="s1">ctol=</span><span class="s4">1e-6</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None,</span>
            <span class="s1">params_niter=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">first_dep_update=</span><span class="s4">0</span><span class="s2">,</span>
            <span class="s1">cov_type=</span><span class="s5">'robust'</span><span class="s1">):</span>

        <span class="s1">rslt = super(NominalGEE</span><span class="s2">, </span><span class="s1">self).fit(maxiter</span><span class="s2">, </span><span class="s1">ctol</span><span class="s2">, </span><span class="s1">start_params</span><span class="s2">,</span>
                                           <span class="s1">params_niter</span><span class="s2">, </span><span class="s1">first_dep_update</span><span class="s2">,</span>
                                           <span class="s1">cov_type=cov_type)</span>
        <span class="s2">if </span><span class="s1">rslt </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;GEE updates did not converge&quot;</span><span class="s2">,</span>
                          <span class="s1">ConvergenceWarning)</span>
            <span class="s2">return None</span>

        <span class="s1">rslt = rslt._results   </span><span class="s3"># use unwrapped instance</span>
        <span class="s1">res_kwds = dict(((k</span><span class="s2">, </span><span class="s1">getattr(rslt</span><span class="s2">, </span><span class="s1">k)) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">rslt._props))</span>
        <span class="s3"># Convert the GEEResults to a NominalGEEResults</span>
        <span class="s1">nom_rslt = NominalGEEResults(self</span><span class="s2">, </span><span class="s1">rslt.params</span><span class="s2">,</span>
                                     <span class="s1">rslt.cov_params() / rslt.scale</span><span class="s2">,</span>
                                     <span class="s1">rslt.scale</span><span class="s2">,</span>
                                     <span class="s1">cov_type=cov_type</span><span class="s2">,</span>
                                     <span class="s1">attr_kwds=res_kwds)</span>
        <span class="s3"># TODO: document or delete</span>
        <span class="s3"># for k in rslt._props:</span>
        <span class="s3">#    setattr(nom_rslt, k, getattr(rslt, k))</span>

        <span class="s2">return </span><span class="s1">NominalGEEResultsWrapper(nom_rslt)</span>


<span class="s2">class </span><span class="s1">NominalGEEResults(GEEResults):</span>

    <span class="s1">__doc__ = (</span>
        <span class="s5">&quot;This class summarizes the fit of a marginal regression model&quot;</span>
        <span class="s5">&quot;for a nominal response using GEE.</span><span class="s2">\n</span><span class="s5">&quot;</span>
        <span class="s1">+ _gee_results_doc)</span>

    <span class="s2">def </span><span class="s1">plot_distribution(self</span><span class="s2">, </span><span class="s1">ax=</span><span class="s2">None, </span><span class="s1">exog_values=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Plot the fitted probabilities of endog in an nominal model, 
        for specified values of the predictors. 
 
        Parameters 
        ---------- 
        ax : AxesSubplot 
            An axes on which to draw the graph.  If None, new 
            figure and axes objects are created 
        exog_values : array_like 
            A list of dictionaries, with each dictionary mapping 
            variable names to values at which the variable is held 
            fixed.  The values P(endog=y | exog) are plotted for all 
            possible values of y, at the given exog value.  Variables 
            not included in a dictionary are held fixed at the mean 
            value. 
 
        Example: 
        -------- 
        We have a model with covariates 'age' and 'sex', and wish to 
        plot the probabilities P(endog=y | exog) for males (sex=0) and 
        for females (sex=1), as separate paths on the plot.  Since 
        'age' is not included below in the map, it is held fixed at 
        its mean value. 
 
        &gt;&gt;&gt; ex = [{&quot;sex&quot;: 1}, {&quot;sex&quot;: 0}] 
        &gt;&gt;&gt; rslt.distribution_plot(exog_values=ex) 
        &quot;&quot;&quot;</span>

        <span class="s2">from </span><span class="s1">statsmodels.graphics </span><span class="s2">import </span><span class="s1">utils </span><span class="s2">as </span><span class="s1">gutils</span>

        <span class="s2">if </span><span class="s1">ax </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">fig</span><span class="s2">, </span><span class="s1">ax = gutils.create_mpl_ax(ax)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fig = ax.get_figure()</span>

        <span class="s3"># If no covariate patterns are specified, create one with all</span>
        <span class="s3"># variables set to their mean values.</span>
        <span class="s2">if </span><span class="s1">exog_values </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog_values = [{}</span><span class="s2">, </span><span class="s1">]</span>

        <span class="s1">link = self.model.family.link.inverse</span>
        <span class="s1">ncut = self.model.family.ncut</span>

        <span class="s1">k = int(self.model.exog.shape[</span><span class="s4">1</span><span class="s1">] / ncut)</span>
        <span class="s1">exog_means = self.model.exog.mean(</span><span class="s4">0</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">:k]</span>
        <span class="s1">exog_names = self.model.exog_names[</span><span class="s4">0</span><span class="s1">:k]</span>
        <span class="s1">exog_names = [x.split(</span><span class="s5">&quot;[&quot;</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">] </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">exog_names]</span>

        <span class="s1">params = np.reshape(self.params</span><span class="s2">,</span>
                            <span class="s1">(ncut</span><span class="s2">, </span><span class="s1">len(self.params) // ncut))</span>

        <span class="s2">for </span><span class="s1">ev </span><span class="s2">in </span><span class="s1">exog_values:</span>

            <span class="s1">exog = exog_means.copy()</span>

            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">ev.keys():</span>
                <span class="s2">if </span><span class="s1">k </span><span class="s2">not in </span><span class="s1">exog_names:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;%s is not a variable in the model&quot;</span>
                                     <span class="s1">% k)</span>

                <span class="s1">ii = exog_names.index(k)</span>
                <span class="s1">exog[ii] = ev[k]</span>

            <span class="s1">lpr = np.dot(params</span><span class="s2">, </span><span class="s1">exog)</span>
            <span class="s1">pr = link(lpr)</span>
            <span class="s1">pr = np.r_[pr</span><span class="s2">, </span><span class="s4">1 </span><span class="s1">- pr.sum()]</span>

            <span class="s1">ax.plot(self.model.endog_values</span><span class="s2">, </span><span class="s1">pr</span><span class="s2">, </span><span class="s5">'o-'</span><span class="s1">)</span>

        <span class="s1">ax.set_xlabel(</span><span class="s5">&quot;Response value&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_ylabel(</span><span class="s5">&quot;Probability&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_xticks(self.model.endog_values)</span>
        <span class="s1">ax.set_xticklabels(self.model.endog_values)</span>
        <span class="s1">ax.set_ylim(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>


<span class="s2">class </span><span class="s1">NominalGEEResultsWrapper(GEEResultsWrapper):</span>
    <span class="s2">pass</span>
<span class="s1">wrap.populate_wrapper(NominalGEEResultsWrapper</span><span class="s2">, </span><span class="s1">NominalGEEResults)  </span><span class="s3"># noqa:E305</span>


<span class="s2">class </span><span class="s1">_MultinomialLogit(Link):</span>
    <span class="s0">&quot;&quot;&quot; 
    The multinomial logit transform, only for use with GEE. 
 
    Notes 
    ----- 
    The data are assumed coded as binary indicators, where each 
    observed multinomial value y is coded as I(y == S[0]), ..., I(y == 
    S[-1]), where S is the set of possible response labels, excluding 
    the largest one.  Thererefore functions in this class should only 
    be called using vector argument whose length is a multiple of |S| 
    = ncut, which is an argument to be provided when initializing the 
    class. 
 
    call and derivative use a private method _clean to trim p by 1e-10 
    so that p is in (0, 1) 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">ncut):</span>
        <span class="s1">self.ncut = ncut</span>

    <span class="s2">def </span><span class="s1">inverse(self</span><span class="s2">, </span><span class="s1">lpr):</span>
        <span class="s0">&quot;&quot;&quot; 
        Inverse of the multinomial logit transform, which gives the 
        expected values of the data as a function of the linear 
        predictors. 
 
        Parameters 
        ---------- 
        lpr : array_like (length must be divisible by `ncut`) 
            The linear predictors 
 
        Returns 
        ------- 
        prob : ndarray 
            Probabilities, or expected values 
        &quot;&quot;&quot;</span>

        <span class="s1">expval = np.exp(lpr)</span>

        <span class="s1">denom = </span><span class="s4">1 </span><span class="s1">+ np.reshape(expval</span><span class="s2">, </span><span class="s1">(len(expval) // self.ncut</span><span class="s2">,</span>
                                        <span class="s1">self.ncut)).sum(</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">denom = np.kron(denom</span><span class="s2">, </span><span class="s1">np.ones(self.ncut</span><span class="s2">, </span><span class="s1">dtype=np.float64))</span>

        <span class="s1">prob = expval / denom</span>

        <span class="s2">return </span><span class="s1">prob</span>


<span class="s2">class </span><span class="s1">_Multinomial(families.Family):</span>
    <span class="s0">&quot;&quot;&quot; 
    Pseudo-link function for fitting nominal multinomial models with 
    GEE.  Not for use outside the GEE class. 
    &quot;&quot;&quot;</span>

    <span class="s1">links = [_MultinomialLogit</span><span class="s2">, </span><span class="s1">]</span>
    <span class="s1">variance = varfuncs.binary</span>
    <span class="s1">safe_links = [_MultinomialLogit</span><span class="s2">, </span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">nlevels</span><span class="s2">, </span><span class="s1">check_link=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Parameters 
        ---------- 
        nlevels : int 
            The number of distinct categories for the multinomial 
            distribution. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._check_link = check_link</span>
        <span class="s1">self.initialize(nlevels)</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">nlevels):</span>
        <span class="s1">self.ncut = nlevels - </span><span class="s4">1</span>
        <span class="s1">self.link = _MultinomialLogit(self.ncut)</span>


<span class="s2">class </span><span class="s1">GEEMargins:</span>
    <span class="s0">&quot;&quot;&quot; 
    Estimated marginal effects for a regression model fit with GEE. 
 
    Parameters 
    ---------- 
    results : GEEResults instance 
        The results instance of a fitted discrete choice model 
    args : tuple 
        Args are passed to `get_margeff`. This is the same as 
        results.get_margeff. See there for more information. 
    kwargs : dict 
        Keyword args are passed to `get_margeff`. This is the same as 
        results.get_margeff. See there for more information. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">results</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwargs={}):</span>
        <span class="s1">self._cache = {}</span>
        <span class="s1">self.results = results</span>
        <span class="s1">self.get_margeff(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s2">def </span><span class="s1">_reset(self):</span>
        <span class="s1">self._cache = {}</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">tvalues(self):</span>
        <span class="s1">_check_at_is_all(self.margeff_options)</span>
        <span class="s2">return </span><span class="s1">self.margeff / self.margeff_se</span>

    <span class="s2">def </span><span class="s1">summary_frame(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a DataFrame summarizing the marginal effects. 
 
        Parameters 
        ---------- 
        alpha : float 
            Number between 0 and 1. The confidence intervals have the 
            probability 1-alpha. 
 
        Returns 
        ------- 
        frame : DataFrames 
            A DataFrame summarizing the marginal effects. 
        &quot;&quot;&quot;</span>
        <span class="s1">_check_at_is_all(self.margeff_options)</span>
        <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">DataFrame</span>
        <span class="s1">names = [_transform_names[self.margeff_options[</span><span class="s5">'method'</span><span class="s1">]]</span><span class="s2">,</span>
                 <span class="s5">'Std. Err.'</span><span class="s2">, </span><span class="s5">'z'</span><span class="s2">, </span><span class="s5">'Pr(&gt;|z|)'</span><span class="s2">,</span>
                 <span class="s5">'Conf. Int. Low'</span><span class="s2">, </span><span class="s5">'Cont. Int. Hi.'</span><span class="s1">]</span>
        <span class="s1">ind = self.results.model.exog.var(</span><span class="s4">0</span><span class="s1">) != </span><span class="s4">0  </span><span class="s3"># True if not a constant</span>
        <span class="s1">exog_names = self.results.model.exog_names</span>
        <span class="s1">var_names = [name </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">name </span><span class="s2">in </span><span class="s1">enumerate(exog_names) </span><span class="s2">if </span><span class="s1">ind[i]]</span>
        <span class="s1">table = np.column_stack((self.margeff</span><span class="s2">, </span><span class="s1">self.margeff_se</span><span class="s2">, </span><span class="s1">self.tvalues</span><span class="s2">,</span>
                                 <span class="s1">self.pvalues</span><span class="s2">, </span><span class="s1">self.conf_int(alpha)))</span>
        <span class="s2">return </span><span class="s1">DataFrame(table</span><span class="s2">, </span><span class="s1">columns=names</span><span class="s2">, </span><span class="s1">index=var_names)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">pvalues(self):</span>
        <span class="s1">_check_at_is_all(self.margeff_options)</span>
        <span class="s2">return </span><span class="s1">stats.norm.sf(np.abs(self.tvalues)) * </span><span class="s4">2</span>

    <span class="s2">def </span><span class="s1">conf_int(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the confidence intervals of the marginal effects 
 
        Parameters 
        ---------- 
        alpha : float 
            Number between 0 and 1. The confidence intervals have the 
            probability 1-alpha. 
 
        Returns 
        ------- 
        conf_int : ndarray 
            An array with lower, upper confidence intervals for the marginal 
            effects. 
        &quot;&quot;&quot;</span>
        <span class="s1">_check_at_is_all(self.margeff_options)</span>
        <span class="s1">me_se = self.margeff_se</span>
        <span class="s1">q = stats.norm.ppf(</span><span class="s4">1 </span><span class="s1">- alpha / </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">lower = self.margeff - q * me_se</span>
        <span class="s1">upper = self.margeff + q * me_se</span>
        <span class="s2">return </span><span class="s1">np.asarray(lzip(lower</span><span class="s2">, </span><span class="s1">upper))</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a summary table for marginal effects 
 
        Parameters 
        ---------- 
        alpha : float 
            Number between 0 and 1. The confidence intervals have the 
            probability 1-alpha. 
 
        Returns 
        ------- 
        Summary : SummaryTable 
            A SummaryTable instance 
        &quot;&quot;&quot;</span>
        <span class="s1">_check_at_is_all(self.margeff_options)</span>
        <span class="s1">results = self.results</span>
        <span class="s1">model = results.model</span>
        <span class="s1">title = model.__class__.__name__ + </span><span class="s5">&quot; Marginal Effects&quot;</span>
        <span class="s1">method = self.margeff_options[</span><span class="s5">'method'</span><span class="s1">]</span>
        <span class="s1">top_left = [(</span><span class="s5">'Dep. Variable:'</span><span class="s2">, </span><span class="s1">[model.endog_names])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'Method:'</span><span class="s2">, </span><span class="s1">[method])</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s5">'At:'</span><span class="s2">, </span><span class="s1">[self.margeff_options[</span><span class="s5">'at'</span><span class="s1">]])</span><span class="s2">, </span><span class="s1">]</span>

        <span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">(Summary</span><span class="s2">, </span><span class="s1">summary_params</span><span class="s2">,</span>
                                               <span class="s1">table_extend)</span>
        <span class="s1">exog_names = model.exog_names[:]  </span><span class="s3"># copy</span>
        <span class="s1">smry = Summary()</span>

        <span class="s1">const_idx = model.data.const_idx</span>
        <span class="s2">if </span><span class="s1">const_idx </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">exog_names.pop(const_idx)</span>

        <span class="s1">J = int(getattr(model</span><span class="s2">, </span><span class="s5">&quot;J&quot;</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>
        <span class="s2">if </span><span class="s1">J &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">yname</span><span class="s2">, </span><span class="s1">yname_list = results._get_endog_name(model.endog_names</span><span class="s2">,</span>
                                                        <span class="s2">None, </span><span class="s1">all=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">yname = model.endog_names</span>
            <span class="s1">yname_list = [yname]</span>

        <span class="s1">smry.add_table_2cols(self</span><span class="s2">, </span><span class="s1">gleft=top_left</span><span class="s2">, </span><span class="s1">gright=[]</span><span class="s2">,</span>
                             <span class="s1">yname=yname</span><span class="s2">, </span><span class="s1">xname=exog_names</span><span class="s2">, </span><span class="s1">title=title)</span>

        <span class="s3"># NOTE: add_table_params is not general enough yet for margeff</span>
        <span class="s3"># could use a refactor with getattr instead of hard-coded params</span>
        <span class="s3"># tvalues etc.</span>
        <span class="s1">table = []</span>
        <span class="s1">conf_int = self.conf_int(alpha)</span>
        <span class="s1">margeff = self.margeff</span>
        <span class="s1">margeff_se = self.margeff_se</span>
        <span class="s1">tvalues = self.tvalues</span>
        <span class="s1">pvalues = self.pvalues</span>
        <span class="s2">if </span><span class="s1">J &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">eq </span><span class="s2">in </span><span class="s1">range(J):</span>
                <span class="s1">restup = (results</span><span class="s2">, </span><span class="s1">margeff[:</span><span class="s2">, </span><span class="s1">eq]</span><span class="s2">, </span><span class="s1">margeff_se[:</span><span class="s2">, </span><span class="s1">eq]</span><span class="s2">,</span>
                          <span class="s1">tvalues[:</span><span class="s2">, </span><span class="s1">eq]</span><span class="s2">, </span><span class="s1">pvalues[:</span><span class="s2">, </span><span class="s1">eq]</span><span class="s2">, </span><span class="s1">conf_int[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">eq])</span>
                <span class="s1">tble = summary_params(restup</span><span class="s2">, </span><span class="s1">yname=yname_list[eq]</span><span class="s2">,</span>
                                      <span class="s1">xname=exog_names</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">,</span>
                                      <span class="s1">use_t=</span><span class="s2">False,</span>
                                      <span class="s1">skip_header=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s1">tble.title = yname_list[eq]</span>
                <span class="s3"># overwrite coef with method name</span>
                <span class="s1">header = [</span><span class="s5">''</span><span class="s2">, </span><span class="s1">_transform_names[method]</span><span class="s2">, </span><span class="s5">'std err'</span><span class="s2">, </span><span class="s5">'z'</span><span class="s2">,</span>
                          <span class="s5">'P&gt;|z|'</span><span class="s2">,</span>
                          <span class="s5">'[%3.1f%% Conf. Int.]' </span><span class="s1">% (</span><span class="s4">100 </span><span class="s1">- alpha * </span><span class="s4">100</span><span class="s1">)]</span>
                <span class="s1">tble.insert_header_row(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">header)</span>
                <span class="s3"># from IPython.core.debugger import Pdb; Pdb().set_trace()</span>
                <span class="s1">table.append(tble)</span>

            <span class="s1">table = table_extend(table</span><span class="s2">, </span><span class="s1">keep_headers=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">restup = (results</span><span class="s2">, </span><span class="s1">margeff</span><span class="s2">, </span><span class="s1">margeff_se</span><span class="s2">, </span><span class="s1">tvalues</span><span class="s2">, </span><span class="s1">pvalues</span><span class="s2">, </span><span class="s1">conf_int)</span>
            <span class="s1">table = summary_params(restup</span><span class="s2">, </span><span class="s1">yname=yname</span><span class="s2">, </span><span class="s1">xname=exog_names</span><span class="s2">,</span>
                                   <span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False, </span><span class="s1">skip_header=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">header = [</span><span class="s5">''</span><span class="s2">, </span><span class="s1">_transform_names[method]</span><span class="s2">, </span><span class="s5">'std err'</span><span class="s2">, </span><span class="s5">'z'</span><span class="s2">,</span>
                      <span class="s5">'P&gt;|z|'</span><span class="s2">, </span><span class="s5">'[%3.1f%% Conf. Int.]' </span><span class="s1">% (</span><span class="s4">100 </span><span class="s1">- alpha * </span><span class="s4">100</span><span class="s1">)]</span>
            <span class="s1">table.insert_header_row(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">header)</span>

        <span class="s1">smry.tables.append(table)</span>
        <span class="s2">return </span><span class="s1">smry</span>

    <span class="s2">def </span><span class="s1">get_margeff(self</span><span class="s2">, </span><span class="s1">at=</span><span class="s5">'overall'</span><span class="s2">, </span><span class="s1">method=</span><span class="s5">'dydx'</span><span class="s2">, </span><span class="s1">atexog=</span><span class="s2">None,</span>
                    <span class="s1">dummy=</span><span class="s2">False, </span><span class="s1">count=</span><span class="s2">False</span><span class="s1">):</span>

        <span class="s1">self._reset()  </span><span class="s3"># always reset the cache when this is called</span>
        <span class="s3"># TODO: if at is not all or overall, we can also put atexog values</span>
        <span class="s3"># in summary table head</span>
        <span class="s1">method = method.lower()</span>
        <span class="s1">at = at.lower()</span>
        <span class="s1">_check_margeff_args(at</span><span class="s2">, </span><span class="s1">method)</span>
        <span class="s1">self.margeff_options = dict(method=method</span><span class="s2">, </span><span class="s1">at=at)</span>
        <span class="s1">results = self.results</span>
        <span class="s1">model = results.model</span>
        <span class="s1">params = results.params</span>
        <span class="s1">exog = model.exog.copy()  </span><span class="s3"># copy because values are changed</span>
        <span class="s1">effects_idx = exog.var(</span><span class="s4">0</span><span class="s1">) != </span><span class="s4">0</span>
        <span class="s1">const_idx = model.data.const_idx</span>

        <span class="s2">if </span><span class="s1">dummy:</span>
            <span class="s1">_check_discrete_args(at</span><span class="s2">, </span><span class="s1">method)</span>
            <span class="s1">dummy_idx</span><span class="s2">, </span><span class="s1">dummy = _get_dummy_index(exog</span><span class="s2">, </span><span class="s1">const_idx)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dummy_idx = </span><span class="s2">None</span>

        <span class="s2">if </span><span class="s1">count:</span>
            <span class="s1">_check_discrete_args(at</span><span class="s2">, </span><span class="s1">method)</span>
            <span class="s1">count_idx</span><span class="s2">, </span><span class="s1">count = _get_count_index(exog</span><span class="s2">, </span><span class="s1">const_idx)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">count_idx = </span><span class="s2">None</span>

        <span class="s3"># get the exogenous variables</span>
        <span class="s1">exog = _get_margeff_exog(exog</span><span class="s2">, </span><span class="s1">at</span><span class="s2">, </span><span class="s1">atexog</span><span class="s2">, </span><span class="s1">effects_idx)</span>

        <span class="s3"># get base marginal effects, handled by sub-classes</span>
        <span class="s1">effects = model._derivative_exog(params</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">method</span><span class="s2">,</span>
                                         <span class="s1">dummy_idx</span><span class="s2">, </span><span class="s1">count_idx)</span>
        <span class="s1">effects = _effects_at(effects</span><span class="s2">, </span><span class="s1">at)</span>

        <span class="s2">if </span><span class="s1">at == </span><span class="s5">'all'</span><span class="s1">:</span>
            <span class="s1">self.margeff = effects[:</span><span class="s2">, </span><span class="s1">effects_idx]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># Set standard error of the marginal effects by Delta method.</span>
            <span class="s1">margeff_cov</span><span class="s2">, </span><span class="s1">margeff_se = margeff_cov_with_se(</span>
                <span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">results.cov_params()</span><span class="s2">, </span><span class="s1">at</span><span class="s2">,</span>
                <span class="s1">model._derivative_exog</span><span class="s2">, </span><span class="s1">dummy_idx</span><span class="s2">, </span><span class="s1">count_idx</span><span class="s2">,</span>
                <span class="s1">method</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

            <span class="s3"># do not care about at constant</span>
            <span class="s1">self.margeff_cov = margeff_cov[effects_idx][:</span><span class="s2">, </span><span class="s1">effects_idx]</span>
            <span class="s1">self.margeff_se = margeff_se[effects_idx]</span>
            <span class="s1">self.margeff = effects[effects_idx]</span>
</pre>
</body>
</html>
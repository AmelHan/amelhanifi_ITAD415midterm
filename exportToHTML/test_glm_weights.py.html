<html>
<head>
<title>test_glm_weights.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #6a8759;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_glm_weights.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Test for weights in GLM, Poisson and OLS/WLS, continuous test_glm.py 
 
 
Below is a table outlining the test coverage. 
 
================================= ====================== ====== ===================== === ======= ======== ============== ============= ============== ============= ============== ==== ========= 
Test                              Compared To            params normalized_cov_params bse loglike deviance resid_response resid_pearson resid_deviance resid_working resid_anscombe chi2 optimizer 
================================= ====================== ====== ===================== === ======= ======== ============== ============= ============== ============= ============== ==== ========= 
TestGlmPoissonPlain               stata                  X                            X   X       X        X              X             X              X             X              X    bfgs 
TestGlmPoissonFwNr                stata                  X                            X   X       X        X              X             X              X             X              X    bfgs 
TestGlmPoissonAwNr                stata                  X                            X   X       X        X              X             X              X             X              X    bfgs 
TestGlmPoissonFwHC                stata                  X                            X   X       X                                                                                 X 
TestGlmPoissonAwHC                stata                  X                            X   X       X                                                                                 X 
TestGlmPoissonFwClu               stata                  X                            X   X       X                                                                                 X 
TestGlmTweedieAwNr                R                      X                            X           X        X              X             X              X                                 newton 
TestGlmGammaAwNr                  R                      X                            X   special X        X              X             X              X                                 bfgs 
TestGlmGaussianAwNr               R                      X                            X   special X        X              X             X              X                                 bfgs 
TestRepeatedvsAggregated          statsmodels.GLM        X      X                                                                                                                        bfgs 
TestRepeatedvsAverage             statsmodels.GLM        X      X                                                                                                                        bfgs 
TestTweedieRepeatedvsAggregated   statsmodels.GLM        X      X                                                                                                                        bfgs 
TestTweedieRepeatedvsAverage      statsmodels.GLM        X      X                                                                                                                        bfgs 
TestBinomial0RepeatedvsAverage    statsmodels.GLM        X      X 
TestBinomial0RepeatedvsDuplicated statsmodels.GLM        X      X                                                                                                                        bfgs 
TestBinomialVsVarWeights          statsmodels.GLM        X      X                     X                                                                                                  bfgs 
TestGlmGaussianWLS                statsmodels.WLS        X      X                     X                                                                                                  bfgs 
================================= ====================== ====== ===================== === ======= ======== ============== ============= ============== ============= ============== ==== ========= 
&quot;&quot;&quot;  </span><span class="s2"># noqa: E501</span>
<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">numpy.testing </span><span class="s3">import </span><span class="s1">assert_allclose</span><span class="s3">, </span><span class="s1">assert_raises</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>
<span class="s3">import </span><span class="s1">pytest</span>

<span class="s3">import </span><span class="s1">statsmodels.api </span><span class="s3">as </span><span class="s1">sm</span>
<span class="s2"># load data into module namespace</span>
<span class="s3">from </span><span class="s1">statsmodels.datasets.cpunish </span><span class="s3">import </span><span class="s1">load</span>
<span class="s3">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s3">import </span><span class="s1">GLM</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">SpecificationWarning</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.tools </span><span class="s3">import </span><span class="s1">add_constant</span>

<span class="s3">from </span><span class="s1">.results </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">res_R_var_weight </span><span class="s3">as </span><span class="s1">res_r</span><span class="s3">,</span>
    <span class="s1">results_glm_poisson_weights </span><span class="s3">as </span><span class="s1">res_stata</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s1">cpunish_data = load()</span>
<span class="s1">cpunish_data.exog = np.asarray(cpunish_data.exog)</span>
<span class="s1">cpunish_data.endog = np.asarray(cpunish_data.endog)</span>
<span class="s1">cpunish_data.exog[:</span><span class="s3">, </span><span class="s4">3</span><span class="s1">] = np.log(cpunish_data.exog[:</span><span class="s3">, </span><span class="s4">3</span><span class="s1">])</span>
<span class="s1">cpunish_data.exog = add_constant(cpunish_data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">CheckWeight:</span>
    <span class="s3">def </span><span class="s1">test_basic(self):</span>
        <span class="s1">res1 = self.res1</span>
        <span class="s1">res2 = self.res2</span>

        <span class="s1">assert_allclose(res1.params</span><span class="s3">, </span><span class="s1">res2.params</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s1">corr_fact = getattr(self</span><span class="s3">, </span><span class="s0">'corr_fact'</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">hasattr(res2</span><span class="s3">, </span><span class="s0">'normalized_cov_params'</span><span class="s1">):</span>
            <span class="s1">assert_allclose(res1.normalized_cov_params</span><span class="s3">,</span>
                            <span class="s1">res2.normalized_cov_params</span><span class="s3">,</span>
                            <span class="s1">atol=</span><span class="s4">1e-8</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">(TestRepeatedvsAggregated</span><span class="s3">, </span><span class="s1">TestRepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestTweedieRepeatedvsAggregated</span><span class="s3">,</span>
                             <span class="s1">TestTweedieRepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestBinomial0RepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestBinomial0RepeatedvsDuplicated)):</span>
            <span class="s2"># Loglikelihood, scale, deviance is different between repeated vs.</span>
            <span class="s2"># exposure/average</span>
            <span class="s3">return None</span>
        <span class="s1">assert_allclose(res1.bse</span><span class="s3">, </span><span class="s1">corr_fact * res2.bse</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">TestBinomialVsVarWeights):</span>
            <span class="s2"># Binomial ll and deviance are different for 1d vs. counts...</span>
            <span class="s3">return None</span>
        <span class="s3">if </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">TestGlmGaussianWLS):</span>
            <span class="s2"># This will not work right now either</span>
            <span class="s3">return None</span>
        <span class="s3">if not </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">(TestGlmGaussianAwNr</span><span class="s3">, </span><span class="s1">TestGlmGammaAwNr)):</span>
            <span class="s2"># Matching R is hard</span>
            <span class="s1">assert_allclose(res1.llf</span><span class="s3">, </span><span class="s1">res2.ll</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-7</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res1.deviance</span><span class="s3">, </span><span class="s1">res2.deviance</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-7</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_residuals(self):</span>
        <span class="s3">if </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">(TestRepeatedvsAggregated</span><span class="s3">, </span><span class="s1">TestRepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestTweedieRepeatedvsAggregated</span><span class="s3">,</span>
                             <span class="s1">TestTweedieRepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestBinomial0RepeatedvsAverage</span><span class="s3">,</span>
                             <span class="s1">TestBinomial0RepeatedvsDuplicated)):</span>
            <span class="s2"># This will not match as different number of records</span>
            <span class="s3">return None</span>
        <span class="s1">res1 = self.res1</span>
        <span class="s1">res2 = self.res2</span>
        <span class="s3">if not </span><span class="s1">hasattr(res2</span><span class="s3">, </span><span class="s0">'resids'</span><span class="s1">):</span>
            <span class="s3">return None  </span><span class="s2"># use SkipError instead</span>
        <span class="s1">resid_all = dict(zip(res2.resids_colnames</span><span class="s3">, </span><span class="s1">res2.resids.T))</span>

        <span class="s1">assert_allclose(res1.resid_response</span><span class="s3">, </span><span class="s1">resid_all[</span><span class="s0">'resid_response'</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res1.resid_pearson</span><span class="s3">, </span><span class="s1">resid_all[</span><span class="s0">'resid_pearson'</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res1.resid_deviance</span><span class="s3">, </span><span class="s1">resid_all[</span><span class="s0">'resid_deviance'</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res1.resid_working</span><span class="s3">, </span><span class="s1">resid_all[</span><span class="s0">'resid_working'</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">resid_all.get(</span><span class="s0">'resid_anscombe'</span><span class="s1">) </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">return None</span>
        <span class="s2"># Stata does not use var_weights in anscombe residuals, it seems.</span>
        <span class="s2"># Adjust residuals to match our approach.</span>
        <span class="s1">resid_a = res1.resid_anscombe</span>

        <span class="s1">resid_a1 = resid_all[</span><span class="s0">'resid_anscombe'</span><span class="s1">] * np.sqrt(res1._var_weights)</span>
        <span class="s1">assert_allclose(resid_a</span><span class="s3">, </span><span class="s1">resid_a1</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-6</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_compare_optimizers(self):</span>
        <span class="s1">res1 = self.res1</span>
        <span class="s3">if </span><span class="s1">isinstance(res1.model.family</span><span class="s3">, </span><span class="s1">sm.families.Tweedie):</span>
            <span class="s1">method = </span><span class="s0">'newton'</span>
            <span class="s1">optim_hessian = </span><span class="s0">'eim'</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">method = </span><span class="s0">'bfgs'</span>
            <span class="s1">optim_hessian = </span><span class="s0">'oim'</span>
        <span class="s3">if </span><span class="s1">isinstance(self</span><span class="s3">, </span><span class="s1">(TestGlmPoissonFwHC</span><span class="s3">, </span><span class="s1">TestGlmPoissonAwHC</span><span class="s3">,</span>
                             <span class="s1">TestGlmPoissonFwClu</span><span class="s3">,</span>
                             <span class="s1">TestBinomial0RepeatedvsAverage)):</span>
            <span class="s3">return None</span>

        <span class="s1">start_params = res1.params</span>
        <span class="s1">res2 = self.res1.model.fit(start_params=start_params</span><span class="s3">, </span><span class="s1">method=method</span><span class="s3">,</span>
                                   <span class="s1">optim_hessian=optim_hessian)</span>
        <span class="s1">assert_allclose(res1.params</span><span class="s3">, </span><span class="s1">res2.params</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-3</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">2e-3</span><span class="s1">)</span>
        <span class="s1">H = res2.model.hessian(res2.params</span><span class="s3">, </span><span class="s1">observed=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res2_bse = np.sqrt(-np.diag(np.linalg.inv(H)))</span>
        <span class="s1">assert_allclose(res1.bse</span><span class="s3">, </span><span class="s1">res2_bse</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-3</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-3</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_pearson_chi2(self):</span>
        <span class="s3">if </span><span class="s1">hasattr(self.res2</span><span class="s3">, </span><span class="s0">'chi2'</span><span class="s1">):</span>
            <span class="s1">assert_allclose(self.res1.pearson_chi2</span><span class="s3">, </span><span class="s1">self.res2.deviance_p</span><span class="s3">,</span>
                            <span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_getprediction(self):</span>
        <span class="s1">pred = self.res1.get_prediction()</span>
        <span class="s1">assert_allclose(pred.linpred.se_mean</span><span class="s3">, </span><span class="s1">pred.linpred.se_mean</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestGlmPoissonPlain(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">cls.res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Poisson()).fit()</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_none_nonrobust</span>


<span class="s3">class </span><span class="s1">TestGlmPoissonFwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s1">fweights = np.array(fweights)</span>

        <span class="s1">cls.res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">freq_weights=fweights</span>
                       <span class="s1">).fit()</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_fweight_nonrobust</span>


<span class="s3">class </span><span class="s1">TestGlmPoissonAwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2"># faking aweights by using normalized freq_weights</span>
        <span class="s1">fweights = np.array(fweights)</span>
        <span class="s1">wsum = fweights.sum()</span>
        <span class="s1">nobs = len(cpunish_data.endog)</span>
        <span class="s1">aweights = fweights / wsum * nobs</span>

        <span class="s1">cls.res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">var_weights=aweights</span>
                       <span class="s1">).fit()</span>

        <span class="s2"># Need to copy to avoid inplace adjustment</span>
        <span class="s3">from </span><span class="s1">copy </span><span class="s3">import </span><span class="s1">copy</span>
        <span class="s1">cls.res2 = copy(res_stata.results_poisson_aweight_nonrobust)</span>
        <span class="s1">cls.res2.resids = cls.res2.resids.copy()</span>

        <span class="s2"># Need to adjust resids for pearson and deviance to add weights</span>
        <span class="s1">cls.res2.resids[:</span><span class="s3">, </span><span class="s4">3</span><span class="s1">:</span><span class="s4">5</span><span class="s1">] *= np.sqrt(aweights[:</span><span class="s3">, </span><span class="s1">np.newaxis])</span>


<span class="s2"># prob_weights fail with HC, not properly implemented yet</span>
<span class="s3">class </span><span class="s1">TestGlmPoissonPwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2"># faking aweights by using normalized freq_weights</span>
        <span class="s1">fweights = np.array(fweights)</span>
        <span class="s1">wsum = fweights.sum()</span>
        <span class="s1">nobs = len(cpunish_data.endog)</span>
        <span class="s1">aweights = fweights / wsum * nobs</span>

        <span class="s1">cls.res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">freq_weights=fweights</span>
                       <span class="s1">).fit(cov_type=</span><span class="s0">'HC1'</span><span class="s1">)</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_pweight_nonrobust</span>

    <span class="s2"># TODO: find more informative reasons why these fail</span>
    <span class="s1">@pytest.mark.xfail(reason=</span><span class="s0">'Known to fail'</span><span class="s3">, </span><span class="s1">strict=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">test_basic(self):</span>
        <span class="s1">super(TestGlmPoissonPwNr</span><span class="s3">, </span><span class="s1">self).test_basic()</span>

    <span class="s1">@pytest.mark.xfail(reason=</span><span class="s0">'Known to fail'</span><span class="s3">, </span><span class="s1">strict=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">test_compare_optimizers(self):</span>
        <span class="s1">super(TestGlmPoissonPwNr</span><span class="s3">, </span><span class="s1">self).test_compare_optimizers()</span>


<span class="s3">class </span><span class="s1">TestGlmPoissonFwHC(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2"># faking aweights by using normalized freq_weights</span>
        <span class="s1">fweights = np.array(fweights)</span>
        <span class="s1">wsum = fweights.sum()</span>
        <span class="s1">nobs = len(cpunish_data.endog)</span>
        <span class="s1">aweights = fweights / wsum * nobs</span>
        <span class="s1">cls.corr_fact = np.sqrt((wsum - </span><span class="s4">1.</span><span class="s1">) / wsum)</span>

        <span class="s1">mod = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                  <span class="s1">family=sm.families.Poisson()</span><span class="s3">,</span>
                  <span class="s1">freq_weights=fweights)</span>
        <span class="s1">cls.res1 = mod.fit(cov_type=</span><span class="s0">'HC0'</span><span class="s1">)</span>
        <span class="s2"># cov_kwds={'use_correction':False})</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_fweight_hc1</span>


<span class="s2"># var_weights (aweights fail with HC, not properly implemented yet</span>
<span class="s3">class </span><span class="s1">TestGlmPoissonAwHC(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2"># faking aweights by using normalized freq_weights</span>
        <span class="s1">fweights = np.array(fweights)</span>
        <span class="s1">wsum = fweights.sum()</span>
        <span class="s1">nobs = len(cpunish_data.endog)</span>
        <span class="s1">aweights = fweights / wsum * nobs</span>

        <span class="s2"># This is really close when corr_fact = (wsum - 1.) / wsum, but to</span>
        <span class="s2"># avoid having loosen precision of the assert_allclose, I'm doing this</span>
        <span class="s2"># manually. Its *possible* lowering the IRLS convergence criterion</span>
        <span class="s2"># in stata and here will make this less sketchy.</span>
        <span class="s1">cls.corr_fact = np.sqrt((wsum - </span><span class="s4">1.</span><span class="s1">) / wsum) * </span><span class="s4">0.98518473599905609</span>
        <span class="s1">mod = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                  <span class="s1">family=sm.families.Poisson()</span><span class="s3">,</span>
                  <span class="s1">var_weights=aweights)</span>
        <span class="s1">cls.res1 = mod.fit(cov_type=</span><span class="s0">'HC0'</span><span class="s1">)</span>
        <span class="s2"># cov_kwds={'use_correction':False})</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_aweight_hc1</span>


<span class="s3">class </span><span class="s1">TestGlmPoissonFwClu(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">fweights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2"># faking aweights by using normalized freq_weights</span>
        <span class="s1">fweights = np.array(fweights)</span>
        <span class="s1">wsum = fweights.sum()</span>
        <span class="s1">nobs = len(cpunish_data.endog)</span>
        <span class="s1">aweights = fweights / wsum * nobs</span>

        <span class="s1">gid = np.arange(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">17 </span><span class="s1">+ </span><span class="s4">1</span><span class="s1">) // </span><span class="s4">2</span>
        <span class="s1">n_groups = len(np.unique(gid))</span>

        <span class="s2"># no wnobs yet in sandwich covariance calcualtion</span>
        <span class="s1">cls.corr_fact = </span><span class="s4">1 </span><span class="s1">/ np.sqrt(n_groups / (n_groups - </span><span class="s4">1</span><span class="s1">))</span>
        <span class="s2"># np.sqrt((wsum - 1.) / wsum)</span>
        <span class="s1">cov_kwds = {</span><span class="s0">'groups'</span><span class="s1">: gid</span><span class="s3">, </span><span class="s0">'use_correction'</span><span class="s1">: </span><span class="s3">False</span><span class="s1">}</span>
        <span class="s3">with </span><span class="s1">pytest.warns(SpecificationWarning):</span>
            <span class="s1">mod = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                      <span class="s1">family=sm.families.Poisson()</span><span class="s3">,</span>
                      <span class="s1">freq_weights=fweights)</span>
            <span class="s1">cls.res1 = mod.fit(cov_type=</span><span class="s0">'cluster'</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds)</span>

        <span class="s1">cls.res2 = res_stata.results_poisson_fweight_clu1</span>


<span class="s3">class </span><span class="s1">TestGlmTweedieAwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">import </span><span class="s1">statsmodels.formula.api </span><span class="s3">as </span><span class="s1">smf</span>

        <span class="s1">data = sm.datasets.fair.load_pandas()</span>
        <span class="s1">endog = data.endog</span>
        <span class="s1">data = data.exog</span>
        <span class="s1">data[</span><span class="s0">'fair'</span><span class="s1">] = endog</span>
        <span class="s1">aweights = np.repeat(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">len(data.index))</span>
        <span class="s1">aweights[::</span><span class="s4">5</span><span class="s1">] = </span><span class="s4">5</span>
        <span class="s1">aweights[::</span><span class="s4">13</span><span class="s1">] = </span><span class="s4">3</span>
        <span class="s1">model = smf.glm(</span>
                <span class="s0">'fair ~ age + yrs_married'</span><span class="s3">,</span>
                <span class="s1">data=data</span><span class="s3">,</span>
                <span class="s1">family=sm.families.Tweedie(</span>
                    <span class="s1">var_power=</span><span class="s4">1.55</span><span class="s3">,</span>
                    <span class="s1">link=sm.families.links.Log()</span>
                    <span class="s1">)</span><span class="s3">,</span>
                <span class="s1">var_weights=aweights</span>
        <span class="s1">)</span>
        <span class="s1">cls.res1 = model.fit(rtol=</span><span class="s4">1e-25</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">cls.res2 = res_r.results_tweedie_aweights_nonrobust</span>


<span class="s3">class </span><span class="s1">TestGlmGammaAwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">.results.results_glm </span><span class="s3">import </span><span class="s1">CancerLog</span>
        <span class="s1">res2 = CancerLog()</span>
        <span class="s1">endog = res2.endog</span>
        <span class="s1">exog = res2.exog[:</span><span class="s3">, </span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">exog = sm.add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">True</span><span class="s1">)</span>

        <span class="s1">aweights = np.repeat(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">len(endog))</span>
        <span class="s1">aweights[::</span><span class="s4">5</span><span class="s1">] = </span><span class="s4">5</span>
        <span class="s1">aweights[::</span><span class="s4">13</span><span class="s1">] = </span><span class="s4">3</span>
        <span class="s1">model = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Gamma(link=sm.families.links.Log())</span><span class="s3">,</span>
                       <span class="s1">var_weights=aweights)</span>
        <span class="s1">cls.res1 = model.fit(rtol=</span><span class="s4">1e-25</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">cls.res2 = res_r.results_gamma_aweights_nonrobust</span>

    <span class="s3">def </span><span class="s1">test_r_llf(self):</span>
        <span class="s1">scale = self.res1.deviance / self.res1._iweights.sum()</span>
        <span class="s1">ll = self.res1.family.loglike(self.res1.model.endog</span><span class="s3">,</span>
                                      <span class="s1">self.res1.mu</span><span class="s3">,</span>
                                      <span class="s1">freq_weights=self.res1._var_weights</span><span class="s3">,</span>
                                      <span class="s1">scale=scale)</span>
        <span class="s1">assert_allclose(ll</span><span class="s3">, </span><span class="s1">self.res2.ll</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-7</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestGlmGaussianAwNr(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">import </span><span class="s1">statsmodels.formula.api </span><span class="s3">as </span><span class="s1">smf</span>

        <span class="s1">data = sm.datasets.cpunish.load_pandas()</span>
        <span class="s1">endog = data.endog</span>
        <span class="s1">data = data.exog</span>
        <span class="s1">data[</span><span class="s0">'EXECUTIONS'</span><span class="s1">] = endog</span>
        <span class="s1">data[</span><span class="s0">'INCOME'</span><span class="s1">] /= </span><span class="s4">1000</span>
        <span class="s1">aweights = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">,</span>
                             <span class="s4">1</span><span class="s1">])</span>
        <span class="s1">model = smf.glm(</span>
                <span class="s0">'EXECUTIONS ~ INCOME + SOUTH - 1'</span><span class="s3">,</span>
                <span class="s1">data=data</span><span class="s3">,</span>
                <span class="s1">family=sm.families.Gaussian(link=sm.families.links.Log())</span><span class="s3">,</span>
                <span class="s1">var_weights=aweights</span>
        <span class="s1">)</span>
        <span class="s1">cls.res1 = model.fit(rtol=</span><span class="s4">1e-25</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">cls.res2 = res_r.results_gaussian_aweights_nonrobust</span>

    <span class="s3">def </span><span class="s1">test_r_llf(self):</span>
        <span class="s1">res1 = self.res1</span>
        <span class="s1">res2 = self.res2</span>
        <span class="s1">model = self.res1.model</span>

        <span class="s2"># Need to make a few adjustments...</span>
        <span class="s2"># First, calculate scale using nobs as denominator</span>
        <span class="s1">scale = res1.scale * model.df_resid / model.wnobs</span>
        <span class="s2"># Calculate llf using adj scale and wts = freq_weights</span>
        <span class="s1">wts = model.freq_weights</span>
        <span class="s1">llf = model.family.loglike(model.endog</span><span class="s3">, </span><span class="s1">res1.mu</span><span class="s3">,</span>
                                   <span class="s1">freq_weights=wts</span><span class="s3">,</span>
                                   <span class="s1">scale=scale)</span>
        <span class="s2"># SM uses (essentially) stat's loglike formula... first term is</span>
        <span class="s2"># (endog - mu) ** 2 / scale</span>
        <span class="s1">adj_sm = -</span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">2 </span><span class="s1">* ((model.endog - res1.mu) ** </span><span class="s4">2</span><span class="s1">).sum() / scale</span>
        <span class="s2"># R has these 2 terms that stata/sm do not</span>
        <span class="s1">adj_r = -model.wnobs / </span><span class="s4">2 </span><span class="s1">+ np.sum(np.log(model.var_weights)) / </span><span class="s4">2</span>
        <span class="s1">llf_adj = llf - adj_sm + adj_r</span>
        <span class="s1">assert_allclose(llf_adj</span><span class="s3">, </span><span class="s1">res2.ll</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-7</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family_class</span><span class="s3">, </span><span class="s1">link</span><span class="s3">, </span><span class="s1">binom_version=</span><span class="s4">0</span><span class="s1">):</span>

    <span class="s1">np.random.seed(</span><span class="s4">872</span><span class="s1">)</span>

    <span class="s1">fam = sm.families</span>

    <span class="s1">mu = link().inverse(lin_pred)</span>

    <span class="s3">if </span><span class="s1">family_class == fam.Binomial:</span>
        <span class="s3">if </span><span class="s1">binom_version == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">endog = </span><span class="s4">1</span><span class="s1">*(np.random.uniform(size=len(lin_pred)) &lt; mu)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">endog = np.empty((len(lin_pred)</span><span class="s3">, </span><span class="s4">2</span><span class="s1">))</span>
            <span class="s1">n = </span><span class="s4">10</span>
            <span class="s1">endog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = (np.random.uniform(size=(len(lin_pred)</span><span class="s3">, </span><span class="s1">n)) &lt;</span>
                           <span class="s1">mu[:</span><span class="s3">, None</span><span class="s1">]).sum(</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">endog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = n - endog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.Poisson:</span>
        <span class="s1">endog = np.random.poisson(mu)</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.Gamma:</span>
        <span class="s1">endog = np.random.gamma(</span><span class="s4">2</span><span class="s3">, </span><span class="s1">mu)</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.Gaussian:</span>
        <span class="s1">endog = mu + np.random.normal(size=len(lin_pred))</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.NegativeBinomial:</span>
        <span class="s3">from </span><span class="s1">scipy.stats.distributions </span><span class="s3">import </span><span class="s1">nbinom</span>
        <span class="s1">endog = nbinom.rvs(mu</span><span class="s3">, </span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.InverseGaussian:</span>
        <span class="s3">from </span><span class="s1">scipy.stats.distributions </span><span class="s3">import </span><span class="s1">invgauss</span>
        <span class="s1">endog = invgauss.rvs(mu)</span>
    <span class="s3">elif </span><span class="s1">family_class == fam.Tweedie:</span>
        <span class="s1">rate = </span><span class="s4">1</span>
        <span class="s1">shape = </span><span class="s4">1.0</span>
        <span class="s1">scale = mu / (rate * shape)</span>
        <span class="s1">endog = (np.random.poisson(rate</span><span class="s3">, </span><span class="s1">size=scale.shape[</span><span class="s4">0</span><span class="s1">]) *</span>
                 <span class="s1">np.random.gamma(shape * scale))</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span>

    <span class="s3">return </span><span class="s1">endog</span>


<span class="s3">def </span><span class="s1">test_wtd_gradient_irls():</span>
    <span class="s2"># Compare the results when using gradient optimization and IRLS.</span>
    <span class="s2"># TODO: Find working examples for inverse_squared link</span>

    <span class="s1">np.random.seed(</span><span class="s4">87342</span><span class="s1">)</span>

    <span class="s1">fam = sm.families</span>
    <span class="s1">lnk = sm.families.links</span>
    <span class="s1">families = [(fam.Binomial</span><span class="s3">, </span><span class="s1">[lnk.Logit</span><span class="s3">, </span><span class="s1">lnk.Probit</span><span class="s3">, </span><span class="s1">lnk.CLogLog</span><span class="s3">, </span><span class="s1">lnk.Log</span><span class="s3">,</span>
                                <span class="s1">lnk.Cauchy])</span><span class="s3">,</span>
                <span class="s1">(fam.Poisson</span><span class="s3">, </span><span class="s1">[lnk.Log</span><span class="s3">, </span><span class="s1">lnk.Identity</span><span class="s3">, </span><span class="s1">lnk.Sqrt])</span><span class="s3">,</span>
                <span class="s1">(fam.Gamma</span><span class="s3">, </span><span class="s1">[lnk.Log</span><span class="s3">, </span><span class="s1">lnk.Identity</span><span class="s3">, </span><span class="s1">lnk.InversePower])</span><span class="s3">,</span>
                <span class="s1">(fam.Gaussian</span><span class="s3">, </span><span class="s1">[lnk.Identity</span><span class="s3">, </span><span class="s1">lnk.Log</span><span class="s3">, </span><span class="s1">lnk.InversePower])</span><span class="s3">,</span>
                <span class="s1">(fam.InverseGaussian</span><span class="s3">, </span><span class="s1">[lnk.Log</span><span class="s3">, </span><span class="s1">lnk.Identity</span><span class="s3">,</span>
                                       <span class="s1">lnk.InversePower</span><span class="s3">,</span>
                                       <span class="s1">lnk.InverseSquared])</span><span class="s3">,</span>
                <span class="s1">(fam.NegativeBinomial</span><span class="s3">, </span><span class="s1">[lnk.Log</span><span class="s3">, </span><span class="s1">lnk.InversePower</span><span class="s3">,</span>
                                        <span class="s1">lnk.InverseSquared</span><span class="s3">, </span><span class="s1">lnk.Identity])]</span>

    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">3</span>
    <span class="s1">exog = np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span>
    <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>

    <span class="s1">skip_one = </span><span class="s3">False</span>
    <span class="s3">for </span><span class="s1">family_class</span><span class="s3">, </span><span class="s1">family_links </span><span class="s3">in </span><span class="s1">families:</span>
        <span class="s3">for </span><span class="s1">link </span><span class="s3">in </span><span class="s1">family_links:</span>
            <span class="s3">for </span><span class="s1">binom_version </span><span class="s3">in </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">method = </span><span class="s0">'bfgs'</span>

                <span class="s3">if </span><span class="s1">family_class != fam.Binomial </span><span class="s3">and </span><span class="s1">binom_version == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">family_class == fam.Binomial </span><span class="s3">and </span><span class="s1">link == lnk.CLogLog:</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">family_class == fam.Binomial </span><span class="s3">and </span><span class="s1">link == lnk.Log:</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Poisson</span><span class="s3">, </span><span class="s1">lnk.Identity):</span>
                    <span class="s1">lin_pred = </span><span class="s4">20 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">)</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Binomial</span><span class="s3">, </span><span class="s1">lnk.Log):</span>
                    <span class="s1">lin_pred = -</span><span class="s4">1 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">) / </span><span class="s4">8</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Poisson</span><span class="s3">, </span><span class="s1">lnk.Sqrt):</span>
                    <span class="s1">lin_pred = -</span><span class="s4">2 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">)</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gamma</span><span class="s3">, </span><span class="s1">lnk.Log):</span>
                    <span class="s2"># Cannot get gradient to converge with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gamma</span><span class="s3">, </span><span class="s1">lnk.Identity):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gamma</span><span class="s3">, </span><span class="s1">lnk.InversePower):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gaussian</span><span class="s3">, </span><span class="s1">lnk.Log):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gaussian</span><span class="s3">, </span><span class="s1">lnk.InversePower):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.InverseGaussian</span><span class="s3">, </span><span class="s1">lnk.Log):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s1">lin_pred = -</span><span class="s4">1 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">)</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.InverseGaussian</span><span class="s3">,</span>
                                              <span class="s1">lnk.Identity):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s1">lin_pred = </span><span class="s4">20 </span><span class="s1">+ </span><span class="s4">5</span><span class="s1">*exog.sum(</span><span class="s4">1</span><span class="s1">)</span>
                    <span class="s1">lin_pred = np.clip(lin_pred</span><span class="s3">, </span><span class="s4">1e-4</span><span class="s3">, </span><span class="s1">np.inf)</span>
                    <span class="s3">continue</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.InverseGaussian</span><span class="s3">,</span>
                                              <span class="s1">lnk.InverseSquared):</span>
                    <span class="s1">lin_pred = </span><span class="s4">0.5 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">) / </span><span class="s4">5</span>
                    <span class="s3">continue  </span><span class="s2"># skip due to non-convergence</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.InverseGaussian</span><span class="s3">,</span>
                                              <span class="s1">lnk.InversePower):</span>
                    <span class="s1">lin_pred = </span><span class="s4">1 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">) / </span><span class="s4">5</span>
                    <span class="s1">method = </span><span class="s0">'newton'</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.NegativeBinomial</span><span class="s3">,</span>
                                              <span class="s1">lnk.Identity):</span>
                    <span class="s1">lin_pred = </span><span class="s4">20 </span><span class="s1">+ </span><span class="s4">5</span><span class="s1">*exog.sum(</span><span class="s4">1</span><span class="s1">)</span>
                    <span class="s1">lin_pred = np.clip(lin_pred</span><span class="s3">, </span><span class="s4">1e-3</span><span class="s3">, </span><span class="s1">np.inf)</span>
                    <span class="s1">method = </span><span class="s0">'newton'</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.NegativeBinomial</span><span class="s3">,</span>
                                              <span class="s1">lnk.InverseSquared):</span>
                    <span class="s1">lin_pred = </span><span class="s4">0.1 </span><span class="s1">+ np.random.uniform(size=exog.shape[</span><span class="s4">0</span><span class="s1">])</span>
                    <span class="s3">continue  </span><span class="s2"># skip due to non-convergence</span>
                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.NegativeBinomial</span><span class="s3">,</span>
                                              <span class="s1">lnk.InversePower):</span>
                    <span class="s2"># Cannot get gradient to converage with var_weights here</span>
                    <span class="s1">lin_pred = </span><span class="s4">1 </span><span class="s1">+ exog.sum(</span><span class="s4">1</span><span class="s1">) / </span><span class="s4">5</span>
                    <span class="s3">continue</span>

                <span class="s3">elif </span><span class="s1">(family_class</span><span class="s3">, </span><span class="s1">link) == (fam.Gaussian</span><span class="s3">, </span><span class="s1">lnk.InversePower):</span>
                    <span class="s2"># adding skip because of convergence failure</span>
                    <span class="s1">skip_one = </span><span class="s3">True</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">lin_pred = np.random.uniform(size=exog.shape[</span><span class="s4">0</span><span class="s1">])</span>

                <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family_class</span><span class="s3">, </span><span class="s1">link</span><span class="s3">, </span><span class="s1">binom_version)</span>
                <span class="s3">if </span><span class="s1">binom_version == </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">wts = np.ones_like(endog)</span>
                    <span class="s1">tmp = np.random.randint(</span>
                            <span class="s4">2</span><span class="s3">,</span>
                            <span class="s4">5</span><span class="s3">,</span>
                            <span class="s1">size=(endog &gt; endog.mean()).sum()</span>
                    <span class="s1">)</span>
                    <span class="s1">wts[endog &gt; endog.mean()] = tmp</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">wts = np.ones(shape=endog.shape[</span><span class="s4">0</span><span class="s1">])</span>
                    <span class="s1">y = endog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] / endog.sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
                    <span class="s1">tmp = np.random.gamma(</span><span class="s4">2</span><span class="s3">, </span><span class="s1">size=(y &gt; y.mean()).sum())</span>
                    <span class="s1">wts[y &gt; y.mean()] = tmp</span>

                <span class="s3">with </span><span class="s1">warnings.catch_warnings():</span>
                    <span class="s1">warnings.simplefilter(</span><span class="s0">&quot;ignore&quot;</span><span class="s1">)</span>
                    <span class="s1">mod_irls = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">var_weights=wts</span><span class="s3">,</span>
                                      <span class="s1">family=family_class(link=link()))</span>
                <span class="s1">rslt_irls = mod_irls.fit(method=</span><span class="s0">&quot;IRLS&quot;</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-10</span><span class="s3">,</span>
                                         <span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s1">)</span>

                <span class="s2"># Try with and without starting values.</span>
                <span class="s3">for </span><span class="s1">max_start_irls</span><span class="s3">, </span><span class="s1">start_params </span><span class="s3">in </span><span class="s1">((</span><span class="s4">0</span><span class="s3">, </span><span class="s1">rslt_irls.params)</span><span class="s3">,</span>
                                                     <span class="s1">(</span><span class="s4">3</span><span class="s3">, None</span><span class="s1">)):</span>
                    <span class="s2"># TODO: skip convergence failures for now</span>
                    <span class="s3">if </span><span class="s1">max_start_irls &gt; </span><span class="s4">0 </span><span class="s3">and </span><span class="s1">skip_one:</span>
                        <span class="s3">continue</span>
                    <span class="s3">with </span><span class="s1">warnings.catch_warnings():</span>
                        <span class="s1">warnings.simplefilter(</span><span class="s0">&quot;ignore&quot;</span><span class="s1">)</span>
                        <span class="s1">mod_gradient = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">var_weights=wts</span><span class="s3">,</span>
                                              <span class="s1">family=family_class(link=link()))</span>
                    <span class="s1">rslt_gradient = mod_gradient.fit(</span>
                            <span class="s1">max_start_irls=max_start_irls</span><span class="s3">,</span>
                            <span class="s1">start_params=start_params</span><span class="s3">,</span>
                            <span class="s1">method=method</span>
                    <span class="s1">)</span>
                    <span class="s1">assert_allclose(rslt_gradient.params</span><span class="s3">,</span>
                                    <span class="s1">rslt_irls.params</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">5e-5</span><span class="s1">)</span>

                    <span class="s1">assert_allclose(rslt_gradient.llf</span><span class="s3">, </span><span class="s1">rslt_irls.llf</span><span class="s3">,</span>
                                    <span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s1">)</span>

                    <span class="s1">assert_allclose(rslt_gradient.scale</span><span class="s3">, </span><span class="s1">rslt_irls.scale</span><span class="s3">,</span>
                                    <span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s1">)</span>

                    <span class="s2"># Get the standard errors using expected information.</span>
                    <span class="s1">gradient_bse = rslt_gradient.bse</span>
                    <span class="s1">ehess = mod_gradient.hessian(rslt_gradient.params</span><span class="s3">,</span>
                                                 <span class="s1">observed=</span><span class="s3">False</span><span class="s1">)</span>
                    <span class="s1">gradient_bse = np.sqrt(-np.diag(np.linalg.inv(ehess)))</span>
                    <span class="s1">assert_allclose(gradient_bse</span><span class="s3">, </span><span class="s1">rslt_irls.bse</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-6</span><span class="s3">,</span>
                                    <span class="s1">atol=</span><span class="s4">5e-5</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">get_dummies(x):</span>
    <span class="s1">values = np.sort(np.unique(x))</span>
    <span class="s1">out = np.zeros(shape=(x.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">len(values) - </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">v </span><span class="s3">in </span><span class="s1">enumerate(values):</span>
        <span class="s3">if </span><span class="s1">i == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s3">continue</span>
        <span class="s1">out[:</span><span class="s3">, </span><span class="s1">i - </span><span class="s4">1</span><span class="s1">] = np.where(v == x</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">out</span>


<span class="s3">class </span><span class="s1">TestRepeatedvsAggregated(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">100</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Poisson</span>
        <span class="s1">link = sm.families.links.Log</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link()))</span>
        <span class="s1">cls.res1 = mod1.fit()</span>

        <span class="s1">agg = pd.DataFrame(exog)</span>
        <span class="s1">agg[</span><span class="s0">'endog'</span><span class="s1">] = endog</span>
        <span class="s1">agg_endog = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).sum()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_wt = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).count()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_exog = np.array(agg_endog.index.tolist())</span>
        <span class="s1">agg_wt = agg_wt[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">agg_endog = agg_endog[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">mod2 = sm.GLM(agg_endog</span><span class="s3">, </span><span class="s1">agg_exog</span><span class="s3">, </span><span class="s1">family=family(link=link())</span><span class="s3">,</span>
                      <span class="s1">exposure=agg_wt)</span>
        <span class="s1">cls.res2 = mod2.fit()</span>


<span class="s3">class </span><span class="s1">TestRepeatedvsAverage(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">10000</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Poisson</span>
        <span class="s1">link = sm.families.links.Log</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link()))</span>
        <span class="s1">cls.res1 = mod1.fit()</span>

        <span class="s1">agg = pd.DataFrame(exog)</span>
        <span class="s1">agg[</span><span class="s0">'endog'</span><span class="s1">] = endog</span>
        <span class="s1">agg_endog = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).sum()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_wt = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).count()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_exog = np.array(agg_endog.index.tolist())</span>
        <span class="s1">agg_wt = agg_wt[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">avg_endog = agg_endog[</span><span class="s0">'endog'</span><span class="s1">] / agg_wt</span>
        <span class="s1">mod2 = sm.GLM(avg_endog</span><span class="s3">, </span><span class="s1">agg_exog</span><span class="s3">, </span><span class="s1">family=family(link=link())</span><span class="s3">,</span>
                      <span class="s1">var_weights=agg_wt)</span>
        <span class="s1">cls.res2 = mod2.fit()</span>


<span class="s3">class </span><span class="s1">TestTweedieRepeatedvsAggregated(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">10000</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([</span><span class="s4">7</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Tweedie</span>
        <span class="s1">link = sm.families.links.Log</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link()</span><span class="s3">, </span><span class="s1">var_power=</span><span class="s4">1.5</span><span class="s1">))</span>
        <span class="s1">cls.res1 = mod1.fit(rtol=</span><span class="s4">1e-20</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s1">)</span>

        <span class="s1">agg = pd.DataFrame(exog)</span>
        <span class="s1">agg[</span><span class="s0">'endog'</span><span class="s1">] = endog</span>
        <span class="s1">agg_endog = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).sum()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_wt = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).count()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_exog = np.array(agg_endog.index.tolist())</span>
        <span class="s1">agg_wt = agg_wt[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">agg_endog = agg_endog[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">mod2 = sm.GLM(agg_endog</span><span class="s3">, </span><span class="s1">agg_exog</span><span class="s3">,</span>
                      <span class="s1">family=family(link=link()</span><span class="s3">, </span><span class="s1">var_power=</span><span class="s4">1.5</span><span class="s1">)</span><span class="s3">,</span>
                      <span class="s1">exposure=agg_wt</span><span class="s3">, </span><span class="s1">var_weights=agg_wt ** </span><span class="s4">0.5</span><span class="s1">)</span>
        <span class="s1">cls.res2 = mod2.fit(rtol=</span><span class="s4">1e-20</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestTweedieRepeatedvsAverage(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">1000</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([</span><span class="s4">7</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Tweedie</span>
        <span class="s1">link = sm.families.links.Log</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link()</span><span class="s3">, </span><span class="s1">var_power=</span><span class="s4">1.5</span><span class="s1">))</span>
        <span class="s1">cls.res1 = mod1.fit(rtol=</span><span class="s4">1e-10</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s3">,</span>
                            <span class="s1">scaletype=</span><span class="s0">'x2'</span><span class="s1">)</span>

        <span class="s1">agg = pd.DataFrame(exog)</span>
        <span class="s1">agg[</span><span class="s0">'endog'</span><span class="s1">] = endog</span>
        <span class="s1">agg_endog = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).sum()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_wt = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).count()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_exog = np.array(agg_endog.index.tolist())</span>
        <span class="s1">agg_wt = agg_wt[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">avg_endog = agg_endog[</span><span class="s0">'endog'</span><span class="s1">] / agg_wt</span>
        <span class="s1">mod2 = sm.GLM(avg_endog</span><span class="s3">, </span><span class="s1">agg_exog</span><span class="s3">,</span>
                      <span class="s1">family=family(link=link()</span><span class="s3">, </span><span class="s1">var_power=</span><span class="s4">1.5</span><span class="s1">)</span><span class="s3">,</span>
                      <span class="s1">var_weights=agg_wt)</span>
        <span class="s1">cls.res2 = mod2.fit(rtol=</span><span class="s4">1e-10</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestBinomial0RepeatedvsAverage(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">20</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Binomial</span>
        <span class="s1">link = sm.families.links.Logit</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link</span><span class="s3">, </span><span class="s1">binom_version=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link()))</span>
        <span class="s1">cls.res1 = mod1.fit(rtol=</span><span class="s4">1e-10</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s3">,</span>
                            <span class="s1">scaletype=</span><span class="s0">'x2'</span><span class="s1">)</span>

        <span class="s1">agg = pd.DataFrame(exog)</span>
        <span class="s1">agg[</span><span class="s0">'endog'</span><span class="s1">] = endog</span>
        <span class="s1">agg_endog = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).sum()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_wt = agg.groupby([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]).count()[[</span><span class="s0">'endog'</span><span class="s1">]]</span>
        <span class="s1">agg_exog = np.array(agg_endog.index.tolist())</span>
        <span class="s1">agg_wt = agg_wt[</span><span class="s0">'endog'</span><span class="s1">]</span>
        <span class="s1">avg_endog = agg_endog[</span><span class="s0">'endog'</span><span class="s1">] / agg_wt</span>
        <span class="s1">mod2 = sm.GLM(avg_endog</span><span class="s3">, </span><span class="s1">agg_exog</span><span class="s3">,</span>
                      <span class="s1">family=family(link=link())</span><span class="s3">,</span>
                      <span class="s1">var_weights=agg_wt)</span>
        <span class="s1">cls.res2 = mod2.fit(rtol=</span><span class="s4">1e-10</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">tol_criterion=</span><span class="s0">'params'</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestBinomial0RepeatedvsDuplicated(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">4321</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">10000</span>
        <span class="s1">p = </span><span class="s4">5</span>
        <span class="s1">exog = np.empty((n</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = np.random.randint(low=-</span><span class="s4">5</span><span class="s3">, </span><span class="s1">high=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">size=n)</span>
        <span class="s1">x = np.repeat(np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">])</span><span class="s3">, </span><span class="s1">n / </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">:] = get_dummies(x)</span>
        <span class="s1">beta = np.array([-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05</span><span class="s3">, </span><span class="s4">.2</span><span class="s3">, </span><span class="s4">0.35</span><span class="s1">])</span>
        <span class="s1">lin_pred = (exog * beta).sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">family = sm.families.Binomial</span>
        <span class="s1">link = sm.families.links.Logit</span>
        <span class="s1">endog = gen_endog(lin_pred</span><span class="s3">, </span><span class="s1">family</span><span class="s3">, </span><span class="s1">link</span><span class="s3">, </span><span class="s1">binom_version=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">wt = np.random.randint(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s1">n)</span>
        <span class="s1">mod1 = sm.GLM(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family(link=link())</span><span class="s3">, </span><span class="s1">freq_weights=wt)</span>
        <span class="s1">cls.res1 = mod1.fit()</span>

        <span class="s1">exog_dup = np.repeat(exog</span><span class="s3">, </span><span class="s1">wt</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">endog_dup = np.repeat(endog</span><span class="s3">, </span><span class="s1">wt)</span>
        <span class="s1">mod2 = sm.GLM(endog_dup</span><span class="s3">, </span><span class="s1">exog_dup</span><span class="s3">, </span><span class="s1">family=family(link=link()))</span>
        <span class="s1">cls.res2 = mod2.fit()</span>


<span class="s3">def </span><span class="s1">test_warnings_raised():</span>
    <span class="s1">weights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s2"># faking aweights by using normalized freq_weights</span>
    <span class="s1">weights = np.array(weights)</span>

    <span class="s1">gid = np.arange(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">17 </span><span class="s1">+ </span><span class="s4">1</span><span class="s1">) // </span><span class="s4">2</span>

    <span class="s1">cov_kwds = {</span><span class="s0">'groups'</span><span class="s1">: gid</span><span class="s3">, </span><span class="s0">'use_correction'</span><span class="s1">: </span><span class="s3">False</span><span class="s1">}</span>

    <span class="s3">with </span><span class="s1">pytest.warns(SpecificationWarning):</span>
        <span class="s1">res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                   <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">freq_weights=weights</span>
                   <span class="s1">).fit(cov_type=</span><span class="s0">'cluster'</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds)</span>
        <span class="s1">res1.summary()</span>

    <span class="s3">with </span><span class="s1">pytest.warns(SpecificationWarning):</span>
        <span class="s1">res1 = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
                   <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">var_weights=weights</span>
                   <span class="s1">).fit(cov_type=</span><span class="s0">'cluster'</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds)</span>
        <span class="s1">res1.summary()</span>


<span class="s1">weights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s0">'formatted'</span><span class="s3">, </span><span class="s1">[weights</span><span class="s3">, </span><span class="s1">np.asarray(weights)</span><span class="s3">,</span>
                                       <span class="s1">pd.Series(weights)]</span><span class="s3">,</span>
                         <span class="s1">ids=[</span><span class="s0">'list'</span><span class="s3">, </span><span class="s0">'ndarray'</span><span class="s3">, </span><span class="s0">'Series'</span><span class="s1">])</span>
<span class="s3">def </span><span class="s1">test_weights_different_formats(formatted):</span>
    <span class="s1">check_weights_as_formats(formatted)</span>


<span class="s3">def </span><span class="s1">check_weights_as_formats(weights):</span>
    <span class="s1">res = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
              <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">freq_weights=weights</span>
              <span class="s1">).fit()</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._freq_weights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._var_weights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._iweights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>

    <span class="s1">res = GLM(cpunish_data.endog</span><span class="s3">, </span><span class="s1">cpunish_data.exog</span><span class="s3">,</span>
              <span class="s1">family=sm.families.Poisson()</span><span class="s3">, </span><span class="s1">var_weights=weights</span>
              <span class="s1">).fit()</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._freq_weights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._var_weights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res._iweights</span><span class="s3">, </span><span class="s1">np.ndarray)</span>


<span class="s3">class </span><span class="s1">TestBinomialVsVarWeights(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">statsmodels.datasets.star98 </span><span class="s3">import </span><span class="s1">load</span>
        <span class="s1">data = load()</span>
        <span class="s1">data.exog = np.require(data.exog</span><span class="s3">, </span><span class="s1">requirements=</span><span class="s0">&quot;W&quot;</span><span class="s1">)</span>
        <span class="s1">data.endog = np.require(data.endog</span><span class="s3">, </span><span class="s1">requirements=</span><span class="s0">&quot;W&quot;</span><span class="s1">)</span>
        <span class="s1">data.exog /= data.exog.std(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>

        <span class="s1">cls.res1 = GLM(data.endog</span><span class="s3">, </span><span class="s1">data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Binomial()).fit()</span>
        <span class="s1">weights = data.endog.sum(axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">endog2 = data.endog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] / weights</span>
        <span class="s1">cls.res2 = GLM(endog2</span><span class="s3">, </span><span class="s1">data.exog</span><span class="s3">,</span>
                       <span class="s1">family=sm.families.Binomial()</span><span class="s3">,</span>
                       <span class="s1">var_weights=weights).fit()</span>


<span class="s3">class </span><span class="s1">TestGlmGaussianWLS(CheckWeight):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">import </span><span class="s1">statsmodels.formula.api </span><span class="s3">as </span><span class="s1">smf</span>

        <span class="s1">data = sm.datasets.cpunish.load_pandas()</span>
        <span class="s1">endog = data.endog</span>
        <span class="s1">data = data.exog</span>
        <span class="s1">data[</span><span class="s0">'EXECUTIONS'</span><span class="s1">] = endog</span>
        <span class="s1">data[</span><span class="s0">'INCOME'</span><span class="s1">] /= </span><span class="s4">1000</span>
        <span class="s1">aweights = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">,</span>
                             <span class="s4">1</span><span class="s1">])</span>
        <span class="s1">model = smf.glm(</span>
                <span class="s0">'EXECUTIONS ~ INCOME + SOUTH - 1'</span><span class="s3">,</span>
                <span class="s1">data=data</span><span class="s3">,</span>
                <span class="s1">family=sm.families.Gaussian(link=sm.families.links.Identity())</span><span class="s3">,</span>
                <span class="s1">var_weights=aweights</span>
        <span class="s1">)</span>
        <span class="s1">wlsmodel = smf.wls(</span>
                <span class="s0">'EXECUTIONS ~ INCOME + SOUTH - 1'</span><span class="s3">,</span>
                <span class="s1">data=data</span><span class="s3">,</span>
                <span class="s1">weights=aweights)</span>
        <span class="s1">cls.res1 = model.fit(rtol=</span><span class="s4">1e-25</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-25</span><span class="s1">)</span>
        <span class="s1">cls.res2 = wlsmodel.fit()</span>


<span class="s3">def </span><span class="s1">test_incompatible_input():</span>
    <span class="s1">weights = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s1">]</span>
    <span class="s1">exog = cpunish_data.exog</span>
    <span class="s1">endog = cpunish_data.endog</span>
    <span class="s1">family = sm.families.Poisson()</span>
    <span class="s2"># Too short</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">freq_weights=weights[:-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">var_weights=weights[:-</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s2"># Too long</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">freq_weights=weights + [</span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">var_weights=weights + [</span><span class="s4">3</span><span class="s1">])</span>

    <span class="s2"># Too many dimensions</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">freq_weights=[weights</span><span class="s3">, </span><span class="s1">weights])</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">GLM</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">family=family</span><span class="s3">,</span>
                  <span class="s1">var_weights=[weights</span><span class="s3">, </span><span class="s1">weights])</span>


<span class="s3">def </span><span class="s1">test_poisson_residuals():</span>
    <span class="s1">nobs</span><span class="s3">, </span><span class="s1">k_exog = </span><span class="s4">100</span><span class="s3">, </span><span class="s4">5</span>
    <span class="s1">np.random.seed(</span><span class="s4">987125</span><span class="s1">)</span>
    <span class="s1">x = np.random.randn(nobs</span><span class="s3">, </span><span class="s1">k_exog - </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">x = add_constant(x)</span>

    <span class="s1">y_true = x.sum(</span><span class="s4">1</span><span class="s1">) / </span><span class="s4">2</span>
    <span class="s1">y = y_true + </span><span class="s4">2 </span><span class="s1">* np.random.randn(nobs)</span>
    <span class="s1">exposure = </span><span class="s4">1 </span><span class="s1">+ np.arange(nobs) // </span><span class="s4">4</span>

    <span class="s1">yp = np.random.poisson(np.exp(y_true) * exposure)</span>
    <span class="s1">yp[</span><span class="s4">10</span><span class="s1">:</span><span class="s4">15</span><span class="s1">] += </span><span class="s4">10</span>

    <span class="s1">fam = sm.families.Poisson()</span>
    <span class="s1">mod_poi_e = GLM(yp</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">family=fam</span><span class="s3">, </span><span class="s1">exposure=exposure)</span>
    <span class="s1">res_poi_e = mod_poi_e.fit()</span>

    <span class="s1">mod_poi_w = GLM(yp / exposure</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">family=fam</span><span class="s3">, </span><span class="s1">var_weights=exposure)</span>
    <span class="s1">res_poi_w = mod_poi_w.fit()</span>

    <span class="s1">assert_allclose(res_poi_e.resid_response / exposure</span><span class="s3">,</span>
                    <span class="s1">res_poi_w.resid_response)</span>
    <span class="s1">assert_allclose(res_poi_e.resid_pearson</span><span class="s3">, </span><span class="s1">res_poi_w.resid_pearson)</span>
    <span class="s1">assert_allclose(res_poi_e.resid_deviance</span><span class="s3">, </span><span class="s1">res_poi_w.resid_deviance)</span>
    <span class="s1">assert_allclose(res_poi_e.resid_anscombe</span><span class="s3">, </span><span class="s1">res_poi_w.resid_anscombe)</span>
    <span class="s1">assert_allclose(res_poi_e.resid_anscombe_unscaled</span><span class="s3">,</span>
                    <span class="s1">res_poi_w.resid_anscombe)</span>
</pre>
</body>
</html>
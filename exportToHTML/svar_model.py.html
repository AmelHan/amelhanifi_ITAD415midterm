<html>
<head>
<title>svar_model.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
svar_model.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Vector Autoregression (VAR) processes 
 
References 
---------- 
Lütkepohl (2005) New Introduction to Multiple Time Series Analysis 
&quot;&quot;&quot;</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">numpy.linalg </span><span class="s3">as </span><span class="s1">npl</span>
<span class="s3">from </span><span class="s1">numpy.linalg </span><span class="s3">import </span><span class="s1">slogdet</span>

<span class="s3">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s3">import </span><span class="s1">deprecated_alias</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.numdiff </span><span class="s3">import </span><span class="s1">approx_fprime</span><span class="s3">, </span><span class="s1">approx_hess</span>
<span class="s3">import </span><span class="s1">statsmodels.tsa.base.tsa_model </span><span class="s3">as </span><span class="s1">tsbase</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.irf </span><span class="s3">import </span><span class="s1">IRAnalysis</span>
<span class="s3">import </span><span class="s1">statsmodels.tsa.vector_ar.util </span><span class="s3">as </span><span class="s1">util</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.var_model </span><span class="s3">import </span><span class="s1">VARProcess</span><span class="s3">, </span><span class="s1">VARResults</span>


<span class="s3">def </span><span class="s1">svar_ckerr(svar_type</span><span class="s3">, </span><span class="s1">A</span><span class="s3">, </span><span class="s1">B):</span>
    <span class="s3">if </span><span class="s1">A </span><span class="s3">is None and </span><span class="s1">(svar_type == </span><span class="s4">'A' </span><span class="s3">or </span><span class="s1">svar_type == </span><span class="s4">'AB'</span><span class="s1">):</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'SVAR of type A or AB but A array not given.'</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">B </span><span class="s3">is None and </span><span class="s1">(svar_type == </span><span class="s4">'B' </span><span class="s3">or </span><span class="s1">svar_type == </span><span class="s4">'AB'</span><span class="s1">):</span>

        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'SVAR of type B or AB but B array not given.'</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">SVAR(tsbase.TimeSeriesModel):</span>
    <span class="s2">r&quot;&quot;&quot; 
    Fit VAR and then estimate structural components of A and B, defined: 
 
    .. math:: Ay_t = A_1 y_{t-1} + \ldots + A_p y_{t-p} + B\var(\epsilon_t) 
 
    Parameters 
    ---------- 
    endog : array_like 
        1-d endogenous response variable. The independent variable. 
    dates : array_like 
        must match number of rows of endog 
    svar_type : str 
        &quot;A&quot; - estimate structural parameters of A matrix, B assumed = I 
        &quot;B&quot; - estimate structural parameters of B matrix, A assumed = I 
        &quot;AB&quot; - estimate structural parameters indicated in both A and B matrix 
    A : array_like 
        neqs x neqs with unknown parameters marked with 'E' for estimate 
    B : array_like 
        neqs x neqs with unknown parameters marked with 'E' for estimate 
 
    References 
    ---------- 
    Hamilton (1994) Time Series Analysis 
    &quot;&quot;&quot;</span>

    <span class="s1">y = deprecated_alias(</span><span class="s4">&quot;y&quot;</span><span class="s3">, </span><span class="s4">&quot;endog&quot;</span><span class="s3">, </span><span class="s1">remove_version=</span><span class="s4">&quot;0.11.0&quot;</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">svar_type</span><span class="s3">, </span><span class="s1">dates=</span><span class="s3">None,</span>
                 <span class="s1">freq=</span><span class="s3">None, </span><span class="s1">A=</span><span class="s3">None, </span><span class="s1">B=</span><span class="s3">None, </span><span class="s1">missing=</span><span class="s4">'none'</span><span class="s1">):</span>
        <span class="s1">super().__init__(endog</span><span class="s3">, None, </span><span class="s1">dates</span><span class="s3">, </span><span class="s1">freq</span><span class="s3">, </span><span class="s1">missing=missing)</span>
        <span class="s0">#(self.endog, self.names,</span>
        <span class="s0"># self.dates) = data_util.interpret_data(endog, names, dates)</span>

        <span class="s1">self.neqs = self.endog.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">types = [</span><span class="s4">'A'</span><span class="s3">, </span><span class="s4">'B'</span><span class="s3">, </span><span class="s4">'AB'</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">svar_type </span><span class="s3">not in </span><span class="s1">types:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'SVAR type not recognized, must be in '</span>
                             <span class="s1">+ str(types))</span>
        <span class="s1">self.svar_type = svar_type</span>

        <span class="s1">svar_ckerr(svar_type</span><span class="s3">, </span><span class="s1">A</span><span class="s3">, </span><span class="s1">B)</span>

        <span class="s1">self.A_original = A</span>
        <span class="s1">self.B_original = B</span>

        <span class="s0"># initialize A, B as I if not given</span>
        <span class="s0"># Initialize SVAR masks</span>
        <span class="s3">if </span><span class="s1">A </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">A = np.identity(self.neqs)</span>
            <span class="s1">self.A_mask = A_mask = np.zeros(A.shape</span><span class="s3">, </span><span class="s1">dtype=bool)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">A_mask = np.logical_or(A == </span><span class="s4">'E'</span><span class="s3">, </span><span class="s1">A == </span><span class="s4">'e'</span><span class="s1">)</span>
            <span class="s1">self.A_mask = A_mask</span>
        <span class="s3">if </span><span class="s1">B </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">B = np.identity(self.neqs)</span>
            <span class="s1">self.B_mask = B_mask = np.zeros(B.shape</span><span class="s3">, </span><span class="s1">dtype=bool)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">B_mask = np.logical_or(B == </span><span class="s4">'E'</span><span class="s3">, </span><span class="s1">B == </span><span class="s4">'e'</span><span class="s1">)</span>
            <span class="s1">self.B_mask = B_mask</span>

        <span class="s0"># convert A and B to numeric</span>
        <span class="s0">#TODO: change this when masked support is better or with formula</span>
        <span class="s0">#integration</span>
        <span class="s1">Anum = np.zeros(A.shape</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s1">Anum[~A_mask] = A[~A_mask]</span>
        <span class="s1">Anum[A_mask] = np.nan</span>
        <span class="s1">self.A = Anum</span>

        <span class="s1">Bnum = np.zeros(B.shape</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s1">Bnum[~B_mask] = B[~B_mask]</span>
        <span class="s1">Bnum[B_mask] = np.nan</span>
        <span class="s1">self.B = Bnum</span>

        <span class="s0">#LikelihoodModel.__init__(self, endog)</span>

        <span class="s0">#super().__init__(endog)</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">A_guess=</span><span class="s3">None, </span><span class="s1">B_guess=</span><span class="s3">None, </span><span class="s1">maxlags=</span><span class="s3">None, </span><span class="s1">method=</span><span class="s4">'ols'</span><span class="s3">,</span>
            <span class="s1">ic=</span><span class="s3">None, </span><span class="s1">trend=</span><span class="s4">'c'</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s3">False, </span><span class="s1">s_method=</span><span class="s4">'mle'</span><span class="s3">,</span>
            <span class="s1">solver=</span><span class="s4">&quot;bfgs&quot;</span><span class="s3">, </span><span class="s1">override=</span><span class="s3">False, </span><span class="s1">maxiter=</span><span class="s5">500</span><span class="s3">, </span><span class="s1">maxfun=</span><span class="s5">500</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Fit the SVAR model and solve for structural parameters 
 
        Parameters 
        ---------- 
        A_guess : array_like, optional 
            A vector of starting values for all parameters to be estimated 
            in A. 
        B_guess : array_like, optional 
            A vector of starting values for all parameters to be estimated 
            in B. 
        maxlags : int 
            Maximum number of lags to check for order selection, defaults to 
            12 * (nobs/100.)**(1./4), see select_order function 
        method : {'ols'} 
            Estimation method to use 
        ic : {'aic', 'fpe', 'hqic', 'bic', None} 
            Information criterion to use for VAR order selection. 
            aic : Akaike 
            fpe : Final prediction error 
            hqic : Hannan-Quinn 
            bic : Bayesian a.k.a. Schwarz 
        verbose : bool, default False 
            Print order selection output to the screen 
        trend, str {&quot;c&quot;, &quot;ct&quot;, &quot;ctt&quot;, &quot;n&quot;} 
            &quot;c&quot; - add constant 
            &quot;ct&quot; - constant and trend 
            &quot;ctt&quot; - constant, linear and quadratic trend 
            &quot;n&quot; - co constant, no trend 
            Note that these are prepended to the columns of the dataset. 
        s_method : {'mle'} 
            Estimation method for structural parameters 
        solver : {'nm', 'newton', 'bfgs', 'cg', 'ncg', 'powell'} 
            Solution method 
            See statsmodels.base for details 
        override : bool, default False 
            If True, returns estimates of A and B without checking 
            order or rank condition 
        maxiter : int, default 500 
            Number of iterations to perform in solution method 
        maxfun : int 
            Number of function evaluations to perform 
 
        Notes 
        ----- 
        Lütkepohl pp. 146-153 
        Hamilton pp. 324-336 
 
        Returns 
        ------- 
        est : SVARResults 
        &quot;&quot;&quot;</span>
        <span class="s1">lags = maxlags</span>
        <span class="s3">if </span><span class="s1">ic </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">selections = self.select_order(maxlags=maxlags</span><span class="s3">, </span><span class="s1">verbose=verbose)</span>
            <span class="s3">if </span><span class="s1">ic </span><span class="s3">not in </span><span class="s1">selections:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;%s not recognized, must be among %s&quot;</span>
                                 <span class="s1">% (ic</span><span class="s3">, </span><span class="s1">sorted(selections)))</span>
            <span class="s1">lags = selections[ic]</span>
            <span class="s3">if </span><span class="s1">verbose:</span>
                <span class="s1">print(</span><span class="s4">'Using %d based on %s criterion' </span><span class="s1">%  (lags</span><span class="s3">, </span><span class="s1">ic))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">lags </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">lags = </span><span class="s5">1</span>

        <span class="s1">self.nobs = len(self.endog) - lags</span>

        <span class="s0"># initialize starting parameters</span>
        <span class="s1">start_params = self._get_init_params(A_guess</span><span class="s3">, </span><span class="s1">B_guess)</span>

        <span class="s3">return </span><span class="s1">self._estimate_svar(start_params</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">trend=trend</span><span class="s3">,</span>
                                   <span class="s1">solver=solver</span><span class="s3">, </span><span class="s1">override=override</span><span class="s3">,</span>
                                   <span class="s1">maxiter=maxiter</span><span class="s3">, </span><span class="s1">maxfun=maxfun)</span>

    <span class="s3">def </span><span class="s1">_get_init_params(self</span><span class="s3">, </span><span class="s1">A_guess</span><span class="s3">, </span><span class="s1">B_guess):</span>
        <span class="s2">&quot;&quot;&quot; 
        Returns either the given starting or .1 if none are given. 
        &quot;&quot;&quot;</span>

        <span class="s1">var_type = self.svar_type.lower()</span>

        <span class="s1">n_masked_a = self.A_mask.sum()</span>
        <span class="s3">if </span><span class="s1">var_type </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'ab'</span><span class="s3">, </span><span class="s4">'a'</span><span class="s1">]:</span>
            <span class="s3">if </span><span class="s1">A_guess </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">A_guess = np.array([</span><span class="s5">.1</span><span class="s1">]*n_masked_a)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">if </span><span class="s1">len(A_guess) != n_masked_a:</span>
                    <span class="s1">msg = </span><span class="s4">'len(A_guess) = %s, there are %s parameters in A'</span>
                    <span class="s3">raise </span><span class="s1">ValueError(msg % (len(A_guess)</span><span class="s3">, </span><span class="s1">n_masked_a))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">A_guess = []</span>

        <span class="s1">n_masked_b = self.B_mask.sum()</span>
        <span class="s3">if </span><span class="s1">var_type </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'ab'</span><span class="s3">, </span><span class="s4">'b'</span><span class="s1">]:</span>
            <span class="s3">if </span><span class="s1">B_guess </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">B_guess = np.array([</span><span class="s5">.1</span><span class="s1">]*n_masked_b)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">if </span><span class="s1">len(B_guess) != n_masked_b:</span>
                    <span class="s1">msg = </span><span class="s4">'len(B_guess) = %s, there are %s parameters in B'</span>
                    <span class="s3">raise </span><span class="s1">ValueError(msg % (len(B_guess)</span><span class="s3">, </span><span class="s1">n_masked_b))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">B_guess = []</span>

        <span class="s3">return </span><span class="s1">np.r_[A_guess</span><span class="s3">, </span><span class="s1">B_guess]</span>

    <span class="s3">def </span><span class="s1">_estimate_svar(self</span><span class="s3">, </span><span class="s1">start_params</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">maxiter</span><span class="s3">, </span><span class="s1">maxfun</span><span class="s3">,</span>
                       <span class="s1">trend=</span><span class="s4">'c'</span><span class="s3">, </span><span class="s1">solver=</span><span class="s4">&quot;nm&quot;</span><span class="s3">, </span><span class="s1">override=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        lags : int 
        trend : {str, None} 
            As per above 
        &quot;&quot;&quot;</span>
        <span class="s1">k_trend = util.get_trendorder(trend)</span>
        <span class="s1">y = self.endog</span>
        <span class="s1">z = util.get_var_endog(y</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">trend=trend</span><span class="s3">, </span><span class="s1">has_constant=</span><span class="s4">'raise'</span><span class="s1">)</span>
        <span class="s1">y_sample = y[lags:]</span>

        <span class="s0"># Lutkepohl p75, about 5x faster than stated formula</span>
        <span class="s1">var_params = np.linalg.lstsq(z</span><span class="s3">, </span><span class="s1">y_sample</span><span class="s3">, </span><span class="s1">rcond=-</span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">resid = y_sample - np.dot(z</span><span class="s3">, </span><span class="s1">var_params)</span>

        <span class="s0"># Unbiased estimate of covariance matrix $\Sigma_u$ of the white noise</span>
        <span class="s0"># process $u$</span>
        <span class="s0"># equivalent definition</span>
        <span class="s0"># .. math:: \frac{1}{T - Kp - 1} Y^\prime (I_T - Z (Z^\prime Z)^{-1}</span>
        <span class="s0"># Z^\prime) Y</span>
        <span class="s0"># Ref: Lutkepohl p.75</span>
        <span class="s0"># df_resid right now is T - Kp - 1, which is a suggested correction</span>

        <span class="s1">avobs = len(y_sample)</span>

        <span class="s1">df_resid = avobs - (self.neqs * lags + k_trend)</span>

        <span class="s1">sse = np.dot(resid.T</span><span class="s3">, </span><span class="s1">resid)</span>
        <span class="s0">#TODO: should give users the option to use a dof correction or not</span>
        <span class="s1">omega = sse / df_resid</span>
        <span class="s1">self.sigma_u = omega</span>

        <span class="s1">A</span><span class="s3">, </span><span class="s1">B = self._solve_AB(start_params</span><span class="s3">, </span><span class="s1">override=override</span><span class="s3">,</span>
                              <span class="s1">solver=solver</span><span class="s3">,</span>
                              <span class="s1">maxiter=maxiter)</span>
        <span class="s1">A_mask = self.A_mask</span>
        <span class="s1">B_mask = self.B_mask</span>

        <span class="s3">return </span><span class="s1">SVARResults(y</span><span class="s3">, </span><span class="s1">z</span><span class="s3">, </span><span class="s1">var_params</span><span class="s3">, </span><span class="s1">omega</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">,</span>
                           <span class="s1">names=self.endog_names</span><span class="s3">, </span><span class="s1">trend=trend</span><span class="s3">,</span>
                           <span class="s1">dates=self.data.dates</span><span class="s3">, </span><span class="s1">model=self</span><span class="s3">,</span>
                           <span class="s1">A=A</span><span class="s3">, </span><span class="s1">B=B</span><span class="s3">, </span><span class="s1">A_mask=A_mask</span><span class="s3">, </span><span class="s1">B_mask=B_mask)</span>

    <span class="s3">def </span><span class="s1">loglike(self</span><span class="s3">, </span><span class="s1">params):</span>
        <span class="s2">&quot;&quot;&quot; 
        Loglikelihood for SVAR model 
 
        Notes 
        ----- 
        This method assumes that the autoregressive parameters are 
        first estimated, then likelihood with structural parameters 
        is estimated 
        &quot;&quot;&quot;</span>

        <span class="s0">#TODO: this does not look robust if A or B is None</span>
        <span class="s1">A = self.A</span>
        <span class="s1">B = self.B</span>
        <span class="s1">A_mask = self.A_mask</span>
        <span class="s1">B_mask = self.B_mask</span>
        <span class="s1">A_len = len(A[A_mask])</span>
        <span class="s1">B_len = len(B[B_mask])</span>

        <span class="s3">if </span><span class="s1">A </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">A[A_mask] = params[:A_len]</span>
        <span class="s3">if </span><span class="s1">B </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">B[B_mask] = params[A_len:A_len+B_len]</span>

        <span class="s1">nobs = self.nobs</span>
        <span class="s1">neqs = self.neqs</span>
        <span class="s1">sigma_u = self.sigma_u</span>

        <span class="s1">W = np.dot(npl.inv(B)</span><span class="s3">,</span><span class="s1">A)</span>
        <span class="s1">trc_in = np.dot(np.dot(W.T</span><span class="s3">,</span><span class="s1">W)</span><span class="s3">,</span><span class="s1">sigma_u)</span>
        <span class="s1">sign</span><span class="s3">, </span><span class="s1">b_logdet = slogdet(B**</span><span class="s5">2</span><span class="s1">) </span><span class="s0">#numpy 1.4 compat</span>
        <span class="s1">b_slogdet = sign * b_logdet</span>

        <span class="s1">likl = -nobs/</span><span class="s5">2. </span><span class="s1">* (neqs * np.log(</span><span class="s5">2 </span><span class="s1">* np.pi) -</span>
                           <span class="s1">np.log(npl.det(A)**</span><span class="s5">2</span><span class="s1">) + b_slogdet +</span>
                           <span class="s1">np.trace(trc_in))</span>

        <span class="s3">return </span><span class="s1">likl</span>

    <span class="s3">def </span><span class="s1">score(self</span><span class="s3">, </span><span class="s1">AB_mask):</span>
        <span class="s2">&quot;&quot;&quot; 
        Return the gradient of the loglike at AB_mask. 
 
        Parameters 
        ---------- 
        AB_mask : unknown values of A and B matrix concatenated 
 
        Notes 
        ----- 
        Return numerical gradient 
        &quot;&quot;&quot;</span>
        <span class="s1">loglike = self.loglike</span>
        <span class="s3">return </span><span class="s1">approx_fprime(AB_mask</span><span class="s3">, </span><span class="s1">loglike</span><span class="s3">, </span><span class="s1">epsilon=</span><span class="s5">1e-8</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">hessian(self</span><span class="s3">, </span><span class="s1">AB_mask):</span>
        <span class="s2">&quot;&quot;&quot; 
        Returns numerical hessian. 
        &quot;&quot;&quot;</span>
        <span class="s1">loglike = self.loglike</span>
        <span class="s3">return </span><span class="s1">approx_hess(AB_mask</span><span class="s3">, </span><span class="s1">loglike)</span>

    <span class="s3">def </span><span class="s1">_solve_AB(self</span><span class="s3">, </span><span class="s1">start_params</span><span class="s3">, </span><span class="s1">maxiter</span><span class="s3">, </span><span class="s1">override=</span><span class="s3">False, </span><span class="s1">solver=</span><span class="s4">'bfgs'</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Solves for MLE estimate of structural parameters 
 
        Parameters 
        ---------- 
 
        override : bool, default False 
            If True, returns estimates of A and B without checking 
            order or rank condition 
        solver : str or None, optional 
            Solver to be used. The default is 'nm' (Nelder-Mead). Other 
            choices are 'bfgs', 'newton' (Newton-Raphson), 'cg' 
            conjugate, 'ncg' (non-conjugate gradient), and 'powell'. 
        maxiter : int, optional 
            The maximum number of iterations. Default is 500. 
 
        Returns 
        ------- 
        A_solve, B_solve: ML solutions for A, B matrices 
        &quot;&quot;&quot;</span>
        <span class="s0">#TODO: this could stand a refactor</span>
        <span class="s1">A_mask = self.A_mask</span>
        <span class="s1">B_mask = self.B_mask</span>
        <span class="s1">A = self.A</span>
        <span class="s1">B = self.B</span>
        <span class="s1">A_len = len(A[A_mask])</span>

        <span class="s1">A[A_mask] = start_params[:A_len]</span>
        <span class="s1">B[B_mask] = start_params[A_len:]</span>

        <span class="s3">if not </span><span class="s1">override:</span>
            <span class="s1">J = self._compute_J(A</span><span class="s3">, </span><span class="s1">B)</span>
            <span class="s1">self.check_order(J)</span>
            <span class="s1">self.check_rank(J)</span>
        <span class="s3">else</span><span class="s1">: </span><span class="s0">#TODO: change to a warning?</span>
            <span class="s1">print(</span><span class="s4">&quot;Order/rank conditions have not been checked&quot;</span><span class="s1">)</span>

        <span class="s1">retvals = super().fit(start_params=start_params</span><span class="s3">,</span>
                              <span class="s1">method=solver</span><span class="s3">, </span><span class="s1">maxiter=maxiter</span><span class="s3">,</span>
                              <span class="s1">gtol=</span><span class="s5">1e-20</span><span class="s3">, </span><span class="s1">disp=</span><span class="s3">False</span><span class="s1">).params</span>

        <span class="s1">A[A_mask] = retvals[:A_len]</span>
        <span class="s1">B[B_mask] = retvals[A_len:]</span>

        <span class="s3">return </span><span class="s1">A</span><span class="s3">, </span><span class="s1">B</span>

    <span class="s3">def </span><span class="s1">_compute_J(self</span><span class="s3">, </span><span class="s1">A_solve</span><span class="s3">, </span><span class="s1">B_solve):</span>

        <span class="s0">#first compute appropriate duplication matrix</span>
        <span class="s0"># taken from Magnus and Neudecker (1980),</span>
        <span class="s0">#&quot;The Elimination Matrix: Some Lemmas and Applications</span>
        <span class="s0"># the creation of the D_n matrix follows MN (1980) directly,</span>
        <span class="s0">#while the rest follows Hamilton (1994)</span>

        <span class="s1">neqs = self.neqs</span>
        <span class="s1">sigma_u = self.sigma_u</span>
        <span class="s1">A_mask = self.A_mask</span>
        <span class="s1">B_mask = self.B_mask</span>

        <span class="s0">#first generate duplication matrix, see MN (1980) for notation</span>

        <span class="s1">D_nT = np.zeros([int((</span><span class="s5">1.0 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">) * (neqs) * (neqs + </span><span class="s5">1</span><span class="s1">))</span><span class="s3">, </span><span class="s1">neqs**</span><span class="s5">2</span><span class="s1">])</span>

        <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(neqs):</span>
            <span class="s1">i=j</span>
            <span class="s3">while </span><span class="s1">j &lt;= i &lt; neqs:</span>
                <span class="s1">u=np.zeros([int((</span><span class="s5">1.0</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)*neqs*(neqs+</span><span class="s5">1</span><span class="s1">))</span><span class="s3">, </span><span class="s5">1</span><span class="s1">])</span>
                <span class="s1">u[int(j * neqs + (i + </span><span class="s5">1</span><span class="s1">) - (</span><span class="s5">1.0 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">) * (j + </span><span class="s5">1</span><span class="s1">) * j - </span><span class="s5">1</span><span class="s1">)] = </span><span class="s5">1</span>
                <span class="s1">Tij=np.zeros([neqs</span><span class="s3">,</span><span class="s1">neqs])</span>
                <span class="s1">Tij[i</span><span class="s3">,</span><span class="s1">j]=</span><span class="s5">1</span>
                <span class="s1">Tij[j</span><span class="s3">,</span><span class="s1">i]=</span><span class="s5">1</span>
                <span class="s1">D_nT=D_nT+np.dot(u</span><span class="s3">,</span><span class="s1">(Tij.ravel(</span><span class="s4">'F'</span><span class="s1">)[:</span><span class="s3">,None</span><span class="s1">]).T)</span>
                <span class="s1">i=i+</span><span class="s5">1</span>

        <span class="s1">D_n=D_nT.T</span>
        <span class="s1">D_pl=npl.pinv(D_n)</span>

        <span class="s0">#generate S_B</span>
        <span class="s1">S_B = np.zeros((neqs**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">len(A_solve[A_mask])))</span>
        <span class="s1">S_D = np.zeros((neqs**</span><span class="s5">2</span><span class="s3">, </span><span class="s1">len(B_solve[B_mask])))</span>

        <span class="s1">j = </span><span class="s5">0</span>
        <span class="s1">j_d = </span><span class="s5">0</span>
        <span class="s3">if </span><span class="s1">len(A_solve[A_mask]) != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">A_vec = np.ravel(A_mask</span><span class="s3">, </span><span class="s1">order=</span><span class="s4">'F'</span><span class="s1">)</span>
            <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range(neqs**</span><span class="s5">2</span><span class="s1">):</span>
                <span class="s3">if </span><span class="s1">A_vec[k]:</span>
                    <span class="s1">S_B[k</span><span class="s3">,</span><span class="s1">j] = -</span><span class="s5">1</span>
                    <span class="s1">j += </span><span class="s5">1</span>
        <span class="s3">if </span><span class="s1">len(B_solve[B_mask]) != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">B_vec = np.ravel(B_mask</span><span class="s3">, </span><span class="s1">order=</span><span class="s4">'F'</span><span class="s1">)</span>
            <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range(neqs**</span><span class="s5">2</span><span class="s1">):</span>
                <span class="s3">if </span><span class="s1">B_vec[k]:</span>
                    <span class="s1">S_D[k</span><span class="s3">,</span><span class="s1">j_d] = </span><span class="s5">1</span>
                    <span class="s1">j_d +=</span><span class="s5">1</span>

        <span class="s0">#now compute J</span>
        <span class="s1">invA = npl.inv(A_solve)</span>
        <span class="s1">J_p1i = np.dot(np.dot(D_pl</span><span class="s3">, </span><span class="s1">np.kron(sigma_u</span><span class="s3">, </span><span class="s1">invA))</span><span class="s3">, </span><span class="s1">S_B)</span>
        <span class="s1">J_p1 = -</span><span class="s5">2.0 </span><span class="s1">* J_p1i</span>
        <span class="s1">J_p2 = np.dot(np.dot(D_pl</span><span class="s3">, </span><span class="s1">np.kron(invA</span><span class="s3">, </span><span class="s1">invA))</span><span class="s3">, </span><span class="s1">S_D)</span>

        <span class="s1">J = np.append(J_p1</span><span class="s3">, </span><span class="s1">J_p2</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">J</span>

    <span class="s3">def </span><span class="s1">check_order(self</span><span class="s3">, </span><span class="s1">J):</span>
        <span class="s3">if </span><span class="s1">np.size(J</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">) &lt; np.size(J</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Order condition not met: &quot;</span>
                             <span class="s4">&quot;solution may not be unique&quot;</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">check_rank(self</span><span class="s3">, </span><span class="s1">J):</span>
        <span class="s1">rank = np.linalg.matrix_rank(J)</span>
        <span class="s3">if </span><span class="s1">rank &lt; np.size(J</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Rank condition not met: &quot;</span>
                             <span class="s4">&quot;solution may not be unique.&quot;</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">SVARProcess(VARProcess):</span>
    <span class="s2">&quot;&quot;&quot; 
    Class represents a known SVAR(p) process 
 
    Parameters 
    ---------- 
    coefs : ndarray (p x k x k) 
    intercept : ndarray (length k) 
    sigma_u : ndarray (k x k) 
    names : sequence (length k) 
    A : neqs x neqs np.ndarray with unknown parameters marked with 'E' 
    A_mask : neqs x neqs mask array with known parameters masked 
    B : neqs x neqs np.ndarry with unknown parameters marked with 'E' 
    B_mask : neqs x neqs mask array with known parameters masked 
    &quot;&quot;&quot;</span>
    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">A_solve</span><span class="s3">, </span><span class="s1">B_solve</span><span class="s3">,</span>
                 <span class="s1">names=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.k_ar = len(coefs)</span>
        <span class="s1">self.neqs = coefs.shape[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">self.coefs = coefs</span>
        <span class="s1">self.intercept = intercept</span>
        <span class="s1">self.sigma_u = sigma_u</span>
        <span class="s1">self.A_solve = A_solve</span>
        <span class="s1">self.B_solve = B_solve</span>
        <span class="s1">self.names = names</span>

    <span class="s3">def </span><span class="s1">orth_ma_rep(self</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">P=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
 
        Unavailable for SVAR 
        &quot;&quot;&quot;</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError</span>

    <span class="s3">def </span><span class="s1">svar_ma_rep(self</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">P=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
 
        Compute Structural MA coefficient matrices using MLE 
        of A, B 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">P </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">A_solve = self.A_solve</span>
            <span class="s1">B_solve = self.B_solve</span>
            <span class="s1">P = np.dot(npl.inv(A_solve)</span><span class="s3">, </span><span class="s1">B_solve)</span>

        <span class="s1">ma_mats = self.ma_rep(maxn=maxn)</span>
        <span class="s3">return </span><span class="s1">np.array([np.dot(coefs</span><span class="s3">, </span><span class="s1">P) </span><span class="s3">for </span><span class="s1">coefs </span><span class="s3">in </span><span class="s1">ma_mats])</span>


<span class="s3">class </span><span class="s1">SVARResults(SVARProcess</span><span class="s3">, </span><span class="s1">VARResults):</span>
    <span class="s2">&quot;&quot;&quot; 
    Estimate VAR(p) process with fixed number of lags 
 
    Parameters 
    ---------- 
    endog : ndarray 
    endog_lagged : ndarray 
    params : ndarray 
    sigma_u : ndarray 
    lag_order : int 
    model : VAR model instance 
    trend : str {'n', 'c', 'ct'} 
    names : array_like 
        List of names of the endogenous variables in order of appearance in `endog`. 
    dates 
 
    Attributes 
    ---------- 
    aic 
    bic 
    bse 
    coefs : ndarray (p x K x K) 
        Estimated A_i matrices, A_i = coefs[i-1] 
    cov_params 
    dates 
    detomega 
    df_model : int 
    df_resid : int 
    endog 
    endog_lagged 
    fittedvalues 
    fpe 
    intercept 
    info_criteria 
    k_ar : int 
    k_trend : int 
    llf 
    model 
    names 
    neqs : int 
        Number of variables (equations) 
    nobs : int 
    n_totobs : int 
    params 
    k_ar : int 
        Order of VAR process 
    params : ndarray (Kp + 1) x K 
        A_i matrices and intercept in stacked form [int A_1 ... A_p] 
    pvalue 
    names : list 
        variables names 
    resid 
    sigma_u : ndarray (K x K) 
        Estimate of white noise process variance Var[u_t] 
    sigma_u_mle 
    stderr 
    trenorder 
    tvalues 
    &quot;&quot;&quot;</span>

    <span class="s1">_model_type = </span><span class="s4">'SVAR'</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_lagged</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">lag_order</span><span class="s3">,</span>
                 <span class="s1">A=</span><span class="s3">None, </span><span class="s1">B=</span><span class="s3">None, </span><span class="s1">A_mask=</span><span class="s3">None, </span><span class="s1">B_mask=</span><span class="s3">None, </span><span class="s1">model=</span><span class="s3">None,</span>
                 <span class="s1">trend=</span><span class="s4">'c'</span><span class="s3">, </span><span class="s1">names=</span><span class="s3">None, </span><span class="s1">dates=</span><span class="s3">None</span><span class="s1">):</span>

        <span class="s1">self.model = model</span>
        <span class="s1">self.endog = endog</span>
        <span class="s1">self.endog_lagged = endog_lagged</span>
        <span class="s1">self.dates = dates</span>

        <span class="s1">self.n_totobs</span><span class="s3">, </span><span class="s1">self.neqs = self.endog.shape</span>
        <span class="s1">self.nobs = self.n_totobs - lag_order</span>
        <span class="s1">k_trend = util.get_trendorder(trend)</span>
        <span class="s3">if </span><span class="s1">k_trend &gt; </span><span class="s5">0</span><span class="s1">: </span><span class="s0"># make this the polynomial trend order</span>
            <span class="s1">trendorder = k_trend - </span><span class="s5">1</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">trendorder = </span><span class="s3">None</span>
        <span class="s1">self.k_trend = k_trend</span>
        <span class="s1">self.k_exog = k_trend  </span><span class="s0"># now (0.9) required by VARProcess</span>
        <span class="s1">self.trendorder = trendorder</span>

        <span class="s1">self.exog_names = util.make_lag_names(names</span><span class="s3">, </span><span class="s1">lag_order</span><span class="s3">, </span><span class="s1">k_trend)</span>
        <span class="s1">self.params = params</span>
        <span class="s1">self.sigma_u = sigma_u</span>

        <span class="s0"># Each matrix needs to be transposed</span>
        <span class="s1">reshaped = self.params[self.k_trend:]</span>
        <span class="s1">reshaped = reshaped.reshape((lag_order</span><span class="s3">, </span><span class="s1">self.neqs</span><span class="s3">, </span><span class="s1">self.neqs))</span>

        <span class="s0"># Need to transpose each coefficient matrix</span>
        <span class="s1">intercept = self.params[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">coefs = reshaped.swapaxes(</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s1">).copy()</span>

        <span class="s0">#SVAR components</span>
        <span class="s0">#TODO: if you define these here, you do not also have to define</span>
        <span class="s0">#them in SVAR process, but I left them for now -ss</span>
        <span class="s1">self.A = A</span>
        <span class="s1">self.B = B</span>
        <span class="s1">self.A_mask = A_mask</span>
        <span class="s1">self.B_mask = B_mask</span>

        <span class="s1">super().__init__(coefs</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">A</span><span class="s3">, </span><span class="s1">B</span><span class="s3">,</span>
                                          <span class="s1">names=names)</span>

    <span class="s3">def </span><span class="s1">irf(self</span><span class="s3">, </span><span class="s1">periods=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">var_order=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Analyze structural impulse responses to shocks in system 
 
        Parameters 
        ---------- 
        periods : int 
 
        Returns 
        ------- 
        irf : IRAnalysis 
        &quot;&quot;&quot;</span>
        <span class="s1">A = self.A</span>
        <span class="s1">B= self.B</span>
        <span class="s1">P = np.dot(npl.inv(A)</span><span class="s3">, </span><span class="s1">B)</span>

        <span class="s3">return </span><span class="s1">IRAnalysis(self</span><span class="s3">, </span><span class="s1">P=P</span><span class="s3">, </span><span class="s1">periods=periods</span><span class="s3">, </span><span class="s1">svar=</span><span class="s3">True</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">sirf_errband_mc(self</span><span class="s3">, </span><span class="s1">orth=</span><span class="s3">False, </span><span class="s1">repl=</span><span class="s5">1000</span><span class="s3">, </span><span class="s1">steps=</span><span class="s5">10</span><span class="s3">,</span>
                        <span class="s1">signif=</span><span class="s5">0.05</span><span class="s3">, </span><span class="s1">seed=</span><span class="s3">None, </span><span class="s1">burn=</span><span class="s5">100</span><span class="s3">, </span><span class="s1">cum=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute Monte Carlo integrated error bands assuming normally 
        distributed for impulse response functions 
 
        Parameters 
        ---------- 
        orth : bool, default False 
            Compute orthogonalized impulse response error bands 
        repl : int 
            number of Monte Carlo replications to perform 
        steps : int, default 10 
            number of impulse response periods 
        signif : float (0 &lt; signif &lt;1) 
            Significance level for error bars, defaults to 95% CI 
        seed : int 
            np.random.seed for replications 
        burn : int 
            number of initial observations to discard for simulation 
        cum : bool, default False 
            produce cumulative irf error bands 
 
        Notes 
        ----- 
        Lütkepohl (2005) Appendix D 
 
        Returns 
        ------- 
        Tuple of lower and upper arrays of ma_rep monte carlo standard errors 
        &quot;&quot;&quot;</span>
        <span class="s1">neqs = self.neqs</span>
        <span class="s1">mean = self.mean()</span>
        <span class="s1">k_ar = self.k_ar</span>
        <span class="s1">coefs = self.coefs</span>
        <span class="s1">sigma_u = self.sigma_u</span>
        <span class="s1">intercept = self.intercept</span>
        <span class="s1">df_model = self.df_model</span>
        <span class="s1">nobs = self.nobs</span>

        <span class="s1">ma_coll = np.zeros((repl</span><span class="s3">, </span><span class="s1">steps + </span><span class="s5">1</span><span class="s3">, </span><span class="s1">neqs</span><span class="s3">, </span><span class="s1">neqs))</span>
        <span class="s1">A = self.A</span>
        <span class="s1">B = self.B</span>
        <span class="s1">A_mask = self.A_mask</span>
        <span class="s1">B_mask = self.B_mask</span>
        <span class="s1">A_pass = self.model.A_original</span>
        <span class="s1">B_pass = self.model.B_original</span>
        <span class="s1">s_type = self.model.svar_type</span>

        <span class="s1">g_list = []</span>

        <span class="s3">def </span><span class="s1">agg(impulses):</span>
            <span class="s3">if </span><span class="s1">cum:</span>
                <span class="s3">return </span><span class="s1">impulses.cumsum(axis=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s3">return </span><span class="s1">impulses</span>

        <span class="s1">opt_A = A[A_mask]</span>
        <span class="s1">opt_B = B[B_mask]</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(repl):</span>
            <span class="s0"># discard first hundred to correct for starting bias</span>
            <span class="s1">sim = util.varsim(coefs</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">seed=seed</span><span class="s3">,</span>
                              <span class="s1">steps=nobs + burn)</span>
            <span class="s1">sim = sim[burn:]</span>

            <span class="s1">smod = SVAR(sim</span><span class="s3">, </span><span class="s1">svar_type=s_type</span><span class="s3">, </span><span class="s1">A=A_pass</span><span class="s3">, </span><span class="s1">B=B_pass)</span>
            <span class="s3">if </span><span class="s1">i == </span><span class="s5">10</span><span class="s1">:</span>
                <span class="s0"># Use first 10 to update starting val for remainder of fits</span>
                <span class="s1">mean_AB = np.mean(g_list</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
                <span class="s1">split = len(A[A_mask])</span>
                <span class="s1">opt_A = mean_AB[:split]</span>
                <span class="s1">opt_B = mean_AB[split:]</span>

            <span class="s1">sres = smod.fit(maxlags=k_ar</span><span class="s3">, </span><span class="s1">A_guess=opt_A</span><span class="s3">, </span><span class="s1">B_guess=opt_B)</span>

            <span class="s3">if </span><span class="s1">i &lt; </span><span class="s5">10</span><span class="s1">:</span>
                <span class="s0"># save estimates for starting val if in first 10</span>
                <span class="s1">g_list.append(np.append(sres.A[A_mask].tolist()</span><span class="s3">,</span>
                                        <span class="s1">sres.B[B_mask].tolist()))</span>
            <span class="s1">ma_coll[i] = agg(sres.svar_ma_rep(maxn=steps))</span>

        <span class="s1">ma_sort = np.sort(ma_coll</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)  </span><span class="s0"># sort to get quantiles</span>
        <span class="s1">index = (int(round(signif / </span><span class="s5">2 </span><span class="s1">* repl) - </span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
                 <span class="s1">int(round((</span><span class="s5">1 </span><span class="s1">- signif / </span><span class="s5">2</span><span class="s1">) * repl) - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">lower = ma_sort[index[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s1">upper = ma_sort[index[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s3">return </span><span class="s1">lower</span><span class="s3">, </span><span class="s1">upper</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_precision_recall_display.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_precision_recall_display.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">collections </span><span class="s0">import </span><span class="s1">Counter</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">sklearn.compose </span><span class="s0">import </span><span class="s1">make_column_transformer</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">load_breast_cancer</span><span class="s0">, </span><span class="s1">make_classification</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">NotFittedError</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LogisticRegression</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">PrecisionRecallDisplay</span><span class="s0">,</span>
    <span class="s1">average_precision_score</span><span class="s0">,</span>
    <span class="s1">precision_recall_curve</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.model_selection </span><span class="s0">import </span><span class="s1">train_test_split</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">StandardScaler</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">shuffle</span>
<span class="s0">from </span><span class="s1">sklearn.utils.fixes </span><span class="s0">import </span><span class="s1">trapezoid</span>

<span class="s2"># TODO: Remove when https://github.com/numpy/numpy/issues/14397 is resolved</span>
<span class="s1">pytestmark = pytest.mark.filterwarnings(</span>
    <span class="s3">&quot;ignore:In future, it will be an error for 'np.bool_':DeprecationWarning:&quot;</span>
    <span class="s3">&quot;matplotlib.*&quot;</span>
<span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;constructor_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;predict_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;drop_intermediate&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_display_plotting(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">constructor_name</span><span class="s0">, </span><span class="s1">response_method</span><span class="s0">, </span><span class="s1">drop_intermediate</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Check the overall plotting rendering.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">n_samples=</span><span class="s5">50</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">pos_label = </span><span class="s5">1</span>

    <span class="s1">classifier = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">classifier.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">y_pred = getattr(classifier</span><span class="s0">, </span><span class="s1">response_method)(X)</span>
    <span class="s1">y_pred = y_pred </span><span class="s0">if </span><span class="s1">y_pred.ndim == </span><span class="s5">1 </span><span class="s0">else </span><span class="s1">y_pred[:</span><span class="s0">, </span><span class="s1">pos_label]</span>

    <span class="s2"># safe guard for the binary if/else construction</span>
    <span class="s0">assert </span><span class="s1">constructor_name </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(</span>
            <span class="s1">classifier</span><span class="s0">,</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">y</span><span class="s0">,</span>
            <span class="s1">response_method=response_method</span><span class="s0">,</span>
            <span class="s1">drop_intermediate=drop_intermediate</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label</span><span class="s0">, </span><span class="s1">drop_intermediate=drop_intermediate</span>
        <span class="s1">)</span>

    <span class="s1">precision</span><span class="s0">, </span><span class="s1">recall</span><span class="s0">, </span><span class="s1">_ = precision_recall_curve(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label</span><span class="s0">, </span><span class="s1">drop_intermediate=drop_intermediate</span>
    <span class="s1">)</span>
    <span class="s1">average_precision = average_precision_score(y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label)</span>

    <span class="s1">np.testing.assert_allclose(display.precision</span><span class="s0">, </span><span class="s1">precision)</span>
    <span class="s1">np.testing.assert_allclose(display.recall</span><span class="s0">, </span><span class="s1">recall)</span>
    <span class="s0">assert </span><span class="s1">display.average_precision == pytest.approx(average_precision)</span>

    <span class="s0">import </span><span class="s1">matplotlib </span><span class="s0">as </span><span class="s1">mpl</span>

    <span class="s0">assert </span><span class="s1">isinstance(display.line_</span><span class="s0">, </span><span class="s1">mpl.lines.Line2D)</span>
    <span class="s0">assert </span><span class="s1">isinstance(display.ax_</span><span class="s0">, </span><span class="s1">mpl.axes.Axes)</span>
    <span class="s0">assert </span><span class="s1">isinstance(display.figure_</span><span class="s0">, </span><span class="s1">mpl.figure.Figure)</span>

    <span class="s0">assert </span><span class="s1">display.ax_.get_xlabel() == </span><span class="s3">&quot;Recall (Positive label: 1)&quot;</span>
    <span class="s0">assert </span><span class="s1">display.ax_.get_ylabel() == </span><span class="s3">&quot;Precision (Positive label: 1)&quot;</span>

    <span class="s2"># plotting passing some new parameters</span>
    <span class="s1">display.plot(alpha=</span><span class="s5">0.8</span><span class="s0">, </span><span class="s1">name=</span><span class="s3">&quot;MySpecialEstimator&quot;</span><span class="s1">)</span>
    <span class="s1">expected_label = </span><span class="s3">f&quot;MySpecialEstimator (AP = </span><span class="s0">{</span><span class="s1">average_precision</span><span class="s0">:</span><span class="s3">0.2f</span><span class="s0">}</span><span class="s3">)&quot;</span>
    <span class="s0">assert </span><span class="s1">display.line_.get_label() == expected_label</span>
    <span class="s0">assert </span><span class="s1">display.line_.get_alpha() == pytest.approx(</span><span class="s5">0.8</span><span class="s1">)</span>

    <span class="s2"># Check that the chance level line is not plotted by default</span>
    <span class="s0">assert </span><span class="s1">display.chance_level_ </span><span class="s0">is None</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;chance_level_kw&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">None, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;constructor_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_chance_level_line(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">chance_level_kw</span><span class="s0">,</span>
    <span class="s1">constructor_name</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Check the chance level line plotting behavior.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">n_samples=</span><span class="s5">50</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">pos_prevalence = Counter(y)[</span><span class="s5">1</span><span class="s1">] / len(y)</span>

    <span class="s1">lr = LogisticRegression()</span>
    <span class="s1">y_pred = lr.fit(X</span><span class="s0">, </span><span class="s1">y).predict_proba(X)[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(</span>
            <span class="s1">lr</span><span class="s0">,</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">y</span><span class="s0">,</span>
            <span class="s1">plot_chance_level=</span><span class="s0">True,</span>
            <span class="s1">chance_level_kw=chance_level_kw</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y</span><span class="s0">,</span>
            <span class="s1">y_pred</span><span class="s0">,</span>
            <span class="s1">plot_chance_level=</span><span class="s0">True,</span>
            <span class="s1">chance_level_kw=chance_level_kw</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s0">import </span><span class="s1">matplotlib </span><span class="s0">as </span><span class="s1">mpl  </span><span class="s2"># noqa</span>

    <span class="s0">assert </span><span class="s1">isinstance(display.chance_level_</span><span class="s0">, </span><span class="s1">mpl.lines.Line2D)</span>
    <span class="s0">assert </span><span class="s1">tuple(display.chance_level_.get_xdata()) == (</span><span class="s5">0</span><span class="s0">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">tuple(display.chance_level_.get_ydata()) == (pos_prevalence</span><span class="s0">, </span><span class="s1">pos_prevalence)</span>

    <span class="s2"># Checking for chance level line styles</span>
    <span class="s0">if </span><span class="s1">chance_level_kw </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">display.chance_level_.get_color() == </span><span class="s3">&quot;k&quot;</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">display.chance_level_.get_color() == </span><span class="s3">&quot;r&quot;</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;constructor_name, default_label&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;LogisticRegression (AP = {:.2f})&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;from_predictions&quot;</span><span class="s0">, </span><span class="s3">&quot;Classifier (AP = {:.2f})&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_precision_recall_display_name(pyplot</span><span class="s0">, </span><span class="s1">constructor_name</span><span class="s0">, </span><span class="s1">default_label):</span>
    <span class="s4">&quot;&quot;&quot;Check the behaviour of the name parameters&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">n_samples=</span><span class="s5">100</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">pos_label = </span><span class="s5">1</span>

    <span class="s1">classifier = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">classifier.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">y_pred = classifier.predict_proba(X)[:</span><span class="s0">, </span><span class="s1">pos_label]</span>

    <span class="s2"># safe guard for the binary if/else construction</span>
    <span class="s0">assert </span><span class="s1">constructor_name </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(classifier</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label</span>
        <span class="s1">)</span>

    <span class="s1">average_precision = average_precision_score(y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=pos_label)</span>

    <span class="s2"># check that the default name is used</span>
    <span class="s0">assert </span><span class="s1">display.line_.get_label() == default_label.format(average_precision)</span>

    <span class="s2"># check that the name can be set</span>
    <span class="s1">display.plot(name=</span><span class="s3">&quot;MySpecialEstimator&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">(</span>
        <span class="s1">display.line_.get_label()</span>
        <span class="s1">== </span><span class="s3">f&quot;MySpecialEstimator (AP = </span><span class="s0">{</span><span class="s1">average_precision</span><span class="s0">:</span><span class="s3">.2f</span><span class="s0">}</span><span class="s3">)&quot;</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;clf&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">make_pipeline(StandardScaler()</span><span class="s0">, </span><span class="s1">LogisticRegression())</span><span class="s0">,</span>
        <span class="s1">make_pipeline(</span>
            <span class="s1">make_column_transformer((StandardScaler()</span><span class="s0">, </span><span class="s1">[</span><span class="s5">0</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]))</span><span class="s0">, </span><span class="s1">LogisticRegression()</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_precision_recall_display_pipeline(pyplot</span><span class="s0">, </span><span class="s1">clf):</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">n_samples=</span><span class="s5">50</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(NotFittedError):</span>
        <span class="s1">PrecisionRecallDisplay.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">display = PrecisionRecallDisplay.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">display.estimator_name == clf.__class__.__name__</span>


<span class="s0">def </span><span class="s1">test_precision_recall_display_string_labels(pyplot):</span>
    <span class="s2"># regression test #15738</span>
    <span class="s1">cancer = load_breast_cancer()</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = cancer.data</span><span class="s0">, </span><span class="s1">cancer.target_names[cancer.target]</span>

    <span class="s1">lr = make_pipeline(StandardScaler()</span><span class="s0">, </span><span class="s1">LogisticRegression())</span>
    <span class="s1">lr.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">for </span><span class="s1">klass </span><span class="s0">in </span><span class="s1">cancer.target_names:</span>
        <span class="s0">assert </span><span class="s1">klass </span><span class="s0">in </span><span class="s1">lr.classes_</span>
    <span class="s1">display = PrecisionRecallDisplay.from_estimator(lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">y_pred = lr.predict_proba(X)[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">avg_prec = average_precision_score(y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=lr.classes_[</span><span class="s5">1</span><span class="s1">])</span>

    <span class="s0">assert </span><span class="s1">display.average_precision == pytest.approx(avg_prec)</span>
    <span class="s0">assert </span><span class="s1">display.estimator_name == lr.__class__.__name__</span>

    <span class="s1">err_msg = </span><span class="s3">r&quot;y_true takes value in {'benign', 'malignant'}&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">PrecisionRecallDisplay.from_predictions(y</span><span class="s0">, </span><span class="s1">y_pred)</span>

    <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">pos_label=lr.classes_[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">display.average_precision == pytest.approx(avg_prec)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;average_precision, estimator_name, expected_label&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s5">0.9</span><span class="s0">, None, </span><span class="s3">&quot;AP = 0.90&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s0">None, </span><span class="s3">&quot;my_est&quot;</span><span class="s0">, </span><span class="s3">&quot;my_est&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s5">0.8</span><span class="s0">, </span><span class="s3">&quot;my_est2&quot;</span><span class="s0">, </span><span class="s3">&quot;my_est2 (AP = 0.80)&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_default_labels(pyplot</span><span class="s0">, </span><span class="s1">average_precision</span><span class="s0">, </span><span class="s1">estimator_name</span><span class="s0">, </span><span class="s1">expected_label):</span>
    <span class="s4">&quot;&quot;&quot;Check the default labels used in the display.&quot;&quot;&quot;</span>
    <span class="s1">precision = np.array([</span><span class="s5">1</span><span class="s0">, </span><span class="s5">0.5</span><span class="s0">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">recall = np.array([</span><span class="s5">0</span><span class="s0">, </span><span class="s5">0.5</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">display = PrecisionRecallDisplay(</span>
        <span class="s1">precision</span><span class="s0">,</span>
        <span class="s1">recall</span><span class="s0">,</span>
        <span class="s1">average_precision=average_precision</span><span class="s0">,</span>
        <span class="s1">estimator_name=estimator_name</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">display.plot()</span>
    <span class="s0">assert </span><span class="s1">display.line_.get_label() == expected_label</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;constructor_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;predict_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_plot_precision_recall_pos_label(pyplot</span><span class="s0">, </span><span class="s1">constructor_name</span><span class="s0">, </span><span class="s1">response_method):</span>
    <span class="s2"># check that we can provide the positive label and display the proper</span>
    <span class="s2"># statistics</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = load_breast_cancer(return_X_y=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s2"># create an highly imbalanced version of the breast cancer dataset</span>
    <span class="s1">idx_positive = np.flatnonzero(y == </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">idx_negative = np.flatnonzero(y == </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">idx_selected = np.hstack([idx_negative</span><span class="s0">, </span><span class="s1">idx_positive[:</span><span class="s5">25</span><span class="s1">]])</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = X[idx_selected]</span><span class="s0">, </span><span class="s1">y[idx_selected]</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = shuffle(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">42</span><span class="s1">)</span>
    <span class="s2"># only use 2 features to make the problem even harder</span>
    <span class="s1">X = X[:</span><span class="s0">, </span><span class="s1">:</span><span class="s5">2</span><span class="s1">]</span>
    <span class="s1">y = np.array([</span><span class="s3">&quot;cancer&quot; </span><span class="s0">if </span><span class="s1">c == </span><span class="s5">1 </span><span class="s0">else </span><span class="s3">&quot;not cancer&quot; </span><span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">y]</span><span class="s0">, </span><span class="s1">dtype=object)</span>
    <span class="s1">X_train</span><span class="s0">, </span><span class="s1">X_test</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">y_test = train_test_split(</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">y</span><span class="s0">,</span>
        <span class="s1">stratify=y</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s5">0</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">classifier = LogisticRegression()</span>
    <span class="s1">classifier.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>

    <span class="s2"># sanity check to be sure the positive class is classes_[0] and that we</span>
    <span class="s2"># are betrayed by the class imbalance</span>
    <span class="s0">assert </span><span class="s1">classifier.classes_.tolist() == [</span><span class="s3">&quot;cancer&quot;</span><span class="s0">, </span><span class="s3">&quot;not cancer&quot;</span><span class="s1">]</span>

    <span class="s1">y_pred = getattr(classifier</span><span class="s0">, </span><span class="s1">response_method)(X_test)</span>
    <span class="s2"># we select the corresponding probability columns or reverse the decision</span>
    <span class="s2">#  function otherwise</span>
    <span class="s1">y_pred_cancer = -</span><span class="s5">1 </span><span class="s1">* y_pred </span><span class="s0">if </span><span class="s1">y_pred.ndim == </span><span class="s5">1 </span><span class="s0">else </span><span class="s1">y_pred[:</span><span class="s0">, </span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">y_pred_not_cancer = y_pred </span><span class="s0">if </span><span class="s1">y_pred.ndim == </span><span class="s5">1 </span><span class="s0">else </span><span class="s1">y_pred[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(</span>
            <span class="s1">classifier</span><span class="s0">,</span>
            <span class="s1">X_test</span><span class="s0">,</span>
            <span class="s1">y_test</span><span class="s0">,</span>
            <span class="s1">pos_label=</span><span class="s3">&quot;cancer&quot;</span><span class="s0">,</span>
            <span class="s1">response_method=response_method</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y_test</span><span class="s0">,</span>
            <span class="s1">y_pred_cancer</span><span class="s0">,</span>
            <span class="s1">pos_label=</span><span class="s3">&quot;cancer&quot;</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s2"># we should obtain the statistics of the &quot;cancer&quot; class</span>
    <span class="s1">avg_prec_limit = </span><span class="s5">0.65</span>
    <span class="s0">assert </span><span class="s1">display.average_precision &lt; avg_prec_limit</span>
    <span class="s0">assert </span><span class="s1">-trapezoid(display.precision</span><span class="s0">, </span><span class="s1">display.recall) &lt; avg_prec_limit</span>

    <span class="s2"># otherwise we should obtain the statistics of the &quot;not cancer&quot; class</span>
    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(</span>
            <span class="s1">classifier</span><span class="s0">,</span>
            <span class="s1">X_test</span><span class="s0">,</span>
            <span class="s1">y_test</span><span class="s0">,</span>
            <span class="s1">response_method=response_method</span><span class="s0">,</span>
            <span class="s1">pos_label=</span><span class="s3">&quot;not cancer&quot;</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y_test</span><span class="s0">,</span>
            <span class="s1">y_pred_not_cancer</span><span class="s0">,</span>
            <span class="s1">pos_label=</span><span class="s3">&quot;not cancer&quot;</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s1">avg_prec_limit = </span><span class="s5">0.95</span>
    <span class="s0">assert </span><span class="s1">display.average_precision &gt; avg_prec_limit</span>
    <span class="s0">assert </span><span class="s1">-trapezoid(display.precision</span><span class="s0">, </span><span class="s1">display.recall) &gt; avg_prec_limit</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;constructor_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s3">&quot;from_predictions&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_precision_recall_prevalence_pos_label_reusable(pyplot</span><span class="s0">, </span><span class="s1">constructor_name):</span>
    <span class="s2"># Check that even if one passes plot_chance_level=False the first time</span>
    <span class="s2"># one can still call disp.plot with plot_chance_level=True and get the</span>
    <span class="s2"># chance level line</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">n_samples=</span><span class="s5">50</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s1">lr = LogisticRegression()</span>
    <span class="s1">y_pred = lr.fit(X</span><span class="s0">, </span><span class="s1">y).predict_proba(X)[:</span><span class="s0">, </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s3">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_estimator(</span>
            <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">plot_chance_level=</span><span class="s0">False</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">display = PrecisionRecallDisplay.from_predictions(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">plot_chance_level=</span><span class="s0">False</span>
        <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">display.chance_level_ </span><span class="s0">is None</span>

    <span class="s0">import </span><span class="s1">matplotlib </span><span class="s0">as </span><span class="s1">mpl  </span><span class="s2"># noqa</span>

    <span class="s2"># When calling from_estimator or from_predictions,</span>
    <span class="s2"># prevalence_pos_label should have been set, so that directly</span>
    <span class="s2"># calling plot_chance_level=True should plot the chance level line</span>
    <span class="s1">display.plot(plot_chance_level=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">isinstance(display.chance_level_</span><span class="s0">, </span><span class="s1">mpl.lines.Line2D)</span>


<span class="s0">def </span><span class="s1">test_precision_recall_raise_no_prevalence(pyplot):</span>
    <span class="s2"># Check that raises correctly when plotting chance level with</span>
    <span class="s2"># no prvelance_pos_label is provided</span>
    <span class="s1">precision = np.array([</span><span class="s5">1</span><span class="s0">, </span><span class="s5">0.5</span><span class="s0">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">recall = np.array([</span><span class="s5">0</span><span class="s0">, </span><span class="s5">0.5</span><span class="s0">, </span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">display = PrecisionRecallDisplay(precision</span><span class="s0">, </span><span class="s1">recall)</span>

    <span class="s1">msg = (</span>
        <span class="s3">&quot;You must provide prevalence_pos_label when constructing the &quot;</span>
        <span class="s3">&quot;PrecisionRecallDisplay object in order to plot the chance &quot;</span>
        <span class="s3">&quot;level line. Alternatively, you may use &quot;</span>
        <span class="s3">&quot;PrecisionRecallDisplay.from_estimator or &quot;</span>
        <span class="s3">&quot;PrecisionRecallDisplay.from_predictions &quot;</span>
        <span class="s3">&quot;to automatically set prevalence_pos_label&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">display.plot(plot_chance_level=</span><span class="s0">True</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>smoothers_lowess.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
smoothers_lowess.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot;Lowess - wrapper for cythonized extension 
 
Author : Chris Jordan-Squire 
Author : Carl Vogel 
Author : Josef Perktold 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">._smoothers_lowess </span><span class="s3">import </span><span class="s1">lowess </span><span class="s3">as </span><span class="s1">_lowess</span>

<span class="s3">def </span><span class="s1">lowess(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">frac=</span><span class="s4">2.0</span><span class="s1">/</span><span class="s4">3.0</span><span class="s3">, </span><span class="s1">it=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">delta=</span><span class="s4">0.0</span><span class="s3">, </span><span class="s1">xvals=</span><span class="s3">None, </span><span class="s1">is_sorted=</span><span class="s3">False,</span>
           <span class="s1">missing=</span><span class="s5">'drop'</span><span class="s3">, </span><span class="s1">return_sorted=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">'''LOWESS (Locally Weighted Scatterplot Smoothing) 
 
    A lowess function that outs smoothed estimates of endog 
    at the given exog values from points (exog, endog) 
 
    Parameters 
    ---------- 
    endog : 1-D numpy array 
        The y-values of the observed points 
    exog : 1-D numpy array 
        The x-values of the observed points 
    frac : float 
        Between 0 and 1. The fraction of the data used 
        when estimating each y-value. 
    it : int 
        The number of residual-based reweightings 
        to perform. 
    delta : float 
        Distance within which to use linear-interpolation 
        instead of weighted regression. 
    xvals: 1-D numpy array 
        Values of the exogenous variable at which to evaluate the regression. 
        If supplied, cannot use delta. 
    is_sorted : bool 
        If False (default), then the data will be sorted by exog before 
        calculating lowess. If True, then it is assumed that the data is 
        already sorted by exog. If xvals is specified, then it too must be 
        sorted if is_sorted is True. 
    missing : str 
        Available options are 'none', 'drop', and 'raise'. If 'none', no nan 
        checking is done. If 'drop', any observations with nans are dropped. 
        If 'raise', an error is raised. Default is 'drop'. 
    return_sorted : bool 
        If True (default), then the returned array is sorted by exog and has 
        missing (nan or infinite) observations removed. 
        If False, then the returned array is in the same length and the same 
        sequence of observations as the input array. 
 
    Returns 
    ------- 
    out : {ndarray, float} 
        The returned array is two-dimensional if return_sorted is True, and 
        one dimensional if return_sorted is False. 
        If return_sorted is True, then a numpy array with two columns. The 
        first column contains the sorted x (exog) values and the second column 
        the associated estimated y (endog) values. 
        If return_sorted is False, then only the fitted values are returned, 
        and the observations will be in the same order as the input arrays. 
        If xvals is provided, then return_sorted is ignored and the returned 
        array is always one dimensional, containing the y values fitted at 
        the x values provided by xvals. 
 
    Notes 
    ----- 
    This lowess function implements the algorithm given in the 
    reference below using local linear estimates. 
 
    Suppose the input data has N points. The algorithm works by 
    estimating the `smooth` y_i by taking the frac*N closest points 
    to (x_i,y_i) based on their x values and estimating y_i 
    using a weighted linear regression. The weight for (x_j,y_j) 
    is tricube function applied to abs(x_i-x_j). 
 
    If it &gt; 1, then further weighted local linear regressions 
    are performed, where the weights are the same as above 
    times the _lowess_bisquare function of the residuals. Each iteration 
    takes approximately the same amount of time as the original fit, 
    so these iterations are expensive. They are most useful when 
    the noise has extremely heavy tails, such as Cauchy noise. 
    Noise with less heavy-tails, such as t-distributions with df&gt;2, 
    are less problematic. The weights downgrade the influence of 
    points with large residuals. In the extreme case, points whose 
    residuals are larger than 6 times the median absolute residual 
    are given weight 0. 
 
    `delta` can be used to save computations. For each `x_i`, regressions 
    are skipped for points closer than `delta`. The next regression is 
    fit for the farthest point within delta of `x_i` and all points in 
    between are estimated by linearly interpolating between the two 
    regression fits. 
 
    Judicious choice of delta can cut computation time considerably 
    for large data (N &gt; 5000). A good choice is ``delta = 0.01 * range(exog)``. 
 
    If `xvals` is provided, the regression is then computed at those points 
    and the fit values are returned. Otherwise, the regression is run 
    at points of `exog`. 
 
    Some experimentation is likely required to find a good 
    choice of `frac` and `iter` for a particular dataset. 
 
    References 
    ---------- 
    Cleveland, W.S. (1979) &quot;Robust Locally Weighted Regression 
    and Smoothing Scatterplots&quot;. Journal of the American Statistical 
    Association 74 (368): 829-836. 
 
    Examples 
    -------- 
    The below allows a comparison between how different the fits from 
    lowess for different values of frac can be. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; lowess = sm.nonparametric.lowess 
    &gt;&gt;&gt; x = np.random.uniform(low = -2*np.pi, high = 2*np.pi, size=500) 
    &gt;&gt;&gt; y = np.sin(x) + np.random.normal(size=len(x)) 
    &gt;&gt;&gt; z = lowess(y, x) 
    &gt;&gt;&gt; w = lowess(y, x, frac=1./3) 
 
    This gives a similar comparison for when it is 0 vs not. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import scipy.stats as stats 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; lowess = sm.nonparametric.lowess 
    &gt;&gt;&gt; x = np.random.uniform(low = -2*np.pi, high = 2*np.pi, size=500) 
    &gt;&gt;&gt; y = np.sin(x) + stats.cauchy.rvs(size=len(x)) 
    &gt;&gt;&gt; z = lowess(y, x, frac= 1./3, it=0) 
    &gt;&gt;&gt; w = lowess(y, x, frac=1./3) 
 
    '''</span>

    <span class="s1">endog = np.asarray(endog</span><span class="s3">, </span><span class="s1">float)</span>
    <span class="s1">exog = np.asarray(exog</span><span class="s3">, </span><span class="s1">float)</span>

    <span class="s0"># Whether xvals argument was provided</span>
    <span class="s1">given_xvals = (xvals </span><span class="s3">is not None</span><span class="s1">)</span>

    <span class="s0"># Inputs should be vectors (1-D arrays) of the</span>
    <span class="s0"># same length.</span>
    <span class="s3">if </span><span class="s1">exog.ndim != </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'exog must be a vector'</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">endog.ndim != </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'endog must be a vector'</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">endog.shape[</span><span class="s4">0</span><span class="s1">] != exog.shape[</span><span class="s4">0</span><span class="s1">] :</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'exog and endog must have same length'</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">xvals </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">xvals = np.ascontiguousarray(xvals)</span>
        <span class="s3">if </span><span class="s1">xvals.ndim != </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'exog_predict must be a vector'</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">missing </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'drop'</span><span class="s3">, </span><span class="s5">'raise'</span><span class="s1">]:</span>
        <span class="s1">mask_valid = (np.isfinite(exog) &amp; np.isfinite(endog))</span>
        <span class="s1">all_valid = np.all(mask_valid)</span>
        <span class="s3">if </span><span class="s1">all_valid:</span>
            <span class="s1">y = endog</span>
            <span class="s1">x = exog</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">missing == </span><span class="s5">'drop'</span><span class="s1">:</span>
                <span class="s1">x = exog[mask_valid]</span>
                <span class="s1">y = endog[mask_valid]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'nan or inf found in data'</span><span class="s1">)</span>
    <span class="s3">elif </span><span class="s1">missing == </span><span class="s5">'none'</span><span class="s1">:</span>
        <span class="s1">y = endog</span>
        <span class="s1">x = exog</span>
        <span class="s1">all_valid = </span><span class="s3">True   </span><span class="s0"># we assume it's true if missing='none'</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;missing can only be 'none', 'drop' or 'raise'&quot;</span><span class="s1">)</span>

    <span class="s3">if not </span><span class="s1">is_sorted:</span>
        <span class="s0"># Sort both inputs according to the ascending order of x values</span>
        <span class="s1">sort_index = np.argsort(x)</span>
        <span class="s1">x = np.array(x[sort_index])</span>
        <span class="s1">y = np.array(y[sort_index])</span>

    <span class="s3">if not </span><span class="s1">given_xvals:</span>
        <span class="s0"># If given no explicit x values, we use the x-values in the exog array</span>
        <span class="s1">xvals = exog</span>
        <span class="s1">xvalues = x</span>

        <span class="s1">xvals_all_valid = all_valid</span>
        <span class="s3">if </span><span class="s1">missing == </span><span class="s5">'drop'</span><span class="s1">:</span>
            <span class="s1">xvals_mask_valid = mask_valid</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">delta != </span><span class="s4">0.0</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Cannot have non-zero 'delta' and 'xvals' values&quot;</span><span class="s1">)</span>
            <span class="s0"># TODO: allow this again</span>
        <span class="s1">mask_valid = np.isfinite(xvals)</span>
        <span class="s3">if </span><span class="s1">missing == </span><span class="s5">&quot;raise&quot;</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;NaN values in xvals with missing='raise'&quot;</span><span class="s1">)</span>
        <span class="s3">elif </span><span class="s1">missing == </span><span class="s5">'drop'</span><span class="s1">:</span>
            <span class="s1">xvals_mask_valid = mask_valid</span>

        <span class="s1">xvalues = xvals</span>
        <span class="s1">xvals_all_valid = </span><span class="s3">True if </span><span class="s1">missing == </span><span class="s5">&quot;none&quot; </span><span class="s3">else </span><span class="s1">np.all(mask_valid)</span>
        <span class="s0"># With explicit xvals, we ignore 'return_sorted' and always</span>
        <span class="s0"># use the order provided</span>
        <span class="s1">return_sorted = </span><span class="s3">False</span>

        <span class="s3">if </span><span class="s1">missing </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'drop'</span><span class="s3">, </span><span class="s5">'raise'</span><span class="s1">]:</span>
            <span class="s1">xvals_mask_valid = np.isfinite(xvals)</span>
            <span class="s1">xvals_all_valid = np.all(xvals_mask_valid)</span>
            <span class="s3">if </span><span class="s1">xvals_all_valid:</span>
                <span class="s1">xvalues = xvals</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">if </span><span class="s1">missing == </span><span class="s5">'drop'</span><span class="s1">:</span>
                    <span class="s1">xvalues = xvals[xvals_mask_valid]</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;nan or inf found in xvals&quot;</span><span class="s1">)</span>

        <span class="s3">if not </span><span class="s1">is_sorted:</span>
            <span class="s1">sort_index = np.argsort(xvalues)</span>
            <span class="s1">xvalues = np.array(xvalues[sort_index])</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">xvals_all_valid = </span><span class="s3">True</span>
    <span class="s1">y = np.ascontiguousarray(y)</span>
    <span class="s1">x = np.ascontiguousarray(x)</span>
    <span class="s3">if not </span><span class="s1">given_xvals:</span>
        <span class="s0"># Run LOWESS on the data points</span>
        <span class="s1">res</span><span class="s3">, </span><span class="s1">_ = _lowess(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">np.ones_like(x)</span><span class="s3">,</span>
                        <span class="s1">frac=frac</span><span class="s3">, </span><span class="s1">it=it</span><span class="s3">, </span><span class="s1">delta=delta</span><span class="s3">, </span><span class="s1">given_xvals=</span><span class="s3">False</span><span class="s1">)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s0"># First run LOWESS on the data points to get the weights of the data points</span>
        <span class="s0"># using it-1 iterations, last iter done next</span>
        <span class="s3">if </span><span class="s1">it &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">_</span><span class="s3">, </span><span class="s1">weights = _lowess(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">np.ones_like(x)</span><span class="s3">,</span>
                                <span class="s1">frac=frac</span><span class="s3">, </span><span class="s1">it=it-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">delta=delta</span><span class="s3">, </span><span class="s1">given_xvals=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">weights = np.ones_like(x)</span>
        <span class="s1">xvalues = np.ascontiguousarray(xvalues</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s0"># Then run once more using those supplied weights at the points provided by xvals</span>
        <span class="s0"># No extra iterations are performed here since weights are fixed</span>
        <span class="s1">res</span><span class="s3">, </span><span class="s1">_ = _lowess(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">xvalues</span><span class="s3">, </span><span class="s1">weights</span><span class="s3">,</span>
                        <span class="s1">frac=frac</span><span class="s3">, </span><span class="s1">it=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">delta=delta</span><span class="s3">, </span><span class="s1">given_xvals=</span><span class="s3">True</span><span class="s1">)</span>

    <span class="s1">_</span><span class="s3">, </span><span class="s1">yfitted = res.T</span>

    <span class="s3">if </span><span class="s1">return_sorted:</span>
        <span class="s3">return </span><span class="s1">res</span>
    <span class="s3">else</span><span class="s1">:</span>

        <span class="s0"># rebuild yfitted with original indices</span>
        <span class="s0"># a bit messy: y might have been selected twice</span>
        <span class="s3">if not </span><span class="s1">is_sorted:</span>
            <span class="s1">yfitted_ = np.empty_like(xvalues)</span>
            <span class="s1">yfitted_.fill(np.nan)</span>
            <span class="s1">yfitted_[sort_index] = yfitted</span>
            <span class="s1">yfitted = yfitted_</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">yfitted = yfitted</span>

        <span class="s3">if not </span><span class="s1">xvals_all_valid:</span>
            <span class="s1">yfitted_ = np.empty_like(xvals)</span>
            <span class="s1">yfitted_.fill(np.nan)</span>
            <span class="s1">yfitted_[xvals_mask_valid] = yfitted</span>
            <span class="s1">yfitted = yfitted_</span>

        <span class="s0"># we do not need to return exog anymore</span>
        <span class="s3">return </span><span class="s1">yfitted</span>
</pre>
</body>
</html>
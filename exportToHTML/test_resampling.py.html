<html>
<head>
<title>test_resampling.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_resampling.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">bootstrap</span><span class="s0">, </span><span class="s1">monte_carlo_test</span><span class="s0">, </span><span class="s1">permutation_test</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_equal</span><span class="s0">, </span><span class="s1">suppress_warnings</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">stats</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">special</span>
<span class="s0">from </span><span class="s1">.. </span><span class="s0">import </span><span class="s1">_resampling </span><span class="s0">as </span><span class="s1">_resampling</span>
<span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">rng_integers</span>
<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">root</span>


<span class="s0">def </span><span class="s1">test_bootstrap_iv():</span>

    <span class="s1">message = </span><span class="s2">&quot;`data` must be a sequence of samples.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">np.mean)</span>

    <span class="s1">message = </span><span class="s2">&quot;`data` must contain at least one sample.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(tuple()</span><span class="s0">, </span><span class="s1">np.mean)</span>

    <span class="s1">message = </span><span class="s2">&quot;each sample in `data` must contain two or more observations...&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">])</span><span class="s0">, </span><span class="s1">np.mean)</span>

    <span class="s1">message = (</span><span class="s2">&quot;When `paired is True`, all samples must have the same length &quot;</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">paired=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`vectorized` must be `True`, `False`, or `None`.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s2">'ekki'</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`axis` must be an integer.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1.5</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;could not convert string to float&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">confidence_level=</span><span class="s2">'ni'</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a non-negative integer.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=-</span><span class="s3">1000</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a non-negative integer.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">1000.5</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">batch=-</span><span class="s3">1000</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">1000.5</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`method` must be in&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'ekki'</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;`bootstrap_result` must have attribute `bootstrap_distribution'&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">bootstrap_result=</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;Either `bootstrap_result.bootstrap_distribution.size`&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">message = </span><span class="s2">&quot;'herring' cannot be used to seed a&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
        <span class="s1">bootstrap(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">'herring'</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">'basic'</span><span class="s0">, </span><span class="s2">'percentile'</span><span class="s0">, </span><span class="s2">'BCa'</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_batch(method</span><span class="s0">, </span><span class="s1">axis):</span>
    <span class="s4"># for one-sample statistics, batch size shouldn't affect the result</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">x = np.random.rand(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span><span class="s1">)</span>
    <span class="s1">res1 = bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">batch=</span><span class="s0">None, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">res2 = bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s1">)</span>

    <span class="s1">assert_equal(res2.confidence_interval.low</span><span class="s0">, </span><span class="s1">res1.confidence_interval.low)</span>
    <span class="s1">assert_equal(res2.confidence_interval.high</span><span class="s0">, </span><span class="s1">res1.confidence_interval.high)</span>
    <span class="s1">assert_equal(res2.standard_error</span><span class="s0">, </span><span class="s1">res1.standard_error)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">'basic'</span><span class="s0">, </span><span class="s2">'percentile'</span><span class="s0">, </span><span class="s2">'BCa'</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_paired(method):</span>
    <span class="s4"># test that `paired` works as expected</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s3">100</span>
    <span class="s1">x = np.random.rand(n)</span>
    <span class="s1">y = np.random.rand(n)</span>

    <span class="s0">def </span><span class="s1">my_statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">((x-y)**</span><span class="s3">2</span><span class="s1">).mean(axis=axis)</span>

    <span class="s0">def </span><span class="s1">my_paired_statistic(i</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s1">a = x[i]</span>
        <span class="s1">b = y[i]</span>
        <span class="s1">res = my_statistic(a</span><span class="s0">, </span><span class="s1">b)</span>
        <span class="s0">return </span><span class="s1">res</span>

    <span class="s1">i = np.arange(len(x))</span>

    <span class="s1">res1 = bootstrap((i</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">my_paired_statistic</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">res2 = bootstrap((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">my_statistic</span><span class="s0">, </span><span class="s1">paired=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">assert_allclose(res1.confidence_interval</span><span class="s0">, </span><span class="s1">res2.confidence_interval)</span>
    <span class="s1">assert_allclose(res1.standard_error</span><span class="s0">, </span><span class="s1">res2.standard_error)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">'basic'</span><span class="s0">, </span><span class="s2">'percentile'</span><span class="s0">, </span><span class="s2">'BCa'</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;paired&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_vectorized(method</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">paired):</span>
    <span class="s4"># test that paired is vectorized as expected: when samples are tiled,</span>
    <span class="s4"># CI and standard_error of each axis-slice is the same as those of the</span>
    <span class="s4"># original 1d sample</span>

    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">my_statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">x.mean(axis=axis) + y.mean(axis=axis) + z.mean(axis=axis)</span>

    <span class="s1">shape = </span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">12</span>
    <span class="s1">n_samples = shape[axis]</span>

    <span class="s1">x = np.random.rand(n_samples)</span>
    <span class="s1">y = np.random.rand(n_samples)</span>
    <span class="s1">z = np.random.rand(n_samples)</span>
    <span class="s1">res1 = bootstrap((x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span><span class="s0">, </span><span class="s1">my_statistic</span><span class="s0">, </span><span class="s1">paired=paired</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">(res1.bootstrap_distribution.shape</span>
            <span class="s1">== res1.standard_error.shape + (</span><span class="s3">100</span><span class="s0">,</span><span class="s1">))</span>

    <span class="s1">reshape = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">reshape[axis] = n_samples</span>
    <span class="s1">x = np.broadcast_to(x.reshape(reshape)</span><span class="s0">, </span><span class="s1">shape)</span>
    <span class="s1">y = np.broadcast_to(y.reshape(reshape)</span><span class="s0">, </span><span class="s1">shape)</span>
    <span class="s1">z = np.broadcast_to(z.reshape(reshape)</span><span class="s0">, </span><span class="s1">shape)</span>
    <span class="s1">res2 = bootstrap((x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span><span class="s0">, </span><span class="s1">my_statistic</span><span class="s0">, </span><span class="s1">paired=paired</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s1">)</span>

    <span class="s1">assert_allclose(res2.confidence_interval.low</span><span class="s0">,</span>
                    <span class="s1">res1.confidence_interval.low)</span>
    <span class="s1">assert_allclose(res2.confidence_interval.high</span><span class="s0">,</span>
                    <span class="s1">res1.confidence_interval.high)</span>
    <span class="s1">assert_allclose(res2.standard_error</span><span class="s0">, </span><span class="s1">res1.standard_error)</span>

    <span class="s1">result_shape = list(shape)</span>
    <span class="s1">result_shape.pop(axis)</span>

    <span class="s1">assert_equal(res2.confidence_interval.low.shape</span><span class="s0">, </span><span class="s1">result_shape)</span>
    <span class="s1">assert_equal(res2.confidence_interval.high.shape</span><span class="s0">, </span><span class="s1">result_shape)</span>
    <span class="s1">assert_equal(res2.standard_error.shape</span><span class="s0">, </span><span class="s1">result_shape)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">'basic'</span><span class="s0">, </span><span class="s2">'percentile'</span><span class="s0">, </span><span class="s2">'BCa'</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_against_theory(method):</span>
    <span class="s4"># based on https://www.statology.org/confidence-intervals-python/</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">2442101192988600726</span><span class="s1">)</span>
    <span class="s1">data = stats.norm.rvs(loc=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">5000</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">alpha = </span><span class="s3">0.95</span>
    <span class="s1">dist = stats.t(df=len(data)-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">loc=np.mean(data)</span><span class="s0">, </span><span class="s1">scale=stats.sem(data))</span>
    <span class="s1">expected_interval = dist.interval(confidence=alpha)</span>
    <span class="s1">expected_se = dist.std()</span>

    <span class="s1">config = dict(data=(data</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic=np.mean</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">5000</span><span class="s0">,</span>
                  <span class="s1">method=method</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">res = bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=alpha)</span>
    <span class="s1">assert_allclose(res.confidence_interval</span><span class="s0">, </span><span class="s1">expected_interval</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">5e-4</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.standard_error</span><span class="s0">, </span><span class="s1">expected_se</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">3e-4</span><span class="s1">)</span>

    <span class="s1">config.update(dict(n_resamples=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">bootstrap_result=res))</span>
    <span class="s1">res = bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=alpha</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval.high</span><span class="s0">, </span><span class="s1">dist.ppf(alpha)</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">5e-4</span><span class="s1">)</span>

    <span class="s1">config.update(dict(n_resamples=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">bootstrap_result=res))</span>
    <span class="s1">res = bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=alpha</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval.low</span><span class="s0">, </span><span class="s1">dist.ppf(</span><span class="s3">1</span><span class="s1">-alpha)</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">5e-4</span><span class="s1">)</span>


<span class="s1">tests_R = {</span><span class="s2">&quot;basic&quot;</span><span class="s1">: (</span><span class="s3">23.77</span><span class="s0">, </span><span class="s3">79.12</span><span class="s1">)</span><span class="s0">,</span>
           <span class="s2">&quot;percentile&quot;</span><span class="s1">: (</span><span class="s3">28.86</span><span class="s0">, </span><span class="s3">84.21</span><span class="s1">)</span><span class="s0">,</span>
           <span class="s2">&quot;BCa&quot;</span><span class="s1">: (</span><span class="s3">32.31</span><span class="s0">, </span><span class="s3">91.43</span><span class="s1">)}</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method, expected&quot;</span><span class="s0">, </span><span class="s1">tests_R.items())</span>
<span class="s0">def </span><span class="s1">test_bootstrap_against_R(method</span><span class="s0">, </span><span class="s1">expected):</span>
    <span class="s4"># Compare against R's &quot;boot&quot; library</span>
    <span class="s4"># library(boot)</span>

    <span class="s4"># stat &lt;- function (x, a) {</span>
    <span class="s4">#     mean(x[a])</span>
    <span class="s4"># }</span>

    <span class="s4"># x &lt;- c(10, 12, 12.5, 12.5, 13.9, 15, 21, 22,</span>
    <span class="s4">#        23, 34, 50, 81, 89, 121, 134, 213)</span>

    <span class="s4"># # Use a large value so we get a few significant digits for the CI.</span>
    <span class="s4"># n = 1000000</span>
    <span class="s4"># bootresult = boot(x, stat, n)</span>
    <span class="s4"># result &lt;- boot.ci(bootresult)</span>
    <span class="s4"># print(result)</span>
    <span class="s1">x = np.array([</span><span class="s3">10</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">12.5</span><span class="s0">, </span><span class="s3">12.5</span><span class="s0">, </span><span class="s3">13.9</span><span class="s0">, </span><span class="s3">15</span><span class="s0">, </span><span class="s3">21</span><span class="s0">, </span><span class="s3">22</span><span class="s0">,</span>
                  <span class="s3">23</span><span class="s0">, </span><span class="s3">34</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">89</span><span class="s0">, </span><span class="s3">121</span><span class="s0">, </span><span class="s3">134</span><span class="s0">, </span><span class="s3">213</span><span class="s1">])</span>
    <span class="s1">res = bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">1000000</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                    <span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">0.005</span><span class="s1">)</span>


<span class="s1">tests_against_itself_1samp = {</span><span class="s2">&quot;basic&quot;</span><span class="s1">: </span><span class="s3">1780</span><span class="s0">,</span>
                              <span class="s2">&quot;percentile&quot;</span><span class="s1">: </span><span class="s3">1784</span><span class="s0">,</span>
                              <span class="s2">&quot;BCa&quot;</span><span class="s1">: </span><span class="s3">1784</span><span class="s1">}</span>


<span class="s0">def </span><span class="s1">test_multisample_BCa_against_R():</span>
    <span class="s4"># Because bootstrap is stochastic, it's tricky to test against reference</span>
    <span class="s4"># behavior. Here, we show that SciPy's BCa CI matches R wboot's BCa CI</span>
    <span class="s4"># much more closely than the other SciPy CIs do.</span>

    <span class="s4"># arbitrary skewed data</span>
    <span class="s1">x = [</span><span class="s3">0.75859206</span><span class="s0">, </span><span class="s3">0.5910282</span><span class="s0">, </span><span class="s1">-</span><span class="s3">0.4419409</span><span class="s0">, </span><span class="s1">-</span><span class="s3">0.36654601</span><span class="s0">,</span>
         <span class="s3">0.34955357</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1.38835871</span><span class="s0">, </span><span class="s3">0.76735821</span><span class="s1">]</span>
    <span class="s1">y = [</span><span class="s3">1.41186073</span><span class="s0">, </span><span class="s3">0.49775975</span><span class="s0">, </span><span class="s3">0.08275588</span><span class="s0">, </span><span class="s3">0.24086388</span><span class="s0">,</span>
         <span class="s3">0.03567057</span><span class="s0">, </span><span class="s3">0.52024419</span><span class="s0">, </span><span class="s3">0.31966611</span><span class="s0">, </span><span class="s3">1.32067634</span><span class="s1">]</span>

    <span class="s4"># a multi-sample statistic for which the BCa CI tends to be different</span>
    <span class="s4"># from the other CIs</span>
    <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s1">s1 = stats.skew(x</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">s2 = stats.skew(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s0">return </span><span class="s1">s1 - s2</span>

    <span class="s4"># compute confidence intervals using each method</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">468865032284792692</span><span class="s1">)</span>

    <span class="s1">res_basic = stats.bootstrap((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'basic'</span><span class="s0">,</span>
                                <span class="s1">batch=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">res_percent = stats.bootstrap((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'percentile'</span><span class="s0">,</span>
                                  <span class="s1">batch=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">res_bca = stats.bootstrap((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'bca'</span><span class="s0">,</span>
                              <span class="s1">batch=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s4"># compute midpoints so we can compare just one number for each</span>
    <span class="s1">mid_basic = np.mean(res_basic.confidence_interval)</span>
    <span class="s1">mid_percent = np.mean(res_percent.confidence_interval)</span>
    <span class="s1">mid_bca = np.mean(res_bca.confidence_interval)</span>

    <span class="s4"># reference for BCA CI computed using R wboot package:</span>
    <span class="s4"># library(wBoot)</span>
    <span class="s4"># library(moments)</span>

    <span class="s4"># x = c(0.75859206, 0.5910282, -0.4419409, -0.36654601,</span>
    <span class="s4">#       0.34955357, -1.38835871,  0.76735821)</span>
    <span class="s4"># y = c(1.41186073, 0.49775975, 0.08275588, 0.24086388,</span>
    <span class="s4">#       0.03567057, 0.52024419, 0.31966611, 1.32067634)</span>

    <span class="s4"># twoskew &lt;- function(x1, y1) {skewness(x1) - skewness(y1)}</span>
    <span class="s4"># boot.two.bca(x, y, skewness, conf.level = 0.95,</span>
    <span class="s4">#              R = 9999, stacked = FALSE)</span>
    <span class="s1">mid_wboot = -</span><span class="s3">1.5519</span>

    <span class="s4"># compute percent difference relative to wboot BCA method</span>
    <span class="s1">diff_basic = (mid_basic - mid_wboot)/abs(mid_wboot)</span>
    <span class="s1">diff_percent = (mid_percent - mid_wboot)/abs(mid_wboot)</span>
    <span class="s1">diff_bca = (mid_bca - mid_wboot)/abs(mid_wboot)</span>

    <span class="s4"># SciPy's BCa CI midpoint is much closer than that of the other methods</span>
    <span class="s0">assert </span><span class="s1">diff_basic &lt; -</span><span class="s3">0.15</span>
    <span class="s0">assert </span><span class="s1">diff_percent &gt; </span><span class="s3">0.15</span>
    <span class="s0">assert </span><span class="s1">abs(diff_bca) &lt; </span><span class="s3">0.03</span>


<span class="s0">def </span><span class="s1">test_BCa_acceleration_against_reference():</span>
    <span class="s4"># Compare the (deterministic) acceleration parameter for a multi-sample</span>
    <span class="s4"># problem against a reference value. The example is from [1], but Efron's</span>
    <span class="s4"># value seems inaccurate. Straightorward code for computing the</span>
    <span class="s4"># reference acceleration (0.011008228344026734) is available at:</span>
    <span class="s4"># https://github.com/scipy/scipy/pull/16455#issuecomment-1193400981</span>

    <span class="s1">y = np.array([</span><span class="s3">10</span><span class="s0">, </span><span class="s3">27</span><span class="s0">, </span><span class="s3">31</span><span class="s0">, </span><span class="s3">40</span><span class="s0">, </span><span class="s3">46</span><span class="s0">, </span><span class="s3">50</span><span class="s0">, </span><span class="s3">52</span><span class="s0">, </span><span class="s3">104</span><span class="s0">, </span><span class="s3">146</span><span class="s1">])</span>
    <span class="s1">z = np.array([</span><span class="s3">16</span><span class="s0">, </span><span class="s3">23</span><span class="s0">, </span><span class="s3">38</span><span class="s0">, </span><span class="s3">94</span><span class="s0">, </span><span class="s3">99</span><span class="s0">, </span><span class="s3">141</span><span class="s0">, </span><span class="s3">197</span><span class="s1">])</span>

    <span class="s0">def </span><span class="s1">statistic(z</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">np.mean(z</span><span class="s0">, </span><span class="s1">axis=axis) - np.mean(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>

    <span class="s1">data = [z</span><span class="s0">, </span><span class="s1">y]</span>
    <span class="s1">res = stats.bootstrap(data</span><span class="s0">, </span><span class="s1">statistic)</span>

    <span class="s1">axis = -</span><span class="s3">1</span>
    <span class="s1">alpha = </span><span class="s3">0.95</span>
    <span class="s1">theta_hat_b = res.bootstrap_distribution</span>
    <span class="s1">batch = </span><span class="s3">100</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">a_hat = _resampling._bca_interval(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">alpha</span><span class="s0">,</span>
                                            <span class="s1">theta_hat_b</span><span class="s0">, </span><span class="s1">batch)</span>
    <span class="s1">assert_allclose(a_hat</span><span class="s0">, </span><span class="s3">0.011008228344026734</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method, expected&quot;</span><span class="s0">,</span>
                         <span class="s1">tests_against_itself_1samp.items())</span>
<span class="s0">def </span><span class="s1">test_bootstrap_against_itself_1samp(method</span><span class="s0">, </span><span class="s1">expected):</span>
    <span class="s4"># The expected values in this test were generated using bootstrap</span>
    <span class="s4"># to check for unintended changes in behavior. The test also makes sure</span>
    <span class="s4"># that bootstrap works with multi-sample statistics and that the</span>
    <span class="s4"># `axis` argument works as expected / function is vectorized.</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s3">100  </span><span class="s4"># size of sample</span>
    <span class="s1">n_resamples = </span><span class="s3">999  </span><span class="s4"># number of bootstrap resamples used to form each CI</span>
    <span class="s1">confidence_level = </span><span class="s3">0.9</span>

    <span class="s4"># The true mean is 5</span>
    <span class="s1">dist = stats.norm(loc=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">stat_true = dist.mean()</span>

    <span class="s4"># Do the same thing 2000 times. (The code is fully vectorized.)</span>
    <span class="s1">n_replications = </span><span class="s3">2000</span>
    <span class="s1">data = dist.rvs(size=(n_replications</span><span class="s0">, </span><span class="s1">n))</span>
    <span class="s1">res = bootstrap((data</span><span class="s0">,</span><span class="s1">)</span><span class="s0">,</span>
                    <span class="s1">statistic=np.mean</span><span class="s0">,</span>
                    <span class="s1">confidence_level=confidence_level</span><span class="s0">,</span>
                    <span class="s1">n_resamples=n_resamples</span><span class="s0">,</span>
                    <span class="s1">batch=</span><span class="s3">50</span><span class="s0">,</span>
                    <span class="s1">method=method</span><span class="s0">,</span>
                    <span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">ci = res.confidence_interval</span>

    <span class="s4"># ci contains vectors of lower and upper confidence interval bounds</span>
    <span class="s1">ci_contains_true = np.sum((ci[</span><span class="s3">0</span><span class="s1">] &lt; stat_true) &amp; (stat_true &lt; ci[</span><span class="s3">1</span><span class="s1">]))</span>
    <span class="s0">assert </span><span class="s1">ci_contains_true == expected</span>

    <span class="s4"># ci_contains_true is not inconsistent with confidence_level</span>
    <span class="s1">pvalue = stats.binomtest(ci_contains_true</span><span class="s0">, </span><span class="s1">n_replications</span><span class="s0">,</span>
                             <span class="s1">confidence_level).pvalue</span>
    <span class="s0">assert </span><span class="s1">pvalue &gt; </span><span class="s3">0.1</span>


<span class="s1">tests_against_itself_2samp = {</span><span class="s2">&quot;basic&quot;</span><span class="s1">: </span><span class="s3">892</span><span class="s0">,</span>
                              <span class="s2">&quot;percentile&quot;</span><span class="s1">: </span><span class="s3">890</span><span class="s1">}</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method, expected&quot;</span><span class="s0">,</span>
                         <span class="s1">tests_against_itself_2samp.items())</span>
<span class="s0">def </span><span class="s1">test_bootstrap_against_itself_2samp(method</span><span class="s0">, </span><span class="s1">expected):</span>
    <span class="s4"># The expected values in this test were generated using bootstrap</span>
    <span class="s4"># to check for unintended changes in behavior. The test also makes sure</span>
    <span class="s4"># that bootstrap works with multi-sample statistics and that the</span>
    <span class="s4"># `axis` argument works as expected / function is vectorized.</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">n1 = </span><span class="s3">100  </span><span class="s4"># size of sample 1</span>
    <span class="s1">n2 = </span><span class="s3">120  </span><span class="s4"># size of sample 2</span>
    <span class="s1">n_resamples = </span><span class="s3">999  </span><span class="s4"># number of bootstrap resamples used to form each CI</span>
    <span class="s1">confidence_level = </span><span class="s3">0.9</span>

    <span class="s4"># The statistic we're interested in is the difference in means</span>
    <span class="s0">def </span><span class="s1">my_stat(data1</span><span class="s0">, </span><span class="s1">data2</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s1">mean1 = np.mean(data1</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">mean2 = np.mean(data2</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s0">return </span><span class="s1">mean1 - mean2</span>

    <span class="s4"># The true difference in the means is -0.1</span>
    <span class="s1">dist1 = stats.norm(loc=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">dist2 = stats.norm(loc=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">stat_true = dist1.mean() - dist2.mean()</span>

    <span class="s4"># Do the same thing 1000 times. (The code is fully vectorized.)</span>
    <span class="s1">n_replications = </span><span class="s3">1000</span>
    <span class="s1">data1 = dist1.rvs(size=(n_replications</span><span class="s0">, </span><span class="s1">n1))</span>
    <span class="s1">data2 = dist2.rvs(size=(n_replications</span><span class="s0">, </span><span class="s1">n2))</span>
    <span class="s1">res = bootstrap((data1</span><span class="s0">, </span><span class="s1">data2)</span><span class="s0">,</span>
                    <span class="s1">statistic=my_stat</span><span class="s0">,</span>
                    <span class="s1">confidence_level=confidence_level</span><span class="s0">,</span>
                    <span class="s1">n_resamples=n_resamples</span><span class="s0">,</span>
                    <span class="s1">batch=</span><span class="s3">50</span><span class="s0">,</span>
                    <span class="s1">method=method</span><span class="s0">,</span>
                    <span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">ci = res.confidence_interval</span>

    <span class="s4"># ci contains vectors of lower and upper confidence interval bounds</span>
    <span class="s1">ci_contains_true = np.sum((ci[</span><span class="s3">0</span><span class="s1">] &lt; stat_true) &amp; (stat_true &lt; ci[</span><span class="s3">1</span><span class="s1">]))</span>
    <span class="s0">assert </span><span class="s1">ci_contains_true == expected</span>

    <span class="s4"># ci_contains_true is not inconsistent with confidence_level</span>
    <span class="s1">pvalue = stats.binomtest(ci_contains_true</span><span class="s0">, </span><span class="s1">n_replications</span><span class="s0">,</span>
                             <span class="s1">confidence_level).pvalue</span>
    <span class="s0">assert </span><span class="s1">pvalue &gt; </span><span class="s3">0.1</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;basic&quot;</span><span class="s0">, </span><span class="s2">&quot;percentile&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_vectorized_3samp(method</span><span class="s0">, </span><span class="s1">axis):</span>
    <span class="s0">def </span><span class="s1">statistic(*data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s4"># an arbitrary, vectorized statistic</span>
        <span class="s0">return </span><span class="s1">sum(sample.mean(axis) </span><span class="s0">for </span><span class="s1">sample </span><span class="s0">in </span><span class="s1">data)</span>

    <span class="s0">def </span><span class="s1">statistic_1d(*data):</span>
        <span class="s4"># the same statistic, not vectorized</span>
        <span class="s0">for </span><span class="s1">sample </span><span class="s0">in </span><span class="s1">data:</span>
            <span class="s0">assert </span><span class="s1">sample.ndim == </span><span class="s3">1</span>
        <span class="s0">return </span><span class="s1">statistic(*data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">y = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">z = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">res1 = bootstrap((x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                     <span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">res2 = bootstrap((x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span><span class="s0">, </span><span class="s1">statistic_1d</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False,</span>
                     <span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res1.confidence_interval</span><span class="s0">, </span><span class="s1">res2.confidence_interval)</span>
    <span class="s1">assert_allclose(res1.standard_error</span><span class="s0">, </span><span class="s1">res2.standard_error)</span>


<span class="s1">@pytest.mark.xfail_on_32bit(</span><span class="s2">&quot;Failure is not concerning; see gh-14107&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;basic&quot;</span><span class="s0">, </span><span class="s2">&quot;percentile&quot;</span><span class="s0">, </span><span class="s2">&quot;BCa&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_vectorized_1samp(method</span><span class="s0">, </span><span class="s1">axis):</span>
    <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">):</span>
        <span class="s4"># an arbitrary, vectorized statistic</span>
        <span class="s0">return </span><span class="s1">x.mean(axis=axis)</span>

    <span class="s0">def </span><span class="s1">statistic_1d(x):</span>
        <span class="s4"># the same statistic, not vectorized</span>
        <span class="s0">assert </span><span class="s1">x.ndim == </span><span class="s3">1</span>
        <span class="s0">return </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">res1 = bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True, </span><span class="s1">axis=axis</span><span class="s0">,</span>
                     <span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">batch=</span><span class="s0">None, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">res2 = bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic_1d</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False, </span><span class="s1">axis=axis</span><span class="s0">,</span>
                     <span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                     <span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res1.confidence_interval</span><span class="s0">, </span><span class="s1">res2.confidence_interval)</span>
    <span class="s1">assert_allclose(res1.standard_error</span><span class="s0">, </span><span class="s1">res2.standard_error)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;basic&quot;</span><span class="s0">, </span><span class="s2">&quot;percentile&quot;</span><span class="s0">, </span><span class="s2">&quot;BCa&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_degenerate(method):</span>
    <span class="s1">data = </span><span class="s3">35 </span><span class="s1">* [</span><span class="s3">10000.</span><span class="s1">]</span>
    <span class="s0">if </span><span class="s1">method == </span><span class="s2">&quot;BCa&quot;</span><span class="s1">:</span>
        <span class="s0">with </span><span class="s1">np.errstate(invalid=</span><span class="s2">'ignore'</span><span class="s1">):</span>
            <span class="s1">msg = </span><span class="s2">&quot;The BCa confidence interval cannot be calculated&quot;</span>
            <span class="s0">with </span><span class="s1">pytest.warns(stats.DegenerateDataWarning</span><span class="s0">, </span><span class="s1">match=msg):</span>
                <span class="s1">res = bootstrap([data</span><span class="s0">, </span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">method=method)</span>
                <span class="s1">assert_equal(res.confidence_interval</span><span class="s0">, </span><span class="s1">(np.nan</span><span class="s0">, </span><span class="s1">np.nan))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">res = bootstrap([data</span><span class="s0">, </span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">method=method)</span>
        <span class="s1">assert_equal(res.confidence_interval</span><span class="s0">, </span><span class="s1">(</span><span class="s3">10000.</span><span class="s0">, </span><span class="s3">10000.</span><span class="s1">))</span>
    <span class="s1">assert_equal(res.standard_error</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;basic&quot;</span><span class="s0">, </span><span class="s2">&quot;percentile&quot;</span><span class="s0">, </span><span class="s2">&quot;BCa&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_gh15678(method):</span>
    <span class="s4"># Check that gh-15678 is fixed: when statistic function returned a Python</span>
    <span class="s4"># float, method=&quot;BCa&quot; failed when trying to add a dimension to the float</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">354645618886684</span><span class="s1">)</span>
    <span class="s1">dist = stats.norm(loc=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">data = dist.rvs(size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">data = (data</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s1">res = bootstrap(data</span><span class="s0">, </span><span class="s1">stats.skew</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">,</span>
                    <span class="s1">random_state=np.random.default_rng(</span><span class="s3">9563</span><span class="s1">))</span>
    <span class="s4"># this always worked because np.apply_along_axis returns NumPy data type</span>
    <span class="s1">ref = bootstrap(data</span><span class="s0">, </span><span class="s1">stats.skew</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">,</span>
                    <span class="s1">random_state=np.random.default_rng(</span><span class="s3">9563</span><span class="s1">)</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval</span><span class="s0">, </span><span class="s1">ref.confidence_interval)</span>
    <span class="s1">assert_allclose(res.standard_error</span><span class="s0">, </span><span class="s1">ref.standard_error)</span>
    <span class="s0">assert </span><span class="s1">isinstance(res.standard_error</span><span class="s0">, </span><span class="s1">np.float64)</span>


<span class="s0">def </span><span class="s1">test_bootstrap_min():</span>
    <span class="s4"># Check that gh-15883 is fixed: percentileofscore should</span>
    <span class="s4"># behave according to the 'mean' behavior and not trigger nan for BCa</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">1891289180021102</span><span class="s1">)</span>
    <span class="s1">dist = stats.norm(loc=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">data = dist.rvs(size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">true_min = np.min(data)</span>
    <span class="s1">data = (data</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s1">res = bootstrap(data</span><span class="s0">, </span><span class="s1">np.min</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;BCa&quot;</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">,</span>
                    <span class="s1">random_state=np.random.default_rng(</span><span class="s3">3942</span><span class="s1">))</span>
    <span class="s0">assert </span><span class="s1">true_min == res.confidence_interval.low</span>
    <span class="s1">res2 = bootstrap(-np.array(data)</span><span class="s0">, </span><span class="s1">np.max</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;BCa&quot;</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">100</span><span class="s0">,</span>
                     <span class="s1">random_state=np.random.default_rng(</span><span class="s3">3942</span><span class="s1">))</span>
    <span class="s1">assert_allclose(-res.confidence_interval.low</span><span class="s0">,</span>
                    <span class="s1">res2.confidence_interval.high)</span>
    <span class="s1">assert_allclose(-res.confidence_interval.high</span><span class="s0">,</span>
                    <span class="s1">res2.confidence_interval.low)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;additional_resamples&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_re_bootstrap(additional_resamples):</span>
    <span class="s4"># Test behavior of parameter `bootstrap_result`</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">8958153316228384</span><span class="s1">)</span>
    <span class="s1">x = rng.random(size=</span><span class="s3">100</span><span class="s1">)</span>

    <span class="s1">n1 = </span><span class="s3">1000</span>
    <span class="s1">n2 = additional_resamples</span>
    <span class="s1">n3 = n1 + additional_resamples</span>

    <span class="s1">rng = np.random.default_rng(</span><span class="s3">296689032789913033</span><span class="s1">)</span>
    <span class="s1">res = stats.bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=n1</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">,</span>
                          <span class="s1">confidence_level=</span><span class="s3">0.95</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'percentile'</span><span class="s1">)</span>
    <span class="s1">res = stats.bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=n2</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">,</span>
                          <span class="s1">confidence_level=</span><span class="s3">0.90</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'BCa'</span><span class="s0">,</span>
                          <span class="s1">bootstrap_result=res)</span>

    <span class="s1">rng = np.random.default_rng(</span><span class="s3">296689032789913033</span><span class="s1">)</span>
    <span class="s1">ref = stats.bootstrap((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">, </span><span class="s1">n_resamples=n3</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">,</span>
                          <span class="s1">confidence_level=</span><span class="s3">0.90</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'BCa'</span><span class="s1">)</span>

    <span class="s1">assert_allclose(res.standard_error</span><span class="s0">, </span><span class="s1">ref.standard_error</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-14</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval</span><span class="s0">, </span><span class="s1">ref.confidence_interval</span><span class="s0">,</span>
                    <span class="s1">rtol=</span><span class="s3">1e-14</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">'basic'</span><span class="s0">, </span><span class="s2">'percentile'</span><span class="s0">, </span><span class="s2">'BCa'</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_alternative(method):</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">5894822712842015040</span><span class="s1">)</span>
    <span class="s1">dist = stats.norm(loc=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">data = (dist.rvs(size=(</span><span class="s3">100</span><span class="s1">)</span><span class="s0">, </span><span class="s1">random_state=rng)</span><span class="s0">,</span><span class="s1">)</span>

    <span class="s1">config = dict(data=data</span><span class="s0">, </span><span class="s1">statistic=np.std</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">t = stats.bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=</span><span class="s3">0.9</span><span class="s1">)</span>

    <span class="s1">config.update(dict(n_resamples=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">bootstrap_result=t))</span>
    <span class="s1">l = stats.bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=</span><span class="s3">0.95</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">)</span>
    <span class="s1">g = stats.bootstrap(**config</span><span class="s0">, </span><span class="s1">confidence_level=</span><span class="s3">0.95</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>

    <span class="s1">assert_equal(l.confidence_interval.high</span><span class="s0">, </span><span class="s1">t.confidence_interval.high)</span>
    <span class="s1">assert_equal(g.confidence_interval.low</span><span class="s0">, </span><span class="s1">t.confidence_interval.low)</span>
    <span class="s0">assert </span><span class="s1">np.isneginf(l.confidence_interval.low)</span>
    <span class="s0">assert </span><span class="s1">np.isposinf(g.confidence_interval.high)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s2">'`alternative` must be one of'</span><span class="s1">):</span>
        <span class="s1">stats.bootstrap(**config</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'ekki-ekki'</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_jackknife_resample():</span>
    <span class="s1">shape = </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(*shape)</span>
    <span class="s1">y = next(_resampling._jackknife_resample(x))</span>

    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(shape[-</span><span class="s3">1</span><span class="s1">]):</span>
        <span class="s4"># each resample is indexed along second to last axis</span>
        <span class="s4"># (last axis is the one the statistic will be taken over / consumed)</span>
        <span class="s1">slc = y[...</span><span class="s0">, </span><span class="s1">i</span><span class="s0">, </span><span class="s1">:]</span>
        <span class="s1">expected = np.delete(x</span><span class="s0">, </span><span class="s1">i</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>

        <span class="s0">assert </span><span class="s1">np.array_equal(slc</span><span class="s0">, </span><span class="s1">expected)</span>

    <span class="s1">y2 = np.concatenate(list(_resampling._jackknife_resample(x</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">2</span><span class="s1">))</span><span class="s0">,</span>
                        <span class="s1">axis=-</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.array_equal(y2</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;rng_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;RandomState&quot;</span><span class="s0">, </span><span class="s2">&quot;default_rng&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_bootstrap_resample(rng_name):</span>
    <span class="s1">rng = getattr(np.random</span><span class="s0">, </span><span class="s1">rng_name</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">rng </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">pytest.skip(</span><span class="s2">f&quot;</span><span class="s0">{</span><span class="s1">rng_name</span><span class="s0">} </span><span class="s2">not available.&quot;</span><span class="s1">)</span>
    <span class="s1">rng1 = rng(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">rng2 = rng(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">n_resamples = </span><span class="s3">10</span>
    <span class="s1">shape = </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span>

    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(*shape)</span>
    <span class="s1">y = _resampling._bootstrap_resample(x</span><span class="s0">, </span><span class="s1">n_resamples</span><span class="s0">, </span><span class="s1">random_state=rng1)</span>

    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n_resamples):</span>
        <span class="s4"># each resample is indexed along second to last axis</span>
        <span class="s4"># (last axis is the one the statistic will be taken over / consumed)</span>
        <span class="s1">slc = y[...</span><span class="s0">, </span><span class="s1">i</span><span class="s0">, </span><span class="s1">:]</span>

        <span class="s1">js = rng_integers(rng2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s1">shape[-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">shape[-</span><span class="s3">1</span><span class="s1">])</span>
        <span class="s1">expected = x[...</span><span class="s0">, </span><span class="s1">js]</span>

        <span class="s0">assert </span><span class="s1">np.array_equal(slc</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;score&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_percentile_of_score(score</span><span class="s0">, </span><span class="s1">axis):</span>
    <span class="s1">shape = </span><span class="s3">10</span><span class="s0">, </span><span class="s3">20</span><span class="s0">, </span><span class="s3">30</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(*shape)</span>
    <span class="s1">p = _resampling._percentile_of_score(x</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">vectorized_pos(a</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s0">return </span><span class="s1">np.apply_along_axis(stats.percentileofscore</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">score)</span>

    <span class="s1">p2 = vectorized_pos(x</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)/</span><span class="s3">100</span>

    <span class="s1">assert_allclose(p</span><span class="s0">, </span><span class="s1">p2</span><span class="s0">, </span><span class="s3">1e-15</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_percentile_along_axis():</span>
    <span class="s4"># the difference between _percentile_along_axis and np.percentile is that</span>
    <span class="s4"># np.percentile gets _all_ the qs for each axis slice, whereas</span>
    <span class="s4"># _percentile_along_axis gets the q corresponding with each axis slice</span>

    <span class="s1">shape = </span><span class="s3">10</span><span class="s0">, </span><span class="s3">20</span>
    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(*shape)</span>
    <span class="s1">q = np.random.rand(*shape[:-</span><span class="s3">1</span><span class="s1">]) * </span><span class="s3">100</span>
    <span class="s1">y = _resampling._percentile_along_axis(x</span><span class="s0">, </span><span class="s1">q)</span>

    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(shape[</span><span class="s3">0</span><span class="s1">]):</span>
        <span class="s1">res = y[i]</span>
        <span class="s1">expected = np.percentile(x[i]</span><span class="s0">, </span><span class="s1">q[i]</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s3">1e-15</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;axis&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_vectorize_statistic(axis):</span>
    <span class="s4"># test that _vectorize_statistic vectorizes a statistic along `axis`</span>

    <span class="s0">def </span><span class="s1">statistic(*data</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s4"># an arbitrary, vectorized statistic</span>
        <span class="s0">return </span><span class="s1">sum(sample.mean(axis) </span><span class="s0">for </span><span class="s1">sample </span><span class="s0">in </span><span class="s1">data)</span>

    <span class="s0">def </span><span class="s1">statistic_1d(*data):</span>
        <span class="s4"># the same statistic, not vectorized</span>
        <span class="s0">for </span><span class="s1">sample </span><span class="s0">in </span><span class="s1">data:</span>
            <span class="s0">assert </span><span class="s1">sample.ndim == </span><span class="s3">1</span>
        <span class="s0">return </span><span class="s1">statistic(*data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s4"># vectorize the non-vectorized statistic</span>
    <span class="s1">statistic2 = _resampling._vectorize_statistic(statistic_1d)</span>

    <span class="s1">np.random.seed(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">x = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">)</span>
    <span class="s1">y = np.random.rand(</span><span class="s3">4</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">6</span><span class="s1">)</span>
    <span class="s1">z = np.random.rand(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s1">)</span>

    <span class="s1">res1 = statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z</span><span class="s0">, </span><span class="s1">axis=axis)</span>
    <span class="s1">res2 = statistic2(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z</span><span class="s0">, </span><span class="s1">axis=axis)</span>
    <span class="s1">assert_allclose(res1</span><span class="s0">, </span><span class="s1">res2)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;basic&quot;</span><span class="s0">, </span><span class="s2">&quot;percentile&quot;</span><span class="s0">, </span><span class="s2">&quot;BCa&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_vector_valued_statistic(method):</span>
    <span class="s4"># Generate 95% confidence interval around MLE of normal distribution</span>
    <span class="s4"># parameters. Repeat 100 times, each time on sample of size 100.</span>
    <span class="s4"># Check that confidence interval contains true parameters ~95 times.</span>
    <span class="s4"># Confidence intervals are estimated and stochastic; a test failure</span>
    <span class="s4"># does not necessarily indicate that something is wrong. More important</span>
    <span class="s4"># than values of `counts` below is that the shapes of the outputs are</span>
    <span class="s4"># correct.</span>

    <span class="s1">rng = np.random.default_rng(</span><span class="s3">2196847219</span><span class="s1">)</span>
    <span class="s1">params = </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.5</span>
    <span class="s1">sample = stats.norm.rvs(*params</span><span class="s0">, </span><span class="s1">size=(</span><span class="s3">100</span><span class="s0">, </span><span class="s3">100</span><span class="s1">)</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s0">def </span><span class="s1">statistic(data</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s0">return </span><span class="s1">np.asarray([np.mean(data</span><span class="s0">, </span><span class="s1">axis)</span><span class="s0">,</span>
                           <span class="s1">np.std(data</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)])</span>

    <span class="s1">res = bootstrap((sample</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s0">,</span>
                    <span class="s1">n_resamples=</span><span class="s3">9999</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">200</span><span class="s1">)</span>

    <span class="s1">counts = np.sum((res.confidence_interval.low.T &lt; params)</span>
                    <span class="s1">&amp; (res.confidence_interval.high.T &gt; params)</span><span class="s0">,</span>
                    <span class="s1">axis=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.all(counts &gt;= </span><span class="s3">90</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">np.all(counts &lt;= </span><span class="s3">100</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">res.confidence_interval.low.shape == (</span><span class="s3">2</span><span class="s0">, </span><span class="s3">100</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">res.confidence_interval.high.shape == (</span><span class="s3">2</span><span class="s0">, </span><span class="s3">100</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">res.standard_error.shape == (</span><span class="s3">2</span><span class="s0">, </span><span class="s3">100</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">res.bootstrap_distribution.shape == (</span><span class="s3">2</span><span class="s0">, </span><span class="s3">100</span><span class="s0">, </span><span class="s3">9999</span><span class="s1">)</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s1">@pytest.mark.filterwarnings(</span><span class="s2">'ignore::RuntimeWarning'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_vector_valued_statistic_gh17715():</span>
    <span class="s4"># gh-17715 reported a mistake introduced in the extension of BCa to</span>
    <span class="s4"># multi-sample statistics; a `len` should have been `.shape[-1]`. Check</span>
    <span class="s4"># that this is resolved.</span>

    <span class="s1">rng = np.random.default_rng(</span><span class="s3">141921000979291141</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">concordance(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s1">xm = x.mean(axis)</span>
        <span class="s1">ym = y.mean(axis)</span>
        <span class="s1">cov = ((x - xm[...</span><span class="s0">, None</span><span class="s1">]) * (y - ym[...</span><span class="s0">, None</span><span class="s1">])).mean(axis)</span>
        <span class="s0">return </span><span class="s1">(</span><span class="s3">2 </span><span class="s1">* cov) / (x.var(axis) + y.var(axis) + (xm - ym) ** </span><span class="s3">2</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">statistic(tp</span><span class="s0">, </span><span class="s1">tn</span><span class="s0">, </span><span class="s1">fp</span><span class="s0">, </span><span class="s1">fn</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s1">actual = tp + fp</span>
        <span class="s1">expected = tp + fn</span>
        <span class="s0">return </span><span class="s1">np.nan_to_num(concordance(actual</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s1">axis))</span>

    <span class="s0">def </span><span class="s1">statistic_extradim(*args</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s0">return </span><span class="s1">statistic(*args</span><span class="s0">, </span><span class="s1">axis)[np.newaxis</span><span class="s0">, </span><span class="s1">...]</span>

    <span class="s1">data = [[</span><span class="s3">4</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># (tp, tn, fp, fn)</span>
            <span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]]</span>
    <span class="s1">data = np.array(data).T</span>

    <span class="s1">res = bootstrap(data</span><span class="s0">, </span><span class="s1">statistic_extradim</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">, </span><span class="s1">paired=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">ref = bootstrap(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">random_state=rng</span><span class="s0">, </span><span class="s1">paired=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval.low[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">ref.confidence_interval.low</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-15</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.confidence_interval.high[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">ref.confidence_interval.high</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-15</span><span class="s1">)</span>


<span class="s4"># --- Test Monte Carlo Hypothesis Test --- #</span>

<span class="s0">class </span><span class="s1">TestMonteCarloHypothesisTest:</span>
    <span class="s1">atol = </span><span class="s3">2.5e-2  </span><span class="s4"># for comparing p-value</span>

    <span class="s0">def </span><span class="s1">rvs(self</span><span class="s0">, </span><span class="s1">rvs_in</span><span class="s0">, </span><span class="s1">rs):</span>
        <span class="s0">return lambda </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds: rvs_in(*args</span><span class="s0">, </span><span class="s1">random_state=rs</span><span class="s0">, </span><span class="s1">**kwds)</span>

    <span class="s0">def </span><span class="s1">test_input_validation(self):</span>
        <span class="s4"># test that the appropriate error messages are raised for invalid input</span>

        <span class="s0">def </span><span class="s1">stat(x):</span>
            <span class="s0">return </span><span class="s1">stats.skewnorm(x).statistic</span>

        <span class="s1">message = </span><span class="s2">&quot;Array shapes are incompatible for broadcasting.&quot;</span>
        <span class="s1">data = (np.zeros((</span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s1">))</span><span class="s0">, </span><span class="s1">np.zeros((</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)))</span>
        <span class="s1">rvs = (stats.norm.rvs</span><span class="s0">, </span><span class="s1">stats.norm.rvs)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test(data</span><span class="s0">, </span><span class="s1">rvs</span><span class="s0">, lambda </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y: </span><span class="s3">1</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`axis` must be an integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`vectorized` must be `True`, `False`, or `None`.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s3">1.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`rvs` must be callable or sequence of callables.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, None, </span><span class="s1">stat)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s0">lambda </span><span class="s1">x: x</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stat)</span>

        <span class="s1">message = </span><span class="s2">&quot;If `rvs` is a sequence...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">[</span><span class="s0">lambda </span><span class="s1">x: x</span><span class="s0">, lambda </span><span class="s1">x: x]</span><span class="s0">, </span><span class="s1">stat)</span>

        <span class="s1">message = </span><span class="s2">&quot;`statistic` must be callable.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, None</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a positive integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">,</span>
                             <span class="s1">n_resamples=-</span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a positive integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">,</span>
                             <span class="s1">n_resamples=</span><span class="s3">1000.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">batch=-</span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">1000.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`alternative` must be in...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">monte_carlo_test([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">stats.norm.rvs</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">,</span>
                             <span class="s1">alternative=</span><span class="s2">'ekki'</span><span class="s1">)</span>


    <span class="s0">def </span><span class="s1">test_batch(self):</span>
        <span class="s4"># make sure that the `batch` parameter is respected by checking the</span>
        <span class="s4"># maximum batch size provided in calls to `statistic`</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">23492340193</span><span class="s1">)</span>
        <span class="s1">x = rng.random(</span><span class="s3">10</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s1">batch_size = </span><span class="s3">1 </span><span class="s0">if </span><span class="s1">x.ndim == </span><span class="s3">1 </span><span class="s0">else </span><span class="s1">len(x)</span>
            <span class="s1">statistic.batch_size = max(batch_size</span><span class="s0">, </span><span class="s1">statistic.batch_size)</span>
            <span class="s1">statistic.counter += </span><span class="s3">1</span>
            <span class="s0">return </span><span class="s1">stats.skewtest(x</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>
        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">statistic.batch_size = </span><span class="s3">0</span>

        <span class="s1">kwds = {</span><span class="s2">'sample'</span><span class="s1">: x</span><span class="s0">, </span><span class="s2">'statistic'</span><span class="s1">: statistic</span><span class="s0">,</span>
                <span class="s2">'n_resamples'</span><span class="s1">: </span><span class="s3">1000</span><span class="s0">, </span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True</span><span class="s1">}</span>

        <span class="s1">kwds[</span><span class="s2">'rvs'</span><span class="s1">] = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">np.random.default_rng(</span><span class="s3">32842398</span><span class="s1">))</span>
        <span class="s1">res1 = monte_carlo_test(batch=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">1001</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">kwds[</span><span class="s2">'rvs'</span><span class="s1">] = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">np.random.default_rng(</span><span class="s3">32842398</span><span class="s1">))</span>
        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">res2 = monte_carlo_test(batch=</span><span class="s3">50</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">21</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">50</span><span class="s1">)</span>

        <span class="s1">kwds[</span><span class="s2">'rvs'</span><span class="s1">] = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">np.random.default_rng(</span><span class="s3">32842398</span><span class="s1">))</span>
        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">res3 = monte_carlo_test(**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">assert_equal(res1.pvalue</span><span class="s0">, </span><span class="s1">res3.pvalue)</span>
        <span class="s1">assert_equal(res2.pvalue</span><span class="s0">, </span><span class="s1">res3.pvalue)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'axis'</span><span class="s0">, </span><span class="s1">range(-</span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_axis(self</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s4"># test that Nd-array samples are handled correctly for valid values</span>
        <span class="s4"># of the `axis` parameter</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">2389234</span><span class="s1">)</span>
        <span class="s1">norm_rvs = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">rng)</span>

        <span class="s1">size = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span>
        <span class="s1">size[axis] = </span><span class="s3">100</span>
        <span class="s1">x = norm_rvs(size=size)</span>
        <span class="s1">expected = stats.skewtest(x</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.skewtest(x</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">norm_rvs</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                               <span class="s1">n_resamples=</span><span class="s3">20000</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s1">))</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'a'</span><span class="s0">, </span><span class="s1">np.linspace(-</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">))  </span><span class="s4"># skewness</span>
    <span class="s0">def </span><span class="s1">test_against_ks_1samp(self</span><span class="s0">, </span><span class="s1">alternative</span><span class="s0">, </span><span class="s1">a):</span>
        <span class="s4"># test that monte_carlo_test can reproduce pvalue of ks_1samp</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">65723433</span><span class="s1">)</span>

        <span class="s1">x = stats.skewnorm.rvs(a=a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">30</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">expected = stats.ks_1samp(x</span><span class="s0">, </span><span class="s1">stats.norm.cdf</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.ks_1samp(x</span><span class="s0">, </span><span class="s1">stats.norm.cdf</span><span class="s0">, </span><span class="s1">mode=</span><span class="s2">'asymp'</span><span class="s0">,</span>
                                  <span class="s1">alternative=alternative).statistic</span>

        <span class="s1">norm_rvs = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">rng)</span>
        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">norm_rvs</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">,</span>
                               <span class="s1">n_resamples=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False,</span>
                               <span class="s1">alternative=alternative)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic)</span>
        <span class="s0">if </span><span class="s1">alternative == </span><span class="s2">'greater'</span><span class="s1">:</span>
            <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>
        <span class="s0">elif </span><span class="s1">alternative == </span><span class="s2">'less'</span><span class="s1">:</span>
            <span class="s1">assert_allclose(</span><span class="s3">1</span><span class="s1">-res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'hypotest'</span><span class="s0">, </span><span class="s1">(stats.skewtest</span><span class="s0">, </span><span class="s1">stats.kurtosistest))</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'a'</span><span class="s0">, </span><span class="s1">np.linspace(-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s1">))  </span><span class="s4"># skewness</span>
    <span class="s0">def </span><span class="s1">test_against_normality_tests(self</span><span class="s0">, </span><span class="s1">hypotest</span><span class="s0">, </span><span class="s1">alternative</span><span class="s0">, </span><span class="s1">a):</span>
        <span class="s4"># test that monte_carlo_test can reproduce pvalue of normality tests</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">85723405</span><span class="s1">)</span>

        <span class="s1">x = stats.skewnorm.rvs(a=a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">150</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">expected = hypotest(x</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">hypotest(x</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">norm_rvs = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">rng)</span>
        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">norm_rvs</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                               <span class="s1">alternative=alternative)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'a'</span><span class="s0">, </span><span class="s1">np.arange(-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))  </span><span class="s4"># skewness parameter</span>
    <span class="s0">def </span><span class="s1">test_against_normaltest(self</span><span class="s0">, </span><span class="s1">a):</span>
        <span class="s4"># test that monte_carlo_test can reproduce pvalue of normaltest</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">12340513</span><span class="s1">)</span>

        <span class="s1">x = stats.skewnorm.rvs(a=a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">150</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">expected = stats.normaltest(x)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.normaltest(x</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">norm_rvs = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">rng)</span>
        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">norm_rvs</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                               <span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'a'</span><span class="s0">, </span><span class="s1">np.linspace(-</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">))  </span><span class="s4"># skewness</span>
    <span class="s0">def </span><span class="s1">test_against_cramervonmises(self</span><span class="s0">, </span><span class="s1">a):</span>
        <span class="s4"># test that monte_carlo_test can reproduce pvalue of cramervonmises</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">234874135</span><span class="s1">)</span>

        <span class="s1">x = stats.skewnorm.rvs(a=a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">30</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">expected = stats.cramervonmises(x</span><span class="s0">, </span><span class="s1">stats.norm.cdf)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.cramervonmises(x</span><span class="s0">, </span><span class="s1">stats.norm.cdf).statistic</span>

        <span class="s1">norm_rvs = self.rvs(stats.norm.rvs</span><span class="s0">, </span><span class="s1">rng)</span>
        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">norm_rvs</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">,</span>
                               <span class="s1">n_resamples=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False,</span>
                               <span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">atol=self.atol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'dist_name'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">'norm'</span><span class="s0">, </span><span class="s2">'logistic'</span><span class="s1">))</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'i'</span><span class="s0">, </span><span class="s1">range(</span><span class="s3">5</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_anderson(self</span><span class="s0">, </span><span class="s1">dist_name</span><span class="s0">, </span><span class="s1">i):</span>
        <span class="s4"># test that monte_carlo_test can reproduce results of `anderson`. Note:</span>
        <span class="s4"># `anderson` does not provide a p-value; it provides a list of</span>
        <span class="s4"># significance levels and the associated critical value of the test</span>
        <span class="s4"># statistic. `i` used to index this list.</span>

        <span class="s4"># find the skewness for which the sample statistic matches one of the</span>
        <span class="s4"># critical values provided by `stats.anderson`</span>

        <span class="s0">def </span><span class="s1">fun(a):</span>
            <span class="s1">rng = np.random.default_rng(</span><span class="s3">394295467</span><span class="s1">)</span>
            <span class="s1">x = stats.tukeylambda.rvs(a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
            <span class="s1">expected = stats.anderson(x</span><span class="s0">, </span><span class="s1">dist_name)</span>
            <span class="s0">return </span><span class="s1">expected.statistic - expected.critical_values[i]</span>
        <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(RuntimeWarning)</span>
            <span class="s1">sol = root(fun</span><span class="s0">, </span><span class="s1">x0=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">sol.success</span>

        <span class="s4"># get the significance level (p-value) associated with that critical</span>
        <span class="s4"># value</span>
        <span class="s1">a = sol.x[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">394295467</span><span class="s1">)</span>
        <span class="s1">x = stats.tukeylambda.rvs(a</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">expected = stats.anderson(x</span><span class="s0">, </span><span class="s1">dist_name)</span>
        <span class="s1">expected_stat = expected.statistic</span>
        <span class="s1">expected_p = expected.significance_level[i]/</span><span class="s3">100</span>

        <span class="s4"># perform equivalent Monte Carlo test and compare results</span>
        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.anderson(x</span><span class="s0">, </span><span class="s1">dist_name).statistic</span>

        <span class="s1">dist_rvs = self.rvs(getattr(stats</span><span class="s0">, </span><span class="s1">dist_name).rvs</span><span class="s0">, </span><span class="s1">rng)</span>
        <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(RuntimeWarning)</span>
            <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">dist_rvs</span><span class="s0">,</span>
                                   <span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">1000</span><span class="s0">,</span>
                                   <span class="s1">vectorized=</span><span class="s0">False, </span><span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected_stat)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected_p</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">2</span><span class="s1">*self.atol)</span>

    <span class="s0">def </span><span class="s1">test_p_never_zero(self):</span>
        <span class="s4"># Use biased estimate of p-value to ensure that p-value is never zero</span>
        <span class="s4"># per monte_carlo_test reference [1]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">2190176673029737545</span><span class="s1">)</span>
        <span class="s1">x = np.zeros(</span><span class="s3">100</span><span class="s1">)</span>
        <span class="s1">res = monte_carlo_test(x</span><span class="s0">, </span><span class="s1">rng.random</span><span class="s0">, </span><span class="s1">np.mean</span><span class="s0">,</span>
                               <span class="s1">vectorized=</span><span class="s0">True, </span><span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">res.pvalue == </span><span class="s3">0.0001</span>

    <span class="s0">def </span><span class="s1">test_against_ttest_ind(self):</span>
        <span class="s4"># test that `monte_carlo_test` can reproduce results of `ttest_ind`.</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">219017667302737545</span><span class="s1">)</span>
        <span class="s1">data = rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s1">))</span><span class="s0">, </span><span class="s1">rng.random(size=</span><span class="s3">7</span><span class="s1">)  </span><span class="s4"># broadcastable</span>
        <span class="s1">rvs = rng.normal</span><span class="s0">, </span><span class="s1">rng.normal</span>
        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.ttest_ind(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis).statistic</span>

        <span class="s1">res = stats.monte_carlo_test(data</span><span class="s0">, </span><span class="s1">rvs</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">ref = stats.ttest_ind(data[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[data[</span><span class="s3">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref.pvalue</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">2e-2</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_f_oneway(self):</span>
        <span class="s4"># test that `monte_carlo_test` can reproduce results of `f_oneway`.</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">219017667302737545</span><span class="s1">)</span>
        <span class="s1">data = (rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">100</span><span class="s1">))</span><span class="s0">, </span><span class="s1">rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">101</span><span class="s1">))</span><span class="s0">,</span>
                <span class="s1">rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">102</span><span class="s1">))</span><span class="s0">, </span><span class="s1">rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">103</span><span class="s1">)))</span>
        <span class="s1">rvs = rng.normal</span><span class="s0">, </span><span class="s1">rng.normal</span><span class="s0">, </span><span class="s1">rng.normal</span><span class="s0">, </span><span class="s1">rng.normal</span>

        <span class="s0">def </span><span class="s1">statistic(*args</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.f_oneway(*args</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">res = stats.monte_carlo_test(data</span><span class="s0">, </span><span class="s1">rvs</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s0">,</span>
                                     <span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s1">)</span>
        <span class="s1">ref = stats.f_oneway(*data</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-2</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">TestPermutationTest:</span>

    <span class="s1">rtol = </span><span class="s3">1e-14</span>

    <span class="s0">def </span><span class="s1">setup_method(self):</span>
        <span class="s1">self.rng = np.random.default_rng(</span><span class="s3">7170559330470561044</span><span class="s1">)</span>

    <span class="s4"># -- Input validation -- #</span>

    <span class="s0">def </span><span class="s1">test_permutation_test_iv(self):</span>

        <span class="s0">def </span><span class="s1">stat(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.ttest_ind((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">axis).statistic</span>

        <span class="s1">message = </span><span class="s2">&quot;each sample in `data` must contain two or more ...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat)</span>

        <span class="s1">message = </span><span class="s2">&quot;`data` must be a tuple containing at least two samples&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test((</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">stat)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">stat)</span>

        <span class="s1">message = </span><span class="s2">&quot;`axis` must be an integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`permutation_type` must be in...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">,</span>
                             <span class="s1">permutation_type=</span><span class="s2">&quot;ekki&quot;</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`vectorized` must be `True`, `False`, or `None`.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s3">1.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a positive integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">n_resamples=-</span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`n_resamples` must be a positive integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">1000.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">batch=-</span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`batch` must be a positive integer or None.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">1000.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;`alternative` must be in...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'ekki'</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s2">&quot;'herring' cannot be used to seed a&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">permutation_test(([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span><span class="s0">, </span><span class="s1">stat</span><span class="s0">,</span>
                             <span class="s1">random_state=</span><span class="s2">'herring'</span><span class="s1">)</span>

    <span class="s4"># -- Test Parameters -- #</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'random_state'</span><span class="s0">, </span><span class="s1">[np.random.RandomState</span><span class="s0">,</span>
                                              <span class="s1">np.random.default_rng])</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'permutation_type'</span><span class="s0">,</span>
                             <span class="s1">[</span><span class="s2">'pairings'</span><span class="s0">, </span><span class="s2">'samples'</span><span class="s0">, </span><span class="s2">'independent'</span><span class="s1">])</span>
    <span class="s0">def </span><span class="s1">test_batch(self</span><span class="s0">, </span><span class="s1">permutation_type</span><span class="s0">, </span><span class="s1">random_state):</span>
        <span class="s4"># make sure that the `batch` parameter is respected by checking the</span>
        <span class="s4"># maximum batch size provided in calls to `statistic`</span>
        <span class="s1">x = self.rng.random(</span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">y = self.rng.random(</span><span class="s3">10</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s1">batch_size = </span><span class="s3">1 </span><span class="s0">if </span><span class="s1">x.ndim == </span><span class="s3">1 </span><span class="s0">else </span><span class="s1">len(x)</span>
            <span class="s1">statistic.batch_size = max(batch_size</span><span class="s0">, </span><span class="s1">statistic.batch_size)</span>
            <span class="s1">statistic.counter += </span><span class="s3">1</span>
            <span class="s0">return </span><span class="s1">np.mean(x</span><span class="s0">, </span><span class="s1">axis=axis) - np.mean(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">statistic.batch_size = </span><span class="s3">0</span>

        <span class="s1">kwds = {</span><span class="s2">'n_resamples'</span><span class="s1">: </span><span class="s3">1000</span><span class="s0">, </span><span class="s2">'permutation_type'</span><span class="s1">: permutation_type</span><span class="s0">,</span>
                <span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True</span><span class="s1">}</span>
        <span class="s1">res1 = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">1</span><span class="s0">,</span>
                                      <span class="s1">random_state=random_state(</span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">1001</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">res2 = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">50</span><span class="s0">,</span>
                                      <span class="s1">random_state=random_state(</span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">21</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">50</span><span class="s1">)</span>

        <span class="s1">statistic.counter = </span><span class="s3">0</span>
        <span class="s1">res3 = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">batch=</span><span class="s3">1000</span><span class="s0">,</span>
                                      <span class="s1">random_state=random_state(</span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(statistic.counter</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">assert_equal(statistic.batch_size</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">)</span>

        <span class="s1">assert_equal(res1.pvalue</span><span class="s0">, </span><span class="s1">res3.pvalue)</span>
        <span class="s1">assert_equal(res2.pvalue</span><span class="s0">, </span><span class="s1">res3.pvalue)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'random_state'</span><span class="s0">, </span><span class="s1">[np.random.RandomState</span><span class="s0">,</span>
                                              <span class="s1">np.random.default_rng])</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'permutation_type, exact_size'</span><span class="s0">,</span>
                             <span class="s1">[(</span><span class="s2">'pairings'</span><span class="s0">, </span><span class="s1">special.factorial(</span><span class="s3">3</span><span class="s1">)**</span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
                              <span class="s1">(</span><span class="s2">'samples'</span><span class="s0">, </span><span class="s3">2</span><span class="s1">**</span><span class="s3">3</span><span class="s1">)</span><span class="s0">,</span>
                              <span class="s1">(</span><span class="s2">'independent'</span><span class="s0">, </span><span class="s1">special.binom(</span><span class="s3">6</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))])</span>
    <span class="s0">def </span><span class="s1">test_permutations(self</span><span class="s0">, </span><span class="s1">permutation_type</span><span class="s0">, </span><span class="s1">exact_size</span><span class="s0">, </span><span class="s1">random_state):</span>
        <span class="s4"># make sure that the `permutations` parameter is respected by checking</span>
        <span class="s4"># the size of the null distribution</span>
        <span class="s1">x = self.rng.random(</span><span class="s3">3</span><span class="s1">)</span>
        <span class="s1">y = self.rng.random(</span><span class="s3">3</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">np.mean(x</span><span class="s0">, </span><span class="s1">axis=axis) - np.mean(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s1">kwds = {</span><span class="s2">'permutation_type'</span><span class="s1">: permutation_type</span><span class="s0">,</span>
                <span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True</span><span class="s1">}</span>
        <span class="s1">res = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">3</span><span class="s0">,</span>
                                     <span class="s1">random_state=random_state(</span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(res.null_distribution.size</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>

        <span class="s1">res = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">assert_equal(res.null_distribution.size</span><span class="s0">, </span><span class="s1">exact_size)</span>

    <span class="s4"># -- Randomized Permutation Tests -- #</span>

    <span class="s4"># To get reasonable accuracy, these next three tests are somewhat slow.</span>
    <span class="s4"># Originally, I had them passing for all combinations of permutation type,</span>
    <span class="s4"># alternative, and RNG, but that takes too long for CI. Instead, split</span>
    <span class="s4"># into three tests, each testing a particular combination of the three</span>
    <span class="s4"># parameters.</span>

    <span class="s0">def </span><span class="s1">test_randomized_test_against_exact_both(self):</span>
        <span class="s4"># check that the randomized and exact tests agree to reasonable</span>
        <span class="s4"># precision for permutation_type='both</span>

        <span class="s1">alternative</span><span class="s0">, </span><span class="s1">rng = </span><span class="s2">'less'</span><span class="s0">, </span><span class="s3">0</span>

        <span class="s1">nx</span><span class="s0">, </span><span class="s1">ny</span><span class="s0">, </span><span class="s1">permutations = </span><span class="s3">8</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">24000</span>
        <span class="s0">assert </span><span class="s1">special.binom(nx + ny</span><span class="s0">, </span><span class="s1">nx) &gt; permutations</span>

        <span class="s1">x = stats.norm.rvs(size=nx)</span>
        <span class="s1">y = stats.norm.rvs(size=ny)</span>
        <span class="s1">data = x</span><span class="s0">, </span><span class="s1">y</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">np.mean(x</span><span class="s0">, </span><span class="s1">axis=axis) - np.mean(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True, </span><span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'independent'</span><span class="s0">,</span>
                <span class="s2">'batch'</span><span class="s1">: </span><span class="s3">100</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: alternative</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: rng}</span>
        <span class="s1">res = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=permutations</span><span class="s0">,</span>
                               <span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s0">assert </span><span class="s1">res.statistic == res2.statistic</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-2</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.slow()</span>
    <span class="s0">def </span><span class="s1">test_randomized_test_against_exact_samples(self):</span>
        <span class="s4"># check that the randomized and exact tests agree to reasonable</span>
        <span class="s4"># precision for permutation_type='samples'</span>

        <span class="s1">alternative</span><span class="s0">, </span><span class="s1">rng = </span><span class="s2">'greater'</span><span class="s0">, None</span>

        <span class="s1">nx</span><span class="s0">, </span><span class="s1">ny</span><span class="s0">, </span><span class="s1">permutations = </span><span class="s3">15</span><span class="s0">, </span><span class="s3">15</span><span class="s0">, </span><span class="s3">32000</span>
        <span class="s0">assert </span><span class="s3">2</span><span class="s1">**nx &gt; permutations</span>

        <span class="s1">x = stats.norm.rvs(size=nx)</span>
        <span class="s1">y = stats.norm.rvs(size=ny)</span>
        <span class="s1">data = x</span><span class="s0">, </span><span class="s1">y</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">np.mean(x - y</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True, </span><span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'samples'</span><span class="s0">,</span>
                <span class="s2">'batch'</span><span class="s1">: </span><span class="s3">100</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: alternative</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: rng}</span>
        <span class="s1">res = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=permutations</span><span class="s0">,</span>
                               <span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s0">assert </span><span class="s1">res.statistic == res2.statistic</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-2</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_randomized_test_against_exact_pairings(self):</span>
        <span class="s4"># check that the randomized and exact tests agree to reasonable</span>
        <span class="s4"># precision for permutation_type='pairings'</span>

        <span class="s1">alternative</span><span class="s0">, </span><span class="s1">rng = </span><span class="s2">'two-sided'</span><span class="s0">, </span><span class="s1">self.rng</span>

        <span class="s1">nx</span><span class="s0">, </span><span class="s1">ny</span><span class="s0">, </span><span class="s1">permutations = </span><span class="s3">8</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">40000</span>
        <span class="s0">assert </span><span class="s1">special.factorial(nx) &gt; permutations</span>

        <span class="s1">x = stats.norm.rvs(size=nx)</span>
        <span class="s1">y = stats.norm.rvs(size=ny)</span>
        <span class="s1">data = [x]</span>

        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.pearsonr(x</span><span class="s0">, </span><span class="s1">y)[</span><span class="s3">0</span><span class="s1">]</span>

        <span class="s1">statistic = _resampling._vectorize_statistic(statistic1d)</span>

        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">True, </span><span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'samples'</span><span class="s0">,</span>
                <span class="s2">'batch'</span><span class="s1">: </span><span class="s3">100</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: alternative</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: rng}</span>
        <span class="s1">res = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=permutations</span><span class="s0">,</span>
                               <span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s0">assert </span><span class="s1">res.statistic == res2.statistic</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-2</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">'less'</span><span class="s0">, </span><span class="s2">'greater'</span><span class="s1">))</span>
    <span class="s4"># Different conventions for two-sided p-value here VS ttest_ind.</span>
    <span class="s4"># Eventually, we can add multiple options for the two-sided alternative</span>
    <span class="s4"># here in permutation_test.</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'permutations'</span><span class="s0">, </span><span class="s1">(</span><span class="s3">30</span><span class="s0">, </span><span class="s3">1e9</span><span class="s1">))</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'axis'</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_permutation_ttest(self</span><span class="s0">, </span><span class="s1">alternative</span><span class="s0">, </span><span class="s1">permutations</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s4"># check that this function and ttest_ind with permutations give</span>
        <span class="s4"># essentially identical results.</span>

        <span class="s1">x = np.arange(</span><span class="s3">3</span><span class="s1">*</span><span class="s3">4</span><span class="s1">*</span><span class="s3">5</span><span class="s1">).reshape(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
        <span class="s1">y = np.moveaxis(np.arange(</span><span class="s3">4</span><span class="s1">)[:</span><span class="s0">, None, None</span><span class="s1">]</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis)</span>

        <span class="s1">rng1 = np.random.default_rng(</span><span class="s3">4337234444626115331</span><span class="s1">)</span>
        <span class="s1">res1 = stats.ttest_ind(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">permutations=permutations</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">,</span>
                               <span class="s1">random_state=rng1</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.ttest_ind(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">rng2 = np.random.default_rng(</span><span class="s3">4337234444626115331</span><span class="s1">)</span>
        <span class="s1">res2 = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                                <span class="s1">n_resamples=permutations</span><span class="s0">,</span>
                                <span class="s1">alternative=alternative</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">,</span>
                                <span class="s1">random_state=rng2)</span>

        <span class="s1">assert_allclose(res1.statistic</span><span class="s0">, </span><span class="s1">res2.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res1.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s4"># -- Independent (Unpaired) Sample Tests -- #</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_ks_2samp(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s1">x = self.rng.normal(size=</span><span class="s3">4</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">y = self.rng.normal(size=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">3</span><span class="s1">)</span>

        <span class="s1">expected = stats.ks_2samp(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">alternative=alternative</span><span class="s0">, </span><span class="s1">mode=</span><span class="s2">'exact'</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.ks_2samp(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">mode=</span><span class="s2">'asymp'</span><span class="s0">,</span>
                                  <span class="s1">alternative=alternative).statistic</span>

        <span class="s4"># ks_2samp is always a one-tailed 'greater' test</span>
        <span class="s4"># it's the statistic that changes (D+ vs D- vs max(D+, D-))</span>
        <span class="s1">res = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">,</span>
                               <span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_ansari(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s1">x = self.rng.normal(size=</span><span class="s3">4</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">y = self.rng.normal(size=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">3</span><span class="s1">)</span>

        <span class="s4"># ansari has a different convention for 'alternative'</span>
        <span class="s1">alternative_correspondence = {</span><span class="s2">&quot;less&quot;</span><span class="s1">: </span><span class="s2">&quot;greater&quot;</span><span class="s0">,</span>
                                      <span class="s2">&quot;greater&quot;</span><span class="s1">: </span><span class="s2">&quot;less&quot;</span><span class="s0">,</span>
                                      <span class="s2">&quot;two-sided&quot;</span><span class="s1">: </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">}</span>
        <span class="s1">alternative_scipy = alternative_correspondence[alternative]</span>
        <span class="s1">expected = stats.ansari(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">alternative=alternative_scipy)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.ansari(x</span><span class="s0">, </span><span class="s1">y).statistic</span>

        <span class="s1">res = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">,</span>
                               <span class="s1">alternative=alternative</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_mannwhitneyu(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s1">x = stats.uniform.rvs(size=(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>
        <span class="s1">y = stats.uniform.rvs(size=(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">0.05</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">expected = stats.mannwhitneyu(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis):</span>
            <span class="s0">return </span><span class="s1">stats.mannwhitneyu(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=axis).statistic</span>

        <span class="s1">res = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                               <span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">alternative=alternative</span><span class="s0">,</span>
                               <span class="s1">axis=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s0">def </span><span class="s1">test_against_cvm(self):</span>

        <span class="s1">x = stats.norm.rvs(size=</span><span class="s3">4</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>
        <span class="s1">y = stats.norm.rvs(size=</span><span class="s3">5</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">expected = stats.cramervonmises_2samp(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'exact'</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.cramervonmises_2samp(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">,</span>
                                              <span class="s1">method=</span><span class="s2">'asymptotic'</span><span class="s1">).statistic</span>

        <span class="s4"># cramervonmises_2samp has only one alternative, greater</span>
        <span class="s1">res = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">,</span>
                               <span class="s1">alternative=</span><span class="s2">'greater'</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s1">@pytest.mark.xslow()</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'axis'</span><span class="s0">, </span><span class="s1">(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_vectorized_nsamp_ptype_both(self</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s4"># Test that permutation_test with permutation_type='independent' works</span>
        <span class="s4"># properly for a 3-sample statistic with nd array samples of different</span>
        <span class="s4"># (but compatible) shapes and ndims. Show that exact permutation test</span>
        <span class="s4"># and random permutation tests approximate SciPy's asymptotic pvalues</span>
        <span class="s4"># and that exact and random permutation test results are even closer</span>
        <span class="s4"># to one another (than they are to the asymptotic results).</span>

        <span class="s4"># Three samples, different (but compatible) shapes with different ndims</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">6709265303529651545</span><span class="s1">)</span>
        <span class="s1">x = rng.random(size=(</span><span class="s3">3</span><span class="s1">))</span>
        <span class="s1">y = rng.random(size=(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))</span>
        <span class="s1">z = rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>
        <span class="s1">data = (x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span>

        <span class="s4"># Define the statistic (and pvalue for comparison)</span>
        <span class="s0">def </span><span class="s1">statistic1d(*data):</span>
            <span class="s0">return </span><span class="s1">stats.kruskal(*data).statistic</span>

        <span class="s0">def </span><span class="s1">pvalue1d(*data):</span>
            <span class="s0">return </span><span class="s1">stats.kruskal(*data).pvalue</span>

        <span class="s1">statistic = _resampling._vectorize_statistic(statistic1d)</span>
        <span class="s1">pvalue = _resampling._vectorize_statistic(pvalue1d)</span>

        <span class="s4"># Calculate the expected results</span>
        <span class="s1">x2 = np.broadcast_to(x</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))  </span><span class="s4"># broadcast manually because</span>
        <span class="s1">y2 = np.broadcast_to(y</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))  </span><span class="s4"># _vectorize_statistic doesn't</span>
        <span class="s1">z2 = np.broadcast_to(z</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">))</span>
        <span class="s1">expected_statistic = statistic(x2</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">z2</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">expected_pvalue = pvalue(x2</span><span class="s0">, </span><span class="s1">y2</span><span class="s0">, </span><span class="s1">z2</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s4"># Calculate exact and randomized permutation results</span>
        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">False, </span><span class="s2">'axis'</span><span class="s1">: axis</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: </span><span class="s2">'greater'</span><span class="s0">,</span>
                <span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'independent'</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: self.rng}</span>
        <span class="s1">res = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s4"># Check results</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected_statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">res2.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected_pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">6e-2</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">3e-2</span><span class="s1">)</span>

    <span class="s4"># -- Paired-Sample Tests -- #</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_wilcoxon(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s1">x = stats.uniform.rvs(size=(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>
        <span class="s1">y = stats.uniform.rvs(size=(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">0.05</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s4"># We'll check both 1- and 2-sample versions of the same test;</span>
        <span class="s4"># we expect identical results to wilcoxon in all cases.</span>
        <span class="s0">def </span><span class="s1">statistic_1samp_1d(z):</span>
            <span class="s4"># 'less' ensures we get the same of two statistics every time</span>
            <span class="s0">return </span><span class="s1">stats.wilcoxon(z</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">).statistic</span>

        <span class="s0">def </span><span class="s1">statistic_2samp_1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.wilcoxon(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">).statistic</span>

        <span class="s0">def </span><span class="s1">test_1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.wilcoxon(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s1">test = _resampling._vectorize_statistic(test_1d)</span>

        <span class="s1">expected = test(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">expected_stat = expected[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">expected_p = expected[</span><span class="s3">1</span><span class="s1">]</span>

        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">False, </span><span class="s2">'axis'</span><span class="s1">: </span><span class="s3">1</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: alternative</span><span class="s0">,</span>
                <span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'samples'</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: self.rng</span><span class="s0">,</span>
                <span class="s2">'n_resamples'</span><span class="s1">: np.inf}</span>
        <span class="s1">res1 = permutation_test((x-y</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic_1samp_1d</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic_2samp_1d</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s4"># `wilcoxon` returns a different statistic with 'two-sided'</span>
        <span class="s1">assert_allclose(res1.statistic</span><span class="s0">, </span><span class="s1">res2.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s0">if </span><span class="s1">alternative != </span><span class="s2">'two-sided'</span><span class="s1">:</span>
            <span class="s1">assert_allclose(res2.statistic</span><span class="s0">, </span><span class="s1">expected_stat</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

        <span class="s1">assert_allclose(res2.pvalue</span><span class="s0">, </span><span class="s1">expected_p</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res1.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;less&quot;</span><span class="s0">, </span><span class="s2">&quot;greater&quot;</span><span class="s0">, </span><span class="s2">&quot;two-sided&quot;</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_binomtest(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s1">x = self.rng.integers(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">x[x == </span><span class="s3">0</span><span class="s1">] = -</span><span class="s3">1</span>
        <span class="s4"># More naturally, the test would flip elements between 0 and one.</span>
        <span class="s4"># However, permutation_test will flip the _signs_ of the elements.</span>
        <span class="s4"># So we have to work with +1/-1 instead of 1/0.</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s3">0</span><span class="s1">):</span>
            <span class="s0">return </span><span class="s1">np.sum(x &gt; </span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s1">k</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p = statistic(x)</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">0.5</span>
        <span class="s1">expected = stats.binomtest(k</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s1">res = stats.permutation_test((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True,</span>
                                     <span class="s1">permutation_type=</span><span class="s2">'samples'</span><span class="s0">,</span>
                                     <span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">random_state=self.rng</span><span class="s0">,</span>
                                     <span class="s1">alternative=alternative)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s4"># -- Exact Association Tests -- #</span>

    <span class="s0">def </span><span class="s1">test_against_kendalltau(self):</span>

        <span class="s1">x = self.rng.normal(size=</span><span class="s3">6</span><span class="s1">)</span>
        <span class="s1">y = x + self.rng.normal(size=</span><span class="s3">6</span><span class="s1">)</span>

        <span class="s1">expected = stats.kendalltau(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'exact'</span><span class="s1">)</span>

        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.kendalltau(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'asymptotic'</span><span class="s1">).statistic</span>

        <span class="s4"># kendalltau currently has only one alternative, two-sided</span>
        <span class="s1">res = permutation_test((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">permutation_type=</span><span class="s2">'pairings'</span><span class="s0">,</span>
                               <span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">random_state=self.rng)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected.pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative'</span><span class="s0">, </span><span class="s1">(</span><span class="s2">'less'</span><span class="s0">, </span><span class="s2">'greater'</span><span class="s0">, </span><span class="s2">'two-sided'</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_against_fisher_exact(self</span><span class="s0">, </span><span class="s1">alternative):</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">,</span><span class="s1">):</span>
            <span class="s0">return </span><span class="s1">np.sum((x == </span><span class="s3">1</span><span class="s1">) &amp; (y == </span><span class="s3">1</span><span class="s1">))</span>

        <span class="s4"># x and y are binary random variables with some dependence</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">6235696159000529929</span><span class="s1">)</span>
        <span class="s1">x = (rng.random(</span><span class="s3">7</span><span class="s1">) &gt; </span><span class="s3">0.6</span><span class="s1">).astype(float)</span>
        <span class="s1">y = (rng.random(</span><span class="s3">7</span><span class="s1">) + </span><span class="s3">0.25</span><span class="s1">*x &gt; </span><span class="s3">0.6</span><span class="s1">).astype(float)</span>
        <span class="s1">tab = stats.contingency.crosstab(x</span><span class="s0">, </span><span class="s1">y)[</span><span class="s3">1</span><span class="s1">]</span>

        <span class="s1">res = permutation_test((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">permutation_type=</span><span class="s2">'pairings'</span><span class="s0">,</span>
                               <span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">alternative=alternative</span><span class="s0">,</span>
                               <span class="s1">random_state=rng)</span>
        <span class="s1">res2 = stats.fisher_exact(tab</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2[</span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">@pytest.mark.xslow()</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'axis'</span><span class="s0">, </span><span class="s1">(-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_vectorized_nsamp_ptype_samples(self</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s4"># Test that permutation_test with permutation_type='samples' works</span>
        <span class="s4"># properly for a 3-sample statistic with nd array samples of different</span>
        <span class="s4"># (but compatible) shapes and ndims. Show that exact permutation test</span>
        <span class="s4"># reproduces SciPy's exact pvalue and that random permutation test</span>
        <span class="s4"># approximates it.</span>

        <span class="s1">x = self.rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>
        <span class="s1">y = self.rng.random(size=(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">3</span><span class="s1">))</span>
        <span class="s1">z = self.rng.random(size=(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span>
        <span class="s1">x = stats.rankdata(x</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">y = stats.rankdata(y</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">z = stats.rankdata(z</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">y = y[</span><span class="s3">0</span><span class="s1">]  </span><span class="s4"># to check broadcast with different ndim</span>
        <span class="s1">data = (x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">z)</span>

        <span class="s0">def </span><span class="s1">statistic1d(*data):</span>
            <span class="s0">return </span><span class="s1">stats.page_trend_test(data</span><span class="s0">, </span><span class="s1">ranked=</span><span class="s0">True,</span>
                                         <span class="s1">method=</span><span class="s2">'asymptotic'</span><span class="s1">).statistic</span>

        <span class="s0">def </span><span class="s1">pvalue1d(*data):</span>
            <span class="s0">return </span><span class="s1">stats.page_trend_test(data</span><span class="s0">, </span><span class="s1">ranked=</span><span class="s0">True,</span>
                                         <span class="s1">method=</span><span class="s2">'exact'</span><span class="s1">).pvalue</span>

        <span class="s1">statistic = _resampling._vectorize_statistic(statistic1d)</span>
        <span class="s1">pvalue = _resampling._vectorize_statistic(pvalue1d)</span>

        <span class="s1">expected_statistic = statistic(*np.broadcast_arrays(*data)</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">expected_pvalue = pvalue(*np.broadcast_arrays(*data)</span><span class="s0">, </span><span class="s1">axis=axis)</span>

        <span class="s4"># Let's forgive this use of an integer seed, please.</span>
        <span class="s1">kwds = {</span><span class="s2">'vectorized'</span><span class="s1">: </span><span class="s0">False, </span><span class="s2">'axis'</span><span class="s1">: axis</span><span class="s0">, </span><span class="s2">'alternative'</span><span class="s1">: </span><span class="s2">'greater'</span><span class="s0">,</span>
                <span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'pairings'</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: </span><span class="s3">0</span><span class="s1">}</span>
        <span class="s1">res = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">**kwds)</span>
        <span class="s1">res2 = permutation_test(data</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=</span><span class="s3">5000</span><span class="s0">, </span><span class="s1">**kwds)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected_statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">res2.statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected_pvalue</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">res2.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">3e-2</span><span class="s1">)</span>

    <span class="s4"># -- Test Against External References -- #</span>

    <span class="s1">tie_case_1 = {</span><span class="s2">'x'</span><span class="s1">: [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s2">'y'</span><span class="s1">: [</span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">]</span><span class="s0">,</span>
                  <span class="s2">'expected_less'</span><span class="s1">: </span><span class="s3">0.2000000000</span><span class="s0">,</span>
                  <span class="s2">'expected_2sided'</span><span class="s1">: </span><span class="s3">0.4</span><span class="s0">,  </span><span class="s4"># 2*expected_less</span>
                  <span class="s2">'expected_Pr_gte_S_mean'</span><span class="s1">: </span><span class="s3">0.3428571429</span><span class="s0">,  </span><span class="s4"># see note below</span>
                  <span class="s2">'expected_statistic'</span><span class="s1">: </span><span class="s3">7.5</span><span class="s0">,</span>
                  <span class="s2">'expected_avg'</span><span class="s1">: </span><span class="s3">9.142857</span><span class="s0">, </span><span class="s2">'expected_std'</span><span class="s1">: </span><span class="s3">1.40698</span><span class="s1">}</span>
    <span class="s1">tie_case_2 = {</span><span class="s2">'x'</span><span class="s1">: [</span><span class="s3">111</span><span class="s0">, </span><span class="s3">107</span><span class="s0">, </span><span class="s3">100</span><span class="s0">, </span><span class="s3">99</span><span class="s0">, </span><span class="s3">102</span><span class="s0">, </span><span class="s3">106</span><span class="s0">, </span><span class="s3">109</span><span class="s0">, </span><span class="s3">108</span><span class="s1">]</span><span class="s0">,</span>
                  <span class="s2">'y'</span><span class="s1">: [</span><span class="s3">107</span><span class="s0">, </span><span class="s3">108</span><span class="s0">, </span><span class="s3">106</span><span class="s0">, </span><span class="s3">98</span><span class="s0">, </span><span class="s3">105</span><span class="s0">, </span><span class="s3">103</span><span class="s0">, </span><span class="s3">110</span><span class="s0">, </span><span class="s3">105</span><span class="s0">, </span><span class="s3">104</span><span class="s1">]</span><span class="s0">,</span>
                  <span class="s2">'expected_less'</span><span class="s1">: </span><span class="s3">0.1555738379</span><span class="s0">,</span>
                  <span class="s2">'expected_2sided'</span><span class="s1">: </span><span class="s3">0.3111476758</span><span class="s0">,</span>
                  <span class="s2">'expected_Pr_gte_S_mean'</span><span class="s1">: </span><span class="s3">0.2969971205</span><span class="s0">,  </span><span class="s4"># see note below</span>
                  <span class="s2">'expected_statistic'</span><span class="s1">: </span><span class="s3">32.5</span><span class="s0">,</span>
                  <span class="s2">'expected_avg'</span><span class="s1">: </span><span class="s3">38.117647</span><span class="s0">, </span><span class="s2">'expected_std'</span><span class="s1">: </span><span class="s3">5.172124</span><span class="s1">}</span>

    <span class="s1">@pytest.mark.xslow()  </span><span class="s4"># only the second case is slow, really</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'case'</span><span class="s0">, </span><span class="s1">(tie_case_1</span><span class="s0">, </span><span class="s1">tie_case_2))</span>
    <span class="s0">def </span><span class="s1">test_with_ties(self</span><span class="s0">, </span><span class="s1">case):</span>
        <span class="s5">&quot;&quot;&quot; 
        Results above from SAS PROC NPAR1WAY, e.g. 
 
        DATA myData; 
        INPUT X Y; 
        CARDS; 
        1 1 
        1 2 
        1 3 
        1 4 
        2 1.5 
        2 2 
        2 2.5 
        ods graphics on; 
        proc npar1way AB data=myData; 
            class X; 
            EXACT; 
        run; 
        ods graphics off; 
 
        Note: SAS provides Pr &gt;= |S-Mean|, which is different from our 
        definition of a two-sided p-value. 
 
        &quot;&quot;&quot;</span>

        <span class="s1">x = case[</span><span class="s2">'x'</span><span class="s1">]</span>
        <span class="s1">y = case[</span><span class="s2">'y'</span><span class="s1">]</span>

        <span class="s1">expected_statistic = case[</span><span class="s2">'expected_statistic'</span><span class="s1">]</span>
        <span class="s1">expected_less = case[</span><span class="s2">'expected_less'</span><span class="s1">]</span>
        <span class="s1">expected_2sided = case[</span><span class="s2">'expected_2sided'</span><span class="s1">]</span>
        <span class="s1">expected_Pr_gte_S_mean = case[</span><span class="s2">'expected_Pr_gte_S_mean'</span><span class="s1">]</span>
        <span class="s1">expected_avg = case[</span><span class="s2">'expected_avg'</span><span class="s1">]</span>
        <span class="s1">expected_std = case[</span><span class="s2">'expected_std'</span><span class="s1">]</span>

        <span class="s0">def </span><span class="s1">statistic1d(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.ansari(x</span><span class="s0">, </span><span class="s1">y).statistic</span>

        <span class="s0">with </span><span class="s1">np.testing.suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(UserWarning</span><span class="s0">, </span><span class="s2">&quot;Ties preclude use of exact statistic&quot;</span><span class="s1">)</span>
            <span class="s1">res = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">,</span>
                                   <span class="s1">alternative=</span><span class="s2">'less'</span><span class="s1">)</span>
            <span class="s1">res2 = permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">n_resamples=np.inf</span><span class="s0">,</span>
                                    <span class="s1">alternative=</span><span class="s2">'two-sided'</span><span class="s1">)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected_statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected_less</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-10</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res2.pvalue</span><span class="s0">, </span><span class="s1">expected_2sided</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-10</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res2.null_distribution.mean()</span><span class="s0">, </span><span class="s1">expected_avg</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res2.null_distribution.std()</span><span class="s0">, </span><span class="s1">expected_std</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-6</span><span class="s1">)</span>

        <span class="s4"># SAS provides Pr &gt;= |S-Mean|; might as well check against that, too</span>
        <span class="s1">S = res.statistic</span>
        <span class="s1">mean = res.null_distribution.mean()</span>
        <span class="s1">n = len(res.null_distribution)</span>
        <span class="s1">Pr_gte_S_mean = np.sum(np.abs(res.null_distribution-mean)</span>
                               <span class="s1">&gt;= np.abs(S-mean))/n</span>
        <span class="s1">assert_allclose(expected_Pr_gte_S_mean</span><span class="s0">, </span><span class="s1">Pr_gte_S_mean)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">'alternative, expected_pvalue'</span><span class="s0">,</span>
                             <span class="s1">((</span><span class="s2">'less'</span><span class="s0">, </span><span class="s3">0.9708333333333</span><span class="s1">)</span><span class="s0">,</span>
                              <span class="s1">(</span><span class="s2">'greater'</span><span class="s0">, </span><span class="s3">0.05138888888889</span><span class="s1">)</span><span class="s0">,</span>
                              <span class="s1">(</span><span class="s2">'two-sided'</span><span class="s0">, </span><span class="s3">0.1027777777778</span><span class="s1">)))</span>
    <span class="s0">def </span><span class="s1">test_against_spearmanr_in_R(self</span><span class="s0">, </span><span class="s1">alternative</span><span class="s0">, </span><span class="s1">expected_pvalue):</span>
        <span class="s5">&quot;&quot;&quot; 
        Results above from R cor.test, e.g. 
 
        options(digits=16) 
        x &lt;- c(1.76405235, 0.40015721, 0.97873798, 
               2.2408932, 1.86755799, -0.97727788) 
        y &lt;- c(2.71414076, 0.2488, 0.87551913, 
               2.6514917, 2.01160156, 0.47699563) 
        cor.test(x, y, method = &quot;spearm&quot;, alternative = &quot;t&quot;) 
        &quot;&quot;&quot;</span>
        <span class="s4"># data comes from</span>
        <span class="s4"># np.random.seed(0)</span>
        <span class="s4"># x = stats.norm.rvs(size=6)</span>
        <span class="s4"># y = x + stats.norm.rvs(size=6)</span>
        <span class="s1">x = [</span><span class="s3">1.76405235</span><span class="s0">, </span><span class="s3">0.40015721</span><span class="s0">, </span><span class="s3">0.97873798</span><span class="s0">,</span>
             <span class="s3">2.2408932</span><span class="s0">, </span><span class="s3">1.86755799</span><span class="s0">, </span><span class="s1">-</span><span class="s3">0.97727788</span><span class="s1">]</span>
        <span class="s1">y = [</span><span class="s3">2.71414076</span><span class="s0">, </span><span class="s3">0.2488</span><span class="s0">, </span><span class="s3">0.87551913</span><span class="s0">,</span>
             <span class="s3">2.6514917</span><span class="s0">, </span><span class="s3">2.01160156</span><span class="s0">, </span><span class="s3">0.47699563</span><span class="s1">]</span>
        <span class="s1">expected_statistic = </span><span class="s3">0.7714285714285715</span>

        <span class="s0">def </span><span class="s1">statistic1d(x):</span>
            <span class="s0">return </span><span class="s1">stats.spearmanr(x</span><span class="s0">, </span><span class="s1">y).statistic</span>

        <span class="s1">res = permutation_test((x</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">statistic1d</span><span class="s0">, </span><span class="s1">permutation_type=</span><span class="s2">'pairings'</span><span class="s0">,</span>
                               <span class="s1">n_resamples=np.inf</span><span class="s0">, </span><span class="s1">alternative=alternative)</span>

        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">expected_statistic</span><span class="s0">, </span><span class="s1">rtol=self.rtol)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">expected_pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-13</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;batch&quot;</span><span class="s0">, </span><span class="s1">(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">))</span>
    <span class="s0">def </span><span class="s1">test_batch_generator_iv(self</span><span class="s0">, </span><span class="s1">batch):</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s2">&quot;`batch` must be positive.&quot;</span><span class="s1">):</span>
            <span class="s1">list(_resampling._batch_generator([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">batch))</span>

    <span class="s1">batch_generator_cases = [(range(</span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">[])</span><span class="s0">,</span>
                             <span class="s1">(range(</span><span class="s3">6</span><span class="s1">)</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">[[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]])</span><span class="s0">,</span>
                             <span class="s1">(range(</span><span class="s3">8</span><span class="s1">)</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">[[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]])]</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;iterable, batch, expected&quot;</span><span class="s0">,</span>
                             <span class="s1">batch_generator_cases)</span>
    <span class="s0">def </span><span class="s1">test_batch_generator(self</span><span class="s0">, </span><span class="s1">iterable</span><span class="s0">, </span><span class="s1">batch</span><span class="s0">, </span><span class="s1">expected):</span>
        <span class="s1">got = list(_resampling._batch_generator(iterable</span><span class="s0">, </span><span class="s1">batch))</span>
        <span class="s0">assert </span><span class="s1">got == expected</span>

    <span class="s0">def </span><span class="s1">test_finite_precision_statistic(self):</span>
        <span class="s4"># Some statistics return numerically distinct values when the values</span>
        <span class="s4"># should be equal in theory. Test that `permutation_test` accounts</span>
        <span class="s4"># for this in some way.</span>
        <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span>
        <span class="s1">y = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">8</span><span class="s1">]</span>

        <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s0">return </span><span class="s1">stats.pearsonr(x</span><span class="s0">, </span><span class="s1">y)[</span><span class="s3">0</span><span class="s1">]</span>

        <span class="s1">res = stats.permutation_test((x</span><span class="s0">, </span><span class="s1">y)</span><span class="s0">, </span><span class="s1">statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False,</span>
                                     <span class="s1">permutation_type=</span><span class="s2">'pairings'</span><span class="s1">)</span>
        <span class="s1">r</span><span class="s0">, </span><span class="s1">pvalue</span><span class="s0">, </span><span class="s1">null = res.statistic</span><span class="s0">, </span><span class="s1">res.pvalue</span><span class="s0">, </span><span class="s1">res.null_distribution</span>

        <span class="s1">correct_p = </span><span class="s3">2 </span><span class="s1">* np.sum(null &gt;= r - </span><span class="s3">1e-14</span><span class="s1">) / len(null)</span>
        <span class="s0">assert </span><span class="s1">pvalue == correct_p == </span><span class="s3">1</span><span class="s1">/</span><span class="s3">3</span>
        <span class="s4"># Compare against other exact correlation tests using R corr.test</span>
        <span class="s4"># options(digits=16)</span>
        <span class="s4"># x = c(1, 2, 4, 3)</span>
        <span class="s4"># y = c(2, 4, 6, 8)</span>
        <span class="s4"># cor.test(x, y, alternative = &quot;t&quot;, method = &quot;spearman&quot;)  # 0.333333333</span>
        <span class="s4"># cor.test(x, y, alternative = &quot;t&quot;, method = &quot;kendall&quot;)  # 0.333333333</span>


<span class="s0">def </span><span class="s1">test_all_partitions_concatenated():</span>
    <span class="s4"># make sure that _all_paritions_concatenated produces the correct number</span>
    <span class="s4"># of partitions of the data into samples of the given sizes and that</span>
    <span class="s4"># all are unique</span>
    <span class="s1">n = np.array([</span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">nc = np.cumsum(n)</span>

    <span class="s1">all_partitions = set()</span>
    <span class="s1">counter = </span><span class="s3">0</span>
    <span class="s0">for </span><span class="s1">partition_concatenated </span><span class="s0">in </span><span class="s1">_resampling._all_partitions_concatenated(n):</span>
        <span class="s1">counter += </span><span class="s3">1</span>
        <span class="s1">partitioning = np.split(partition_concatenated</span><span class="s0">, </span><span class="s1">nc[:-</span><span class="s3">1</span><span class="s1">])</span>
        <span class="s1">all_partitions.add(tuple([frozenset(i) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">partitioning]))</span>

    <span class="s1">expected = np.prod([special.binom(sum(n[i:])</span><span class="s0">, </span><span class="s1">sum(n[i+</span><span class="s3">1</span><span class="s1">:]))</span>
                        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(len(n)-</span><span class="s3">1</span><span class="s1">)])</span>

    <span class="s1">assert_equal(counter</span><span class="s0">, </span><span class="s1">expected)</span>
    <span class="s1">assert_equal(len(all_partitions)</span><span class="s0">, </span><span class="s1">expected)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">'fun_name'</span><span class="s0">,</span>
                         <span class="s1">[</span><span class="s2">'bootstrap'</span><span class="s0">, </span><span class="s2">'permutation_test'</span><span class="s0">, </span><span class="s2">'monte_carlo_test'</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_parameter_vectorized(fun_name):</span>
    <span class="s4"># Check that parameter `vectorized` is working as desired for all</span>
    <span class="s4"># resampling functions. Results don't matter; just don't fail asserts.</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">75245098234592</span><span class="s1">)</span>
    <span class="s1">sample = rng.random(size=</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">rvs(size):  </span><span class="s4"># needed by `monte_carlo_test`</span>
        <span class="s0">return </span><span class="s1">stats.norm.rvs(size=size</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

    <span class="s1">fun_options = {</span><span class="s2">'bootstrap'</span><span class="s1">: {</span><span class="s2">'data'</span><span class="s1">: (sample</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: rng</span><span class="s0">,</span>
                                 <span class="s2">'method'</span><span class="s1">: </span><span class="s2">'percentile'</span><span class="s1">}</span><span class="s0">,</span>
                   <span class="s2">'permutation_test'</span><span class="s1">: {</span><span class="s2">'data'</span><span class="s1">: (sample</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s2">'random_state'</span><span class="s1">: rng</span><span class="s0">,</span>
                                        <span class="s2">'permutation_type'</span><span class="s1">: </span><span class="s2">'samples'</span><span class="s1">}</span><span class="s0">,</span>
                   <span class="s2">'monte_carlo_test'</span><span class="s1">: {</span><span class="s2">'sample'</span><span class="s1">: sample</span><span class="s0">, </span><span class="s2">'rvs'</span><span class="s1">: rvs}}</span>
    <span class="s1">common_options = {</span><span class="s2">'n_resamples'</span><span class="s1">: </span><span class="s3">100</span><span class="s1">}</span>

    <span class="s1">fun = getattr(stats</span><span class="s0">, </span><span class="s1">fun_name)</span>
    <span class="s1">options = fun_options[fun_name]</span>
    <span class="s1">options.update(common_options)</span>

    <span class="s0">def </span><span class="s1">statistic(x</span><span class="s0">, </span><span class="s1">axis):</span>
        <span class="s0">assert </span><span class="s1">x.ndim &gt; </span><span class="s3">1 </span><span class="s0">or </span><span class="s1">np.array_equal(x</span><span class="s0">, </span><span class="s1">sample)</span>
        <span class="s0">return </span><span class="s1">np.mean(x</span><span class="s0">, </span><span class="s1">axis=axis)</span>
    <span class="s1">fun(statistic=statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">None, </span><span class="s1">**options)</span>
    <span class="s1">fun(statistic=statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">True, </span><span class="s1">**options)</span>

    <span class="s0">def </span><span class="s1">statistic(x):</span>
        <span class="s0">assert </span><span class="s1">x.ndim == </span><span class="s3">1</span>
        <span class="s0">return </span><span class="s1">np.mean(x)</span>
    <span class="s1">fun(statistic=statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">None, </span><span class="s1">**options)</span>
    <span class="s1">fun(statistic=statistic</span><span class="s0">, </span><span class="s1">vectorized=</span><span class="s0">False, </span><span class="s1">**options)</span>
</pre>
</body>
</html>
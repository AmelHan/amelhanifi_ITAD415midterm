<html>
<head>
<title>partial_dependence.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
partial_dependence.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numbers</span>
<span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">chain</span>
<span class="s0">from </span><span class="s1">math </span><span class="s0">import </span><span class="s1">ceil</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">sparse</span>
<span class="s0">from </span><span class="s1">scipy.stats.mstats </span><span class="s0">import </span><span class="s1">mquantiles</span>

<span class="s0">from </span><span class="s1">...base </span><span class="s0">import </span><span class="s1">is_regressor</span>
<span class="s0">from </span><span class="s1">...utils </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">Bunch</span><span class="s0">,</span>
    <span class="s1">_safe_indexing</span><span class="s0">,</span>
    <span class="s1">check_array</span><span class="s0">,</span>
    <span class="s1">check_matplotlib_support</span><span class="s0">,  </span><span class="s2"># noqa</span>
    <span class="s1">check_random_state</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">...utils._encode </span><span class="s0">import </span><span class="s1">_unique</span>
<span class="s0">from </span><span class="s1">...utils.parallel </span><span class="s0">import </span><span class="s1">Parallel</span><span class="s0">, </span><span class="s1">delayed</span>
<span class="s0">from </span><span class="s1">.. </span><span class="s0">import </span><span class="s1">partial_dependence</span>
<span class="s0">from </span><span class="s1">.._pd_utils </span><span class="s0">import </span><span class="s1">_check_feature_names</span><span class="s0">, </span><span class="s1">_get_feature_index</span>


<span class="s0">class </span><span class="s1">PartialDependenceDisplay:</span>
    <span class="s3">&quot;&quot;&quot;Partial Dependence Plot (PDP). 
 
    This can also display individual partial dependencies which are often 
    referred to as: Individual Condition Expectation (ICE). 
 
    It is recommended to use 
    :func:`~sklearn.inspection.PartialDependenceDisplay.from_estimator` to create a 
    :class:`~sklearn.inspection.PartialDependenceDisplay`. All parameters are 
    stored as attributes. 
 
    Read more in 
    :ref:`sphx_glr_auto_examples_miscellaneous_plot_partial_dependence_visualization_api.py` 
    and the :ref:`User Guide &lt;partial_dependence&gt;`. 
 
        .. versionadded:: 0.22 
 
    Parameters 
    ---------- 
    pd_results : list of Bunch 
        Results of :func:`~sklearn.inspection.partial_dependence` for 
        ``features``. 
 
    features : list of (int,) or list of (int, int) 
        Indices of features for a given plot. A tuple of one integer will plot 
        a partial dependence curve of one feature. A tuple of two integers will 
        plot a two-way partial dependence curve as a contour plot. 
 
    feature_names : list of str 
        Feature names corresponding to the indices in ``features``. 
 
    target_idx : int 
 
        - In a multiclass setting, specifies the class for which the PDPs 
          should be computed. Note that for binary classification, the 
          positive class (index 1) is always used. 
        - In a multioutput setting, specifies the task for which the PDPs 
          should be computed. 
 
        Ignored in binary classification or classical regression settings. 
 
    deciles : dict 
        Deciles for feature indices in ``features``. 
 
    kind : {'average', 'individual', 'both'} or list of such str, \ 
            default='average' 
        Whether to plot the partial dependence averaged across all the samples 
        in the dataset or one line per sample or both. 
 
        - ``kind='average'`` results in the traditional PD plot; 
        - ``kind='individual'`` results in the ICE plot; 
        - ``kind='both'`` results in plotting both the ICE and PD on the same 
          plot. 
 
        A list of such strings can be provided to specify `kind` on a per-plot 
        basis. The length of the list should be the same as the number of 
        interaction requested in `features`. 
 
        .. note:: 
           ICE ('individual' or 'both') is not a valid option for 2-ways 
           interactions plot. As a result, an error will be raised. 
           2-ways interaction plots should always be configured to 
           use the 'average' kind instead. 
 
        .. note:: 
           The fast ``method='recursion'`` option is only available for 
           `kind='average'` and `sample_weights=None`. Computing individual 
           dependencies and doing weighted averages requires using the slower 
           `method='brute'`. 
 
        .. versionadded:: 0.24 
           Add `kind` parameter with `'average'`, `'individual'`, and `'both'` 
           options. 
 
        .. versionadded:: 1.1 
           Add the possibility to pass a list of string specifying `kind` 
           for each plot. 
 
    subsample : float, int or None, default=1000 
        Sampling for ICE curves when `kind` is 'individual' or 'both'. 
        If float, should be between 0.0 and 1.0 and represent the proportion 
        of the dataset to be used to plot ICE curves. If int, represents the 
        maximum absolute number of samples to use. 
 
        Note that the full dataset is still used to calculate partial 
        dependence when `kind='both'`. 
 
        .. versionadded:: 0.24 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the randomness of the selected samples when subsamples is not 
        `None`. See :term:`Glossary &lt;random_state&gt;` for details. 
 
        .. versionadded:: 0.24 
 
    is_categorical : list of (bool,) or list of (bool, bool), default=None 
        Whether each target feature in `features` is categorical or not. 
        The list should be same size as `features`. If `None`, all features 
        are assumed to be continuous. 
 
        .. versionadded:: 1.2 
 
    Attributes 
    ---------- 
    bounding_ax_ : matplotlib Axes or None 
        If `ax` is an axes or None, the `bounding_ax_` is the axes where the 
        grid of partial dependence plots are drawn. If `ax` is a list of axes 
        or a numpy array of axes, `bounding_ax_` is None. 
 
    axes_ : ndarray of matplotlib Axes 
        If `ax` is an axes or None, `axes_[i, j]` is the axes on the i-th row 
        and j-th column. If `ax` is a list of axes, `axes_[i]` is the i-th item 
        in `ax`. Elements that are None correspond to a nonexisting axes in 
        that position. 
 
    lines_ : ndarray of matplotlib Artists 
        If `ax` is an axes or None, `lines_[i, j]` is the partial dependence 
        curve on the i-th row and j-th column. If `ax` is a list of axes, 
        `lines_[i]` is the partial dependence curve corresponding to the i-th 
        item in `ax`. Elements that are None correspond to a nonexisting axes 
        or an axes that does not include a line plot. 
 
    deciles_vlines_ : ndarray of matplotlib LineCollection 
        If `ax` is an axes or None, `vlines_[i, j]` is the line collection 
        representing the x axis deciles of the i-th row and j-th column. If 
        `ax` is a list of axes, `vlines_[i]` corresponds to the i-th item in 
        `ax`. Elements that are None correspond to a nonexisting axes or an 
        axes that does not include a PDP plot. 
 
        .. versionadded:: 0.23 
 
    deciles_hlines_ : ndarray of matplotlib LineCollection 
        If `ax` is an axes or None, `vlines_[i, j]` is the line collection 
        representing the y axis deciles of the i-th row and j-th column. If 
        `ax` is a list of axes, `vlines_[i]` corresponds to the i-th item in 
        `ax`. Elements that are None correspond to a nonexisting axes or an 
        axes that does not include a 2-way plot. 
 
        .. versionadded:: 0.23 
 
    contours_ : ndarray of matplotlib Artists 
        If `ax` is an axes or None, `contours_[i, j]` is the partial dependence 
        plot on the i-th row and j-th column. If `ax` is a list of axes, 
        `contours_[i]` is the partial dependence plot corresponding to the i-th 
        item in `ax`. Elements that are None correspond to a nonexisting axes 
        or an axes that does not include a contour plot. 
 
    bars_ : ndarray of matplotlib Artists 
        If `ax` is an axes or None, `bars_[i, j]` is the partial dependence bar 
        plot on the i-th row and j-th column (for a categorical feature). 
        If `ax` is a list of axes, `bars_[i]` is the partial dependence bar 
        plot corresponding to the i-th item in `ax`. Elements that are None 
        correspond to a nonexisting axes or an axes that does not include a 
        bar plot. 
 
        .. versionadded:: 1.2 
 
    heatmaps_ : ndarray of matplotlib Artists 
        If `ax` is an axes or None, `heatmaps_[i, j]` is the partial dependence 
        heatmap on the i-th row and j-th column (for a pair of categorical 
        features) . If `ax` is a list of axes, `heatmaps_[i]` is the partial 
        dependence heatmap corresponding to the i-th item in `ax`. Elements 
        that are None correspond to a nonexisting axes or an axes that does not 
        include a heatmap. 
 
        .. versionadded:: 1.2 
 
    figure_ : matplotlib Figure 
        Figure containing partial dependence plots. 
 
    See Also 
    -------- 
    partial_dependence : Compute Partial Dependence values. 
    PartialDependenceDisplay.from_estimator : Plot Partial Dependence. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from sklearn.datasets import make_friedman1 
    &gt;&gt;&gt; from sklearn.ensemble import GradientBoostingRegressor 
    &gt;&gt;&gt; from sklearn.inspection import PartialDependenceDisplay 
    &gt;&gt;&gt; from sklearn.inspection import partial_dependence 
    &gt;&gt;&gt; X, y = make_friedman1() 
    &gt;&gt;&gt; clf = GradientBoostingRegressor(n_estimators=10).fit(X, y) 
    &gt;&gt;&gt; features, feature_names = [(0,)], [f&quot;Features #{i}&quot; for i in range(X.shape[1])] 
    &gt;&gt;&gt; deciles = {0: np.linspace(0, 1, num=5)} 
    &gt;&gt;&gt; pd_results = partial_dependence( 
    ...     clf, X, features=0, kind=&quot;average&quot;, grid_resolution=5) 
    &gt;&gt;&gt; display = PartialDependenceDisplay( 
    ...     [pd_results], features=features, feature_names=feature_names, 
    ...     target_idx=0, deciles=deciles 
    ... ) 
    &gt;&gt;&gt; display.plot(pdp_lim={1: (-1.38, 0.66)}) 
    &lt;...&gt; 
    &gt;&gt;&gt; plt.show() 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">pd_results</span><span class="s0">,</span>
        <span class="s1">*</span><span class="s0">,</span>
        <span class="s1">features</span><span class="s0">,</span>
        <span class="s1">feature_names</span><span class="s0">,</span>
        <span class="s1">target_idx</span><span class="s0">,</span>
        <span class="s1">deciles</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s4">&quot;average&quot;</span><span class="s0">,</span>
        <span class="s1">subsample=</span><span class="s5">1000</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
        <span class="s1">is_categorical=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.pd_results = pd_results</span>
        <span class="s1">self.features = features</span>
        <span class="s1">self.feature_names = feature_names</span>
        <span class="s1">self.target_idx = target_idx</span>
        <span class="s1">self.deciles = deciles</span>
        <span class="s1">self.kind = kind</span>
        <span class="s1">self.subsample = subsample</span>
        <span class="s1">self.random_state = random_state</span>
        <span class="s1">self.is_categorical = is_categorical</span>

    <span class="s1">@classmethod</span>
    <span class="s0">def </span><span class="s1">from_estimator(</span>
        <span class="s1">cls</span><span class="s0">,</span>
        <span class="s1">estimator</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">features</span><span class="s0">,</span>
        <span class="s1">*</span><span class="s0">,</span>
        <span class="s1">sample_weight=</span><span class="s0">None,</span>
        <span class="s1">categorical_features=</span><span class="s0">None,</span>
        <span class="s1">feature_names=</span><span class="s0">None,</span>
        <span class="s1">target=</span><span class="s0">None,</span>
        <span class="s1">response_method=</span><span class="s4">&quot;auto&quot;</span><span class="s0">,</span>
        <span class="s1">n_cols=</span><span class="s5">3</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s5">100</span><span class="s0">,</span>
        <span class="s1">percentiles=(</span><span class="s5">0.05</span><span class="s0">, </span><span class="s5">0.95</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s4">&quot;auto&quot;</span><span class="s0">,</span>
        <span class="s1">n_jobs=</span><span class="s0">None,</span>
        <span class="s1">verbose=</span><span class="s5">0</span><span class="s0">,</span>
        <span class="s1">line_kw=</span><span class="s0">None,</span>
        <span class="s1">ice_lines_kw=</span><span class="s0">None,</span>
        <span class="s1">pd_line_kw=</span><span class="s0">None,</span>
        <span class="s1">contour_kw=</span><span class="s0">None,</span>
        <span class="s1">ax=</span><span class="s0">None,</span>
        <span class="s1">kind=</span><span class="s4">&quot;average&quot;</span><span class="s0">,</span>
        <span class="s1">centered=</span><span class="s0">False,</span>
        <span class="s1">subsample=</span><span class="s5">1000</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Partial dependence (PD) and individual conditional expectation (ICE) plots. 
 
        Partial dependence plots, individual conditional expectation plots or an 
        overlay of both of them can be plotted by setting the ``kind`` 
        parameter. The ``len(features)`` plots are arranged in a grid with 
        ``n_cols`` columns. Two-way partial dependence plots are plotted as 
        contour plots. The deciles of the feature values will be shown with tick 
        marks on the x-axes for one-way plots, and on both axes for two-way 
        plots. 
 
        Read more in the :ref:`User Guide &lt;partial_dependence&gt;`. 
 
        .. note:: 
 
            :func:`PartialDependenceDisplay.from_estimator` does not support using the 
            same axes with multiple calls. To plot the partial dependence for 
            multiple estimators, please pass the axes created by the first call to the 
            second call:: 
 
               &gt;&gt;&gt; from sklearn.inspection import PartialDependenceDisplay 
               &gt;&gt;&gt; from sklearn.datasets import make_friedman1 
               &gt;&gt;&gt; from sklearn.linear_model import LinearRegression 
               &gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor 
               &gt;&gt;&gt; X, y = make_friedman1() 
               &gt;&gt;&gt; est1 = LinearRegression().fit(X, y) 
               &gt;&gt;&gt; est2 = RandomForestRegressor().fit(X, y) 
               &gt;&gt;&gt; disp1 = PartialDependenceDisplay.from_estimator(est1, X, 
               ...                                                 [1, 2]) 
               &gt;&gt;&gt; disp2 = PartialDependenceDisplay.from_estimator(est2, X, [1, 2], 
               ...                                                 ax=disp1.axes_) 
 
        .. warning:: 
 
            For :class:`~sklearn.ensemble.GradientBoostingClassifier` and 
            :class:`~sklearn.ensemble.GradientBoostingRegressor`, the 
            `'recursion'` method (used by default) will not account for the `init` 
            predictor of the boosting process. In practice, this will produce 
            the same values as `'brute'` up to a constant offset in the target 
            response, provided that `init` is a constant estimator (which is the 
            default). However, if `init` is not a constant estimator, the 
            partial dependence values are incorrect for `'recursion'` because the 
            offset will be sample-dependent. It is preferable to use the `'brute'` 
            method. Note that this only applies to 
            :class:`~sklearn.ensemble.GradientBoostingClassifier` and 
            :class:`~sklearn.ensemble.GradientBoostingRegressor`, not to 
            :class:`~sklearn.ensemble.HistGradientBoostingClassifier` and 
            :class:`~sklearn.ensemble.HistGradientBoostingRegressor`. 
 
        .. versionadded:: 1.0 
 
        Parameters 
        ---------- 
        estimator : BaseEstimator 
            A fitted estimator object implementing :term:`predict`, 
            :term:`predict_proba`, or :term:`decision_function`. 
            Multioutput-multiclass classifiers are not supported. 
 
        X : {array-like, dataframe} of shape (n_samples, n_features) 
            ``X`` is used to generate a grid of values for the target 
            ``features`` (where the partial dependence will be evaluated), and 
            also to generate values for the complement features when the 
            `method` is `'brute'`. 
 
        features : list of {int, str, pair of int, pair of str} 
            The target features for which to create the PDPs. 
            If `features[i]` is an integer or a string, a one-way PDP is created; 
            if `features[i]` is a tuple, a two-way PDP is created (only supported 
            with `kind='average'`). Each tuple must be of size 2. 
            If any entry is a string, then it must be in ``feature_names``. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights are used to calculate weighted means when averaging the 
            model output. If `None`, then samples are equally weighted. If 
            `sample_weight` is not `None`, then `method` will be set to `'brute'`. 
            Note that `sample_weight` is ignored for `kind='individual'`. 
 
            .. versionadded:: 1.3 
 
        categorical_features : array-like of shape (n_features,) or shape \ 
                (n_categorical_features,), dtype={bool, int, str}, default=None 
            Indicates the categorical features. 
 
            - `None`: no feature will be considered categorical; 
            - boolean array-like: boolean mask of shape `(n_features,)` 
              indicating which features are categorical. Thus, this array has 
              the same shape has `X.shape[1]`; 
            - integer or string array-like: integer indices or strings 
              indicating categorical features. 
 
            .. versionadded:: 1.2 
 
        feature_names : array-like of shape (n_features,), dtype=str, default=None 
            Name of each feature; `feature_names[i]` holds the name of the feature 
            with index `i`. 
            By default, the name of the feature corresponds to their numerical 
            index for NumPy array and their column name for pandas dataframe. 
 
        target : int, default=None 
            - In a multiclass setting, specifies the class for which the PDPs 
              should be computed. Note that for binary classification, the 
              positive class (index 1) is always used. 
            - In a multioutput setting, specifies the task for which the PDPs 
              should be computed. 
 
            Ignored in binary classification or classical regression settings. 
 
        response_method : {'auto', 'predict_proba', 'decision_function'}, \ 
                default='auto' 
            Specifies whether to use :term:`predict_proba` or 
            :term:`decision_function` as the target response. For regressors 
            this parameter is ignored and the response is always the output of 
            :term:`predict`. By default, :term:`predict_proba` is tried first 
            and we revert to :term:`decision_function` if it doesn't exist. If 
            ``method`` is `'recursion'`, the response is always the output of 
            :term:`decision_function`. 
 
        n_cols : int, default=3 
            The maximum number of columns in the grid plot. Only active when `ax` 
            is a single axis or `None`. 
 
        grid_resolution : int, default=100 
            The number of equally spaced points on the axes of the plots, for each 
            target feature. 
 
        percentiles : tuple of float, default=(0.05, 0.95) 
            The lower and upper percentile used to create the extreme values 
            for the PDP axes. Must be in [0, 1]. 
 
        method : str, default='auto' 
            The method used to calculate the averaged predictions: 
 
            - `'recursion'` is only supported for some tree-based estimators 
              (namely 
              :class:`~sklearn.ensemble.GradientBoostingClassifier`, 
              :class:`~sklearn.ensemble.GradientBoostingRegressor`, 
              :class:`~sklearn.ensemble.HistGradientBoostingClassifier`, 
              :class:`~sklearn.ensemble.HistGradientBoostingRegressor`, 
              :class:`~sklearn.tree.DecisionTreeRegressor`, 
              :class:`~sklearn.ensemble.RandomForestRegressor` 
              but is more efficient in terms of speed. 
              With this method, the target response of a 
              classifier is always the decision function, not the predicted 
              probabilities. Since the `'recursion'` method implicitly computes 
              the average of the ICEs by design, it is not compatible with ICE and 
              thus `kind` must be `'average'`. 
 
            - `'brute'` is supported for any estimator, but is more 
              computationally intensive. 
 
            - `'auto'`: the `'recursion'` is used for estimators that support it, 
              and `'brute'` is used otherwise. If `sample_weight` is not `None`, 
              then `'brute'` is used regardless of the estimator. 
 
            Please see :ref:`this note &lt;pdp_method_differences&gt;` for 
            differences between the `'brute'` and `'recursion'` method. 
 
        n_jobs : int, default=None 
            The number of CPUs to use to compute the partial dependences. 
            Computation is parallelized over features specified by the `features` 
            parameter. 
 
            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
            ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
            for more details. 
 
        verbose : int, default=0 
            Verbose output during PD computations. 
 
        line_kw : dict, default=None 
            Dict with keywords passed to the ``matplotlib.pyplot.plot`` call. 
            For one-way partial dependence plots. It can be used to define common 
            properties for both `ice_lines_kw` and `pdp_line_kw`. 
 
        ice_lines_kw : dict, default=None 
            Dictionary with keywords passed to the `matplotlib.pyplot.plot` call. 
            For ICE lines in the one-way partial dependence plots. 
            The key value pairs defined in `ice_lines_kw` takes priority over 
            `line_kw`. 
 
        pd_line_kw : dict, default=None 
            Dictionary with keywords passed to the `matplotlib.pyplot.plot` call. 
            For partial dependence in one-way partial dependence plots. 
            The key value pairs defined in `pd_line_kw` takes priority over 
            `line_kw`. 
 
        contour_kw : dict, default=None 
            Dict with keywords passed to the ``matplotlib.pyplot.contourf`` call. 
            For two-way partial dependence plots. 
 
        ax : Matplotlib axes or array-like of Matplotlib axes, default=None 
            - If a single axis is passed in, it is treated as a bounding axes 
              and a grid of partial dependence plots will be drawn within 
              these bounds. The `n_cols` parameter controls the number of 
              columns in the grid. 
            - If an array-like of axes are passed in, the partial dependence 
              plots will be drawn directly into these axes. 
            - If `None`, a figure and a bounding axes is created and treated 
              as the single axes case. 
 
        kind : {'average', 'individual', 'both'}, default='average' 
            Whether to plot the partial dependence averaged across all the samples 
            in the dataset or one line per sample or both. 
 
            - ``kind='average'`` results in the traditional PD plot; 
            - ``kind='individual'`` results in the ICE plot. 
 
           Note that the fast `method='recursion'` option is only available for 
           `kind='average'` and `sample_weights=None`. Computing individual 
           dependencies and doing weighted averages requires using the slower 
           `method='brute'`. 
 
        centered : bool, default=False 
            If `True`, the ICE and PD lines will start at the origin of the 
            y-axis. By default, no centering is done. 
 
            .. versionadded:: 1.1 
 
        subsample : float, int or None, default=1000 
            Sampling for ICE curves when `kind` is 'individual' or 'both'. 
            If `float`, should be between 0.0 and 1.0 and represent the proportion 
            of the dataset to be used to plot ICE curves. If `int`, represents the 
            absolute number samples to use. 
 
            Note that the full dataset is still used to calculate averaged partial 
            dependence when `kind='both'`. 
 
        random_state : int, RandomState instance or None, default=None 
            Controls the randomness of the selected samples when subsamples is not 
            `None` and `kind` is either `'both'` or `'individual'`. 
            See :term:`Glossary &lt;random_state&gt;` for details. 
 
        Returns 
        ------- 
        display : :class:`~sklearn.inspection.PartialDependenceDisplay` 
 
        See Also 
        -------- 
        partial_dependence : Compute Partial Dependence values. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; import matplotlib.pyplot as plt 
        &gt;&gt;&gt; from sklearn.datasets import make_friedman1 
        &gt;&gt;&gt; from sklearn.ensemble import GradientBoostingRegressor 
        &gt;&gt;&gt; from sklearn.inspection import PartialDependenceDisplay 
        &gt;&gt;&gt; X, y = make_friedman1() 
        &gt;&gt;&gt; clf = GradientBoostingRegressor(n_estimators=10).fit(X, y) 
        &gt;&gt;&gt; PartialDependenceDisplay.from_estimator(clf, X, [0, (0, 1)]) 
        &lt;...&gt; 
        &gt;&gt;&gt; plt.show() 
        &quot;&quot;&quot;</span>
        <span class="s1">check_matplotlib_support(</span><span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">cls.__name__</span><span class="s0">}</span><span class="s4">.from_estimator&quot;</span><span class="s1">)  </span><span class="s2"># noqa</span>
        <span class="s0">import </span><span class="s1">matplotlib.pyplot </span><span class="s0">as </span><span class="s1">plt  </span><span class="s2"># noqa</span>

        <span class="s2"># set target_idx for multi-class estimators</span>
        <span class="s0">if </span><span class="s1">hasattr(estimator</span><span class="s0">, </span><span class="s4">&quot;classes_&quot;</span><span class="s1">) </span><span class="s0">and </span><span class="s1">np.size(estimator.classes_) &gt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">target </span><span class="s0">is None</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;target must be specified for multi-class&quot;</span><span class="s1">)</span>
            <span class="s1">target_idx = np.searchsorted(estimator.classes_</span><span class="s0">, </span><span class="s1">target)</span>
            <span class="s0">if </span><span class="s1">(</span>
                <span class="s0">not </span><span class="s1">(</span><span class="s5">0 </span><span class="s1">&lt;= target_idx &lt; len(estimator.classes_))</span>
                <span class="s0">or </span><span class="s1">estimator.classes_[target_idx] != target</span>
            <span class="s1">):</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;target not in est.classes_, got {}&quot;</span><span class="s1">.format(target))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s2"># regression and binary classification</span>
            <span class="s1">target_idx = </span><span class="s5">0</span>

        <span class="s2"># Use check_array only on lists and other non-array-likes / sparse. Do not</span>
        <span class="s2"># convert DataFrame into a NumPy array.</span>
        <span class="s0">if not </span><span class="s1">(hasattr(X</span><span class="s0">, </span><span class="s4">&quot;__array__&quot;</span><span class="s1">) </span><span class="s0">or </span><span class="s1">sparse.issparse(X)):</span>
            <span class="s1">X = check_array(X</span><span class="s0">, </span><span class="s1">force_all_finite=</span><span class="s4">&quot;allow-nan&quot;</span><span class="s0">, </span><span class="s1">dtype=object)</span>
        <span class="s1">n_features = X.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">feature_names = _check_feature_names(X</span><span class="s0">, </span><span class="s1">feature_names)</span>
        <span class="s2"># expand kind to always be a list of str</span>
        <span class="s1">kind_ = [kind] * len(features) </span><span class="s0">if </span><span class="s1">isinstance(kind</span><span class="s0">, </span><span class="s1">str) </span><span class="s0">else </span><span class="s1">kind</span>
        <span class="s0">if </span><span class="s1">len(kind_) != len(features):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;When `kind` is provided as a list of strings, it should contain &quot;</span>
                <span class="s4">f&quot;as many elements as `features`. `kind` contains </span><span class="s0">{</span><span class="s1">len(kind_)</span><span class="s0">} </span><span class="s4">&quot;</span>
                <span class="s4">f&quot;element(s) and `features` contains </span><span class="s0">{</span><span class="s1">len(features)</span><span class="s0">} </span><span class="s4">element(s).&quot;</span>
            <span class="s1">)</span>

        <span class="s2"># convert features into a seq of int tuples</span>
        <span class="s1">tmp_features</span><span class="s0">, </span><span class="s1">ice_for_two_way_pd = []</span><span class="s0">, </span><span class="s1">[]</span>
        <span class="s0">for </span><span class="s1">kind_plot</span><span class="s0">, </span><span class="s1">fxs </span><span class="s0">in </span><span class="s1">zip(kind_</span><span class="s0">, </span><span class="s1">features):</span>
            <span class="s0">if </span><span class="s1">isinstance(fxs</span><span class="s0">, </span><span class="s1">(numbers.Integral</span><span class="s0">, </span><span class="s1">str)):</span>
                <span class="s1">fxs = (fxs</span><span class="s0">,</span><span class="s1">)</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">fxs = tuple(</span>
                    <span class="s1">_get_feature_index(fx</span><span class="s0">, </span><span class="s1">feature_names=feature_names) </span><span class="s0">for </span><span class="s1">fx </span><span class="s0">in </span><span class="s1">fxs</span>
                <span class="s1">)</span>
            <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Each entry in features must be either an int, &quot;</span>
                    <span class="s4">&quot;a string, or an iterable of size at most 2.&quot;</span>
                <span class="s1">) </span><span class="s0">from </span><span class="s1">e</span>
            <span class="s0">if not </span><span class="s5">1 </span><span class="s1">&lt;= np.size(fxs) &lt;= </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Each entry in features must be either an int, &quot;</span>
                    <span class="s4">&quot;a string, or an iterable of size at most 2.&quot;</span>
                <span class="s1">)</span>
            <span class="s2"># store the information if 2-way PD was requested with ICE to later</span>
            <span class="s2"># raise a ValueError with an exhaustive list of problematic</span>
            <span class="s2"># settings.</span>
            <span class="s1">ice_for_two_way_pd.append(kind_plot != </span><span class="s4">&quot;average&quot; </span><span class="s0">and </span><span class="s1">np.size(fxs) &gt; </span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">tmp_features.append(fxs)</span>

        <span class="s0">if </span><span class="s1">any(ice_for_two_way_pd):</span>
            <span class="s2"># raise an error and be specific regarding the parameter values</span>
            <span class="s2"># when 1- and 2-way PD were requested</span>
            <span class="s1">kind_ = [</span>
                <span class="s4">&quot;average&quot; </span><span class="s0">if </span><span class="s1">forcing_average </span><span class="s0">else </span><span class="s1">kind_plot</span>
                <span class="s0">for </span><span class="s1">forcing_average</span><span class="s0">, </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">zip(ice_for_two_way_pd</span><span class="s0">, </span><span class="s1">kind_)</span>
            <span class="s1">]</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;ICE plot cannot be rendered for 2-way feature interactions. &quot;</span>
                <span class="s4">&quot;2-way feature interactions mandates PD plots using the &quot;</span>
                <span class="s4">&quot;'average' kind: &quot;</span>
                <span class="s4">f&quot;features=</span><span class="s0">{</span><span class="s1">features</span><span class="s0">!r} </span><span class="s4">should be configured to use &quot;</span>
                <span class="s4">f&quot;kind=</span><span class="s0">{</span><span class="s1">kind_</span><span class="s0">!r} </span><span class="s4">explicitly.&quot;</span>
            <span class="s1">)</span>
        <span class="s1">features = tmp_features</span>

        <span class="s0">if </span><span class="s1">categorical_features </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">is_categorical = [</span>
                <span class="s1">(</span><span class="s0">False,</span><span class="s1">) </span><span class="s0">if </span><span class="s1">len(fxs) == </span><span class="s5">1 </span><span class="s0">else </span><span class="s1">(</span><span class="s0">False, False</span><span class="s1">) </span><span class="s0">for </span><span class="s1">fxs </span><span class="s0">in </span><span class="s1">features</span>
            <span class="s1">]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s2"># we need to create a boolean indicator of which features are</span>
            <span class="s2"># categorical from the categorical_features list.</span>
            <span class="s1">categorical_features = np.array(categorical_features</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s0">if </span><span class="s1">categorical_features.dtype.kind == </span><span class="s4">&quot;b&quot;</span><span class="s1">:</span>
                <span class="s2"># categorical features provided as a list of boolean</span>
                <span class="s0">if </span><span class="s1">categorical_features.size != n_features:</span>
                    <span class="s0">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">&quot;When `categorical_features` is a boolean array-like, &quot;</span>
                        <span class="s4">&quot;the array should be of shape (n_features,). Got &quot;</span>
                        <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">categorical_features.size</span><span class="s0">} </span><span class="s4">elements while `X` contains &quot;</span>
                        <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">n_features</span><span class="s0">} </span><span class="s4">features.&quot;</span>
                    <span class="s1">)</span>
                <span class="s1">is_categorical = [</span>
                    <span class="s1">tuple(categorical_features[fx] </span><span class="s0">for </span><span class="s1">fx </span><span class="s0">in </span><span class="s1">fxs) </span><span class="s0">for </span><span class="s1">fxs </span><span class="s0">in </span><span class="s1">features</span>
                <span class="s1">]</span>
            <span class="s0">elif </span><span class="s1">categorical_features.dtype.kind </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;i&quot;</span><span class="s0">, </span><span class="s4">&quot;O&quot;</span><span class="s0">, </span><span class="s4">&quot;U&quot;</span><span class="s1">):</span>
                <span class="s2"># categorical features provided as a list of indices or feature names</span>
                <span class="s1">categorical_features_idx = [</span>
                    <span class="s1">_get_feature_index(cat</span><span class="s0">, </span><span class="s1">feature_names=feature_names)</span>
                    <span class="s0">for </span><span class="s1">cat </span><span class="s0">in </span><span class="s1">categorical_features</span>
                <span class="s1">]</span>
                <span class="s1">is_categorical = [</span>
                    <span class="s1">tuple([idx </span><span class="s0">in </span><span class="s1">categorical_features_idx </span><span class="s0">for </span><span class="s1">idx </span><span class="s0">in </span><span class="s1">fxs])</span>
                    <span class="s0">for </span><span class="s1">fxs </span><span class="s0">in </span><span class="s1">features</span>
                <span class="s1">]</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Expected `categorical_features` to be an array-like of boolean,&quot;</span>
                    <span class="s4">f&quot; integer, or string. Got </span><span class="s0">{</span><span class="s1">categorical_features.dtype</span><span class="s0">} </span><span class="s4">instead.&quot;</span>
                <span class="s1">)</span>

            <span class="s0">for </span><span class="s1">cats </span><span class="s0">in </span><span class="s1">is_categorical:</span>
                <span class="s0">if </span><span class="s1">np.size(cats) == </span><span class="s5">2 </span><span class="s0">and </span><span class="s1">(cats[</span><span class="s5">0</span><span class="s1">] != cats[</span><span class="s5">1</span><span class="s1">]):</span>
                    <span class="s0">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">&quot;Two-way partial dependence plots are not supported for pairs&quot;</span>
                        <span class="s4">&quot; of continuous and categorical features.&quot;</span>
                    <span class="s1">)</span>

            <span class="s2"># collect the indices of the categorical features targeted by the partial</span>
            <span class="s2"># dependence computation</span>
            <span class="s1">categorical_features_targeted = set(</span>
                <span class="s1">[</span>
                    <span class="s1">fx</span>
                    <span class="s0">for </span><span class="s1">fxs</span><span class="s0">, </span><span class="s1">cats </span><span class="s0">in </span><span class="s1">zip(features</span><span class="s0">, </span><span class="s1">is_categorical)</span>
                    <span class="s0">for </span><span class="s1">fx </span><span class="s0">in </span><span class="s1">fxs</span>
                    <span class="s0">if </span><span class="s1">any(cats)</span>
                <span class="s1">]</span>
            <span class="s1">)</span>
            <span class="s0">if </span><span class="s1">categorical_features_targeted:</span>
                <span class="s1">min_n_cats = min(</span>
                    <span class="s1">[</span>
                        <span class="s1">len(_unique(_safe_indexing(X</span><span class="s0">, </span><span class="s1">idx</span><span class="s0">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)))</span>
                        <span class="s0">for </span><span class="s1">idx </span><span class="s0">in </span><span class="s1">categorical_features_targeted</span>
                    <span class="s1">]</span>
                <span class="s1">)</span>
                <span class="s0">if </span><span class="s1">grid_resolution &lt; min_n_cats:</span>
                    <span class="s0">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">&quot;The resolution of the computed grid is less than the &quot;</span>
                        <span class="s4">&quot;minimum number of categories in the targeted categorical &quot;</span>
                        <span class="s4">&quot;features. Expect the `grid_resolution` to be greater than &quot;</span>
                        <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">min_n_cats</span><span class="s0">}</span><span class="s4">. Got </span><span class="s0">{</span><span class="s1">grid_resolution</span><span class="s0">} </span><span class="s4">instead.&quot;</span>
                    <span class="s1">)</span>

            <span class="s0">for </span><span class="s1">is_cat</span><span class="s0">, </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">zip(is_categorical</span><span class="s0">, </span><span class="s1">kind_):</span>
                <span class="s0">if </span><span class="s1">any(is_cat) </span><span class="s0">and </span><span class="s1">kind_plot != </span><span class="s4">&quot;average&quot;</span><span class="s1">:</span>
                    <span class="s0">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">&quot;It is not possible to display individual effects for&quot;</span>
                        <span class="s4">&quot; categorical features.&quot;</span>
                    <span class="s1">)</span>

        <span class="s2"># Early exit if the axes does not have the correct number of axes</span>
        <span class="s0">if </span><span class="s1">ax </span><span class="s0">is not None and not </span><span class="s1">isinstance(ax</span><span class="s0">, </span><span class="s1">plt.Axes):</span>
            <span class="s1">axes = np.asarray(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s0">if </span><span class="s1">axes.size != len(features):</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Expected ax to have {} axes, got {}&quot;</span><span class="s1">.format(</span>
                        <span class="s1">len(features)</span><span class="s0">, </span><span class="s1">axes.size</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>

        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">chain.from_iterable(features):</span>
            <span class="s0">if </span><span class="s1">i &gt;= len(feature_names):</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;All entries of features must be less than &quot;</span>
                    <span class="s4">&quot;len(feature_names) = {0}, got {1}.&quot;</span><span class="s1">.format(len(feature_names)</span><span class="s0">, </span><span class="s1">i)</span>
                <span class="s1">)</span>

        <span class="s0">if </span><span class="s1">isinstance(subsample</span><span class="s0">, </span><span class="s1">numbers.Integral):</span>
            <span class="s0">if </span><span class="s1">subsample &lt;= </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">f&quot;When an integer, subsample=</span><span class="s0">{</span><span class="s1">subsample</span><span class="s0">} </span><span class="s4">should be positive.&quot;</span>
                <span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">isinstance(subsample</span><span class="s0">, </span><span class="s1">numbers.Real):</span>
            <span class="s0">if </span><span class="s1">subsample &lt;= </span><span class="s5">0 </span><span class="s0">or </span><span class="s1">subsample &gt;= </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">f&quot;When a floating-point, subsample=</span><span class="s0">{</span><span class="s1">subsample</span><span class="s0">} </span><span class="s4">should be in &quot;</span>
                    <span class="s4">&quot;the (0, 1) range.&quot;</span>
                <span class="s1">)</span>

        <span class="s2"># compute predictions and/or averaged predictions</span>
        <span class="s1">pd_results = Parallel(n_jobs=n_jobs</span><span class="s0">, </span><span class="s1">verbose=verbose)(</span>
            <span class="s1">delayed(partial_dependence)(</span>
                <span class="s1">estimator</span><span class="s0">,</span>
                <span class="s1">X</span><span class="s0">,</span>
                <span class="s1">fxs</span><span class="s0">,</span>
                <span class="s1">sample_weight=sample_weight</span><span class="s0">,</span>
                <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
                <span class="s1">categorical_features=categorical_features</span><span class="s0">,</span>
                <span class="s1">response_method=response_method</span><span class="s0">,</span>
                <span class="s1">method=method</span><span class="s0">,</span>
                <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
                <span class="s1">percentiles=percentiles</span><span class="s0">,</span>
                <span class="s1">kind=kind_plot</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s0">for </span><span class="s1">kind_plot</span><span class="s0">, </span><span class="s1">fxs </span><span class="s0">in </span><span class="s1">zip(kind_</span><span class="s0">, </span><span class="s1">features)</span>
        <span class="s1">)</span>

        <span class="s2"># For multioutput regression, we can only check the validity of target</span>
        <span class="s2"># now that we have the predictions.</span>
        <span class="s2"># Also note: as multiclass-multioutput classifiers are not supported,</span>
        <span class="s2"># multiclass and multioutput scenario are mutually exclusive. So there is</span>
        <span class="s2"># no risk of overwriting target_idx here.</span>
        <span class="s1">pd_result = pd_results[</span><span class="s5">0</span><span class="s1">]  </span><span class="s2"># checking the first result is enough</span>
        <span class="s1">n_tasks = (</span>
            <span class="s1">pd_result.average.shape[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s0">if </span><span class="s1">kind_[</span><span class="s5">0</span><span class="s1">] == </span><span class="s4">&quot;average&quot;</span>
            <span class="s0">else </span><span class="s1">pd_result.individual.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">is_regressor(estimator) </span><span class="s0">and </span><span class="s1">n_tasks &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">target </span><span class="s0">is None</span><span class="s1">:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;target must be specified for multi-output regressors&quot;</span><span class="s1">)</span>
            <span class="s0">if not </span><span class="s5">0 </span><span class="s1">&lt;= target &lt;= n_tasks:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;target must be in [0, n_tasks], got {}.&quot;</span><span class="s1">.format(target)</span>
                <span class="s1">)</span>
            <span class="s1">target_idx = target</span>

        <span class="s1">deciles = {}</span>
        <span class="s0">for </span><span class="s1">fxs</span><span class="s0">, </span><span class="s1">cats </span><span class="s0">in </span><span class="s1">zip(features</span><span class="s0">, </span><span class="s1">is_categorical):</span>
            <span class="s0">for </span><span class="s1">fx</span><span class="s0">, </span><span class="s1">cat </span><span class="s0">in </span><span class="s1">zip(fxs</span><span class="s0">, </span><span class="s1">cats):</span>
                <span class="s0">if not </span><span class="s1">cat </span><span class="s0">and </span><span class="s1">fx </span><span class="s0">not in </span><span class="s1">deciles:</span>
                    <span class="s1">X_col = _safe_indexing(X</span><span class="s0">, </span><span class="s1">fx</span><span class="s0">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
                    <span class="s1">deciles[fx] = mquantiles(X_col</span><span class="s0">, </span><span class="s1">prob=np.arange(</span><span class="s5">0.1</span><span class="s0">, </span><span class="s5">1.0</span><span class="s0">, </span><span class="s5">0.1</span><span class="s1">))</span>

        <span class="s1">display = PartialDependenceDisplay(</span>
            <span class="s1">pd_results=pd_results</span><span class="s0">,</span>
            <span class="s1">features=features</span><span class="s0">,</span>
            <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
            <span class="s1">target_idx=target_idx</span><span class="s0">,</span>
            <span class="s1">deciles=deciles</span><span class="s0">,</span>
            <span class="s1">kind=kind</span><span class="s0">,</span>
            <span class="s1">subsample=subsample</span><span class="s0">,</span>
            <span class="s1">random_state=random_state</span><span class="s0">,</span>
            <span class="s1">is_categorical=is_categorical</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s0">return </span><span class="s1">display.plot(</span>
            <span class="s1">ax=ax</span><span class="s0">,</span>
            <span class="s1">n_cols=n_cols</span><span class="s0">,</span>
            <span class="s1">line_kw=line_kw</span><span class="s0">,</span>
            <span class="s1">ice_lines_kw=ice_lines_kw</span><span class="s0">,</span>
            <span class="s1">pd_line_kw=pd_line_kw</span><span class="s0">,</span>
            <span class="s1">contour_kw=contour_kw</span><span class="s0">,</span>
            <span class="s1">centered=centered</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">_get_sample_count(self</span><span class="s0">, </span><span class="s1">n_samples):</span>
        <span class="s3">&quot;&quot;&quot;Compute the number of samples as an integer.&quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">isinstance(self.subsample</span><span class="s0">, </span><span class="s1">numbers.Integral):</span>
            <span class="s0">if </span><span class="s1">self.subsample &lt; n_samples:</span>
                <span class="s0">return </span><span class="s1">self.subsample</span>
            <span class="s0">return </span><span class="s1">n_samples</span>
        <span class="s0">elif </span><span class="s1">isinstance(self.subsample</span><span class="s0">, </span><span class="s1">numbers.Real):</span>
            <span class="s0">return </span><span class="s1">ceil(n_samples * self.subsample)</span>
        <span class="s0">return </span><span class="s1">n_samples</span>

    <span class="s0">def </span><span class="s1">_plot_ice_lines(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">preds</span><span class="s0">,</span>
        <span class="s1">feature_values</span><span class="s0">,</span>
        <span class="s1">n_ice_to_plot</span><span class="s0">,</span>
        <span class="s1">ax</span><span class="s0">,</span>
        <span class="s1">pd_plot_idx</span><span class="s0">,</span>
        <span class="s1">n_total_lines_by_plot</span><span class="s0">,</span>
        <span class="s1">individual_line_kw</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Plot the ICE lines. 
 
        Parameters 
        ---------- 
        preds : ndarray of shape \ 
                (n_instances, n_grid_points) 
            The predictions computed for all points of `feature_values` for a 
            given feature for all samples in `X`. 
        feature_values : ndarray of shape (n_grid_points,) 
            The feature values for which the predictions have been computed. 
        n_ice_to_plot : int 
            The number of ICE lines to plot. 
        ax : Matplotlib axes 
            The axis on which to plot the ICE lines. 
        pd_plot_idx : int 
            The sequential index of the plot. It will be unraveled to find the 
            matching 2D position in the grid layout. 
        n_total_lines_by_plot : int 
            The total number of lines expected to be plot on the axis. 
        individual_line_kw : dict 
            Dict with keywords passed when plotting the ICE lines. 
        &quot;&quot;&quot;</span>
        <span class="s1">rng = check_random_state(self.random_state)</span>
        <span class="s2"># subsample ice</span>
        <span class="s1">ice_lines_idx = rng.choice(</span>
            <span class="s1">preds.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">n_ice_to_plot</span><span class="s0">,</span>
            <span class="s1">replace=</span><span class="s0">False,</span>
        <span class="s1">)</span>
        <span class="s1">ice_lines_subsampled = preds[ice_lines_idx</span><span class="s0">, </span><span class="s1">:]</span>
        <span class="s2"># plot the subsampled ice</span>
        <span class="s0">for </span><span class="s1">ice_idx</span><span class="s0">, </span><span class="s1">ice </span><span class="s0">in </span><span class="s1">enumerate(ice_lines_subsampled):</span>
            <span class="s1">line_idx = np.unravel_index(</span>
                <span class="s1">pd_plot_idx * n_total_lines_by_plot + ice_idx</span><span class="s0">, </span><span class="s1">self.lines_.shape</span>
            <span class="s1">)</span>
            <span class="s1">self.lines_[line_idx] = ax.plot(</span>
                <span class="s1">feature_values</span><span class="s0">, </span><span class="s1">ice.ravel()</span><span class="s0">, </span><span class="s1">**individual_line_kw</span>
            <span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s0">def </span><span class="s1">_plot_average_dependence(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">avg_preds</span><span class="s0">,</span>
        <span class="s1">feature_values</span><span class="s0">,</span>
        <span class="s1">ax</span><span class="s0">,</span>
        <span class="s1">pd_line_idx</span><span class="s0">,</span>
        <span class="s1">line_kw</span><span class="s0">,</span>
        <span class="s1">categorical</span><span class="s0">,</span>
        <span class="s1">bar_kw</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Plot the average partial dependence. 
 
        Parameters 
        ---------- 
        avg_preds : ndarray of shape (n_grid_points,) 
            The average predictions for all points of `feature_values` for a 
            given feature for all samples in `X`. 
        feature_values : ndarray of shape (n_grid_points,) 
            The feature values for which the predictions have been computed. 
        ax : Matplotlib axes 
            The axis on which to plot the average PD. 
        pd_line_idx : int 
            The sequential index of the plot. It will be unraveled to find the 
            matching 2D position in the grid layout. 
        line_kw : dict 
            Dict with keywords passed when plotting the PD plot. 
        categorical : bool 
            Whether feature is categorical. 
        bar_kw: dict 
            Dict with keywords passed when plotting the PD bars (categorical). 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">categorical:</span>
            <span class="s1">bar_idx = np.unravel_index(pd_line_idx</span><span class="s0">, </span><span class="s1">self.bars_.shape)</span>
            <span class="s1">self.bars_[bar_idx] = ax.bar(feature_values</span><span class="s0">, </span><span class="s1">avg_preds</span><span class="s0">, </span><span class="s1">**bar_kw)[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">ax.tick_params(axis=</span><span class="s4">&quot;x&quot;</span><span class="s0">, </span><span class="s1">rotation=</span><span class="s5">90</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">line_idx = np.unravel_index(pd_line_idx</span><span class="s0">, </span><span class="s1">self.lines_.shape)</span>
            <span class="s1">self.lines_[line_idx] = ax.plot(</span>
                <span class="s1">feature_values</span><span class="s0">,</span>
                <span class="s1">avg_preds</span><span class="s0">,</span>
                <span class="s1">**line_kw</span><span class="s0">,</span>
            <span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s0">def </span><span class="s1">_plot_one_way_partial_dependence(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">kind</span><span class="s0">,</span>
        <span class="s1">preds</span><span class="s0">,</span>
        <span class="s1">avg_preds</span><span class="s0">,</span>
        <span class="s1">feature_values</span><span class="s0">,</span>
        <span class="s1">feature_idx</span><span class="s0">,</span>
        <span class="s1">n_ice_lines</span><span class="s0">,</span>
        <span class="s1">ax</span><span class="s0">,</span>
        <span class="s1">n_cols</span><span class="s0">,</span>
        <span class="s1">pd_plot_idx</span><span class="s0">,</span>
        <span class="s1">n_lines</span><span class="s0">,</span>
        <span class="s1">ice_lines_kw</span><span class="s0">,</span>
        <span class="s1">pd_line_kw</span><span class="s0">,</span>
        <span class="s1">categorical</span><span class="s0">,</span>
        <span class="s1">bar_kw</span><span class="s0">,</span>
        <span class="s1">pdp_lim</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Plot 1-way partial dependence: ICE and PDP. 
 
        Parameters 
        ---------- 
        kind : str 
            The kind of partial plot to draw. 
        preds : ndarray of shape \ 
                (n_instances, n_grid_points) or None 
            The predictions computed for all points of `feature_values` for a 
            given feature for all samples in `X`. 
        avg_preds : ndarray of shape (n_grid_points,) 
            The average predictions for all points of `feature_values` for a 
            given feature for all samples in `X`. 
        feature_values : ndarray of shape (n_grid_points,) 
            The feature values for which the predictions have been computed. 
        feature_idx : int 
            The index corresponding to the target feature. 
        n_ice_lines : int 
            The number of ICE lines to plot. 
        ax : Matplotlib axes 
            The axis on which to plot the ICE and PDP lines. 
        n_cols : int or None 
            The number of column in the axis. 
        pd_plot_idx : int 
            The sequential index of the plot. It will be unraveled to find the 
            matching 2D position in the grid layout. 
        n_lines : int 
            The total number of lines expected to be plot on the axis. 
        ice_lines_kw : dict 
            Dict with keywords passed when plotting the ICE lines. 
        pd_line_kw : dict 
            Dict with keywords passed when plotting the PD plot. 
        categorical : bool 
            Whether feature is categorical. 
        bar_kw: dict 
            Dict with keywords passed when plotting the PD bars (categorical). 
        pdp_lim : dict 
            Global min and max average predictions, such that all plots will 
            have the same scale and y limits. `pdp_lim[1]` is the global min 
            and max for single partial dependence curves. 
        &quot;&quot;&quot;</span>
        <span class="s0">from </span><span class="s1">matplotlib </span><span class="s0">import </span><span class="s1">transforms  </span><span class="s2"># noqa</span>

        <span class="s0">if </span><span class="s1">kind </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;individual&quot;</span><span class="s0">, </span><span class="s4">&quot;both&quot;</span><span class="s1">):</span>
            <span class="s1">self._plot_ice_lines(</span>
                <span class="s1">preds[self.target_idx]</span><span class="s0">,</span>
                <span class="s1">feature_values</span><span class="s0">,</span>
                <span class="s1">n_ice_lines</span><span class="s0">,</span>
                <span class="s1">ax</span><span class="s0">,</span>
                <span class="s1">pd_plot_idx</span><span class="s0">,</span>
                <span class="s1">n_lines</span><span class="s0">,</span>
                <span class="s1">ice_lines_kw</span><span class="s0">,</span>
            <span class="s1">)</span>

        <span class="s0">if </span><span class="s1">kind </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;average&quot;</span><span class="s0">, </span><span class="s4">&quot;both&quot;</span><span class="s1">):</span>
            <span class="s2"># the average is stored as the last line</span>
            <span class="s0">if </span><span class="s1">kind == </span><span class="s4">&quot;average&quot;</span><span class="s1">:</span>
                <span class="s1">pd_line_idx = pd_plot_idx</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">pd_line_idx = pd_plot_idx * n_lines + n_ice_lines</span>
            <span class="s1">self._plot_average_dependence(</span>
                <span class="s1">avg_preds[self.target_idx].ravel()</span><span class="s0">,</span>
                <span class="s1">feature_values</span><span class="s0">,</span>
                <span class="s1">ax</span><span class="s0">,</span>
                <span class="s1">pd_line_idx</span><span class="s0">,</span>
                <span class="s1">pd_line_kw</span><span class="s0">,</span>
                <span class="s1">categorical</span><span class="s0">,</span>
                <span class="s1">bar_kw</span><span class="s0">,</span>
            <span class="s1">)</span>

        <span class="s1">trans = transforms.blended_transform_factory(ax.transData</span><span class="s0">, </span><span class="s1">ax.transAxes)</span>
        <span class="s2"># create the decile line for the vertical axis</span>
        <span class="s1">vlines_idx = np.unravel_index(pd_plot_idx</span><span class="s0">, </span><span class="s1">self.deciles_vlines_.shape)</span>
        <span class="s0">if </span><span class="s1">self.deciles.get(feature_idx[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, None</span><span class="s1">) </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">self.deciles_vlines_[vlines_idx] = ax.vlines(</span>
                <span class="s1">self.deciles[feature_idx[</span><span class="s5">0</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s5">0</span><span class="s0">,</span>
                <span class="s5">0.05</span><span class="s0">,</span>
                <span class="s1">transform=trans</span><span class="s0">,</span>
                <span class="s1">color=</span><span class="s4">&quot;k&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
        <span class="s2"># reset ylim which was overwritten by vlines</span>
        <span class="s1">min_val = min(val[</span><span class="s5">0</span><span class="s1">] </span><span class="s0">for </span><span class="s1">val </span><span class="s0">in </span><span class="s1">pdp_lim.values())</span>
        <span class="s1">max_val = max(val[</span><span class="s5">1</span><span class="s1">] </span><span class="s0">for </span><span class="s1">val </span><span class="s0">in </span><span class="s1">pdp_lim.values())</span>
        <span class="s1">ax.set_ylim([min_val</span><span class="s0">, </span><span class="s1">max_val])</span>

        <span class="s2"># Set xlabel if it is not already set</span>
        <span class="s0">if not </span><span class="s1">ax.get_xlabel():</span>
            <span class="s1">ax.set_xlabel(self.feature_names[feature_idx[</span><span class="s5">0</span><span class="s1">]])</span>

        <span class="s0">if </span><span class="s1">n_cols </span><span class="s0">is None or </span><span class="s1">pd_plot_idx % n_cols == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s0">if not </span><span class="s1">ax.get_ylabel():</span>
                <span class="s1">ax.set_ylabel(</span><span class="s4">&quot;Partial dependence&quot;</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">ax.set_yticklabels([])</span>

        <span class="s0">if </span><span class="s1">pd_line_kw.get(</span><span class="s4">&quot;label&quot;</span><span class="s0">, None</span><span class="s1">) </span><span class="s0">and </span><span class="s1">kind != </span><span class="s4">&quot;individual&quot; </span><span class="s0">and not </span><span class="s1">categorical:</span>
            <span class="s1">ax.legend()</span>

    <span class="s0">def </span><span class="s1">_plot_two_way_partial_dependence(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">avg_preds</span><span class="s0">,</span>
        <span class="s1">feature_values</span><span class="s0">,</span>
        <span class="s1">feature_idx</span><span class="s0">,</span>
        <span class="s1">ax</span><span class="s0">,</span>
        <span class="s1">pd_plot_idx</span><span class="s0">,</span>
        <span class="s1">Z_level</span><span class="s0">,</span>
        <span class="s1">contour_kw</span><span class="s0">,</span>
        <span class="s1">categorical</span><span class="s0">,</span>
        <span class="s1">heatmap_kw</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Plot 2-way partial dependence. 
 
        Parameters 
        ---------- 
        avg_preds : ndarray of shape \ 
                (n_instances, n_grid_points, n_grid_points) 
            The average predictions for all points of `feature_values[0]` and 
            `feature_values[1]` for some given features for all samples in `X`. 
        feature_values : seq of 1d array 
            A sequence of array of the feature values for which the predictions 
            have been computed. 
        feature_idx : tuple of int 
            The indices of the target features 
        ax : Matplotlib axes 
            The axis on which to plot the ICE and PDP lines. 
        pd_plot_idx : int 
            The sequential index of the plot. It will be unraveled to find the 
            matching 2D position in the grid layout. 
        Z_level : ndarray of shape (8, 8) 
            The Z-level used to encode the average predictions. 
        contour_kw : dict 
            Dict with keywords passed when plotting the contours. 
        categorical : bool 
            Whether features are categorical. 
        heatmap_kw: dict 
            Dict with keywords passed when plotting the PD heatmap 
            (categorical). 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">categorical:</span>
            <span class="s0">import </span><span class="s1">matplotlib.pyplot </span><span class="s0">as </span><span class="s1">plt</span>

            <span class="s1">default_im_kw = dict(interpolation=</span><span class="s4">&quot;nearest&quot;</span><span class="s0">, </span><span class="s1">cmap=</span><span class="s4">&quot;viridis&quot;</span><span class="s1">)</span>
            <span class="s1">im_kw = {**default_im_kw</span><span class="s0">, </span><span class="s1">**heatmap_kw}</span>

            <span class="s1">data = avg_preds[self.target_idx]</span>
            <span class="s1">im = ax.imshow(data</span><span class="s0">, </span><span class="s1">**im_kw)</span>
            <span class="s1">text = </span><span class="s0">None</span>
            <span class="s1">cmap_min</span><span class="s0">, </span><span class="s1">cmap_max = im.cmap(</span><span class="s5">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">im.cmap(</span><span class="s5">1.0</span><span class="s1">)</span>

            <span class="s1">text = np.empty_like(data</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s2"># print text with appropriate color depending on background</span>
            <span class="s1">thresh = (data.max() + data.min()) / </span><span class="s5">2.0</span>

            <span class="s0">for </span><span class="s1">flat_index </span><span class="s0">in </span><span class="s1">range(data.size):</span>
                <span class="s1">row</span><span class="s0">, </span><span class="s1">col = np.unravel_index(flat_index</span><span class="s0">, </span><span class="s1">data.shape)</span>
                <span class="s1">color = cmap_max </span><span class="s0">if </span><span class="s1">data[row</span><span class="s0">, </span><span class="s1">col] &lt; thresh </span><span class="s0">else </span><span class="s1">cmap_min</span>

                <span class="s1">values_format = </span><span class="s4">&quot;.2f&quot;</span>
                <span class="s1">text_data = format(data[row</span><span class="s0">, </span><span class="s1">col]</span><span class="s0">, </span><span class="s1">values_format)</span>

                <span class="s1">text_kwargs = dict(ha=</span><span class="s4">&quot;center&quot;</span><span class="s0">, </span><span class="s1">va=</span><span class="s4">&quot;center&quot;</span><span class="s0">, </span><span class="s1">color=color)</span>
                <span class="s1">text[row</span><span class="s0">, </span><span class="s1">col] = ax.text(col</span><span class="s0">, </span><span class="s1">row</span><span class="s0">, </span><span class="s1">text_data</span><span class="s0">, </span><span class="s1">**text_kwargs)</span>

            <span class="s1">fig = ax.figure</span>
            <span class="s1">fig.colorbar(im</span><span class="s0">, </span><span class="s1">ax=ax)</span>
            <span class="s1">ax.set(</span>
                <span class="s1">xticks=np.arange(len(feature_values[</span><span class="s5">1</span><span class="s1">]))</span><span class="s0">,</span>
                <span class="s1">yticks=np.arange(len(feature_values[</span><span class="s5">0</span><span class="s1">]))</span><span class="s0">,</span>
                <span class="s1">xticklabels=feature_values[</span><span class="s5">1</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">yticklabels=feature_values[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">xlabel=self.feature_names[feature_idx[</span><span class="s5">1</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s1">ylabel=self.feature_names[feature_idx[</span><span class="s5">0</span><span class="s1">]]</span><span class="s0">,</span>
            <span class="s1">)</span>

            <span class="s1">plt.setp(ax.get_xticklabels()</span><span class="s0">, </span><span class="s1">rotation=</span><span class="s4">&quot;vertical&quot;</span><span class="s1">)</span>

            <span class="s1">heatmap_idx = np.unravel_index(pd_plot_idx</span><span class="s0">, </span><span class="s1">self.heatmaps_.shape)</span>
            <span class="s1">self.heatmaps_[heatmap_idx] = im</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">from </span><span class="s1">matplotlib </span><span class="s0">import </span><span class="s1">transforms  </span><span class="s2"># noqa</span>

            <span class="s1">XX</span><span class="s0">, </span><span class="s1">YY = np.meshgrid(feature_values[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">feature_values[</span><span class="s5">1</span><span class="s1">])</span>
            <span class="s1">Z = avg_preds[self.target_idx].T</span>
            <span class="s1">CS = ax.contour(XX</span><span class="s0">, </span><span class="s1">YY</span><span class="s0">, </span><span class="s1">Z</span><span class="s0">, </span><span class="s1">levels=Z_level</span><span class="s0">, </span><span class="s1">linewidths=</span><span class="s5">0.5</span><span class="s0">, </span><span class="s1">colors=</span><span class="s4">&quot;k&quot;</span><span class="s1">)</span>
            <span class="s1">contour_idx = np.unravel_index(pd_plot_idx</span><span class="s0">, </span><span class="s1">self.contours_.shape)</span>
            <span class="s1">self.contours_[contour_idx] = ax.contourf(</span>
                <span class="s1">XX</span><span class="s0">,</span>
                <span class="s1">YY</span><span class="s0">,</span>
                <span class="s1">Z</span><span class="s0">,</span>
                <span class="s1">levels=Z_level</span><span class="s0">,</span>
                <span class="s1">vmax=Z_level[-</span><span class="s5">1</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">vmin=Z_level[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">**contour_kw</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">ax.clabel(CS</span><span class="s0">, </span><span class="s1">fmt=</span><span class="s4">&quot;%2.2f&quot;</span><span class="s0">, </span><span class="s1">colors=</span><span class="s4">&quot;k&quot;</span><span class="s0">, </span><span class="s1">fontsize=</span><span class="s5">10</span><span class="s0">, </span><span class="s1">inline=</span><span class="s0">True</span><span class="s1">)</span>

            <span class="s1">trans = transforms.blended_transform_factory(ax.transData</span><span class="s0">, </span><span class="s1">ax.transAxes)</span>
            <span class="s2"># create the decile line for the vertical axis</span>
            <span class="s1">xlim</span><span class="s0">, </span><span class="s1">ylim = ax.get_xlim()</span><span class="s0">, </span><span class="s1">ax.get_ylim()</span>
            <span class="s1">vlines_idx = np.unravel_index(pd_plot_idx</span><span class="s0">, </span><span class="s1">self.deciles_vlines_.shape)</span>
            <span class="s1">self.deciles_vlines_[vlines_idx] = ax.vlines(</span>
                <span class="s1">self.deciles[feature_idx[</span><span class="s5">0</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s5">0</span><span class="s0">,</span>
                <span class="s5">0.05</span><span class="s0">,</span>
                <span class="s1">transform=trans</span><span class="s0">,</span>
                <span class="s1">color=</span><span class="s4">&quot;k&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s2"># create the decile line for the horizontal axis</span>
            <span class="s1">hlines_idx = np.unravel_index(pd_plot_idx</span><span class="s0">, </span><span class="s1">self.deciles_hlines_.shape)</span>
            <span class="s1">self.deciles_hlines_[hlines_idx] = ax.hlines(</span>
                <span class="s1">self.deciles[feature_idx[</span><span class="s5">1</span><span class="s1">]]</span><span class="s0">,</span>
                <span class="s5">0</span><span class="s0">,</span>
                <span class="s5">0.05</span><span class="s0">,</span>
                <span class="s1">transform=trans</span><span class="s0">,</span>
                <span class="s1">color=</span><span class="s4">&quot;k&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s2"># reset xlim and ylim since they are overwritten by hlines and</span>
            <span class="s2"># vlines</span>
            <span class="s1">ax.set_xlim(xlim)</span>
            <span class="s1">ax.set_ylim(ylim)</span>

            <span class="s2"># set xlabel if it is not already set</span>
            <span class="s0">if not </span><span class="s1">ax.get_xlabel():</span>
                <span class="s1">ax.set_xlabel(self.feature_names[feature_idx[</span><span class="s5">0</span><span class="s1">]])</span>
            <span class="s1">ax.set_ylabel(self.feature_names[feature_idx[</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s0">def </span><span class="s1">plot(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">*</span><span class="s0">,</span>
        <span class="s1">ax=</span><span class="s0">None,</span>
        <span class="s1">n_cols=</span><span class="s5">3</span><span class="s0">,</span>
        <span class="s1">line_kw=</span><span class="s0">None,</span>
        <span class="s1">ice_lines_kw=</span><span class="s0">None,</span>
        <span class="s1">pd_line_kw=</span><span class="s0">None,</span>
        <span class="s1">contour_kw=</span><span class="s0">None,</span>
        <span class="s1">bar_kw=</span><span class="s0">None,</span>
        <span class="s1">heatmap_kw=</span><span class="s0">None,</span>
        <span class="s1">pdp_lim=</span><span class="s0">None,</span>
        <span class="s1">centered=</span><span class="s0">False,</span>
    <span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;Plot partial dependence plots. 
 
        Parameters 
        ---------- 
        ax : Matplotlib axes or array-like of Matplotlib axes, default=None 
            - If a single axis is passed in, it is treated as a bounding axes 
                and a grid of partial dependence plots will be drawn within 
                these bounds. The `n_cols` parameter controls the number of 
                columns in the grid. 
            - If an array-like of axes are passed in, the partial dependence 
                plots will be drawn directly into these axes. 
            - If `None`, a figure and a bounding axes is created and treated 
                as the single axes case. 
 
        n_cols : int, default=3 
            The maximum number of columns in the grid plot. Only active when 
            `ax` is a single axes or `None`. 
 
        line_kw : dict, default=None 
            Dict with keywords passed to the `matplotlib.pyplot.plot` call. 
            For one-way partial dependence plots. 
 
        ice_lines_kw : dict, default=None 
            Dictionary with keywords passed to the `matplotlib.pyplot.plot` call. 
            For ICE lines in the one-way partial dependence plots. 
            The key value pairs defined in `ice_lines_kw` takes priority over 
            `line_kw`. 
 
            .. versionadded:: 1.0 
 
        pd_line_kw : dict, default=None 
            Dictionary with keywords passed to the `matplotlib.pyplot.plot` call. 
            For partial dependence in one-way partial dependence plots. 
            The key value pairs defined in `pd_line_kw` takes priority over 
            `line_kw`. 
 
            .. versionadded:: 1.0 
 
        contour_kw : dict, default=None 
            Dict with keywords passed to the `matplotlib.pyplot.contourf` 
            call for two-way partial dependence plots. 
 
        bar_kw : dict, default=None 
            Dict with keywords passed to the `matplotlib.pyplot.bar` 
            call for one-way categorical partial dependence plots. 
 
            .. versionadded:: 1.2 
 
        heatmap_kw : dict, default=None 
            Dict with keywords passed to the `matplotlib.pyplot.imshow` 
            call for two-way categorical partial dependence plots. 
 
            .. versionadded:: 1.2 
 
        pdp_lim : dict, default=None 
            Global min and max average predictions, such that all plots will have the 
            same scale and y limits. `pdp_lim[1]` is the global min and max for single 
            partial dependence curves. `pdp_lim[2]` is the global min and max for 
            two-way partial dependence curves. If `None` (default), the limit will be 
            inferred from the global minimum and maximum of all predictions. 
 
            .. versionadded:: 1.1 
 
        centered : bool, default=False 
            If `True`, the ICE and PD lines will start at the origin of the 
            y-axis. By default, no centering is done. 
 
            .. versionadded:: 1.1 
 
        Returns 
        ------- 
        display : :class:`~sklearn.inspection.PartialDependenceDisplay` 
            Returns a :class:`~sklearn.inspection.PartialDependenceDisplay` 
            object that contains the partial dependence plots. 
        &quot;&quot;&quot;</span>

        <span class="s1">check_matplotlib_support(</span><span class="s4">&quot;plot_partial_dependence&quot;</span><span class="s1">)</span>
        <span class="s0">import </span><span class="s1">matplotlib.pyplot </span><span class="s0">as </span><span class="s1">plt  </span><span class="s2"># noqa</span>
        <span class="s0">from </span><span class="s1">matplotlib.gridspec </span><span class="s0">import </span><span class="s1">GridSpecFromSubplotSpec  </span><span class="s2"># noqa</span>

        <span class="s0">if </span><span class="s1">isinstance(self.kind</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">kind = [self.kind] * len(self.features)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">kind = self.kind</span>

        <span class="s0">if </span><span class="s1">self.is_categorical </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">is_categorical = [</span>
                <span class="s1">(</span><span class="s0">False,</span><span class="s1">) </span><span class="s0">if </span><span class="s1">len(fx) == </span><span class="s5">1 </span><span class="s0">else </span><span class="s1">(</span><span class="s0">False, False</span><span class="s1">) </span><span class="s0">for </span><span class="s1">fx </span><span class="s0">in </span><span class="s1">self.features</span>
            <span class="s1">]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">is_categorical = self.is_categorical</span>

        <span class="s0">if </span><span class="s1">len(kind) != len(self.features):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;When `kind` is provided as a list of strings, it should &quot;</span>
                <span class="s4">&quot;contain as many elements as `features`. `kind` contains &quot;</span>
                <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">len(kind)</span><span class="s0">} </span><span class="s4">element(s) and `features` contains &quot;</span>
                <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">len(self.features)</span><span class="s0">} </span><span class="s4">element(s).&quot;</span>
            <span class="s1">)</span>

        <span class="s1">valid_kinds = {</span><span class="s4">&quot;average&quot;</span><span class="s0">, </span><span class="s4">&quot;individual&quot;</span><span class="s0">, </span><span class="s4">&quot;both&quot;</span><span class="s1">}</span>
        <span class="s0">if </span><span class="s1">any([k </span><span class="s0">not in </span><span class="s1">valid_kinds </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">kind]):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;Values provided to `kind` must be one of: </span><span class="s0">{</span><span class="s1">valid_kinds</span><span class="s0">!r} </span><span class="s4">or a list&quot;</span>
                <span class="s4">f&quot; of such values. Currently, kind=</span><span class="s0">{</span><span class="s1">self.kind</span><span class="s0">!r}</span><span class="s4">&quot;</span>
            <span class="s1">)</span>

        <span class="s2"># Center results before plotting</span>
        <span class="s0">if not </span><span class="s1">centered:</span>
            <span class="s1">pd_results_ = self.pd_results</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">pd_results_ = []</span>
            <span class="s0">for </span><span class="s1">kind_plot</span><span class="s0">, </span><span class="s1">pd_result </span><span class="s0">in </span><span class="s1">zip(kind</span><span class="s0">, </span><span class="s1">self.pd_results):</span>
                <span class="s1">current_results = {</span><span class="s4">&quot;grid_values&quot;</span><span class="s1">: pd_result[</span><span class="s4">&quot;grid_values&quot;</span><span class="s1">]}</span>

                <span class="s0">if </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;individual&quot;</span><span class="s0">, </span><span class="s4">&quot;both&quot;</span><span class="s1">):</span>
                    <span class="s1">preds = pd_result.individual</span>
                    <span class="s1">preds = preds - preds[self.target_idx</span><span class="s0">, </span><span class="s1">:</span><span class="s0">, </span><span class="s5">0</span><span class="s0">, None</span><span class="s1">]</span>
                    <span class="s1">current_results[</span><span class="s4">&quot;individual&quot;</span><span class="s1">] = preds</span>

                <span class="s0">if </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;average&quot;</span><span class="s0">, </span><span class="s4">&quot;both&quot;</span><span class="s1">):</span>
                    <span class="s1">avg_preds = pd_result.average</span>
                    <span class="s1">avg_preds = avg_preds - avg_preds[self.target_idx</span><span class="s0">, </span><span class="s5">0</span><span class="s0">, None</span><span class="s1">]</span>
                    <span class="s1">current_results[</span><span class="s4">&quot;average&quot;</span><span class="s1">] = avg_preds</span>

                <span class="s1">pd_results_.append(Bunch(**current_results))</span>

        <span class="s0">if </span><span class="s1">pdp_lim </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s2"># get global min and max average predictions of PD grouped by plot type</span>
            <span class="s1">pdp_lim = {}</span>
            <span class="s0">for </span><span class="s1">kind_plot</span><span class="s0">, </span><span class="s1">pdp </span><span class="s0">in </span><span class="s1">zip(kind</span><span class="s0">, </span><span class="s1">pd_results_):</span>
                <span class="s1">values = pdp[</span><span class="s4">&quot;grid_values&quot;</span><span class="s1">]</span>
                <span class="s1">preds = pdp.average </span><span class="s0">if </span><span class="s1">kind_plot == </span><span class="s4">&quot;average&quot; </span><span class="s0">else </span><span class="s1">pdp.individual</span>
                <span class="s1">min_pd = preds[self.target_idx].min()</span>
                <span class="s1">max_pd = preds[self.target_idx].max()</span>

                <span class="s2"># expand the limits to account so that the plotted lines do not touch</span>
                <span class="s2"># the edges of the plot</span>
                <span class="s1">span = max_pd - min_pd</span>
                <span class="s1">min_pd -= </span><span class="s5">0.05 </span><span class="s1">* span</span>
                <span class="s1">max_pd += </span><span class="s5">0.05 </span><span class="s1">* span</span>

                <span class="s1">n_fx = len(values)</span>
                <span class="s1">old_min_pd</span><span class="s0">, </span><span class="s1">old_max_pd = pdp_lim.get(n_fx</span><span class="s0">, </span><span class="s1">(min_pd</span><span class="s0">, </span><span class="s1">max_pd))</span>
                <span class="s1">min_pd = min(min_pd</span><span class="s0">, </span><span class="s1">old_min_pd)</span>
                <span class="s1">max_pd = max(max_pd</span><span class="s0">, </span><span class="s1">old_max_pd)</span>
                <span class="s1">pdp_lim[n_fx] = (min_pd</span><span class="s0">, </span><span class="s1">max_pd)</span>

        <span class="s0">if </span><span class="s1">line_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">line_kw = {}</span>
        <span class="s0">if </span><span class="s1">ice_lines_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">ice_lines_kw = {}</span>
        <span class="s0">if </span><span class="s1">pd_line_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">pd_line_kw = {}</span>
        <span class="s0">if </span><span class="s1">bar_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">bar_kw = {}</span>
        <span class="s0">if </span><span class="s1">heatmap_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">heatmap_kw = {}</span>

        <span class="s0">if </span><span class="s1">ax </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">_</span><span class="s0">, </span><span class="s1">ax = plt.subplots()</span>

        <span class="s0">if </span><span class="s1">contour_kw </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">contour_kw = {}</span>
        <span class="s1">default_contour_kws = {</span><span class="s4">&quot;alpha&quot;</span><span class="s1">: </span><span class="s5">0.75</span><span class="s1">}</span>
        <span class="s1">contour_kw = {**default_contour_kws</span><span class="s0">, </span><span class="s1">**contour_kw}</span>

        <span class="s1">n_features = len(self.features)</span>
        <span class="s1">is_average_plot = [kind_plot == </span><span class="s4">&quot;average&quot; </span><span class="s0">for </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">kind]</span>
        <span class="s0">if </span><span class="s1">all(is_average_plot):</span>
            <span class="s2"># only average plots are requested</span>
            <span class="s1">n_ice_lines = </span><span class="s5">0</span>
            <span class="s1">n_lines = </span><span class="s5">1</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s2"># we need to determine the number of ICE samples computed</span>
            <span class="s1">ice_plot_idx = is_average_plot.index(</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s1">n_ice_lines = self._get_sample_count(</span>
                <span class="s1">len(pd_results_[ice_plot_idx].individual[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s1">)</span>
            <span class="s0">if </span><span class="s1">any([kind_plot == </span><span class="s4">&quot;both&quot; </span><span class="s0">for </span><span class="s1">kind_plot </span><span class="s0">in </span><span class="s1">kind]):</span>
                <span class="s1">n_lines = n_ice_lines + </span><span class="s5">1  </span><span class="s2"># account for the average line</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">n_lines = n_ice_lines</span>

        <span class="s0">if </span><span class="s1">isinstance(ax</span><span class="s0">, </span><span class="s1">plt.Axes):</span>
            <span class="s2"># If ax was set off, it has most likely been set to off</span>
            <span class="s2"># by a previous call to plot.</span>
            <span class="s0">if not </span><span class="s1">ax.axison:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;The ax was already used in another plot &quot;</span>
                    <span class="s4">&quot;function, please set ax=display.axes_ &quot;</span>
                    <span class="s4">&quot;instead&quot;</span>
                <span class="s1">)</span>

            <span class="s1">ax.set_axis_off()</span>
            <span class="s1">self.bounding_ax_ = ax</span>
            <span class="s1">self.figure_ = ax.figure</span>

            <span class="s1">n_cols = min(n_cols</span><span class="s0">, </span><span class="s1">n_features)</span>
            <span class="s1">n_rows = int(np.ceil(n_features / float(n_cols)))</span>

            <span class="s1">self.axes_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s0">if </span><span class="s1">all(is_average_plot):</span>
                <span class="s1">self.lines_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self.lines_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols</span><span class="s0">, </span><span class="s1">n_lines)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.contours_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.bars_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.heatmaps_ = np.empty((n_rows</span><span class="s0">, </span><span class="s1">n_cols)</span><span class="s0">, </span><span class="s1">dtype=object)</span>

            <span class="s1">axes_ravel = self.axes_.ravel()</span>

            <span class="s1">gs = GridSpecFromSubplotSpec(</span>
                <span class="s1">n_rows</span><span class="s0">, </span><span class="s1">n_cols</span><span class="s0">, </span><span class="s1">subplot_spec=ax.get_subplotspec()</span>
            <span class="s1">)</span>
            <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">spec </span><span class="s0">in </span><span class="s1">zip(range(n_features)</span><span class="s0">, </span><span class="s1">gs):</span>
                <span class="s1">axes_ravel[i] = self.figure_.add_subplot(spec)</span>

        <span class="s0">else</span><span class="s1">:  </span><span class="s2"># array-like</span>
            <span class="s1">ax = np.asarray(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s0">if </span><span class="s1">ax.size != n_features:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Expected ax to have {} axes, got {}&quot;</span><span class="s1">.format(n_features</span><span class="s0">, </span><span class="s1">ax.size)</span>
                <span class="s1">)</span>

            <span class="s0">if </span><span class="s1">ax.ndim == </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s1">n_cols = ax.shape[</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">n_cols = </span><span class="s0">None</span>

            <span class="s1">self.bounding_ax_ = </span><span class="s0">None</span>
            <span class="s1">self.figure_ = ax.ravel()[</span><span class="s5">0</span><span class="s1">].figure</span>
            <span class="s1">self.axes_ = ax</span>
            <span class="s0">if </span><span class="s1">all(is_average_plot):</span>
                <span class="s1">self.lines_ = np.empty_like(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self.lines_ = np.empty(ax.shape + (n_lines</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.contours_ = np.empty_like(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.bars_ = np.empty_like(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>
            <span class="s1">self.heatmaps_ = np.empty_like(ax</span><span class="s0">, </span><span class="s1">dtype=object)</span>

        <span class="s2"># create contour levels for two-way plots</span>
        <span class="s0">if </span><span class="s5">2 </span><span class="s0">in </span><span class="s1">pdp_lim:</span>
            <span class="s1">Z_level = np.linspace(*pdp_lim[</span><span class="s5">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">num=</span><span class="s5">8</span><span class="s1">)</span>

        <span class="s1">self.deciles_vlines_ = np.empty_like(self.axes_</span><span class="s0">, </span><span class="s1">dtype=object)</span>
        <span class="s1">self.deciles_hlines_ = np.empty_like(self.axes_</span><span class="s0">, </span><span class="s1">dtype=object)</span>

        <span class="s0">for </span><span class="s1">pd_plot_idx</span><span class="s0">, </span><span class="s1">(axi</span><span class="s0">, </span><span class="s1">feature_idx</span><span class="s0">, </span><span class="s1">cat</span><span class="s0">, </span><span class="s1">pd_result</span><span class="s0">, </span><span class="s1">kind_plot) </span><span class="s0">in </span><span class="s1">enumerate(</span>
            <span class="s1">zip(</span>
                <span class="s1">self.axes_.ravel()</span><span class="s0">,</span>
                <span class="s1">self.features</span><span class="s0">,</span>
                <span class="s1">is_categorical</span><span class="s0">,</span>
                <span class="s1">pd_results_</span><span class="s0">,</span>
                <span class="s1">kind</span><span class="s0">,</span>
            <span class="s1">)</span>
        <span class="s1">):</span>
            <span class="s1">avg_preds = </span><span class="s0">None</span>
            <span class="s1">preds = </span><span class="s0">None</span>
            <span class="s1">feature_values = pd_result[</span><span class="s4">&quot;grid_values&quot;</span><span class="s1">]</span>
            <span class="s0">if </span><span class="s1">kind_plot == </span><span class="s4">&quot;individual&quot;</span><span class="s1">:</span>
                <span class="s1">preds = pd_result.individual</span>
            <span class="s0">elif </span><span class="s1">kind_plot == </span><span class="s4">&quot;average&quot;</span><span class="s1">:</span>
                <span class="s1">avg_preds = pd_result.average</span>
            <span class="s0">else</span><span class="s1">:  </span><span class="s2"># kind_plot == 'both'</span>
                <span class="s1">avg_preds = pd_result.average</span>
                <span class="s1">preds = pd_result.individual</span>

            <span class="s0">if </span><span class="s1">len(feature_values) == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2"># define the line-style for the current plot</span>
                <span class="s1">default_line_kws = {</span>
                    <span class="s4">&quot;color&quot;</span><span class="s1">: </span><span class="s4">&quot;C0&quot;</span><span class="s0">,</span>
                    <span class="s4">&quot;label&quot;</span><span class="s1">: </span><span class="s4">&quot;average&quot; </span><span class="s0">if </span><span class="s1">kind_plot == </span><span class="s4">&quot;both&quot; </span><span class="s0">else None,</span>
                <span class="s1">}</span>
                <span class="s0">if </span><span class="s1">kind_plot == </span><span class="s4">&quot;individual&quot;</span><span class="s1">:</span>
                    <span class="s1">default_ice_lines_kws = {</span><span class="s4">&quot;alpha&quot;</span><span class="s1">: </span><span class="s5">0.3</span><span class="s0">, </span><span class="s4">&quot;linewidth&quot;</span><span class="s1">: </span><span class="s5">0.5</span><span class="s1">}</span>
                    <span class="s1">default_pd_lines_kws = {}</span>
                <span class="s0">elif </span><span class="s1">kind_plot == </span><span class="s4">&quot;both&quot;</span><span class="s1">:</span>
                    <span class="s2"># by default, we need to distinguish the average line from</span>
                    <span class="s2"># the individual lines via color and line style</span>
                    <span class="s1">default_ice_lines_kws = {</span>
                        <span class="s4">&quot;alpha&quot;</span><span class="s1">: </span><span class="s5">0.3</span><span class="s0">,</span>
                        <span class="s4">&quot;linewidth&quot;</span><span class="s1">: </span><span class="s5">0.5</span><span class="s0">,</span>
                        <span class="s4">&quot;color&quot;</span><span class="s1">: </span><span class="s4">&quot;tab:blue&quot;</span><span class="s0">,</span>
                    <span class="s1">}</span>
                    <span class="s1">default_pd_lines_kws = {</span>
                        <span class="s4">&quot;color&quot;</span><span class="s1">: </span><span class="s4">&quot;tab:orange&quot;</span><span class="s0">,</span>
                        <span class="s4">&quot;linestyle&quot;</span><span class="s1">: </span><span class="s4">&quot;--&quot;</span><span class="s0">,</span>
                    <span class="s1">}</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">default_ice_lines_kws = {}</span>
                    <span class="s1">default_pd_lines_kws = {}</span>

                <span class="s1">ice_lines_kw = {</span>
                    <span class="s1">**default_line_kws</span><span class="s0">,</span>
                    <span class="s1">**default_ice_lines_kws</span><span class="s0">,</span>
                    <span class="s1">**line_kw</span><span class="s0">,</span>
                    <span class="s1">**ice_lines_kw</span><span class="s0">,</span>
                <span class="s1">}</span>
                <span class="s0">del </span><span class="s1">ice_lines_kw[</span><span class="s4">&quot;label&quot;</span><span class="s1">]</span>

                <span class="s1">pd_line_kw = {</span>
                    <span class="s1">**default_line_kws</span><span class="s0">,</span>
                    <span class="s1">**default_pd_lines_kws</span><span class="s0">,</span>
                    <span class="s1">**line_kw</span><span class="s0">,</span>
                    <span class="s1">**pd_line_kw</span><span class="s0">,</span>
                <span class="s1">}</span>

                <span class="s1">default_bar_kws = {</span><span class="s4">&quot;color&quot;</span><span class="s1">: </span><span class="s4">&quot;C0&quot;</span><span class="s1">}</span>
                <span class="s1">bar_kw = {**default_bar_kws</span><span class="s0">, </span><span class="s1">**bar_kw}</span>

                <span class="s1">default_heatmap_kw = {}</span>
                <span class="s1">heatmap_kw = {**default_heatmap_kw</span><span class="s0">, </span><span class="s1">**heatmap_kw}</span>

                <span class="s1">self._plot_one_way_partial_dependence(</span>
                    <span class="s1">kind_plot</span><span class="s0">,</span>
                    <span class="s1">preds</span><span class="s0">,</span>
                    <span class="s1">avg_preds</span><span class="s0">,</span>
                    <span class="s1">feature_values[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">feature_idx</span><span class="s0">,</span>
                    <span class="s1">n_ice_lines</span><span class="s0">,</span>
                    <span class="s1">axi</span><span class="s0">,</span>
                    <span class="s1">n_cols</span><span class="s0">,</span>
                    <span class="s1">pd_plot_idx</span><span class="s0">,</span>
                    <span class="s1">n_lines</span><span class="s0">,</span>
                    <span class="s1">ice_lines_kw</span><span class="s0">,</span>
                    <span class="s1">pd_line_kw</span><span class="s0">,</span>
                    <span class="s1">cat[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">bar_kw</span><span class="s0">,</span>
                    <span class="s1">pdp_lim</span><span class="s0">,</span>
                <span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self._plot_two_way_partial_dependence(</span>
                    <span class="s1">avg_preds</span><span class="s0">,</span>
                    <span class="s1">feature_values</span><span class="s0">,</span>
                    <span class="s1">feature_idx</span><span class="s0">,</span>
                    <span class="s1">axi</span><span class="s0">,</span>
                    <span class="s1">pd_plot_idx</span><span class="s0">,</span>
                    <span class="s1">Z_level</span><span class="s0">,</span>
                    <span class="s1">contour_kw</span><span class="s0">,</span>
                    <span class="s1">cat[</span><span class="s5">0</span><span class="s1">] </span><span class="s0">and </span><span class="s1">cat[</span><span class="s5">1</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">heatmap_kw</span><span class="s0">,</span>
                <span class="s1">)</span>

        <span class="s0">return </span><span class="s1">self</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_common_curve_display.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_common_curve_display.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">ClassifierMixin</span><span class="s0">, </span><span class="s1">clone</span>
<span class="s0">from </span><span class="s1">sklearn.calibration </span><span class="s0">import </span><span class="s1">CalibrationDisplay</span>
<span class="s0">from </span><span class="s1">sklearn.compose </span><span class="s0">import </span><span class="s1">make_column_transformer</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">load_iris</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">NotFittedError</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LogisticRegression</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">DetCurveDisplay</span><span class="s0">,</span>
    <span class="s1">PrecisionRecallDisplay</span><span class="s0">,</span>
    <span class="s1">RocCurveDisplay</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">StandardScaler</span>
<span class="s0">from </span><span class="s1">sklearn.tree </span><span class="s0">import </span><span class="s1">DecisionTreeClassifier</span><span class="s0">, </span><span class="s1">DecisionTreeRegressor</span>


<span class="s1">@pytest.fixture(scope=</span><span class="s2">&quot;module&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">data():</span>
    <span class="s0">return </span><span class="s1">load_iris(return_X_y=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s1">@pytest.fixture(scope=</span><span class="s2">&quot;module&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">data_binary(data):</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data</span>
    <span class="s0">return </span><span class="s1">X[y &lt; </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y[y &lt; </span><span class="s3">2</span><span class="s1">]</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">,</span>
    <span class="s1">[CalibrationDisplay</span><span class="s0">, </span><span class="s1">DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_error_classifier(pyplot</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">data_binary</span><span class="s0">, </span><span class="s1">Display):</span>
    <span class="s4">&quot;&quot;&quot;Check that a proper error is raised when only binary classification is 
    supported.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data</span>
    <span class="s1">X_binary</span><span class="s0">, </span><span class="s1">y_binary = data_binary</span>
    <span class="s1">clf = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s5"># Case 1: multiclass classifier with multiclass target</span>
    <span class="s1">msg = </span><span class="s2">&quot;Expected 'estimator' to be a binary classifier. Got 3 classes instead.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s5"># Case 2: multiclass classifier with binary target</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(clf</span><span class="s0">, </span><span class="s1">X_binary</span><span class="s0">, </span><span class="s1">y_binary)</span>

    <span class="s5"># Case 3: binary classifier with multiclass target</span>
    <span class="s1">clf = DecisionTreeClassifier().fit(X_binary</span><span class="s0">, </span><span class="s1">y_binary)</span>
    <span class="s1">msg = </span><span class="s2">&quot;The target y is not binary. Got multiclass type of target.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">,</span>
    <span class="s1">[CalibrationDisplay</span><span class="s0">, </span><span class="s1">DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_error_regression(pyplot</span><span class="s0">, </span><span class="s1">data_binary</span><span class="s0">, </span><span class="s1">Display):</span>
    <span class="s4">&quot;&quot;&quot;Check that we raise an error with regressor.&quot;&quot;&quot;</span>

    <span class="s5"># Case 1: regressor</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>
    <span class="s1">regressor = DecisionTreeRegressor().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s2">&quot;Expected 'estimator' to be a binary classifier. Got DecisionTreeRegressor&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(regressor</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s5"># Case 2: regression target</span>
    <span class="s1">classifier = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s5"># Force `y_true` to be seen as a regression problem</span>
    <span class="s1">y = y + </span><span class="s3">0.5</span>
    <span class="s1">msg = </span><span class="s2">&quot;The target y is not binary. Got continuous type of target.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(classifier</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_predictions(y</span><span class="s0">, </span><span class="s1">regressor.fit(X</span><span class="s0">, </span><span class="s1">y).predict(X))</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;response_method, msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s2">&quot;predict_proba&quot;</span><span class="s0">,</span>
            <span class="s2">&quot;MyClassifier has none of the following attributes: predict_proba.&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s2">&quot;decision_function&quot;</span><span class="s0">,</span>
            <span class="s2">&quot;MyClassifier has none of the following attributes: decision_function.&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s2">&quot;auto&quot;</span><span class="s0">,</span>
            <span class="s1">(</span>
                <span class="s2">&quot;MyClassifier has none of the following attributes: predict_proba,&quot;</span>
                <span class="s2">&quot; decision_function.&quot;</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s2">&quot;bad_method&quot;</span><span class="s0">,</span>
            <span class="s2">&quot;MyClassifier has none of the following attributes: bad_method.&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">, </span><span class="s1">[DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_error_no_response(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">data_binary</span><span class="s0">,</span>
    <span class="s1">response_method</span><span class="s0">,</span>
    <span class="s1">msg</span><span class="s0">,</span>
    <span class="s1">Display</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Check that a proper error is raised when the response method requested 
    is not defined for the given trained classifier.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>

    <span class="s0">class </span><span class="s1">MyClassifier(ClassifierMixin):</span>
        <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s1">self.classes_ = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
            <span class="s0">return </span><span class="s1">self</span>

    <span class="s1">clf = MyClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(AttributeError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">response_method=response_method)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">, </span><span class="s1">[DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;constructor_name&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s2">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s2">&quot;from_predictions&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_display_curve_estimator_name_multiple_calls(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">data_binary</span><span class="s0">,</span>
    <span class="s1">Display</span><span class="s0">,</span>
    <span class="s1">constructor_name</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Check that passing `name` when calling `plot` will overwrite the original name 
    in the legend.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>
    <span class="s1">clf_name = </span><span class="s2">&quot;my hand-crafted name&quot;</span>
    <span class="s1">clf = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred = clf.predict_proba(X)[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>

    <span class="s5"># safe guard for the binary if/else construction</span>
    <span class="s0">assert </span><span class="s1">constructor_name </span><span class="s0">in </span><span class="s1">(</span><span class="s2">&quot;from_estimator&quot;</span><span class="s0">, </span><span class="s2">&quot;from_predictions&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">constructor_name == </span><span class="s2">&quot;from_estimator&quot;</span><span class="s1">:</span>
        <span class="s1">disp = Display.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">name=clf_name)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">disp = Display.from_predictions(y</span><span class="s0">, </span><span class="s1">y_pred</span><span class="s0">, </span><span class="s1">name=clf_name)</span>
    <span class="s0">assert </span><span class="s1">disp.estimator_name == clf_name</span>
    <span class="s1">pyplot.close(</span><span class="s2">&quot;all&quot;</span><span class="s1">)</span>
    <span class="s1">disp.plot()</span>
    <span class="s0">assert </span><span class="s1">clf_name </span><span class="s0">in </span><span class="s1">disp.line_.get_label()</span>
    <span class="s1">pyplot.close(</span><span class="s2">&quot;all&quot;</span><span class="s1">)</span>
    <span class="s1">clf_name = </span><span class="s2">&quot;another_name&quot;</span>
    <span class="s1">disp.plot(name=clf_name)</span>
    <span class="s0">assert </span><span class="s1">clf_name </span><span class="s0">in </span><span class="s1">disp.line_.get_label()</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;clf&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">LogisticRegression()</span><span class="s0">,</span>
        <span class="s1">make_pipeline(StandardScaler()</span><span class="s0">, </span><span class="s1">LogisticRegression())</span><span class="s0">,</span>
        <span class="s1">make_pipeline(</span>
            <span class="s1">make_column_transformer((StandardScaler()</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]))</span><span class="s0">, </span><span class="s1">LogisticRegression()</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">, </span><span class="s1">[DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_not_fitted_errors(pyplot</span><span class="s0">, </span><span class="s1">data_binary</span><span class="s0">, </span><span class="s1">clf</span><span class="s0">, </span><span class="s1">Display):</span>
    <span class="s4">&quot;&quot;&quot;Check that a proper error is raised when the classifier is not 
    fitted.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>
    <span class="s5"># clone since we parametrize the test and the classifier will be fitted</span>
    <span class="s5"># when testing the second and subsequent plotting function</span>
    <span class="s1">model = clone(clf)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(NotFittedError):</span>
        <span class="s1">Display.from_estimator(model</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">model.fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">disp = Display.from_estimator(model</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">assert </span><span class="s1">model.__class__.__name__ </span><span class="s0">in </span><span class="s1">disp.line_.get_label()</span>
    <span class="s0">assert </span><span class="s1">disp.estimator_name == model.__class__.__name__</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">, </span><span class="s1">[DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_n_samples_consistency(pyplot</span><span class="s0">, </span><span class="s1">data_binary</span><span class="s0">, </span><span class="s1">Display):</span>
    <span class="s4">&quot;&quot;&quot;Check the error raised when `y_pred` or `sample_weight` have inconsistent 
    length.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>
    <span class="s1">classifier = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s2">&quot;Found input variables with inconsistent numbers of samples&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(classifier</span><span class="s0">, </span><span class="s1">X[:-</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(classifier</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y[:-</span><span class="s3">2</span><span class="s1">])</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_estimator(classifier</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">sample_weight=np.ones(X.shape[</span><span class="s3">0</span><span class="s1">] - </span><span class="s3">2</span><span class="s1">))</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;Display&quot;</span><span class="s0">, </span><span class="s1">[DetCurveDisplay</span><span class="s0">, </span><span class="s1">PrecisionRecallDisplay</span><span class="s0">, </span><span class="s1">RocCurveDisplay]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_display_curve_error_pos_label(pyplot</span><span class="s0">, </span><span class="s1">data_binary</span><span class="s0">, </span><span class="s1">Display):</span>
    <span class="s4">&quot;&quot;&quot;Check consistence of error message when `pos_label` should be specified.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data_binary</span>
    <span class="s1">y = y + </span><span class="s3">10</span>

    <span class="s1">classifier = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">y_pred = classifier.predict_proba(X)[:</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span>
    <span class="s1">msg = </span><span class="s2">r&quot;y_true takes value in {10, 11} and pos_label is not specified&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">Display.from_predictions(y</span><span class="s0">, </span><span class="s1">y_pred)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_glsar_gretl.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_glsar_gretl.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot;Tests of GLSAR and diagnostics against Gretl 
 
Created on Thu Feb 02 21:15:47 2012 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">os</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">numpy.testing </span><span class="s3">import </span><span class="s1">(assert_almost_equal</span><span class="s3">, </span><span class="s1">assert_equal</span><span class="s3">,</span>
                           <span class="s1">assert_allclose</span><span class="s3">, </span><span class="s1">assert_array_less)</span>

<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">GLSAR</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.tools </span><span class="s3">import </span><span class="s1">add_constant</span>
<span class="s3">from </span><span class="s1">statsmodels.datasets </span><span class="s3">import </span><span class="s1">macrodata</span>

<span class="s3">import </span><span class="s1">statsmodels.stats.sandwich_covariance </span><span class="s3">as </span><span class="s1">sw</span>
<span class="s3">import </span><span class="s1">statsmodels.stats.diagnostic </span><span class="s3">as </span><span class="s1">smsdia</span>
<span class="s3">import </span><span class="s1">statsmodels.stats.outliers_influence </span><span class="s3">as </span><span class="s1">oi</span>


<span class="s3">def </span><span class="s1">compare_ftest(contrast_res</span><span class="s3">, </span><span class="s1">other</span><span class="s3">, </span><span class="s1">decimal=(</span><span class="s4">5</span><span class="s3">,</span><span class="s4">4</span><span class="s1">)):</span>
    <span class="s1">assert_almost_equal(contrast_res.fvalue</span><span class="s3">, </span><span class="s1">other[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=decimal[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">assert_almost_equal(contrast_res.pvalue</span><span class="s3">, </span><span class="s1">other[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=decimal[</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">assert_equal(contrast_res.df_num</span><span class="s3">, </span><span class="s1">other[</span><span class="s4">2</span><span class="s1">])</span>
    <span class="s1">assert_equal(contrast_res.df_denom</span><span class="s3">, </span><span class="s1">other[</span><span class="s4">3</span><span class="s1">])</span>
    <span class="s1">assert_equal(</span><span class="s5">&quot;f&quot;</span><span class="s3">, </span><span class="s1">other[</span><span class="s4">4</span><span class="s1">])</span>


<span class="s3">class </span><span class="s1">TestGLSARGretl:</span>

    <span class="s3">def </span><span class="s1">test_all(self):</span>

        <span class="s1">d = macrodata.load_pandas().data</span>
        <span class="s0">#import datasetswsm.greene as g</span>
        <span class="s0">#d = g.load('5-1')</span>

        <span class="s0">#growth rates</span>
        <span class="s1">gs_l_realinv = </span><span class="s4">400 </span><span class="s1">* np.diff(np.log(d[</span><span class="s5">'realinv'</span><span class="s1">].values))</span>
        <span class="s1">gs_l_realgdp = </span><span class="s4">400 </span><span class="s1">* np.diff(np.log(d[</span><span class="s5">'realgdp'</span><span class="s1">].values))</span>

        <span class="s0">#simple diff, not growthrate, I want heteroscedasticity later for testing</span>
        <span class="s1">endogd = np.diff(d[</span><span class="s5">'realinv'</span><span class="s1">])</span>
        <span class="s1">exogd = add_constant(np.c_[np.diff(d[</span><span class="s5">'realgdp'</span><span class="s1">].values)</span><span class="s3">, </span><span class="s1">d[</span><span class="s5">'realint'</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">].values])</span>

        <span class="s1">endogg = gs_l_realinv</span>
        <span class="s1">exogg = add_constant(np.c_[gs_l_realgdp</span><span class="s3">, </span><span class="s1">d[</span><span class="s5">'realint'</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">].values])</span>

        <span class="s1">res_ols = OLS(endogg</span><span class="s3">, </span><span class="s1">exogg).fit()</span>
        <span class="s0">#print res_ols.params</span>

        <span class="s1">mod_g1 = GLSAR(endogg</span><span class="s3">, </span><span class="s1">exogg</span><span class="s3">, </span><span class="s1">rho=-</span><span class="s4">0.108136</span><span class="s1">)</span>
        <span class="s1">res_g1 = mod_g1.fit()</span>
        <span class="s0">#print res_g1.params</span>

        <span class="s1">mod_g2 = GLSAR(endogg</span><span class="s3">, </span><span class="s1">exogg</span><span class="s3">, </span><span class="s1">rho=-</span><span class="s4">0.108136</span><span class="s1">)   </span><span class="s0">#-0.1335859) from R</span>
        <span class="s1">res_g2 = mod_g2.iterative_fit(maxiter=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s0">#print res_g2.params</span>


        <span class="s1">rho = -</span><span class="s4">0.108136</span>

        <span class="s0">#                 coefficient   std. error   t-ratio    p-value 95% CONFIDENCE INTERVAL</span>
        <span class="s1">partable = np.array([</span>
                        <span class="s1">[-</span><span class="s4">9.50990</span><span class="s3">,  </span><span class="s4">0.990456</span><span class="s3">, </span><span class="s1">-</span><span class="s4">9.602</span><span class="s3">, </span><span class="s4">3.65e-018</span><span class="s3">, </span><span class="s1">-</span><span class="s4">11.4631</span><span class="s3">, </span><span class="s1">-</span><span class="s4">7.55670</span><span class="s1">]</span><span class="s3">, </span><span class="s0"># ***</span>
                        <span class="s1">[ </span><span class="s4">4.37040</span><span class="s3">,  </span><span class="s4">0.208146</span><span class="s3">, </span><span class="s4">21.00</span><span class="s3">,  </span><span class="s4">2.93e-052</span><span class="s3">,  </span><span class="s4">3.95993</span><span class="s3">, </span><span class="s4">4.78086</span><span class="s1">]</span><span class="s3">, </span><span class="s0"># ***</span>
                        <span class="s1">[-</span><span class="s4">0.579253</span><span class="s3">, </span><span class="s4">0.268009</span><span class="s3">, </span><span class="s1">-</span><span class="s4">2.161</span><span class="s3">, </span><span class="s4">0.0319</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1.10777</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.0507346</span><span class="s1">]]) </span><span class="s0">#    **</span>

        <span class="s0">#Statistics based on the rho-differenced data:</span>

        <span class="s1">result_gretl_g1 = dict(</span>
        <span class="s1">endog_mean = (</span><span class="s5">&quot;Mean dependent var&quot;</span><span class="s3">,   </span><span class="s4">3.113973</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">endog_std = (</span><span class="s5">&quot;S.D. dependent var&quot;</span><span class="s3">,   </span><span class="s4">18.67447</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">ssr = (</span><span class="s5">&quot;Sum squared resid&quot;</span><span class="s3">,    </span><span class="s4">22530.90</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">mse_resid_sqrt = (</span><span class="s5">&quot;S.E. of regression&quot;</span><span class="s3">,   </span><span class="s4">10.66735</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">rsquared = (</span><span class="s5">&quot;R-squared&quot;</span><span class="s3">,            </span><span class="s4">0.676973</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">rsquared_adj = (</span><span class="s5">&quot;Adjusted R-squared&quot;</span><span class="s3">,   </span><span class="s4">0.673710</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">fvalue = (</span><span class="s5">&quot;F(2, 198)&quot;</span><span class="s3">,            </span><span class="s4">221.0475</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">f_pvalue = (</span><span class="s5">&quot;P-value(F)&quot;</span><span class="s3">,           </span><span class="s4">3.56e-51</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">resid_acf1 = (</span><span class="s5">&quot;rho&quot;</span><span class="s3">,                 </span><span class="s1">-</span><span class="s4">0.003481</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">dw = (</span><span class="s5">&quot;Durbin-Watson&quot;</span><span class="s3">,        </span><span class="s4">1.993858</span><span class="s1">))</span>


        <span class="s0">#fstatistic, p-value, df1, df2</span>
        <span class="s1">reset_2_3 = [</span><span class="s4">5.219019</span><span class="s3">, </span><span class="s4">0.00619</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">197</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]</span>
        <span class="s1">reset_2 = [</span><span class="s4">7.268492</span><span class="s3">, </span><span class="s4">0.00762</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">198</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]</span>
        <span class="s1">reset_3 = [</span><span class="s4">5.248951</span><span class="s3">, </span><span class="s4">0.023</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">198</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]</span>
        <span class="s0">#LM-statistic, p-value, df</span>
        <span class="s1">arch_4 = [</span><span class="s4">7.30776</span><span class="s3">, </span><span class="s4">0.120491</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>

        <span class="s0">#multicollinearity</span>
        <span class="s1">vif = [</span><span class="s4">1.002</span><span class="s3">, </span><span class="s4">1.002</span><span class="s1">]</span>
        <span class="s1">cond_1norm = </span><span class="s4">6862.0664</span>
        <span class="s1">determinant = </span><span class="s4">1.0296049e+009</span>
        <span class="s1">reciprocal_condition_number = </span><span class="s4">0.013819244</span>

        <span class="s0">#Chi-square(2): test-statistic, pvalue, df</span>
        <span class="s1">normality = [</span><span class="s4">20.2792</span><span class="s3">, </span><span class="s4">3.94837e-005</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>

        <span class="s0">#tests</span>
        <span class="s1">res = res_g1  </span><span class="s0">#with rho from Gretl</span>

        <span class="s0">#basic</span>

        <span class="s1">assert_almost_equal(res.params</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.bse</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.tvalues</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s1">assert_almost_equal(res.ssr</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'ssr'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s0">#assert_almost_equal(res.llf, result_gretl_g1['llf'][1], decimal=7) #not in gretl</span>
        <span class="s0">#assert_almost_equal(res.rsquared, result_gretl_g1['rsquared'][1], decimal=7) #FAIL</span>
        <span class="s0">#assert_almost_equal(res.rsquared_adj, result_gretl_g1['rsquared_adj'][1], decimal=7) #FAIL</span>
        <span class="s1">assert_almost_equal(np.sqrt(res.mse_resid)</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'mse_resid_sqrt'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.fvalue</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'fvalue'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.f_pvalue</span><span class="s3">,</span>
                        <span class="s1">result_gretl_g1[</span><span class="s5">'f_pvalue'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">rtol=</span><span class="s4">1e-2</span><span class="s1">)</span>
        <span class="s0">#assert_almost_equal(res.durbin_watson, result_gretl_g1['dw'][1], decimal=7) #TODO</span>

        <span class="s0">#arch</span>
        <span class="s0">#sm_arch = smsdia.acorr_lm(res.wresid**2, maxlag=4, autolag=None)</span>
        <span class="s1">sm_arch = smsdia.het_arch(res.wresid</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>

        <span class="s0">#tests</span>
        <span class="s1">res = res_g2 </span><span class="s0">#with estimated rho</span>

        <span class="s0">#estimated lag coefficient</span>
        <span class="s1">assert_almost_equal(res.model.rho</span><span class="s3">, </span><span class="s1">rho</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>

        <span class="s0">#basic</span>
        <span class="s1">assert_almost_equal(res.params</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.bse</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.tvalues</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)</span>

        <span class="s1">assert_almost_equal(res.ssr</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'ssr'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s0">#assert_almost_equal(res.llf, result_gretl_g1['llf'][1], decimal=7) #not in gretl</span>
        <span class="s0">#assert_almost_equal(res.rsquared, result_gretl_g1['rsquared'][1], decimal=7) #FAIL</span>
        <span class="s0">#assert_almost_equal(res.rsquared_adj, result_gretl_g1['rsquared_adj'][1], decimal=7) #FAIL</span>
        <span class="s1">assert_almost_equal(np.sqrt(res.mse_resid)</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'mse_resid_sqrt'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.fvalue</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'fvalue'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.f_pvalue</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'f_pvalue'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>
        <span class="s0">#assert_almost_equal(res.durbin_watson, result_gretl_g1['dw'][1], decimal=7) #TODO</span>



        <span class="s1">c = oi.reset_ramsey(res</span><span class="s3">, </span><span class="s1">degree=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">compare_ftest(c</span><span class="s3">, </span><span class="s1">reset_2</span><span class="s3">, </span><span class="s1">decimal=(</span><span class="s4">2</span><span class="s3">,</span><span class="s4">4</span><span class="s1">))</span>
        <span class="s1">c = oi.reset_ramsey(res</span><span class="s3">, </span><span class="s1">degree=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">compare_ftest(c</span><span class="s3">, </span><span class="s1">reset_2_3</span><span class="s3">, </span><span class="s1">decimal=(</span><span class="s4">2</span><span class="s3">,</span><span class="s4">4</span><span class="s1">))</span>

        <span class="s0">#arch</span>
        <span class="s0">#sm_arch = smsdia.acorr_lm(res.wresid**2, maxlag=4, autolag=None)</span>
        <span class="s1">sm_arch = smsdia.het_arch(res.wresid</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>



        <span class="s5">''' 
        Performing iterative calculation of rho... 
 
                         ITER       RHO        ESS 
                           1     -0.10734   22530.9 
                           2     -0.10814   22530.9 
 
        Model 4: Cochrane-Orcutt, using observations 1959:3-2009:3 (T = 201) 
        Dependent variable: ds_l_realinv 
        rho = -0.108136 
 
                         coefficient   std. error   t-ratio    p-value 
          ------------------------------------------------------------- 
          const           -9.50990      0.990456    -9.602    3.65e-018 *** 
          ds_l_realgdp     4.37040      0.208146    21.00     2.93e-052 *** 
          realint_1       -0.579253     0.268009    -2.161    0.0319    ** 
 
        Statistics based on the rho-differenced data: 
 
        Mean dependent var   3.113973   S.D. dependent var   18.67447 
        Sum squared resid    22530.90   S.E. of regression   10.66735 
        R-squared            0.676973   Adjusted R-squared   0.673710 
        F(2, 198)            221.0475   P-value(F)           3.56e-51 
        rho                 -0.003481   Durbin-Watson        1.993858 
        '''</span>

        <span class="s5">''' 
        RESET test for specification (squares and cubes) 
        Test statistic: F = 5.219019, 
        with p-value = P(F(2,197) &gt; 5.21902) = 0.00619 
 
        RESET test for specification (squares only) 
        Test statistic: F = 7.268492, 
        with p-value = P(F(1,198) &gt; 7.26849) = 0.00762 
 
        RESET test for specification (cubes only) 
        Test statistic: F = 5.248951, 
        with p-value = P(F(1,198) &gt; 5.24895) = 0.023: 
        '''</span>

        <span class="s5">''' 
        Test for ARCH of order 4 
 
                     coefficient   std. error   t-ratio   p-value 
          -------------------------------------------------------- 
          alpha(0)   97.0386       20.3234       4.775    3.56e-06 *** 
          alpha(1)    0.176114      0.0714698    2.464    0.0146   ** 
          alpha(2)   -0.0488339     0.0724981   -0.6736   0.5014 
          alpha(3)   -0.0705413     0.0737058   -0.9571   0.3397 
          alpha(4)    0.0384531     0.0725763    0.5298   0.5968 
 
          Null hypothesis: no ARCH effect is present 
          Test statistic: LM = 7.30776 
          with p-value = P(Chi-square(4) &gt; 7.30776) = 0.120491: 
        '''</span>

        <span class="s5">''' 
        Variance Inflation Factors 
 
        Minimum possible value = 1.0 
        Values &gt; 10.0 may indicate a collinearity problem 
 
           ds_l_realgdp    1.002 
              realint_1    1.002 
 
        VIF(j) = 1/(1 - R(j)^2), where R(j) is the multiple correlation coefficient 
        between variable j and the other independent variables 
 
        Properties of matrix X'X: 
 
         1-norm = 6862.0664 
         Determinant = 1.0296049e+009 
         Reciprocal condition number = 0.013819244 
        '''</span>
        <span class="s5">''' 
        Test for ARCH of order 4 - 
          Null hypothesis: no ARCH effect is present 
          Test statistic: LM = 7.30776 
          with p-value = P(Chi-square(4) &gt; 7.30776) = 0.120491 
 
        Test of common factor restriction - 
          Null hypothesis: restriction is acceptable 
          Test statistic: F(2, 195) = 0.426391 
          with p-value = P(F(2, 195) &gt; 0.426391) = 0.653468 
 
        Test for normality of residual - 
          Null hypothesis: error is normally distributed 
          Test statistic: Chi-square(2) = 20.2792 
          with p-value = 3.94837e-005: 
        '''</span>

        <span class="s0">#no idea what this is</span>
        <span class="s5">''' 
        Augmented regression for common factor test 
        OLS, using observations 1959:3-2009:3 (T = 201) 
        Dependent variable: ds_l_realinv 
 
                           coefficient   std. error   t-ratio    p-value 
          --------------------------------------------------------------- 
          const            -10.9481      1.35807      -8.062    7.44e-014 *** 
          ds_l_realgdp       4.28893     0.229459     18.69     2.40e-045 *** 
          realint_1         -0.662644    0.334872     -1.979    0.0492    ** 
          ds_l_realinv_1    -0.108892    0.0715042    -1.523    0.1294 
          ds_l_realgdp_1     0.660443    0.390372      1.692    0.0923    * 
          realint_2          0.0769695   0.341527      0.2254   0.8219 
 
          Sum of squared residuals = 22432.8 
 
        Test of common factor restriction 
 
          Test statistic: F(2, 195) = 0.426391, with p-value = 0.653468 
        '''</span>


        <span class="s0">################ with OLS, HAC errors</span>

        <span class="s0">#Model 5: OLS, using observations 1959:2-2009:3 (T = 202)</span>
        <span class="s0">#Dependent variable: ds_l_realinv</span>
        <span class="s0">#HAC standard errors, bandwidth 4 (Bartlett kernel)</span>

        <span class="s0">#coefficient   std. error   t-ratio    p-value 95% CONFIDENCE INTERVAL</span>
        <span class="s0">#for confidence interval t(199, 0.025) = 1.972</span>

        <span class="s1">partable = np.array([</span>
        <span class="s1">[-</span><span class="s4">9.48167</span><span class="s3">,      </span><span class="s4">1.17709</span><span class="s3">,     </span><span class="s1">-</span><span class="s4">8.055</span><span class="s3">,    </span><span class="s4">7.17e-014</span><span class="s3">, </span><span class="s1">-</span><span class="s4">11.8029</span><span class="s3">, </span><span class="s1">-</span><span class="s4">7.16049</span><span class="s1">]</span><span class="s3">, </span><span class="s0"># ***</span>
        <span class="s1">[</span><span class="s4">4.37422</span><span class="s3">,      </span><span class="s4">0.328787</span><span class="s3">,    </span><span class="s4">13.30</span><span class="s3">,     </span><span class="s4">2.62e-029</span><span class="s3">, </span><span class="s4">3.72587</span><span class="s3">, </span><span class="s4">5.02258</span><span class="s1">]</span><span class="s3">, </span><span class="s0">#***</span>
        <span class="s1">[-</span><span class="s4">0.613997</span><span class="s3">,     </span><span class="s4">0.293619</span><span class="s3">,    </span><span class="s1">-</span><span class="s4">2.091</span><span class="s3">,    </span><span class="s4">0.0378</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1.19300</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.0349939</span><span class="s1">]]) </span><span class="s0"># **</span>

        <span class="s1">result_gretl_g1 = dict(</span>
                    <span class="s1">endog_mean = (</span><span class="s5">&quot;Mean dependent var&quot;</span><span class="s3">,   </span><span class="s4">3.257395</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">endog_std = (</span><span class="s5">&quot;S.D. dependent var&quot;</span><span class="s3">,   </span><span class="s4">18.73915</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">ssr = (</span><span class="s5">&quot;Sum squared resid&quot;</span><span class="s3">,    </span><span class="s4">22799.68</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">mse_resid_sqrt = (</span><span class="s5">&quot;S.E. of regression&quot;</span><span class="s3">,   </span><span class="s4">10.70380</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">rsquared = (</span><span class="s5">&quot;R-squared&quot;</span><span class="s3">,            </span><span class="s4">0.676978</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">rsquared_adj = (</span><span class="s5">&quot;Adjusted R-squared&quot;</span><span class="s3">,   </span><span class="s4">0.673731</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">fvalue = (</span><span class="s5">&quot;F(2, 199)&quot;</span><span class="s3">,            </span><span class="s4">90.79971</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">f_pvalue = (</span><span class="s5">&quot;P-value(F)&quot;</span><span class="s3">,           </span><span class="s4">9.53e-29</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">llf = (</span><span class="s5">&quot;Log-likelihood&quot;</span><span class="s3">,      </span><span class="s1">-</span><span class="s4">763.9752</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">aic = (</span><span class="s5">&quot;Akaike criterion&quot;</span><span class="s3">,     </span><span class="s4">1533.950</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">bic = (</span><span class="s5">&quot;Schwarz criterion&quot;</span><span class="s3">,    </span><span class="s4">1543.875</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">hqic = (</span><span class="s5">&quot;Hannan-Quinn&quot;</span><span class="s3">,         </span><span class="s4">1537.966</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">resid_acf1 = (</span><span class="s5">&quot;rho&quot;</span><span class="s3">,                 </span><span class="s1">-</span><span class="s4">0.107341</span><span class="s1">)</span><span class="s3">,</span>
                    <span class="s1">dw = (</span><span class="s5">&quot;Durbin-Watson&quot;</span><span class="s3">,        </span><span class="s4">2.213805</span><span class="s1">))</span>

        <span class="s1">linear_logs = [</span><span class="s4">1.68351</span><span class="s3">, </span><span class="s4">0.430953</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>
        <span class="s0">#for logs: dropping 70 nan or incomplete observations, T=133</span>
        <span class="s0">#(res_ols.model.exog &lt;=0).any(1).sum() = 69  ?not 70</span>
        <span class="s1">linear_squares = [</span><span class="s4">7.52477</span><span class="s3">, </span><span class="s4">0.0232283</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>

        <span class="s0">#Autocorrelation, Breusch-Godfrey test for autocorrelation up to order 4</span>
        <span class="s1">lm_acorr4 = [</span><span class="s4">1.17928</span><span class="s3">, </span><span class="s4">0.321197</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">195</span><span class="s3">, </span><span class="s5">&quot;F&quot;</span><span class="s1">]</span>
        <span class="s1">lm2_acorr4 = [</span><span class="s4">4.771043</span><span class="s3">, </span><span class="s4">0.312</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>
        <span class="s1">acorr_ljungbox4 = [</span><span class="s4">5.23587</span><span class="s3">, </span><span class="s4">0.264</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>

        <span class="s0">#break</span>
        <span class="s1">cusum_Harvey_Collier  = [</span><span class="s4">0.494432</span><span class="s3">, </span><span class="s4">0.621549</span><span class="s3">, </span><span class="s4">198</span><span class="s3">, </span><span class="s5">&quot;t&quot;</span><span class="s1">] </span><span class="s0">#stats.t.sf(0.494432, 198)*2</span>
        <span class="s0">#see cusum results in files</span>
        <span class="s1">break_qlr = [</span><span class="s4">3.01985</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">196</span><span class="s3">, </span><span class="s5">&quot;maxF&quot;</span><span class="s1">]  </span><span class="s0">#TODO check this, max at 2001:4</span>
        <span class="s1">break_chow = [</span><span class="s4">13.1897</span><span class="s3">, </span><span class="s4">0.00424384</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">] </span><span class="s0"># break at 1984:1</span>

        <span class="s1">arch_4 = [</span><span class="s4">3.43473</span><span class="s3">, </span><span class="s4">0.487871</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>

        <span class="s1">normality = [</span><span class="s4">23.962</span><span class="s3">, </span><span class="s4">0.00001</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>

        <span class="s1">het_white = [</span><span class="s4">33.503723</span><span class="s3">, </span><span class="s4">0.000003</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>
        <span class="s1">het_breusch_pagan = [</span><span class="s4">1.302014</span><span class="s3">, </span><span class="s4">0.521520</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]  </span><span class="s0">#TODO: not available</span>
        <span class="s1">het_breusch_pagan_konker = [</span><span class="s4">0.709924</span><span class="s3">, </span><span class="s4">0.701200</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s5">&quot;chi2&quot;</span><span class="s1">]</span>


        <span class="s1">reset_2_3 = [</span><span class="s4">5.219019</span><span class="s3">, </span><span class="s4">0.00619</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">197</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]</span>
        <span class="s1">reset_2 = [</span><span class="s4">7.268492</span><span class="s3">, </span><span class="s4">0.00762</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">198</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]</span>
        <span class="s1">reset_3 = [</span><span class="s4">5.248951</span><span class="s3">, </span><span class="s4">0.023</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">198</span><span class="s3">, </span><span class="s5">&quot;f&quot;</span><span class="s1">]  </span><span class="s0">#not available</span>

        <span class="s1">cond_1norm = </span><span class="s4">5984.0525</span>
        <span class="s1">determinant = </span><span class="s4">7.1087467e+008</span>
        <span class="s1">reciprocal_condition_number = </span><span class="s4">0.013826504</span>
        <span class="s1">vif = [</span><span class="s4">1.001</span><span class="s3">, </span><span class="s4">1.001</span><span class="s1">]</span>

        <span class="s1">names = </span><span class="s5">'date   residual        leverage       influence        DFFITS'</span><span class="s1">.split()</span>
        <span class="s1">cur_dir = os.path.abspath(os.path.dirname(__file__))</span>
        <span class="s1">fpath = os.path.join(cur_dir</span><span class="s3">, </span><span class="s5">'results/leverage_influence_ols_nostars.txt'</span><span class="s1">)</span>
        <span class="s1">lev = np.genfromtxt(fpath</span><span class="s3">, </span><span class="s1">skip_header=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">skip_footer=</span><span class="s4">1</span><span class="s3">,</span>
                            <span class="s1">converters={</span><span class="s4">0</span><span class="s1">:</span><span class="s3">lambda </span><span class="s1">s: s})</span>
        <span class="s0">#either numpy 1.6 or python 3.2 changed behavior</span>
        <span class="s3">if </span><span class="s1">np.isnan(lev[-</span><span class="s4">1</span><span class="s1">][</span><span class="s5">'f1'</span><span class="s1">]):</span>
            <span class="s1">lev = np.genfromtxt(fpath</span><span class="s3">, </span><span class="s1">skip_header=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">skip_footer=</span><span class="s4">2</span><span class="s3">,</span>
                                <span class="s1">converters={</span><span class="s4">0</span><span class="s1">:</span><span class="s3">lambda </span><span class="s1">s: s})</span>

        <span class="s1">lev.dtype.names = names</span>

        <span class="s1">res = res_ols </span><span class="s0">#for easier copying</span>

        <span class="s1">cov_hac = sw.cov_hac_simple(res</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">4</span><span class="s3">, </span><span class="s1">use_correction=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">bse_hac =  sw.se_cov(cov_hac)</span>

        <span class="s1">assert_almost_equal(res.params</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(bse_hac</span><span class="s3">, </span><span class="s1">partable[:</span><span class="s3">,</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">5</span><span class="s1">)</span>
        <span class="s0">#TODO</span>

        <span class="s1">assert_almost_equal(res.ssr</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'ssr'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(res.llf</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'llf'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">) </span><span class="s0">#not in gretl</span>
        <span class="s1">assert_almost_equal(res.rsquared</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'rsquared'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">) </span><span class="s0">#FAIL</span>
        <span class="s1">assert_almost_equal(res.rsquared_adj</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'rsquared_adj'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">) </span><span class="s0">#FAIL</span>
        <span class="s1">assert_almost_equal(np.sqrt(res.mse_resid)</span><span class="s3">, </span><span class="s1">result_gretl_g1[</span><span class="s5">'mse_resid_sqrt'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s0">#f-value is based on cov_hac I guess</span>
        <span class="s0">#res2 = res.get_robustcov_results(cov_type='HC1')</span>
        <span class="s0"># TODO: fvalue differs from Gretl, trying any of the HCx</span>
        <span class="s0">#assert_almost_equal(res2.fvalue, result_gretl_g1['fvalue'][1], decimal=0) #FAIL</span>
        <span class="s0">#assert_approx_equal(res.f_pvalue, result_gretl_g1['f_pvalue'][1], significant=1) #FAIL</span>
        <span class="s0">#assert_almost_equal(res.durbin_watson, result_gretl_g1['dw'][1], decimal=7) #TODO</span>


        <span class="s1">c = oi.reset_ramsey(res</span><span class="s3">, </span><span class="s1">degree=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">compare_ftest(c</span><span class="s3">, </span><span class="s1">reset_2</span><span class="s3">, </span><span class="s1">decimal=(</span><span class="s4">6</span><span class="s3">,</span><span class="s4">5</span><span class="s1">))</span>
        <span class="s1">c = oi.reset_ramsey(res</span><span class="s3">, </span><span class="s1">degree=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">compare_ftest(c</span><span class="s3">, </span><span class="s1">reset_2_3</span><span class="s3">, </span><span class="s1">decimal=(</span><span class="s4">6</span><span class="s3">,</span><span class="s4">5</span><span class="s1">))</span>

        <span class="s1">linear_sq = smsdia.linear_lm(res.resid</span><span class="s3">, </span><span class="s1">res.model.exog)</span>
        <span class="s1">assert_almost_equal(linear_sq[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">linear_squares[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(linear_sq[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">linear_squares[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">7</span><span class="s1">)</span>

        <span class="s1">hbpk = smsdia.het_breuschpagan(res.resid</span><span class="s3">, </span><span class="s1">res.model.exog)</span>
        <span class="s1">assert_almost_equal(hbpk[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">het_breusch_pagan_konker[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(hbpk[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">het_breusch_pagan_konker[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>

        <span class="s1">hw = smsdia.het_white(res.resid</span><span class="s3">, </span><span class="s1">res.model.exog)</span>
        <span class="s1">assert_almost_equal(hw[:</span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s1">het_white[:</span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>

        <span class="s0">#arch</span>
        <span class="s0">#sm_arch = smsdia.acorr_lm(res.resid**2, maxlag=4, autolag=None)</span>
        <span class="s1">sm_arch = smsdia.het_arch(res.resid</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">4</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(sm_arch[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">arch_4[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">6</span><span class="s1">)</span>

        <span class="s1">vif2 = [oi.variance_inflation_factor(res.model.exog</span><span class="s3">, </span><span class="s1">k) </span><span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">[</span><span class="s4">1</span><span class="s3">,</span><span class="s4">2</span><span class="s1">]]</span>

        <span class="s1">infl = oi.OLSInfluence(res_ols)</span>
        <span class="s0">#print np.max(np.abs(lev['DFFITS'] - infl.dffits[0]))</span>
        <span class="s0">#print np.max(np.abs(lev['leverage'] - infl.hat_matrix_diag))</span>
        <span class="s0">#print np.max(np.abs(lev['influence'] - infl.influence))  #just added this based on Gretl</span>

        <span class="s0">#just rough test, low decimal in Gretl output,</span>
        <span class="s1">assert_almost_equal(lev[</span><span class="s5">'residual'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">res.resid</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(lev[</span><span class="s5">'DFFITS'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">infl.dffits[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(lev[</span><span class="s5">'leverage'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">infl.hat_matrix_diag</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(lev[</span><span class="s5">'influence'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">infl.influence</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">4</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">test_GLSARlag():</span>
    <span class="s0">#test that results for lag&gt;1 is close to lag=1, and smaller ssr</span>

    <span class="s3">from </span><span class="s1">statsmodels.datasets </span><span class="s3">import </span><span class="s1">macrodata</span>
    <span class="s1">d2 = macrodata.load_pandas().data</span>
    <span class="s1">g_gdp = </span><span class="s4">400</span><span class="s1">*np.diff(np.log(d2[</span><span class="s5">'realgdp'</span><span class="s1">].values))</span>
    <span class="s1">g_inv = </span><span class="s4">400</span><span class="s1">*np.diff(np.log(d2[</span><span class="s5">'realinv'</span><span class="s1">].values))</span>
    <span class="s1">exogg = add_constant(np.c_[g_gdp</span><span class="s3">, </span><span class="s1">d2[</span><span class="s5">'realint'</span><span class="s1">][:-</span><span class="s4">1</span><span class="s1">].values]</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>

    <span class="s1">mod1 = GLSAR(g_inv</span><span class="s3">, </span><span class="s1">exogg</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">res1 = mod1.iterative_fit(</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">mod4 = GLSAR(g_inv</span><span class="s3">, </span><span class="s1">exogg</span><span class="s3">, </span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">res4 = mod4.iterative_fit(</span><span class="s4">10</span><span class="s1">)</span>

    <span class="s1">assert_array_less(np.abs(res1.params / res4.params - </span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s4">0.03</span><span class="s1">)</span>
    <span class="s1">assert_array_less(res4.ssr</span><span class="s3">, </span><span class="s1">res1.ssr)</span>
    <span class="s1">assert_array_less(np.abs(res4.bse / res1.bse) - </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.015</span><span class="s1">)</span>
    <span class="s1">assert_array_less(np.abs((res4.fittedvalues / res1.fittedvalues - </span><span class="s4">1</span><span class="s1">).mean())</span><span class="s3">,</span>
                      <span class="s4">0.015</span><span class="s1">)</span>
    <span class="s1">assert_equal(len(mod4.rho)</span><span class="s3">, </span><span class="s4">4</span><span class="s1">)</span>




<span class="s3">if </span><span class="s1">__name__ == </span><span class="s5">'__main__'</span><span class="s1">:</span>
    <span class="s1">t = TestGLSARGretl()</span>
    <span class="s1">t.test_all()</span>


<span class="s5">''' 
Model 5: OLS, using observations 1959:2-2009:3 (T = 202) 
Dependent variable: ds_l_realinv 
HAC standard errors, bandwidth 4 (Bartlett kernel) 
 
                 coefficient   std. error   t-ratio    p-value 
  ------------------------------------------------------------- 
  const           -9.48167      1.17709     -8.055    7.17e-014 *** 
  ds_l_realgdp     4.37422      0.328787    13.30     2.62e-029 *** 
  realint_1       -0.613997     0.293619    -2.091    0.0378    ** 
 
Mean dependent var   3.257395   S.D. dependent var   18.73915 
Sum squared resid    22799.68   S.E. of regression   10.70380 
R-squared            0.676978   Adjusted R-squared   0.673731 
F(2, 199)            90.79971   P-value(F)           9.53e-29 
Log-likelihood      -763.9752   Akaike criterion     1533.950 
Schwarz criterion    1543.875   Hannan-Quinn         1537.966 
rho                 -0.107341   Durbin-Watson        2.213805 
 
QLR test for structural break - 
  Null hypothesis: no structural break 
  Test statistic: max F(3, 196) = 3.01985 at observation 2001:4 
  (10 percent critical value = 4.09) 
 
Non-linearity test (logs) - 
  Null hypothesis: relationship is linear 
  Test statistic: LM = 1.68351 
  with p-value = P(Chi-square(2) &gt; 1.68351) = 0.430953 
 
Non-linearity test (squares) - 
  Null hypothesis: relationship is linear 
  Test statistic: LM = 7.52477 
  with p-value = P(Chi-square(2) &gt; 7.52477) = 0.0232283 
 
LM test for autocorrelation up to order 4 - 
  Null hypothesis: no autocorrelation 
  Test statistic: LMF = 1.17928 
  with p-value = P(F(4,195) &gt; 1.17928) = 0.321197 
 
CUSUM test for parameter stability - 
  Null hypothesis: no change in parameters 
  Test statistic: Harvey-Collier t(198) = 0.494432 
  with p-value = P(t(198) &gt; 0.494432) = 0.621549 
 
Chow test for structural break at observation 1984:1 - 
  Null hypothesis: no structural break 
  Asymptotic test statistic: Chi-square(3) = 13.1897 
  with p-value = 0.00424384 
 
Test for ARCH of order 4 - 
  Null hypothesis: no ARCH effect is present 
  Test statistic: LM = 3.43473 
  with p-value = P(Chi-square(4) &gt; 3.43473) = 0.487871: 
 
#ANOVA 
Analysis of Variance: 
 
                     Sum of squares       df      Mean square 
 
  Regression                47782.7        2          23891.3 
  Residual                  22799.7      199          114.571 
  Total                     70582.3      201          351.156 
 
  R^2 = 47782.7 / 70582.3 = 0.676978 
  F(2, 199) = 23891.3 / 114.571 = 208.528 [p-value 1.47e-049] 
 
#LM-test autocorrelation 
Breusch-Godfrey test for autocorrelation up to order 4 
OLS, using observations 1959:2-2009:3 (T = 202) 
Dependent variable: uhat 
 
                 coefficient   std. error   t-ratio    p-value 
  ------------------------------------------------------------ 
  const           0.0640964    1.06719       0.06006   0.9522 
  ds_l_realgdp   -0.0456010    0.217377     -0.2098    0.8341 
  realint_1       0.0511769    0.293136      0.1746    0.8616 
  uhat_1         -0.104707     0.0719948    -1.454     0.1475 
  uhat_2         -0.00898483   0.0742817    -0.1210    0.9039 
  uhat_3          0.0837332    0.0735015     1.139     0.2560 
  uhat_4         -0.0636242    0.0737363    -0.8629    0.3893 
 
  Unadjusted R-squared = 0.023619 
 
Test statistic: LMF = 1.179281, 
with p-value = P(F(4,195) &gt; 1.17928) = 0.321 
 
Alternative statistic: TR^2 = 4.771043, 
with p-value = P(Chi-square(4) &gt; 4.77104) = 0.312 
 
Ljung-Box Q' = 5.23587, 
with p-value = P(Chi-square(4) &gt; 5.23587) = 0.264: 
 
RESET test for specification (squares and cubes) 
Test statistic: F = 5.219019, 
with p-value = P(F(2,197) &gt; 5.21902) = 0.00619 
 
RESET test for specification (squares only) 
Test statistic: F = 7.268492, 
with p-value = P(F(1,198) &gt; 7.26849) = 0.00762 
 
RESET test for specification (cubes only) 
Test statistic: F = 5.248951, 
with p-value = P(F(1,198) &gt; 5.24895) = 0.023 
 
#heteroscedasticity White 
White's test for heteroskedasticity 
OLS, using observations 1959:2-2009:3 (T = 202) 
Dependent variable: uhat^2 
 
                  coefficient   std. error   t-ratio   p-value 
  ------------------------------------------------------------- 
  const           104.920       21.5848       4.861    2.39e-06 *** 
  ds_l_realgdp    -29.7040       6.24983     -4.753    3.88e-06 *** 
  realint_1        -6.93102      6.95607     -0.9964   0.3203 
  sq_ds_l_realg     4.12054      0.684920     6.016    8.62e-09 *** 
  X2_X3             2.89685      1.38571      2.091    0.0379   ** 
  sq_realint_1      0.662135     1.10919      0.5970   0.5512 
 
  Unadjusted R-squared = 0.165860 
 
Test statistic: TR^2 = 33.503723, 
with p-value = P(Chi-square(5) &gt; 33.503723) = 0.000003: 
 
#heteroscedasticity Breusch-Pagan (original) 
Breusch-Pagan test for heteroskedasticity 
OLS, using observations 1959:2-2009:3 (T = 202) 
Dependent variable: scaled uhat^2 
 
                 coefficient   std. error   t-ratio    p-value 
  ------------------------------------------------------------- 
  const           1.09468      0.192281      5.693     4.43e-08 *** 
  ds_l_realgdp   -0.0323119    0.0386353    -0.8363    0.4040 
  realint_1       0.00410778   0.0512274     0.08019   0.9362 
 
  Explained sum of squares = 2.60403 
 
Test statistic: LM = 1.302014, 
with p-value = P(Chi-square(2) &gt; 1.302014) = 0.521520 
 
#heteroscedasticity Breusch-Pagan Koenker 
Breusch-Pagan test for heteroskedasticity 
OLS, using observations 1959:2-2009:3 (T = 202) 
Dependent variable: scaled uhat^2 (Koenker robust variant) 
 
                 coefficient   std. error   t-ratio    p-value 
  ------------------------------------------------------------ 
  const           10.6870       21.7027      0.4924    0.6230 
  ds_l_realgdp    -3.64704       4.36075    -0.8363    0.4040 
  realint_1        0.463643      5.78202     0.08019   0.9362 
 
  Explained sum of squares = 33174.2 
 
Test statistic: LM = 0.709924, 
with p-value = P(Chi-square(2) &gt; 0.709924) = 0.701200 
 
########## forecast 
#forecast mean y 
 For 95% confidence intervals, t(199, 0.025) = 1.972 
 
     Obs ds_l_realinv    prediction    std. error        95% interval 
 
  2008:3     -7.134492   -17.177905     2.946312   -22.987904 - -11.367905 
  2008:4    -27.665860   -36.294434     3.036851   -42.282972 - -30.305896 
  2009:1    -70.239280   -44.018178     4.007017   -51.919841 - -36.116516 
  2009:2    -27.024588   -12.284842     1.427414   -15.099640 - -9.470044 
  2009:3      8.078897     4.483669     1.315876     1.888819 - 7.078520 
 
  Forecast evaluation statistics 
 
  Mean Error                       -3.7387 
  Mean Squared Error                218.61 
  Root Mean Squared Error           14.785 
  Mean Absolute Error               12.646 
  Mean Percentage Error            -7.1173 
  Mean Absolute Percentage Error   -43.867 
  Theil's U                         0.4365 
  Bias proportion, UM               0.06394 
  Regression proportion, UR         0.13557 
  Disturbance proportion, UD        0.80049 
 
#forecast actual y 
 For 95% confidence intervals, t(199, 0.025) = 1.972 
 
     Obs ds_l_realinv    prediction    std. error        95% interval 
 
  2008:3     -7.134492   -17.177905    11.101892   -39.070353 - 4.714544 
  2008:4    -27.665860   -36.294434    11.126262   -58.234939 - -14.353928 
  2009:1    -70.239280   -44.018178    11.429236   -66.556135 - -21.480222 
  2009:2    -27.024588   -12.284842    10.798554   -33.579120 - 9.009436 
  2009:3      8.078897     4.483669    10.784377   -16.782652 - 25.749991 
 
  Forecast evaluation statistics 
 
  Mean Error                       -3.7387 
  Mean Squared Error                218.61 
  Root Mean Squared Error           14.785 
  Mean Absolute Error               12.646 
  Mean Percentage Error            -7.1173 
  Mean Absolute Percentage Error   -43.867 
  Theil's U                         0.4365 
  Bias proportion, UM               0.06394 
  Regression proportion, UR         0.13557 
  Disturbance proportion, UD        0.80049 
 
'''</span>
</pre>
</body>
</html>
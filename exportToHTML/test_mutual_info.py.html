<html>
<head>
<title>test_mutual_info.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_mutual_info.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">csr_matrix</span>

<span class="s0">from </span><span class="s1">sklearn.feature_selection </span><span class="s0">import </span><span class="s1">mutual_info_classif</span><span class="s0">, </span><span class="s1">mutual_info_regression</span>
<span class="s0">from </span><span class="s1">sklearn.feature_selection._mutual_info </span><span class="s0">import </span><span class="s1">_compute_mi</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">check_random_state</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_compute_mi_dd():</span>
    <span class="s2"># In discrete case computations are straightforward and can be done</span>
    <span class="s2"># by hand on given vectors.</span>
    <span class="s1">x = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">])</span>
    <span class="s1">y = np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

    <span class="s1">H_x = H_y = -(</span><span class="s3">3 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">) * np.log(</span><span class="s3">3 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">) - (</span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">) * np.log(</span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">H_xy = -</span><span class="s3">1 </span><span class="s1">/ </span><span class="s3">5 </span><span class="s1">* np.log(</span><span class="s3">1 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">) - </span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5 </span><span class="s1">* np.log(</span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">) - </span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5 </span><span class="s1">* np.log(</span><span class="s3">2 </span><span class="s1">/ </span><span class="s3">5</span><span class="s1">)</span>
    <span class="s1">I_xy = H_x + H_y - H_xy</span>

    <span class="s1">assert_allclose(_compute_mi(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">x_discrete=</span><span class="s0">True, </span><span class="s1">y_discrete=</span><span class="s0">True</span><span class="s1">)</span><span class="s0">, </span><span class="s1">I_xy)</span>


<span class="s0">def </span><span class="s1">test_compute_mi_cc(global_dtype):</span>
    <span class="s2"># For two continuous variables a good approach is to test on bivariate</span>
    <span class="s2"># normal distribution, where mutual information is known.</span>

    <span class="s2"># Mean of the distribution, irrelevant for mutual information.</span>
    <span class="s1">mean = np.zeros(</span><span class="s3">2</span><span class="s1">)</span>

    <span class="s2"># Setup covariance matrix with correlation coeff. equal 0.5.</span>
    <span class="s1">sigma_1 = </span><span class="s3">1</span>
    <span class="s1">sigma_2 = </span><span class="s3">10</span>
    <span class="s1">corr = </span><span class="s3">0.5</span>
    <span class="s1">cov = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[sigma_1**</span><span class="s3">2</span><span class="s0">, </span><span class="s1">corr * sigma_1 * sigma_2]</span><span class="s0">,</span>
            <span class="s1">[corr * sigma_1 * sigma_2</span><span class="s0">, </span><span class="s1">sigma_2**</span><span class="s3">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>

    <span class="s2"># True theoretical mutual information.</span>
    <span class="s1">I_theory = np.log(sigma_1) + np.log(sigma_2) - </span><span class="s3">0.5 </span><span class="s1">* np.log(np.linalg.det(cov))</span>

    <span class="s1">rng = check_random_state(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Z = rng.multivariate_normal(mean</span><span class="s0">, </span><span class="s1">cov</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">1000</span><span class="s1">).astype(global_dtype</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">x</span><span class="s0">, </span><span class="s1">y = Z[:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">Z[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>

    <span class="s2"># Theory and computed values won't be very close</span>
    <span class="s2"># We here check with a large relative tolerance</span>
    <span class="s0">for </span><span class="s1">n_neighbors </span><span class="s0">in </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]:</span>
        <span class="s1">I_computed = _compute_mi(</span>
            <span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">x_discrete=</span><span class="s0">False, </span><span class="s1">y_discrete=</span><span class="s0">False, </span><span class="s1">n_neighbors=n_neighbors</span>
        <span class="s1">)</span>
        <span class="s1">assert_allclose(I_computed</span><span class="s0">, </span><span class="s1">I_theory</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_compute_mi_cd(global_dtype):</span>
    <span class="s2"># To test define a joint distribution as follows:</span>
    <span class="s2"># p(x, y) = p(x) p(y | x)</span>
    <span class="s2"># X ~ Bernoulli(p)</span>
    <span class="s2"># (Y | x = 0) ~ Uniform(-1, 1)</span>
    <span class="s2"># (Y | x = 1) ~ Uniform(0, 2)</span>

    <span class="s2"># Use the following formula for mutual information:</span>
    <span class="s2"># I(X; Y) = H(Y) - H(Y | X)</span>
    <span class="s2"># Two entropies can be computed by hand:</span>
    <span class="s2"># H(Y) = -(1-p)/2 * ln((1-p)/2) - p/2*log(p/2) - 1/2*log(1/2)</span>
    <span class="s2"># H(Y | X) = ln(2)</span>

    <span class="s2"># Now we need to implement sampling from out distribution, which is</span>
    <span class="s2"># done easily using conditional distribution logic.</span>

    <span class="s1">n_samples = </span><span class="s3">1000</span>
    <span class="s1">rng = check_random_state(</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">p </span><span class="s0">in </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.7</span><span class="s1">]:</span>
        <span class="s1">x = rng.uniform(size=n_samples) &gt; p</span>

        <span class="s1">y = np.empty(n_samples</span><span class="s0">, </span><span class="s1">global_dtype)</span>
        <span class="s1">mask = x == </span><span class="s3">0</span>
        <span class="s1">y[mask] = rng.uniform(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=np.sum(mask))</span>
        <span class="s1">y[~mask] = rng.uniform(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=np.sum(~mask))</span>

        <span class="s1">I_theory = -</span><span class="s3">0.5 </span><span class="s1">* (</span>
            <span class="s1">(</span><span class="s3">1 </span><span class="s1">- p) * np.log(</span><span class="s3">0.5 </span><span class="s1">* (</span><span class="s3">1 </span><span class="s1">- p)) + p * np.log(</span><span class="s3">0.5 </span><span class="s1">* p) + np.log(</span><span class="s3">0.5</span><span class="s1">)</span>
        <span class="s1">) - np.log(</span><span class="s3">2</span><span class="s1">)</span>

        <span class="s2"># Assert the same tolerance.</span>
        <span class="s0">for </span><span class="s1">n_neighbors </span><span class="s0">in </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]:</span>
            <span class="s1">I_computed = _compute_mi(</span>
                <span class="s1">x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">x_discrete=</span><span class="s0">True, </span><span class="s1">y_discrete=</span><span class="s0">False, </span><span class="s1">n_neighbors=n_neighbors</span>
            <span class="s1">)</span>
            <span class="s1">assert_allclose(I_computed</span><span class="s0">, </span><span class="s1">I_theory</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_compute_mi_cd_unique_label(global_dtype):</span>
    <span class="s2"># Test that adding unique label doesn't change MI.</span>
    <span class="s1">n_samples = </span><span class="s3">100</span>
    <span class="s1">x = np.random.uniform(size=n_samples) &gt; </span><span class="s3">0.5</span>

    <span class="s1">y = np.empty(n_samples</span><span class="s0">, </span><span class="s1">global_dtype)</span>
    <span class="s1">mask = x == </span><span class="s3">0</span>
    <span class="s1">y[mask] = np.random.uniform(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=np.sum(mask))</span>
    <span class="s1">y[~mask] = np.random.uniform(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=np.sum(~mask))</span>

    <span class="s1">mi_1 = _compute_mi(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">x_discrete=</span><span class="s0">True, </span><span class="s1">y_discrete=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">x = np.hstack((x</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))</span>
    <span class="s1">y = np.hstack((y</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">mi_2 = _compute_mi(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">x_discrete=</span><span class="s0">True, </span><span class="s1">y_discrete=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">assert_allclose(mi_1</span><span class="s0">, </span><span class="s1">mi_2)</span>


<span class="s2"># We are going test that feature ordering by MI matches our expectations.</span>
<span class="s0">def </span><span class="s1">test_mutual_info_classif_discrete(global_dtype):</span>
    <span class="s1">X = np.array(</span>
        <span class="s1">[[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=global_dtype</span>
    <span class="s1">)</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>

    <span class="s2"># Here X[:, 0] is the most informative feature, and X[:, 1] is weakly</span>
    <span class="s2"># informative.</span>
    <span class="s1">mi = mutual_info_classif(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(np.argsort(-mi)</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]))</span>


<span class="s0">def </span><span class="s1">test_mutual_info_regression(global_dtype):</span>
    <span class="s2"># We generate sample from multivariate normal distribution, using</span>
    <span class="s2"># transformation from initially uncorrelated variables. The zero</span>
    <span class="s2"># variables after transformation is selected as the target vector,</span>
    <span class="s2"># it has the strongest correlation with the variable 2, and</span>
    <span class="s2"># the weakest correlation with the variable 1.</span>
    <span class="s1">T = np.array([[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]])</span>
    <span class="s1">cov = T.dot(T.T)</span>
    <span class="s1">mean = np.zeros(</span><span class="s3">4</span><span class="s1">)</span>

    <span class="s1">rng = check_random_state(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">Z = rng.multivariate_normal(mean</span><span class="s0">, </span><span class="s1">cov</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">1000</span><span class="s1">).astype(global_dtype</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">X = Z[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">:]</span>
    <span class="s1">y = Z[:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">mi = mutual_info_regression(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(np.argsort(-mi)</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]))</span>
    <span class="s2"># XXX: should mutual_info_regression be fixed to avoid</span>
    <span class="s2"># up-casting float32 inputs to float64?</span>
    <span class="s0">assert </span><span class="s1">mi.dtype == np.float64</span>


<span class="s0">def </span><span class="s1">test_mutual_info_classif_mixed(global_dtype):</span>
    <span class="s2"># Here the target is discrete and there are two continuous and one</span>
    <span class="s2"># discrete feature. The idea of this test is clear from the code.</span>
    <span class="s1">rng = check_random_state(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rng.rand(</span><span class="s3">1000</span><span class="s0">, </span><span class="s3">3</span><span class="s1">).astype(global_dtype</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">X[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] += X[:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">y = ((</span><span class="s3">0.5 </span><span class="s1">* X[:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] + X[:</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]) &gt; </span><span class="s3">0.5</span><span class="s1">).astype(int)</span>
    <span class="s1">X[:</span><span class="s0">, </span><span class="s3">2</span><span class="s1">] = X[:</span><span class="s0">, </span><span class="s3">2</span><span class="s1">] &gt; </span><span class="s3">0.5</span>

    <span class="s1">mi = mutual_info_classif(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_neighbors=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(np.argsort(-mi)</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">])</span>
    <span class="s0">for </span><span class="s1">n_neighbors </span><span class="s0">in </span><span class="s1">[</span><span class="s3">5</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">9</span><span class="s1">]:</span>
        <span class="s1">mi_nn = mutual_info_classif(</span>
            <span class="s1">X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_neighbors=n_neighbors</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span>
        <span class="s1">)</span>
        <span class="s2"># Check that the continuous values have an higher MI with greater</span>
        <span class="s2"># n_neighbors</span>
        <span class="s0">assert </span><span class="s1">mi_nn[</span><span class="s3">0</span><span class="s1">] &gt; mi[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s0">assert </span><span class="s1">mi_nn[</span><span class="s3">1</span><span class="s1">] &gt; mi[</span><span class="s3">1</span><span class="s1">]</span>
        <span class="s2"># The n_neighbors should not have any effect on the discrete value</span>
        <span class="s2"># The MI should be the same</span>
        <span class="s0">assert </span><span class="s1">mi_nn[</span><span class="s3">2</span><span class="s1">] == mi[</span><span class="s3">2</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">test_mutual_info_options(global_dtype):</span>
    <span class="s1">X = np.array(</span>
        <span class="s1">[[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">dtype=global_dtype</span>
    <span class="s1">)</span>
    <span class="s1">y = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=global_dtype)</span>
    <span class="s1">X_csr = csr_matrix(X)</span>

    <span class="s0">for </span><span class="s1">mutual_info </span><span class="s0">in </span><span class="s1">(mutual_info_regression</span><span class="s0">, </span><span class="s1">mutual_info_classif):</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">mutual_info(X_csr</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s0">False</span><span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s4">&quot;manual&quot;</span><span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">mutual_info(X_csr</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s0">True, False, True</span><span class="s1">])</span>
        <span class="s0">with </span><span class="s1">pytest.raises(IndexError):</span>
            <span class="s1">mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s0">True, False, True, False</span><span class="s1">])</span>
        <span class="s0">with </span><span class="s1">pytest.raises(IndexError):</span>
            <span class="s1">mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">4</span><span class="s1">])</span>

        <span class="s1">mi_1 = mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">mi_2 = mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s0">False, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">mi_3 = mutual_info(X_csr</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">mi_4 = mutual_info(X_csr</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">mi_5 = mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s0">True, False, True</span><span class="s1">]</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">mi_6 = mutual_info(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>

        <span class="s1">assert_allclose(mi_1</span><span class="s0">, </span><span class="s1">mi_2)</span>
        <span class="s1">assert_allclose(mi_3</span><span class="s0">, </span><span class="s1">mi_4)</span>
        <span class="s1">assert_allclose(mi_5</span><span class="s0">, </span><span class="s1">mi_6)</span>

        <span class="s0">assert not </span><span class="s1">np.allclose(mi_1</span><span class="s0">, </span><span class="s1">mi_3)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;correlated&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_mutual_information_symmetry_classif_regression(correlated</span><span class="s0">, </span><span class="s1">global_random_seed):</span>
    <span class="s5">&quot;&quot;&quot;Check that `mutual_info_classif` and `mutual_info_regression` are 
    symmetric by switching the target `y` as `feature` in `X` and vice 
    versa. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/23720 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">n = </span><span class="s3">100</span>
    <span class="s1">d = rng.randint(</span><span class="s3">10</span><span class="s0">, </span><span class="s1">size=n)</span>

    <span class="s0">if </span><span class="s1">correlated:</span>
        <span class="s1">c = d.astype(np.float64)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">c = rng.normal(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=n)</span>

    <span class="s1">mi_classif = mutual_info_classif(</span>
        <span class="s1">c[:</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s0">False</span><span class="s1">]</span><span class="s0">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">)</span>

    <span class="s1">mi_regression = mutual_info_regression(</span>
        <span class="s1">d[:</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">discrete_features=[</span><span class="s0">True</span><span class="s1">]</span><span class="s0">, </span><span class="s1">random_state=global_random_seed</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">mi_classif == pytest.approx(mi_regression)</span>


<span class="s0">def </span><span class="s1">test_mutual_info_regression_X_int_dtype(global_random_seed):</span>
    <span class="s5">&quot;&quot;&quot;Check that results agree when X is integer dtype and float dtype. 
 
    Non-regression test for Issue #26696. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">X = rng.randint(</span><span class="s3">100</span><span class="s0">, </span><span class="s1">size=(</span><span class="s3">100</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span>
    <span class="s1">X_float = X.astype(np.float64</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">y = rng.randint(</span><span class="s3">100</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s1">)</span>

    <span class="s1">expected = mutual_info_regression(X_float</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">result = mutual_info_regression(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">assert_allclose(result</span><span class="s0">, </span><span class="s1">expected)</span>
</pre>
</body>
</html>
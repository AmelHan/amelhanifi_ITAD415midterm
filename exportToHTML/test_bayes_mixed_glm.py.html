<html>
<head>
<title>test_bayes_mixed_glm.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_bayes_mixed_glm.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">statsmodels.genmod.bayes_mixed_glm </span><span class="s0">import </span><span class="s1">(BinomialBayesMixedGLM</span><span class="s0">,</span>
                                                <span class="s1">PoissonBayesMixedGLM)</span>
<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">sparse</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_equal</span>
<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">approx_fprime</span>


<span class="s0">def </span><span class="s1">gen_simple_logit(nc</span><span class="s0">, </span><span class="s1">cs</span><span class="s0">, </span><span class="s1">s):</span>

    <span class="s1">np.random.seed(</span><span class="s2">3799</span><span class="s1">)</span>

    <span class="s1">exog_vc = np.kron(np.eye(nc)</span><span class="s0">, </span><span class="s1">np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)))</span>
    <span class="s1">exog_fe = np.random.normal(size=(nc * cs</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
    <span class="s1">vc = s * np.random.normal(size=nc)</span>
    <span class="s1">lp = np.dot(exog_fe</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]) + np.dot(exog_vc</span><span class="s0">, </span><span class="s1">vc)</span>
    <span class="s1">pr = </span><span class="s2">1 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ np.exp(-lp))</span>
    <span class="s1">y = </span><span class="s2">1 </span><span class="s1">* (np.random.uniform(size=nc * cs) &lt; pr)</span>
    <span class="s1">ident = np.zeros(nc</span><span class="s0">, </span><span class="s1">dtype=int)</span>

    <span class="s0">return </span><span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span>


<span class="s0">def </span><span class="s1">gen_simple_poisson(nc</span><span class="s0">, </span><span class="s1">cs</span><span class="s0">, </span><span class="s1">s):</span>

    <span class="s1">np.random.seed(</span><span class="s2">3799</span><span class="s1">)</span>

    <span class="s1">exog_vc = np.kron(np.eye(nc)</span><span class="s0">, </span><span class="s1">np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)))</span>
    <span class="s1">exog_fe = np.random.normal(size=(nc * cs</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
    <span class="s1">vc = s * np.random.normal(size=nc)</span>
    <span class="s1">lp = np.dot(exog_fe</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.1</span><span class="s1">]) + np.dot(exog_vc</span><span class="s0">, </span><span class="s1">vc)</span>
    <span class="s1">r = np.exp(lp)</span>
    <span class="s1">y = np.random.poisson(r)</span>
    <span class="s1">ident = np.zeros(nc</span><span class="s0">, </span><span class="s1">dtype=int)</span>

    <span class="s0">return </span><span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span>


<span class="s0">def </span><span class="s1">gen_crossed_logit(nc</span><span class="s0">, </span><span class="s1">cs</span><span class="s0">, </span><span class="s1">s1</span><span class="s0">, </span><span class="s1">s2):</span>

    <span class="s1">np.random.seed(</span><span class="s2">3799</span><span class="s1">)</span>

    <span class="s1">a = np.kron(np.eye(nc)</span><span class="s0">, </span><span class="s1">np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)))</span>
    <span class="s1">b = np.kron(np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))</span><span class="s0">, </span><span class="s1">np.eye(nc))</span>
    <span class="s1">exog_vc = np.concatenate((a</span><span class="s0">, </span><span class="s1">b)</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)</span>

    <span class="s1">exog_fe = np.random.normal(size=(nc * cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))</span>
    <span class="s1">vc = s1 * np.random.normal(size=</span><span class="s2">2 </span><span class="s1">* nc)</span>
    <span class="s1">vc[nc:] *= s2 / s1</span>
    <span class="s1">lp = np.dot(exog_fe</span><span class="s0">, </span><span class="s1">np.r_[-</span><span class="s2">0.5</span><span class="s1">]) + np.dot(exog_vc</span><span class="s0">, </span><span class="s1">vc)</span>
    <span class="s1">pr = </span><span class="s2">1 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ np.exp(-lp))</span>
    <span class="s1">y = </span><span class="s2">1 </span><span class="s1">* (np.random.uniform(size=nc * cs) &lt; pr)</span>
    <span class="s1">ident = np.zeros(</span><span class="s2">2 </span><span class="s1">* nc</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">ident[nc:] = </span><span class="s2">1</span>

    <span class="s0">return </span><span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span>


<span class="s0">def </span><span class="s1">gen_crossed_poisson(nc</span><span class="s0">, </span><span class="s1">cs</span><span class="s0">, </span><span class="s1">s1</span><span class="s0">, </span><span class="s1">s2):</span>

    <span class="s1">np.random.seed(</span><span class="s2">3799</span><span class="s1">)</span>

    <span class="s1">a = np.kron(np.eye(nc)</span><span class="s0">, </span><span class="s1">np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)))</span>
    <span class="s1">b = np.kron(np.ones((cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))</span><span class="s0">, </span><span class="s1">np.eye(nc))</span>
    <span class="s1">exog_vc = np.concatenate((a</span><span class="s0">, </span><span class="s1">b)</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)</span>

    <span class="s1">exog_fe = np.random.normal(size=(nc * cs</span><span class="s0">, </span><span class="s2">1</span><span class="s1">))</span>
    <span class="s1">vc = s1 * np.random.normal(size=</span><span class="s2">2 </span><span class="s1">* nc)</span>
    <span class="s1">vc[nc:] *= s2 / s1</span>
    <span class="s1">lp = np.dot(exog_fe</span><span class="s0">, </span><span class="s1">np.r_[-</span><span class="s2">0.5</span><span class="s1">]) + np.dot(exog_vc</span><span class="s0">, </span><span class="s1">vc)</span>
    <span class="s1">r = np.exp(lp)</span>
    <span class="s1">y = np.random.poisson(r)</span>
    <span class="s1">ident = np.zeros(</span><span class="s2">2 </span><span class="s1">* nc</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">ident[nc:] = </span><span class="s2">1</span>

    <span class="s0">return </span><span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span>


<span class="s0">def </span><span class="s1">gen_crossed_logit_pandas(nc</span><span class="s0">, </span><span class="s1">cs</span><span class="s0">, </span><span class="s1">s1</span><span class="s0">, </span><span class="s1">s2):</span>

    <span class="s1">np.random.seed(</span><span class="s2">3799</span><span class="s1">)</span>

    <span class="s1">a = np.kron(np.arange(nc)</span><span class="s0">, </span><span class="s1">np.ones(cs))</span>
    <span class="s1">b = np.kron(np.ones(cs)</span><span class="s0">, </span><span class="s1">np.arange(nc))</span>
    <span class="s1">fe = np.ones(nc * cs)</span>

    <span class="s1">vc = np.zeros(nc * cs)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">np.unique(a):</span>
        <span class="s1">ii = np.flatnonzero(a == i)</span>
        <span class="s1">vc[ii] += s1 * np.random.normal()</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">np.unique(b):</span>
        <span class="s1">ii = np.flatnonzero(b == i)</span>
        <span class="s1">vc[ii] += s2 * np.random.normal()</span>

    <span class="s1">lp = -</span><span class="s2">0.5 </span><span class="s1">* fe + vc</span>
    <span class="s1">pr = </span><span class="s2">1 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ np.exp(-lp))</span>
    <span class="s1">y = </span><span class="s2">1 </span><span class="s1">* (np.random.uniform(size=nc * cs) &lt; pr)</span>

    <span class="s1">ident = np.zeros(</span><span class="s2">2 </span><span class="s1">* nc</span><span class="s0">, </span><span class="s1">dtype=int)</span>
    <span class="s1">ident[nc:] = </span><span class="s2">1</span>

    <span class="s1">df = pd.DataFrame({</span><span class="s3">&quot;fe&quot;</span><span class="s1">: fe</span><span class="s0">, </span><span class="s3">&quot;a&quot;</span><span class="s1">: a</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">: b</span><span class="s0">, </span><span class="s3">&quot;y&quot;</span><span class="s1">: y})</span>

    <span class="s0">return </span><span class="s1">df</span>


<span class="s0">def </span><span class="s1">test_simple_logit_map():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm = BinomialBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt = glmm.fit_map()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">glmm.logposterior_grad(rslt.params)</span><span class="s0">,</span>
        <span class="s1">np.zeros_like(rslt.params)</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-3</span><span class="s1">)</span>

    <span class="s4"># Test the predict method</span>
    <span class="s0">for </span><span class="s1">linear </span><span class="s0">in False, True</span><span class="s1">:</span>
        <span class="s0">for </span><span class="s1">exog </span><span class="s0">in None, </span><span class="s1">exog_fe:</span>
            <span class="s1">pr1 = rslt.predict(linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">pr2 = glmm.predict(rslt.params</span><span class="s0">, </span><span class="s1">linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">assert_allclose(pr1</span><span class="s0">, </span><span class="s1">pr2)</span>
            <span class="s0">if not </span><span class="s1">linear:</span>
                <span class="s1">assert_equal(pr1.min() &gt;= </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">)</span>
                <span class="s1">assert_equal(pr1.max() &lt;= </span><span class="s2">1</span><span class="s0">, True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_simple_poisson_map():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_poisson(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">0.2</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm1 = PoissonBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_map()</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">glmm1.logposterior_grad(rslt1.params)</span><span class="s0">,</span>
        <span class="s1">np.zeros_like(rslt1.params)</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-3</span><span class="s1">)</span>

    <span class="s4"># This should give the same answer as above</span>
    <span class="s1">glmm2 = PoissonBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_map()</span>
    <span class="s1">assert_allclose(rslt1.params</span><span class="s0">, </span><span class="s1">rslt2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s4"># Test the predict method</span>
    <span class="s0">for </span><span class="s1">linear </span><span class="s0">in False, True</span><span class="s1">:</span>
        <span class="s0">for </span><span class="s1">exog </span><span class="s0">in None, </span><span class="s1">exog_fe:</span>
            <span class="s1">pr1 = rslt1.predict(linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">pr2 = rslt2.predict(linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">pr3 = glmm1.predict(rslt1.params</span><span class="s0">, </span><span class="s1">linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">pr4 = glmm2.predict(rslt2.params</span><span class="s0">, </span><span class="s1">linear=linear</span><span class="s0">, </span><span class="s1">exog=exog)</span>
            <span class="s1">assert_allclose(pr1</span><span class="s0">, </span><span class="s1">pr2</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
            <span class="s1">assert_allclose(pr2</span><span class="s0">, </span><span class="s1">pr3</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
            <span class="s1">assert_allclose(pr3</span><span class="s0">, </span><span class="s1">pr4</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
            <span class="s0">if not </span><span class="s1">linear:</span>
                <span class="s1">assert_equal(pr1.min() &gt;= </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">)</span>
                <span class="s1">assert_equal(pr2.min() &gt;= </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">)</span>
                <span class="s1">assert_equal(pr3.min() &gt;= </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">)</span>

    <span class="s4"># Check dimensions and PSD status of cov_params</span>
    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
        <span class="s1">np.linalg.cholesky(cp)</span>


<span class="s0">def </span><span class="s1">test_crossed_logit_map():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm = BinomialBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt = glmm.fit_map()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">glmm.logposterior_grad(rslt.params)</span><span class="s0">,</span>
        <span class="s1">np.zeros_like(rslt.params)</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s4"># Check dimensions and PSD status of cov_params</span>
    <span class="s1">cp = rslt.cov_params()</span>
    <span class="s1">p = len(rslt.params)</span>
    <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
    <span class="s1">np.linalg.cholesky(cp)</span>


<span class="s0">def </span><span class="s1">test_crossed_poisson_map():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_poisson(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm = PoissonBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt = glmm.fit_map()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">glmm.logposterior_grad(rslt.params)</span><span class="s0">,</span>
        <span class="s1">np.zeros_like(rslt.params)</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s4"># Check dimensions and PSD status of cov_params</span>
    <span class="s1">cp = rslt.cov_params()</span>
    <span class="s1">p = len(rslt.params)</span>
    <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
    <span class="s1">np.linalg.cholesky(cp)</span>

<span class="s0">def </span><span class="s1">test_logit_map_crossed_formula():</span>

    <span class="s1">data = gen_crossed_logit_pandas(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">)</span>

    <span class="s1">fml = </span><span class="s3">&quot;y ~ fe&quot;</span>
    <span class="s1">fml_vc = {</span><span class="s3">&quot;a&quot;</span><span class="s1">: </span><span class="s3">&quot;0 + C(a)&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">: </span><span class="s3">&quot;0 + C(b)&quot;</span><span class="s1">}</span>
    <span class="s1">glmm = BinomialBayesMixedGLM.from_formula(fml</span><span class="s0">, </span><span class="s1">fml_vc</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt = glmm.fit_map()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">glmm.logposterior_grad(rslt.params)</span><span class="s0">,</span>
        <span class="s1">np.zeros_like(rslt.params)</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
    <span class="s1">rslt.summary()</span>

    <span class="s1">r = rslt.random_effects(</span><span class="s3">&quot;a&quot;</span><span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">r.iloc[</span><span class="s2">0</span><span class="s0">, </span><span class="s1">:].values</span><span class="s0">, </span><span class="s1">np.r_[-</span><span class="s2">0.02004904</span><span class="s0">, </span><span class="s2">0.094014</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s4"># Check dimensions and PSD status of cov_params</span>
    <span class="s1">cm = rslt.cov_params()</span>
    <span class="s1">p = rslt.params.shape[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">assert_equal(list(cm.shape)</span><span class="s0">, </span><span class="s1">[p</span><span class="s0">, </span><span class="s1">p])</span>
    <span class="s1">np.linalg.cholesky(cm)</span>

<span class="s0">def </span><span class="s1">test_elbo_grad():</span>

    <span class="s0">for </span><span class="s1">f </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">2</span><span class="s1">):</span>
        <span class="s0">for </span><span class="s1">j </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">2</span><span class="s1">):</span>

            <span class="s0">if </span><span class="s1">f == </span><span class="s2">0</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">j == </span><span class="s2">0</span><span class="s1">:</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_logit(</span>
                        <span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
            <span class="s0">elif </span><span class="s1">f == </span><span class="s2">1</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">j == </span><span class="s2">0</span><span class="s1">:</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_poisson(</span>
                        <span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_poisson(</span>
                        <span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">)</span>

            <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

            <span class="s0">if </span><span class="s1">f == </span><span class="s2">0</span><span class="s1">:</span>
                <span class="s1">glmm1 = BinomialBayesMixedGLM(</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">glmm1 = PoissonBayesMixedGLM(</span>
                    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>

            <span class="s1">rslt1 = glmm1.fit_map()</span>

            <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">3</span><span class="s1">):</span>

                <span class="s0">if </span><span class="s1">k == </span><span class="s2">0</span><span class="s1">:</span>
                    <span class="s1">vb_mean = rslt1.params</span>
                    <span class="s1">vb_sd = np.ones_like(vb_mean)</span>
                <span class="s0">elif </span><span class="s1">k == </span><span class="s2">1</span><span class="s1">:</span>
                    <span class="s1">vb_mean = np.zeros(len(vb_mean))</span>
                    <span class="s1">vb_sd = np.ones_like(vb_mean)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">vb_mean = np.random.normal(size=len(vb_mean))</span>
                    <span class="s1">vb_sd = np.random.uniform(</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s1">size=len(vb_mean))</span>

                <span class="s1">mean_grad</span><span class="s0">, </span><span class="s1">sd_grad = glmm1.vb_elbo_grad(vb_mean</span><span class="s0">, </span><span class="s1">vb_sd)</span>

                <span class="s0">def </span><span class="s1">elbo(vec):</span>
                    <span class="s1">n = len(vec) // </span><span class="s2">2</span>
                    <span class="s0">return </span><span class="s1">glmm1.vb_elbo(vec[:n]</span><span class="s0">, </span><span class="s1">vec[n:])</span>

                <span class="s1">x = np.concatenate((vb_mean</span><span class="s0">, </span><span class="s1">vb_sd))</span>
                <span class="s1">g1 = approx_fprime(x</span><span class="s0">, </span><span class="s1">elbo</span><span class="s0">, </span><span class="s2">1e-5</span><span class="s1">)</span>
                <span class="s1">n = len(x) // </span><span class="s2">2</span>

                <span class="s1">mean_grad_n = g1[:n]</span>
                <span class="s1">sd_grad_n = g1[n:]</span>

                <span class="s1">assert_allclose(mean_grad</span><span class="s0">, </span><span class="s1">mean_grad_n</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-2</span><span class="s1">)</span>
                <span class="s1">assert_allclose(sd_grad</span><span class="s0">, </span><span class="s1">sd_grad_n</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_simple_logit_vb():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm1 = BinomialBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_map()</span>

    <span class="s1">glmm2 = BinomialBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_vb(rslt1.params)</span>

    <span class="s1">rslt1.summary()</span>
    <span class="s1">rslt2.summary()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">0.75330405</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.71643228</span><span class="s0">, </span><span class="s1">-</span><span class="s2">2.49091288</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.00959806</span><span class="s0">, </span><span class="s2">0.00450254</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">0.79338836</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.7599833</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.64149356</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.24772884</span><span class="s0">, </span><span class="s2">0.10775366</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s0">if </span><span class="s1">rslt </span><span class="s0">is </span><span class="s1">rslt1:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
            <span class="s1">np.linalg.cholesky(cp)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>

<span class="s0">def </span><span class="s1">test_simple_poisson_vb():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_poisson(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">glmm1 = PoissonBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_map()</span>

    <span class="s1">glmm2 = PoissonBayesMixedGLM(y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_vb(rslt1.params)</span>

    <span class="s1">rslt1.summary()</span>
    <span class="s1">rslt2.summary()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">0.07233493</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.06706505</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.47159649</span><span class="s0">, </span><span class="s2">1.12575122</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.02442201</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.cov_params().flat[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">0.00790914</span><span class="s0">, </span><span class="s2">0.00080666</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.00050719</span><span class="s0">, </span><span class="s2">0.00022648</span><span class="s0">, </span><span class="s2">0.00046235</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">0.07088814</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.06373107</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.22770786</span><span class="s0">, </span><span class="s2">1.12923746</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.26161339</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.cov_params()[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">0.00747782</span><span class="s0">, </span><span class="s2">0.0092554</span><span class="s0">, </span><span class="s2">0.04508904</span><span class="s0">, </span><span class="s2">0.02934488</span><span class="s0">, </span><span class="s2">0.20312746</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s0">if </span><span class="s1">rslt </span><span class="s0">is </span><span class="s1">rslt1:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
            <span class="s1">np.linalg.cholesky(cp)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>


<span class="s0">def </span><span class="s1">test_crossed_logit_vb():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>

    <span class="s1">glmm1 = BinomialBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_map()</span>

    <span class="s1">glmm2 = BinomialBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_vb(mean=rslt1.params)</span>

    <span class="s1">rslt1.summary()</span>
    <span class="s1">rslt2.summary()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">5.43073978e-01</span><span class="s0">, </span><span class="s1">-</span><span class="s2">2.46197518e+00</span><span class="s0">, </span><span class="s1">-</span><span class="s2">2.36582801e+00</span><span class="s0">,</span>
              <span class="s1">-</span><span class="s2">9.64030461e-03</span><span class="s0">, </span><span class="s2">2.32701078e-03</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.cov_params().flat[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">4.12927123e-02</span><span class="s0">, </span><span class="s1">-</span><span class="s2">2.04448923e-04</span><span class="s0">, </span><span class="s2">4.64829219e-05</span><span class="s0">, </span><span class="s2">1.20377543e-04</span><span class="s0">,</span>
              <span class="s1">-</span><span class="s2">1.45003234e-04</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">0.70834417</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.3571011</span><span class="s0">, </span><span class="s2">0.19126823</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.36074489</span><span class="s0">, </span><span class="s2">0.058976</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.cov_params()[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[</span><span class="s2">0.05212492</span><span class="s0">, </span><span class="s2">0.04729656</span><span class="s0">, </span><span class="s2">0.03916944</span><span class="s0">, </span><span class="s2">0.25921842</span><span class="s0">, </span><span class="s2">0.25782576</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s0">if </span><span class="s1">rslt </span><span class="s0">is </span><span class="s1">rslt1:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
            <span class="s1">np.linalg.cholesky(cp)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>


<span class="s0">def </span><span class="s1">test_crossed_logit_vb_formula():</span>

    <span class="s1">data = gen_crossed_logit_pandas(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>

    <span class="s1">fml = </span><span class="s3">&quot;y ~ fe&quot;</span>
    <span class="s1">fml_vc = {</span><span class="s3">&quot;a&quot;</span><span class="s1">: </span><span class="s3">&quot;0 + C(a)&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">: </span><span class="s3">&quot;0 + C(b)&quot;</span><span class="s1">}</span>
    <span class="s1">glmm1 = BinomialBayesMixedGLM.from_formula(fml</span><span class="s0">, </span><span class="s1">fml_vc</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_vb()</span>

    <span class="s1">glmm2 = BinomialBayesMixedGLM(</span>
        <span class="s1">glmm1.endog</span><span class="s0">, </span><span class="s1">glmm1.exog</span><span class="s0">, </span><span class="s1">glmm1.exog_vc</span><span class="s0">, </span><span class="s1">glmm1.ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_vb()</span>

    <span class="s1">assert_allclose(rslt1.params</span><span class="s0">, </span><span class="s1">rslt2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">rslt1.summary()</span>
    <span class="s1">rslt2.summary()</span>

    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s0">if </span><span class="s1">rslt </span><span class="s0">is </span><span class="s1">rslt1:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>


<span class="s0">def </span><span class="s1">test_crossed_poisson_vb():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_poisson(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">)</span>

    <span class="s1">glmm1 = PoissonBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt1 = glmm1.fit_map()</span>

    <span class="s1">glmm2 = PoissonBayesMixedGLM(</span>
        <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
    <span class="s1">rslt2 = glmm2.fit_vb(mean=rslt1.params)</span>

    <span class="s1">rslt1.summary()</span>
    <span class="s1">rslt2.summary()</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt1.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">0.54855281</span><span class="s0">, </span><span class="s2">0.10458834</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.68777741</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.01699925</span><span class="s0">, </span><span class="s2">0.77200546</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">rslt2.params[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">5</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">np.r_[-</span><span class="s2">0.54691502</span><span class="s0">, </span><span class="s2">0.22297158</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.52673802</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.06218684</span><span class="s0">, </span><span class="s2">0.74385237</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
        <span class="s1">cp = rslt.cov_params()</span>
        <span class="s1">p = len(rslt.params)</span>
        <span class="s0">if </span><span class="s1">rslt </span><span class="s0">is </span><span class="s1">rslt1:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
            <span class="s1">np.linalg.cholesky(cp)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
            <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>


<span class="s0">def </span><span class="s1">test_poisson_formula():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_crossed_poisson(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">vb </span><span class="s0">in False, True</span><span class="s1">:</span>

        <span class="s1">glmm1 = PoissonBayesMixedGLM(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident)</span>
        <span class="s0">if </span><span class="s1">vb:</span>
            <span class="s1">rslt1 = glmm1.fit_vb()</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">rslt1 = glmm1.fit_map()</span>

        <span class="s4"># Build categorical variables that match exog_vc</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s3">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">, </span><span class="s3">&quot;x1&quot;</span><span class="s1">: exog_fe[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]})</span>
        <span class="s1">z1 = np.zeros(len(y))</span>
        <span class="s0">for </span><span class="s1">j</span><span class="s0">,</span><span class="s1">k </span><span class="s0">in </span><span class="s1">enumerate(np.flatnonzero(ident == </span><span class="s2">0</span><span class="s1">)):</span>
            <span class="s1">z1[exog_vc[:</span><span class="s0">, </span><span class="s1">k] == </span><span class="s2">1</span><span class="s1">] = j</span>
        <span class="s1">df[</span><span class="s3">&quot;z1&quot;</span><span class="s1">] = z1</span>
        <span class="s1">z2 = np.zeros(len(y))</span>
        <span class="s0">for </span><span class="s1">j</span><span class="s0">,</span><span class="s1">k </span><span class="s0">in </span><span class="s1">enumerate(np.flatnonzero(ident == </span><span class="s2">1</span><span class="s1">)):</span>
            <span class="s1">z2[exog_vc[:</span><span class="s0">, </span><span class="s1">k] == </span><span class="s2">1</span><span class="s1">] = j</span>
        <span class="s1">df[</span><span class="s3">&quot;z2&quot;</span><span class="s1">] = z2</span>

        <span class="s1">fml = </span><span class="s3">&quot;y ~ 0 + x1&quot;</span>
        <span class="s1">vc_fml = {}</span>
        <span class="s1">vc_fml[</span><span class="s3">&quot;z1&quot;</span><span class="s1">] = </span><span class="s3">&quot;0 + C(z1)&quot;</span>
        <span class="s1">vc_fml[</span><span class="s3">&quot;z2&quot;</span><span class="s1">] = </span><span class="s3">&quot;0 + C(z2)&quot;</span>
        <span class="s1">glmm2 = PoissonBayesMixedGLM.from_formula(fml</span><span class="s0">, </span><span class="s1">vc_fml</span><span class="s0">, </span><span class="s1">df)</span>
        <span class="s0">if </span><span class="s1">vb:</span>
            <span class="s1">rslt2 = glmm2.fit_vb()</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">rslt2 = glmm2.fit_map()</span>

        <span class="s1">assert_allclose(rslt1.params</span><span class="s0">, </span><span class="s1">rslt2.params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

        <span class="s0">for </span><span class="s1">rslt </span><span class="s0">in </span><span class="s1">rslt1</span><span class="s0">, </span><span class="s1">rslt2:</span>
            <span class="s1">cp = rslt.cov_params()</span>
            <span class="s1">p = len(rslt.params)</span>
            <span class="s0">if </span><span class="s1">vb:</span>
                <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">,</span><span class="s1">])</span>
                <span class="s1">assert_equal(cp &gt; </span><span class="s2">0</span><span class="s0">, True</span><span class="s1">*np.ones(p))</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">assert_equal(cp.shape</span><span class="s0">, </span><span class="s1">np.r_[p</span><span class="s0">, </span><span class="s1">p])</span>
                <span class="s1">np.linalg.cholesky(cp)</span>

<span class="s0">def </span><span class="s1">test_scale_vb():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_fe -= exog_fe.mean(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_fe /= exog_fe.std(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">rslts = []</span>
    <span class="s0">for </span><span class="s1">scale_fe </span><span class="s0">in False, True</span><span class="s1">:</span>
        <span class="s1">glmm = BinomialBayesMixedGLM(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
        <span class="s1">rslt = glmm.fit_vb(scale_fe=scale_fe)</span>
        <span class="s1">rslts.append(rslt)</span>

    <span class="s1">assert_allclose(rslts[</span><span class="s2">0</span><span class="s1">].params</span><span class="s0">, </span><span class="s1">rslts[</span><span class="s2">1</span><span class="s1">].params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

<span class="s0">def </span><span class="s1">test_scale_map():</span>

    <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident = gen_simple_logit(</span><span class="s2">10</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_fe -= exog_fe.mean(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_fe /= exog_fe.std(</span><span class="s2">0</span><span class="s1">)</span>
    <span class="s1">exog_vc = sparse.csr_matrix(exog_vc)</span>

    <span class="s1">rslts = []</span>
    <span class="s0">for </span><span class="s1">scale_fe </span><span class="s0">in False, True</span><span class="s1">:</span>
        <span class="s1">glmm = BinomialBayesMixedGLM(</span>
            <span class="s1">y</span><span class="s0">, </span><span class="s1">exog_fe</span><span class="s0">, </span><span class="s1">exog_vc</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">vcp_p=</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">fe_p=</span><span class="s2">0.5</span><span class="s1">)</span>
        <span class="s1">rslt = glmm.fit_map(scale_fe=scale_fe)</span>
        <span class="s1">rslts.append(rslt)</span>

    <span class="s1">assert_allclose(rslts[</span><span class="s2">0</span><span class="s1">].params</span><span class="s0">, </span><span class="s1">rslts[</span><span class="s2">1</span><span class="s1">].params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

<span class="s0">def </span><span class="s1">test_doc_examples():</span>

    <span class="s1">np.random.seed(</span><span class="s2">8767</span><span class="s1">)</span>
    <span class="s1">n = </span><span class="s2">200</span>
    <span class="s1">m = </span><span class="s2">20</span>
    <span class="s1">data = pd.DataFrame({</span><span class="s3">&quot;Year&quot;</span><span class="s1">: np.random.uniform(</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">,</span>
                         <span class="s3">&quot;Village&quot;</span><span class="s1">: np.random.randint(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">m</span><span class="s0">, </span><span class="s1">n)})</span>
    <span class="s1">data[</span><span class="s3">'year_cen'</span><span class="s1">] = data[</span><span class="s3">'Year'</span><span class="s1">] - data.Year.mean()</span>

    <span class="s4"># Binomial outcome</span>
    <span class="s1">lpr = np.random.normal(size=m)[data.Village]</span>
    <span class="s1">lpr += np.random.normal(size=m)[data.Village] * data.year_cen</span>
    <span class="s1">y = (np.random.uniform(size=n) &lt; </span><span class="s2">1 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ np.exp(-lpr)))</span>
    <span class="s1">data[</span><span class="s3">&quot;y&quot;</span><span class="s1">] = y.astype(int)</span>

    <span class="s4"># These lines should agree with the example in the class docstring.</span>
    <span class="s1">random = {</span><span class="s3">&quot;a&quot;</span><span class="s1">: </span><span class="s3">'0 + C(Village)'</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">: </span><span class="s3">'0 + C(Village)*year_cen'</span><span class="s1">}</span>
    <span class="s1">model = BinomialBayesMixedGLM.from_formula(</span>
                 <span class="s3">'y ~ year_cen'</span><span class="s0">, </span><span class="s1">random</span><span class="s0">, </span><span class="s1">data)</span>
    <span class="s1">result = model.fit_vb()</span>
    <span class="s1">_ = result</span>

    <span class="s4"># Poisson outcome</span>
    <span class="s1">lpr = np.random.normal(size=m)[data.Village]</span>
    <span class="s1">lpr += np.random.normal(size=m)[data.Village] * data.year_cen</span>
    <span class="s1">data[</span><span class="s3">&quot;y&quot;</span><span class="s1">] = np.random.poisson(np.exp(lpr))</span>

    <span class="s4"># These lines should agree with the example in the class docstring.</span>
    <span class="s1">random = {</span><span class="s3">&quot;a&quot;</span><span class="s1">: </span><span class="s3">'0 + C(Village)'</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">: </span><span class="s3">'0 + C(Village)*year_cen'</span><span class="s1">}</span>
    <span class="s1">model = PoissonBayesMixedGLM.from_formula(</span>
                 <span class="s3">'y ~ year_cen'</span><span class="s0">, </span><span class="s1">random</span><span class="s0">, </span><span class="s1">data)</span>
    <span class="s1">result = model.fit_vb()</span>
    <span class="s1">_ = result</span>
</pre>
</body>
</html>
<html>
<head>
<title>multiprocessing.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
multiprocessing.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>

<span class="s0">import </span><span class="s1">copyreg</span>
<span class="s0">import </span><span class="s1">multiprocessing</span>
<span class="s0">import </span><span class="s1">multiprocessing.pool</span>
<span class="s0">import </span><span class="s1">os</span>
<span class="s0">import </span><span class="s1">pickle</span>
<span class="s0">import </span><span class="s1">sys</span>
<span class="s0">import </span><span class="s1">traceback</span>
<span class="s0">from </span><span class="s1">collections.abc </span><span class="s0">import </span><span class="s1">Mapping</span><span class="s0">, </span><span class="s1">Sequence</span>
<span class="s0">from </span><span class="s1">concurrent.futures </span><span class="s0">import </span><span class="s1">ProcessPoolExecutor</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>
<span class="s0">from </span><span class="s1">warnings </span><span class="s0">import </span><span class="s1">warn</span>

<span class="s0">import </span><span class="s1">cloudpickle</span>

<span class="s0">from </span><span class="s1">dask </span><span class="s0">import </span><span class="s1">config</span>
<span class="s0">from </span><span class="s1">dask.local </span><span class="s0">import </span><span class="s1">MultiprocessingPoolExecutor</span><span class="s0">, </span><span class="s1">get_async</span><span class="s0">, </span><span class="s1">reraise</span>
<span class="s0">from </span><span class="s1">dask.optimization </span><span class="s0">import </span><span class="s1">cull</span><span class="s0">, </span><span class="s1">fuse</span>
<span class="s0">from </span><span class="s1">dask.system </span><span class="s0">import </span><span class="s1">CPU_COUNT</span>
<span class="s0">from </span><span class="s1">dask.typing </span><span class="s0">import </span><span class="s1">Key</span>
<span class="s0">from </span><span class="s1">dask.utils </span><span class="s0">import </span><span class="s1">ensure_dict</span>


<span class="s0">def </span><span class="s1">_reduce_method_descriptor(m):</span>
    <span class="s0">return </span><span class="s1">getattr</span><span class="s0">, </span><span class="s1">(m.__objclass__</span><span class="s0">, </span><span class="s1">m.__name__)</span>


<span class="s2"># type(set.union) is used as a proxy to &lt;class 'method_descriptor'&gt;</span>
<span class="s1">copyreg.pickle(type(set.union)</span><span class="s0">, </span><span class="s1">_reduce_method_descriptor)</span>

<span class="s1">_dumps = partial(cloudpickle.dumps</span><span class="s0">, </span><span class="s1">protocol=pickle.HIGHEST_PROTOCOL)</span>
<span class="s1">_loads = cloudpickle.loads</span>


<span class="s0">def </span><span class="s1">_process_get_id():</span>
    <span class="s0">return </span><span class="s1">multiprocessing.current_process().ident</span>


<span class="s2"># -- Remote Exception Handling --</span>
<span class="s2"># By default, tracebacks can't be serialized using pickle. However, the</span>
<span class="s2"># `tblib` library can enable support for this. Since we don't mandate</span>
<span class="s2"># that tblib is installed, we do the following:</span>
<span class="s2">#</span>
<span class="s2"># - If tblib is installed, use it to serialize the traceback and reraise</span>
<span class="s2">#   in the scheduler process</span>
<span class="s2"># - Otherwise, use a ``RemoteException`` class to contain a serialized</span>
<span class="s2">#   version of the formatted traceback, which will then print in the</span>
<span class="s2">#   scheduler process.</span>
<span class="s2">#</span>
<span class="s2"># To enable testing of the ``RemoteException`` class even when tblib is</span>
<span class="s2"># installed, we don't wrap the class in the try block below</span>
<span class="s0">class </span><span class="s1">RemoteException(Exception):</span>
    <span class="s3">&quot;&quot;&quot;Remote Exception 
 
    Contains the exception and traceback from a remotely run task 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">exception</span><span class="s0">, </span><span class="s1">traceback):</span>
        <span class="s1">self.exception = exception</span>
        <span class="s1">self.traceback = traceback</span>

    <span class="s0">def </span><span class="s1">__str__(self):</span>
        <span class="s0">return </span><span class="s1">str(self.exception) + </span><span class="s4">&quot;</span><span class="s0">\n\n</span><span class="s4">Traceback</span><span class="s0">\n</span><span class="s4">---------</span><span class="s0">\n</span><span class="s4">&quot; </span><span class="s1">+ self.traceback</span>

    <span class="s0">def </span><span class="s1">__dir__(self):</span>
        <span class="s0">return </span><span class="s1">sorted(set(dir(type(self)) + list(self.__dict__) + dir(self.exception)))</span>

    <span class="s0">def </span><span class="s1">__getattr__(self</span><span class="s0">, </span><span class="s1">key):</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">object.__getattribute__(self</span><span class="s0">, </span><span class="s1">key)</span>
        <span class="s0">except </span><span class="s1">AttributeError:</span>
            <span class="s0">return </span><span class="s1">getattr(self.exception</span><span class="s0">, </span><span class="s1">key)</span>


<span class="s1">exceptions: dict[type[Exception]</span><span class="s0">, </span><span class="s1">type[Exception]] = {}</span>


<span class="s0">def </span><span class="s1">remote_exception(exc: Exception</span><span class="s0">, </span><span class="s1">tb) -&gt; Exception:</span>
    <span class="s3">&quot;&quot;&quot;Metaclass that wraps exception type in RemoteException&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">type(exc) </span><span class="s0">in </span><span class="s1">exceptions:</span>
        <span class="s1">typ = exceptions[type(exc)]</span>
        <span class="s0">return </span><span class="s1">typ(exc</span><span class="s0">, </span><span class="s1">tb)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">typ = type(</span>
                <span class="s1">exc.__class__.__name__</span><span class="s0">,</span>
                <span class="s1">(RemoteException</span><span class="s0">, </span><span class="s1">type(exc))</span><span class="s0">,</span>
                <span class="s1">{</span><span class="s4">&quot;exception_type&quot;</span><span class="s1">: type(exc)}</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">exceptions[type(exc)] = typ</span>
            <span class="s0">return </span><span class="s1">typ(exc</span><span class="s0">, </span><span class="s1">tb)</span>
        <span class="s0">except </span><span class="s1">TypeError:</span>
            <span class="s0">return </span><span class="s1">exc</span>


<span class="s0">try</span><span class="s1">:</span>
    <span class="s0">import </span><span class="s1">tblib.pickling_support</span>

    <span class="s1">tblib.pickling_support.install()</span>

    <span class="s0">def </span><span class="s1">_pack_traceback(tb):</span>
        <span class="s0">return </span><span class="s1">tb</span>

<span class="s0">except </span><span class="s1">ImportError:</span>

    <span class="s0">def </span><span class="s1">_pack_traceback(tb):</span>
        <span class="s0">return </span><span class="s4">&quot;&quot;</span><span class="s1">.join(traceback.format_tb(tb))</span>

    <span class="s0">def </span><span class="s1">reraise(exc</span><span class="s0">, </span><span class="s1">tb=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">exc = remote_exception(exc</span><span class="s0">, </span><span class="s1">tb)</span>
        <span class="s0">raise </span><span class="s1">exc</span>


<span class="s0">def </span><span class="s1">pack_exception(e</span><span class="s0">, </span><span class="s1">dumps):</span>
    <span class="s1">exc_type</span><span class="s0">, </span><span class="s1">exc_value</span><span class="s0">, </span><span class="s1">exc_traceback = sys.exc_info()</span>
    <span class="s1">tb = _pack_traceback(exc_traceback)</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">result = dumps((e</span><span class="s0">, </span><span class="s1">tb))</span>
    <span class="s0">except </span><span class="s1">BaseException </span><span class="s0">as </span><span class="s1">e:</span>
        <span class="s1">exc_type</span><span class="s0">, </span><span class="s1">exc_value</span><span class="s0">, </span><span class="s1">exc_traceback = sys.exc_info()</span>
        <span class="s1">tb = _pack_traceback(exc_traceback)</span>
        <span class="s1">result = dumps((e</span><span class="s0">, </span><span class="s1">tb))</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s1">_CONTEXT_UNSUPPORTED = </span><span class="s4">&quot;&quot;&quot;</span><span class="s0">\ 
</span><span class="s4">The 'multiprocessing.context' configuration option will be ignored on Python 2 
and on Windows, because they each only support a single context. 
&quot;&quot;&quot;</span>


<span class="s0">def </span><span class="s1">get_context():</span>
    <span class="s3">&quot;&quot;&quot;Return the current multiprocessing context.&quot;&quot;&quot;</span>
    <span class="s2"># fork context does fork()-without-exec(), which can lead to deadlocks,</span>
    <span class="s2"># so default to &quot;spawn&quot;.</span>
    <span class="s1">context_name = config.get(</span><span class="s4">&quot;multiprocessing.context&quot;</span><span class="s0">, </span><span class="s4">&quot;spawn&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">sys.platform == </span><span class="s4">&quot;win32&quot;</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">context_name != </span><span class="s4">&quot;spawn&quot;</span><span class="s1">:</span>
            <span class="s2"># Only spawn is supported on Win32, can't change it:</span>
            <span class="s1">warn(_CONTEXT_UNSUPPORTED</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s0">return </span><span class="s1">multiprocessing</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">multiprocessing.get_context(context_name)</span>


<span class="s0">def </span><span class="s1">get(</span>
    <span class="s1">dsk: Mapping</span><span class="s0">,</span>
    <span class="s1">keys: Sequence[Key] | Key</span><span class="s0">,</span>
    <span class="s1">num_workers=</span><span class="s0">None,</span>
    <span class="s1">func_loads=</span><span class="s0">None,</span>
    <span class="s1">func_dumps=</span><span class="s0">None,</span>
    <span class="s1">optimize_graph=</span><span class="s0">True,</span>
    <span class="s1">pool=</span><span class="s0">None,</span>
    <span class="s1">initializer=</span><span class="s0">None,</span>
    <span class="s1">chunksize=</span><span class="s0">None,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot;Multiprocessed get function appropriate for Bags 
 
    Parameters 
    ---------- 
    dsk : dict 
        dask graph 
    keys : object or list 
        Desired results from graph 
    num_workers : int 
        Number of worker processes (defaults to number of cores) 
    func_dumps : function 
        Function to use for function serialization (defaults to cloudpickle.dumps) 
    func_loads : function 
        Function to use for function deserialization (defaults to cloudpickle.loads) 
    optimize_graph : bool 
        If True [default], `fuse` is applied to the graph before computation. 
    pool : Executor or Pool 
        Some sort of `Executor` or `Pool` to use 
    initializer: function 
        Ignored if ``pool`` has been set. 
        Function to initialize a worker process before running any tasks in it. 
    chunksize: int, optional 
        Size of chunks to use when dispatching work. 
        Defaults to 5 as some batching is helpful. 
        If -1, will be computed to evenly divide ready work across workers. 
    &quot;&quot;&quot;</span>
    <span class="s1">chunksize = chunksize </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;chunksize&quot;</span><span class="s0">, </span><span class="s5">6</span><span class="s1">)</span>
    <span class="s1">pool = pool </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;pool&quot;</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s1">initializer = initializer </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;multiprocessing.initializer&quot;</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s1">num_workers = num_workers </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;num_workers&quot;</span><span class="s0">, None</span><span class="s1">) </span><span class="s0">or </span><span class="s1">CPU_COUNT</span>
    <span class="s0">if </span><span class="s1">pool </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s2"># In order to get consistent hashing in subprocesses, we need to set a</span>
        <span class="s2"># consistent seed for the Python hash algorithm. Unfortunately, there</span>
        <span class="s2"># is no way to specify environment variables only for the Pool</span>
        <span class="s2"># processes, so we have to rely on environment variables being</span>
        <span class="s2"># inherited.</span>
        <span class="s0">if </span><span class="s1">os.environ.get(</span><span class="s4">&quot;PYTHONHASHSEED&quot;</span><span class="s1">) </span><span class="s0">in </span><span class="s1">(</span><span class="s0">None, </span><span class="s4">&quot;0&quot;</span><span class="s1">):</span>
            <span class="s2"># This number is arbitrary; it was chosen to commemorate</span>
            <span class="s2"># https://github.com/dask/dask/issues/6640.</span>
            <span class="s1">os.environ[</span><span class="s4">&quot;PYTHONHASHSEED&quot;</span><span class="s1">] = </span><span class="s4">&quot;6640&quot;</span>
        <span class="s1">context = get_context()</span>
        <span class="s1">initializer = partial(initialize_worker_process</span><span class="s0">, </span><span class="s1">user_initializer=initializer)</span>
        <span class="s1">pool = ProcessPoolExecutor(</span>
            <span class="s1">num_workers</span><span class="s0">, </span><span class="s1">mp_context=context</span><span class="s0">, </span><span class="s1">initializer=initializer</span>
        <span class="s1">)</span>
        <span class="s1">cleanup = </span><span class="s0">True</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">initializer </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">warn(</span>
                <span class="s4">&quot;The ``initializer`` argument is ignored when ``pool`` is provided. &quot;</span>
                <span class="s4">&quot;The user should configure ``pool`` with the needed ``initializer`` &quot;</span>
                <span class="s4">&quot;on creation.&quot;</span>
            <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">isinstance(pool</span><span class="s0">, </span><span class="s1">multiprocessing.pool.Pool):</span>
            <span class="s1">pool = MultiprocessingPoolExecutor(pool)</span>
        <span class="s1">cleanup = </span><span class="s0">False</span>

    <span class="s2"># Optimize Dask</span>
    <span class="s1">dsk = ensure_dict(dsk)</span>
    <span class="s1">dsk2</span><span class="s0">, </span><span class="s1">dependencies = cull(dsk</span><span class="s0">, </span><span class="s1">keys)</span>
    <span class="s0">if </span><span class="s1">optimize_graph:</span>
        <span class="s1">dsk3</span><span class="s0">, </span><span class="s1">dependencies = fuse(dsk2</span><span class="s0">, </span><span class="s1">keys</span><span class="s0">, </span><span class="s1">dependencies)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dsk3 = dsk2</span>

    <span class="s2"># We specify marshalling functions in order to catch serialization</span>
    <span class="s2"># errors and report them to the user.</span>
    <span class="s1">loads = func_loads </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;func_loads&quot;</span><span class="s0">, None</span><span class="s1">) </span><span class="s0">or </span><span class="s1">_loads</span>
    <span class="s1">dumps = func_dumps </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s4">&quot;func_dumps&quot;</span><span class="s0">, None</span><span class="s1">) </span><span class="s0">or </span><span class="s1">_dumps</span>

    <span class="s2"># Note former versions used a multiprocessing Manager to share</span>
    <span class="s2"># a Queue between parent and workers, but this is fragile on Windows</span>
    <span class="s2"># (issue #1652).</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s2"># Run</span>
        <span class="s1">result = get_async(</span>
            <span class="s1">pool.submit</span><span class="s0">,</span>
            <span class="s1">pool._max_workers</span><span class="s0">,</span>
            <span class="s1">dsk3</span><span class="s0">,</span>
            <span class="s1">keys</span><span class="s0">,</span>
            <span class="s1">get_id=_process_get_id</span><span class="s0">,</span>
            <span class="s1">dumps=dumps</span><span class="s0">,</span>
            <span class="s1">loads=loads</span><span class="s0">,</span>
            <span class="s1">pack_exception=pack_exception</span><span class="s0">,</span>
            <span class="s1">raise_exception=reraise</span><span class="s0">,</span>
            <span class="s1">chunksize=chunksize</span><span class="s0">,</span>
            <span class="s1">**kwargs</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">finally</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">cleanup:</span>
            <span class="s1">pool.shutdown()</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s0">def </span><span class="s1">default_initializer():</span>
    <span class="s2"># If Numpy is already imported, presumably its random state was</span>
    <span class="s2"># inherited from the parent =&gt; re-seed it.</span>
    <span class="s1">np = sys.modules.get(</span><span class="s4">&quot;numpy&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">np </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">np.random.seed()</span>


<span class="s0">def </span><span class="s1">initialize_worker_process(user_initializer=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Initialize a worker process before running any tasks in it. 
    &quot;&quot;&quot;</span>
    <span class="s1">default_initializer()</span>

    <span class="s0">if </span><span class="s1">user_initializer </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">user_initializer()</span>
</pre>
</body>
</html>
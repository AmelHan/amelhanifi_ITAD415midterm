<html>
<head>
<title>dynamic_factor_mq.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
dynamic_factor_mq.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Dynamic factor model. 
 
Author: Chad Fulton 
License: BSD-3 
&quot;&quot;&quot;</span>
<span class="s3">from </span><span class="s1">collections </span><span class="s3">import </span><span class="s1">OrderedDict</span>
<span class="s3">from </span><span class="s1">warnings </span><span class="s3">import </span><span class="s1">warn</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>
<span class="s3">from </span><span class="s1">scipy.linalg </span><span class="s3">import </span><span class="s1">cho_factor</span><span class="s3">, </span><span class="s1">cho_solve</span><span class="s3">, </span><span class="s1">LinAlgError</span>

<span class="s3">from </span><span class="s1">statsmodels.tools.data </span><span class="s3">import </span><span class="s1">_is_using_pandas</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.validation </span><span class="s3">import </span><span class="s1">int_like</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s3">import </span><span class="s1">cache_readonly</span>
<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span>
<span class="s3">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s3">import </span><span class="s1">GLM</span>
<span class="s3">from </span><span class="s1">statsmodels.multivariate.pca </span><span class="s3">import </span><span class="s1">PCA</span>

<span class="s3">from </span><span class="s1">statsmodels.tsa.statespace.sarimax </span><span class="s3">import </span><span class="s1">SARIMAX</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.statespace._quarterly_ar1 </span><span class="s3">import </span><span class="s1">QuarterlyAR1</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.var_model </span><span class="s3">import </span><span class="s1">VAR</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.tools </span><span class="s3">import </span><span class="s1">Bunch</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.validation </span><span class="s3">import </span><span class="s1">string_like</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.tsatools </span><span class="s3">import </span><span class="s1">lagmat</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.statespace </span><span class="s3">import </span><span class="s1">mlemodel</span><span class="s3">, </span><span class="s1">initialization</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.statespace.tools </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">companion_matrix</span><span class="s3">, </span><span class="s1">is_invertible</span><span class="s3">, </span><span class="s1">constrain_stationary_univariate</span><span class="s3">,</span>
    <span class="s1">constrain_stationary_multivariate</span><span class="s3">, </span><span class="s1">unconstrain_stationary_univariate</span><span class="s3">,</span>
    <span class="s1">unconstrain_stationary_multivariate)</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.statespace.kalman_smoother </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">SMOOTHER_STATE</span><span class="s3">, </span><span class="s1">SMOOTHER_STATE_COV</span><span class="s3">, </span><span class="s1">SMOOTHER_STATE_AUTOCOV)</span>
<span class="s3">from </span><span class="s1">statsmodels.base.data </span><span class="s3">import </span><span class="s1">PandasData</span>

<span class="s3">from </span><span class="s1">statsmodels.iolib.table </span><span class="s3">import </span><span class="s1">SimpleTable</span>
<span class="s3">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s3">import </span><span class="s1">Summary</span>
<span class="s3">from </span><span class="s1">statsmodels.iolib.tableformatting </span><span class="s3">import </span><span class="s1">fmt_params</span>


<span class="s3">class </span><span class="s1">FactorBlock(dict):</span>
    <span class="s2">&quot;&quot;&quot; 
    Helper class for describing and indexing a block of factors. 
 
    Parameters 
    ---------- 
    factor_names : tuple of str 
        Tuple of factor names in the block (in the order that they will appear 
        in the state vector). 
    factor_order : int 
        Order of the vector autoregression governing the factor block dynamics. 
    endog_factor_map : pd.DataFrame 
        Mapping from endog variable names to factor names. 
    state_offset : int 
        Offset of this factor block in the state vector. 
    has_endog_Q : bool 
        Flag if the model contains quarterly data. 
 
    Notes 
    ----- 
    The goal of this class is, in particular, to make it easier to retrieve 
    indexes of subsets of the state vector that are associated with a 
    particular block of factors. 
 
    - `factors_ix` is a matrix of indices, with rows corresponding to factors 
      in the block and columns corresponding to lags 
    - `factors` is vec(factors_ix) (i.e. it stacks columns, so that it is 
      `factors_ix.ravel(order='F')`). Thinking about a VAR system, the first 
       k*p elements correspond to the equation for the first variable. The next 
       k*p elements correspond to the equation for the second variable, and so 
       on. It contains all of the lags in the state vector, which is max(5, p) 
    - `factors_ar` is the subset of `factors` that have nonzero coefficients, 
      so it contains lags up to p. 
    - `factors_L1` only contains the first lag of the factors 
    - `factors_L1_5` contains the first - fifth lags of the factors 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">factor_names</span><span class="s3">, </span><span class="s1">factor_order</span><span class="s3">, </span><span class="s1">endog_factor_map</span><span class="s3">,</span>
                 <span class="s1">state_offset</span><span class="s3">, </span><span class="s1">k_endog_Q):</span>
        <span class="s1">self.factor_names = factor_names</span>
        <span class="s1">self.k_factors = len(self.factor_names)</span>
        <span class="s1">self.factor_order = factor_order</span>
        <span class="s1">self.endog_factor_map = endog_factor_map.loc[:</span><span class="s3">, </span><span class="s1">factor_names]</span>
        <span class="s1">self.state_offset = state_offset</span>
        <span class="s1">self.k_endog_Q = k_endog_Q</span>
        <span class="s3">if </span><span class="s1">self.k_endog_Q &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">self._factor_order = max(</span><span class="s4">5</span><span class="s3">, </span><span class="s1">self.factor_order)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self._factor_order = self.factor_order</span>
        <span class="s1">self.k_states = self.k_factors * self._factor_order</span>

        <span class="s0"># Save items</span>
        <span class="s1">self[</span><span class="s5">'factors'</span><span class="s1">] = self.factors</span>
        <span class="s1">self[</span><span class="s5">'factors_ar'</span><span class="s1">] = self.factors_ar</span>
        <span class="s1">self[</span><span class="s5">'factors_ix'</span><span class="s1">] = self.factors_ix</span>
        <span class="s1">self[</span><span class="s5">'factors_L1'</span><span class="s1">] = self.factors_L1</span>
        <span class="s1">self[</span><span class="s5">'factors_L1_5'</span><span class="s1">] = self.factors_L1_5</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_ix(self):</span>
        <span class="s2">&quot;&quot;&quot;Factor state index array, shaped (k_factors, lags).&quot;&quot;&quot;</span>
        <span class="s0"># i.e. the position in the state vector of the second lag of the third</span>
        <span class="s0"># factor is factors_ix[2, 1]</span>
        <span class="s0"># ravel(order='F') gives e.g (f0.L1, f1.L1, f0.L2, f1.L2, f0.L3, ...)</span>
        <span class="s0"># while</span>
        <span class="s0"># ravel(order='C') gives e.g (f0.L1, f0.L2, f0.L3, f1.L1, f1.L2, ...)</span>
        <span class="s1">o = self.state_offset</span>
        <span class="s3">return </span><span class="s1">np.reshape(o + np.arange(self.k_factors * self._factor_order)</span><span class="s3">,</span>
                          <span class="s1">(self._factor_order</span><span class="s3">, </span><span class="s1">self.k_factors)).T</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors and all lags in the state vector (max(5, p)).&quot;&quot;&quot;</span>
        <span class="s0"># Note that this is equivalent to factors_ix with ravel(order='F')</span>
        <span class="s1">o = self.state_offset</span>
        <span class="s3">return </span><span class="s1">np.s_[o:o + self.k_factors * self._factor_order]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_ar(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors and all lags used in the factor autoregression (p).&quot;&quot;&quot;</span>
        <span class="s1">o = self.state_offset</span>
        <span class="s3">return </span><span class="s1">np.s_[o:o + self.k_factors * self.factor_order]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_L1(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors (first block / lag only).&quot;&quot;&quot;</span>
        <span class="s1">o = self.state_offset</span>
        <span class="s3">return </span><span class="s1">np.s_[o:o + self.k_factors]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_L1_5(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors plus four lags.&quot;&quot;&quot;</span>
        <span class="s1">o = self.state_offset</span>
        <span class="s3">return </span><span class="s1">np.s_[o:o + self.k_factors * </span><span class="s4">5</span><span class="s1">]</span>


<span class="s3">class </span><span class="s1">DynamicFactorMQStates(dict):</span>
    <span class="s2">&quot;&quot;&quot; 
    Helper class for describing and indexing the state vector. 
 
    Parameters 
    ---------- 
    k_endog_M : int 
        Number of monthly (or non-time-specific, if k_endog_Q=0) variables. 
    k_endog_Q : int 
        Number of quarterly variables. 
    endog_names : list 
        Names of the endogenous variables. 
    factors : int, list, or dict 
        Integer giving the number of (global) factors, a list with the names of 
        (global) factors, or a dictionary with: 
 
        - keys : names of endogenous variables 
        - values : lists of factor names. 
 
        If this is an integer, then the factor names will be 0, 1, .... 
    factor_orders : int or dict 
        Integer describing the order of the vector autoregression (VAR) 
        governing all factor block dynamics or dictionary with: 
 
        - keys : factor name or tuples of factor names in a block 
        - values : integer describing the VAR order for that factor block 
 
        If a dictionary, this defines the order of the factor blocks in the 
        state vector. Otherwise, factors are ordered so that factors that load 
        on more variables come first (and then alphabetically, to break ties). 
    factor_multiplicities : int or dict 
        This argument provides a convenient way to specify multiple factors 
        that load identically on variables. For example, one may want two 
        &quot;global&quot; factors (factors that load on all variables) that evolve 
        jointly according to a VAR. One could specify two global factors in the 
        `factors` argument and specify that they are in the same block in the 
        `factor_orders` argument, but it is easier to specify a single global 
        factor in the `factors` argument, and set the order in the 
        `factor_orders` argument, and then set the factor multiplicity to 2. 
 
        This argument must be an integer describing the factor multiplicity for 
        all factors or dictionary with: 
 
        - keys : factor name 
        - values : integer describing the factor multiplicity for the factors 
          in the given block 
    idiosyncratic_ar1 : bool 
        Whether or not to model the idiosyncratic component for each series as 
        an AR(1) process. If False, the idiosyncratic component is instead 
        modeled as white noise. 
 
    Attributes 
    ---------- 
    k_endog : int 
        Total number of endogenous variables. 
    k_states : int 
        Total number of state variables (those associated with the factors and 
        those associated with the idiosyncratic disturbances). 
    k_posdef : int 
        Total number of state disturbance terms (those associated with the 
        factors and those associated with the idiosyncratic disturbances). 
    k_endog_M : int 
        Number of monthly (or non-time-specific, if k_endog_Q=0) variables. 
    k_endog_Q : int 
        Number of quarterly variables. 
    k_factors : int 
        Total number of factors. Note that factor multiplicities will have 
        already been expanded. 
    k_states_factors : int 
        The number of state variables associated with factors (includes both 
        factors and lags of factors included in the state vector). 
    k_posdef_factors : int 
        The number of state disturbance terms associated with factors. 
    k_states_idio : int 
        Total number of state variables associated with idiosyncratic 
        disturbances. 
    k_posdef_idio : int 
        Total number of state disturbance terms associated with idiosyncratic 
        disturbances. 
    k_states_idio_M : int 
        The number of state variables associated with idiosyncratic 
        disturbances for monthly (or non-time-specific if there are no 
        quarterly variables) variables. If the disturbances are AR(1), then 
        this will be equal to `k_endog_M`, otherwise it will be equal to zero. 
    k_states_idio_Q : int 
        The number of state variables associated with idiosyncratic 
        disturbances for quarterly variables. This will always be equal to 
        `k_endog_Q * 5`, even if the disturbances are not AR(1). 
    k_posdef_idio_M : int 
        The number of state disturbance terms associated with idiosyncratic 
        disturbances for monthly (or non-time-specific if there are no 
        quarterly variables) variables. If the disturbances are AR(1), then 
        this will be equal to `k_endog_M`, otherwise it will be equal to zero. 
    k_posdef_idio_Q : int 
        The number of state disturbance terms associated with idiosyncratic 
        disturbances for quarterly variables. This will always be equal to 
        `k_endog_Q`, even if the disturbances are not AR(1). 
    idiosyncratic_ar1 : bool 
        Whether or not to model the idiosyncratic component for each series as 
        an AR(1) process. 
    factor_blocks : list of FactorBlock 
        List of `FactorBlock` helper instances for each factor block. 
    factor_names : list of str 
        List of factor names. 
    factors : dict 
        Dictionary with: 
 
        - keys : names of endogenous variables 
        - values : lists of factor names. 
 
        Note that factor multiplicities will have already been expanded. 
    factor_orders : dict 
        Dictionary with: 
 
        - keys : tuple of factor names 
        - values : integer describing autoregression order 
 
        Note that factor multiplicities will have already been expanded. 
    max_factor_order : int 
        Maximum autoregression order across all factor blocks. 
    factor_block_orders : pd.Series 
        Series containing lag orders, with the factor block (a tuple of factor 
        names) as the index. 
    factor_multiplicities : dict 
        Dictionary with: 
 
        - keys : factor name 
        - values : integer describing the factor multiplicity for the factors 
          in the given block 
    endog_factor_map : dict 
        Dictionary with: 
 
        - keys : endog name 
        - values : list of factor names 
    loading_counts : pd.Series 
        Series containing number of endogenous variables loading on each 
        factor, with the factor name as the index. 
    block_loading_counts : dict 
        Dictionary with: 
 
        - keys : tuple of factor names 
        - values : average number of endogenous variables loading on the block 
          (note that average is over the factors in the block) 
 
    Notes 
    ----- 
    The goal of this class is, in particular, to make it easier to retrieve 
    indexes of subsets of the state vector. 
 
    Note that the ordering of the factor blocks in the state vector is 
    determined by the `factor_orders` argument if a dictionary. Otherwise, 
    factors are ordered so that factors that load on more variables come first 
    (and then alphabetically, to break ties). 
 
    - `factors_L1` is an array with the indexes of first lag of the factors 
      from each block. Ordered first by block, and then by lag. 
    - `factors_L1_5` is an array with the indexes contains the first - fifth 
      lags of the factors from each block. Ordered first by block, and then by 
      lag. 
    - `factors_L1_5_ix` is an array shaped (5, k_factors) with the indexes 
      of the first - fifth lags of the factors from each block. 
    - `idio_ar_L1` is an array with the indexes of the first lag of the 
      idiosyncratic AR states, both monthly (if appliable) and quarterly. 
    - `idio_ar_M` is a slice with the indexes of the idiosyncratic disturbance 
      states for the monthly (or non-time-specific if there are no quarterly 
      variables) variables. It is an empty slice if 
      `idiosyncratic_ar1 = False`. 
    - `idio_ar_Q` is a slice with the indexes of the idiosyncratic disturbance 
      states and all lags, for the quarterly variables. It is an empty slice if 
      there are no quarterly variable. 
    - `idio_ar_Q_ix` is an array shaped (k_endog_Q, 5) with the indexes of the 
      first - fifth lags of the idiosyncratic disturbance states for the 
      quarterly variables. 
    - `endog_factor_iloc` is a list of lists, with entries for each endogenous 
      variable. The entry for variable `i`, `endog_factor_iloc[i]` is a list of 
      indexes of the factors that variable `i` loads on. This does not include 
      any lags, but it can be used with e.g. `factors_L1_5_ix` to get lags. 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">k_endog_M</span><span class="s3">, </span><span class="s1">k_endog_Q</span><span class="s3">, </span><span class="s1">endog_names</span><span class="s3">, </span><span class="s1">factors</span><span class="s3">,</span>
                 <span class="s1">factor_orders</span><span class="s3">, </span><span class="s1">factor_multiplicities</span><span class="s3">, </span><span class="s1">idiosyncratic_ar1):</span>
        <span class="s0"># Save model parameterization</span>
        <span class="s1">self.k_endog_M = k_endog_M</span>
        <span class="s1">self.k_endog_Q = k_endog_Q</span>
        <span class="s1">self.k_endog = self.k_endog_M + self.k_endog_Q</span>
        <span class="s1">self.idiosyncratic_ar1 = idiosyncratic_ar1</span>

        <span class="s0"># Validate factor-related inputs</span>
        <span class="s1">factors_is_int = np.issubdtype(type(factors)</span><span class="s3">, </span><span class="s1">np.integer)</span>
        <span class="s1">factors_is_list = isinstance(factors</span><span class="s3">, </span><span class="s1">(list</span><span class="s3">, </span><span class="s1">tuple))</span>
        <span class="s1">orders_is_int = np.issubdtype(type(factor_orders)</span><span class="s3">, </span><span class="s1">np.integer)</span>
        <span class="s3">if </span><span class="s1">factor_multiplicities </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">factor_multiplicities = </span><span class="s4">1</span>
        <span class="s1">mult_is_int = np.issubdtype(type(factor_multiplicities)</span><span class="s3">, </span><span class="s1">np.integer)</span>

        <span class="s3">if not </span><span class="s1">(factors_is_int </span><span class="s3">or </span><span class="s1">factors_is_list </span><span class="s3">or</span>
                <span class="s1">isinstance(factors</span><span class="s3">, </span><span class="s1">dict)):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'`factors` argument must an integer number of'</span>
                             <span class="s5">' factors, a list of global factor names, or a'</span>
                             <span class="s5">' dictionary, mapping observed variables to'</span>
                             <span class="s5">' factors.'</span><span class="s1">)</span>
        <span class="s3">if not </span><span class="s1">(orders_is_int </span><span class="s3">or </span><span class="s1">isinstance(factor_orders</span><span class="s3">, </span><span class="s1">dict)):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'`factor_orders` argument must either be an'</span>
                             <span class="s5">' integer or a dictionary.'</span><span class="s1">)</span>
        <span class="s3">if not </span><span class="s1">(mult_is_int </span><span class="s3">or </span><span class="s1">isinstance(factor_multiplicities</span><span class="s3">, </span><span class="s1">dict)):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'`factor_multiplicities` argument must either be'</span>
                             <span class="s5">' an integer or a dictionary.'</span><span class="s1">)</span>

        <span class="s0"># Expand integers</span>
        <span class="s0"># If `factors` is an integer, we assume that it denotes the number of</span>
        <span class="s0"># global factors (factors that load on each variable)</span>
        <span class="s3">if </span><span class="s1">factors_is_int </span><span class="s3">or </span><span class="s1">factors_is_list:</span>
            <span class="s0"># Validate this here for a more informative error message</span>
            <span class="s3">if </span><span class="s1">((factors_is_int </span><span class="s3">and </span><span class="s1">factors == </span><span class="s4">0</span><span class="s1">) </span><span class="s3">or</span>
                    <span class="s1">(factors_is_list </span><span class="s3">and </span><span class="s1">len(factors) == </span><span class="s4">0</span><span class="s1">)):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'The model must contain at least one factor.'</span><span class="s1">)</span>

            <span class="s3">if </span><span class="s1">factors_is_list:</span>
                <span class="s1">factor_names = list(factors)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">factor_names = [</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(factors)]</span>
            <span class="s1">factors = {name: factor_names[:] </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names}</span>
        <span class="s1">_factor_names = []</span>
        <span class="s3">for </span><span class="s1">val </span><span class="s3">in </span><span class="s1">factors.values():</span>
            <span class="s1">_factor_names.extend(val)</span>
        <span class="s1">factor_names = set(_factor_names)</span>
        <span class="s3">if </span><span class="s1">orders_is_int:</span>
            <span class="s1">factor_orders = {factor_name: factor_orders</span>
                             <span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">factor_names}</span>
        <span class="s3">if </span><span class="s1">mult_is_int:</span>
            <span class="s1">factor_multiplicities = {factor_name: factor_multiplicities</span>
                                     <span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">factor_names}</span>

        <span class="s0"># Apply the factor multiplicities</span>
        <span class="s1">factors</span><span class="s3">, </span><span class="s1">factor_orders = self._apply_factor_multiplicities(</span>
            <span class="s1">factors</span><span class="s3">, </span><span class="s1">factor_orders</span><span class="s3">, </span><span class="s1">factor_multiplicities)</span>

        <span class="s0"># Save the (potentially expanded) variables</span>
        <span class="s1">self.factors = factors</span>
        <span class="s1">self.factor_orders = factor_orders</span>
        <span class="s1">self.factor_multiplicities = factor_multiplicities</span>

        <span class="s0"># Get the mapping between endog and factors</span>
        <span class="s1">self.endog_factor_map = self._construct_endog_factor_map(</span>
            <span class="s1">factors</span><span class="s3">, </span><span class="s1">endog_names)</span>
        <span class="s1">self.k_factors = self.endog_factor_map.shape[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s0"># Validate number of factors</span>
        <span class="s0"># TODO: could do more extensive validation here.</span>
        <span class="s3">if </span><span class="s1">self.k_factors &gt; self.k_endog_M:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f'Number of factors (</span><span class="s3">{</span><span class="s1">self.k_factors</span><span class="s3">}</span><span class="s5">) cannot be'</span>
                             <span class="s5">' greater than the number of monthly endogenous'</span>
                             <span class="s5">f' variables (</span><span class="s3">{</span><span class="s1">self.k_endog_M</span><span class="s3">}</span><span class="s5">).'</span><span class="s1">)</span>

        <span class="s0"># Get `loading_counts`: factor -&gt; # endog loading on the factor</span>
        <span class="s1">self.loading_counts = (</span>
            <span class="s1">self.endog_factor_map.sum(axis=</span><span class="s4">0</span><span class="s1">).rename(</span><span class="s5">'count'</span><span class="s1">)</span>
                <span class="s1">.reset_index().sort_values([</span><span class="s5">'count'</span><span class="s3">, </span><span class="s5">'factor'</span><span class="s1">]</span><span class="s3">,</span>
                                           <span class="s1">ascending=[</span><span class="s3">False, True</span><span class="s1">])</span>
                <span class="s1">.set_index(</span><span class="s5">'factor'</span><span class="s1">))</span>
        <span class="s0"># `block_loading_counts`: block -&gt; average of (# loading on factor)</span>
        <span class="s0"># across each factor in the block</span>
        <span class="s1">block_loading_counts = {</span>
            <span class="s1">block: np.atleast_1d(</span>
                <span class="s1">self.loading_counts.loc[list(block)</span><span class="s3">, </span><span class="s5">'count'</span><span class="s1">]).mean(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">factor_orders.keys()}</span>
        <span class="s1">ix = pd.Index(block_loading_counts.keys()</span><span class="s3">, </span><span class="s1">tupleize_cols=</span><span class="s3">False,</span>
                      <span class="s1">name=</span><span class="s5">'block'</span><span class="s1">)</span>
        <span class="s1">self.block_loading_counts = pd.Series(</span>
            <span class="s1">list(block_loading_counts.values())</span><span class="s3">,</span>
            <span class="s1">index=ix</span><span class="s3">, </span><span class="s1">name=</span><span class="s5">'count'</span><span class="s1">).to_frame().sort_values(</span>
                <span class="s1">[</span><span class="s5">'count'</span><span class="s3">, </span><span class="s5">'block'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ascending=[</span><span class="s3">False, True</span><span class="s1">])[</span><span class="s5">'count'</span><span class="s1">]</span>

        <span class="s0"># Get the mapping between factor blocks and VAR order</span>

        <span class="s0"># `factor_block_orders`: pd.Series of factor block -&gt; lag order</span>
        <span class="s1">ix = pd.Index(factor_orders.keys()</span><span class="s3">, </span><span class="s1">tupleize_cols=</span><span class="s3">False, </span><span class="s1">name=</span><span class="s5">'block'</span><span class="s1">)</span>
        <span class="s1">self.factor_block_orders = pd.Series(</span>
            <span class="s1">list(factor_orders.values())</span><span class="s3">, </span><span class="s1">index=ix</span><span class="s3">, </span><span class="s1">name=</span><span class="s5">'order'</span><span class="s1">)</span>

        <span class="s0"># If the `factor_orders` variable was an integer, then it did not</span>
        <span class="s0"># define an ordering for the factor blocks. In this case, we use the</span>
        <span class="s0"># loading counts to do so. This ensures that e.g. global factors are</span>
        <span class="s0"># listed first.</span>
        <span class="s3">if </span><span class="s1">orders_is_int:</span>
            <span class="s1">keys = self.block_loading_counts.keys()</span>
            <span class="s1">self.factor_block_orders = self.factor_block_orders.loc[keys]</span>
            <span class="s1">self.factor_block_orders.index.name = </span><span class="s5">'block'</span>

        <span class="s0"># Define factor_names based on factor_block_orders (instead of on those</span>
        <span class="s0"># from `endog_factor_map`) to (a) make sure that factors are allocated</span>
        <span class="s0"># to only one block, and (b) order the factor names to be consistent</span>
        <span class="s0"># with the block definitions.</span>
        <span class="s1">factor_names = pd.Series(</span>
            <span class="s1">np.concatenate(list(self.factor_block_orders.index)))</span>
        <span class="s1">missing = [name </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">self.endog_factor_map.columns</span>
                   <span class="s3">if </span><span class="s1">name </span><span class="s3">not in </span><span class="s1">factor_names.tolist()]</span>
        <span class="s3">if </span><span class="s1">len(missing):</span>
            <span class="s1">ix = pd.Index([(factor_name</span><span class="s3">,</span><span class="s1">) </span><span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">missing]</span><span class="s3">,</span>
                          <span class="s1">tupleize_cols=</span><span class="s3">False, </span><span class="s1">name=</span><span class="s5">'block'</span><span class="s1">)</span>
            <span class="s1">default_block_orders = pd.Series(np.ones(len(ix)</span><span class="s3">, </span><span class="s1">dtype=int)</span><span class="s3">,</span>
                                             <span class="s1">index=ix</span><span class="s3">, </span><span class="s1">name=</span><span class="s5">'order'</span><span class="s1">)</span>
            <span class="s1">self.factor_block_orders = (</span>
                <span class="s1">self.factor_block_orders.append(default_block_orders))</span>
            <span class="s1">factor_names = pd.Series(</span>
                <span class="s1">np.concatenate(list(self.factor_block_orders.index)))</span>
        <span class="s1">duplicates = factor_names.duplicated()</span>
        <span class="s3">if </span><span class="s1">duplicates.any():</span>
            <span class="s1">duplicate_names = set(factor_names[duplicates])</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Each factor can be assigned to at most one'</span>
                             <span class="s5">' block of factors in `factor_orders`.'</span>
                             <span class="s5">f' Duplicate entries for </span><span class="s3">{</span><span class="s1">duplicate_names</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>
        <span class="s1">self.factor_names = factor_names.tolist()</span>
        <span class="s1">self.max_factor_order = np.max(self.factor_block_orders)</span>

        <span class="s0"># Re-order the columns of the endog factor mapping to reflect the</span>
        <span class="s0"># orderings of endog_names and factor_names</span>
        <span class="s1">self.endog_factor_map = (</span>
            <span class="s1">self.endog_factor_map.loc[endog_names</span><span class="s3">, </span><span class="s1">factor_names])</span>

        <span class="s0"># Create factor block helpers, and get factor-related state and posdef</span>
        <span class="s0"># dimensions</span>
        <span class="s1">self.k_states_factors = </span><span class="s4">0</span>
        <span class="s1">self.k_posdef_factors = </span><span class="s4">0</span>
        <span class="s1">state_offset = </span><span class="s4">0</span>
        <span class="s1">self.factor_blocks = []</span>
        <span class="s3">for </span><span class="s1">factor_names</span><span class="s3">, </span><span class="s1">factor_order </span><span class="s3">in </span><span class="s1">self.factor_block_orders.items():</span>
            <span class="s1">block = FactorBlock(factor_names</span><span class="s3">, </span><span class="s1">factor_order</span><span class="s3">,</span>
                                <span class="s1">self.endog_factor_map</span><span class="s3">, </span><span class="s1">state_offset</span><span class="s3">,</span>
                                <span class="s1">self.k_endog_Q)</span>
            <span class="s1">self.k_states_factors += block.k_states</span>
            <span class="s1">self.k_posdef_factors += block.k_factors</span>
            <span class="s1">state_offset += block.k_states</span>

            <span class="s1">self.factor_blocks.append(block)</span>

        <span class="s0"># Idiosyncratic state dimensions</span>
        <span class="s1">self.k_states_idio_M = self.k_endog_M </span><span class="s3">if </span><span class="s1">idiosyncratic_ar1 </span><span class="s3">else </span><span class="s4">0</span>
        <span class="s1">self.k_states_idio_Q = self.k_endog_Q * </span><span class="s4">5</span>
        <span class="s1">self.k_states_idio = self.k_states_idio_M + self.k_states_idio_Q</span>

        <span class="s0"># Idiosyncratic posdef dimensions</span>
        <span class="s1">self.k_posdef_idio_M = self.k_endog_M </span><span class="s3">if </span><span class="s1">self.idiosyncratic_ar1 </span><span class="s3">else </span><span class="s4">0</span>
        <span class="s1">self.k_posdef_idio_Q = self.k_endog_Q</span>
        <span class="s1">self.k_posdef_idio = self.k_posdef_idio_M + self.k_posdef_idio_Q</span>

        <span class="s0"># Total states, posdef</span>
        <span class="s1">self.k_states = self.k_states_factors + self.k_states_idio</span>
        <span class="s1">self.k_posdef = self.k_posdef_factors + self.k_posdef_idio</span>

        <span class="s0"># Cache</span>
        <span class="s1">self._endog_factor_iloc = </span><span class="s3">None</span>

    <span class="s3">def </span><span class="s1">_apply_factor_multiplicities(self</span><span class="s3">, </span><span class="s1">factors</span><span class="s3">, </span><span class="s1">factor_orders</span><span class="s3">,</span>
                                     <span class="s1">factor_multiplicities):</span>
        <span class="s2">&quot;&quot;&quot; 
        Expand `factors` and `factor_orders` to account for factor multiplity. 
 
        For example, if there is a `global` factor with multiplicity 2, then 
        this method expands that into `global.1` and `global.2` in both the 
        `factors` and `factor_orders` dictionaries. 
 
        Parameters 
        ---------- 
        factors : dict 
            Dictionary of {endog_name: list of factor names} 
        factor_orders : dict 
            Dictionary of {tuple of factor names: factor order} 
        factor_multiplicities : dict 
            Dictionary of {factor name: factor multiplicity} 
 
        Returns 
        ------- 
        new_factors : dict 
            Dictionary of {endog_name: list of factor names}, with factor names 
            expanded to incorporate multiplicities. 
        new_factors : dict 
            Dictionary of {tuple of factor names: factor order}, with factor 
            names in each tuple expanded to incorporate multiplicities. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Expand the factors to account for the multiplicities</span>
        <span class="s1">new_factors = {}</span>
        <span class="s3">for </span><span class="s1">endog_name</span><span class="s3">, </span><span class="s1">factors_list </span><span class="s3">in </span><span class="s1">factors.items():</span>
            <span class="s1">new_factor_list = []</span>
            <span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">factors_list:</span>
                <span class="s1">n = factor_multiplicities.get(factor_name</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
                <span class="s3">if </span><span class="s1">n &gt; </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">new_factor_list += [</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">factor_name</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">'</span>
                                        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(n)]</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">new_factor_list.append(factor_name)</span>
            <span class="s1">new_factors[endog_name] = new_factor_list</span>

        <span class="s0"># Expand the factor orders to account for the multiplicities</span>
        <span class="s1">new_factor_orders = {}</span>
        <span class="s3">for </span><span class="s1">block</span><span class="s3">, </span><span class="s1">factor_order </span><span class="s3">in </span><span class="s1">factor_orders.items():</span>
            <span class="s3">if not </span><span class="s1">isinstance(block</span><span class="s3">, </span><span class="s1">tuple):</span>
                <span class="s1">block = (block</span><span class="s3">,</span><span class="s1">)</span>
            <span class="s1">new_block = []</span>
            <span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">block:</span>
                <span class="s1">n = factor_multiplicities.get(factor_name</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
                <span class="s3">if </span><span class="s1">n &gt; </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">new_block += [</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">factor_name</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">'</span>
                                  <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(n)]</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">new_block += [factor_name]</span>
            <span class="s1">new_factor_orders[tuple(new_block)] = factor_order</span>

        <span class="s3">return </span><span class="s1">new_factors</span><span class="s3">, </span><span class="s1">new_factor_orders</span>

    <span class="s3">def </span><span class="s1">_construct_endog_factor_map(self</span><span class="s3">, </span><span class="s1">factors</span><span class="s3">, </span><span class="s1">endog_names):</span>
        <span class="s2">&quot;&quot;&quot; 
        Construct mapping of observed variables to factors. 
 
        Parameters 
        ---------- 
        factors : dict 
            Dictionary of {endog_name: list of factor names} 
        endog_names : list of str 
            List of the names of the observed variables. 
 
        Returns 
        ------- 
        endog_factor_map : pd.DataFrame 
            Boolean dataframe with `endog_names` as the index and the factor 
            names (computed from the `factors` input) as the columns. Each cell 
            is True if the associated factor is allowed to load on the 
            associated observed variable. 
 
        &quot;&quot;&quot;</span>
        <span class="s0"># Validate that all entries in the factors dictionary have associated</span>
        <span class="s0"># factors</span>
        <span class="s1">missing = []</span>
        <span class="s3">for </span><span class="s1">key</span><span class="s3">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">factors.items():</span>
            <span class="s3">if not </span><span class="s1">isinstance(value</span><span class="s3">, </span><span class="s1">(list</span><span class="s3">, </span><span class="s1">tuple)) </span><span class="s3">or </span><span class="s1">len(value) == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">missing.append(key)</span>
        <span class="s3">if </span><span class="s1">len(missing):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Each observed variable must be mapped to at'</span>
                             <span class="s5">' least one factor in the `factors` dictionary.'</span>
                             <span class="s5">f' Variables missing factors are: </span><span class="s3">{</span><span class="s1">missing</span><span class="s3">}</span><span class="s5">.'</span><span class="s1">)</span>

        <span class="s0"># Validate that we have been told about the factors for each endog</span>
        <span class="s0"># variable. This is because it doesn't make sense to include an</span>
        <span class="s0"># observed variable that doesn't load on any factor</span>
        <span class="s1">missing = set(endog_names).difference(set(factors.keys()))</span>
        <span class="s3">if </span><span class="s1">len(missing):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'If a `factors` dictionary is provided, then'</span>
                             <span class="s5">' it must include entries for each observed'</span>
                             <span class="s5">f' variable. Missing variables are: </span><span class="s3">{</span><span class="s1">missing</span><span class="s3">}</span><span class="s5">.'</span><span class="s1">)</span>

        <span class="s0"># Figure out the set of factor names</span>
        <span class="s0"># (0 is just a dummy value for the dict - we just do it this way to</span>
        <span class="s0"># collect the keys, in order, without duplicates.)</span>
        <span class="s1">factor_names = {}</span>
        <span class="s3">for </span><span class="s1">key</span><span class="s3">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">factors.items():</span>
            <span class="s3">if </span><span class="s1">isinstance(value</span><span class="s3">, </span><span class="s1">str):</span>
                <span class="s1">factor_names[value] = </span><span class="s4">0</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">factor_names.update({v: </span><span class="s4">0 </span><span class="s3">for </span><span class="s1">v </span><span class="s3">in </span><span class="s1">value})</span>
        <span class="s1">factor_names = list(factor_names.keys())</span>
        <span class="s1">k_factors = len(factor_names)</span>

        <span class="s1">endog_factor_map = pd.DataFrame(</span>
            <span class="s1">np.zeros((self.k_endog</span><span class="s3">, </span><span class="s1">k_factors)</span><span class="s3">, </span><span class="s1">dtype=bool)</span><span class="s3">,</span>
            <span class="s1">index=pd.Index(endog_names</span><span class="s3">, </span><span class="s1">name=</span><span class="s5">'endog'</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">columns=pd.Index(factor_names</span><span class="s3">, </span><span class="s1">name=</span><span class="s5">'factor'</span><span class="s1">))</span>
        <span class="s3">for </span><span class="s1">key</span><span class="s3">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">factors.items():</span>
            <span class="s1">endog_factor_map.loc[key</span><span class="s3">, </span><span class="s1">value] = </span><span class="s3">True</span>

        <span class="s3">return </span><span class="s1">endog_factor_map</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_L1(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors.&quot;&quot;&quot;</span>
        <span class="s1">ix = np.arange(self.k_states_factors)</span>
        <span class="s1">iloc = tuple(ix[block.factors_L1] </span><span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self.factor_blocks)</span>
        <span class="s3">return </span><span class="s1">np.concatenate(iloc)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors_L1_5_ix(self):</span>
        <span class="s2">&quot;&quot;&quot;Factors plus any lags, index shaped (5, k_factors).&quot;&quot;&quot;</span>
        <span class="s1">ix = np.arange(self.k_states_factors)</span>
        <span class="s1">iloc = []</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self.factor_blocks:</span>
            <span class="s1">iloc.append(ix[block.factors_L1_5].reshape(</span><span class="s4">5</span><span class="s3">, </span><span class="s1">block.k_factors))</span>
        <span class="s3">return </span><span class="s1">np.concatenate(iloc</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">idio_ar_L1(self):</span>
        <span class="s2">&quot;&quot;&quot;Idiosyncratic AR states, (first block / lag only).&quot;&quot;&quot;</span>
        <span class="s1">ix1 = self.k_states_factors</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">ix2 = ix1 + self.k_endog</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">ix2 = ix1 + self.k_endog_Q</span>
        <span class="s3">return </span><span class="s1">np.s_[ix1:ix2]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">idio_ar_M(self):</span>
        <span class="s2">&quot;&quot;&quot;Idiosyncratic AR states for monthly variables.&quot;&quot;&quot;</span>
        <span class="s1">ix1 = self.k_states_factors</span>
        <span class="s1">ix2 = ix1</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">ix2 += self.k_endog_M</span>
        <span class="s3">return </span><span class="s1">np.s_[ix1:ix2]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">idio_ar_Q(self):</span>
        <span class="s2">&quot;&quot;&quot;Idiosyncratic AR states and all lags for quarterly variables.&quot;&quot;&quot;</span>
        <span class="s0"># Note that this is equivalent to idio_ar_Q_ix with ravel(order='F')</span>
        <span class="s1">ix1 = self.k_states_factors</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">ix1 += self.k_endog_M</span>
        <span class="s1">ix2 = ix1 + self.k_endog_Q * </span><span class="s4">5</span>
        <span class="s3">return </span><span class="s1">np.s_[ix1:ix2]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">idio_ar_Q_ix(self):</span>
        <span class="s2">&quot;&quot;&quot;Idiosyncratic AR (quarterly) state index, (k_endog_Q, lags).&quot;&quot;&quot;</span>
        <span class="s0"># i.e. the position in the state vector of the second lag of the third</span>
        <span class="s0"># quarterly variable is idio_ar_Q_ix[2, 1]</span>
        <span class="s0"># ravel(order='F') gives e.g (y1.L1, y2.L1, y1.L2, y2.L3, y1.L3, ...)</span>
        <span class="s0"># while</span>
        <span class="s0"># ravel(order='C') gives e.g (y1.L1, y1.L2, y1.L3, y2.L1, y2.L2, ...)</span>
        <span class="s1">start = self.k_states_factors</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">start += self.k_endog_M</span>
        <span class="s3">return </span><span class="s1">(start + np.reshape(</span>
                <span class="s1">np.arange(</span><span class="s4">5 </span><span class="s1">* self.k_endog_Q)</span><span class="s3">, </span><span class="s1">(</span><span class="s4">5</span><span class="s3">, </span><span class="s1">self.k_endog_Q)).T)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">endog_factor_iloc(self):</span>
        <span class="s2">&quot;&quot;&quot;List of list of int, factor indexes for each observed variable.&quot;&quot;&quot;</span>
        <span class="s0"># i.e. endog_factor_iloc[i] is a list of integer locations of the</span>
        <span class="s0"># factors that load on the ith observed variable</span>
        <span class="s3">if </span><span class="s1">self._endog_factor_iloc </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">ilocs = []</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog):</span>
                <span class="s1">ilocs.append(np.where(self.endog_factor_map.iloc[i])[</span><span class="s4">0</span><span class="s1">])</span>
            <span class="s1">self._endog_factor_iloc = ilocs</span>
        <span class="s3">return </span><span class="s1">self._endog_factor_iloc</span>

    <span class="s3">def </span><span class="s1">__getitem__(self</span><span class="s3">, </span><span class="s1">key):</span>
        <span class="s2">&quot;&quot;&quot; 
        Use square brackets to access index / slice elements. 
 
        This is convenient in highlighting the indexing / slice quality of 
        these attributes in the code below. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">key </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'factors_L1'</span><span class="s3">, </span><span class="s5">'factors_L1_5_ix'</span><span class="s3">, </span><span class="s5">'idio_ar_L1'</span><span class="s3">, </span><span class="s5">'idio_ar_M'</span><span class="s3">,</span>
                   <span class="s5">'idio_ar_Q'</span><span class="s3">, </span><span class="s5">'idio_ar_Q_ix'</span><span class="s1">]:</span>
            <span class="s3">return </span><span class="s1">getattr(self</span><span class="s3">, </span><span class="s1">key)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">KeyError(key)</span>


<span class="s3">class </span><span class="s1">DynamicFactorMQ(mlemodel.MLEModel):</span>
    <span class="s2">r&quot;&quot;&quot; 
    Dynamic factor model with EM algorithm; option for monthly/quarterly data. 
 
    Implementation of the dynamic factor model of Bańbura and Modugno (2014) 
    ([1]_) and Bańbura, Giannone, and Reichlin (2011) ([2]_). Uses the EM 
    algorithm for parameter fitting, and so can accommodate a large number of 
    left-hand-side variables. Specifications can include any collection of 
    blocks of factors, including different factor autoregression orders, and 
    can include AR(1) processes for idiosyncratic disturbances. Can 
    incorporate monthly/quarterly mixed frequency data along the lines of 
    Mariano and Murasawa (2011) ([4]_). A special case of this model is the 
    Nowcasting model of Bok et al. (2017) ([3]_). Moreover, this model can be 
    used to compute the news associated with updated data releases. 
 
    Parameters 
    ---------- 
    endog : array_like 
        Observed time-series process :math:`y`. See the &quot;Notes&quot; section for 
        details on how to set up a model with monthly/quarterly mixed frequency 
        data. 
    k_endog_monthly : int, optional 
        If specifying a monthly/quarterly mixed frequency model in which the 
        provided `endog` dataset contains both the monthly and quarterly data, 
        this variable should be used to indicate how many of the variables 
        are monthly. Note that when using the `k_endog_monthly` argument, the 
        columns with monthly variables in `endog` should be ordered first, and 
        the columns with quarterly variables should come afterwards. See the 
        &quot;Notes&quot; section for details on how to set up a model with 
        monthly/quarterly mixed frequency data. 
    factors : int, list, or dict, optional 
        Integer giving the number of (global) factors, a list with the names of 
        (global) factors, or a dictionary with: 
 
        - keys : names of endogenous variables 
        - values : lists of factor names. 
 
        If this is an integer, then the factor names will be 0, 1, .... The 
        default is a single factor that loads on all variables. Note that there 
        cannot be more factors specified than there are monthly variables. 
    factor_orders : int or dict, optional 
        Integer describing the order of the vector autoregression (VAR) 
        governing all factor block dynamics or dictionary with: 
 
        - keys : factor name or tuples of factor names in a block 
        - values : integer describing the VAR order for that factor block 
 
        If a dictionary, this defines the order of the factor blocks in the 
        state vector. Otherwise, factors are ordered so that factors that load 
        on more variables come first (and then alphabetically, to break ties). 
    factor_multiplicities : int or dict, optional 
        This argument provides a convenient way to specify multiple factors 
        that load identically on variables. For example, one may want two 
        &quot;global&quot; factors (factors that load on all variables) that evolve 
        jointly according to a VAR. One could specify two global factors in the 
        `factors` argument and specify that they are in the same block in the 
        `factor_orders` argument, but it is easier to specify a single global 
        factor in the `factors` argument, and set the order in the 
        `factor_orders` argument, and then set the factor multiplicity to 2. 
 
        This argument must be an integer describing the factor multiplicity for 
        all factors or dictionary with: 
 
        - keys : factor name 
        - values : integer describing the factor multiplicity for the factors 
          in the given block 
 
    idiosyncratic_ar1 : bool 
        Whether or not to model the idiosyncratic component for each series as 
        an AR(1) process. If False, the idiosyncratic component is instead 
        modeled as white noise. 
    standardize : bool or tuple, optional 
        If a boolean, whether or not to standardize each endogenous variable to 
        have mean zero and standard deviation 1 before fitting the model. See 
        &quot;Notes&quot; for details about how this option works with postestimation 
        output. If a tuple (usually only used internally), then the tuple must 
        have length 2, with each element containing a Pandas series with index 
        equal to the names of the endogenous variables. The first element 
        should contain the mean values and the second element should contain 
        the standard deviations. Default is True. 
    endog_quarterly : pandas.Series or pandas.DataFrame 
        Observed quarterly variables. If provided, must be a Pandas Series or 
        DataFrame with a DatetimeIndex or PeriodIndex at the quarterly 
        frequency. See the &quot;Notes&quot; section for details on how to set up a model 
        with monthly/quarterly mixed frequency data. 
    init_t0 : bool, optional 
        If True, this option initializes the Kalman filter with the 
        distribution for :math:`\alpha_0` rather than :math:`\alpha_1`. See 
        the &quot;Notes&quot; section for more details. This option is rarely used except 
        for testing. Default is False. 
    obs_cov_diag : bool, optional 
        If True and if `idiosyncratic_ar1 is True`, then this option puts small 
        positive values in the observation disturbance covariance matrix. This 
        is not required for estimation and is rarely used except for testing. 
        (It is sometimes used to prevent numerical errors, for example those 
        associated with a positive semi-definite forecast error covariance 
        matrix at the first time step when using EM initialization, but state 
        space models in Statsmodels switch to the univariate approach in those 
        cases, and so do not need to use this trick). Default is False. 
 
    Notes 
    ----- 
    The basic model is: 
 
    .. math:: 
 
        y_t &amp; = \Lambda f_t + \epsilon_t \\ 
        f_t &amp; = A_1 f_{t-1} + \dots + A_p f_{t-p} + u_t 
 
    where: 
 
    - :math:`y_t` is observed data at time t 
    - :math:`\epsilon_t` is idiosyncratic disturbance at time t (see below for 
      details, including modeling serial correlation in this term) 
    - :math:`f_t` is the unobserved factor at time t 
    - :math:`u_t \sim N(0, Q)` is the factor disturbance at time t 
 
    and: 
 
    - :math:`\Lambda` is referred to as the matrix of factor loadings 
    - :math:`A_i` are matrices of autoregression coefficients 
 
    Furthermore, we allow the idiosyncratic disturbances to be serially 
    correlated, so that, if `idiosyncratic_ar1=True`, 
    :math:`\epsilon_{i,t} = \rho_i \epsilon_{i,t-1} + e_{i,t}`, where 
    :math:`e_{i,t} \sim N(0, \sigma_i^2)`. If `idiosyncratic_ar1=False`, 
    then we instead have :math:`\epsilon_{i,t} = e_{i,t}`. 
 
    This basic setup can be found in [1]_, [2]_, [3]_, and [4]_. 
 
    We allow for two generalizations of this model: 
 
    1. Following [2]_, we allow multiple &quot;blocks&quot; of factors, which are 
       independent from the other blocks of factors. Different blocks can be 
       set to load on different subsets of the observed variables, and can be 
       specified with different lag orders. 
    2. Following [4]_ and [2]_, we allow mixed frequency models in which both 
       monthly and quarterly data are used. See the section on &quot;Mixed frequency 
       models&quot;, below, for more details. 
 
    Additional notes: 
 
    - The observed data may contain arbitrary patterns of missing entries. 
 
    **EM algorithm** 
 
    This model contains a potentially very large number of parameters, and it 
    can be difficult and take a prohibitively long time to numerically optimize 
    the likelihood function using quasi-Newton methods. Instead, the default 
    fitting method in this model uses the EM algorithm, as detailed in [1]_. 
    As a result, the model can accommodate datasets with hundreds of 
    observed variables. 
 
    **Mixed frequency data** 
 
    This model can handle mixed frequency data in two ways. In this section, 
    we only briefly describe this, and refer readers to [2]_ and [4]_ for all 
    details. 
 
    First, because there can be arbitrary patterns of missing data in the 
    observed vector, one can simply include lower frequency variables as 
    observed in a particular higher frequency period, and missing otherwise. 
    For example, in a monthly model, one could include quarterly data as 
    occurring on the third month of each quarter. To use this method, one 
    simply needs to combine the data into a single dataset at the higher 
    frequency that can be passed to this model as the `endog` argument. 
    However, depending on the type of variables used in the analysis and the 
    assumptions about the data generating process, this approach may not be 
    valid. 
 
    For example, suppose that we are interested in the growth rate of real GDP, 
    which is measured at a quarterly frequency. If the basic factor model is 
    specified at a monthly frequency, then the quarterly growth rate in the 
    third month of each quarter -- which is what we actually observe -- is 
    approximated by a particular weighted average of unobserved monthly growth 
    rates. We need to take this particular weight moving average into account 
    in constructing our model, and this is what the second approach does. 
 
    The second approach follows [2]_ and [4]_ in constructing a state space 
    form to explicitly model the quarterly growth rates in terms of the 
    unobserved monthly growth rates. To use this approach, there are two 
    methods: 
 
    1. Combine the monthly and quarterly data into a single dataset at the 
       monthly frequency, with the monthly data in the first columns and the 
       quarterly data in the last columns. Pass this dataset to the model as 
       the `endog` argument and give the number of the variables that are 
       monthly as the `k_endog_monthly` argument. 
    2. Construct a monthly dataset as a Pandas DataFrame with a DatetimeIndex 
       or PeriodIndex at the monthly frequency and separately construct a 
       quarterly dataset as a Pandas DataFrame with a DatetimeIndex or 
       PeriodIndex at the quarterly frequency. Pass the monthly DataFrame to 
       the model as the `endog` argument and pass the quarterly DataFrame to 
       the model as the `endog_quarterly` argument. 
 
    Note that this only incorporates one particular type of mixed frequency 
    data. See also Banbura et al. (2013). &quot;Now-Casting and the Real-Time Data 
    Flow.&quot; for discussion about other types of mixed frequency data that are 
    not supported by this framework. 
 
    **Nowcasting and the news** 
 
    Through its support for monthly/quarterly mixed frequency data, this model 
    can allow for the nowcasting of quarterly variables based on monthly 
    observations. In particular, [2]_ and [3]_ use this model to construct 
    nowcasts of real GDP and analyze the impacts of &quot;the news&quot;, derived from 
    incoming data on a real-time basis. This latter functionality can be 
    accessed through the `news` method of the results object. 
 
    **Standardizing data** 
 
    As is often the case in formulating a dynamic factor model, we do not 
    explicitly account for the mean of each observed variable. Instead, the 
    default behavior is to standardize each variable prior to estimation. Thus 
    if :math:`y_t` are the given observed data, the dynamic factor model is 
    actually estimated on the standardized data defined by: 
 
    .. math:: 
 
        x_{i, t} = (y_{i, t} - \bar y_i) / s_i 
 
    where :math:`\bar y_i` is the sample mean and :math:`s_i` is the sample 
    standard deviation. 
 
    By default, if standardization is applied prior to estimation, results such 
    as in-sample predictions, out-of-sample forecasts, and the computation of 
    the &quot;news&quot;  are reported in the scale of the original data (i.e. the model 
    output has the reverse transformation applied before it is returned to the 
    user). 
 
    Standardization can be disabled by passing `standardization=False` to the 
    model constructor. 
 
    **Identification of factors and loadings** 
 
    The estimated factors and the factor loadings in this model are only 
    identified up to an invertible transformation. As described in (the working 
    paper version of) [2]_, while it is possible to impose normalizations to 
    achieve identification, the EM algorithm does will converge regardless. 
    Moreover, for nowcasting and forecasting purposes, identification is not 
    required. This model does not impose any normalization to identify the 
    factors and the factor loadings. 
 
    **Miscellaneous** 
 
    There are two arguments available in the model constructor that are rarely 
    used but which deserve a brief mention: `init_t0` and `obs_cov_diag`. These 
    arguments are provided to allow exactly matching the output of other 
    packages that have slight differences in how the underlying state space 
    model is set up / applied. 
 
    - `init_t0`: state space models in Statsmodels follow Durbin and Koopman in 
      initializing the model with :math:`\alpha_1 \sim N(a_1, P_1)`. Other 
      implementations sometimes initialize instead with 
      :math:`\alpha_0 \sim N(a_0, P_0)`. We can accommodate this by prepending 
      a row of NaNs to the observed dataset. 
    - `obs_cov_diag`: the state space form in [1]_ incorporates non-zero (but 
      very small) diagonal elements for the observation disturbance covariance 
      matrix. 
 
    Examples 
    -------- 
    Constructing and fitting a `DynamicFactorMQ` model. 
 
    &gt;&gt;&gt; data = sm.datasets.macrodata.load_pandas().data.iloc[-100:] 
    &gt;&gt;&gt; data.index = pd.period_range(start='1984Q4', end='2009Q3', freq='Q') 
    &gt;&gt;&gt; endog = data[['infl', 'tbilrate']].resample('M').last() 
    &gt;&gt;&gt; endog_Q = np.log(data[['realgdp', 'realcons']]).diff().iloc[1:] * 400 
 
    **Basic usage** 
 
    In the simplest case, passing only the `endog` argument results in a model 
    with a single factor that follows an AR(1) process. Note that because we 
    are not also providing an `endog_quarterly` dataset, `endog` can be a numpy 
    array or Pandas DataFrame with any index (it does not have to be monthly). 
 
    The `summary` method can be useful in checking the model specification. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 1 factors in 1 blocks   # of factors:                    1 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    ======================== 
    Dep. variable          0 
    ------------------------ 
             infl          X 
         tbilrate          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
             0          1 
    ===================== 
 
    **Factors** 
 
    With `factors=2`, there will be two independent factors that will each 
    evolve according to separate AR(1) processes. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, factors=2) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 2 factors in 2 blocks   # of factors:                    2 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    =================================== 
    Dep. variable          0          1 
    ----------------------------------- 
             infl          X          X 
         tbilrate          X          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
             0          1 
             1          1 
    ===================== 
 
    **Factor multiplicities** 
 
    By instead specifying `factor_multiplicities=2`, we would still have two 
    factors, but they would be dependent and would evolve jointly according 
    to a VAR(1) process. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, factor_multiplicities=2) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 2 factors in 1 blocks   # of factors:                    2 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    =================================== 
    Dep. variable        0.1        0.2 
    ----------------------------------- 
             infl         X          X 
         tbilrate         X          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
      0.1, 0.2          1 
    ===================== 
 
    **Factor orders** 
 
    In either of the above cases, we could extend the order of the (vector) 
    autoregressions by using the `factor_orders` argument. For example, the 
    below model would contain two independent factors that each evolve 
    according to a separate AR(2) process: 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, factors=2, factor_orders=2) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 2 factors in 2 blocks   # of factors:                    2 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    =================================== 
    Dep. variable          0          1 
    ----------------------------------- 
             infl          X          X 
         tbilrate          X          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
             0          2 
             1          2 
    ===================== 
 
    **Serial correlation in the idiosyncratic disturbances** 
 
    By default, the model allows each idiosyncratic disturbance terms to evolve 
    according to an AR(1) process. If preferred, they can instead be specified 
    to be serially independent by passing `ididosyncratic_ar1=False`. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, idiosyncratic_ar1=False) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 1 factors in 1 blocks   # of factors:                    1 
                    + iid idiosyncratic   Idiosyncratic disturbances:    iid 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    ======================== 
    Dep. variable          0 
    ------------------------ 
             infl          X 
         tbilrate          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
             0          1 
    ===================== 
 
    *Monthly / Quarterly mixed frequency* 
 
    To specify a monthly / quarterly mixed frequency model see the (Notes 
    section for more details about these models): 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, endog_quarterly=endog_Q) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 1 factors in 1 blocks   # of quarterly variables:        2 
                + Mixed frequency (M/Q)   # of factors:                    1 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    ======================== 
    Dep. variable          0 
    ------------------------ 
             infl          X 
         tbilrate          X 
          realgdp          X 
         realcons          X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
             0          1 
    ===================== 
 
    *Customize observed variable / factor loadings* 
 
    To specify that certain that certain observed variables only load on 
    certain factors, it is possible to pass a dictionary to the `factors` 
    argument. 
 
    &gt;&gt;&gt; factors = {'infl': ['global'] 
    ...            'tbilrate': ['global'] 
    ...            'realgdp': ['global', 'real'] 
    ...            'realcons': ['global', 'real']} 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog, endog_quarterly=endog_Q) 
    &gt;&gt;&gt; print(mod.summary()) 
                        Model Specification: Dynamic Factor Model 
    ========================================================================== 
    Model:         Dynamic Factor Model   # of monthly variables:          2 
                + 2 factors in 2 blocks   # of quarterly variables:        2 
                + Mixed frequency (M/Q)   # of factor blocks:              2 
                  + AR(1) idiosyncratic   Idiosyncratic disturbances:  AR(1) 
    Sample:                     1984-10   Standardize variables:        True 
                              - 2009-09 
    Observed variables / factor loadings 
    =================================== 
    Dep. variable     global       real 
    ----------------------------------- 
             infl       X 
         tbilrate       X 
          realgdp       X           X 
         realcons       X           X 
        Factor blocks: 
    ===================== 
         block      order 
    --------------------- 
        global          1 
          real          1 
    ===================== 
 
    **Fitting parameters** 
 
    To fit the model, use the `fit` method. This method uses the EM algorithm 
    by default. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog) 
    &gt;&gt;&gt; res = mod.fit() 
    &gt;&gt;&gt; print(res.summary()) 
                              Dynamic Factor Results 
    ========================================================================== 
    Dep. Variable:      ['infl', 'tbilrate']   No. Observations:         300 
    Model:              Dynamic Factor Model   Log Likelihood       -127.909 
                     + 1 factors in 1 blocks   AIC                   271.817 
                       + AR(1) idiosyncratic   BIC                   301.447 
    Date:                   Tue, 04 Aug 2020   HQIC                  283.675 
    Time:                           15:59:11   EM Iterations              83 
    Sample:                       10-31-1984 
                                - 09-30-2009 
    Covariance Type:            Not computed 
                        Observation equation: 
    ============================================================== 
    Factor loadings:          0    idiosyncratic: AR(1)       var. 
    -------------------------------------------------------------- 
                infl      -0.67                    0.39       0.73 
            tbilrate      -0.63                    0.99       0.01 
           Transition: Factor block 0 
    ======================================= 
                     L1.0    error variance 
    --------------------------------------- 
             0       0.98              0.01 
    ======================================= 
    Warnings: 
    [1] Covariance matrix not calculated. 
 
    *Displaying iteration progress* 
 
    To display information about the EM iterations, use the `disp` argument. 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog) 
    &gt;&gt;&gt; res = mod.fit(disp=10) 
    EM start iterations, llf=-291.21 
    EM iteration 10, llf=-157.17, convergence criterion=0.053801 
    EM iteration 20, llf=-128.99, convergence criterion=0.0035545 
    EM iteration 30, llf=-127.97, convergence criterion=0.00010224 
    EM iteration 40, llf=-127.93, convergence criterion=1.3281e-05 
    EM iteration 50, llf=-127.92, convergence criterion=5.4725e-06 
    EM iteration 60, llf=-127.91, convergence criterion=2.8665e-06 
    EM iteration 70, llf=-127.91, convergence criterion=1.6999e-06 
    EM iteration 80, llf=-127.91, convergence criterion=1.1085e-06 
    EM converged at iteration 83, llf=-127.91, 
       convergence criterion=9.9004e-07 &lt; tolerance=1e-06 
 
    **Results: forecasting, impulse responses, and more** 
 
    One the model is fitted, there are a number of methods available from the 
    results object. Some examples include: 
 
    *Forecasting* 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog) 
    &gt;&gt;&gt; res = mod.fit() 
    &gt;&gt;&gt; print(res.forecast(steps=5)) 
                 infl  tbilrate 
    2009-10  1.784169  0.260401 
    2009-11  1.735848  0.305981 
    2009-12  1.730674  0.350968 
    2010-01  1.742110  0.395369 
    2010-02  1.759786  0.439194 
 
    *Impulse responses* 
 
    &gt;&gt;&gt; mod = sm.tsa.DynamicFactorMQ(endog) 
    &gt;&gt;&gt; res = mod.fit() 
    &gt;&gt;&gt; print(res.impulse_responses(steps=5)) 
           infl  tbilrate 
    0 -1.511956 -1.341498 
    1 -1.483172 -1.315960 
    2 -1.454937 -1.290908 
    3 -1.427240 -1.266333 
    4 -1.400069 -1.242226 
    5 -1.373416 -1.218578 
 
    For other available methods (including in-sample prediction, simulation of 
    time series, extending the results to incorporate new data, and the news), 
    see the documentation for state space models. 
 
    References 
    ---------- 
    .. [1] Bańbura, Marta, and Michele Modugno. 
           &quot;Maximum likelihood estimation of factor models on datasets with 
           arbitrary pattern of missing data.&quot; 
           Journal of Applied Econometrics 29, no. 1 (2014): 133-160. 
    .. [2] Bańbura, Marta, Domenico Giannone, and Lucrezia Reichlin. 
           &quot;Nowcasting.&quot; 
           The Oxford Handbook of Economic Forecasting. July 8, 2011. 
    .. [3] Bok, Brandyn, Daniele Caratelli, Domenico Giannone, 
           Argia M. Sbordone, and Andrea Tambalotti. 2018. 
           &quot;Macroeconomic Nowcasting and Forecasting with Big Data.&quot; 
           Annual Review of Economics 10 (1): 615-43. 
           https://doi.org/10.1146/annurev-economics-080217-053214. 
    .. [4] Mariano, Roberto S., and Yasutomo Murasawa. 
           &quot;A coincident index, common factors, and monthly real GDP.&quot; 
           Oxford Bulletin of Economics and Statistics 72, no. 1 (2010): 27-46. 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly=</span><span class="s3">None, </span><span class="s1">factors=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">factor_orders=</span><span class="s4">1</span><span class="s3">,</span>
                 <span class="s1">factor_multiplicities=</span><span class="s3">None, </span><span class="s1">idiosyncratic_ar1=</span><span class="s3">True,</span>
                 <span class="s1">standardize=</span><span class="s3">True, </span><span class="s1">endog_quarterly=</span><span class="s3">None, </span><span class="s1">init_t0=</span><span class="s3">False,</span>
                 <span class="s1">obs_cov_diag=</span><span class="s3">False, </span><span class="s1">**kwargs):</span>
        <span class="s0"># Handle endog variables</span>
        <span class="s3">if </span><span class="s1">endog_quarterly </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">k_endog_monthly </span><span class="s3">is not None</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'If `endog_quarterly` is specified, then'</span>
                                 <span class="s5">' `endog` must contain only monthly'</span>
                                 <span class="s5">' variables, and so `k_endog_monthly` cannot'</span>
                                 <span class="s5">' be specified since it will be inferred from'</span>
                                 <span class="s5">' the shape of `endog`.'</span><span class="s1">)</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly = self.construct_endog(</span>
                <span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_quarterly)</span>
        <span class="s1">endog_is_pandas = _is_using_pandas(endog</span><span class="s3">, None</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">endog_is_pandas:</span>
            <span class="s3">if </span><span class="s1">isinstance(endog</span><span class="s3">, </span><span class="s1">pd.Series):</span>
                <span class="s1">endog = endog.to_frame()</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">np.ndim(endog) &lt; </span><span class="s4">2</span><span class="s1">:</span>
                <span class="s1">endog = np.atleast_2d(endog).T</span>

        <span class="s3">if </span><span class="s1">k_endog_monthly </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">k_endog_monthly = endog.shape[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s3">if </span><span class="s1">endog_is_pandas:</span>
            <span class="s1">endog_names = endog.columns.tolist()</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">endog.shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">endog_names = [</span><span class="s5">'y'</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">endog_names = [</span><span class="s5">f'y</span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(endog.shape[</span><span class="s4">1</span><span class="s1">])]</span>

        <span class="s1">self.k_endog_M = int_like(k_endog_monthly</span><span class="s3">, </span><span class="s5">'k_endog_monthly'</span><span class="s1">)</span>
        <span class="s1">self.k_endog_Q = endog.shape[</span><span class="s4">1</span><span class="s1">] - self.k_endog_M</span>

        <span class="s0"># Compute helper for handling factors / state indexing</span>
        <span class="s1">s = self._s = DynamicFactorMQStates(</span>
            <span class="s1">self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog_Q</span><span class="s3">, </span><span class="s1">endog_names</span><span class="s3">, </span><span class="s1">factors</span><span class="s3">,</span>
            <span class="s1">factor_orders</span><span class="s3">, </span><span class="s1">factor_multiplicities</span><span class="s3">, </span><span class="s1">idiosyncratic_ar1)</span>

        <span class="s0"># Save parameterization</span>
        <span class="s1">self.factors = factors</span>
        <span class="s1">self.factor_orders = factor_orders</span>
        <span class="s1">self.factor_multiplicities = factor_multiplicities</span>

        <span class="s1">self.endog_factor_map = self._s.endog_factor_map</span>
        <span class="s1">self.factor_block_orders = self._s.factor_block_orders</span>
        <span class="s1">self.factor_names = self._s.factor_names</span>
        <span class="s1">self.k_factors = self._s.k_factors</span>
        <span class="s1">self.k_factor_blocks = len(self.factor_block_orders)</span>
        <span class="s1">self.max_factor_order = self._s.max_factor_order</span>
        <span class="s1">self.idiosyncratic_ar1 = idiosyncratic_ar1</span>
        <span class="s1">self.init_t0 = init_t0</span>
        <span class="s1">self.obs_cov_diag = obs_cov_diag</span>

        <span class="s3">if </span><span class="s1">self.init_t0:</span>
            <span class="s0"># TODO: test each of these options</span>
            <span class="s3">if </span><span class="s1">endog_is_pandas:</span>
                <span class="s1">ix = pd.period_range(endog.index[</span><span class="s4">0</span><span class="s1">] - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">endog.index[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
                                     <span class="s1">freq=endog.index.freq)</span>
                <span class="s1">endog = endog.reindex(ix)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">endog = np.c_[[np.nan] * endog.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">endog.T].T</span>

        <span class="s0"># Standardize endog, if requested</span>
        <span class="s0"># Note: endog_mean and endog_std will always each be 1-dimensional with</span>
        <span class="s0"># length equal to the number of endog variables</span>
        <span class="s3">if </span><span class="s1">isinstance(standardize</span><span class="s3">, </span><span class="s1">tuple) </span><span class="s3">and </span><span class="s1">len(standardize) == </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s1">endog_mean</span><span class="s3">, </span><span class="s1">endog_std = standardize</span>

            <span class="s0"># Validate the input</span>
            <span class="s1">n = endog.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s3">if </span><span class="s1">(isinstance(endog_mean</span><span class="s3">, </span><span class="s1">pd.Series) </span><span class="s3">and not</span>
                    <span class="s1">endog_mean.index.equals(pd.Index(endog_names))):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Invalid value passed for `standardize`:'</span>
                                 <span class="s5">' if a Pandas Series, must have index'</span>
                                 <span class="s5">f' </span><span class="s3">{</span><span class="s1">endog_names</span><span class="s3">}</span><span class="s5">. Got </span><span class="s3">{</span><span class="s1">endog_mean.index</span><span class="s3">}</span><span class="s5">.'</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">endog_mean = np.atleast_1d(endog_mean)</span>
            <span class="s3">if </span><span class="s1">(isinstance(endog_std</span><span class="s3">, </span><span class="s1">pd.Series) </span><span class="s3">and not</span>
                    <span class="s1">endog_std.index.equals(pd.Index(endog_names))):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Invalid value passed for `standardize`:'</span>
                                 <span class="s5">' if a Pandas Series, must have index'</span>
                                 <span class="s5">f' </span><span class="s3">{</span><span class="s1">endog_names</span><span class="s3">}</span><span class="s5">. Got </span><span class="s3">{</span><span class="s1">endog_std.index</span><span class="s3">}</span><span class="s5">.'</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">endog_std = np.atleast_1d(endog_std)</span>

            <span class="s3">if </span><span class="s1">(np.shape(endog_mean) != (n</span><span class="s3">,</span><span class="s1">) </span><span class="s3">or </span><span class="s1">np.shape(endog_std) != (n</span><span class="s3">,</span><span class="s1">)):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Invalid value passed for `standardize`: each'</span>
                                 <span class="s5">f' element must be shaped (</span><span class="s3">{</span><span class="s1">n</span><span class="s3">}</span><span class="s5">,).'</span><span class="s1">)</span>
            <span class="s1">standardize = </span><span class="s3">True</span>

            <span class="s0"># Make sure we have Pandas if endog is Pandas</span>
            <span class="s3">if </span><span class="s1">endog_is_pandas:</span>
                <span class="s1">endog_mean = pd.Series(endog_mean</span><span class="s3">, </span><span class="s1">index=endog_names)</span>
                <span class="s1">endog_std = pd.Series(endog_std</span><span class="s3">, </span><span class="s1">index=endog_names)</span>

        <span class="s3">elif </span><span class="s1">standardize </span><span class="s3">in </span><span class="s1">[</span><span class="s4">1</span><span class="s3">, True</span><span class="s1">]:</span>
            <span class="s1">endog_mean = endog.mean(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">endog_std = endog.std(axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s3">elif </span><span class="s1">standardize </span><span class="s3">in </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, False</span><span class="s1">]:</span>
            <span class="s1">endog_mean = np.zeros(endog.shape[</span><span class="s4">1</span><span class="s1">])</span>
            <span class="s1">endog_std = np.ones(endog.shape[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Invalid value passed for `standardize`.'</span><span class="s1">)</span>
        <span class="s1">self._endog_mean = endog_mean</span>
        <span class="s1">self._endog_std = endog_std</span>
        <span class="s1">self.standardize = standardize</span>
        <span class="s3">if </span><span class="s1">np.any(self._endog_std &lt; </span><span class="s4">1e-10</span><span class="s1">):</span>
            <span class="s1">ix = np.where(self._endog_std &lt; </span><span class="s4">1e-10</span><span class="s1">)</span>
            <span class="s1">names = np.array(endog_names)[ix[</span><span class="s4">0</span><span class="s1">]].tolist()</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Constant variable(s) found in observed'</span>
                             <span class="s5">' variables, but constants cannot be included'</span>
                             <span class="s5">f' in this model. These variables are: </span><span class="s3">{</span><span class="s1">names</span><span class="s3">}</span><span class="s5">.'</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">self.standardize:</span>
            <span class="s1">endog = (endog - self._endog_mean) / self._endog_std</span>

        <span class="s0"># Observation / states slices</span>
        <span class="s1">o = self._o = {</span>
            <span class="s5">'M'</span><span class="s1">: np.s_[:self.k_endog_M]</span><span class="s3">,</span>
            <span class="s5">'Q'</span><span class="s1">: np.s_[self.k_endog_M:]}</span>

        <span class="s0"># Construct the basic state space representation</span>
        <span class="s1">super().__init__(endog</span><span class="s3">, </span><span class="s1">k_states=s.k_states</span><span class="s3">, </span><span class="s1">k_posdef=s.k_posdef</span><span class="s3">,</span>
                         <span class="s1">**kwargs)</span>

        <span class="s0"># Revert the standardization for orig_endog</span>
        <span class="s3">if </span><span class="s1">self.standardize:</span>
            <span class="s1">self.data.orig_endog = (</span>
                <span class="s1">self.data.orig_endog * self._endog_std + self._endog_mean)</span>

        <span class="s0"># State initialization</span>
        <span class="s0"># Note: we could just initialize the entire thing as stationary, but</span>
        <span class="s0"># doing each block separately should be faster and avoid numerical</span>
        <span class="s0"># issues</span>
        <span class="s3">if </span><span class="s5">'initialization' </span><span class="s3">not in </span><span class="s1">kwargs:</span>
            <span class="s1">self.ssm.initialize(self._default_initialization())</span>

        <span class="s0"># Fixed components of the state space representation</span>

        <span class="s0"># &gt; design</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">self[</span><span class="s5">'design'</span><span class="s3">, </span><span class="s1">o[</span><span class="s5">'M'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_M'</span><span class="s1">]] = np.eye(self.k_endog_M)</span>
        <span class="s1">multipliers = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(len(multipliers)):</span>
            <span class="s1">m = multipliers[i]</span>
            <span class="s1">self[</span><span class="s5">'design'</span><span class="s3">, </span><span class="s1">o[</span><span class="s5">'Q'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_Q_ix'</span><span class="s1">][:</span><span class="s3">, </span><span class="s1">i]] = (</span>
                <span class="s1">m * np.eye(self.k_endog_Q))</span>

        <span class="s0"># &gt; obs cov</span>
        <span class="s3">if </span><span class="s1">self.obs_cov_diag:</span>
            <span class="s1">self[</span><span class="s5">'obs_cov'</span><span class="s1">] = np.eye(self.k_endog) * </span><span class="s4">1e-4</span>

        <span class="s0"># &gt; transition</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s3">if </span><span class="s1">block.k_factors == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">tmp = </span><span class="s4">0</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">tmp = np.zeros((block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors))</span>
            <span class="s1">self[</span><span class="s5">'transition'</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors'</span><span class="s1">]] = (</span>
                <span class="s1">companion_matrix([</span><span class="s4">1</span><span class="s1">] + [tmp] * block._factor_order).T)</span>
        <span class="s3">if </span><span class="s1">self.k_endog_Q == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">tmp = </span><span class="s4">0</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">tmp = np.zeros((self.k_endog_Q</span><span class="s3">, </span><span class="s1">self.k_endog_Q))</span>
        <span class="s1">self[</span><span class="s5">'transition'</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]] = (</span>
            <span class="s1">companion_matrix([</span><span class="s4">1</span><span class="s1">] + [tmp] * </span><span class="s4">5</span><span class="s1">).T)</span>

        <span class="s0"># &gt; selection</span>
        <span class="s1">ix1 = ix2 = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s1">ix2 += block.k_factors</span>
            <span class="s1">self[</span><span class="s5">'selection'</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors_ix'</span><span class="s1">][:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ix1:ix2] = (</span>
                <span class="s1">np.eye(block.k_factors))</span>
            <span class="s1">ix1 = ix2</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">ix2 = ix1 + self.k_endog_M</span>
            <span class="s1">self[</span><span class="s5">'selection'</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_M'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ix1:ix2] = np.eye(self.k_endog_M)</span>
            <span class="s1">ix1 = ix2</span>

        <span class="s1">ix2 = ix1 + self.k_endog_Q</span>
        <span class="s1">self[</span><span class="s5">'selection'</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_Q_ix'</span><span class="s1">][:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">ix1:ix2] = (</span>
            <span class="s1">np.eye(self.k_endog_Q))</span>

        <span class="s0"># Parameters</span>
        <span class="s1">self.params = OrderedDict([</span>
            <span class="s1">(</span><span class="s5">'loadings'</span><span class="s3">, </span><span class="s1">np.sum(self.endog_factor_map.values))</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">'factor_ar'</span><span class="s3">, </span><span class="s1">np.sum([block.k_factors**</span><span class="s4">2 </span><span class="s1">* block.factor_order</span>
                                  <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks]))</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">'factor_cov'</span><span class="s3">, </span><span class="s1">np.sum([block.k_factors * (block.k_factors + </span><span class="s4">1</span><span class="s1">) // </span><span class="s4">2</span>
                                   <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks]))</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">'idiosyncratic_ar1'</span><span class="s3">,</span>
                <span class="s1">self.k_endog </span><span class="s3">if </span><span class="s1">self.idiosyncratic_ar1 </span><span class="s3">else </span><span class="s4">0</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">'idiosyncratic_var'</span><span class="s3">, </span><span class="s1">self.k_endog)])</span>
        <span class="s1">self.k_params = np.sum(list(self.params.values()))</span>

        <span class="s0"># Parameter slices</span>
        <span class="s1">ix = np.split(np.arange(self.k_params)</span><span class="s3">,</span>
                      <span class="s1">np.cumsum(list(self.params.values()))[:-</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">self._p = dict(zip(self.params.keys()</span><span class="s3">, </span><span class="s1">ix))</span>

        <span class="s0"># Cache</span>
        <span class="s1">self._loading_constraints = {}</span>

        <span class="s0"># Initialization kwarg keys, e.g. for cloning</span>
        <span class="s1">self._init_keys += [</span>
            <span class="s5">'factors'</span><span class="s3">, </span><span class="s5">'factor_orders'</span><span class="s3">, </span><span class="s5">'factor_multiplicities'</span><span class="s3">,</span>
            <span class="s5">'idiosyncratic_ar1'</span><span class="s3">, </span><span class="s5">'standardize'</span><span class="s3">, </span><span class="s5">'init_t0'</span><span class="s3">,</span>
            <span class="s5">'obs_cov_diag'</span><span class="s1">] + list(kwargs.keys())</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">construct_endog(cls</span><span class="s3">, </span><span class="s1">endog_monthly</span><span class="s3">, </span><span class="s1">endog_quarterly):</span>
        <span class="s2">&quot;&quot;&quot; 
        Construct a combined dataset from separate monthly and quarterly data. 
 
        Parameters 
        ---------- 
        endog_monthly : array_like 
            Monthly dataset. If a quarterly dataset is given, then this must 
            be a Pandas object with a PeriodIndex or DatetimeIndex at a monthly 
            frequency. 
        endog_quarterly : array_like or None 
            Quarterly dataset. If not None, then this must be a Pandas object 
            with a PeriodIndex or DatetimeIndex at a quarterly frequency. 
 
        Returns 
        ------- 
        endog : array_like 
            If both endog_monthly and endog_quarterly were given, this is a 
            Pandas DataFrame with a PeriodIndex at the monthly frequency, with 
            all of the columns from `endog_monthly` ordered first and the 
            columns from `endog_quarterly` ordered afterwards. Otherwise it is 
            simply the input `endog_monthly` dataset. 
        k_endog_monthly : int 
            The number of monthly variables (which are ordered first) in the 
            returned `endog` dataset. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Create combined dataset</span>
        <span class="s3">if </span><span class="s1">endog_quarterly </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s0"># Validate endog_monthly</span>
            <span class="s1">base_msg = (</span><span class="s5">'If given both monthly and quarterly data'</span>
                        <span class="s5">' then the monthly dataset must be a Pandas'</span>
                        <span class="s5">' object with a date index at a monthly frequency.'</span><span class="s1">)</span>
            <span class="s3">if not </span><span class="s1">isinstance(endog_monthly</span><span class="s3">, </span><span class="s1">(pd.Series</span><span class="s3">, </span><span class="s1">pd.DataFrame)):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Given monthly dataset is not a'</span>
                                 <span class="s5">' Pandas object. ' </span><span class="s1">+ base_msg)</span>
            <span class="s3">elif </span><span class="s1">endog_monthly.index.inferred_type </span><span class="s3">not in </span><span class="s1">(</span><span class="s5">&quot;datetime64&quot;</span><span class="s3">,</span>
                                                           <span class="s5">&quot;period&quot;</span><span class="s1">):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Given monthly dataset has an'</span>
                                 <span class="s5">' index with non-date values. ' </span><span class="s1">+ base_msg)</span>
            <span class="s3">elif not </span><span class="s1">getattr(endog_monthly.index</span><span class="s3">, </span><span class="s5">'freqstr'</span><span class="s3">, </span><span class="s5">'N'</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">] == </span><span class="s5">'M'</span><span class="s1">:</span>
                <span class="s1">freqstr = getattr(endog_monthly.index</span><span class="s3">, </span><span class="s5">'freqstr'</span><span class="s3">, </span><span class="s5">'None'</span><span class="s1">)</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Index of given monthly dataset has a'</span>
                                 <span class="s5">' non-monthly frequency (to check this,'</span>
                                 <span class="s5">' examine the `freqstr` attribute of the'</span>
                                 <span class="s5">' index of the dataset - it should start with'</span>
                                 <span class="s5">' M if it is monthly).'</span>
                                 <span class="s5">f' Got </span><span class="s3">{</span><span class="s1">freqstr</span><span class="s3">}</span><span class="s5">. ' </span><span class="s1">+ base_msg)</span>

            <span class="s0"># Validate endog_quarterly</span>
            <span class="s1">base_msg = (</span><span class="s5">'If a quarterly dataset is given, then it must be a'</span>
                        <span class="s5">' Pandas object with a date index at a quarterly'</span>
                        <span class="s5">' frequency.'</span><span class="s1">)</span>
            <span class="s3">if not </span><span class="s1">isinstance(endog_quarterly</span><span class="s3">, </span><span class="s1">(pd.Series</span><span class="s3">, </span><span class="s1">pd.DataFrame)):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Given quarterly dataset is not a'</span>
                                 <span class="s5">' Pandas object. ' </span><span class="s1">+ base_msg)</span>
            <span class="s3">elif </span><span class="s1">endog_quarterly.index.inferred_type </span><span class="s3">not in </span><span class="s1">(</span><span class="s5">&quot;datetime64&quot;</span><span class="s3">,</span>
                                                             <span class="s5">&quot;period&quot;</span><span class="s1">):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Given quarterly dataset has an'</span>
                                 <span class="s5">' index with non-date values. ' </span><span class="s1">+ base_msg)</span>
            <span class="s3">elif not </span><span class="s1">getattr(endog_quarterly.index</span><span class="s3">, </span><span class="s5">'freqstr'</span><span class="s3">, </span><span class="s5">'N'</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">] == </span><span class="s5">'Q'</span><span class="s1">:</span>
                <span class="s1">freqstr = getattr(endog_quarterly.index</span><span class="s3">, </span><span class="s5">'freqstr'</span><span class="s3">, </span><span class="s5">'None'</span><span class="s1">)</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Index of given quarterly dataset'</span>
                                 <span class="s5">' has a non-quarterly frequency (to check'</span>
                                 <span class="s5">' this, examine the `freqstr` attribute of'</span>
                                 <span class="s5">' the index of the dataset - it should start'</span>
                                 <span class="s5">' with Q if it is quarterly).'</span>
                                 <span class="s5">f' Got </span><span class="s3">{</span><span class="s1">freqstr</span><span class="s3">}</span><span class="s5">. ' </span><span class="s1">+ base_msg)</span>

            <span class="s0"># Convert to PeriodIndex, if applicable</span>
            <span class="s3">if </span><span class="s1">hasattr(endog_monthly.index</span><span class="s3">, </span><span class="s5">'to_period'</span><span class="s1">):</span>
                <span class="s1">endog_monthly = endog_monthly.to_period(</span><span class="s5">'M'</span><span class="s1">)</span>
            <span class="s3">if </span><span class="s1">hasattr(endog_quarterly.index</span><span class="s3">, </span><span class="s5">'to_period'</span><span class="s1">):</span>
                <span class="s1">endog_quarterly = endog_quarterly.to_period(</span><span class="s5">'Q'</span><span class="s1">)</span>

            <span class="s0"># Combine the datasets</span>
            <span class="s1">endog = pd.concat([</span>
                <span class="s1">endog_monthly</span><span class="s3">,</span>
                <span class="s1">endog_quarterly.resample(</span><span class="s5">'M'</span><span class="s3">, </span><span class="s1">convention=</span><span class="s5">'end'</span><span class="s1">).first()]</span><span class="s3">,</span>
                <span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

            <span class="s0"># Make sure we didn't accidentally get duplicate column names</span>
            <span class="s1">column_counts = endog.columns.value_counts()</span>
            <span class="s3">if </span><span class="s1">column_counts.max() &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">columns = endog.columns.values.astype(object)</span>
                <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">column_counts.index:</span>
                    <span class="s1">count = column_counts.loc[name]</span>
                    <span class="s3">if </span><span class="s1">count == </span><span class="s4">1</span><span class="s1">:</span>
                        <span class="s3">continue</span>
                    <span class="s1">mask = columns == name</span>
                    <span class="s1">columns[mask] = [</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(count)]</span>
                <span class="s1">endog.columns = columns</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">endog = endog_monthly.copy()</span>
        <span class="s1">shape = endog_monthly.shape</span>
        <span class="s1">k_endog_monthly = shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">len(shape) == </span><span class="s4">2 </span><span class="s3">else </span><span class="s4">1</span>

        <span class="s3">return </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly</span>

    <span class="s3">def </span><span class="s1">clone(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly=</span><span class="s3">None, </span><span class="s1">endog_quarterly=</span><span class="s3">None,</span>
              <span class="s1">retain_standardization=</span><span class="s3">False, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Clone state space model with new data and optionally new specification. 
 
        Parameters 
        ---------- 
        endog : array_like 
            The observed time-series process :math:`y` 
        k_endog_monthly : int, optional 
            If specifying a monthly/quarterly mixed frequency model in which 
            the provided `endog` dataset contains both the monthly and 
            quarterly data, this variable should be used to indicate how many 
            of the variables are monthly. 
        endog_quarterly : array_like, optional 
            Observations of quarterly variables. If provided, must be a 
            Pandas Series or DataFrame with a DatetimeIndex or PeriodIndex at 
            the quarterly frequency. 
        kwargs 
            Keyword arguments to pass to the new model class to change the 
            model specification. 
 
        Returns 
        ------- 
        model : DynamicFactorMQ instance 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">retain_standardization </span><span class="s3">and </span><span class="s1">self.standardize:</span>
            <span class="s1">kwargs[</span><span class="s5">'standardize'</span><span class="s1">] = (self._endog_mean</span><span class="s3">, </span><span class="s1">self._endog_std)</span>
        <span class="s1">mod = self._clone_from_init_kwds(</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly=k_endog_monthly</span><span class="s3">,</span>
            <span class="s1">endog_quarterly=endog_quarterly</span><span class="s3">, </span><span class="s1">**kwargs)</span>
        <span class="s3">return </span><span class="s1">mod</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">_res_classes(self):</span>
        <span class="s3">return </span><span class="s1">{</span><span class="s5">'fit'</span><span class="s1">: (DynamicFactorMQResults</span><span class="s3">, </span><span class="s1">mlemodel.MLEResultsWrapper)}</span>

    <span class="s3">def </span><span class="s1">_default_initialization(self):</span>
        <span class="s1">s = self._s</span>
        <span class="s1">init = initialization.Initialization(self.k_states)</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s1">init.set(block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s5">'stationary'</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(s[</span><span class="s5">'idio_ar_M'</span><span class="s1">].start</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_M'</span><span class="s1">].stop):</span>
                <span class="s1">init.set(i</span><span class="s3">, </span><span class="s5">'stationary'</span><span class="s1">)</span>
        <span class="s1">init.set(s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]</span><span class="s3">, </span><span class="s5">'stationary'</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">init</span>

    <span class="s3">def </span><span class="s1">_get_endog_names(self</span><span class="s3">, </span><span class="s1">truncate=</span><span class="s3">None, </span><span class="s1">as_string=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s3">if </span><span class="s1">truncate </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">truncate = </span><span class="s3">False if </span><span class="s1">as_string </span><span class="s3">is False or </span><span class="s1">self.k_endog == </span><span class="s4">1 </span><span class="s3">else </span><span class="s4">24</span>
        <span class="s3">if </span><span class="s1">as_string </span><span class="s3">is False and </span><span class="s1">truncate </span><span class="s3">is not False</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Can only truncate endog names if they'</span>
                             <span class="s5">' are returned as a string.'</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">as_string </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">as_string = truncate </span><span class="s3">is not False</span>

        <span class="s0"># The base `endog_names` property is only a list if there are at least</span>
        <span class="s0"># two variables; often, we need it to be a list</span>
        <span class="s1">endog_names = self.endog_names</span>
        <span class="s3">if not </span><span class="s1">isinstance(endog_names</span><span class="s3">, </span><span class="s1">list):</span>
            <span class="s1">endog_names = [endog_names]</span>

        <span class="s3">if </span><span class="s1">as_string:</span>
            <span class="s1">endog_names = [str(name) </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names]</span>

        <span class="s3">if </span><span class="s1">truncate </span><span class="s3">is not False</span><span class="s1">:</span>
            <span class="s1">n = truncate</span>
            <span class="s1">endog_names = [name </span><span class="s3">if </span><span class="s1">len(name) &lt;= n </span><span class="s3">else </span><span class="s1">name[:n] + </span><span class="s5">'...'</span>
                           <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names]</span>

        <span class="s3">return </span><span class="s1">endog_names</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">_model_name(self):</span>
        <span class="s1">model_name = [</span>
            <span class="s5">'Dynamic Factor Model'</span><span class="s3">,</span>
            <span class="s5">f'</span><span class="s3">{</span><span class="s1">self.k_factors</span><span class="s3">} </span><span class="s5">factors in </span><span class="s3">{</span><span class="s1">self.k_factor_blocks</span><span class="s3">} </span><span class="s5">blocks'</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">self.k_endog_Q &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">model_name.append(</span><span class="s5">'Mixed frequency (M/Q)'</span><span class="s1">)</span>

        <span class="s1">error_type = </span><span class="s5">'AR(1)' </span><span class="s3">if </span><span class="s1">self.idiosyncratic_ar1 </span><span class="s3">else </span><span class="s5">'iid'</span>
        <span class="s1">model_name.append(</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">error_type</span><span class="s3">} </span><span class="s5">idiosyncratic'</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">model_name</span>

    <span class="s3">def </span><span class="s1">summary(self</span><span class="s3">, </span><span class="s1">truncate_endog_names=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Create a summary table describing the model. 
 
        Parameters 
        ---------- 
        truncate_endog_names : int, optional 
            The number of characters to show for names of observed variables. 
            Default is 24 if there is more than one observed variable, or 
            an unlimited number of there is only one. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Get endog names</span>
        <span class="s1">endog_names = self._get_endog_names(truncate=truncate_endog_names</span><span class="s3">,</span>
                                            <span class="s1">as_string=</span><span class="s3">True</span><span class="s1">)</span>

        <span class="s1">title = </span><span class="s5">'Model Specification: Dynamic Factor Model'</span>

        <span class="s3">if </span><span class="s1">self._index_dates:</span>
            <span class="s1">ix = self._index</span>
            <span class="s1">d = ix[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">sample = [</span><span class="s5">'%s' </span><span class="s1">% d]</span>
            <span class="s1">d = ix[-</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">sample += [</span><span class="s5">'- ' </span><span class="s1">+ </span><span class="s5">'%s' </span><span class="s1">% d]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">sample = [str(</span><span class="s4">0</span><span class="s1">)</span><span class="s3">, </span><span class="s5">' - ' </span><span class="s1">+ str(self.nobs)]</span>

        <span class="s0"># Standardize the model name as a list of str</span>
        <span class="s1">model_name = self._model_name</span>

        <span class="s0"># - Top summary table ------------------------------------------------</span>
        <span class="s1">top_left = []</span>
        <span class="s1">top_left.append((</span><span class="s5">'Model:'</span><span class="s3">, </span><span class="s1">[model_name[</span><span class="s4">0</span><span class="s1">]]))</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">len(model_name)):</span>
            <span class="s1">top_left.append((</span><span class="s5">''</span><span class="s3">, </span><span class="s1">[</span><span class="s5">'+ ' </span><span class="s1">+ model_name[i]]))</span>
        <span class="s1">top_left += [</span>
            <span class="s1">(</span><span class="s5">'Sample:'</span><span class="s3">, </span><span class="s1">[sample[</span><span class="s4">0</span><span class="s1">]])</span><span class="s3">,</span>
            <span class="s1">(</span><span class="s5">''</span><span class="s3">, </span><span class="s1">[sample[</span><span class="s4">1</span><span class="s1">]])]</span>

        <span class="s1">top_right = []</span>
        <span class="s3">if </span><span class="s1">self.k_endog_Q &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">top_right += [</span>
                <span class="s1">(</span><span class="s5">'# of monthly variables:'</span><span class="s3">, </span><span class="s1">[self.k_endog_M])</span><span class="s3">,</span>
                <span class="s1">(</span><span class="s5">'# of quarterly variables:'</span><span class="s3">, </span><span class="s1">[self.k_endog_Q])]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">top_right += [(</span><span class="s5">'# of observed variables:'</span><span class="s3">, </span><span class="s1">[self.k_endog])]</span>
        <span class="s3">if </span><span class="s1">self.k_factor_blocks == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">top_right += [(</span><span class="s5">'# of factors:'</span><span class="s3">, </span><span class="s1">[self.k_factors])]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">top_right += [(</span><span class="s5">'# of factor blocks:'</span><span class="s3">, </span><span class="s1">[self.k_factor_blocks])]</span>
        <span class="s1">top_right += [(</span><span class="s5">'Idiosyncratic disturbances:'</span><span class="s3">,</span>
                       <span class="s1">[</span><span class="s5">'AR(1)' </span><span class="s3">if </span><span class="s1">self.idiosyncratic_ar1 </span><span class="s3">else </span><span class="s5">'iid'</span><span class="s1">])</span><span class="s3">,</span>
                      <span class="s1">(</span><span class="s5">'Standardize variables:'</span><span class="s3">, </span><span class="s1">[self.standardize])]</span>

        <span class="s1">summary = Summary()</span>
        <span class="s1">self.model = self</span>
        <span class="s1">summary.add_table_2cols(self</span><span class="s3">, </span><span class="s1">gleft=top_left</span><span class="s3">, </span><span class="s1">gright=top_right</span><span class="s3">,</span>
                                <span class="s1">title=title)</span>
        <span class="s1">table_ix = </span><span class="s4">1</span>
        <span class="s3">del </span><span class="s1">self.model</span>

        <span class="s0"># - Endog / factor map -----------------------------------------------</span>
        <span class="s1">data = self.endog_factor_map.replace({</span><span class="s3">True</span><span class="s1">: </span><span class="s5">'X'</span><span class="s3">, False</span><span class="s1">: </span><span class="s5">''</span><span class="s1">})</span>
        <span class="s1">data.index = endog_names</span>
        <span class="s3">try</span><span class="s1">:</span>
            <span class="s1">items = data.items()</span>
        <span class="s3">except </span><span class="s1">AttributeError:</span>
            <span class="s0"># Remove after pandas 1.5 is minimum</span>
            <span class="s1">items = data.iteritems()</span>
        <span class="s3">for </span><span class="s1">name</span><span class="s3">, </span><span class="s1">col </span><span class="s3">in </span><span class="s1">items:</span>
            <span class="s1">data[name] = data[name] + (</span><span class="s5">' ' </span><span class="s1">* (len(name) // </span><span class="s4">2</span><span class="s1">))</span>
        <span class="s1">data.index.name = </span><span class="s5">'Dep. variable'</span>
        <span class="s1">data = data.reset_index()</span>

        <span class="s1">params_data = data.values</span>
        <span class="s1">params_header = data.columns.map(str).tolist()</span>
        <span class="s1">params_stubs = </span><span class="s3">None</span>

        <span class="s1">title = </span><span class="s5">'Observed variables / factor loadings'</span>
        <span class="s1">table = SimpleTable(</span>
            <span class="s1">params_data</span><span class="s3">, </span><span class="s1">params_header</span><span class="s3">, </span><span class="s1">params_stubs</span><span class="s3">,</span>
            <span class="s1">txt_fmt=fmt_params</span><span class="s3">, </span><span class="s1">title=title)</span>

        <span class="s1">summary.tables.insert(table_ix</span><span class="s3">, </span><span class="s1">table)</span>
        <span class="s1">table_ix += </span><span class="s4">1</span>

        <span class="s0"># - Factor blocks summary table --------------------------------------</span>
        <span class="s1">data = self.factor_block_orders.reset_index()</span>
        <span class="s1">data[</span><span class="s5">'block'</span><span class="s1">] = data[</span><span class="s5">'block'</span><span class="s1">].map(</span>
            <span class="s3">lambda </span><span class="s1">factor_names: </span><span class="s5">', '</span><span class="s1">.join(factor_names))</span>
        <span class="s3">try</span><span class="s1">:</span>
            <span class="s1">data[[</span><span class="s5">'order'</span><span class="s1">]] = data[[</span><span class="s5">'order'</span><span class="s1">]].map(str)</span>
        <span class="s3">except </span><span class="s1">AttributeError:</span>
            <span class="s1">data[[</span><span class="s5">'order'</span><span class="s1">]] = data[[</span><span class="s5">'order'</span><span class="s1">]].applymap(str)</span>

        <span class="s1">params_data = data.values</span>
        <span class="s1">params_header = data.columns.map(str).tolist()</span>
        <span class="s1">params_stubs = </span><span class="s3">None</span>

        <span class="s1">title = </span><span class="s5">'Factor blocks:'</span>
        <span class="s1">table = SimpleTable(</span>
            <span class="s1">params_data</span><span class="s3">, </span><span class="s1">params_header</span><span class="s3">, </span><span class="s1">params_stubs</span><span class="s3">,</span>
            <span class="s1">txt_fmt=fmt_params</span><span class="s3">, </span><span class="s1">title=title)</span>

        <span class="s1">summary.tables.insert(table_ix</span><span class="s3">, </span><span class="s1">table)</span>
        <span class="s1">table_ix += </span><span class="s4">1</span>

        <span class="s3">return </span><span class="s1">summary</span>

    <span class="s3">def </span><span class="s1">__str__(self):</span>
        <span class="s2">&quot;&quot;&quot;Summary tables showing model specification.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">str(self.summary())</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">state_names(self):</span>
        <span class="s2">&quot;&quot;&quot;(list of str) List of human readable names for unobserved states.&quot;&quot;&quot;</span>
        <span class="s0"># Factors</span>
        <span class="s1">state_names = []</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
            <span class="s1">state_names += [</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">block.factor_names[:]]</span>
            <span class="s3">for </span><span class="s1">s </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">block._factor_order):</span>
                <span class="s1">state_names += [</span><span class="s5">f'L</span><span class="s3">{</span><span class="s1">s</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">'</span>
                                <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">block.factor_names]</span>

        <span class="s0"># Monthly error</span>
        <span class="s1">endog_names = self._get_endog_names()</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">endog_names_M = endog_names[self._o[</span><span class="s5">'M'</span><span class="s1">]]</span>
            <span class="s1">state_names += [</span><span class="s5">f'eps_M.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names_M]</span>
        <span class="s1">endog_names_Q = endog_names[self._o[</span><span class="s5">'Q'</span><span class="s1">]]</span>

        <span class="s0"># Quarterly error</span>
        <span class="s1">state_names += [</span><span class="s5">f'eps_Q.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names_Q]</span>
        <span class="s3">for </span><span class="s1">s </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">5</span><span class="s1">):</span>
            <span class="s1">state_names += [</span><span class="s5">f'L</span><span class="s3">{</span><span class="s1">s</span><span class="s3">}</span><span class="s5">.eps_Q.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names_Q]</span>
        <span class="s3">return </span><span class="s1">state_names</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">param_names(self):</span>
        <span class="s2">&quot;&quot;&quot;(list of str) List of human readable parameter names.&quot;&quot;&quot;</span>
        <span class="s1">param_names = []</span>
        <span class="s0"># Loadings</span>
        <span class="s0"># So that Lambda = params[ix].reshape(self.k_endog, self.k_factors)</span>
        <span class="s0"># (where Lambda stacks Lambda_M and Lambda_Q)</span>
        <span class="s1">endog_names = self._get_endog_names(as_string=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">endog_name </span><span class="s3">in </span><span class="s1">endog_names:</span>
            <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
                <span class="s3">for </span><span class="s1">factor_name </span><span class="s3">in </span><span class="s1">block.factor_names:</span>
                    <span class="s3">if </span><span class="s1">self.endog_factor_map.loc[endog_name</span><span class="s3">, </span><span class="s1">factor_name]:</span>
                        <span class="s1">param_names.append(</span>
                            <span class="s5">f'loading.</span><span class="s3">{</span><span class="s1">factor_name</span><span class="s3">}</span><span class="s5">-&gt;</span><span class="s3">{</span><span class="s1">endog_name</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

        <span class="s0"># Factor VAR</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
            <span class="s3">for </span><span class="s1">to_factor </span><span class="s3">in </span><span class="s1">block.factor_names:</span>
                <span class="s1">param_names += [</span><span class="s5">f'L</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">from_factor</span><span class="s3">}</span><span class="s5">-&gt;</span><span class="s3">{</span><span class="s1">to_factor</span><span class="s3">}</span><span class="s5">'</span>
                                <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">block.factor_order + </span><span class="s4">1</span><span class="s1">)</span>
                                <span class="s3">for </span><span class="s1">from_factor </span><span class="s3">in </span><span class="s1">block.factor_names]</span>

        <span class="s0"># Factor covariance</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(len(self._s.factor_blocks)):</span>
            <span class="s1">block = self._s.factor_blocks[i]</span>
            <span class="s1">param_names += [</span><span class="s5">f'fb(</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">).cov.chol[</span><span class="s3">{</span><span class="s1">j + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">,</span><span class="s3">{</span><span class="s1">k + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">]'</span>
                            <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(block.k_factors)</span>
                            <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range(j + </span><span class="s4">1</span><span class="s1">)]</span>

        <span class="s0"># Error AR(1)</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">endog_names_M = endog_names[self._o[</span><span class="s5">'M'</span><span class="s1">]]</span>
            <span class="s1">param_names += [</span><span class="s5">f'L1.eps_M.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names_M]</span>

            <span class="s1">endog_names_Q = endog_names[self._o[</span><span class="s5">'Q'</span><span class="s1">]]</span>
            <span class="s1">param_names += [</span><span class="s5">f'L1.eps_Q.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names_Q]</span>

        <span class="s0"># Error innovation variances</span>
        <span class="s1">param_names += [</span><span class="s5">f'sigma2.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">' </span><span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">endog_names]</span>

        <span class="s3">return </span><span class="s1">param_names</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">start_params(self):</span>
        <span class="s2">&quot;&quot;&quot;(array) Starting parameters for maximum likelihood estimation.&quot;&quot;&quot;</span>
        <span class="s1">params = np.zeros(self.k_params</span><span class="s3">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s0"># (1) estimate factors one at a time, where the first step uses</span>
        <span class="s0"># PCA on all `endog` variables that load on the first factor, and</span>
        <span class="s0"># subsequent steps use residuals from the previous steps.</span>
        <span class="s0"># TODO: what about factors that only load on quarterly variables?</span>
        <span class="s1">endog_factor_map_M = self.endog_factor_map.iloc[:self.k_endog_M]</span>
        <span class="s1">factors = []</span>
        <span class="s1">endog = np.require(</span>
            <span class="s1">pd.DataFrame(self.endog).interpolate().fillna(method=</span><span class="s5">'backfill'</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">requirements=</span><span class="s5">&quot;W&quot;</span>
        <span class="s1">)</span>
        <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">self.factor_names:</span>
            <span class="s0"># Try to retrieve this from monthly variables, which is most</span>
            <span class="s0"># consistent</span>
            <span class="s1">endog_ix = np.where(endog_factor_map_M.loc[:</span><span class="s3">, </span><span class="s1">name])[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s0"># But fall back to quarterly if necessary</span>
            <span class="s3">if </span><span class="s1">len(endog_ix) == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">endog_ix = np.where(self.endog_factor_map.loc[:</span><span class="s3">, </span><span class="s1">name])[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">factor_endog = endog[:</span><span class="s3">, </span><span class="s1">endog_ix]</span>

            <span class="s1">res_pca = PCA(factor_endog</span><span class="s3">, </span><span class="s1">ncomp=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">'eig'</span><span class="s3">, </span><span class="s1">normalize=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">factors.append(res_pca.factors)</span>
            <span class="s1">endog[:</span><span class="s3">, </span><span class="s1">endog_ix] -= res_pca.projection</span>
        <span class="s1">factors = np.concatenate(factors</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s0"># (2) Estimate coefficients for each endog, one at a time (OLS for</span>
        <span class="s0"># monthly variables, restricted OLS for quarterly). Also, compute</span>
        <span class="s0"># residuals.</span>
        <span class="s1">loadings = []</span>
        <span class="s1">resid = []</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M):</span>
            <span class="s1">factor_ix = self._s.endog_factor_iloc[i]</span>
            <span class="s1">factor_exog = factors[:</span><span class="s3">, </span><span class="s1">factor_ix]</span>
            <span class="s1">mod_ols = OLS(self.endog[:</span><span class="s3">, </span><span class="s1">i]</span><span class="s3">, </span><span class="s1">exog=factor_exog</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">'drop'</span><span class="s1">)</span>
            <span class="s1">res_ols = mod_ols.fit()</span>
            <span class="s1">loadings += res_ols.params.tolist()</span>
            <span class="s1">resid.append(res_ols.resid)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog):</span>
            <span class="s1">factor_ix = self._s.endog_factor_iloc[i]</span>
            <span class="s1">factor_exog = lagmat(factors[:</span><span class="s3">, </span><span class="s1">factor_ix]</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s1">original=</span><span class="s5">'in'</span><span class="s1">)</span>
            <span class="s1">mod_glm = GLM(self.endog[:</span><span class="s3">, </span><span class="s1">i]</span><span class="s3">, </span><span class="s1">factor_exog</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">'drop'</span><span class="s1">)</span>
            <span class="s1">res_glm = mod_glm.fit_constrained(self.loading_constraints(i))</span>
            <span class="s1">loadings += res_glm.params[:len(factor_ix)].tolist()</span>
            <span class="s1">resid.append(res_glm.resid_response)</span>
        <span class="s1">params[self._p[</span><span class="s5">'loadings'</span><span class="s1">]] = loadings</span>

        <span class="s0"># (3) For each factor block, use an AR or VAR model to get coefficients</span>
        <span class="s0"># and covariance estimate</span>
        <span class="s0"># Factor transitions</span>
        <span class="s1">stationary = </span><span class="s3">True</span>

        <span class="s1">factor_ar = []</span>
        <span class="s1">factor_cov = []</span>
        <span class="s1">i = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
            <span class="s1">factors_endog = factors[:</span><span class="s3">, </span><span class="s1">i:i + block.k_factors]</span>
            <span class="s1">i += block.k_factors</span>

            <span class="s3">if </span><span class="s1">block.factor_order == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s3">continue</span>

            <span class="s3">if </span><span class="s1">block.k_factors == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">mod_factors = SARIMAX(factors_endog</span><span class="s3">,</span>
                                      <span class="s1">order=(block.factor_order</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">))</span>
                <span class="s1">sp = mod_factors.start_params</span>
                <span class="s1">block_factor_ar = sp[:-</span><span class="s4">1</span><span class="s1">]</span>
                <span class="s1">block_factor_cov = sp[-</span><span class="s4">1</span><span class="s1">:]</span>

                <span class="s1">coefficient_matrices = mod_factors.start_params[:-</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s3">elif </span><span class="s1">block.k_factors &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">mod_factors = VAR(factors_endog)</span>
                <span class="s1">res_factors = mod_factors.fit(</span>
                    <span class="s1">maxlags=block.factor_order</span><span class="s3">, </span><span class="s1">ic=</span><span class="s3">None, </span><span class="s1">trend=</span><span class="s5">'n'</span><span class="s1">)</span>

                <span class="s1">block_factor_ar = res_factors.params.T.ravel()</span>
                <span class="s1">L = np.linalg.cholesky(res_factors.sigma_u)</span>
                <span class="s1">block_factor_cov = L[np.tril_indices_from(L)]</span>

                <span class="s1">coefficient_matrices = np.transpose(</span>
                    <span class="s1">np.reshape(block_factor_ar</span><span class="s3">,</span>
                               <span class="s1">(block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors</span><span class="s3">,</span>
                                <span class="s1">block.factor_order))</span><span class="s3">, </span><span class="s1">(</span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>

            <span class="s0"># Test for stationarity</span>
            <span class="s1">stationary = is_invertible([</span><span class="s4">1</span><span class="s1">] + list(-coefficient_matrices))</span>

            <span class="s0"># Check for stationarity</span>
            <span class="s3">if not </span><span class="s1">stationary:</span>
                <span class="s1">warn(</span><span class="s5">'Non-stationary starting factor autoregressive'</span>
                     <span class="s5">' parameters found for factor block'</span>
                     <span class="s5">f' </span><span class="s3">{</span><span class="s1">block.factor_names</span><span class="s3">}</span><span class="s5">. Using zeros as starting'</span>
                     <span class="s5">' parameters.'</span><span class="s1">)</span>
                <span class="s1">block_factor_ar[:] = </span><span class="s4">0</span>
                <span class="s1">cov_factor = np.diag(factors_endog.std(axis=</span><span class="s4">0</span><span class="s1">))</span>
                <span class="s1">block_factor_cov = (</span>
                    <span class="s1">cov_factor[np.tril_indices(block.k_factors)])</span>
            <span class="s1">factor_ar += block_factor_ar.tolist()</span>
            <span class="s1">factor_cov += block_factor_cov.tolist()</span>
        <span class="s1">params[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]] = factor_ar</span>
        <span class="s1">params[self._p[</span><span class="s5">'factor_cov'</span><span class="s1">]] = factor_cov</span>

        <span class="s0"># (4) Use residuals from step (2) to estimate the idiosyncratic</span>
        <span class="s0"># component</span>
        <span class="s0"># Idiosyncratic component</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">idio_ar1 = []</span>
            <span class="s1">idio_var = []</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M):</span>
                <span class="s1">mod_idio = SARIMAX(resid[i]</span><span class="s3">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">trend=</span><span class="s5">'c'</span><span class="s1">)</span>
                <span class="s1">sp = mod_idio.start_params</span>
                <span class="s1">idio_ar1.append(np.clip(sp[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.99</span><span class="s3">, </span><span class="s4">0.99</span><span class="s1">))</span>
                <span class="s1">idio_var.append(np.clip(sp[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">np.inf))</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog):</span>
                <span class="s1">y = self.endog[:</span><span class="s3">, </span><span class="s1">i].copy()</span>
                <span class="s1">y[~np.isnan(y)] = resid[i]</span>
                <span class="s1">mod_idio = QuarterlyAR1(y)</span>
                <span class="s1">res_idio = mod_idio.fit(maxiter=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">return_params=</span><span class="s3">True,</span>
                                        <span class="s1">disp=</span><span class="s3">False</span><span class="s1">)</span>
                <span class="s1">res_idio = mod_idio.fit_em(res_idio</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">5</span><span class="s3">,</span>
                                           <span class="s1">return_params=</span><span class="s3">True</span><span class="s1">)</span>
                <span class="s1">idio_ar1.append(np.clip(res_idio[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.99</span><span class="s3">, </span><span class="s4">0.99</span><span class="s1">))</span>
                <span class="s1">idio_var.append(np.clip(res_idio[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">np.inf))</span>
            <span class="s1">params[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]] = idio_ar1</span>
            <span class="s1">params[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]] = idio_var</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">idio_var = [np.var(resid[i]) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M)]</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog):</span>
                <span class="s1">y = self.endog[:</span><span class="s3">, </span><span class="s1">i].copy()</span>
                <span class="s1">y[~np.isnan(y)] = resid[i]</span>
                <span class="s1">mod_idio = QuarterlyAR1(y)</span>
                <span class="s1">res_idio = mod_idio.fit(return_params=</span><span class="s3">True, </span><span class="s1">disp=</span><span class="s3">False</span><span class="s1">)</span>
                <span class="s1">idio_var.append(np.clip(res_idio[</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">np.inf))</span>
            <span class="s1">params[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]] = idio_var</span>

        <span class="s3">return </span><span class="s1">params</span>

    <span class="s3">def </span><span class="s1">transform_params(self</span><span class="s3">, </span><span class="s1">unconstrained):</span>
        <span class="s2">&quot;&quot;&quot; 
        Transform parameters from optimizer space to model space. 
 
        Transform unconstrained parameters used by the optimizer to constrained 
        parameters used in likelihood evaluation. 
 
        Parameters 
        ---------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer, to be 
            transformed. 
 
        Returns 
        ------- 
        constrained : array_like 
            Array of constrained parameters which may be used in likelihood 
            evaluation. 
        &quot;&quot;&quot;</span>
        <span class="s1">constrained = unconstrained.copy()</span>

        <span class="s0"># Stationary factor VAR</span>
        <span class="s1">unconstrained_factor_ar = unconstrained[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]]</span>
        <span class="s1">constrained_factor_ar = []</span>
        <span class="s1">i = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
            <span class="s1">length = block.k_factors**</span><span class="s4">2 </span><span class="s1">* block.factor_order</span>
            <span class="s1">tmp_coeff = np.reshape(</span>
                <span class="s1">unconstrained_factor_ar[i:i + length]</span><span class="s3">,</span>
                <span class="s1">(block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors * block.factor_order))</span>
            <span class="s1">tmp_cov = np.eye(block.k_factors)</span>
            <span class="s1">tmp_coeff</span><span class="s3">, </span><span class="s1">_ = constrain_stationary_multivariate(tmp_coeff</span><span class="s3">,</span>
                                                             <span class="s1">tmp_cov)</span>
            <span class="s1">constrained_factor_ar += tmp_coeff.ravel().tolist()</span>
            <span class="s1">i += length</span>
        <span class="s1">constrained[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]] = constrained_factor_ar</span>

        <span class="s0"># Stationary idiosyncratic AR(1)</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">idio_ar1 = unconstrained[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]]</span>
            <span class="s1">constrained[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]] = [</span>
                <span class="s1">constrain_stationary_univariate(idio_ar1[i:i + </span><span class="s4">1</span><span class="s1">])[</span><span class="s4">0</span><span class="s1">]</span>
                <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog)]</span>

        <span class="s0"># Positive idiosyncratic variances</span>
        <span class="s1">constrained[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]] = (</span>
            <span class="s1">constrained[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]]**</span><span class="s4">2</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">constrained</span>

    <span class="s3">def </span><span class="s1">untransform_params(self</span><span class="s3">, </span><span class="s1">constrained):</span>
        <span class="s2">&quot;&quot;&quot; 
        Transform parameters from model space to optimizer space. 
 
        Transform constrained parameters used in likelihood evaluation 
        to unconstrained parameters used by the optimizer. 
 
        Parameters 
        ---------- 
        constrained : array_like 
            Array of constrained parameters used in likelihood evaluation, to 
            be transformed. 
 
        Returns 
        ------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer. 
        &quot;&quot;&quot;</span>
        <span class="s1">unconstrained = constrained.copy()</span>

        <span class="s0"># Stationary factor VAR</span>
        <span class="s1">constrained_factor_ar = constrained[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]]</span>
        <span class="s1">unconstrained_factor_ar = []</span>
        <span class="s1">i = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">self._s.factor_blocks:</span>
            <span class="s1">length = block.k_factors**</span><span class="s4">2 </span><span class="s1">* block.factor_order</span>
            <span class="s1">tmp_coeff = np.reshape(</span>
                <span class="s1">constrained_factor_ar[i:i + length]</span><span class="s3">,</span>
                <span class="s1">(block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors * block.factor_order))</span>
            <span class="s1">tmp_cov = np.eye(block.k_factors)</span>
            <span class="s1">tmp_coeff</span><span class="s3">, </span><span class="s1">_ = unconstrain_stationary_multivariate(tmp_coeff</span><span class="s3">,</span>
                                                               <span class="s1">tmp_cov)</span>
            <span class="s1">unconstrained_factor_ar += tmp_coeff.ravel().tolist()</span>
            <span class="s1">i += length</span>
        <span class="s1">unconstrained[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]] = unconstrained_factor_ar</span>

        <span class="s0"># Stationary idiosyncratic AR(1)</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">idio_ar1 = constrained[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]]</span>
            <span class="s1">unconstrained[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]] = [</span>
                <span class="s1">unconstrain_stationary_univariate(idio_ar1[i:i + </span><span class="s4">1</span><span class="s1">])[</span><span class="s4">0</span><span class="s1">]</span>
                <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog)]</span>

        <span class="s0"># Positive idiosyncratic variances</span>
        <span class="s1">unconstrained[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]] = (</span>
            <span class="s1">unconstrained[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]]**</span><span class="s4">0.5</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">unconstrained</span>

    <span class="s3">def </span><span class="s1">update(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Update the parameters of the model. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of new parameters. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. If set to False, 
            `transform_params` is called. Default is True. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">params = super().update(params</span><span class="s3">, </span><span class="s1">**kwargs)</span>

        <span class="s0"># Local copies</span>
        <span class="s1">o = self._o</span>
        <span class="s1">s = self._s</span>
        <span class="s1">p = self._p</span>

        <span class="s0"># Loadings</span>
        <span class="s1">loadings = params[p[</span><span class="s5">'loadings'</span><span class="s1">]]</span>
        <span class="s1">start = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M):</span>
            <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
            <span class="s1">k_factors = len(iloc)</span>
            <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1'</span><span class="s1">][iloc]</span>
            <span class="s1">self[</span><span class="s5">'design'</span><span class="s3">, </span><span class="s1">i</span><span class="s3">, </span><span class="s1">factor_ix] = loadings[start:start + k_factors]</span>
            <span class="s1">start += k_factors</span>
        <span class="s1">multipliers = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog):</span>
            <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
            <span class="s1">k_factors = len(iloc)</span>
            <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1_5_ix'</span><span class="s1">][:</span><span class="s3">, </span><span class="s1">iloc]</span>
            <span class="s1">self[</span><span class="s5">'design'</span><span class="s3">, </span><span class="s1">i</span><span class="s3">, </span><span class="s1">factor_ix.ravel()] = np.ravel(</span>
                <span class="s1">loadings[start:start + k_factors] * multipliers)</span>
            <span class="s1">start += k_factors</span>

        <span class="s0"># Factor VAR</span>
        <span class="s1">factor_ar = params[p[</span><span class="s5">'factor_ar'</span><span class="s1">]]</span>
        <span class="s1">start = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s1">k_params = block.k_factors**</span><span class="s4">2 </span><span class="s1">* block.factor_order</span>
            <span class="s1">A = np.reshape(</span>
                <span class="s1">factor_ar[start:start + k_params]</span><span class="s3">,</span>
                <span class="s1">(block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors * block.factor_order))</span>
            <span class="s1">start += k_params</span>
            <span class="s1">self[</span><span class="s5">'transition'</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors_L1'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors_ar'</span><span class="s1">]] = A</span>

        <span class="s0"># Factor covariance</span>
        <span class="s1">factor_cov = params[p[</span><span class="s5">'factor_cov'</span><span class="s1">]]</span>
        <span class="s1">start = </span><span class="s4">0</span>
        <span class="s1">ix1 = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s1">k_params = block.k_factors * (block.k_factors + </span><span class="s4">1</span><span class="s1">) // </span><span class="s4">2</span>
            <span class="s1">L = np.zeros((block.k_factors</span><span class="s3">, </span><span class="s1">block.k_factors)</span><span class="s3">,</span>
                         <span class="s1">dtype=params.dtype)</span>
            <span class="s1">L[np.tril_indices_from(L)] = factor_cov[start:start + k_params]</span>
            <span class="s1">start += k_params</span>
            <span class="s1">Q = L @ L.T</span>
            <span class="s1">ix2 = ix1 + block.k_factors</span>
            <span class="s1">self[</span><span class="s5">'state_cov'</span><span class="s3">, </span><span class="s1">ix1:ix2</span><span class="s3">, </span><span class="s1">ix1:ix2] = Q</span>
            <span class="s1">ix1 = ix2</span>

        <span class="s0"># Error AR(1)</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">alpha = np.diag(params[p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]])</span>
            <span class="s1">self[</span><span class="s5">'transition'</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_L1'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_L1'</span><span class="s1">]] = alpha</span>

        <span class="s0"># Error variances</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">self[</span><span class="s5">'state_cov'</span><span class="s3">, </span><span class="s1">self.k_factors:</span><span class="s3">, </span><span class="s1">self.k_factors:] = (</span>
                <span class="s1">np.diag(params[p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]]))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">idio_var = params[p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]]</span>
            <span class="s1">self[</span><span class="s5">'obs_cov'</span><span class="s3">, </span><span class="s1">o[</span><span class="s5">'M'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">o[</span><span class="s5">'M'</span><span class="s1">]] = np.diag(idio_var[o[</span><span class="s5">'M'</span><span class="s1">]])</span>
            <span class="s1">self[</span><span class="s5">'state_cov'</span><span class="s3">, </span><span class="s1">self.k_factors:</span><span class="s3">, </span><span class="s1">self.k_factors:] = (</span>
                <span class="s1">np.diag(idio_var[o[</span><span class="s5">'Q'</span><span class="s1">]]))</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">loglike_constant(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Constant term in the joint log-likelihood function. 
 
        Useful in facilitating comparisons to other packages that exclude the 
        constant from the log-likelihood computation. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">-</span><span class="s4">0.5 </span><span class="s1">* (</span><span class="s4">1 </span><span class="s1">- np.isnan(self.endog)).sum() * np.log(</span><span class="s4">2 </span><span class="s1">* np.pi)</span>

    <span class="s3">def </span><span class="s1">loading_constraints(self</span><span class="s3">, </span><span class="s1">i):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Matrix formulation of quarterly variables' factor loading constraints. 
 
        Parameters 
        ---------- 
        i : int 
            Index of the `endog` variable to compute constraints for. 
 
        Returns 
        ------- 
        R : array (k_constraints, k_factors * 5) 
        q : array (k_constraints,) 
 
        Notes 
        ----- 
        If the factors were known, then the factor loadings for the ith 
        quarterly variable would be computed by a linear regression of the form 
 
        y_i = A_i' f + B_i' L1.f + C_i' L2.f + D_i' L3.f + E_i' L4.f 
 
        where: 
 
        - f is (k_i x 1) and collects all of the factors that load on y_i 
        - L{j}.f is (k_i x 1) and collects the jth lag of each factor 
        - A_i, ..., E_i are (k_i x 1) and collect factor loadings 
 
        As the observed variable is quarterly while the factors are monthly, we 
        want to restrict the estimated regression coefficients to be: 
 
        y_i = A_i f + 2 A_i L1.f + 3 A_i L2.f + 2 A_i L3.f + A_i L4.f 
 
        Stack the unconstrained coefficients: \Lambda_i = [A_i' B_i' ... E_i']' 
 
        Then the constraints can be written as follows, for l = 1, ..., k_i 
 
        - 2 A_{i,l} - B_{i,l} = 0 
        - 3 A_{i,l} - C_{i,l} = 0 
        - 2 A_{i,l} - D_{i,l} = 0 
        - A_{i,l} - E_{i,l} = 0 
 
        So that k_constraints = 4 * k_i. In matrix form the constraints are: 
 
        .. math:: 
 
            R \Lambda_i = q 
 
        where :math:`\Lambda_i` is shaped `(k_i * 5,)`, :math:`R` is shaped 
        `(k_constraints, k_i * 5)`, and :math:`q` is shaped `(k_constraints,)`. 
 
 
        For example, for the case that k_i = 2, we can write: 
 
        |  2 0   -1  0    0  0    0  0    0  0  |   | A_{i,1} |     | 0 | 
        |  0 2    0 -1    0  0    0  0    0  0  |   | A_{i,2} |     | 0 | 
        |  3 0    0  0   -1  0    0  0    0  0  |   | B_{i,1} |     | 0 | 
        |  0 3    0  0    0 -1    0  0    0  0  |   | B_{i,2} |     | 0 | 
        |  2 0    0  0    0  0   -1  0    0  0  |   | C_{i,1} |  =  | 0 | 
        |  0 2    0  0    0  0    0 -1    0  0  |   | C_{i,2} |     | 0 | 
        |  1 0    0  0    0  0    0  0   -1  0  |   | D_{i,1} |     | 0 | 
        |  0 1    0  0    0  0    0  0    0 -1  |   | D_{i,2} |     | 0 | 
                                                    | E_{i,1} |     | 0 | 
                                                    | E_{i,2} |     | 0 | 
 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">i &lt; self.k_endog_M:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'No constraints for monthly variables.'</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">i </span><span class="s3">not in </span><span class="s1">self._loading_constraints:</span>
            <span class="s1">k_factors = self.endog_factor_map.iloc[i].sum()</span>

            <span class="s1">R = np.zeros((k_factors * </span><span class="s4">4</span><span class="s3">, </span><span class="s1">k_factors * </span><span class="s4">5</span><span class="s1">))</span>
            <span class="s1">q = np.zeros(R.shape[</span><span class="s4">0</span><span class="s1">])</span>

            <span class="s0"># Let R = [R_1 R_2]</span>
            <span class="s0"># Then R_1 is multiples of the identity matrix</span>
            <span class="s1">multipliers = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])</span>
            <span class="s1">R[:</span><span class="s3">, </span><span class="s1">:k_factors] = np.reshape(</span>
                <span class="s1">(multipliers[</span><span class="s4">1</span><span class="s1">:] * np.eye(k_factors)[...</span><span class="s3">, None</span><span class="s1">]).T</span><span class="s3">,</span>
                <span class="s1">(k_factors * </span><span class="s4">4</span><span class="s3">, </span><span class="s1">k_factors))</span>

            <span class="s0"># And R_2 is the identity</span>
            <span class="s1">R[:</span><span class="s3">, </span><span class="s1">k_factors:] = np.diag([-</span><span class="s4">1</span><span class="s1">] * (k_factors * </span><span class="s4">4</span><span class="s1">))</span>

            <span class="s1">self._loading_constraints[i] = (R</span><span class="s3">, </span><span class="s1">q)</span>
        <span class="s3">return </span><span class="s1">self._loading_constraints[i]</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">start_params=</span><span class="s3">None, </span><span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">includes_fixed=</span><span class="s3">False,</span>
            <span class="s1">cov_type=</span><span class="s5">'none'</span><span class="s3">, </span><span class="s1">cov_kwds=</span><span class="s3">None, </span><span class="s1">method=</span><span class="s5">'em'</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">500</span><span class="s3">,</span>
            <span class="s1">tolerance=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">em_initialization=</span><span class="s3">True, </span><span class="s1">mstep_method=</span><span class="s3">None,</span>
            <span class="s1">full_output=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">disp=</span><span class="s3">False, </span><span class="s1">callback=</span><span class="s3">None, </span><span class="s1">return_params=</span><span class="s3">False,</span>
            <span class="s1">optim_score=</span><span class="s3">None, </span><span class="s1">optim_complex_step=</span><span class="s3">None, </span><span class="s1">optim_hessian=</span><span class="s3">None,</span>
            <span class="s1">flags=</span><span class="s3">None, </span><span class="s1">low_memory=</span><span class="s3">False, </span><span class="s1">llf_decrease_action=</span><span class="s5">'revert'</span><span class="s3">,</span>
            <span class="s1">llf_decrease_tolerance=</span><span class="s4">1e-4</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Fits the model by maximum likelihood via Kalman filter. 
 
        Parameters 
        ---------- 
        start_params : array_like, optional 
            Initial guess of the solution for the loglikelihood maximization. 
            If None, the default is given by Model.start_params. 
        transformed : bool, optional 
            Whether or not `start_params` is already transformed. Default is 
            True. 
        includes_fixed : bool, optional 
            If parameters were previously fixed with the `fix_params` method, 
            this argument describes whether or not `start_params` also includes 
            the fixed parameters, in addition to the free parameters. Default 
            is False. 
        cov_type : str, optional 
            The `cov_type` keyword governs the method for calculating the 
            covariance matrix of parameter estimates. Can be one of: 
 
            - 'opg' for the outer product of gradient estimator 
            - 'oim' for the observed information matrix estimator, calculated 
              using the method of Harvey (1989) 
            - 'approx' for the observed information matrix estimator, 
              calculated using a numerical approximation of the Hessian matrix. 
            - 'robust' for an approximate (quasi-maximum likelihood) covariance 
              matrix that may be valid even in the presence of some 
              misspecifications. Intermediate calculations use the 'oim' 
              method. 
            - 'robust_approx' is the same as 'robust' except that the 
              intermediate calculations use the 'approx' method. 
            - 'none' for no covariance matrix calculation. 
 
            Default is 'none', since computing this matrix can be very slow 
            when there are a large number of parameters. 
        cov_kwds : dict or None, optional 
            A dictionary of arguments affecting covariance matrix computation. 
 
            **opg, oim, approx, robust, robust_approx** 
 
            - 'approx_complex_step' : bool, optional - If True, numerical 
              approximations are computed using complex-step methods. If False, 
              numerical approximations are computed using finite difference 
              methods. Default is True. 
            - 'approx_centered' : bool, optional - If True, numerical 
              approximations computed using finite difference methods use a 
              centered approximation. Default is False. 
        method : str, optional 
            The `method` determines which solver from `scipy.optimize` 
            is used, and it can be chosen from among the following strings: 
 
            - 'em' for the EM algorithm 
            - 'newton' for Newton-Raphson 
            - 'nm' for Nelder-Mead 
            - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS) 
            - 'lbfgs' for limited-memory BFGS with optional box constraints 
            - 'powell' for modified Powell's method 
            - 'cg' for conjugate gradient 
            - 'ncg' for Newton-conjugate gradient 
            - 'basinhopping' for global basin-hopping solver 
 
            The explicit arguments in `fit` are passed to the solver, 
            with the exception of the basin-hopping solver. Each 
            solver has several optional arguments that are not the same across 
            solvers. See the notes section below (or scipy.optimize) for the 
            available arguments and for the list of explicit arguments that the 
            basin-hopping solver supports. 
        maxiter : int, optional 
            The maximum number of iterations to perform. 
        tolerance : float, optional 
            Tolerance to use for convergence checking when using the EM 
            algorithm. To set the tolerance for other methods, pass 
            the optimizer-specific keyword argument(s). 
        full_output : bool, optional 
            Set to True to have all available output in the Results object's 
            mle_retvals attribute. The output is dependent on the solver. 
            See LikelihoodModelResults notes section for more information. 
        disp : bool, optional 
            Set to True to print convergence messages. 
        callback : callable callback(xk), optional 
            Called after each iteration, as callback(xk), where xk is the 
            current parameter vector. 
        return_params : bool, optional 
            Whether or not to return only the array of maximizing parameters. 
            Default is False. 
        optim_score : {'harvey', 'approx'} or None, optional 
            The method by which the score vector is calculated. 'harvey' uses 
            the method from Harvey (1989), 'approx' uses either finite 
            difference or complex step differentiation depending upon the 
            value of `optim_complex_step`, and None uses the built-in gradient 
            approximation of the optimizer. Default is None. This keyword is 
            only relevant if the optimization method uses the score. 
        optim_complex_step : bool, optional 
            Whether or not to use complex step differentiation when 
            approximating the score; if False, finite difference approximation 
            is used. Default is True. This keyword is only relevant if 
            `optim_score` is set to 'harvey' or 'approx'. 
        optim_hessian : {'opg','oim','approx'}, optional 
            The method by which the Hessian is numerically approximated. 'opg' 
            uses outer product of gradients, 'oim' uses the information 
            matrix formula from Harvey (1989), and 'approx' uses numerical 
            approximation. This keyword is only relevant if the 
            optimization method uses the Hessian matrix. 
        low_memory : bool, optional 
            If set to True, techniques are applied to substantially reduce 
            memory usage. If used, some features of the results object will 
            not be available (including smoothed results and in-sample 
            prediction), although out-of-sample forecasting is possible. 
            Note that this option is not available when using the EM algorithm 
            (which is the default for this model). Default is False. 
        llf_decrease_action : {'ignore', 'warn', 'revert'}, optional 
            Action to take if the log-likelihood decreases in an EM iteration. 
            'ignore' continues the iterations, 'warn' issues a warning but 
            continues the iterations, while 'revert' ends the iterations and 
            returns the result from the last good iteration. Default is 'warn'. 
        llf_decrease_tolerance : float, optional 
            Minimum size of the log-likelihood decrease required to trigger a 
            warning or to end the EM iterations. Setting this value slightly 
            larger than zero allows small decreases in the log-likelihood that 
            may be caused by numerical issues. If set to zero, then any 
            decrease will trigger the `llf_decrease_action`. Default is 1e-4. 
        **kwargs 
            Additional keyword arguments to pass to the optimizer. 
 
        Returns 
        ------- 
        MLEResults 
 
        See Also 
        -------- 
        statsmodels.base.model.LikelihoodModel.fit 
        statsmodels.tsa.statespace.mlemodel.MLEResults 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">method == </span><span class="s5">'em'</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">self.fit_em(</span>
                <span class="s1">start_params=start_params</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">,</span>
                <span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span><span class="s3">, </span><span class="s1">maxiter=maxiter</span><span class="s3">,</span>
                <span class="s1">tolerance=tolerance</span><span class="s3">, </span><span class="s1">em_initialization=em_initialization</span><span class="s3">,</span>
                <span class="s1">mstep_method=mstep_method</span><span class="s3">, </span><span class="s1">full_output=full_output</span><span class="s3">, </span><span class="s1">disp=disp</span><span class="s3">,</span>
                <span class="s1">return_params=return_params</span><span class="s3">, </span><span class="s1">low_memory=low_memory</span><span class="s3">,</span>
                <span class="s1">llf_decrease_action=llf_decrease_action</span><span class="s3">,</span>
                <span class="s1">llf_decrease_tolerance=llf_decrease_tolerance</span><span class="s3">, </span><span class="s1">**kwargs)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">super().fit(</span>
                <span class="s1">start_params=start_params</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">,</span>
                <span class="s1">includes_fixed=includes_fixed</span><span class="s3">, </span><span class="s1">cov_type=cov_type</span><span class="s3">,</span>
                <span class="s1">cov_kwds=cov_kwds</span><span class="s3">, </span><span class="s1">method=method</span><span class="s3">, </span><span class="s1">maxiter=maxiter</span><span class="s3">,</span>
                <span class="s1">full_output=full_output</span><span class="s3">, </span><span class="s1">disp=disp</span><span class="s3">,</span>
                <span class="s1">callback=callback</span><span class="s3">, </span><span class="s1">return_params=return_params</span><span class="s3">,</span>
                <span class="s1">optim_score=optim_score</span><span class="s3">,</span>
                <span class="s1">optim_complex_step=optim_complex_step</span><span class="s3">,</span>
                <span class="s1">optim_hessian=optim_hessian</span><span class="s3">, </span><span class="s1">flags=flags</span><span class="s3">,</span>
                <span class="s1">low_memory=low_memory</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s3">def </span><span class="s1">fit_em(self</span><span class="s3">, </span><span class="s1">start_params=</span><span class="s3">None, </span><span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">cov_type=</span><span class="s5">'none'</span><span class="s3">,</span>
               <span class="s1">cov_kwds=</span><span class="s3">None, </span><span class="s1">maxiter=</span><span class="s4">500</span><span class="s3">, </span><span class="s1">tolerance=</span><span class="s4">1e-6</span><span class="s3">, </span><span class="s1">disp=</span><span class="s3">False,</span>
               <span class="s1">em_initialization=</span><span class="s3">True, </span><span class="s1">mstep_method=</span><span class="s3">None, </span><span class="s1">full_output=</span><span class="s3">True,</span>
               <span class="s1">return_params=</span><span class="s3">False, </span><span class="s1">low_memory=</span><span class="s3">False,</span>
               <span class="s1">llf_decrease_action=</span><span class="s5">'revert'</span><span class="s3">, </span><span class="s1">llf_decrease_tolerance=</span><span class="s4">1e-4</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Fits the model by maximum likelihood via the EM algorithm. 
 
        Parameters 
        ---------- 
        start_params : array_like, optional 
            Initial guess of the solution for the loglikelihood maximization. 
            The default is to use `DynamicFactorMQ.start_params`. 
        transformed : bool, optional 
            Whether or not `start_params` is already transformed. Default is 
            True. 
        cov_type : str, optional 
            The `cov_type` keyword governs the method for calculating the 
            covariance matrix of parameter estimates. Can be one of: 
 
            - 'opg' for the outer product of gradient estimator 
            - 'oim' for the observed information matrix estimator, calculated 
              using the method of Harvey (1989) 
            - 'approx' for the observed information matrix estimator, 
              calculated using a numerical approximation of the Hessian matrix. 
            - 'robust' for an approximate (quasi-maximum likelihood) covariance 
              matrix that may be valid even in the presence of some 
              misspecifications. Intermediate calculations use the 'oim' 
              method. 
            - 'robust_approx' is the same as 'robust' except that the 
              intermediate calculations use the 'approx' method. 
            - 'none' for no covariance matrix calculation. 
 
            Default is 'none', since computing this matrix can be very slow 
            when there are a large number of parameters. 
        cov_kwds : dict or None, optional 
            A dictionary of arguments affecting covariance matrix computation. 
 
            **opg, oim, approx, robust, robust_approx** 
 
            - 'approx_complex_step' : bool, optional - If True, numerical 
              approximations are computed using complex-step methods. If False, 
              numerical approximations are computed using finite difference 
              methods. Default is True. 
            - 'approx_centered' : bool, optional - If True, numerical 
              approximations computed using finite difference methods use a 
              centered approximation. Default is False. 
        maxiter : int, optional 
            The maximum number of EM iterations to perform. 
        tolerance : float, optional 
            Parameter governing convergence of the EM algorithm. The 
            `tolerance` is the minimum relative increase in the likelihood 
            for which convergence will be declared. A smaller value for the 
            `tolerance` will typically yield more precise parameter estimates, 
            but will typically require more EM iterations. Default is 1e-6. 
        disp : int or bool, optional 
            Controls printing of EM iteration progress. If an integer, progress 
            is printed at every `disp` iterations. A value of True is 
            interpreted as the value of 1. Default is False (nothing will be 
            printed). 
        em_initialization : bool, optional 
            Whether or not to also update the Kalman filter initialization 
            using the EM algorithm. Default is True. 
        mstep_method : {None, 'missing', 'nonmissing'}, optional 
            The EM algorithm maximization step. If there are no NaN values 
            in the dataset, this can be set to &quot;nonmissing&quot; (which is slightly 
            faster) or &quot;missing&quot;, otherwise it must be &quot;missing&quot;. Default is 
            &quot;nonmissing&quot; if there are no NaN values or &quot;missing&quot; if there are. 
        full_output : bool, optional 
            Set to True to have all available output from EM iterations in 
            the Results object's mle_retvals attribute. 
        return_params : bool, optional 
            Whether or not to return only the array of maximizing parameters. 
            Default is False. 
        low_memory : bool, optional 
            This option cannot be used with the EM algorithm and will raise an 
            error if set to True. Default is False. 
        llf_decrease_action : {'ignore', 'warn', 'revert'}, optional 
            Action to take if the log-likelihood decreases in an EM iteration. 
            'ignore' continues the iterations, 'warn' issues a warning but 
            continues the iterations, while 'revert' ends the iterations and 
            returns the result from the last good iteration. Default is 'warn'. 
        llf_decrease_tolerance : float, optional 
            Minimum size of the log-likelihood decrease required to trigger a 
            warning or to end the EM iterations. Setting this value slightly 
            larger than zero allows small decreases in the log-likelihood that 
            may be caused by numerical issues. If set to zero, then any 
            decrease will trigger the `llf_decrease_action`. Default is 1e-4. 
 
        Returns 
        ------- 
        DynamicFactorMQResults 
 
        See Also 
        -------- 
        statsmodels.tsa.statespace.mlemodel.MLEModel.fit 
        statsmodels.tsa.statespace.mlemodel.MLEResults 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self._has_fixed_params:</span>
            <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">'Cannot fit using the EM algorithm while'</span>
                                      <span class="s5">' holding some parameters fixed.'</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">low_memory:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Cannot fit using the EM algorithm when using'</span>
                             <span class="s5">' low_memory option.'</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">start_params </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">start_params = self.start_params</span>
            <span class="s1">transformed = </span><span class="s3">True</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">start_params = np.array(start_params</span><span class="s3">, </span><span class="s1">ndmin=</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s3">if not </span><span class="s1">transformed:</span>
            <span class="s1">start_params = self.transform_params(start_params)</span>

        <span class="s1">llf_decrease_action = string_like(</span>
            <span class="s1">llf_decrease_action</span><span class="s3">, </span><span class="s5">'llf_decrease_action'</span><span class="s3">,</span>
            <span class="s1">options=[</span><span class="s5">'ignore'</span><span class="s3">, </span><span class="s5">'warn'</span><span class="s3">, </span><span class="s5">'revert'</span><span class="s1">])</span>

        <span class="s1">disp = int(disp)</span>

        <span class="s0"># Perform expectation-maximization</span>
        <span class="s1">s = self._s</span>
        <span class="s1">llf = []</span>
        <span class="s1">params = [start_params]</span>
        <span class="s1">init = </span><span class="s3">None</span>
        <span class="s1">inits = [self.ssm.initialization]</span>
        <span class="s1">i = </span><span class="s4">0</span>
        <span class="s1">delta = </span><span class="s4">0</span>
        <span class="s1">terminate = </span><span class="s3">False</span>
        <span class="s0"># init_stationary = None if em_initialization else True</span>
        <span class="s3">while </span><span class="s1">i &lt; maxiter </span><span class="s3">and not </span><span class="s1">terminate </span><span class="s3">and </span><span class="s1">(i &lt; </span><span class="s4">1 </span><span class="s3">or </span><span class="s1">(delta &gt; tolerance)):</span>
            <span class="s1">out = self._em_iteration(params[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">init=init</span><span class="s3">,</span>
                                     <span class="s1">mstep_method=mstep_method)</span>
            <span class="s1">new_llf = out[</span><span class="s4">0</span><span class="s1">].llf_obs.sum()</span>

            <span class="s0"># If we are not using EM initialization, then we need to check for</span>
            <span class="s0"># non-stationary parameters</span>
            <span class="s3">if not </span><span class="s1">em_initialization:</span>
                <span class="s1">self.update(out[</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s1">switch_init = []</span>
                <span class="s1">T = self[</span><span class="s5">'transition'</span><span class="s1">]</span>
                <span class="s1">init = self.ssm.initialization</span>
                <span class="s1">iloc = np.arange(self.k_states)</span>

                <span class="s0"># We may only have global initialization if we have no</span>
                <span class="s0"># quarterly variables and idiosyncratic_ar1=False</span>
                <span class="s3">if </span><span class="s1">self.k_endog_Q == </span><span class="s4">0 </span><span class="s3">and not </span><span class="s1">self.idiosyncratic_ar1:</span>
                    <span class="s1">block = s.factor_blocks[</span><span class="s4">0</span><span class="s1">]</span>
                    <span class="s3">if </span><span class="s1">init.initialization_type == </span><span class="s5">'stationary'</span><span class="s1">:</span>
                        <span class="s1">Tb = T[block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors'</span><span class="s1">]]</span>
                        <span class="s3">if not </span><span class="s1">np.all(np.linalg.eigvals(Tb) &lt; (</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-10</span><span class="s1">)):</span>
                            <span class="s1">init.set(block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s5">'diffuse'</span><span class="s1">)</span>
                            <span class="s1">switch_init.append(</span>
                                <span class="s5">'factor block:'</span>
                                <span class="s5">f' </span><span class="s3">{</span><span class="s1">tuple(block.factor_names)</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s0"># Factor blocks</span>
                    <span class="s3">for </span><span class="s1">block </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
                        <span class="s1">b = tuple(iloc[block[</span><span class="s5">'factors'</span><span class="s1">]])</span>
                        <span class="s1">init_type = init.blocks[b].initialization_type</span>
                        <span class="s3">if </span><span class="s1">init_type == </span><span class="s5">'stationary'</span><span class="s1">:</span>
                            <span class="s1">Tb = T[block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">block[</span><span class="s5">'factors'</span><span class="s1">]]</span>
                            <span class="s3">if not </span><span class="s1">np.all(np.linalg.eigvals(Tb) &lt; (</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-10</span><span class="s1">)):</span>
                                <span class="s1">init.set(block[</span><span class="s5">'factors'</span><span class="s1">]</span><span class="s3">, </span><span class="s5">'diffuse'</span><span class="s1">)</span>
                                <span class="s1">switch_init.append(</span>
                                    <span class="s5">'factor block:'</span>
                                    <span class="s5">f' </span><span class="s3">{</span><span class="s1">tuple(block.factor_names)</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

                <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
                    <span class="s1">endog_names = self._get_endog_names(as_string=</span><span class="s3">True</span><span class="s1">)</span>
                    <span class="s0"># Monthly variables</span>
                    <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(s[</span><span class="s5">'idio_ar_M'</span><span class="s1">].start</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_M'</span><span class="s1">].stop):</span>
                        <span class="s1">init_type = init.blocks[(j</span><span class="s3">,</span><span class="s1">)].initialization_type</span>
                        <span class="s3">if </span><span class="s1">init_type == </span><span class="s5">'stationary'</span><span class="s1">:</span>
                            <span class="s3">if not </span><span class="s1">np.abs(T[j</span><span class="s3">, </span><span class="s1">j]) &lt; (</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-10</span><span class="s1">):</span>
                                <span class="s1">init.set(j</span><span class="s3">, </span><span class="s5">'diffuse'</span><span class="s1">)</span>
                                <span class="s1">name = endog_names[j - s[</span><span class="s5">'idio_ar_M'</span><span class="s1">].start]</span>
                                <span class="s1">switch_init.append(</span>
                                    <span class="s5">'idiosyncratic AR(1) for monthly'</span>
                                    <span class="s5">f' variable: </span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

                    <span class="s0"># Quarterly variables</span>
                    <span class="s3">if </span><span class="s1">self.k_endog_Q &gt; </span><span class="s4">0</span><span class="s1">:</span>
                        <span class="s1">b = tuple(iloc[s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]])</span>
                        <span class="s1">init_type = init.blocks[b].initialization_type</span>
                        <span class="s3">if </span><span class="s1">init_type == </span><span class="s5">'stationary'</span><span class="s1">:</span>
                            <span class="s1">Tb = T[s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]]</span>
                            <span class="s3">if not </span><span class="s1">np.all(np.linalg.eigvals(Tb) &lt; (</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">1e-10</span><span class="s1">)):</span>
                                <span class="s1">init.set(s[</span><span class="s5">'idio_ar_Q'</span><span class="s1">]</span><span class="s3">, </span><span class="s5">'diffuse'</span><span class="s1">)</span>
                                <span class="s1">switch_init.append(</span>
                                    <span class="s5">'idiosyncratic AR(1) for the'</span>
                                    <span class="s5">' block of quarterly variables'</span><span class="s1">)</span>

                <span class="s3">if </span><span class="s1">len(switch_init) &gt; </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">warn(</span><span class="s5">'Non-stationary parameters found at EM iteration'</span>
                         <span class="s5">f' </span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">, which is not compatible with'</span>
                         <span class="s5">' stationary initialization. Initialization was'</span>
                         <span class="s5">' switched to diffuse for the following: '</span>
                         <span class="s5">f' </span><span class="s3">{</span><span class="s1">switch_init</span><span class="s3">}</span><span class="s5">, and fitting was restarted.'</span><span class="s1">)</span>
                    <span class="s1">results = self.fit_em(</span>
                        <span class="s1">start_params=params[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">,</span>
                        <span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span><span class="s3">,</span>
                        <span class="s1">maxiter=maxiter</span><span class="s3">, </span><span class="s1">tolerance=tolerance</span><span class="s3">,</span>
                        <span class="s1">em_initialization=em_initialization</span><span class="s3">,</span>
                        <span class="s1">mstep_method=mstep_method</span><span class="s3">, </span><span class="s1">full_output=full_output</span><span class="s3">,</span>
                        <span class="s1">disp=disp</span><span class="s3">, </span><span class="s1">return_params=return_params</span><span class="s3">,</span>
                        <span class="s1">low_memory=low_memory</span><span class="s3">,</span>
                        <span class="s1">llf_decrease_action=llf_decrease_action</span><span class="s3">,</span>
                        <span class="s1">llf_decrease_tolerance=llf_decrease_tolerance)</span>
                    <span class="s1">self.ssm.initialize(self._default_initialization())</span>
                    <span class="s3">return </span><span class="s1">results</span>

            <span class="s0"># Check for decrease in the log-likelihood</span>
            <span class="s0"># Note: allow a little numerical error before declaring a decrease</span>
            <span class="s1">llf_decrease = (</span>
                <span class="s1">i &gt; </span><span class="s4">0 </span><span class="s3">and </span><span class="s1">(new_llf - llf[-</span><span class="s4">1</span><span class="s1">]) &lt; -llf_decrease_tolerance)</span>

            <span class="s3">if </span><span class="s1">llf_decrease_action == </span><span class="s5">'revert' </span><span class="s3">and </span><span class="s1">llf_decrease:</span>
                <span class="s1">warn(</span><span class="s5">f'Log-likelihood decreased at EM iteration </span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">.'</span>
                     <span class="s5">f' Reverting to the results from EM iteration </span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">'</span>
                     <span class="s5">' (prior to the decrease) and returning the solution.'</span><span class="s1">)</span>
                <span class="s0"># Terminated iteration</span>
                <span class="s1">i -= </span><span class="s4">1</span>
                <span class="s1">terminate = </span><span class="s3">True</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">if </span><span class="s1">llf_decrease_action == </span><span class="s5">'warn' </span><span class="s3">and </span><span class="s1">llf_decrease:</span>
                    <span class="s1">warn(</span><span class="s5">f'Log-likelihood decreased at EM iteration </span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">,'</span>
                         <span class="s5">' which can indicate numerical issues.'</span><span class="s1">)</span>
                <span class="s1">llf.append(new_llf)</span>
                <span class="s1">params.append(out[</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s3">if </span><span class="s1">em_initialization:</span>
                    <span class="s1">init = initialization.Initialization(</span>
                        <span class="s1">self.k_states</span><span class="s3">, </span><span class="s5">'known'</span><span class="s3">,</span>
                        <span class="s1">constant=out[</span><span class="s4">0</span><span class="s1">].smoothed_state[...</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">stationary_cov=out[</span><span class="s4">0</span><span class="s1">].smoothed_state_cov[...</span><span class="s3">, </span><span class="s4">0</span><span class="s1">])</span>
                    <span class="s1">inits.append(init)</span>
                <span class="s3">if </span><span class="s1">i &gt; </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">delta = (</span><span class="s4">2 </span><span class="s1">* np.abs(llf[-</span><span class="s4">1</span><span class="s1">] - llf[-</span><span class="s4">2</span><span class="s1">]) /</span>
                             <span class="s1">(np.abs(llf[-</span><span class="s4">1</span><span class="s1">]) + np.abs(llf[-</span><span class="s4">2</span><span class="s1">])))</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">delta = np.inf</span>

                <span class="s0"># If `disp` is not False, display the first iteration</span>
                <span class="s3">if </span><span class="s1">disp </span><span class="s3">and </span><span class="s1">i == </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">print(</span><span class="s5">f'EM start iterations, llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>
                <span class="s0"># Print output every `disp` observations</span>
                <span class="s3">elif </span><span class="s1">disp </span><span class="s3">and </span><span class="s1">((i + </span><span class="s4">1</span><span class="s1">) % disp) == </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">print(</span><span class="s5">f'EM iteration </span><span class="s3">{</span><span class="s1">i + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">, llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">,'</span>
                          <span class="s5">f' convergence criterion=</span><span class="s3">{</span><span class="s1">delta</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

            <span class="s0"># Advance the iteration counter</span>
            <span class="s1">i += </span><span class="s4">1</span>

        <span class="s0"># Check for convergence</span>
        <span class="s1">not_converged = (i == maxiter </span><span class="s3">and </span><span class="s1">delta &gt; tolerance)</span>

        <span class="s0"># If no convergence without explicit termination, warn users</span>
        <span class="s3">if </span><span class="s1">not_converged:</span>
            <span class="s1">warn(</span><span class="s5">f'EM reached maximum number of iterations (</span><span class="s3">{</span><span class="s1">maxiter</span><span class="s3">}</span><span class="s5">),'</span>
                 <span class="s5">f' without achieving convergence: llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">,'</span>
                 <span class="s5">f' convergence criterion=</span><span class="s3">{</span><span class="s1">delta</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span>
                 <span class="s5">f' (while specified tolerance was </span><span class="s3">{</span><span class="s1">tolerance</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">)'</span><span class="s1">)</span>

        <span class="s0"># If `disp` is not False, display the final iteration</span>
        <span class="s3">if </span><span class="s1">disp:</span>
            <span class="s3">if </span><span class="s1">terminate:</span>
                <span class="s1">print(</span><span class="s5">f'EM terminated at iteration </span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">, llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">,'</span>
                      <span class="s5">f' convergence criterion=</span><span class="s3">{</span><span class="s1">delta</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span>
                      <span class="s5">f' (while specified tolerance was </span><span class="s3">{</span><span class="s1">tolerance</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">)'</span><span class="s1">)</span>
            <span class="s3">elif </span><span class="s1">not_converged:</span>
                <span class="s1">print(</span><span class="s5">f'EM reached maximum number of iterations (</span><span class="s3">{</span><span class="s1">maxiter</span><span class="s3">}</span><span class="s5">),'</span>
                      <span class="s5">f' without achieving convergence: llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">,'</span>
                      <span class="s5">f' convergence criterion=</span><span class="s3">{</span><span class="s1">delta</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span>
                      <span class="s5">f' (while specified tolerance was </span><span class="s3">{</span><span class="s1">tolerance</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">)'</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">print(</span><span class="s5">f'EM converged at iteration </span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">, llf=</span><span class="s3">{</span><span class="s1">llf[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">,'</span>
                      <span class="s5">f' convergence criterion=</span><span class="s3">{</span><span class="s1">delta</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span>
                      <span class="s5">f' &lt; tolerance=</span><span class="s3">{</span><span class="s1">tolerance</span><span class="s3">:</span><span class="s5">.5g</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

        <span class="s0"># Just return the fitted parameters if requested</span>
        <span class="s3">if </span><span class="s1">return_params:</span>
            <span class="s1">result = params[-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s0"># Otherwise construct the results class if desired</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">em_initialization:</span>
                <span class="s1">base_init = self.ssm.initialization</span>
                <span class="s1">self.ssm.initialization = init</span>
            <span class="s0"># Note that because we are using params[-1], we are actually using</span>
            <span class="s0"># the results from one additional iteration compared to the</span>
            <span class="s0"># iteration at which we declared convergence.</span>
            <span class="s1">result = self.smooth(params[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">transformed=</span><span class="s3">True,</span>
                                 <span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds)</span>
            <span class="s3">if </span><span class="s1">em_initialization:</span>
                <span class="s1">self.ssm.initialization = base_init</span>

            <span class="s0"># Save the output</span>
            <span class="s3">if </span><span class="s1">full_output:</span>
                <span class="s1">llf.append(result.llf)</span>
                <span class="s1">em_retvals = Bunch(**{</span><span class="s5">'params'</span><span class="s1">: np.array(params)</span><span class="s3">,</span>
                                      <span class="s5">'llf'</span><span class="s1">: np.array(llf)</span><span class="s3">,</span>
                                      <span class="s5">'iter'</span><span class="s1">: i</span><span class="s3">,</span>
                                      <span class="s5">'inits'</span><span class="s1">: inits})</span>
                <span class="s1">em_settings = Bunch(**{</span><span class="s5">'method'</span><span class="s1">: </span><span class="s5">'em'</span><span class="s3">,</span>
                                       <span class="s5">'tolerance'</span><span class="s1">: tolerance</span><span class="s3">,</span>
                                       <span class="s5">'maxiter'</span><span class="s1">: maxiter})</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">em_retvals = </span><span class="s3">None</span>
                <span class="s1">em_settings = </span><span class="s3">None</span>

            <span class="s1">result._results.mle_retvals = em_retvals</span>
            <span class="s1">result._results.mle_settings = em_settings</span>

        <span class="s3">return </span><span class="s1">result</span>

    <span class="s3">def </span><span class="s1">_em_iteration(self</span><span class="s3">, </span><span class="s1">params0</span><span class="s3">, </span><span class="s1">init=</span><span class="s3">None, </span><span class="s1">mstep_method=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;EM iteration.&quot;&quot;&quot;</span>
        <span class="s0"># (E)xpectation step</span>
        <span class="s1">res = self._em_expectation_step(params0</span><span class="s3">, </span><span class="s1">init=init)</span>

        <span class="s0"># (M)aximization step</span>
        <span class="s1">params1 = self._em_maximization_step(res</span><span class="s3">, </span><span class="s1">params0</span><span class="s3">,</span>
                                             <span class="s1">mstep_method=mstep_method)</span>

        <span class="s3">return </span><span class="s1">res</span><span class="s3">, </span><span class="s1">params1</span>

    <span class="s3">def </span><span class="s1">_em_expectation_step(self</span><span class="s3">, </span><span class="s1">params0</span><span class="s3">, </span><span class="s1">init=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;EM expectation step.&quot;&quot;&quot;</span>
        <span class="s0"># (E)xpectation step</span>
        <span class="s1">self.update(params0)</span>
        <span class="s0"># Re-initialize state, if new initialization is given</span>
        <span class="s3">if </span><span class="s1">init </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">base_init = self.ssm.initialization</span>
            <span class="s1">self.ssm.initialization = init</span>
        <span class="s0"># Perform smoothing, only saving what is required</span>
        <span class="s1">res = self.ssm.smooth(</span>
            <span class="s1">SMOOTHER_STATE | SMOOTHER_STATE_COV | SMOOTHER_STATE_AUTOCOV</span><span class="s3">,</span>
            <span class="s1">update_filter=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res.llf_obs = np.array(</span>
            <span class="s1">self.ssm._kalman_filter.loglikelihood</span><span class="s3">, </span><span class="s1">copy=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s0"># Reset initialization</span>
        <span class="s3">if </span><span class="s1">init </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">self.ssm.initialization = base_init</span>

        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">_em_maximization_step(self</span><span class="s3">, </span><span class="s1">res</span><span class="s3">, </span><span class="s1">params0</span><span class="s3">, </span><span class="s1">mstep_method=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;EM maximization step.&quot;&quot;&quot;</span>
        <span class="s1">s = self._s</span>

        <span class="s1">a = res.smoothed_state.T[...</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">cov_a = res.smoothed_state_cov.transpose(</span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">acov_a = res.smoothed_state_autocov.transpose(</span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s0"># E[a_t a_t'], t = 0, ..., T</span>
        <span class="s1">Eaa = cov_a.copy() + np.matmul(a</span><span class="s3">, </span><span class="s1">a.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
        <span class="s0"># E[a_t a_{t-1}'], t = 1, ..., T</span>
        <span class="s1">Eaa1 = acov_a[:-</span><span class="s4">1</span><span class="s1">] + np.matmul(a[</span><span class="s4">1</span><span class="s1">:]</span><span class="s3">, </span><span class="s1">a[:-</span><span class="s4">1</span><span class="s1">].transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>

        <span class="s0"># Observation equation</span>
        <span class="s1">has_missing = np.any(res.nmissing)</span>
        <span class="s3">if </span><span class="s1">mstep_method </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">mstep_method = </span><span class="s5">'missing' </span><span class="s3">if </span><span class="s1">has_missing </span><span class="s3">else </span><span class="s5">'nonmissing'</span>
        <span class="s1">mstep_method = mstep_method.lower()</span>
        <span class="s3">if </span><span class="s1">mstep_method == </span><span class="s5">'nonmissing' </span><span class="s3">and </span><span class="s1">has_missing:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Cannot use EM algorithm option'</span>
                             <span class="s5">' `mstep_method=&quot;nonmissing&quot;` with missing data.'</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">mstep_method == </span><span class="s5">'nonmissing'</span><span class="s1">:</span>
            <span class="s1">func = self._em_maximization_obs_nonmissing</span>
        <span class="s3">elif </span><span class="s1">mstep_method == </span><span class="s5">'missing'</span><span class="s1">:</span>
            <span class="s1">func = self._em_maximization_obs_missing</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Invalid maximization step method: &quot;%s&quot;.'</span>
                             <span class="s1">% mstep_method)</span>
        <span class="s0"># TODO: compute H is pretty slow</span>
        <span class="s1">Lambda</span><span class="s3">, </span><span class="s1">H = func(res</span><span class="s3">, </span><span class="s1">Eaa</span><span class="s3">, </span><span class="s1">a</span><span class="s3">, </span><span class="s1">compute_H=(</span><span class="s3">not </span><span class="s1">self.idiosyncratic_ar1))</span>

        <span class="s0"># Factor VAR and covariance</span>
        <span class="s1">factor_ar = []</span>
        <span class="s1">factor_cov = []</span>
        <span class="s3">for </span><span class="s1">b </span><span class="s3">in </span><span class="s1">s.factor_blocks:</span>
            <span class="s1">A = Eaa[:-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_ar'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_ar'</span><span class="s1">]].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">B = Eaa1[:</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_L1'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_ar'</span><span class="s1">]].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">C = Eaa[</span><span class="s4">1</span><span class="s1">:</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_L1'</span><span class="s1">]</span><span class="s3">, </span><span class="s1">b[</span><span class="s5">'factors_L1'</span><span class="s1">]].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">nobs = Eaa.shape[</span><span class="s4">0</span><span class="s1">] - </span><span class="s4">1</span>

            <span class="s0"># want: x = B A^{-1}, so solve: x A = B or solve: A' x' = B'</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">f_A = cho_solve(cho_factor(A)</span><span class="s3">, </span><span class="s1">B.T).T</span>
            <span class="s3">except </span><span class="s1">LinAlgError:</span>
                <span class="s0"># Fall back to general solver if there are problems with</span>
                <span class="s0"># postive-definiteness</span>
                <span class="s1">f_A = np.linalg.solve(A</span><span class="s3">, </span><span class="s1">B.T).T</span>

            <span class="s1">f_Q = (C - f_A @ B.T) / nobs</span>
            <span class="s1">factor_ar += f_A.ravel().tolist()</span>
            <span class="s1">factor_cov += (</span>
                <span class="s1">np.linalg.cholesky(f_Q)[np.tril_indices_from(f_Q)].tolist())</span>

        <span class="s0"># Idiosyncratic AR(1) and variances</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">ix = s[</span><span class="s5">'idio_ar_L1'</span><span class="s1">]</span>

            <span class="s1">Ad = Eaa[:-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">ix</span><span class="s3">, </span><span class="s1">ix].sum(axis=</span><span class="s4">0</span><span class="s1">).diagonal()</span>
            <span class="s1">Bd = Eaa1[:</span><span class="s3">, </span><span class="s1">ix</span><span class="s3">, </span><span class="s1">ix].sum(axis=</span><span class="s4">0</span><span class="s1">).diagonal()</span>
            <span class="s1">Cd = Eaa[</span><span class="s4">1</span><span class="s1">:</span><span class="s3">, </span><span class="s1">ix</span><span class="s3">, </span><span class="s1">ix].sum(axis=</span><span class="s4">0</span><span class="s1">).diagonal()</span>
            <span class="s1">nobs = Eaa.shape[</span><span class="s4">0</span><span class="s1">] - </span><span class="s4">1</span>

            <span class="s1">alpha = Bd / Ad</span>
            <span class="s1">sigma2 = (Cd - alpha * Bd) / nobs</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">ix = s[</span><span class="s5">'idio_ar_L1'</span><span class="s1">]</span>
            <span class="s1">C = Eaa[:</span><span class="s3">, </span><span class="s1">ix</span><span class="s3">, </span><span class="s1">ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">sigma2 = np.r_[H.diagonal()[self._o[</span><span class="s5">'M'</span><span class="s1">]]</span><span class="s3">,</span>
                           <span class="s1">C.diagonal() / Eaa.shape[</span><span class="s4">0</span><span class="s1">]]</span>

        <span class="s0"># Save parameters</span>
        <span class="s1">params1 = np.zeros_like(params0)</span>
        <span class="s1">loadings = []</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog):</span>
            <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
            <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1'</span><span class="s1">][iloc]</span>
            <span class="s1">loadings += Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix].tolist()</span>
        <span class="s1">params1[self._p[</span><span class="s5">'loadings'</span><span class="s1">]] = loadings</span>
        <span class="s1">params1[self._p[</span><span class="s5">'factor_ar'</span><span class="s1">]] = factor_ar</span>
        <span class="s1">params1[self._p[</span><span class="s5">'factor_cov'</span><span class="s1">]] = factor_cov</span>
        <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
            <span class="s1">params1[self._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]] = alpha</span>
        <span class="s1">params1[self._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]] = sigma2</span>

        <span class="s3">return </span><span class="s1">params1</span>

    <span class="s3">def </span><span class="s1">_em_maximization_obs_nonmissing(self</span><span class="s3">, </span><span class="s1">res</span><span class="s3">, </span><span class="s1">Eaa</span><span class="s3">, </span><span class="s1">a</span><span class="s3">, </span><span class="s1">compute_H=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;EM maximization step, observation equation without missing data.&quot;&quot;&quot;</span>
        <span class="s1">s = self._s</span>
        <span class="s1">dtype = Eaa.dtype</span>

        <span class="s0"># Observation equation (non-missing)</span>
        <span class="s0"># Note: we only compute loadings for monthly variables because</span>
        <span class="s0"># quarterly variables will always have missing entries, so we would</span>
        <span class="s0"># never choose this method in that case</span>
        <span class="s1">k = s.k_states_factors</span>
        <span class="s1">Lambda = np.zeros((self.k_endog</span><span class="s3">, </span><span class="s1">k)</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog):</span>
            <span class="s1">y = self.endog[:</span><span class="s3">, </span><span class="s1">i:i + </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
            <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1'</span><span class="s1">][iloc]</span>

            <span class="s1">ix = (np.s_[:]</span><span class="s3">,</span><span class="s1">) + np.ix_(factor_ix</span><span class="s3">, </span><span class="s1">factor_ix)</span>
            <span class="s1">A = Eaa[ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">B = y.T @ a[:</span><span class="s3">, </span><span class="s1">factor_ix</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
                <span class="s1">ix1 = s.k_states_factors + i</span>
                <span class="s1">ix2 = ix1 + </span><span class="s4">1</span>
                <span class="s1">B -= Eaa[:</span><span class="s3">, </span><span class="s1">ix1:ix2</span><span class="s3">, </span><span class="s1">factor_ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>

            <span class="s0"># want: x = B A^{-1}, so solve: x A = B or solve: A' x' = B'</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix] = cho_solve(cho_factor(A)</span><span class="s3">, </span><span class="s1">B.T).T</span>
            <span class="s3">except </span><span class="s1">LinAlgError:</span>
                <span class="s0"># Fall back to general solver if there are problems with</span>
                <span class="s0"># postive-definiteness</span>
                <span class="s1">Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix] = np.linalg.solve(A</span><span class="s3">, </span><span class="s1">B.T).T</span>

        <span class="s0"># Compute new obs cov</span>
        <span class="s0"># Note: this is unnecessary if `idiosyncratic_ar1=True`.</span>
        <span class="s0"># This is written in a slightly more general way than</span>
        <span class="s0"># Banbura and Modugno (2014), equation (7); see instead equation (13)</span>
        <span class="s0"># of Wu et al. (1996)</span>
        <span class="s0"># &quot;An algorithm for estimating parameters of state-space models&quot;</span>
        <span class="s3">if </span><span class="s1">compute_H:</span>
            <span class="s1">Z = self[</span><span class="s5">'design'</span><span class="s1">].copy()</span>
            <span class="s1">Z[:</span><span class="s3">, </span><span class="s1">:k] = Lambda</span>
            <span class="s1">BL = self.endog.T @ a[...</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] @ Z.T</span>
            <span class="s1">C = self.endog.T @ self.endog</span>

            <span class="s1">H = (C + -BL - BL.T + Z @ Eaa.sum(axis=</span><span class="s4">0</span><span class="s1">) @ Z.T) / self.nobs</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">H = np.zeros((self.k_endog</span><span class="s3">, </span><span class="s1">self.k_endog)</span><span class="s3">, </span><span class="s1">dtype=dtype) * np.nan</span>

        <span class="s3">return </span><span class="s1">Lambda</span><span class="s3">, </span><span class="s1">H</span>

    <span class="s3">def </span><span class="s1">_em_maximization_obs_missing(self</span><span class="s3">, </span><span class="s1">res</span><span class="s3">, </span><span class="s1">Eaa</span><span class="s3">, </span><span class="s1">a</span><span class="s3">, </span><span class="s1">compute_H=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;EM maximization step, observation equation with missing data.&quot;&quot;&quot;</span>
        <span class="s1">s = self._s</span>
        <span class="s1">dtype = Eaa.dtype</span>

        <span class="s0"># Observation equation (missing)</span>
        <span class="s1">k = s.k_states_factors</span>
        <span class="s1">Lambda = np.zeros((self.k_endog</span><span class="s3">, </span><span class="s1">k)</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>

        <span class="s1">W = (</span><span class="s4">1 </span><span class="s1">- res.missing.T)</span>
        <span class="s1">mask = W.astype(bool)</span>

        <span class="s0"># Compute design for monthly</span>
        <span class="s0"># Note: the relevant A changes for each i</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M):</span>
            <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
            <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1'</span><span class="s1">][iloc]</span>

            <span class="s1">m = mask[:</span><span class="s3">, </span><span class="s1">i]</span>
            <span class="s1">yt = self.endog[m</span><span class="s3">, </span><span class="s1">i:i + </span><span class="s4">1</span><span class="s1">]</span>

            <span class="s1">ix = np.ix_(m</span><span class="s3">, </span><span class="s1">factor_ix</span><span class="s3">, </span><span class="s1">factor_ix)</span>
            <span class="s1">Ai = Eaa[ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">Bi = yt.T @ a[np.ix_(m</span><span class="s3">, </span><span class="s1">factor_ix)][...</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
                <span class="s1">ix1 = s.k_states_factors + i</span>
                <span class="s1">ix2 = ix1 + </span><span class="s4">1</span>
                <span class="s1">Bi -= Eaa[m</span><span class="s3">, </span><span class="s1">ix1:ix2][...</span><span class="s3">, </span><span class="s1">factor_ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s0"># want: x = B A^{-1}, so solve: x A = B or solve: A' x' = B'</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix] = cho_solve(cho_factor(Ai)</span><span class="s3">, </span><span class="s1">Bi.T).T</span>
            <span class="s3">except </span><span class="s1">LinAlgError:</span>
                <span class="s0"># Fall back to general solver if there are problems with</span>
                <span class="s0"># postive-definiteness</span>
                <span class="s1">Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix] = np.linalg.solve(Ai</span><span class="s3">, </span><span class="s1">Bi.T).T</span>

        <span class="s0"># Compute unrestricted design for quarterly</span>
        <span class="s0"># See Banbura at al. (2011), where this is described in Appendix C,</span>
        <span class="s0"># between equations (13) and (14).</span>
        <span class="s3">if </span><span class="s1">self.k_endog_Q &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0"># Note: the relevant A changes for each i</span>
            <span class="s1">multipliers = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])[:</span><span class="s3">, None</span><span class="s1">]</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_endog_M</span><span class="s3">, </span><span class="s1">self.k_endog):</span>
                <span class="s1">iloc = self._s.endog_factor_iloc[i]</span>
                <span class="s1">factor_ix = s[</span><span class="s5">'factors_L1_5_ix'</span><span class="s1">][:</span><span class="s3">, </span><span class="s1">iloc].ravel().tolist()</span>

                <span class="s1">R</span><span class="s3">, </span><span class="s1">_ = self.loading_constraints(i)</span>

                <span class="s1">iQ = i - self.k_endog_M</span>
                <span class="s1">m = mask[:</span><span class="s3">, </span><span class="s1">i]</span>
                <span class="s1">yt = self.endog[m</span><span class="s3">, </span><span class="s1">i:i + </span><span class="s4">1</span><span class="s1">]</span>
                <span class="s1">ix = np.ix_(m</span><span class="s3">, </span><span class="s1">factor_ix</span><span class="s3">, </span><span class="s1">factor_ix)</span>
                <span class="s1">Ai = Eaa[ix].sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
                <span class="s1">BiQ = yt.T @ a[np.ix_(m</span><span class="s3">, </span><span class="s1">factor_ix)][...</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
                <span class="s3">if </span><span class="s1">self.idiosyncratic_ar1:</span>
                    <span class="s1">ix = (np.s_[:]</span><span class="s3">,</span><span class="s1">) + np.ix_(s[</span><span class="s5">'idio_ar_Q_ix'</span><span class="s1">][iQ]</span><span class="s3">, </span><span class="s1">factor_ix)</span>
                    <span class="s1">Eepsf = Eaa[ix]</span>
                    <span class="s1">BiQ -= (multipliers * Eepsf[m].sum(axis=</span><span class="s4">0</span><span class="s1">)).sum(axis=</span><span class="s4">0</span><span class="s1">)</span>

                <span class="s0"># Note that there was a typo in Banbura et al. (2011) for</span>
                <span class="s0"># the formula applying the restrictions. In their notation,</span>
                <span class="s0"># they show (C D C')^{-1} while it should be (C D^{-1} C')^{-1}</span>
                <span class="s0"># Note: in reality, this is:</span>
                <span class="s0"># unrestricted - Aii @ R.T @ RARi @ (R @ unrestricted - q)</span>
                <span class="s0"># where the restrictions are defined as: R @ unrestricted = q</span>
                <span class="s0"># However, here q = 0, so we can simplify.</span>
                <span class="s3">try</span><span class="s1">:</span>
                    <span class="s1">L_and_lower = cho_factor(Ai)</span>
                    <span class="s0"># x = BQ A^{-1}, or x A = BQ, so solve A' x' = (BQ)'</span>
                    <span class="s1">unrestricted = cho_solve(L_and_lower</span><span class="s3">, </span><span class="s1">BiQ.T).T[</span><span class="s4">0</span><span class="s1">]</span>
                    <span class="s1">AiiRT = cho_solve(L_and_lower</span><span class="s3">, </span><span class="s1">R.T)</span>

                    <span class="s1">L_and_lower = cho_factor(R @ AiiRT)</span>
                    <span class="s1">RAiiRTiR = cho_solve(L_and_lower</span><span class="s3">, </span><span class="s1">R)</span>
                    <span class="s1">restricted = unrestricted - AiiRT @ RAiiRTiR @ unrestricted</span>
                <span class="s3">except </span><span class="s1">LinAlgError:</span>
                    <span class="s0"># Fall back to slower method if there are problems with</span>
                    <span class="s0"># postive-definiteness</span>
                    <span class="s1">Aii = np.linalg.inv(Ai)</span>
                    <span class="s1">unrestricted = (BiQ @ Aii)[</span><span class="s4">0</span><span class="s1">]</span>
                    <span class="s1">RARi = np.linalg.inv(R @ Aii @ R.T)</span>
                    <span class="s1">restricted = (unrestricted -</span>
                                  <span class="s1">Aii @ R.T @ RARi @ R @ unrestricted)</span>
                <span class="s1">Lambda[i</span><span class="s3">, </span><span class="s1">factor_ix] = restricted</span>

        <span class="s0"># Compute new obs cov</span>
        <span class="s0"># Note: this is unnecessary if `idiosyncratic_ar1=True`.</span>
        <span class="s0"># See Banbura and Modugno (2014), equation (12)</span>
        <span class="s0"># This does not literally follow their formula, e.g. multiplying by the</span>
        <span class="s0"># W_t selection matrices, because those formulas require loops that are</span>
        <span class="s0"># relatively slow. The formulation here is vectorized.</span>
        <span class="s3">if </span><span class="s1">compute_H:</span>
            <span class="s1">Z = self[</span><span class="s5">'design'</span><span class="s1">].copy()</span>
            <span class="s1">Z[:</span><span class="s3">, </span><span class="s1">:Lambda.shape[</span><span class="s4">1</span><span class="s1">]] = Lambda</span>

            <span class="s1">y = np.nan_to_num(self.endog)</span>
            <span class="s1">C = y.T @ y</span>
            <span class="s1">W = W[...</span><span class="s3">, None</span><span class="s1">]</span>
            <span class="s1">IW = </span><span class="s4">1 </span><span class="s1">- W</span>

            <span class="s1">WL = W * Z</span>
            <span class="s1">WLT = WL.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">BL = y[...</span><span class="s3">, None</span><span class="s1">] @ a.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">) @ WLT</span>
            <span class="s1">A = Eaa</span>

            <span class="s1">BLT = BL.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">IWT = IW.transpose(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>

            <span class="s1">H = (C + (-BL - BLT + WL @ A @ WLT +</span>
                      <span class="s1">IW * self[</span><span class="s5">'obs_cov'</span><span class="s1">] * IWT).sum(axis=</span><span class="s4">0</span><span class="s1">)) / self.nobs</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">H = np.zeros((self.k_endog</span><span class="s3">, </span><span class="s1">self.k_endog)</span><span class="s3">, </span><span class="s1">dtype=dtype) * np.nan</span>

        <span class="s3">return </span><span class="s1">Lambda</span><span class="s3">, </span><span class="s1">H</span>

    <span class="s3">def </span><span class="s1">smooth(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">includes_fixed=</span><span class="s3">False,</span>
               <span class="s1">complex_step=</span><span class="s3">False, </span><span class="s1">cov_type=</span><span class="s5">'none'</span><span class="s3">, </span><span class="s1">cov_kwds=</span><span class="s3">None,</span>
               <span class="s1">return_ssm=</span><span class="s3">False, </span><span class="s1">results_class=</span><span class="s3">None,</span>
               <span class="s1">results_wrapper_class=</span><span class="s3">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Kalman smoothing. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the loglikelihood 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        return_ssm : bool,optional 
            Whether or not to return only the state space output or a full 
            results object. Default is to return a full results object. 
        cov_type : str, optional 
            See `MLEResults.fit` for a description of covariance matrix types 
            for results object. Default is None. 
        cov_kwds : dict or None, optional 
            See `MLEResults.get_robustcov_results` for a description required 
            keywords for alternative covariance estimators 
        **kwargs 
            Additional keyword arguments to pass to the Kalman filter. See 
            `KalmanFilter.filter` for more details. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">super().smooth(</span>
            <span class="s1">params</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">, </span><span class="s1">includes_fixed=includes_fixed</span><span class="s3">,</span>
            <span class="s1">complex_step=complex_step</span><span class="s3">, </span><span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span><span class="s3">,</span>
            <span class="s1">return_ssm=return_ssm</span><span class="s3">, </span><span class="s1">results_class=results_class</span><span class="s3">,</span>
            <span class="s1">results_wrapper_class=results_wrapper_class</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s3">def </span><span class="s1">filter(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">includes_fixed=</span><span class="s3">False,</span>
               <span class="s1">complex_step=</span><span class="s3">False, </span><span class="s1">cov_type=</span><span class="s5">'none'</span><span class="s3">, </span><span class="s1">cov_kwds=</span><span class="s3">None,</span>
               <span class="s1">return_ssm=</span><span class="s3">False, </span><span class="s1">results_class=</span><span class="s3">None,</span>
               <span class="s1">results_wrapper_class=</span><span class="s3">None, </span><span class="s1">low_memory=</span><span class="s3">False, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Kalman filtering. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the loglikelihood 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        return_ssm : bool,optional 
            Whether or not to return only the state space output or a full 
            results object. Default is to return a full results object. 
        cov_type : str, optional 
            See `MLEResults.fit` for a description of covariance matrix types 
            for results object. Default is 'none'. 
        cov_kwds : dict or None, optional 
            See `MLEResults.get_robustcov_results` for a description required 
            keywords for alternative covariance estimators 
        low_memory : bool, optional 
            If set to True, techniques are applied to substantially reduce 
            memory usage. If used, some features of the results object will 
            not be available (including in-sample prediction), although 
            out-of-sample forecasting is possible. Default is False. 
        **kwargs 
            Additional keyword arguments to pass to the Kalman filter. See 
            `KalmanFilter.filter` for more details. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">super().filter(</span>
            <span class="s1">params</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">, </span><span class="s1">includes_fixed=includes_fixed</span><span class="s3">,</span>
            <span class="s1">complex_step=complex_step</span><span class="s3">, </span><span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span><span class="s3">,</span>
            <span class="s1">return_ssm=return_ssm</span><span class="s3">, </span><span class="s1">results_class=results_class</span><span class="s3">,</span>
            <span class="s1">results_wrapper_class=results_wrapper_class</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s3">def </span><span class="s1">simulate(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">nsimulations</span><span class="s3">, </span><span class="s1">measurement_shocks=</span><span class="s3">None,</span>
                 <span class="s1">state_shocks=</span><span class="s3">None, </span><span class="s1">initial_state=</span><span class="s3">None, </span><span class="s1">anchor=</span><span class="s3">None,</span>
                 <span class="s1">repetitions=</span><span class="s3">None, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">extend_model=</span><span class="s3">None,</span>
                 <span class="s1">extend_kwargs=</span><span class="s3">None, </span><span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">includes_fixed=</span><span class="s3">False,</span>
                 <span class="s1">original_scale=</span><span class="s3">True, </span><span class="s1">**kwargs):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Simulate a new time series following the state space model. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters to use in constructing the state space 
            representation to use when simulating. 
        nsimulations : int 
            The number of observations to simulate. If the model is 
            time-invariant this can be any number. If the model is 
            time-varying, then this number must be less than or equal to the 
            number of observations. 
        measurement_shocks : array_like, optional 
            If specified, these are the shocks to the measurement equation, 
            :math:`\varepsilon_t`. If unspecified, these are automatically 
            generated using a pseudo-random number generator. If specified, 
            must be shaped `nsimulations` x `k_endog`, where `k_endog` is the 
            same as in the state space model. 
        state_shocks : array_like, optional 
            If specified, these are the shocks to the state equation, 
            :math:`\eta_t`. If unspecified, these are automatically 
            generated using a pseudo-random number generator. If specified, 
            must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the 
            same as in the state space model. 
        initial_state : array_like, optional 
            If specified, this is the initial state vector to use in 
            simulation, which should be shaped (`k_states` x 1), where 
            `k_states` is the same as in the state space model. If unspecified, 
            but the model has been initialized, then that initialization is 
            used. This must be specified if `anchor` is anything other than 
            &quot;start&quot; or 0 (or else you can use the `simulate` method on a 
            results object rather than on the model object). 
        anchor : int, str, or datetime, optional 
            First period for simulation. The simulation will be conditional on 
            all existing datapoints prior to the `anchor`.  Type depends on the 
            index of the given `endog` in the model. Two special cases are the 
            strings 'start' and 'end'. `start` refers to beginning the 
            simulation at the first period of the sample, and `end` refers to 
            beginning the simulation at the first period after the sample. 
            Integer values can run from 0 to `nobs`, or can be negative to 
            apply negative indexing. Finally, if a date/time index was provided 
            to the model, then this argument can be a date string to parse or a 
            datetime type. Default is 'start'. 
        repetitions : int, optional 
            Number of simulated paths to generate. Default is 1 simulated path. 
        exog : array_like, optional 
            New observations of exogenous regressors, if applicable. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is 
            True. 
        includes_fixed : bool, optional 
            If parameters were previously fixed with the `fix_params` method, 
            this argument describes whether or not `params` also includes 
            the fixed parameters, in addition to the free parameters. Default 
            is False. 
        original_scale : bool, optional 
            If the model specification standardized the data, whether or not 
            to return simulations in the original scale of the data (i.e. 
            before it was standardized by the model). Default is True. 
 
        Returns 
        ------- 
        simulated_obs : ndarray 
            An array of simulated observations. If `repetitions=None`, then it 
            will be shaped (nsimulations x k_endog) or (nsimulations,) if 
            `k_endog=1`. Otherwise it will be shaped 
            (nsimulations x k_endog x repetitions). If the model was given 
            Pandas input then the output will be a Pandas object. If 
            `k_endog &gt; 1` and `repetitions` is not None, then the output will 
            be a Pandas DataFrame that has a MultiIndex for the columns, with 
            the first level containing the names of the `endog` variables and 
            the second level containing the repetition number. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Get usual simulations (in the possibly-standardized scale)</span>
        <span class="s1">sim = super().simulate(</span>
            <span class="s1">params</span><span class="s3">, </span><span class="s1">nsimulations</span><span class="s3">, </span><span class="s1">measurement_shocks=measurement_shocks</span><span class="s3">,</span>
            <span class="s1">state_shocks=state_shocks</span><span class="s3">, </span><span class="s1">initial_state=initial_state</span><span class="s3">,</span>
            <span class="s1">anchor=anchor</span><span class="s3">, </span><span class="s1">repetitions=repetitions</span><span class="s3">, </span><span class="s1">exog=exog</span><span class="s3">,</span>
            <span class="s1">extend_model=extend_model</span><span class="s3">, </span><span class="s1">extend_kwargs=extend_kwargs</span><span class="s3">,</span>
            <span class="s1">transformed=transformed</span><span class="s3">, </span><span class="s1">includes_fixed=includes_fixed</span><span class="s3">, </span><span class="s1">**kwargs)</span>

        <span class="s0"># If applicable, convert predictions back to original space</span>
        <span class="s3">if </span><span class="s1">self.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">use_pandas = isinstance(self.data</span><span class="s3">, </span><span class="s1">PandasData)</span>
            <span class="s1">shape = sim.shape</span>

            <span class="s3">if </span><span class="s1">use_pandas:</span>
                <span class="s0"># pd.Series (k_endog=1, replications=None)</span>
                <span class="s3">if </span><span class="s1">len(shape) == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">sim = sim * self._endog_std[</span><span class="s4">0</span><span class="s1">] + self._endog_mean[</span><span class="s4">0</span><span class="s1">]</span>
                <span class="s0"># pd.DataFrame (k_endog &gt; 1, replications=None)</span>
                <span class="s0"># [or]</span>
                <span class="s0"># pd.DataFrame with MultiIndex (replications &gt; 0)</span>
                <span class="s3">elif </span><span class="s1">len(shape) == </span><span class="s4">2</span><span class="s1">:</span>
                    <span class="s1">sim = (sim.multiply(self._endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">)</span>
                              <span class="s1">.add(self._endog_mean</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">))</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s0"># 1-dim array (k_endog=1, replications=None)</span>
                <span class="s3">if </span><span class="s1">len(shape) == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">sim = sim * self._endog_std + self._endog_mean</span>
                <span class="s0"># 2-dim array (k_endog &gt; 1, replications=None)</span>
                <span class="s3">elif </span><span class="s1">len(shape) == </span><span class="s4">2</span><span class="s1">:</span>
                    <span class="s1">sim = sim * self._endog_std + self._endog_mean</span>
                <span class="s0"># 3-dim array with MultiIndex (replications &gt; 0)</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s0"># Get arrays into the form that can be used for</span>
                    <span class="s0"># broadcasting</span>
                    <span class="s1">std = np.atleast_2d(self._endog_std)[...</span><span class="s3">, None</span><span class="s1">]</span>
                    <span class="s1">mean = np.atleast_2d(self._endog_mean)[...</span><span class="s3">, None</span><span class="s1">]</span>
                    <span class="s1">sim = sim * std + mean</span>

        <span class="s3">return </span><span class="s1">sim</span>

    <span class="s3">def </span><span class="s1">impulse_responses(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">steps=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">impulse=</span><span class="s4">0</span><span class="s3">,</span>
                          <span class="s1">orthogonalized=</span><span class="s3">False, </span><span class="s1">cumulative=</span><span class="s3">False, </span><span class="s1">anchor=</span><span class="s3">None,</span>
                          <span class="s1">exog=</span><span class="s3">None, </span><span class="s1">extend_model=</span><span class="s3">None, </span><span class="s1">extend_kwargs=</span><span class="s3">None,</span>
                          <span class="s1">transformed=</span><span class="s3">True, </span><span class="s1">includes_fixed=</span><span class="s3">False,</span>
                          <span class="s1">original_scale=</span><span class="s3">True, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Impulse response function. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of model parameters. 
        steps : int, optional 
            The number of steps for which impulse responses are calculated. 
            Default is 1. Note that for time-invariant models, the initial 
            impulse is not counted as a step, so if `steps=1`, the output will 
            have 2 entries. 
        impulse : int or array_like 
            If an integer, the state innovation to pulse; must be between 0 
            and `k_posdef-1`. Alternatively, a custom impulse vector may be 
            provided; must be shaped `k_posdef x 1`. 
        orthogonalized : bool, optional 
            Whether or not to perform impulse using orthogonalized innovations. 
            Note that this will also affect custum `impulse` vectors. Default 
            is False. 
        cumulative : bool, optional 
            Whether or not to return cumulative impulse responses. Default is 
            False. 
        anchor : int, str, or datetime, optional 
            Time point within the sample for the state innovation impulse. Type 
            depends on the index of the given `endog` in the model. Two special 
            cases are the strings 'start' and 'end', which refer to setting the 
            impulse at the first and last points of the sample, respectively. 
            Integer values can run from 0 to `nobs - 1`, or can be negative to 
            apply negative indexing. Finally, if a date/time index was provided 
            to the model, then this argument can be a date string to parse or a 
            datetime type. Default is 'start'. 
        exog : array_like, optional 
            New observations of exogenous regressors for our-of-sample periods, 
            if applicable. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is 
            True. 
        includes_fixed : bool, optional 
            If parameters were previously fixed with the `fix_params` method, 
            this argument describes whether or not `params` also includes 
            the fixed parameters, in addition to the free parameters. Default 
            is False. 
        original_scale : bool, optional 
            If the model specification standardized the data, whether or not 
            to return impulse responses in the original scale of the data (i.e. 
            before it was standardized by the model). Default is True. 
        **kwargs 
            If the model has time-varying design or transition matrices and the 
            combination of `anchor` and `steps` implies creating impulse 
            responses for the out-of-sample period, then these matrices must 
            have updated values provided for the out-of-sample steps. For 
            example, if `design` is a time-varying component, `nobs` is 10, 
            `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7) 
            matrix must be provided with the new design matrix values. 
 
        Returns 
        ------- 
        impulse_responses : ndarray 
            Responses for each endogenous variable due to the impulse 
            given by the `impulse` argument. For a time-invariant model, the 
            impulse responses are given for `steps + 1` elements (this gives 
            the &quot;initial impulse&quot; followed by `steps` responses for the 
            important cases of VAR and SARIMAX models), while for time-varying 
            models the impulse responses are only given for `steps` elements 
            (to avoid having to unexpectedly provide updated time-varying 
            matrices). 
 
        &quot;&quot;&quot;</span>
        <span class="s0"># Get usual simulations (in the possibly-standardized scale)</span>
        <span class="s1">irfs = super().impulse_responses(</span>
            <span class="s1">params</span><span class="s3">, </span><span class="s1">steps=steps</span><span class="s3">, </span><span class="s1">impulse=impulse</span><span class="s3">,</span>
            <span class="s1">orthogonalized=orthogonalized</span><span class="s3">, </span><span class="s1">cumulative=cumulative</span><span class="s3">,</span>
            <span class="s1">anchor=anchor</span><span class="s3">, </span><span class="s1">exog=exog</span><span class="s3">, </span><span class="s1">extend_model=extend_model</span><span class="s3">,</span>
            <span class="s1">extend_kwargs=extend_kwargs</span><span class="s3">, </span><span class="s1">transformed=transformed</span><span class="s3">,</span>
            <span class="s1">includes_fixed=includes_fixed</span><span class="s3">, </span><span class="s1">**kwargs)</span>

        <span class="s0"># If applicable, convert predictions back to original space</span>
        <span class="s3">if </span><span class="s1">self.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">use_pandas = isinstance(self.data</span><span class="s3">, </span><span class="s1">PandasData)</span>
            <span class="s1">shape = irfs.shape</span>

            <span class="s3">if </span><span class="s1">use_pandas:</span>
                <span class="s0"># pd.Series (k_endog=1, replications=None)</span>
                <span class="s3">if </span><span class="s1">len(shape) == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">irfs = irfs * self._endog_std[</span><span class="s4">0</span><span class="s1">]</span>
                <span class="s0"># pd.DataFrame (k_endog &gt; 1)</span>
                <span class="s0"># [or]</span>
                <span class="s0"># pd.DataFrame with MultiIndex (replications &gt; 0)</span>
                <span class="s3">elif </span><span class="s1">len(shape) == </span><span class="s4">2</span><span class="s1">:</span>
                    <span class="s1">irfs = irfs.multiply(self._endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s0"># 1-dim array (k_endog=1)</span>
                <span class="s3">if </span><span class="s1">len(shape) == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">irfs = irfs * self._endog_std</span>
                <span class="s0"># 2-dim array (k_endog &gt; 1)</span>
                <span class="s3">elif </span><span class="s1">len(shape) == </span><span class="s4">2</span><span class="s1">:</span>
                    <span class="s1">irfs = irfs * self._endog_std</span>

        <span class="s3">return </span><span class="s1">irfs</span>


<span class="s3">class </span><span class="s1">DynamicFactorMQResults(mlemodel.MLEResults):</span>
    <span class="s2">&quot;&quot;&quot; 
    Results from fitting a dynamic factor model 
    &quot;&quot;&quot;</span>
    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">model</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">filter_results</span><span class="s3">, </span><span class="s1">cov_type=</span><span class="s3">None, </span><span class="s1">**kwargs):</span>
        <span class="s1">super(DynamicFactorMQResults</span><span class="s3">, </span><span class="s1">self).__init__(</span>
            <span class="s1">model</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">filter_results</span><span class="s3">, </span><span class="s1">cov_type</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">factors(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Estimates of unobserved factors. 
 
        Returns 
        ------- 
        out : Bunch 
            Has the following attributes shown in Notes. 
 
        Notes 
        ----- 
        The output is a bunch of the following format: 
 
        - `filtered`: a time series array with the filtered estimate of 
          the component 
        - `filtered_cov`: a time series array with the filtered estimate of 
          the variance/covariance of the component 
        - `smoothed`: a time series array with the smoothed estimate of 
          the component 
        - `smoothed_cov`: a time series array with the smoothed estimate of 
          the variance/covariance of the component 
        - `offset`: an integer giving the offset in the state vector where 
          this component begins 
        &quot;&quot;&quot;</span>
        <span class="s1">out = </span><span class="s3">None</span>
        <span class="s3">if </span><span class="s1">self.model.k_factors &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">iloc = self.model._s.factors_L1</span>
            <span class="s1">ix = np.array(self.model.state_names)[iloc].tolist()</span>
            <span class="s1">out = Bunch(</span>
                <span class="s1">filtered=self.states.filtered.loc[:</span><span class="s3">, </span><span class="s1">ix]</span><span class="s3">,</span>
                <span class="s1">filtered_cov=self.states.filtered_cov.loc[np.s_[ix</span><span class="s3">, </span><span class="s1">:]</span><span class="s3">, </span><span class="s1">ix]</span><span class="s3">,</span>
                <span class="s1">smoothed=</span><span class="s3">None, </span><span class="s1">smoothed_cov=</span><span class="s3">None</span><span class="s1">)</span>
            <span class="s3">if </span><span class="s1">self.smoothed_state </span><span class="s3">is not None</span><span class="s1">:</span>
                <span class="s1">out.smoothed = self.states.smoothed.loc[:</span><span class="s3">, </span><span class="s1">ix]</span>
            <span class="s3">if </span><span class="s1">self.smoothed_state_cov </span><span class="s3">is not None</span><span class="s1">:</span>
                <span class="s1">out.smoothed_cov = (</span>
                    <span class="s1">self.states.smoothed_cov.loc[np.s_[ix</span><span class="s3">, </span><span class="s1">:]</span><span class="s3">, </span><span class="s1">ix])</span>
        <span class="s3">return </span><span class="s1">out</span>

    <span class="s3">def </span><span class="s1">get_coefficients_of_determination(self</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">'individual'</span><span class="s3">,</span>
                                          <span class="s1">which=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Get coefficients of determination (R-squared) for variables / factors. 
 
        Parameters 
        ---------- 
        method : {'individual', 'joint', 'cumulative'}, optional 
            The type of R-squared values to generate. &quot;individual&quot; plots 
            the R-squared of each variable on each factor; &quot;joint&quot; plots the 
            R-squared of each variable on each factor that it loads on; 
            &quot;cumulative&quot; plots the successive R-squared values as each 
            additional factor is added to the regression, for each variable. 
            Default is 'individual'. 
        which: {None, 'filtered', 'smoothed'}, optional 
            Whether to compute R-squared values based on filtered or smoothed 
            estimates of the factors. Default is 'smoothed' if smoothed results 
            are available and 'filtered' otherwise. 
 
        Returns 
        ------- 
        rsquared : pd.DataFrame or pd.Series 
            The R-squared values from regressions of observed variables on 
            one or more of the factors. If method='individual' or 
            method='cumulative', this will be a Pandas DataFrame with observed 
            variables as the index and factors as the columns . If 
            method='joint', will be a Pandas Series with observed variables as 
            the index. 
 
        See Also 
        -------- 
        plot_coefficients_of_determination 
        coefficients_of_determination 
        &quot;&quot;&quot;</span>
        <span class="s3">from </span><span class="s1">statsmodels.tools </span><span class="s3">import </span><span class="s1">add_constant</span>

        <span class="s1">method = string_like(method</span><span class="s3">, </span><span class="s5">'method'</span><span class="s3">, </span><span class="s1">options=[</span><span class="s5">'individual'</span><span class="s3">, </span><span class="s5">'joint'</span><span class="s3">,</span>
                                                        <span class="s5">'cumulative'</span><span class="s1">])</span>
        <span class="s3">if </span><span class="s1">which </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">which = </span><span class="s5">'filtered' </span><span class="s3">if </span><span class="s1">self.smoothed_state </span><span class="s3">is None else </span><span class="s5">'smoothed'</span>

        <span class="s1">k_endog = self.model.k_endog</span>
        <span class="s1">k_factors = self.model.k_factors</span>
        <span class="s1">ef_map = self.model._s.endog_factor_map</span>
        <span class="s1">endog_names = self.model.endog_names</span>
        <span class="s1">factor_names = self.model.factor_names</span>

        <span class="s3">if </span><span class="s1">method == </span><span class="s5">'individual'</span><span class="s1">:</span>
            <span class="s1">coefficients = np.zeros((k_endog</span><span class="s3">, </span><span class="s1">k_factors))</span>

            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k_factors):</span>
                <span class="s1">exog = add_constant(self.factors[which].iloc[:</span><span class="s3">, </span><span class="s1">i])</span>
                <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(k_endog):</span>
                    <span class="s3">if </span><span class="s1">ef_map.iloc[j</span><span class="s3">, </span><span class="s1">i]:</span>
                        <span class="s1">endog = self.filter_results.endog[j]</span>
                        <span class="s1">coefficients[j</span><span class="s3">, </span><span class="s1">i] = (</span>
                            <span class="s1">OLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">'drop'</span><span class="s1">).fit().rsquared)</span>
                    <span class="s3">else</span><span class="s1">:</span>
                        <span class="s1">coefficients[j</span><span class="s3">, </span><span class="s1">i] = np.nan</span>

            <span class="s1">coefficients = pd.DataFrame(coefficients</span><span class="s3">, </span><span class="s1">index=endog_names</span><span class="s3">,</span>
                                        <span class="s1">columns=factor_names)</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s5">'joint'</span><span class="s1">:</span>
            <span class="s1">coefficients = np.zeros((k_endog</span><span class="s3">,</span><span class="s1">))</span>
            <span class="s1">exog = add_constant(self.factors[which])</span>
            <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(k_endog):</span>
                <span class="s1">endog = self.filter_results.endog[j]</span>
                <span class="s1">ix = np.r_[</span><span class="s3">True, </span><span class="s1">ef_map.iloc[j]].tolist()</span>
                <span class="s1">X = exog.loc[:</span><span class="s3">, </span><span class="s1">ix]</span>
                <span class="s1">coefficients[j] = (</span>
                    <span class="s1">OLS(endog</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">'drop'</span><span class="s1">).fit().rsquared)</span>
            <span class="s1">coefficients = pd.Series(coefficients</span><span class="s3">, </span><span class="s1">index=endog_names)</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s5">'cumulative'</span><span class="s1">:</span>
            <span class="s1">coefficients = np.zeros((k_endog</span><span class="s3">, </span><span class="s1">k_factors))</span>
            <span class="s1">exog = add_constant(self.factors[which])</span>
            <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(k_endog):</span>
                <span class="s1">endog = self.filter_results.endog[j]</span>

                <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k_factors):</span>
                    <span class="s3">if </span><span class="s1">self.model._s.endog_factor_map.iloc[j</span><span class="s3">, </span><span class="s1">i]:</span>
                        <span class="s1">ix = np.r_[</span><span class="s3">True, </span><span class="s1">ef_map.iloc[j</span><span class="s3">, </span><span class="s1">:i + </span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
                                   <span class="s1">[</span><span class="s3">False</span><span class="s1">] * (k_factors - i - </span><span class="s4">1</span><span class="s1">)]</span>
                        <span class="s1">X = exog.loc[:</span><span class="s3">, </span><span class="s1">ix.astype(bool).tolist()]</span>
                        <span class="s1">coefficients[j</span><span class="s3">, </span><span class="s1">i] = (</span>
                            <span class="s1">OLS(endog</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">'drop'</span><span class="s1">).fit().rsquared)</span>
                    <span class="s3">else</span><span class="s1">:</span>
                        <span class="s1">coefficients[j</span><span class="s3">, </span><span class="s1">i] = np.nan</span>
            <span class="s1">coefficients = pd.DataFrame(coefficients</span><span class="s3">, </span><span class="s1">index=endog_names</span><span class="s3">,</span>
                                        <span class="s1">columns=factor_names)</span>

        <span class="s3">return </span><span class="s1">coefficients</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">coefficients_of_determination(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Individual coefficients of determination (:math:`R^2`). 
 
        Coefficients of determination (:math:`R^2`) from regressions of 
        endogenous variables on individual estimated factors. 
 
        Returns 
        ------- 
        coefficients_of_determination : ndarray 
            A `k_endog` x `k_factors` array, where 
            `coefficients_of_determination[i, j]` represents the :math:`R^2` 
            value from a regression of factor `j` and a constant on endogenous 
            variable `i`. 
 
        Notes 
        ----- 
        Although it can be difficult to interpret the estimated factor loadings 
        and factors, it is often helpful to use the coefficients of 
        determination from univariate regressions to assess the importance of 
        each factor in explaining the variation in each endogenous variable. 
 
        In models with many variables and factors, this can sometimes lend 
        interpretation to the factors (for example sometimes one factor will 
        load primarily on real variables and another on nominal variables). 
 
        See Also 
        -------- 
        get_coefficients_of_determination 
        plot_coefficients_of_determination 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.get_coefficients_of_determination(method=</span><span class="s5">'individual'</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">plot_coefficients_of_determination(self</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">'individual'</span><span class="s3">,</span>
                                           <span class="s1">which=</span><span class="s3">None, </span><span class="s1">endog_labels=</span><span class="s3">None,</span>
                                           <span class="s1">fig=</span><span class="s3">None, </span><span class="s1">figsize=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Plot coefficients of determination (R-squared) for variables / factors. 
 
        Parameters 
        ---------- 
        method : {'individual', 'joint', 'cumulative'}, optional 
            The type of R-squared values to generate. &quot;individual&quot; plots 
            the R-squared of each variable on each factor; &quot;joint&quot; plots the 
            R-squared of each variable on each factor that it loads on; 
            &quot;cumulative&quot; plots the successive R-squared values as each 
            additional factor is added to the regression, for each variable. 
            Default is 'individual'. 
        which: {None, 'filtered', 'smoothed'}, optional 
            Whether to compute R-squared values based on filtered or smoothed 
            estimates of the factors. Default is 'smoothed' if smoothed results 
            are available and 'filtered' otherwise. 
        endog_labels : bool, optional 
            Whether or not to label the endogenous variables along the x-axis 
            of the plots. Default is to include labels if there are 5 or fewer 
            endogenous variables. 
        fig : Figure, optional 
            If given, subplots are created in this figure instead of in a new 
            figure. Note that the grid will be created in the provided 
            figure using `fig.add_subplot()`. 
        figsize : tuple, optional 
            If a figure is created, this argument allows specifying a size. 
            The tuple is (width, height). 
 
        Notes 
        ----- 
        The endogenous variables are arranged along the x-axis according to 
        their position in the model's `endog` array. 
 
        See Also 
        -------- 
        get_coefficients_of_determination 
        &quot;&quot;&quot;</span>
        <span class="s3">from </span><span class="s1">statsmodels.graphics.utils </span><span class="s3">import </span><span class="s1">_import_mpl</span><span class="s3">, </span><span class="s1">create_mpl_fig</span>
        <span class="s1">_import_mpl()</span>
        <span class="s1">fig = create_mpl_fig(fig</span><span class="s3">, </span><span class="s1">figsize)</span>

        <span class="s1">method = string_like(method</span><span class="s3">, </span><span class="s5">'method'</span><span class="s3">, </span><span class="s1">options=[</span><span class="s5">'individual'</span><span class="s3">, </span><span class="s5">'joint'</span><span class="s3">,</span>
                                                        <span class="s5">'cumulative'</span><span class="s1">])</span>

        <span class="s0"># Should we label endogenous variables?</span>
        <span class="s3">if </span><span class="s1">endog_labels </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">endog_labels = self.model.k_endog &lt;= </span><span class="s4">5</span>

        <span class="s0"># Plot the coefficients of determination</span>
        <span class="s1">rsquared = self.get_coefficients_of_determination(method=method</span><span class="s3">,</span>
                                                          <span class="s1">which=which)</span>

        <span class="s3">if </span><span class="s1">method </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'individual'</span><span class="s3">, </span><span class="s5">'cumulative'</span><span class="s1">]:</span>
            <span class="s1">plot_idx = </span><span class="s4">1</span>
            <span class="s3">for </span><span class="s1">factor_name</span><span class="s3">, </span><span class="s1">coeffs </span><span class="s3">in </span><span class="s1">rsquared.T.iterrows():</span>
                <span class="s0"># Create the new axis</span>
                <span class="s1">ax = fig.add_subplot(self.model.k_factors</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">plot_idx)</span>
                <span class="s1">ax.set_ylim((</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
                <span class="s1">ax.set(title=</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">factor_name</span><span class="s3">}</span><span class="s5">'</span><span class="s3">, </span><span class="s1">ylabel=</span><span class="s5">r'$R^2$'</span><span class="s1">)</span>

                <span class="s1">coeffs.plot(ax=ax</span><span class="s3">, </span><span class="s1">kind=</span><span class="s5">'bar'</span><span class="s1">)</span>
                <span class="s3">if </span><span class="s1">plot_idx &lt; len(rsquared.columns) </span><span class="s3">or not </span><span class="s1">endog_labels:</span>
                    <span class="s1">ax.xaxis.set_ticklabels([])</span>

                <span class="s1">plot_idx += </span><span class="s4">1</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s5">'joint'</span><span class="s1">:</span>
            <span class="s1">ax = fig.add_subplot(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">ax.set_ylim((</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
            <span class="s1">ax.set(title=</span><span class="s5">r'$R^2$ - regression on all loaded factors'</span><span class="s3">,</span>
                   <span class="s1">ylabel=</span><span class="s5">r'$R^2$'</span><span class="s1">)</span>
            <span class="s1">rsquared.plot(ax=ax</span><span class="s3">, </span><span class="s1">kind=</span><span class="s5">'bar'</span><span class="s1">)</span>
            <span class="s3">if not </span><span class="s1">endog_labels:</span>
                <span class="s1">ax.xaxis.set_ticklabels([])</span>

        <span class="s3">return </span><span class="s1">fig</span>

    <span class="s3">def </span><span class="s1">get_prediction(self</span><span class="s3">, </span><span class="s1">start=</span><span class="s3">None, </span><span class="s1">end=</span><span class="s3">None, </span><span class="s1">dynamic=</span><span class="s3">False,</span>
                       <span class="s1">information_set=</span><span class="s5">'predicted'</span><span class="s3">, </span><span class="s1">signal_only=</span><span class="s3">False,</span>
                       <span class="s1">original_scale=</span><span class="s3">True, </span><span class="s1">index=</span><span class="s3">None, </span><span class="s1">exog=</span><span class="s3">None,</span>
                       <span class="s1">extend_model=</span><span class="s3">None, </span><span class="s1">extend_kwargs=</span><span class="s3">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">r&quot;&quot;&quot; 
        In-sample prediction and out-of-sample forecasting. 
 
        Parameters 
        ---------- 
        start : int, str, or datetime, optional 
            Zero-indexed observation number at which to start forecasting, 
            i.e., the first forecast is start. Can also be a date string to 
            parse or a datetime type. Default is the the zeroth observation. 
        end : int, str, or datetime, optional 
            Zero-indexed observation number at which to end forecasting, i.e., 
            the last forecast is end. Can also be a date string to 
            parse or a datetime type. However, if the dates index does not 
            have a fixed frequency, end must be an integer index if you 
            want out of sample prediction. Default is the last observation in 
            the sample. 
        dynamic : bool, int, str, or datetime, optional 
            Integer offset relative to `start` at which to begin dynamic 
            prediction. Can also be an absolute date string to parse or a 
            datetime type (these are not interpreted as offsets). 
            Prior to this observation, true endogenous values will be used for 
            prediction; starting with this observation and continuing through 
            the end of prediction, forecasted endogenous values will be used 
            instead. 
        information_set : str, optional 
            The information set to condition each prediction on. Default is 
            &quot;predicted&quot;, which computes predictions of period t values 
            conditional on observed data through period t-1; these are 
            one-step-ahead predictions, and correspond with the typical 
            `fittedvalues` results attribute. Alternatives are &quot;filtered&quot;, 
            which computes predictions of period t values conditional on 
            observed data through period t, and &quot;smoothed&quot;, which computes 
            predictions of period t values conditional on the entire dataset 
            (including also future observations t+1, t+2, ...). 
        signal_only : bool, optional 
            Whether to compute forecasts of only the &quot;signal&quot; component of 
            the observation equation. Default is False. For example, the 
            observation equation of a time-invariant model is 
            :math:`y_t = d + Z \alpha_t + \varepsilon_t`, and the &quot;signal&quot; 
            component is then :math:`Z \alpha_t`. If this argument is set to 
            True, then forecasts of the &quot;signal&quot; :math:`Z \alpha_t` will be 
            returned. Otherwise, the default is for forecasts of :math:`y_t` 
            to be returned. 
        original_scale : bool, optional 
            If the model specification standardized the data, whether or not 
            to return predictions in the original scale of the data (i.e. 
            before it was standardized by the model). Default is True. 
        **kwargs 
            Additional arguments may required for forecasting beyond the end 
            of the sample. See `FilterResults.predict` for more details. 
 
        Returns 
        ------- 
        forecast : ndarray 
            Array of out of in-sample predictions and / or out-of-sample 
            forecasts. An (npredict x k_endog) array. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Get usual predictions (in the possibly-standardized scale)</span>
        <span class="s1">res = super().get_prediction(start=start</span><span class="s3">, </span><span class="s1">end=end</span><span class="s3">, </span><span class="s1">dynamic=dynamic</span><span class="s3">,</span>
                                     <span class="s1">information_set=information_set</span><span class="s3">,</span>
                                     <span class="s1">signal_only=signal_only</span><span class="s3">,</span>
                                     <span class="s1">index=index</span><span class="s3">, </span><span class="s1">exog=exog</span><span class="s3">,</span>
                                     <span class="s1">extend_model=extend_model</span><span class="s3">,</span>
                                     <span class="s1">extend_kwargs=extend_kwargs</span><span class="s3">, </span><span class="s1">**kwargs)</span>

        <span class="s0"># If applicable, convert predictions back to original space</span>
        <span class="s3">if </span><span class="s1">self.model.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">prediction_results = res.prediction_results</span>
            <span class="s1">k_endog</span><span class="s3">, </span><span class="s1">_ = prediction_results.endog.shape</span>

            <span class="s1">mean = np.array(self.model._endog_mean)</span>
            <span class="s1">std = np.array(self.model._endog_std)</span>

            <span class="s3">if </span><span class="s1">self.model.k_endog &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">mean = mean[</span><span class="s3">None, </span><span class="s1">:]</span>
                <span class="s1">std = std[</span><span class="s3">None, </span><span class="s1">:]</span>

            <span class="s1">res._results._predicted_mean = (</span>
                <span class="s1">res._results._predicted_mean * std + mean)</span>

            <span class="s3">if </span><span class="s1">k_endog == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">res._results._var_pred_mean *= std**</span><span class="s4">2</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">res._results._var_pred_mean = (</span>
                    <span class="s1">std * res._results._var_pred_mean * std.T)</span>

        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">news(self</span><span class="s3">, </span><span class="s1">comparison</span><span class="s3">, </span><span class="s1">impact_date=</span><span class="s3">None, </span><span class="s1">impacted_variable=</span><span class="s3">None,</span>
             <span class="s1">start=</span><span class="s3">None, </span><span class="s1">end=</span><span class="s3">None, </span><span class="s1">periods=</span><span class="s3">None, </span><span class="s1">exog=</span><span class="s3">None,</span>
             <span class="s1">comparison_type=</span><span class="s3">None, </span><span class="s1">state_index=</span><span class="s3">None, </span><span class="s1">return_raw=</span><span class="s3">False,</span>
             <span class="s1">tolerance=</span><span class="s4">1e-10</span><span class="s3">, </span><span class="s1">endog_quarterly=</span><span class="s3">None, </span><span class="s1">original_scale=</span><span class="s3">True,</span>
             <span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute impacts from updated data (news and revisions). 
 
        Parameters 
        ---------- 
        comparison : array_like or MLEResults 
            An updated dataset with updated and/or revised data from which the 
            news can be computed, or an updated or previous results object 
            to use in computing the news. 
        impact_date : int, str, or datetime, optional 
            A single specific period of impacts from news and revisions to 
            compute. Can also be a date string to parse or a datetime type. 
            This argument cannot be used in combination with `start`, `end`, or 
            `periods`. Default is the first out-of-sample observation. 
        impacted_variable : str, list, array, or slice, optional 
            Observation variable label or slice of labels specifying that only 
            specific impacted variables should be shown in the News output. The 
            impacted variable(s) describe the variables that were *affected* by 
            the news. If you do not know the labels for the variables, check 
            the `endog_names` attribute of the model instance. 
        start : int, str, or datetime, optional 
            The first period of impacts from news and revisions to compute. 
            Can also be a date string to parse or a datetime type. Default is 
            the first out-of-sample observation. 
        end : int, str, or datetime, optional 
            The last period of impacts from news and revisions to compute. 
            Can also be a date string to parse or a datetime type. Default is 
            the first out-of-sample observation. 
        periods : int, optional 
            The number of periods of impacts from news and revisions to 
            compute. 
        exog : array_like, optional 
            Array of exogenous regressors for the out-of-sample period, if 
            applicable. 
        comparison_type : {None, 'previous', 'updated'} 
            This denotes whether the `comparison` argument represents a 
            *previous* results object or dataset or an *updated* results object 
            or dataset. If not specified, then an attempt is made to determine 
            the comparison type. 
        state_index : array_like or &quot;common&quot;, optional 
            An optional index specifying a subset of states to use when 
            constructing the impacts of revisions and news. For example, if 
            `state_index=[0, 1]` is passed, then only the impacts to the 
            observed variables arising from the impacts to the first two 
            states will be returned. If the string &quot;common&quot; is passed and the 
            model includes idiosyncratic AR(1) components, news will only be 
            computed based on the common states. Default is to use all states. 
        return_raw : bool, optional 
            Whether or not to return only the specific output or a full 
            results object. Default is to return a full results object. 
        tolerance : float, optional 
            The numerical threshold for determining zero impact. Default is 
            that any impact less than 1e-10 is assumed to be zero. 
        endog_quarterly : array_like, optional 
            New observations of quarterly variables, if `comparison` was 
            provided as an updated monthly dataset. If this argument is 
            provided, it must be a Pandas Series or DataFrame with a 
            DatetimeIndex or PeriodIndex at the quarterly frequency. 
 
        References 
        ---------- 
        .. [1] Bańbura, Marta, and Michele Modugno. 
               &quot;Maximum likelihood estimation of factor models on datasets with 
               arbitrary pattern of missing data.&quot; 
               Journal of Applied Econometrics 29, no. 1 (2014): 133-160. 
        .. [2] Bańbura, Marta, Domenico Giannone, and Lucrezia Reichlin. 
               &quot;Nowcasting.&quot; 
               The Oxford Handbook of Economic Forecasting. July 8, 2011. 
        .. [3] Bańbura, Marta, Domenico Giannone, Michele Modugno, and Lucrezia 
               Reichlin. 
               &quot;Now-casting and the real-time data flow.&quot; 
               In Handbook of economic forecasting, vol. 2, pp. 195-237. 
               Elsevier, 2013. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">state_index == </span><span class="s5">'common'</span><span class="s1">:</span>
            <span class="s1">state_index = (</span>
                <span class="s1">np.arange(self.model.k_states - self.model.k_endog))</span>

        <span class="s1">news_results = super().news(</span>
            <span class="s1">comparison</span><span class="s3">, </span><span class="s1">impact_date=impact_date</span><span class="s3">,</span>
            <span class="s1">impacted_variable=impacted_variable</span><span class="s3">, </span><span class="s1">start=start</span><span class="s3">, </span><span class="s1">end=end</span><span class="s3">,</span>
            <span class="s1">periods=periods</span><span class="s3">, </span><span class="s1">exog=exog</span><span class="s3">, </span><span class="s1">comparison_type=comparison_type</span><span class="s3">,</span>
            <span class="s1">state_index=state_index</span><span class="s3">, </span><span class="s1">return_raw=return_raw</span><span class="s3">,</span>
            <span class="s1">tolerance=tolerance</span><span class="s3">, </span><span class="s1">endog_quarterly=endog_quarterly</span><span class="s3">, </span><span class="s1">**kwargs)</span>

        <span class="s0"># If we have standardized the data, we may want to report the news in</span>
        <span class="s0"># the original scale. If so, we need to modify the data to &quot;undo&quot; the</span>
        <span class="s0"># standardization.</span>
        <span class="s3">if not </span><span class="s1">return_raw </span><span class="s3">and </span><span class="s1">self.model.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">endog_mean = self.model._endog_mean</span>
            <span class="s1">endog_std = self.model._endog_std</span>

            <span class="s0"># Don't need to add in the mean for the impacts, since they are</span>
            <span class="s0"># the difference of two forecasts</span>
            <span class="s1">news_results.total_impacts = (</span>
                <span class="s1">news_results.total_impacts * endog_std)</span>
            <span class="s1">news_results.update_impacts = (</span>
                <span class="s1">news_results.update_impacts * endog_std)</span>
            <span class="s3">if </span><span class="s1">news_results.revision_impacts </span><span class="s3">is not None</span><span class="s1">:</span>
                <span class="s1">news_results.revision_impacts = (</span>
                    <span class="s1">news_results.revision_impacts * endog_std)</span>

            <span class="s0"># Update forecasts</span>
            <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">[</span><span class="s5">'prev_impacted_forecasts'</span><span class="s3">, </span><span class="s5">'news'</span><span class="s3">, </span><span class="s5">'revisions'</span><span class="s3">,</span>
                         <span class="s5">'update_realized'</span><span class="s3">, </span><span class="s5">'update_forecasts'</span><span class="s3">,</span>
                         <span class="s5">'revised'</span><span class="s3">, </span><span class="s5">'revised_prev'</span><span class="s3">, </span><span class="s5">'post_impacted_forecasts'</span><span class="s1">]:</span>
                <span class="s1">dta = getattr(news_results</span><span class="s3">, </span><span class="s1">name)</span>

                <span class="s0"># for pd.Series, dta.multiply(...) and (sometimes) dta.add(...)</span>
                <span class="s0"># remove the name attribute; save it now so that we can add it</span>
                <span class="s0"># back in</span>
                <span class="s1">orig_name = </span><span class="s3">None</span>
                <span class="s3">if </span><span class="s1">hasattr(dta</span><span class="s3">, </span><span class="s5">'name'</span><span class="s1">):</span>
                    <span class="s1">orig_name = dta.name</span>

                <span class="s1">dta = dta.multiply(endog_std</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">)</span>

                <span class="s3">if </span><span class="s1">name </span><span class="s3">not in </span><span class="s1">[</span><span class="s5">'news'</span><span class="s3">, </span><span class="s5">'revisions'</span><span class="s1">]:</span>
                    <span class="s1">dta = dta.add(endog_mean</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">)</span>

                <span class="s0"># add back in the name attribute if it was removed</span>
                <span class="s3">if </span><span class="s1">orig_name </span><span class="s3">is not None</span><span class="s1">:</span>
                    <span class="s1">dta.name = orig_name</span>

                <span class="s1">setattr(news_results</span><span class="s3">, </span><span class="s1">name</span><span class="s3">, </span><span class="s1">dta)</span>

            <span class="s0"># For the weights: rows correspond to update (date, variable) and</span>
            <span class="s0"># columns correspond to the impacted variable.</span>
            <span class="s0"># 1. Because we have modified the updates (realized, forecasts, and</span>
            <span class="s0">#    forecast errors) to be in the scale of the original updated</span>
            <span class="s0">#    variable, we need to essentially reverse that change for each</span>
            <span class="s0">#    row of the weights by dividing by the standard deviation of</span>
            <span class="s0">#    that row's updated variable</span>
            <span class="s0"># 2. Because we want the impacts to be in the scale of the original</span>
            <span class="s0">#    impacted variable, we need to multiply each column by the</span>
            <span class="s0">#    standard deviation of that column's impacted variable</span>
            <span class="s1">news_results.weights = (</span>
                <span class="s1">news_results.weights.divide(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">)</span>
                                    <span class="s1">.multiply(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">))</span>
            <span class="s1">news_results.revision_weights = (</span>
                <span class="s1">news_results.revision_weights</span>
                            <span class="s1">.divide(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">)</span>
                            <span class="s1">.multiply(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">1</span><span class="s1">))</span>

        <span class="s3">return </span><span class="s1">news_results</span>

    <span class="s3">def </span><span class="s1">get_smoothed_decomposition(self</span><span class="s3">, </span><span class="s1">decomposition_of=</span><span class="s5">'smoothed_state'</span><span class="s3">,</span>
                                   <span class="s1">state_index=</span><span class="s3">None, </span><span class="s1">original_scale=</span><span class="s3">True</span><span class="s1">):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Decompose smoothed output into contributions from observations 
 
        Parameters 
        ---------- 
        decomposition_of : {&quot;smoothed_state&quot;, &quot;smoothed_signal&quot;} 
            The object to perform a decomposition of. If it is set to 
            &quot;smoothed_state&quot;, then the elements of the smoothed state vector 
            are decomposed into the contributions of each observation. If it 
            is set to &quot;smoothed_signal&quot;, then the predictions of the 
            observation vector based on the smoothed state vector are 
            decomposed. Default is &quot;smoothed_state&quot;. 
        state_index : array_like, optional 
            An optional index specifying a subset of states to use when 
            constructing the decomposition of the &quot;smoothed_signal&quot;. For 
            example, if `state_index=[0, 1]` is passed, then only the 
            contributions of observed variables to the smoothed signal arising 
            from the first two states will be returned. Note that if not all 
            states are used, the contributions will not sum to the smoothed 
            signal. Default is to use all states. 
        original_scale : bool, optional 
            If the model specification standardized the data, whether or not 
            to return simulations in the original scale of the data (i.e. 
            before it was standardized by the model). Default is True. 
 
        Returns 
        ------- 
        data_contributions : pd.DataFrame 
            Contributions of observations to the decomposed object. If the 
            smoothed state is being decomposed, then `data_contributions` is 
            shaped `(k_states x nobs, k_endog x nobs)` with a `pd.MultiIndex` 
            index corresponding to `state_to x date_to` and `pd.MultiIndex` 
            columns corresponding to `variable_from x date_from`. If the 
            smoothed signal is being decomposed, then `data_contributions` is 
            shaped `(k_endog x nobs, k_endog x nobs)` with `pd.MultiIndex`-es 
            corresponding to `variable_to x date_to` and 
            `variable_from x date_from`. 
        obs_intercept_contributions : pd.DataFrame 
            Contributions of the observation intercept to the decomposed 
            object. If the smoothed state is being decomposed, then 
            `obs_intercept_contributions` is 
            shaped `(k_states x nobs, k_endog x nobs)` with a `pd.MultiIndex` 
            index corresponding to `state_to x date_to` and `pd.MultiIndex` 
            columns corresponding to `obs_intercept_from x date_from`. If the 
            smoothed signal is being decomposed, then 
            `obs_intercept_contributions` is shaped 
            `(k_endog x nobs, k_endog x nobs)` with `pd.MultiIndex`-es 
            corresponding to `variable_to x date_to` and 
            `obs_intercept_from x date_from`. 
        state_intercept_contributions : pd.DataFrame 
            Contributions of the state intercept to the decomposed 
            object. If the smoothed state is being decomposed, then 
            `state_intercept_contributions` is 
            shaped `(k_states x nobs, k_states x nobs)` with a `pd.MultiIndex` 
            index corresponding to `state_to x date_to` and `pd.MultiIndex` 
            columns corresponding to `state_intercept_from x date_from`. If the 
            smoothed signal is being decomposed, then 
            `state_intercept_contributions` is shaped 
            `(k_endog x nobs, k_states x nobs)` with `pd.MultiIndex`-es 
            corresponding to `variable_to x date_to` and 
            `state_intercept_from x date_from`. 
        prior_contributions : pd.DataFrame 
            Contributions of the prior to the decomposed object. If the 
            smoothed state is being decomposed, then `prior_contributions` is 
            shaped `(nobs x k_states, k_states)`, with a `pd.MultiIndex` 
            index corresponding to `state_to x date_to` and columns 
            corresponding to elements of the prior mean (aka &quot;initial state&quot;). 
            If the smoothed signal is being decomposed, then 
            `prior_contributions` is shaped `(nobs x k_endog, k_states)`, 
            with a `pd.MultiIndex` index corresponding to 
            `variable_to x date_to` and columns corresponding to elements of 
            the prior mean. 
 
        Notes 
        ----- 
        Denote the smoothed state at time :math:`t` by :math:`\alpha_t`. Then 
        the smoothed signal is :math:`Z_t \alpha_t`, where :math:`Z_t` is the 
        design matrix operative at time :math:`t`. 
        &quot;&quot;&quot;</span>
        <span class="s0"># De-meaning the data is like putting the mean into the observation</span>
        <span class="s0"># intercept. To compute the decomposition correctly in the original</span>
        <span class="s0"># scale, we need to account for this, so we fill in the observation</span>
        <span class="s0"># intercept temporarily</span>
        <span class="s3">if </span><span class="s1">self.model.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">cache_obs_intercept = self.model[</span><span class="s5">'obs_intercept'</span><span class="s1">]</span>
            <span class="s1">self.model[</span><span class="s5">'obs_intercept'</span><span class="s1">] = self.model._endog_mean</span>

        <span class="s0"># Compute the contributions</span>
        <span class="s1">(data_contributions</span><span class="s3">, </span><span class="s1">obs_intercept_contributions</span><span class="s3">,</span>
         <span class="s1">state_intercept_contributions</span><span class="s3">, </span><span class="s1">prior_contributions) = (</span>
            <span class="s1">super().get_smoothed_decomposition(</span>
                <span class="s1">decomposition_of=decomposition_of</span><span class="s3">, </span><span class="s1">state_index=state_index))</span>

        <span class="s0"># Replace the original observation intercept</span>
        <span class="s3">if </span><span class="s1">self.model.standardize </span><span class="s3">and </span><span class="s1">original_scale:</span>
            <span class="s1">self.model[</span><span class="s5">'obs_intercept'</span><span class="s1">] = cache_obs_intercept</span>

        <span class="s0"># Reverse the effect of dividing by the standard deviation</span>
        <span class="s3">if </span><span class="s1">(decomposition_of == </span><span class="s5">'smoothed_signal'</span>
                <span class="s3">and </span><span class="s1">self.model.standardize </span><span class="s3">and </span><span class="s1">original_scale):</span>
            <span class="s1">endog_std = self.model._endog_std</span>

            <span class="s1">data_contributions = (</span>
                <span class="s1">data_contributions.multiply(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">))</span>
            <span class="s1">obs_intercept_contributions = (</span>
                <span class="s1">obs_intercept_contributions.multiply(</span>
                    <span class="s1">endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">))</span>
            <span class="s1">state_intercept_contributions = (</span>
                <span class="s1">state_intercept_contributions.multiply(</span>
                    <span class="s1">endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">))</span>
            <span class="s1">prior_contributions = (</span>
                <span class="s1">prior_contributions.multiply(endog_std</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">level=</span><span class="s4">0</span><span class="s1">))</span>

        <span class="s3">return </span><span class="s1">(data_contributions</span><span class="s3">, </span><span class="s1">obs_intercept_contributions</span><span class="s3">,</span>
                <span class="s1">state_intercept_contributions</span><span class="s3">, </span><span class="s1">prior_contributions)</span>

    <span class="s3">def </span><span class="s1">append(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_quarterly=</span><span class="s3">None, </span><span class="s1">refit=</span><span class="s3">False, </span><span class="s1">fit_kwargs=</span><span class="s3">None,</span>
               <span class="s1">copy_initialization=</span><span class="s3">True, </span><span class="s1">retain_standardization=</span><span class="s3">True,</span>
               <span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Recreate the results object with new data appended to original data. 
 
        Creates a new result object applied to a dataset that is created by 
        appending new data to the end of the model's original data. The new 
        results can then be used for analysis or forecasting. 
 
        Parameters 
        ---------- 
        endog : array_like 
            New observations from the modeled time-series process. 
        endog_quarterly : array_like, optional 
            New observations of quarterly variables. If provided, must be a 
            Pandas Series or DataFrame with a DatetimeIndex or PeriodIndex at 
            the quarterly frequency. 
        refit : bool, optional 
            Whether to re-fit the parameters, based on the combined dataset. 
            Default is False (so parameters from the current results object 
            are used to create the new results object). 
        fit_kwargs : dict, optional 
            Keyword arguments to pass to `fit` (if `refit=True`) or `filter` / 
            `smooth`. 
        copy_initialization : bool, optional 
            Whether or not to copy the initialization from the current results 
            set to the new model. Default is True. 
        retain_standardization : bool, optional 
            Whether or not to use the mean and standard deviations that were 
            used to standardize the data in the current model in the new model. 
            Default is True. 
        **kwargs 
            Keyword arguments may be used to modify model specification 
            arguments when created the new model object. 
 
        Returns 
        ------- 
        results 
            Updated Results object, that includes results from both the 
            original dataset and the new dataset. 
 
        Notes 
        ----- 
        The `endog` and `exog` arguments to this method must be formatted in 
        the same way (e.g. Pandas Series versus Numpy array) as were the 
        `endog` and `exog` arrays passed to the original model. 
 
        The `endog` (and, if applicable, `endog_quarterly`) arguments to this 
        method should consist of new observations that occurred directly after 
        the last element of `endog`. For any other kind of dataset, see the 
        `apply` method. 
 
        This method will apply filtering to all of the original data as well 
        as to the new data. To apply filtering only to the new data (which 
        can be much faster if the original dataset is large), see the `extend` 
        method. 
 
        See Also 
        -------- 
        extend 
        apply 
        &quot;&quot;&quot;</span>
        <span class="s0"># Construct the combined dataset, if necessary</span>
        <span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly = DynamicFactorMQ.construct_endog(</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_quarterly)</span>

        <span class="s0"># Check for compatible dimensions</span>
        <span class="s1">k_endog = endog.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">len(endog.shape) == </span><span class="s4">2 </span><span class="s3">else </span><span class="s4">1</span>
        <span class="s3">if </span><span class="s1">(k_endog_monthly != self.model.k_endog_M </span><span class="s3">or</span>
                <span class="s1">k_endog != self.model.k_endog):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Cannot append data of a different dimension to'</span>
                             <span class="s5">' a model.'</span><span class="s1">)</span>

        <span class="s1">kwargs[</span><span class="s5">'k_endog_monthly'</span><span class="s1">] = k_endog_monthly</span>

        <span class="s3">return </span><span class="s1">super().append(</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">refit=refit</span><span class="s3">, </span><span class="s1">fit_kwargs=fit_kwargs</span><span class="s3">,</span>
            <span class="s1">copy_initialization=copy_initialization</span><span class="s3">,</span>
            <span class="s1">retain_standardization=retain_standardization</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s3">def </span><span class="s1">extend(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_quarterly=</span><span class="s3">None, </span><span class="s1">fit_kwargs=</span><span class="s3">None,</span>
               <span class="s1">retain_standardization=</span><span class="s3">True, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Recreate the results object for new data that extends original data. 
 
        Creates a new result object applied to a new dataset that is assumed to 
        follow directly from the end of the model's original data. The new 
        results can then be used for analysis or forecasting. 
 
        Parameters 
        ---------- 
        endog : array_like 
            New observations from the modeled time-series process. 
        endog_quarterly : array_like, optional 
            New observations of quarterly variables. If provided, must be a 
            Pandas Series or DataFrame with a DatetimeIndex or PeriodIndex at 
            the quarterly frequency. 
        fit_kwargs : dict, optional 
            Keyword arguments to pass to `filter` or `smooth`. 
        retain_standardization : bool, optional 
            Whether or not to use the mean and standard deviations that were 
            used to standardize the data in the current model in the new model. 
            Default is True. 
        **kwargs 
            Keyword arguments may be used to modify model specification 
            arguments when created the new model object. 
 
        Returns 
        ------- 
        results 
            Updated Results object, that includes results only for the new 
            dataset. 
 
        See Also 
        -------- 
        append 
        apply 
 
        Notes 
        ----- 
        The `endog` argument to this method should consist of new observations 
        that occurred directly after the last element of the model's original 
        `endog` array. For any other kind of dataset, see the `apply` method. 
 
        This method will apply filtering only to the new data provided by the 
        `endog` argument, which can be much faster than re-filtering the entire 
        dataset. However, the returned results object will only have results 
        for the new data. To retrieve results for both the new data and the 
        original data, see the `append` method. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Construct the combined dataset, if necessary</span>
        <span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly = DynamicFactorMQ.construct_endog(</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">endog_quarterly)</span>

        <span class="s0"># Check for compatible dimensions</span>
        <span class="s1">k_endog = endog.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">len(endog.shape) == </span><span class="s4">2 </span><span class="s3">else </span><span class="s4">1</span>
        <span class="s3">if </span><span class="s1">(k_endog_monthly != self.model.k_endog_M </span><span class="s3">or</span>
                <span class="s1">k_endog != self.model.k_endog):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'Cannot append data of a different dimension to'</span>
                             <span class="s5">' a model.'</span><span class="s1">)</span>

        <span class="s1">kwargs[</span><span class="s5">'k_endog_monthly'</span><span class="s1">] = k_endog_monthly</span>
        <span class="s3">return </span><span class="s1">super().extend(</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">fit_kwargs=fit_kwargs</span><span class="s3">,</span>
            <span class="s1">retain_standardization=retain_standardization</span><span class="s3">, </span><span class="s1">**kwargs)</span>

    <span class="s3">def </span><span class="s1">apply(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">k_endog_monthly=</span><span class="s3">None, </span><span class="s1">endog_quarterly=</span><span class="s3">None,</span>
              <span class="s1">refit=</span><span class="s3">False, </span><span class="s1">fit_kwargs=</span><span class="s3">None, </span><span class="s1">copy_initialization=</span><span class="s3">False,</span>
              <span class="s1">retain_standardization=</span><span class="s3">True, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot; 
        Apply the fitted parameters to new data unrelated to the original data. 
 
        Creates a new result object using the current fitted parameters, 
        applied to a completely new dataset that is assumed to be unrelated to 
        the model's original data. The new results can then be used for 
        analysis or forecasting. 
 
        Parameters 
        ---------- 
        endog : array_like 
            New observations from the modeled time-series process. 
        k_endog_monthly : int, optional 
            If specifying a monthly/quarterly mixed frequency model in which 
            the provided `endog` dataset contains both the monthly and 
            quarterly data, this variable should be used to indicate how many 
            of the variables are monthly. 
        endog_quarterly : array_like, optional 
            New observations of quarterly variables. If provided, must be a 
            Pandas Series or DataFrame with a DatetimeIndex or PeriodIndex at 
            the quarterly frequency. 
        refit : bool, optional 
            Whether to re-fit the parameters, using the new dataset. 
            Default is False (so parameters from the current results object 
            are used to create the new results object). 
        fit_kwargs : dict, optional 
            Keyword arguments to pass to `fit` (if `refit=True`) or `filter` / 
            `smooth`. 
        copy_initialization : bool, optional 
            Whether or not to copy the initialization from the current results 
            set to the new model. Default is False. 
        retain_standardization : bool, optional 
            Whether or not to use the mean and standard deviations that were 
            used to standardize the data in the current model in the new model. 
            Default is True. 
        **kwargs 
            Keyword arguments may be used to modify model specification 
            arguments when created the new model object. 
 
        Returns 
        ------- 
        results 
            Updated Results object, that includes results only for the new 
            dataset. 
 
        See Also 
        -------- 
        statsmodels.tsa.statespace.mlemodel.MLEResults.append 
        statsmodels.tsa.statespace.mlemodel.MLEResults.apply 
 
        Notes 
        ----- 
        The `endog` argument to this method should consist of new observations 
        that are not necessarily related to the original model's `endog` 
        dataset. For observations that continue that original dataset by follow 
        directly after its last element, see the `append` and `extend` methods. 
        &quot;&quot;&quot;</span>
        <span class="s1">mod = self.model.clone(endog</span><span class="s3">, </span><span class="s1">k_endog_monthly=k_endog_monthly</span><span class="s3">,</span>
                               <span class="s1">endog_quarterly=endog_quarterly</span><span class="s3">,</span>
                               <span class="s1">retain_standardization=retain_standardization</span><span class="s3">,</span>
                               <span class="s1">**kwargs)</span>
        <span class="s3">if </span><span class="s1">copy_initialization:</span>
            <span class="s1">init = initialization.Initialization.from_results(</span>
                <span class="s1">self.filter_results)</span>
            <span class="s1">mod.ssm.initialization = init</span>

        <span class="s1">res = self._apply(mod</span><span class="s3">, </span><span class="s1">refit=refit</span><span class="s3">, </span><span class="s1">fit_kwargs=fit_kwargs)</span>

        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">summary(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">.05</span><span class="s3">, </span><span class="s1">start=</span><span class="s3">None, </span><span class="s1">title=</span><span class="s3">None, </span><span class="s1">model_name=</span><span class="s3">None,</span>
                <span class="s1">display_params=</span><span class="s3">True, </span><span class="s1">display_diagnostics=</span><span class="s3">False,</span>
                <span class="s1">display_params_as_list=</span><span class="s3">False, </span><span class="s1">truncate_endog_names=</span><span class="s3">None,</span>
                <span class="s1">display_max_endog=</span><span class="s4">3</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Summarize the Model. 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            Significance level for the confidence intervals. Default is 0.05. 
        start : int, optional 
            Integer of the start observation. Default is 0. 
        title : str, optional 
            The title used for the summary table. 
        model_name : str, optional 
            The name of the model used. Default is to use model class name. 
 
        Returns 
        ------- 
        summary : Summary instance 
            This holds the summary table and text, which can be printed or 
            converted to various output formats. 
 
        See Also 
        -------- 
        statsmodels.iolib.summary.Summary 
        &quot;&quot;&quot;</span>
        <span class="s1">mod = self.model</span>

        <span class="s0"># Default title / model name</span>
        <span class="s3">if </span><span class="s1">title </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">title = </span><span class="s5">'Dynamic Factor Results'</span>
        <span class="s3">if </span><span class="s1">model_name </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">model_name = self.model._model_name</span>

        <span class="s0"># Get endog names</span>
        <span class="s1">endog_names = self.model._get_endog_names(</span>
            <span class="s1">truncate=truncate_endog_names)</span>

        <span class="s0"># Get extra elements for top summary table</span>
        <span class="s1">extra_top_left = </span><span class="s3">None</span>
        <span class="s1">extra_top_right = []</span>
        <span class="s1">mle_retvals = getattr(self</span><span class="s3">, </span><span class="s5">'mle_retvals'</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s1">mle_settings = getattr(self</span><span class="s3">, </span><span class="s5">'mle_settings'</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">mle_settings </span><span class="s3">is not None and </span><span class="s1">mle_settings.method == </span><span class="s5">'em'</span><span class="s1">:</span>
            <span class="s1">extra_top_right += [(</span><span class="s5">'EM Iterations'</span><span class="s3">, </span><span class="s1">[</span><span class="s5">f'</span><span class="s3">{</span><span class="s1">mle_retvals.iter</span><span class="s3">}</span><span class="s5">'</span><span class="s1">])]</span>

        <span class="s0"># Get the basic summary tables</span>
        <span class="s1">summary = super().summary(</span>
            <span class="s1">alpha=alpha</span><span class="s3">, </span><span class="s1">start=start</span><span class="s3">, </span><span class="s1">title=title</span><span class="s3">, </span><span class="s1">model_name=model_name</span><span class="s3">,</span>
            <span class="s1">display_params=(display_params </span><span class="s3">and </span><span class="s1">display_params_as_list)</span><span class="s3">,</span>
            <span class="s1">display_diagnostics=display_diagnostics</span><span class="s3">,</span>
            <span class="s1">truncate_endog_names=truncate_endog_names</span><span class="s3">,</span>
            <span class="s1">display_max_endog=display_max_endog</span><span class="s3">,</span>
            <span class="s1">extra_top_left=extra_top_left</span><span class="s3">, </span><span class="s1">extra_top_right=extra_top_right)</span>

        <span class="s0"># Get tables of parameters</span>
        <span class="s1">table_ix = </span><span class="s4">1</span>
        <span class="s3">if not </span><span class="s1">display_params_as_list:</span>

            <span class="s0"># Observation equation table</span>
            <span class="s1">data = pd.DataFrame(</span>
                <span class="s1">self.filter_results.design[:</span><span class="s3">, </span><span class="s1">mod._s[</span><span class="s5">'factors_L1'</span><span class="s1">]</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">index=endog_names</span><span class="s3">, </span><span class="s1">columns=mod.factor_names)</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">data = data.map(</span><span class="s3">lambda </span><span class="s1">s: </span><span class="s5">'%.2f' </span><span class="s1">% s)</span>
            <span class="s3">except </span><span class="s1">AttributeError:</span>
                <span class="s1">data = data.applymap(</span><span class="s3">lambda </span><span class="s1">s: </span><span class="s5">'%.2f' </span><span class="s1">% s)</span>

            <span class="s0"># Idiosyncratic terms</span>
            <span class="s0"># data['   '] = '   '</span>
            <span class="s1">k_idio = </span><span class="s4">1</span>
            <span class="s3">if </span><span class="s1">mod.idiosyncratic_ar1:</span>
                <span class="s1">data[</span><span class="s5">'   idiosyncratic: AR(1)'</span><span class="s1">] = (</span>
                    <span class="s1">self.params[mod._p[</span><span class="s5">'idiosyncratic_ar1'</span><span class="s1">]])</span>
                <span class="s1">k_idio += </span><span class="s4">1</span>
            <span class="s1">data[</span><span class="s5">'var.'</span><span class="s1">] = self.params[mod._p[</span><span class="s5">'idiosyncratic_var'</span><span class="s1">]]</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">data.iloc[:</span><span class="s3">, </span><span class="s1">-k_idio:] = data.iloc[:</span><span class="s3">, </span><span class="s1">-k_idio:].map(</span>
                    <span class="s3">lambda </span><span class="s1">s: </span><span class="s5">f'</span><span class="s3">{</span><span class="s1">s</span><span class="s3">:</span><span class="s5">.2f</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>
            <span class="s3">except </span><span class="s1">AttributeError:</span>
                <span class="s1">data.iloc[:</span><span class="s3">, </span><span class="s1">-k_idio:] = data.iloc[:</span><span class="s3">, </span><span class="s1">-k_idio:].applymap(</span>
                    <span class="s3">lambda </span><span class="s1">s: </span><span class="s5">f'</span><span class="s3">{</span><span class="s1">s</span><span class="s3">:</span><span class="s5">.2f</span><span class="s3">}</span><span class="s5">'</span><span class="s1">)</span>

            <span class="s1">data.index.name = </span><span class="s5">'Factor loadings:'</span>

            <span class="s0"># Clear entries for non-loading factors</span>
            <span class="s1">base_iloc = np.arange(mod.k_factors)</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(mod.k_endog):</span>
                <span class="s1">iloc = [j </span><span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">base_iloc</span>
                        <span class="s3">if </span><span class="s1">j </span><span class="s3">not in </span><span class="s1">mod._s.endog_factor_iloc[i]]</span>
                <span class="s1">data.iloc[i</span><span class="s3">, </span><span class="s1">iloc] = </span><span class="s5">'.'</span>

            <span class="s1">data = data.reset_index()</span>

            <span class="s0"># Build the table</span>
            <span class="s1">params_data = data.values</span>
            <span class="s1">params_header = data.columns.tolist()</span>
            <span class="s1">params_stubs = </span><span class="s3">None</span>

            <span class="s1">title = </span><span class="s5">'Observation equation:'</span>
            <span class="s1">table = SimpleTable(</span>
                <span class="s1">params_data</span><span class="s3">, </span><span class="s1">params_header</span><span class="s3">, </span><span class="s1">params_stubs</span><span class="s3">,</span>
                <span class="s1">txt_fmt=fmt_params</span><span class="s3">, </span><span class="s1">title=title)</span>
            <span class="s1">summary.tables.insert(table_ix</span><span class="s3">, </span><span class="s1">table)</span>
            <span class="s1">table_ix += </span><span class="s4">1</span>

            <span class="s0"># Factor transitions</span>
            <span class="s1">ix1 = </span><span class="s4">0</span>
            <span class="s1">ix2 = </span><span class="s4">0</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(len(mod._s.factor_blocks)):</span>
                <span class="s1">block = mod._s.factor_blocks[i]</span>
                <span class="s1">ix2 += block.k_factors</span>

                <span class="s1">T = self.filter_results.transition</span>
                <span class="s1">lag_names = []</span>
                <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(block.factor_order):</span>
                    <span class="s1">lag_names += [</span><span class="s5">f'L</span><span class="s3">{</span><span class="s1">j + </span><span class="s4">1</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">name</span><span class="s3">}</span><span class="s5">'</span>
                                  <span class="s3">for </span><span class="s1">name </span><span class="s3">in </span><span class="s1">block.factor_names]</span>
                <span class="s1">data = pd.DataFrame(T[block.factors_L1</span><span class="s3">, </span><span class="s1">block.factors_ar</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                                    <span class="s1">index=block.factor_names</span><span class="s3">,</span>
                                    <span class="s1">columns=lag_names)</span>
                <span class="s1">data.index.name = </span><span class="s5">''</span>
                <span class="s3">try</span><span class="s1">:</span>
                    <span class="s1">data = data.map(</span><span class="s3">lambda </span><span class="s1">s: </span><span class="s5">'%.2f' </span><span class="s1">% s)</span>
                <span class="s3">except </span><span class="s1">AttributeError:</span>
                    <span class="s1">data = data.applymap(</span><span class="s3">lambda </span><span class="s1">s: </span><span class="s5">'%.2f' </span><span class="s1">% s)</span>

                <span class="s1">Q = self.filter_results.state_cov</span>
                <span class="s0"># data[' '] = ''</span>
                <span class="s3">if </span><span class="s1">block.k_factors == </span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">data[</span><span class="s5">'   error variance'</span><span class="s1">] = Q[ix1</span><span class="s3">, </span><span class="s1">ix1]</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">data[</span><span class="s5">'   error covariance'</span><span class="s1">] = block.factor_names</span>
                    <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(block.k_factors):</span>
                        <span class="s1">data[block.factor_names[j]] = Q[ix1:ix2</span><span class="s3">, </span><span class="s1">ix1 + j]</span>
                <span class="s3">try</span><span class="s1">:</span>
                    <span class="s1">formatted_vals = data.iloc[:</span><span class="s3">, </span><span class="s1">-block.k_factors:].map(</span>
                        <span class="s3">lambda </span><span class="s1">s: </span><span class="s5">f'</span><span class="s3">{</span><span class="s1">s</span><span class="s3">:</span><span class="s5">.2f</span><span class="s3">}</span><span class="s5">'</span>
                    <span class="s1">)</span>
                <span class="s3">except </span><span class="s1">AttributeError:</span>
                    <span class="s1">formatted_vals = data.iloc[:</span><span class="s3">, </span><span class="s1">-block.k_factors:].applymap(</span>
                        <span class="s3">lambda </span><span class="s1">s: </span><span class="s5">f'</span><span class="s3">{</span><span class="s1">s</span><span class="s3">:</span><span class="s5">.2f</span><span class="s3">}</span><span class="s5">'</span>
                    <span class="s1">)</span>
                <span class="s1">data.iloc[:</span><span class="s3">, </span><span class="s1">-block.k_factors:] = formatted_vals</span>

                <span class="s1">data = data.reset_index()</span>

                <span class="s1">params_data = data.values</span>
                <span class="s1">params_header = data.columns.tolist()</span>
                <span class="s1">params_stubs = </span><span class="s3">None</span>

                <span class="s1">title = </span><span class="s5">f'Transition: Factor block </span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">'</span>
                <span class="s1">table = SimpleTable(</span>
                    <span class="s1">params_data</span><span class="s3">, </span><span class="s1">params_header</span><span class="s3">, </span><span class="s1">params_stubs</span><span class="s3">,</span>
                    <span class="s1">txt_fmt=fmt_params</span><span class="s3">, </span><span class="s1">title=title)</span>
                <span class="s1">summary.tables.insert(table_ix</span><span class="s3">, </span><span class="s1">table)</span>
                <span class="s1">table_ix += </span><span class="s4">1</span>

                <span class="s1">ix1 = ix2</span>

        <span class="s3">return </span><span class="s1">summary</span>
</pre>
</body>
</html>
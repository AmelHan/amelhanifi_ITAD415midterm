<html>
<head>
<title>diagnostic_gen.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
diagnostic_gen.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Tue Oct  6 12:42:11 2020 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span>

<span class="s3">from </span><span class="s1">statsmodels.stats.base </span><span class="s3">import </span><span class="s1">HolderTuple</span>
<span class="s3">from </span><span class="s1">statsmodels.stats.effect_size </span><span class="s3">import </span><span class="s1">_noncentrality_chisquare</span>


<span class="s3">def </span><span class="s1">test_chisquare_binning(counts</span><span class="s3">, </span><span class="s1">expected</span><span class="s3">, </span><span class="s1">sort_var=</span><span class="s3">None, </span><span class="s1">bins=</span><span class="s4">10</span><span class="s3">,</span>
                           <span class="s1">df=</span><span class="s3">None, </span><span class="s1">ordered=</span><span class="s3">False, </span><span class="s1">sort_method=</span><span class="s5">&quot;quicksort&quot;</span><span class="s3">,</span>
                           <span class="s1">alpha_nc=</span><span class="s4">0.05</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;chisquare gof test with binning of data, Hosmer-Lemeshow type 
 
    ``observed`` and ``expected`` are observation specific and should have 
    observations in rows and choices in columns 
 
    Parameters 
    ---------- 
    counts : array_like 
        Observed frequency, i.e. counts for all choices 
    expected : array_like 
        Expected counts or probability. If expected are counts, then they 
        need to sum to the same total count as the sum of observed. 
        If those sums are unequal and all expected values are smaller or equal 
        to 1, then they are interpreted as probabilities and will be rescaled 
        to match counts. 
    sort_var : array_like 
        1-dimensional array for binning. Groups will be formed according to 
        quantiles of the sorted array ``sort_var``, so that group sizes have 
        equal or approximately equal sizes. 
 
    Returns 
    ------- 
    Holdertuple instance 
        This instance contains the results of the chisquare test and some 
        information about the data 
 
        - statistic : chisquare statistic of the goodness-of-fit test 
        - pvalue : pvalue of the chisquare test 
        = df : degrees of freedom of the test 
 
    Notes 
    ----- 
    Degrees of freedom for Hosmer-Lemeshow tests are given by 
 
    g groups, c choices 
 
    - binary: `df = (g - 2)` for insample, 
         Stata uses `df = g` for outsample 
    - multinomial: `df = (g−2) *(c−1)`, reduces to (g-2) for binary c=2, 
         (Fagerland, Hosmer, Bofin SIM 2008) 
    - ordinal: `df = (g - 2) * (c - 1) + (c - 2)`, reduces to (g-2) for c=2, 
         (Hosmer, ... ?) 
 
    Note: If there are ties in the ``sort_var`` array, then the split of 
    observations into groups will depend on the sort algorithm. 
    &quot;&quot;&quot;</span>

    <span class="s1">observed = np.asarray(counts)</span>
    <span class="s1">expected = np.asarray(expected)</span>
    <span class="s1">n_observed = counts.sum()</span>
    <span class="s1">n_expected = expected.sum()</span>
    <span class="s3">if not </span><span class="s1">np.allclose(n_observed</span><span class="s3">, </span><span class="s1">n_expected</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-13</span><span class="s1">):</span>
        <span class="s3">if </span><span class="s1">np.max(expected) &lt; </span><span class="s4">1 </span><span class="s1">+ </span><span class="s4">1e-13</span><span class="s1">:</span>
            <span class="s0"># expected seems to be probability, warn and rescale</span>
            <span class="s3">import </span><span class="s1">warnings</span>
            <span class="s1">warnings.warn(</span><span class="s5">&quot;sum of expected and of observed differ, &quot;</span>
                          <span class="s5">&quot;rescaling ``expected``&quot;</span><span class="s1">)</span>
            <span class="s1">expected = expected / n_expected * n_observed</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s0"># expected doesn't look like fractions or probabilities</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;total counts of expected and observed differ&quot;</span><span class="s1">)</span>

    <span class="s0"># k = 1 if observed.ndim == 1 else observed.shape[1]</span>
    <span class="s3">if </span><span class="s1">sort_var </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">argsort = np.argsort(sort_var</span><span class="s3">, </span><span class="s1">kind=sort_method)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">argsort = np.arange(observed.shape[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s0"># indices = [arr for arr in np.array_split(argsort, bins, axis=0)]</span>
    <span class="s1">indices = np.array_split(argsort</span><span class="s3">, </span><span class="s1">bins</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s0"># in one loop, observed expected in last dimension, too messy,</span>
    <span class="s0"># freqs_probs = np.array([np.vstack([observed[idx].mean(0),</span>
    <span class="s0">#                                    expected[idx].mean(0)]).T</span>
    <span class="s0">#                         for idx in indices])</span>
    <span class="s1">freqs = np.array([observed[idx].sum(</span><span class="s4">0</span><span class="s1">) </span><span class="s3">for </span><span class="s1">idx </span><span class="s3">in </span><span class="s1">indices])</span>
    <span class="s1">probs = np.array([expected[idx].sum(</span><span class="s4">0</span><span class="s1">) </span><span class="s3">for </span><span class="s1">idx </span><span class="s3">in </span><span class="s1">indices])</span>

    <span class="s0"># chisquare test</span>
    <span class="s1">resid_pearson = (freqs - probs) / np.sqrt(probs)</span>
    <span class="s1">chi2_stat_groups = ((freqs - probs)**</span><span class="s4">2 </span><span class="s1">/ probs).sum(</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">chi2_stat = chi2_stat_groups.sum()</span>
    <span class="s3">if </span><span class="s1">df </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">g</span><span class="s3">, </span><span class="s1">c = freqs.shape</span>
        <span class="s3">if </span><span class="s1">ordered </span><span class="s3">is True</span><span class="s1">:</span>
            <span class="s1">df = (g - </span><span class="s4">2</span><span class="s1">) * (c - </span><span class="s4">1</span><span class="s1">) + (c - </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">df = (g - </span><span class="s4">2</span><span class="s1">) * (c - </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">pvalue = stats.chi2.sf(chi2_stat</span><span class="s3">, </span><span class="s1">df)</span>
    <span class="s1">noncentrality = _noncentrality_chisquare(chi2_stat</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">alpha=alpha_nc)</span>

    <span class="s1">res = HolderTuple(statistic=chi2_stat</span><span class="s3">,</span>
                      <span class="s1">pvalue=pvalue</span><span class="s3">,</span>
                      <span class="s1">df=df</span><span class="s3">,</span>
                      <span class="s1">freqs=freqs</span><span class="s3">,</span>
                      <span class="s1">probs=probs</span><span class="s3">,</span>
                      <span class="s1">noncentrality=noncentrality</span><span class="s3">,</span>
                      <span class="s1">resid_pearson=resid_pearson</span><span class="s3">,</span>
                      <span class="s1">chi2_stat_groups=chi2_stat_groups</span><span class="s3">,</span>
                      <span class="s1">indices=indices</span>
                      <span class="s1">)</span>
    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">prob_larger_ordinal_choice(prob):</span>
    <span class="s2">&quot;&quot;&quot;probability that observed category is larger than distribution prob 
 
    This is a helper function for Ordinal models, where endog is a 1-dim 
    categorical variable and predicted probabilities are 2-dimensional with 
    observations in rows and choices in columns. 
 
    Parameter 
    --------- 
    prob : array_like 
        Expected probabilities for ordinal choices, e.g. from prediction of 
        an ordinal model with observations in rows and choices in columns. 
 
    Returns 
    ------- 
    cdf_mid : ndarray 
        mid cdf, i.e ``P(x &lt; y) + 0.5 P(x=y)`` 
    r : ndarray 
        Probability residual ``P(x &gt; y) - P(x &lt; y)`` for all possible choices. 
        Computed as ``r = cdf_mid * 2 - 1`` 
 
    References 
    ---------- 
    .. [2] Li, Chun, and Bryan E. Shepherd. 2012. “A New Residual for Ordinal 
       Outcomes.” Biometrika 99 (2): 473–80. 
 
    See Also 
    -------- 
    `statsmodels.stats.nonparametric.rank_compare_2ordinal` 
 
    &quot;&quot;&quot;</span>
    <span class="s0"># similar to `nonparametric rank_compare_2ordinal`</span>

    <span class="s1">prob = np.asarray(prob)</span>
    <span class="s1">cdf = prob.cumsum(-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">cdf.ndim == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">cdf_ = np.concatenate(([</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">cdf))</span>
    <span class="s3">elif </span><span class="s1">cdf.ndim == </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s1">cdf_ = np.concatenate((np.zeros((len(cdf)</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span><span class="s3">, </span><span class="s1">cdf)</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0"># r_1 = cdf_[..., 1:] + cdf_[..., :-1] - 1</span>
    <span class="s1">cdf_mid = (cdf_[...</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:] + cdf_[...</span><span class="s3">, </span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]) / </span><span class="s4">2</span>
    <span class="s1">r = cdf_mid * </span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span>
    <span class="s3">return </span><span class="s1">cdf_mid</span><span class="s3">, </span><span class="s1">r</span>


<span class="s3">def </span><span class="s1">prob_larger_2ordinal(probs1</span><span class="s3">, </span><span class="s1">probs2):</span>
    <span class="s2">&quot;&quot;&quot;Stochastically large probability for two ordinal distributions 
 
    Computes Pr(x1 &gt; x2) + 0.5 * Pr(x1 = x2) for two ordered multinomial 
    (ordinal) distributed random variables x1 and x2. 
 
    This is vectorized with choices along last axis. 
    Broadcasting if freq2 is 1-dim also seems to work correctly. 
 
    Returns 
    ------- 
    prob1 : float 
        Probability that random draw from distribution 1 is larger than a 
        random draw from distribution 2. Pr(x1 &gt; x2) + 0.5 * Pr(x1 = x2) 
    prob2 : float 
        prob2 = 1 - prob1 = Pr(x1 &lt; x2) + 0.5 * Pr(x1 = x2) 
    &quot;&quot;&quot;</span>
<span class="s0">#    count1 = np.asarray(count1)</span>
<span class="s0">#    count2 = np.asarray(count2)</span>
<span class="s0">#    nobs1, nobs2 = count1.sum(), count2.sum()</span>
<span class="s0">#    freq1 = count1 / nobs1</span>
<span class="s0">#    freq2 = count2 / nobs2</span>

<span class="s0">#     if freq1.ndim == 1:</span>
<span class="s0">#         freq1_ = np.concatenate(([0], freq1))</span>
<span class="s0">#     elif freq1.ndim == 2:</span>
<span class="s0">#         freq1_ = np.concatenate((np.zeros((len(freq1), 1)), freq1), axis=1)</span>

<span class="s0">#     if freq2.ndim == 1:</span>
<span class="s0">#         freq2_ = np.concatenate(([0], freq2))</span>
<span class="s0">#     elif freq2.ndim == 2:</span>
<span class="s0">#         freq2_ = np.concatenate((np.zeros((len(freq2), 1)), freq2), axis=1)</span>

    <span class="s1">freq1 = np.asarray(probs1)</span>
    <span class="s1">freq2 = np.asarray(probs2)</span>
    <span class="s0"># add zero at beginning of choices for cdf computation</span>
    <span class="s1">freq1_ = np.concatenate((np.zeros(freq1.shape[:-</span><span class="s4">1</span><span class="s1">] + (</span><span class="s4">1</span><span class="s3">,</span><span class="s1">))</span><span class="s3">, </span><span class="s1">freq1)</span><span class="s3">,</span>
                            <span class="s1">axis=-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">freq2_ = np.concatenate((np.zeros(freq2.shape[:-</span><span class="s4">1</span><span class="s1">] + (</span><span class="s4">1</span><span class="s3">,</span><span class="s1">))</span><span class="s3">, </span><span class="s1">freq2)</span><span class="s3">,</span>
                            <span class="s1">axis=-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">cdf1 = freq1_.cumsum(axis=-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">cdf2 = freq2_.cumsum(axis=-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s0"># mid rank cdf</span>
    <span class="s1">cdfm1 = (cdf1[...</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:] + cdf1[...</span><span class="s3">, </span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]) / </span><span class="s4">2</span>
    <span class="s1">cdfm2 = (cdf2[...</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:] + cdf2[...</span><span class="s3">, </span><span class="s1">:-</span><span class="s4">1</span><span class="s1">]) / </span><span class="s4">2</span>
    <span class="s1">prob1 = (cdfm2 * freq1).sum(-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">prob2 = (cdfm1 * freq2).sum(-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">prob1</span><span class="s3">, </span><span class="s1">prob2</span>


<span class="s3">def </span><span class="s1">cov_multinomial(probs):</span>
    <span class="s2">&quot;&quot;&quot;covariance matrix of multinomial distribution 
 
    This is vectorized with choices along last axis. 
 
    cov = diag(probs) - outer(probs, probs) 
 
    &quot;&quot;&quot;</span>

    <span class="s1">k = probs.shape[-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">di = np.diag_indices(k</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">cov = probs[...</span><span class="s3">, None</span><span class="s1">] * probs[...</span><span class="s3">, None, </span><span class="s1">:]</span>
    <span class="s1">cov *= - </span><span class="s4">1</span>
    <span class="s1">cov[...</span><span class="s3">, </span><span class="s1">di[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">di[</span><span class="s4">1</span><span class="s1">]] += probs</span>
    <span class="s3">return </span><span class="s1">cov</span>


<span class="s3">def </span><span class="s1">var_multinomial(probs):</span>
    <span class="s2">&quot;&quot;&quot;variance of multinomial distribution 
 
    var = probs * (1 - probs) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">var = probs * (</span><span class="s4">1 </span><span class="s1">- probs)</span>
    <span class="s3">return </span><span class="s1">var</span>
</pre>
</body>
</html>
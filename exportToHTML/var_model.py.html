<html>
<head>
<title>var_model.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
var_model.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Vector Autoregression (VAR) processes 
 
References 
---------- 
Lütkepohl (2005) New Introduction to Multiple Time Series Analysis 
&quot;&quot;&quot;</span>
<span class="s3">from </span><span class="s1">__future__ </span><span class="s3">import </span><span class="s1">annotations</span>

<span class="s3">from </span><span class="s1">statsmodels.compat.python </span><span class="s3">import </span><span class="s1">lrange</span>

<span class="s3">from </span><span class="s1">collections </span><span class="s3">import </span><span class="s1">defaultdict</span>
<span class="s3">from </span><span class="s1">io </span><span class="s3">import </span><span class="s1">StringIO</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>
<span class="s3">import </span><span class="s1">scipy.stats </span><span class="s3">as </span><span class="s1">stats</span>

<span class="s3">import </span><span class="s1">statsmodels.base.wrapper </span><span class="s3">as </span><span class="s1">wrap</span>
<span class="s3">from </span><span class="s1">statsmodels.iolib.table </span><span class="s3">import </span><span class="s1">SimpleTable</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s3">import </span><span class="s1">cache_readonly</span><span class="s3">, </span><span class="s1">deprecated_alias</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.linalg </span><span class="s3">import </span><span class="s1">logdet_symm</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">OutputWarning</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.validation </span><span class="s3">import </span><span class="s1">array_like</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.base.tsa_model </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">TimeSeriesModel</span><span class="s3">,</span>
    <span class="s1">TimeSeriesResultsWrapper</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">import </span><span class="s1">statsmodels.tsa.tsatools </span><span class="s3">as </span><span class="s1">tsa</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.tsatools </span><span class="s3">import </span><span class="s1">duplication_matrix</span><span class="s3">, </span><span class="s1">unvec</span><span class="s3">, </span><span class="s1">vec</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar </span><span class="s3">import </span><span class="s1">output</span><span class="s3">, </span><span class="s1">plotting</span><span class="s3">, </span><span class="s1">util</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.hypothesis_test_results </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">CausalityTestResults</span><span class="s3">,</span>
    <span class="s1">NormalityTestResults</span><span class="s3">,</span>
    <span class="s1">WhitenessTestResults</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.irf </span><span class="s3">import </span><span class="s1">IRAnalysis</span>
<span class="s3">from </span><span class="s1">statsmodels.tsa.vector_ar.output </span><span class="s3">import </span><span class="s1">VARSummary</span>

<span class="s0"># -------------------------------------------------------------------------------</span>
<span class="s0"># VAR process routines</span>


<span class="s3">def </span><span class="s1">ma_rep(coefs</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s4">10</span><span class="s1">):</span>
    <span class="s2">r&quot;&quot;&quot; 
    MA(\infty) representation of VAR(p) process 
 
    Parameters 
    ---------- 
    coefs : ndarray (p x k x k) 
    maxn : int 
        Number of MA matrices to compute 
 
    Notes 
    ----- 
    VAR(p) process as 
 
    .. math:: y_t = A_1 y_{t-1} + \ldots + A_p y_{t-p} + u_t 
 
    can be equivalently represented as 
 
    .. math:: y_t = \mu + \sum_{i=0}^\infty \Phi_i u_{t-i} 
 
    e.g. can recursively compute the \Phi_i matrices with \Phi_0 = I_k 
 
    Returns 
    ------- 
    phis : ndarray (maxn + 1 x k x k) 
    &quot;&quot;&quot;</span>
    <span class="s1">p</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k = coefs.shape</span>
    <span class="s1">phis = np.zeros((maxn + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k))</span>
    <span class="s1">phis[</span><span class="s4">0</span><span class="s1">] = np.eye(k)</span>

    <span class="s0"># recursively compute Phi matrices</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">maxn + </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">i + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s3">if </span><span class="s1">j &gt; p:</span>
                <span class="s3">break</span>

            <span class="s1">phis[i] += np.dot(phis[i - j]</span><span class="s3">, </span><span class="s1">coefs[j - </span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3">return </span><span class="s1">phis</span>


<span class="s3">def </span><span class="s1">is_stable(coefs</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s3">False</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Determine stability of VAR(p) system by examining the eigenvalues of the 
    VAR(1) representation 
 
    Parameters 
    ---------- 
    coefs : ndarray (p x k x k) 
 
    Returns 
    ------- 
    is_stable : bool 
    &quot;&quot;&quot;</span>
    <span class="s1">A_var1 = util.comp_matrix(coefs)</span>
    <span class="s1">eigs = np.linalg.eigvals(A_var1)</span>

    <span class="s3">if </span><span class="s1">verbose:</span>
        <span class="s1">print(</span><span class="s5">&quot;Eigenvalues of VAR(1) rep&quot;</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">val </span><span class="s3">in </span><span class="s1">np.abs(eigs):</span>
            <span class="s1">print(val)</span>

    <span class="s3">return </span><span class="s1">(np.abs(eigs) &lt;= </span><span class="s4">1</span><span class="s1">).all()</span>


<span class="s3">def </span><span class="s1">var_acf(coefs</span><span class="s3">, </span><span class="s1">sig_u</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute autocovariance function ACF_y(h) up to nlags of stable VAR(p) 
    process 
 
    Parameters 
    ---------- 
    coefs : ndarray (p x k x k) 
        Coefficient matrices A_i 
    sig_u : ndarray (k x k) 
        Covariance of white noise process u_t 
    nlags : int, optional 
        Defaults to order p of system 
 
    Notes 
    ----- 
    Ref: Lütkepohl p.28-29 
 
    Returns 
    ------- 
    acf : ndarray, (p, k, k) 
    &quot;&quot;&quot;</span>
    <span class="s1">p</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">_ = coefs.shape</span>
    <span class="s3">if </span><span class="s1">nlags </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">nlags = p</span>

    <span class="s0"># p x k x k, ACF for lags 0, ..., p-1</span>
    <span class="s1">result = np.zeros((nlags + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k))</span>
    <span class="s1">result[:p] = _var_acf(coefs</span><span class="s3">, </span><span class="s1">sig_u)</span>

    <span class="s0"># yule-walker equations</span>
    <span class="s3">for </span><span class="s1">h </span><span class="s3">in </span><span class="s1">range(p</span><span class="s3">, </span><span class="s1">nlags + </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0"># compute ACF for lag=h</span>
        <span class="s0"># G(h) = A_1 G(h-1) + ... + A_p G(h-p)</span>

        <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(p):</span>
            <span class="s1">result[h] += np.dot(coefs[j]</span><span class="s3">, </span><span class="s1">result[h - j - </span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3">return </span><span class="s1">result</span>


<span class="s3">def </span><span class="s1">_var_acf(coefs</span><span class="s3">, </span><span class="s1">sig_u):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute autocovariance function ACF_y(h) for h=1,...,p 
 
    Notes 
    ----- 
    Lütkepohl (2005) p.29 
    &quot;&quot;&quot;</span>
    <span class="s1">p</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k2 = coefs.shape</span>
    <span class="s3">assert </span><span class="s1">k == k2</span>

    <span class="s1">A = util.comp_matrix(coefs)</span>
    <span class="s0"># construct VAR(1) noise covariance</span>
    <span class="s1">SigU = np.zeros((k * p</span><span class="s3">, </span><span class="s1">k * p))</span>
    <span class="s1">SigU[:k</span><span class="s3">, </span><span class="s1">:k] = sig_u</span>

    <span class="s0"># vec(ACF) = (I_(kp)^2 - kron(A, A))^-1 vec(Sigma_U)</span>
    <span class="s1">vecACF = np.linalg.solve(np.eye((k * p) ** </span><span class="s4">2</span><span class="s1">) - np.kron(A</span><span class="s3">, </span><span class="s1">A)</span><span class="s3">, </span><span class="s1">vec(SigU))</span>

    <span class="s1">acf = unvec(vecACF)</span>
    <span class="s1">acf = [acf[:k</span><span class="s3">, </span><span class="s1">k * i : k * (i + </span><span class="s4">1</span><span class="s1">)] </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(p)]</span>
    <span class="s1">acf = np.array(acf)</span>

    <span class="s3">return </span><span class="s1">acf</span>


<span class="s3">def </span><span class="s1">forecast_cov(ma_coefs</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">steps):</span>
    <span class="s2">r&quot;&quot;&quot; 
    Compute theoretical forecast error variance matrices 
 
    Parameters 
    ---------- 
    steps : int 
        Number of steps ahead 
 
    Notes 
    ----- 
    .. math:: \mathrm{MSE}(h) = \sum_{i=0}^{h-1} \Phi \Sigma_u \Phi^T 
 
    Returns 
    ------- 
    forc_covs : ndarray (steps x neqs x neqs) 
    &quot;&quot;&quot;</span>
    <span class="s1">neqs = len(sigma_u)</span>
    <span class="s1">forc_covs = np.zeros((steps</span><span class="s3">, </span><span class="s1">neqs</span><span class="s3">, </span><span class="s1">neqs))</span>

    <span class="s1">prior = np.zeros((neqs</span><span class="s3">, </span><span class="s1">neqs))</span>
    <span class="s3">for </span><span class="s1">h </span><span class="s3">in </span><span class="s1">range(steps):</span>
        <span class="s0"># Sigma(h) = Sigma(h-1) + Phi Sig_u Phi'</span>
        <span class="s1">phi = ma_coefs[h]</span>
        <span class="s1">var = phi @ sigma_u @ phi.T</span>
        <span class="s1">forc_covs[h] = prior = prior + var</span>

    <span class="s3">return </span><span class="s1">forc_covs</span>


<span class="s1">mse = forecast_cov</span>


<span class="s3">def </span><span class="s1">forecast(y</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">trend_coefs</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Produce linear minimum MSE forecast 
 
    Parameters 
    ---------- 
    y : ndarray (k_ar x neqs) 
    coefs : ndarray (k_ar x neqs x neqs) 
    trend_coefs : ndarray (1 x neqs) or (neqs) 
    steps : int 
    exog : ndarray (trend_coefs.shape[1] x neqs) 
 
    Returns 
    ------- 
    forecasts : ndarray (steps x neqs) 
 
    Notes 
    ----- 
    Lütkepohl p. 37 
    &quot;&quot;&quot;</span>
    <span class="s1">p = len(coefs)</span>
    <span class="s1">k = len(coefs[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s3">if </span><span class="s1">y.shape[</span><span class="s4">0</span><span class="s1">] &lt; p:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s5">f&quot;y must by have at least order (</span><span class="s3">{</span><span class="s1">p</span><span class="s3">}</span><span class="s5">) observations. &quot;</span>
            <span class="s5">f&quot;Got </span><span class="s3">{</span><span class="s1">y.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">}</span><span class="s5">.&quot;</span>
        <span class="s1">)</span>
    <span class="s0"># initial value</span>
    <span class="s1">forcs = np.zeros((steps</span><span class="s3">, </span><span class="s1">k))</span>
    <span class="s3">if </span><span class="s1">exog </span><span class="s3">is not None and </span><span class="s1">trend_coefs </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">forcs += np.dot(exog</span><span class="s3">, </span><span class="s1">trend_coefs)</span>
    <span class="s0"># to make existing code (with trend_coefs=intercept and without exog) work:</span>
    <span class="s3">elif </span><span class="s1">exog </span><span class="s3">is None and </span><span class="s1">trend_coefs </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">forcs += trend_coefs</span>

    <span class="s0"># h=0 forecast should be latest observation</span>
    <span class="s0"># forcs[0] = y[-1]</span>

    <span class="s0"># make indices easier to think about</span>
    <span class="s3">for </span><span class="s1">h </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">steps + </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0"># y_t(h) = intercept + sum_1^p A_i y_t_(h-i)</span>
        <span class="s1">f = forcs[h - </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">p + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s0"># slightly hackish</span>
            <span class="s3">if </span><span class="s1">h - i &lt;= </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s0"># e.g. when h=1, h-1 = 0, which is y[-1]</span>
                <span class="s1">prior_y = y[h - i - </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s0"># e.g. when h=2, h-1=1, which is forcs[0]</span>
                <span class="s1">prior_y = forcs[h - i - </span><span class="s4">1</span><span class="s1">]</span>

            <span class="s0"># i=1 is coefs[0]</span>
            <span class="s1">f = f + np.dot(coefs[i - </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">prior_y)</span>

        <span class="s1">forcs[h - </span><span class="s4">1</span><span class="s1">] = f</span>

    <span class="s3">return </span><span class="s1">forcs</span>


<span class="s3">def </span><span class="s1">_forecast_vars(steps</span><span class="s3">, </span><span class="s1">ma_coefs</span><span class="s3">, </span><span class="s1">sig_u):</span>
    <span class="s2">&quot;&quot;&quot;_forecast_vars function used by VECMResults. Note that the definition 
    of the local variable covs is the same as in VARProcess and as such it 
    differs from the one in VARResults! 
 
    Parameters 
    ---------- 
    steps 
    ma_coefs 
    sig_u 
 
    Returns 
    ------- 
    &quot;&quot;&quot;</span>
    <span class="s1">covs = mse(ma_coefs</span><span class="s3">, </span><span class="s1">sig_u</span><span class="s3">, </span><span class="s1">steps)</span>
    <span class="s0"># Take diagonal for each cov</span>
    <span class="s1">neqs = len(sig_u)</span>
    <span class="s1">inds = np.arange(neqs)</span>
    <span class="s3">return </span><span class="s1">covs[:</span><span class="s3">, </span><span class="s1">inds</span><span class="s3">, </span><span class="s1">inds]</span>


<span class="s3">def </span><span class="s1">forecast_interval(</span>
    <span class="s1">y</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">trend_coefs</span><span class="s3">, </span><span class="s1">sig_u</span><span class="s3">, </span><span class="s1">steps=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">exog=</span><span class="s4">1</span>
<span class="s1">):</span>
    <span class="s3">assert </span><span class="s4">0 </span><span class="s1">&lt; alpha &lt; </span><span class="s4">1</span>
    <span class="s1">q = util.norm_signif_level(alpha)</span>

    <span class="s1">point_forecast = forecast(y</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">trend_coefs</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">exog)</span>
    <span class="s1">ma_coefs = ma_rep(coefs</span><span class="s3">, </span><span class="s1">steps)</span>
    <span class="s1">sigma = np.sqrt(_forecast_vars(steps</span><span class="s3">, </span><span class="s1">ma_coefs</span><span class="s3">, </span><span class="s1">sig_u))</span>

    <span class="s1">forc_lower = point_forecast - q * sigma</span>
    <span class="s1">forc_upper = point_forecast + q * sigma</span>

    <span class="s3">return </span><span class="s1">point_forecast</span><span class="s3">, </span><span class="s1">forc_lower</span><span class="s3">, </span><span class="s1">forc_upper</span>


<span class="s3">def </span><span class="s1">var_loglike(resid</span><span class="s3">, </span><span class="s1">omega</span><span class="s3">, </span><span class="s1">nobs):</span>
    <span class="s2">r&quot;&quot;&quot; 
    Returns the value of the VAR(p) log-likelihood. 
 
    Parameters 
    ---------- 
    resid : ndarray (T x K) 
    omega : ndarray 
        Sigma hat matrix.  Each element i,j is the average product of the 
        OLS residual for variable i and the OLS residual for variable j or 
        np.dot(resid.T,resid)/nobs.  There should be no correction for the 
        degrees of freedom. 
    nobs : int 
 
    Returns 
    ------- 
    llf : float 
        The value of the loglikelihood function for a VAR(p) model 
 
    Notes 
    ----- 
    The loglikelihood function for the VAR(p) is 
 
    .. math:: 
 
        -\left(\frac{T}{2}\right) 
        \left(\ln\left|\Omega\right|-K\ln\left(2\pi\right)-K\right) 
    &quot;&quot;&quot;</span>
    <span class="s1">logdet = logdet_symm(np.asarray(omega))</span>
    <span class="s1">neqs = len(omega)</span>
    <span class="s1">part1 = -(nobs * neqs / </span><span class="s4">2</span><span class="s1">) * np.log(</span><span class="s4">2 </span><span class="s1">* np.pi)</span>
    <span class="s1">part2 = -(nobs / </span><span class="s4">2</span><span class="s1">) * (logdet + neqs)</span>
    <span class="s3">return </span><span class="s1">part1 + part2</span>


<span class="s3">def </span><span class="s1">_reordered(self</span><span class="s3">, </span><span class="s1">order):</span>
    <span class="s0"># Create new arrays to hold rearranged results from .fit()</span>
    <span class="s1">endog = self.endog</span>
    <span class="s1">endog_lagged = self.endog_lagged</span>
    <span class="s1">params = self.params</span>
    <span class="s1">sigma_u = self.sigma_u</span>
    <span class="s1">names = self.names</span>
    <span class="s1">k_ar = self.k_ar</span>
    <span class="s1">endog_new = np.zeros_like(endog)</span>
    <span class="s1">endog_lagged_new = np.zeros_like(endog_lagged)</span>
    <span class="s1">params_new_inc = np.zeros_like(params)</span>
    <span class="s1">params_new = np.zeros_like(params)</span>
    <span class="s1">sigma_u_new_inc = np.zeros_like(sigma_u)</span>
    <span class="s1">sigma_u_new = np.zeros_like(sigma_u)</span>
    <span class="s1">num_end = len(self.params[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">names_new = []</span>

    <span class="s0"># Rearrange elements and fill in new arrays</span>
    <span class="s1">k = self.k_trend</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">c </span><span class="s3">in </span><span class="s1">enumerate(order):</span>
        <span class="s1">endog_new[:</span><span class="s3">, </span><span class="s1">i] = self.endog[:</span><span class="s3">, </span><span class="s1">c]</span>
        <span class="s3">if </span><span class="s1">k &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">params_new_inc[</span><span class="s4">0</span><span class="s3">, </span><span class="s1">i] = params[</span><span class="s4">0</span><span class="s3">, </span><span class="s1">i]</span>
            <span class="s1">endog_lagged_new[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = endog_lagged[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
        <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(k_ar):</span>
            <span class="s1">params_new_inc[i + j * num_end + k</span><span class="s3">, </span><span class="s1">:] = self.params[</span>
                <span class="s1">c + j * num_end + k</span><span class="s3">, </span><span class="s1">:</span>
            <span class="s1">]</span>
            <span class="s1">endog_lagged_new[:</span><span class="s3">, </span><span class="s1">i + j * num_end + k] = endog_lagged[</span>
                <span class="s1">:</span><span class="s3">, </span><span class="s1">c + j * num_end + k</span>
            <span class="s1">]</span>
        <span class="s1">sigma_u_new_inc[i</span><span class="s3">, </span><span class="s1">:] = sigma_u[c</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s1">names_new.append(names[c])</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">c </span><span class="s3">in </span><span class="s1">enumerate(order):</span>
        <span class="s1">params_new[:</span><span class="s3">, </span><span class="s1">i] = params_new_inc[:</span><span class="s3">, </span><span class="s1">c]</span>
        <span class="s1">sigma_u_new[:</span><span class="s3">, </span><span class="s1">i] = sigma_u_new_inc[:</span><span class="s3">, </span><span class="s1">c]</span>

    <span class="s3">return </span><span class="s1">VARResults(</span>
        <span class="s1">endog=endog_new</span><span class="s3">,</span>
        <span class="s1">endog_lagged=endog_lagged_new</span><span class="s3">,</span>
        <span class="s1">params=params_new</span><span class="s3">,</span>
        <span class="s1">sigma_u=sigma_u_new</span><span class="s3">,</span>
        <span class="s1">lag_order=self.k_ar</span><span class="s3">,</span>
        <span class="s1">model=self.model</span><span class="s3">,</span>
        <span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s3">,</span>
        <span class="s1">names=names_new</span><span class="s3">,</span>
        <span class="s1">dates=self.dates</span><span class="s3">,</span>
    <span class="s1">)</span>


<span class="s3">def </span><span class="s1">orth_ma_rep(results</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">P=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">r&quot;&quot;&quot;Compute Orthogonalized MA coefficient matrices using P matrix such 
    that :math:`\Sigma_u = PP^\prime`. P defaults to the Cholesky 
    decomposition of :math:`\Sigma_u` 
 
    Parameters 
    ---------- 
    results : VARResults or VECMResults 
    maxn : int 
        Number of coefficient matrices to compute 
    P : ndarray (neqs x neqs), optional 
        Matrix such that Sigma_u = PP', defaults to the Cholesky decomposition. 
 
    Returns 
    ------- 
    coefs : ndarray (maxn x neqs x neqs) 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">P </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">P = results._chol_sigma_u</span>

    <span class="s1">ma_mats = results.ma_rep(maxn=maxn)</span>
    <span class="s3">return </span><span class="s1">np.array([np.dot(coefs</span><span class="s3">, </span><span class="s1">P) </span><span class="s3">for </span><span class="s1">coefs </span><span class="s3">in </span><span class="s1">ma_mats])</span>


<span class="s3">def </span><span class="s1">test_normality(results</span><span class="s3">, </span><span class="s1">signif=</span><span class="s4">0.05</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Test assumption of normal-distributed errors using Jarque-Bera-style 
    omnibus Chi^2 test 
 
    Parameters 
    ---------- 
    results : VARResults or statsmodels.tsa.vecm.vecm.VECMResults 
    signif : float 
        The test's significance level. 
 
    Notes 
    ----- 
    H0 (null) : data are generated by a Gaussian-distributed process 
 
    Returns 
    ------- 
    result : NormalityTestResults 
 
    References 
    ---------- 
    .. [1] Lütkepohl, H. 2005. *New Introduction to Multiple Time Series* 
       *Analysis*. Springer. 
 
    .. [2] Kilian, L. &amp; Demiroglu, U. (2000). &quot;Residual-Based Tests for 
       Normality in Autoregressions: Asymptotic Theory and Simulation 
       Evidence.&quot; Journal of Business &amp; Economic Statistics 
    &quot;&quot;&quot;</span>
    <span class="s1">resid_c = results.resid - results.resid.mean(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">sig = np.dot(resid_c.T</span><span class="s3">, </span><span class="s1">resid_c) / results.nobs</span>
    <span class="s1">Pinv = np.linalg.inv(np.linalg.cholesky(sig))</span>

    <span class="s1">w = np.dot(Pinv</span><span class="s3">, </span><span class="s1">resid_c.T)</span>
    <span class="s1">b1 = (w ** </span><span class="s4">3</span><span class="s1">).sum(</span><span class="s4">1</span><span class="s1">)[:</span><span class="s3">, None</span><span class="s1">] / results.nobs</span>
    <span class="s1">b2 = (w ** </span><span class="s4">4</span><span class="s1">).sum(</span><span class="s4">1</span><span class="s1">)[:</span><span class="s3">, None</span><span class="s1">] / results.nobs - </span><span class="s4">3</span>

    <span class="s1">lam_skew = results.nobs * np.dot(b1.T</span><span class="s3">, </span><span class="s1">b1) / </span><span class="s4">6</span>
    <span class="s1">lam_kurt = results.nobs * np.dot(b2.T</span><span class="s3">, </span><span class="s1">b2) / </span><span class="s4">24</span>

    <span class="s1">lam_omni = float(np.squeeze(lam_skew + lam_kurt))</span>
    <span class="s1">omni_dist = stats.chi2(results.neqs * </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">omni_pvalue = float(omni_dist.sf(lam_omni))</span>
    <span class="s1">crit_omni = float(omni_dist.ppf(</span><span class="s4">1 </span><span class="s1">- signif))</span>

    <span class="s3">return </span><span class="s1">NormalityTestResults(</span>
        <span class="s1">lam_omni</span><span class="s3">, </span><span class="s1">crit_omni</span><span class="s3">, </span><span class="s1">omni_pvalue</span><span class="s3">, </span><span class="s1">results.neqs * </span><span class="s4">2</span><span class="s3">, </span><span class="s1">signif</span>
    <span class="s1">)</span>


<span class="s3">class </span><span class="s1">LagOrderResults:</span>
    <span class="s2">&quot;&quot;&quot; 
    Results class for choosing a model's lag order. 
 
    Parameters 
    ---------- 
    ics : dict 
        The keys are the strings ``&quot;aic&quot;``, ``&quot;bic&quot;``, ``&quot;hqic&quot;``, and 
        ``&quot;fpe&quot;``. A corresponding value is a list of information criteria for 
        various numbers of lags. 
    selected_orders : dict 
        The keys are the strings ``&quot;aic&quot;``, ``&quot;bic&quot;``, ``&quot;hqic&quot;``, and 
        ``&quot;fpe&quot;``. The corresponding value is an integer specifying the number 
        of lags chosen according to a given criterion (key). 
    vecm : bool, default: `False` 
        `True` indicates that the model is a VECM. In case of a VAR model 
        this argument must be `False`. 
 
    Notes 
    ----- 
    In case of a VECM the shown lags are lagged differences. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">ics</span><span class="s3">, </span><span class="s1">selected_orders</span><span class="s3">, </span><span class="s1">vecm=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s1">self.title = (</span><span class="s5">&quot;VECM&quot; </span><span class="s3">if </span><span class="s1">vecm </span><span class="s3">else </span><span class="s5">&quot;VAR&quot;</span><span class="s1">) + </span><span class="s5">&quot; Order Selection&quot;</span>
        <span class="s1">self.title += </span><span class="s5">&quot; (* highlights the minimums)&quot;</span>
        <span class="s1">self.ics = ics</span>
        <span class="s1">self.selected_orders = selected_orders</span>
        <span class="s1">self.vecm = vecm</span>
        <span class="s1">self.aic = selected_orders[</span><span class="s5">&quot;aic&quot;</span><span class="s1">]</span>
        <span class="s1">self.bic = selected_orders[</span><span class="s5">&quot;bic&quot;</span><span class="s1">]</span>
        <span class="s1">self.hqic = selected_orders[</span><span class="s5">&quot;hqic&quot;</span><span class="s1">]</span>
        <span class="s1">self.fpe = selected_orders[</span><span class="s5">&quot;fpe&quot;</span><span class="s1">]</span>

    <span class="s3">def </span><span class="s1">summary(self):  </span><span class="s0"># basically copied from (now deleted) print_ic_table()</span>
        <span class="s1">cols = sorted(self.ics)  </span><span class="s0"># [&quot;aic&quot;, &quot;bic&quot;, &quot;hqic&quot;, &quot;fpe&quot;]</span>
        <span class="s1">str_data = np.array(</span>
            <span class="s1">[[</span><span class="s5">&quot;%#10.4g&quot; </span><span class="s1">% v </span><span class="s3">for </span><span class="s1">v </span><span class="s3">in </span><span class="s1">self.ics[c]] </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">cols]</span><span class="s3">, </span><span class="s1">dtype=object</span>
        <span class="s1">).T</span>
        <span class="s0"># mark minimum with an asterisk</span>
        <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">col </span><span class="s3">in </span><span class="s1">enumerate(cols):</span>
            <span class="s1">idx = int(self.selected_orders[col])</span><span class="s3">, </span><span class="s1">i</span>
            <span class="s1">str_data[idx] += </span><span class="s5">&quot;*&quot;</span>
        <span class="s3">return </span><span class="s1">SimpleTable(</span>
            <span class="s1">str_data</span><span class="s3">,</span>
            <span class="s1">[col.upper() </span><span class="s3">for </span><span class="s1">col </span><span class="s3">in </span><span class="s1">cols]</span><span class="s3">,</span>
            <span class="s1">lrange(len(str_data))</span><span class="s3">,</span>
            <span class="s1">title=self.title</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">__str__(self):</span>
        <span class="s3">return </span><span class="s1">(</span>
            <span class="s5">f&quot;&lt;</span><span class="s3">{</span><span class="s1">self.__module__</span><span class="s3">}</span><span class="s5">.</span><span class="s3">{</span><span class="s1">self.__class__.__name__</span><span class="s3">} </span><span class="s5">object. Selected &quot;</span>
            <span class="s5">f&quot;orders are: AIC -&gt; </span><span class="s3">{</span><span class="s1">str(self.aic)</span><span class="s3">}</span><span class="s5">, BIC -&gt; </span><span class="s3">{</span><span class="s1">str(self.bic)</span><span class="s3">}</span><span class="s5">, &quot;</span>
            <span class="s5">f&quot;FPE -&gt; </span><span class="s3">{</span><span class="s1">str(self.fpe)</span><span class="s3">}</span><span class="s5">, HQIC -&gt;  </span><span class="s3">{</span><span class="s1">str(self.hqic)</span><span class="s3">}</span><span class="s5">&gt;&quot;</span>
        <span class="s1">)</span>


<span class="s0"># -------------------------------------------------------------------------------</span>
<span class="s0"># VARProcess class: for known or unknown VAR process</span>


<span class="s3">class </span><span class="s1">VAR(TimeSeriesModel):</span>
    <span class="s2">r&quot;&quot;&quot; 
    Fit VAR(p) process and do lag order selection 
 
    .. math:: y_t = A_1 y_{t-1} + \ldots + A_p y_{t-p} + u_t 
 
    Parameters 
    ---------- 
    endog : array_like 
        2-d endogenous response variable. The independent variable. 
    exog : array_like 
        2-d exogenous variable. 
    dates : array_like 
        must match number of rows of endog 
 
    References 
    ---------- 
    Lütkepohl (2005) New Introduction to Multiple Time Series Analysis 
    &quot;&quot;&quot;</span>

    <span class="s1">y = deprecated_alias(</span><span class="s5">&quot;y&quot;</span><span class="s3">, </span><span class="s5">&quot;endog&quot;</span><span class="s3">, </span><span class="s1">remove_version=</span><span class="s5">&quot;0.11.0&quot;</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">dates=</span><span class="s3">None, </span><span class="s1">freq=</span><span class="s3">None, </span><span class="s1">missing=</span><span class="s5">&quot;none&quot;</span>
    <span class="s1">):</span>
        <span class="s1">super().__init__(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">dates</span><span class="s3">, </span><span class="s1">freq</span><span class="s3">, </span><span class="s1">missing=missing)</span>
        <span class="s3">if </span><span class="s1">self.endog.ndim == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Only gave one variable to VAR&quot;</span><span class="s1">)</span>
        <span class="s1">self.neqs = self.endog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">self.n_totobs = len(endog)</span>

    <span class="s3">def </span><span class="s1">predict(self</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">start=</span><span class="s3">None, </span><span class="s1">end=</span><span class="s3">None, </span><span class="s1">lags=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Returns in-sample predictions or forecasts 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params)</span>

        <span class="s3">if </span><span class="s1">start </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">start = lags</span>

        <span class="s0"># Handle start, end</span>
        <span class="s1">(</span>
            <span class="s1">start</span><span class="s3">,</span>
            <span class="s1">end</span><span class="s3">,</span>
            <span class="s1">out_of_sample</span><span class="s3">,</span>
            <span class="s1">prediction_index</span><span class="s3">,</span>
        <span class="s1">) = self._get_prediction_index(start</span><span class="s3">, </span><span class="s1">end)</span>

        <span class="s3">if </span><span class="s1">end &lt; start:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;end is before start&quot;</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">end == start + out_of_sample:</span>
            <span class="s3">return </span><span class="s1">np.array([])</span>

        <span class="s1">k_trend = util.get_trendorder(trend)</span>
        <span class="s1">k = self.neqs</span>
        <span class="s1">k_ar = lags</span>

        <span class="s1">predictedvalues = np.zeros((end + </span><span class="s4">1 </span><span class="s1">- start + out_of_sample</span><span class="s3">, </span><span class="s1">k))</span>
        <span class="s3">if </span><span class="s1">k_trend != </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">intercept = params[:k_trend]</span>
            <span class="s1">predictedvalues += intercept</span>

        <span class="s1">y = self.endog</span>
        <span class="s1">x = util.get_var_endog(y</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">trend=trend</span><span class="s3">, </span><span class="s1">has_constant=</span><span class="s5">&quot;raise&quot;</span><span class="s1">)</span>
        <span class="s1">fittedvalues = np.dot(x</span><span class="s3">, </span><span class="s1">params)</span>

        <span class="s1">fv_start = start - k_ar</span>
        <span class="s1">pv_end = min(len(predictedvalues)</span><span class="s3">, </span><span class="s1">len(fittedvalues) - fv_start)</span>
        <span class="s1">fv_end = min(len(fittedvalues)</span><span class="s3">, </span><span class="s1">end - k_ar + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">predictedvalues[:pv_end] = fittedvalues[fv_start:fv_end]</span>

        <span class="s3">if not </span><span class="s1">out_of_sample:</span>
            <span class="s3">return </span><span class="s1">predictedvalues</span>

        <span class="s0"># fit out of sample</span>
        <span class="s1">y = y[-k_ar:]</span>
        <span class="s1">coefs = params[k_trend:].reshape((k_ar</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k)).swapaxes(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">predictedvalues[pv_end:] = forecast(y</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">out_of_sample)</span>
        <span class="s3">return </span><span class="s1">predictedvalues</span>

    <span class="s3">def </span><span class="s1">fit(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">maxlags: int | </span><span class="s3">None </span><span class="s1">= </span><span class="s3">None,</span>
        <span class="s1">method=</span><span class="s5">&quot;ols&quot;</span><span class="s3">,</span>
        <span class="s1">ic=</span><span class="s3">None,</span>
        <span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s3">,</span>
        <span class="s1">verbose=</span><span class="s3">False,</span>
    <span class="s1">):</span>
        <span class="s0"># todo: this code is only supporting deterministic terms as exog.</span>
        <span class="s0"># This means that all exog-variables have lag 0. If dealing with</span>
        <span class="s0"># different exogs is necessary, a `lags_exog`-parameter might make</span>
        <span class="s0"># sense (e.g. a sequence of ints specifying lags).</span>
        <span class="s0"># Alternatively, leading zeros for exog-variables with smaller number</span>
        <span class="s0"># of lags than the maximum number of exog-lags might work.</span>
        <span class="s2">&quot;&quot;&quot; 
        Fit the VAR model 
 
        Parameters 
        ---------- 
        maxlags : {int, None}, default None 
            Maximum number of lags to check for order selection, defaults to 
            12 * (nobs/100.)**(1./4), see select_order function 
        method : {'ols'} 
            Estimation method to use 
        ic : {'aic', 'fpe', 'hqic', 'bic', None} 
            Information criterion to use for VAR order selection. 
            aic : Akaike 
            fpe : Final prediction error 
            hqic : Hannan-Quinn 
            bic : Bayesian a.k.a. Schwarz 
        verbose : bool, default False 
            Print order selection output to the screen 
        trend : str {&quot;c&quot;, &quot;ct&quot;, &quot;ctt&quot;, &quot;n&quot;} 
            &quot;c&quot; - add constant 
            &quot;ct&quot; - constant and trend 
            &quot;ctt&quot; - constant, linear and quadratic trend 
            &quot;n&quot; - co constant, no trend 
            Note that these are prepended to the columns of the dataset. 
 
        Returns 
        ------- 
        VARResults 
            Estimation results 
 
        Notes 
        ----- 
        See Lütkepohl pp. 146-153 for implementation details. 
        &quot;&quot;&quot;</span>
        <span class="s1">lags = maxlags</span>
        <span class="s3">if </span><span class="s1">trend </span><span class="s3">not in </span><span class="s1">[</span><span class="s5">&quot;c&quot;</span><span class="s3">, </span><span class="s5">&quot;ct&quot;</span><span class="s3">, </span><span class="s5">&quot;ctt&quot;</span><span class="s3">, </span><span class="s5">&quot;n&quot;</span><span class="s1">]:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;trend '{}' not supported for VAR&quot;</span><span class="s1">.format(trend))</span>

        <span class="s3">if </span><span class="s1">ic </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">selections = self.select_order(maxlags=maxlags)</span>
            <span class="s3">if not </span><span class="s1">hasattr(selections</span><span class="s3">, </span><span class="s1">ic):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;%s not recognized, must be among %s&quot;</span>
                    <span class="s1">% (ic</span><span class="s3">, </span><span class="s1">sorted(selections))</span>
                <span class="s1">)</span>
            <span class="s1">lags = getattr(selections</span><span class="s3">, </span><span class="s1">ic)</span>
            <span class="s3">if </span><span class="s1">verbose:</span>
                <span class="s1">print(selections)</span>
                <span class="s1">print(</span><span class="s5">&quot;Using %d based on %s criterion&quot; </span><span class="s1">% (lags</span><span class="s3">, </span><span class="s1">ic))</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">lags </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">lags = </span><span class="s4">1</span>

        <span class="s1">k_trend = util.get_trendorder(trend)</span>
        <span class="s1">orig_exog_names = self.exog_names</span>
        <span class="s1">self.exog_names = util.make_lag_names(self.endog_names</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">k_trend)</span>
        <span class="s1">self.nobs = self.n_totobs - lags</span>

        <span class="s0"># add exog to data.xnames (necessary because the length of xnames also</span>
        <span class="s0"># determines the allowed size of VARResults.params)</span>
        <span class="s3">if </span><span class="s1">self.exog </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">orig_exog_names:</span>
                <span class="s1">x_names_to_add = orig_exog_names</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">x_names_to_add = [</span>
                    <span class="s1">(</span><span class="s5">&quot;exog%d&quot; </span><span class="s1">% i) </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.exog.shape[</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s1">]</span>
            <span class="s1">self.data.xnames = (</span>
                <span class="s1">self.data.xnames[:k_trend]</span>
                <span class="s1">+ x_names_to_add</span>
                <span class="s1">+ self.data.xnames[k_trend:]</span>
            <span class="s1">)</span>
        <span class="s1">self.data.cov_names = pd.MultiIndex.from_product(</span>
            <span class="s1">(self.data.xnames</span><span class="s3">, </span><span class="s1">self.data.ynames)</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">self._estimate_var(lags</span><span class="s3">, </span><span class="s1">trend=trend)</span>

    <span class="s3">def </span><span class="s1">_estimate_var(self</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">offset=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        lags : int 
            Lags of the endogenous variable. 
        offset : int 
            Periods to drop from beginning-- for order selection so it's an 
            apples-to-apples comparison 
        trend : {str, None} 
            As per above 
        &quot;&quot;&quot;</span>
        <span class="s0"># have to do this again because select_order does not call fit</span>
        <span class="s1">self.k_trend = k_trend = util.get_trendorder(trend)</span>

        <span class="s3">if </span><span class="s1">offset &lt; </span><span class="s4">0</span><span class="s1">:  </span><span class="s0"># pragma: no cover</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;offset must be &gt;= 0&quot;</span><span class="s1">)</span>

        <span class="s1">nobs = self.n_totobs - lags - offset</span>
        <span class="s1">endog = self.endog[offset:]</span>
        <span class="s1">exog = </span><span class="s3">None if </span><span class="s1">self.exog </span><span class="s3">is None else </span><span class="s1">self.exog[offset:]</span>
        <span class="s1">z = util.get_var_endog(endog</span><span class="s3">, </span><span class="s1">lags</span><span class="s3">, </span><span class="s1">trend=trend</span><span class="s3">, </span><span class="s1">has_constant=</span><span class="s5">&quot;raise&quot;</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">exog </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s0"># TODO: currently only deterministic terms supported (exoglags==0)</span>
            <span class="s0"># and since exoglags==0, x will be an array of size 0.</span>
            <span class="s1">x = util.get_var_endog(</span>
                <span class="s1">exog[-nobs:]</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">trend=</span><span class="s5">&quot;n&quot;</span><span class="s3">, </span><span class="s1">has_constant=</span><span class="s5">&quot;raise&quot;</span>
            <span class="s1">)</span>
            <span class="s1">x_inst = exog[-nobs:]</span>
            <span class="s1">x = np.column_stack((x</span><span class="s3">, </span><span class="s1">x_inst))</span>
            <span class="s3">del </span><span class="s1">x_inst  </span><span class="s0"># free memory</span>
            <span class="s1">temp_z = z</span>
            <span class="s1">z = np.empty((x.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">x.shape[</span><span class="s4">1</span><span class="s1">] + z.shape[</span><span class="s4">1</span><span class="s1">]))</span>
            <span class="s1">z[:</span><span class="s3">, </span><span class="s1">: self.k_trend] = temp_z[:</span><span class="s3">, </span><span class="s1">: self.k_trend]</span>
            <span class="s1">z[:</span><span class="s3">, </span><span class="s1">self.k_trend : self.k_trend + x.shape[</span><span class="s4">1</span><span class="s1">]] = x</span>
            <span class="s1">z[:</span><span class="s3">, </span><span class="s1">self.k_trend + x.shape[</span><span class="s4">1</span><span class="s1">] :] = temp_z[:</span><span class="s3">, </span><span class="s1">self.k_trend :]</span>
            <span class="s3">del </span><span class="s1">temp_z</span><span class="s3">, </span><span class="s1">x  </span><span class="s0"># free memory</span>
        <span class="s0"># the following modification of z is necessary to get the same results</span>
        <span class="s0"># as JMulTi for the constant-term-parameter...</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.k_trend):</span>
            <span class="s3">if </span><span class="s1">(np.diff(z[:</span><span class="s3">, </span><span class="s1">i]) == </span><span class="s4">1</span><span class="s1">).all():  </span><span class="s0"># modify the trend-column</span>
                <span class="s1">z[:</span><span class="s3">, </span><span class="s1">i] += lags</span>
            <span class="s0"># make the same adjustment for the quadratic term</span>
            <span class="s3">if </span><span class="s1">(np.diff(np.sqrt(z[:</span><span class="s3">, </span><span class="s1">i])) == </span><span class="s4">1</span><span class="s1">).all():</span>
                <span class="s1">z[:</span><span class="s3">, </span><span class="s1">i] = (np.sqrt(z[:</span><span class="s3">, </span><span class="s1">i]) + lags) ** </span><span class="s4">2</span>

        <span class="s1">y_sample = endog[lags:]</span>
        <span class="s0"># Lütkepohl p75, about 5x faster than stated formula</span>
        <span class="s1">params = np.linalg.lstsq(z</span><span class="s3">, </span><span class="s1">y_sample</span><span class="s3">, </span><span class="s1">rcond=</span><span class="s4">1e-15</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">resid = y_sample - np.dot(z</span><span class="s3">, </span><span class="s1">params)</span>

        <span class="s0"># Unbiased estimate of covariance matrix $\Sigma_u$ of the white noise</span>
        <span class="s0"># process $u$</span>
        <span class="s0"># equivalent definition</span>
        <span class="s0"># .. math:: \frac{1}{T - Kp - 1} Y^\prime (I_T - Z (Z^\prime Z)^{-1}</span>
        <span class="s0"># Z^\prime) Y</span>
        <span class="s0"># Ref: Lütkepohl p.75</span>
        <span class="s0"># df_resid right now is T - Kp - 1, which is a suggested correction</span>

        <span class="s1">avobs = len(y_sample)</span>
        <span class="s3">if </span><span class="s1">exog </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">k_trend += exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">df_resid = avobs - (self.neqs * lags + k_trend)</span>

        <span class="s1">sse = np.dot(resid.T</span><span class="s3">, </span><span class="s1">resid)</span>
        <span class="s3">if </span><span class="s1">df_resid:</span>
            <span class="s1">omega = sse / df_resid</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">omega = np.full_like(sse</span><span class="s3">, </span><span class="s1">np.nan)</span>

        <span class="s1">varfit = VARResults(</span>
            <span class="s1">endog</span><span class="s3">,</span>
            <span class="s1">z</span><span class="s3">,</span>
            <span class="s1">params</span><span class="s3">,</span>
            <span class="s1">omega</span><span class="s3">,</span>
            <span class="s1">lags</span><span class="s3">,</span>
            <span class="s1">names=self.endog_names</span><span class="s3">,</span>
            <span class="s1">trend=trend</span><span class="s3">,</span>
            <span class="s1">dates=self.data.dates</span><span class="s3">,</span>
            <span class="s1">model=self</span><span class="s3">,</span>
            <span class="s1">exog=self.exog</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">VARResultsWrapper(varfit)</span>

    <span class="s3">def </span><span class="s1">select_order(self</span><span class="s3">, </span><span class="s1">maxlags=</span><span class="s3">None, </span><span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute lag order selections based on each of the available information 
        criteria 
 
        Parameters 
        ---------- 
        maxlags : int 
            if None, defaults to 12 * (nobs/100.)**(1./4) 
        trend : str {&quot;n&quot;, &quot;c&quot;, &quot;ct&quot;, &quot;ctt&quot;} 
            * &quot;n&quot; - no deterministic terms 
            * &quot;c&quot; - constant term 
            * &quot;ct&quot; - constant and linear term 
            * &quot;ctt&quot; - constant, linear, and quadratic term 
 
        Returns 
        ------- 
        selections : LagOrderResults 
        &quot;&quot;&quot;</span>
        <span class="s1">ntrend = len(trend) </span><span class="s3">if </span><span class="s1">trend.startswith(</span><span class="s5">&quot;c&quot;</span><span class="s1">) </span><span class="s3">else </span><span class="s4">0</span>
        <span class="s1">max_estimable = (self.n_totobs - self.neqs - ntrend) // (</span><span class="s4">1 </span><span class="s1">+ self.neqs)</span>
        <span class="s3">if </span><span class="s1">maxlags </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">maxlags = int(round(</span><span class="s4">12 </span><span class="s1">* (len(self.endog) / </span><span class="s4">100.0</span><span class="s1">) ** (</span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">4.0</span><span class="s1">)))</span>
            <span class="s0"># TODO: This expression shows up in a bunch of places, but</span>
            <span class="s0">#  in some it is `int` and in others `np.ceil`.  Also in some</span>
            <span class="s0">#  it multiplies by 4 instead of 12.  Let's put these all in</span>
            <span class="s0">#  one place and document when to use which variant.</span>

            <span class="s0"># Ensure enough obs to estimate model with maxlags</span>
            <span class="s1">maxlags = min(maxlags</span><span class="s3">, </span><span class="s1">max_estimable)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">maxlags &gt; max_estimable:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;maxlags is too large for the number of observations and &quot;</span>
                    <span class="s5">&quot;the number of equations. The largest model cannot be &quot;</span>
                    <span class="s5">&quot;estimated.&quot;</span>
                <span class="s1">)</span>

        <span class="s1">ics = defaultdict(list)</span>
        <span class="s1">p_min = </span><span class="s4">0 </span><span class="s3">if </span><span class="s1">self.exog </span><span class="s3">is not None or </span><span class="s1">trend != </span><span class="s5">&quot;n&quot; </span><span class="s3">else </span><span class="s4">1</span>
        <span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">range(p_min</span><span class="s3">, </span><span class="s1">maxlags + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s0"># exclude some periods to same amount of data used for each lag</span>
            <span class="s0"># order</span>
            <span class="s1">result = self._estimate_var(p</span><span class="s3">, </span><span class="s1">offset=maxlags - p</span><span class="s3">, </span><span class="s1">trend=trend)</span>

            <span class="s3">for </span><span class="s1">k</span><span class="s3">, </span><span class="s1">v </span><span class="s3">in </span><span class="s1">result.info_criteria.items():</span>
                <span class="s1">ics[k].append(v)</span>

        <span class="s1">selected_orders = dict(</span>
            <span class="s1">(k</span><span class="s3">, </span><span class="s1">np.array(v).argmin() + p_min) </span><span class="s3">for </span><span class="s1">k</span><span class="s3">, </span><span class="s1">v </span><span class="s3">in </span><span class="s1">ics.items()</span>
        <span class="s1">)</span>

        <span class="s3">return </span><span class="s1">LagOrderResults(ics</span><span class="s3">, </span><span class="s1">selected_orders</span><span class="s3">, </span><span class="s1">vecm=</span><span class="s3">False</span><span class="s1">)</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">from_formula(</span>
        <span class="s1">cls</span><span class="s3">, </span><span class="s1">formula</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">subset=</span><span class="s3">None, </span><span class="s1">drop_cols=</span><span class="s3">None, </span><span class="s1">*args</span><span class="s3">, </span><span class="s1">**kwargs</span>
    <span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Not implemented. Formulas are not supported for VAR models. 
        &quot;&quot;&quot;</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">&quot;formulas are not supported for VAR models.&quot;</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">VARProcess:</span>
    <span class="s2">&quot;&quot;&quot; 
    Class represents a known VAR(p) process 
 
    Parameters 
    ---------- 
    coefs : ndarray (p x k x k) 
        coefficients for lags of endog, part or params reshaped 
    coefs_exog : ndarray 
        parameters for trend and user provided exog 
    sigma_u : ndarray (k x k) 
        residual covariance 
    names : sequence (length k) 
    _params_info : dict 
        internal dict to provide information about the composition of `params`, 
        specifically `k_trend` (trend order) and `k_exog_user` (the number of 
        exog variables provided by the user). 
        If it is None, then coefs_exog are assumed to be for the intercept and 
        trend. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">, </span><span class="s1">coefs</span><span class="s3">, </span><span class="s1">coefs_exog</span><span class="s3">, </span><span class="s1">sigma_u</span><span class="s3">, </span><span class="s1">names=</span><span class="s3">None, </span><span class="s1">_params_info=</span><span class="s3">None</span>
    <span class="s1">):</span>
        <span class="s1">self.k_ar = len(coefs)</span>
        <span class="s1">self.neqs = coefs.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">self.coefs = coefs</span>
        <span class="s1">self.coefs_exog = coefs_exog</span>
        <span class="s0"># Note reshaping 1-D coefs_exog to 2_D makes unit tests fail</span>
        <span class="s1">self.sigma_u = sigma_u</span>
        <span class="s1">self.names = names</span>

        <span class="s3">if </span><span class="s1">_params_info </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">_params_info = {}</span>
        <span class="s1">self.k_exog_user = _params_info.get(</span><span class="s5">&quot;k_exog_user&quot;</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">self.coefs_exog </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">k_ex = self.coefs_exog.shape[</span><span class="s4">0</span><span class="s1">] </span><span class="s3">if </span><span class="s1">self.coefs_exog.ndim != </span><span class="s4">1 </span><span class="s3">else </span><span class="s4">1</span>
            <span class="s1">k_c = k_ex - self.k_exog_user</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">k_c = </span><span class="s4">0</span>
        <span class="s1">self.k_trend = _params_info.get(</span><span class="s5">&quot;k_trend&quot;</span><span class="s3">, </span><span class="s1">k_c)</span>
        <span class="s0"># TODO: we need to distinguish exog including trend and exog_user</span>
        <span class="s1">self.k_exog = self.k_trend + self.k_exog_user</span>

        <span class="s3">if </span><span class="s1">self.k_trend &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">coefs_exog.ndim == </span><span class="s4">2</span><span class="s1">:</span>
                <span class="s1">self.intercept = coefs_exog[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">self.intercept = coefs_exog</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self.intercept = np.zeros(self.neqs)</span>

    <span class="s3">def </span><span class="s1">get_eq_index(self</span><span class="s3">, </span><span class="s1">name):</span>
        <span class="s2">&quot;&quot;&quot;Return integer position of requested equation name&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">util.get_index(self.names</span><span class="s3">, </span><span class="s1">name)</span>

    <span class="s3">def </span><span class="s1">__str__(self):</span>
        <span class="s1">output = </span><span class="s5">&quot;VAR(%d) process for %d-dimensional response y_t&quot; </span><span class="s1">% (</span>
            <span class="s1">self.k_ar</span><span class="s3">,</span>
            <span class="s1">self.neqs</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s1">output += </span><span class="s5">&quot;</span><span class="s3">\n</span><span class="s5">stable: %s&quot; </span><span class="s1">% self.is_stable()</span>
        <span class="s1">output += </span><span class="s5">&quot;</span><span class="s3">\n</span><span class="s5">mean: %s&quot; </span><span class="s1">% self.mean()</span>

        <span class="s3">return </span><span class="s1">output</span>

    <span class="s3">def </span><span class="s1">is_stable(self</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Determine stability based on model coefficients 
 
        Parameters 
        ---------- 
        verbose : bool 
            Print eigenvalues of the VAR(1) companion 
 
        Notes 
        ----- 
        Checks if det(I - Az) = 0 for any mod(z) &lt;= 1, so all the eigenvalues of 
        the companion matrix must lie outside the unit circle 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">is_stable(self.coefs</span><span class="s3">, </span><span class="s1">verbose=verbose)</span>

    <span class="s3">def </span><span class="s1">simulate_var(self</span><span class="s3">, </span><span class="s1">steps=</span><span class="s3">None, </span><span class="s1">offset=</span><span class="s3">None, </span><span class="s1">seed=</span><span class="s3">None, </span><span class="s1">initial_values=</span><span class="s3">None, </span><span class="s1">nsimulations=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        simulate the VAR(p) process for the desired number of steps 
 
        Parameters 
        ---------- 
        steps : None or int 
            number of observations to simulate, this includes the initial 
            observations to start the autoregressive process. 
            If offset is not None, then exog of the model are used if they were 
            provided in the model 
        offset : None or ndarray (steps, neqs) 
            If not None, then offset is added as an observation specific 
            intercept to the autoregression. If it is None and either trend 
            (including intercept) or exog were used in the VAR model, then 
            the linear predictor of those components will be used as offset. 
            This should have the same number of rows as steps, and the same 
            number of columns as endogenous variables (neqs). 
        seed : {None, int} 
            If seed is not None, then it will be used with for the random 
            variables generated by numpy.random. 
        initial_values : array_like, optional 
            Initial values for use in the simulation. Shape should be 
            (nlags, neqs) or (neqs,). Values should be ordered from less to 
            most recent. Note that this values will be returned by the 
            simulation as the first values of `endog_simulated` and they 
            will count for the total number of steps. 
        nsimulations : {None, int} 
            Number of simulations to perform. If `nsimulations` is None it will 
            perform one simulation and return value will have shape (steps, neqs). 
 
        Returns 
        ------- 
        endog_simulated : nd_array 
            Endog of the simulated VAR process. Shape will be (nsimulations, steps, neqs) 
            or (steps, neqs) if `nsimulations` is None. 
        &quot;&quot;&quot;</span>
        <span class="s1">steps_ = </span><span class="s3">None</span>
        <span class="s3">if </span><span class="s1">offset </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">self.k_exog_user &gt; </span><span class="s4">0 </span><span class="s3">or </span><span class="s1">self.k_trend &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s0"># if more than intercept</span>
                <span class="s0"># endog_lagged contains all regressors, trend, exog_user</span>
                <span class="s0"># and lagged endog, trimmed initial observations</span>
                <span class="s1">offset = self.endog_lagged[:</span><span class="s3">, </span><span class="s1">: self.k_exog].dot(</span>
                    <span class="s1">self.coefs_exog.T</span>
                <span class="s1">)</span>
                <span class="s1">steps_ = self.endog_lagged.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">offset = self.intercept</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">steps_ = offset.shape[</span><span class="s4">0</span><span class="s1">]</span>

        <span class="s0"># default, but over written if exog or offset are used</span>
        <span class="s3">if </span><span class="s1">steps </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">steps_ </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">steps = </span><span class="s4">1000</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">steps = steps_</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">steps_ </span><span class="s3">is not None and </span><span class="s1">steps != steps_:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;if exog or offset are used, then steps must&quot;</span>
                    <span class="s5">&quot;be equal to their length or None&quot;</span>
                <span class="s1">)</span>

        <span class="s1">y = util.varsim(</span>
            <span class="s1">self.coefs</span><span class="s3">,</span>
            <span class="s1">offset</span><span class="s3">,</span>
            <span class="s1">self.sigma_u</span><span class="s3">,</span>
            <span class="s1">steps=steps</span><span class="s3">,</span>
            <span class="s1">seed=seed</span><span class="s3">,</span>
            <span class="s1">initial_values=initial_values</span><span class="s3">,</span>
            <span class="s1">nsimulations=nsimulations</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">y</span>

    <span class="s3">def </span><span class="s1">plotsim(self</span><span class="s3">, </span><span class="s1">steps=</span><span class="s3">None, </span><span class="s1">offset=</span><span class="s3">None, </span><span class="s1">seed=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Plot a simulation from the VAR(p) process for the desired number of 
        steps 
        &quot;&quot;&quot;</span>
        <span class="s1">y = self.simulate_var(steps=steps</span><span class="s3">, </span><span class="s1">offset=offset</span><span class="s3">, </span><span class="s1">seed=seed)</span>
        <span class="s3">return </span><span class="s1">plotting.plot_mts(y)</span>

    <span class="s3">def </span><span class="s1">intercept_longrun(self):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Long run intercept of stable VAR process 
 
        Lütkepohl eq. 2.1.23 
 
        .. math:: \mu = (I - A_1 - \dots - A_p)^{-1} \alpha 
 
        where \alpha is the intercept (parameter of the constant) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">np.linalg.solve(self._char_mat</span><span class="s3">, </span><span class="s1">self.intercept)</span>

    <span class="s3">def </span><span class="s1">mean(self):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Long run intercept of stable VAR process 
 
        Warning: trend and exog except for intercept are ignored for this. 
        This might change in future versions. 
 
        Lütkepohl eq. 2.1.23 
 
        .. math:: \mu = (I - A_1 - \dots - A_p)^{-1} \alpha 
 
        where \alpha is the intercept (parameter of the constant) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.intercept_longrun()</span>

    <span class="s3">def </span><span class="s1">ma_rep(self</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s4">10</span><span class="s1">):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Compute MA(:math:`\infty`) coefficient matrices 
 
        Parameters 
        ---------- 
        maxn : int 
            Number of coefficient matrices to compute 
 
        Returns 
        ------- 
        coefs : ndarray (maxn x k x k) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">ma_rep(self.coefs</span><span class="s3">, </span><span class="s1">maxn=maxn)</span>

    <span class="s3">def </span><span class="s1">orth_ma_rep(self</span><span class="s3">, </span><span class="s1">maxn=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">P=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Compute orthogonalized MA coefficient matrices using P matrix such 
        that :math:`\Sigma_u = PP^\prime`. P defaults to the Cholesky 
        decomposition of :math:`\Sigma_u` 
 
        Parameters 
        ---------- 
        maxn : int 
            Number of coefficient matrices to compute 
        P : ndarray (k x k), optional 
            Matrix such that Sigma_u = PP', defaults to Cholesky descomp 
 
        Returns 
        ------- 
        coefs : ndarray (maxn x k x k) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">orth_ma_rep(self</span><span class="s3">, </span><span class="s1">maxn</span><span class="s3">, </span><span class="s1">P)</span>

    <span class="s3">def </span><span class="s1">long_run_effects(self):</span>
        <span class="s2">r&quot;&quot;&quot;Compute long-run effect of unit impulse 
 
        .. math:: 
 
            \Psi_\infty = \sum_{i=0}^\infty \Phi_i 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">np.linalg.inv(self._char_mat)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">_chol_sigma_u(self):</span>
        <span class="s3">return </span><span class="s1">np.linalg.cholesky(self.sigma_u)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">_char_mat(self):</span>
        <span class="s2">&quot;&quot;&quot;Characteristic matrix of the VAR&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">np.eye(self.neqs) - self.coefs.sum(</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">acf(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Compute theoretical autocovariance function 
 
        Returns 
        ------- 
        acf : ndarray (p x k x k) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">var_acf(self.coefs</span><span class="s3">, </span><span class="s1">self.sigma_u</span><span class="s3">, </span><span class="s1">nlags=nlags)</span>

    <span class="s3">def </span><span class="s1">acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Autocorrelation function 
 
        Parameters 
        ---------- 
        nlags : int or None 
            The number of lags to include in the autocovariance function. The 
            default is the number of lags included in the model. 
 
        Returns 
        ------- 
        acorr : ndarray 
            Autocorrelation and cross correlations (nlags, neqs, neqs) 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">util.acf_to_acorr(self.acf(nlags=nlags))</span>

    <span class="s3">def </span><span class="s1">plot_acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">linewidth=</span><span class="s4">8</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Plot theoretical autocorrelation function&quot;&quot;&quot;</span>
        <span class="s1">fig = plotting.plot_full_acorr(</span>
            <span class="s1">self.acorr(nlags=nlags)</span><span class="s3">, </span><span class="s1">linewidth=linewidth</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>

    <span class="s3">def </span><span class="s1">forecast(self</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">exog_future=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Produce linear minimum MSE forecasts for desired number of steps 
        ahead, using prior values y 
 
        Parameters 
        ---------- 
        y : ndarray (p x k) 
        steps : int 
 
        Returns 
        ------- 
        forecasts : ndarray (steps x neqs) 
 
        Notes 
        ----- 
        Lütkepohl pp 37-38 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self.exog </span><span class="s3">is None and </span><span class="s1">exog_future </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;No exog in model, so no exog_future supported &quot;</span>
                <span class="s5">&quot;in forecast method.&quot;</span>
            <span class="s1">)</span>
        <span class="s3">if </span><span class="s1">self.exog </span><span class="s3">is not None and </span><span class="s1">exog_future </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;Please provide an exog_future argument to &quot;</span>
                <span class="s5">&quot;the forecast method.&quot;</span>
            <span class="s1">)</span>

        <span class="s1">exog_future = array_like(</span>
            <span class="s1">exog_future</span><span class="s3">, </span><span class="s5">&quot;exog_future&quot;</span><span class="s3">, </span><span class="s1">optional=</span><span class="s3">True, </span><span class="s1">ndim=</span><span class="s4">2</span>
        <span class="s1">)</span>
        <span class="s3">if </span><span class="s1">exog_future </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">exog_future.shape[</span><span class="s4">0</span><span class="s1">] != steps:</span>
                <span class="s1">err_msg = </span><span class="s5">f&quot;&quot;&quot;</span><span class="s3">\ 
</span><span class="s5">exog_future only has </span><span class="s3">{</span><span class="s1">exog_future.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">} </span><span class="s5">observations. It must have </span><span class="s3">\ 
</span><span class="s5">steps (</span><span class="s3">{</span><span class="s1">steps</span><span class="s3">}</span><span class="s5">) observations.</span>
<span class="s5">&quot;&quot;&quot;</span>
                <span class="s3">raise </span><span class="s1">ValueError(err_msg)</span>
        <span class="s1">trend_coefs = </span><span class="s3">None if </span><span class="s1">self.coefs_exog.size == </span><span class="s4">0 </span><span class="s3">else </span><span class="s1">self.coefs_exog.T</span>

        <span class="s1">exogs = []</span>
        <span class="s3">if </span><span class="s1">self.trend.startswith(</span><span class="s5">&quot;c&quot;</span><span class="s1">):  </span><span class="s0"># constant term</span>
            <span class="s1">exogs.append(np.ones(steps))</span>
        <span class="s1">exog_lin_trend = np.arange(</span>
            <span class="s1">self.n_totobs + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">self.n_totobs + </span><span class="s4">1 </span><span class="s1">+ steps</span>
        <span class="s1">)</span>
        <span class="s3">if </span><span class="s5">&quot;t&quot; </span><span class="s3">in </span><span class="s1">self.trend:</span>
            <span class="s1">exogs.append(exog_lin_trend)</span>
        <span class="s3">if </span><span class="s5">&quot;tt&quot; </span><span class="s3">in </span><span class="s1">self.trend:</span>
            <span class="s1">exogs.append(exog_lin_trend ** </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">exog_future </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">exogs.append(exog_future)</span>

        <span class="s3">if not </span><span class="s1">exogs:</span>
            <span class="s1">exog_future = </span><span class="s3">None</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">exog_future = np.column_stack(exogs)</span>
        <span class="s3">return </span><span class="s1">forecast(y</span><span class="s3">, </span><span class="s1">self.coefs</span><span class="s3">, </span><span class="s1">trend_coefs</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">exog_future)</span>

    <span class="s0"># TODO: use `mse` module-level function?</span>
    <span class="s3">def </span><span class="s1">mse(self</span><span class="s3">, </span><span class="s1">steps):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Compute theoretical forecast error variance matrices 
 
        Parameters 
        ---------- 
        steps : int 
            Number of steps ahead 
 
        Notes 
        ----- 
        .. math:: \mathrm{MSE}(h) = \sum_{i=0}^{h-1} \Phi \Sigma_u \Phi^T 
 
        Returns 
        ------- 
        forc_covs : ndarray (steps x neqs x neqs) 
        &quot;&quot;&quot;</span>
        <span class="s1">ma_coefs = self.ma_rep(steps)</span>

        <span class="s1">k = len(self.sigma_u)</span>
        <span class="s1">forc_covs = np.zeros((steps</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k))</span>

        <span class="s1">prior = np.zeros((k</span><span class="s3">, </span><span class="s1">k))</span>
        <span class="s3">for </span><span class="s1">h </span><span class="s3">in </span><span class="s1">range(steps):</span>
            <span class="s0"># Sigma(h) = Sigma(h-1) + Phi Sig_u Phi'</span>
            <span class="s1">phi = ma_coefs[h]</span>
            <span class="s1">var = phi @ self.sigma_u @ phi.T</span>
            <span class="s1">forc_covs[h] = prior = prior + var</span>

        <span class="s3">return </span><span class="s1">forc_covs</span>

    <span class="s1">forecast_cov = mse</span>

    <span class="s3">def </span><span class="s1">_forecast_vars(self</span><span class="s3">, </span><span class="s1">steps):</span>
        <span class="s1">covs = self.forecast_cov(steps)</span>

        <span class="s0"># Take diagonal for each cov</span>
        <span class="s1">inds = np.arange(self.neqs)</span>
        <span class="s3">return </span><span class="s1">covs[:</span><span class="s3">, </span><span class="s1">inds</span><span class="s3">, </span><span class="s1">inds]</span>

    <span class="s3">def </span><span class="s1">forecast_interval(self</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">exog_future=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Construct forecast interval estimates assuming the y are Gaussian 
 
        Parameters 
        ---------- 
        y : {ndarray, None} 
            The initial values to use for the forecasts. If None, 
            the last k_ar values of the original endogenous variables are 
            used. 
        steps : int 
            Number of steps ahead to forecast 
        alpha : float, optional 
            The significance level for the confidence intervals. 
        exog_future : ndarray, optional 
            Forecast values of the exogenous variables. Should include 
            constant, trend, etc. as needed, including extrapolating out 
            of sample. 
        Returns 
        ------- 
        point : ndarray 
            Mean value of forecast 
        lower : ndarray 
            Lower bound of confidence interval 
        upper : ndarray 
            Upper bound of confidence interval 
 
        Notes 
        ----- 
        Lütkepohl pp. 39-40 
        &quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s4">0 </span><span class="s1">&lt; alpha &lt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;alpha must be between 0 and 1&quot;</span><span class="s1">)</span>
        <span class="s1">q = util.norm_signif_level(alpha)</span>

        <span class="s1">point_forecast = self.forecast(y</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">exog_future=exog_future)</span>
        <span class="s1">sigma = np.sqrt(self._forecast_vars(steps))</span>

        <span class="s1">forc_lower = point_forecast - q * sigma</span>
        <span class="s1">forc_upper = point_forecast + q * sigma</span>

        <span class="s3">return </span><span class="s1">point_forecast</span><span class="s3">, </span><span class="s1">forc_lower</span><span class="s3">, </span><span class="s1">forc_upper</span>

    <span class="s3">def </span><span class="s1">to_vecm(self):</span>
        <span class="s2">&quot;&quot;&quot;to_vecm&quot;&quot;&quot;</span>
        <span class="s1">k = self.coefs.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">p = self.coefs.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">A = self.coefs</span>
        <span class="s1">pi = -(np.identity(k) - np.sum(A</span><span class="s3">, </span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">gamma = np.zeros((p - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">k))</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(p - </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s1">gamma[i] = -(np.sum(A[i + </span><span class="s4">1 </span><span class="s1">:]</span><span class="s3">, </span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">gamma = np.concatenate(gamma</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">{</span><span class="s5">&quot;Gamma&quot;</span><span class="s1">: gamma</span><span class="s3">, </span><span class="s5">&quot;Pi&quot;</span><span class="s1">: pi}</span>


<span class="s0"># ----------------------------------------------------------------------------</span>
<span class="s0"># VARResults class</span>


<span class="s3">class </span><span class="s1">VARResults(VARProcess):</span>
    <span class="s2">&quot;&quot;&quot;Estimate VAR(p) process with fixed number of lags 
 
    Parameters 
    ---------- 
    endog : ndarray 
    endog_lagged : ndarray 
    params : ndarray 
    sigma_u : ndarray 
    lag_order : int 
    model : VAR model instance 
    trend : str {'n', 'c', 'ct'} 
    names : array_like 
        List of names of the endogenous variables in order of appearance in 
        `endog`. 
    dates 
    exog : ndarray 
 
    Attributes 
    ---------- 
    params : ndarray (p x K x K) 
        Estimated A_i matrices, A_i = coefs[i-1] 
    dates 
    endog 
    endog_lagged 
    k_ar : int 
        Order of VAR process 
    k_trend : int 
    model 
    names 
    neqs : int 
        Number of variables (equations) 
    nobs : int 
    n_totobs : int 
    params : ndarray (Kp + 1) x K 
        A_i matrices and intercept in stacked form [int A_1 ... A_p] 
    names : list 
        variables names 
    sigma_u : ndarray (K x K) 
        Estimate of white noise process variance Var[u_t] 
    &quot;&quot;&quot;</span>

    <span class="s1">_model_type = </span><span class="s5">&quot;VAR&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">endog</span><span class="s3">,</span>
        <span class="s1">endog_lagged</span><span class="s3">,</span>
        <span class="s1">params</span><span class="s3">,</span>
        <span class="s1">sigma_u</span><span class="s3">,</span>
        <span class="s1">lag_order</span><span class="s3">,</span>
        <span class="s1">model=</span><span class="s3">None,</span>
        <span class="s1">trend=</span><span class="s5">&quot;c&quot;</span><span class="s3">,</span>
        <span class="s1">names=</span><span class="s3">None,</span>
        <span class="s1">dates=</span><span class="s3">None,</span>
        <span class="s1">exog=</span><span class="s3">None,</span>
    <span class="s1">):</span>

        <span class="s1">self.model = model</span>
        <span class="s1">self.endog = endog</span>
        <span class="s1">self.endog_lagged = endog_lagged</span>
        <span class="s1">self.dates = dates</span>

        <span class="s1">self.n_totobs</span><span class="s3">, </span><span class="s1">neqs = self.endog.shape</span>
        <span class="s1">self.nobs = self.n_totobs - lag_order</span>
        <span class="s1">self.trend = trend</span>
        <span class="s1">k_trend = util.get_trendorder(trend)</span>
        <span class="s1">self.exog_names = util.make_lag_names(</span>
            <span class="s1">names</span><span class="s3">, </span><span class="s1">lag_order</span><span class="s3">, </span><span class="s1">k_trend</span><span class="s3">, </span><span class="s1">model.data.orig_exog</span>
        <span class="s1">)</span>
        <span class="s1">self.params = params</span>
        <span class="s1">self.exog = exog</span>

        <span class="s0"># Initialize VARProcess parent class</span>
        <span class="s0"># construct coefficient matrices</span>
        <span class="s0"># Each matrix needs to be transposed</span>
        <span class="s1">endog_start = k_trend</span>
        <span class="s3">if </span><span class="s1">exog </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">k_exog_user = exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">endog_start += k_exog_user</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">k_exog_user = </span><span class="s4">0</span>
        <span class="s1">reshaped = self.params[endog_start:]</span>
        <span class="s1">reshaped = reshaped.reshape((lag_order</span><span class="s3">, </span><span class="s1">neqs</span><span class="s3">, </span><span class="s1">neqs))</span>
        <span class="s0"># Need to transpose each coefficient matrix</span>
        <span class="s1">coefs = reshaped.swapaxes(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">).copy()</span>

        <span class="s1">self.coefs_exog = params[:endog_start].T</span>
        <span class="s1">self.k_exog = self.coefs_exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">self.k_exog_user = k_exog_user</span>

        <span class="s0"># maybe change to params class, distinguish exog_all versus exog_user</span>
        <span class="s0"># see issue #4535</span>
        <span class="s1">_params_info = {</span>
            <span class="s5">&quot;k_trend&quot;</span><span class="s1">: k_trend</span><span class="s3">,</span>
            <span class="s5">&quot;k_exog_user&quot;</span><span class="s1">: k_exog_user</span><span class="s3">,</span>
            <span class="s5">&quot;k_ar&quot;</span><span class="s1">: lag_order</span><span class="s3">,</span>
        <span class="s1">}</span>
        <span class="s1">super().__init__(</span>
            <span class="s1">coefs</span><span class="s3">,</span>
            <span class="s1">self.coefs_exog</span><span class="s3">,</span>
            <span class="s1">sigma_u</span><span class="s3">,</span>
            <span class="s1">names=names</span><span class="s3">,</span>
            <span class="s1">_params_info=_params_info</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">plot(self):</span>
        <span class="s2">&quot;&quot;&quot;Plot input time series&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">plotting.plot_mts(</span>
            <span class="s1">self.endog</span><span class="s3">, </span><span class="s1">names=self.names</span><span class="s3">, </span><span class="s1">index=self.dates</span>
        <span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">df_model(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Number of estimated parameters, including the intercept / trends 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.neqs * self.k_ar + self.k_exog</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">df_resid(self):</span>
        <span class="s2">&quot;&quot;&quot;Number of observations minus number of estimated parameters&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.nobs - self.df_model</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">fittedvalues(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        The predicted insample values of the response variables of the model. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">np.dot(self.endog_lagged</span><span class="s3">, </span><span class="s1">self.params)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">resid(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Residuals of response variable resulting from estimated coefficients 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.endog[self.k_ar :] - self.fittedvalues</span>

    <span class="s3">def </span><span class="s1">sample_acov(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Sample acov&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">_compute_acov(self.endog[self.k_ar :]</span><span class="s3">, </span><span class="s1">nlags=nlags)</span>

    <span class="s3">def </span><span class="s1">sample_acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Sample acorr&quot;&quot;&quot;</span>
        <span class="s1">acovs = self.sample_acov(nlags=nlags)</span>
        <span class="s3">return </span><span class="s1">_acovs_to_acorrs(acovs)</span>

    <span class="s3">def </span><span class="s1">plot_sample_acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">linewidth=</span><span class="s4">8</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Plot sample autocorrelation function 
 
        Parameters 
        ---------- 
        nlags : int 
            The number of lags to use in compute the autocorrelation. Does 
            not count the zero lag, which will be returned. 
        linewidth : int 
            The linewidth for the plots. 
 
        Returns 
        ------- 
        Figure 
            The figure that contains the plot axes. 
        &quot;&quot;&quot;</span>
        <span class="s1">fig = plotting.plot_full_acorr(</span>
            <span class="s1">self.sample_acorr(nlags=nlags)</span><span class="s3">, </span><span class="s1">linewidth=linewidth</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>

    <span class="s3">def </span><span class="s1">resid_acov(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute centered sample autocovariance (including lag 0) 
 
        Parameters 
        ---------- 
        nlags : int 
 
        Returns 
        ------- 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">_compute_acov(self.resid</span><span class="s3">, </span><span class="s1">nlags=nlags)</span>

    <span class="s3">def </span><span class="s1">resid_acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute sample autocorrelation (including lag 0) 
 
        Parameters 
        ---------- 
        nlags : int 
 
        Returns 
        ------- 
        &quot;&quot;&quot;</span>
        <span class="s1">acovs = self.resid_acov(nlags=nlags)</span>
        <span class="s3">return </span><span class="s1">_acovs_to_acorrs(acovs)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">resid_corr(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Centered residual correlation matrix 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.resid_acorr(</span><span class="s4">0</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">sigma_u_mle(self):</span>
        <span class="s2">&quot;&quot;&quot;(Biased) maximum likelihood estimate of noise process covariance&quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s1">self.df_resid:</span>
            <span class="s3">return </span><span class="s1">np.zeros_like(self.sigma_u)</span>
        <span class="s3">return </span><span class="s1">self.sigma_u * self.df_resid / self.nobs</span>

    <span class="s3">def </span><span class="s1">cov_params(self):</span>
        <span class="s2">&quot;&quot;&quot;Estimated variance-covariance of model coefficients 
 
        Notes 
        ----- 
        Covariance of vec(B), where B is the matrix 
        [params_for_deterministic_terms, A_1, ..., A_p] with the shape 
        (K x (Kp + number_of_deterministic_terms)) 
        Adjusted to be an unbiased estimator 
        Ref: Lütkepohl p.74-75 
        &quot;&quot;&quot;</span>
        <span class="s1">z = self.endog_lagged</span>
        <span class="s3">return </span><span class="s1">np.kron(np.linalg.inv(z.T @ z)</span><span class="s3">, </span><span class="s1">self.sigma_u)</span>

    <span class="s3">def </span><span class="s1">cov_ybar(self):</span>
        <span class="s2">r&quot;&quot;&quot;Asymptotically consistent estimate of covariance of the sample mean 
 
        .. math:: 
 
            \sqrt(T) (\bar{y} - \mu) \rightarrow 
                  {\cal N}(0, \Sigma_{\bar{y}}) \\ 
 
            \Sigma_{\bar{y}} = B \Sigma_u B^\prime, \text{where } 
                  B = (I_K - A_1 - \cdots - A_p)^{-1} 
 
        Notes 
        ----- 
        Lütkepohl Proposition 3.3 
        &quot;&quot;&quot;</span>

        <span class="s1">Ainv = np.linalg.inv(np.eye(self.neqs) - self.coefs.sum(</span><span class="s4">0</span><span class="s1">))</span>
        <span class="s3">return </span><span class="s1">Ainv @ self.sigma_u @ Ainv.T</span>

    <span class="s0"># ------------------------------------------------------------</span>
    <span class="s0"># Estimation-related things</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">_zz(self):</span>
        <span class="s0"># Z'Z</span>
        <span class="s3">return </span><span class="s1">np.dot(self.endog_lagged.T</span><span class="s3">, </span><span class="s1">self.endog_lagged)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">_cov_alpha(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Estimated covariance matrix of model coefficients w/o exog 
        &quot;&quot;&quot;</span>
        <span class="s0"># drop exog</span>
        <span class="s1">kn = self.k_exog * self.neqs</span>
        <span class="s3">return </span><span class="s1">self.cov_params()[kn:</span><span class="s3">, </span><span class="s1">kn:]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">_cov_sigma(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Estimated covariance matrix of vech(sigma_u) 
        &quot;&quot;&quot;</span>
        <span class="s1">D_K = tsa.duplication_matrix(self.neqs)</span>
        <span class="s1">D_Kinv = np.linalg.pinv(D_K)</span>

        <span class="s1">sigxsig = np.kron(self.sigma_u</span><span class="s3">, </span><span class="s1">self.sigma_u)</span>
        <span class="s3">return </span><span class="s4">2 </span><span class="s1">* D_Kinv @ sigxsig @ D_Kinv.T</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">llf(self):</span>
        <span class="s2">&quot;Compute VAR(p) loglikelihood&quot;</span>
        <span class="s3">return </span><span class="s1">var_loglike(self.resid</span><span class="s3">, </span><span class="s1">self.sigma_u_mle</span><span class="s3">, </span><span class="s1">self.nobs)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">stderr(self):</span>
        <span class="s2">&quot;&quot;&quot;Standard errors of coefficients, reshaped to match in size&quot;&quot;&quot;</span>
        <span class="s1">stderr = np.sqrt(np.diag(self.cov_params()))</span>
        <span class="s3">return </span><span class="s1">stderr.reshape((self.df_model</span><span class="s3">, </span><span class="s1">self.neqs)</span><span class="s3">, </span><span class="s1">order=</span><span class="s5">&quot;C&quot;</span><span class="s1">)</span>

    <span class="s1">bse = stderr  </span><span class="s0"># statsmodels interface?</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">stderr_endog_lagged(self):</span>
        <span class="s2">&quot;&quot;&quot;Stderr_endog_lagged&quot;&quot;&quot;</span>
        <span class="s1">start = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.stderr[start:]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">stderr_dt(self):</span>
        <span class="s2">&quot;&quot;&quot;Stderr_dt&quot;&quot;&quot;</span>
        <span class="s1">end = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.stderr[:end]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">tvalues(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute t-statistics. Use Student-t(T - Kp - 1) = t(df_resid) to 
        test significance. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.params / self.stderr</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">tvalues_endog_lagged(self):</span>
        <span class="s2">&quot;&quot;&quot;tvalues_endog_lagged&quot;&quot;&quot;</span>
        <span class="s1">start = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.tvalues[start:]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">tvalues_dt(self):</span>
        <span class="s2">&quot;&quot;&quot;tvalues_dt&quot;&quot;&quot;</span>
        <span class="s1">end = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.tvalues[:end]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">pvalues(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Two-sided p-values for model coefficients from Student t-distribution 
        &quot;&quot;&quot;</span>
        <span class="s0"># return stats.t.sf(np.abs(self.tvalues), self.df_resid)*2</span>
        <span class="s3">return </span><span class="s4">2 </span><span class="s1">* stats.norm.sf(np.abs(self.tvalues))</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">pvalues_endog_lagged(self):</span>
        <span class="s2">&quot;&quot;&quot;pvalues_endog_laggd&quot;&quot;&quot;</span>
        <span class="s1">start = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.pvalues[start:]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">pvalues_dt(self):</span>
        <span class="s2">&quot;&quot;&quot;pvalues_dt&quot;&quot;&quot;</span>
        <span class="s1">end = self.k_exog</span>
        <span class="s3">return </span><span class="s1">self.pvalues[:end]</span>

    <span class="s0"># todo: ------------------------------------------------------------------</span>

    <span class="s3">def </span><span class="s1">plot_forecast(self</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">plot_stderr=</span><span class="s3">True</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Plot forecast 
        &quot;&quot;&quot;</span>
        <span class="s1">mid</span><span class="s3">, </span><span class="s1">lower</span><span class="s3">, </span><span class="s1">upper = self.forecast_interval(</span>
            <span class="s1">self.endog[-self.k_ar :]</span><span class="s3">, </span><span class="s1">steps</span><span class="s3">, </span><span class="s1">alpha=alpha</span>
        <span class="s1">)</span>
        <span class="s1">fig = plotting.plot_var_forc(</span>
            <span class="s1">self.endog</span><span class="s3">,</span>
            <span class="s1">mid</span><span class="s3">,</span>
            <span class="s1">lower</span><span class="s3">,</span>
            <span class="s1">upper</span><span class="s3">,</span>
            <span class="s1">names=self.names</span><span class="s3">,</span>
            <span class="s1">plot_stderr=plot_stderr</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>

    <span class="s0"># Forecast error covariance functions</span>

    <span class="s3">def </span><span class="s1">forecast_cov(self</span><span class="s3">, </span><span class="s1">steps=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">&quot;mse&quot;</span><span class="s1">):</span>
        <span class="s2">r&quot;&quot;&quot;Compute forecast covariance matrices for desired number of steps 
 
        Parameters 
        ---------- 
        steps : int 
 
        Notes 
        ----- 
        .. math:: \Sigma_{\hat y}(h) = \Sigma_y(h) + \Omega(h) / T 
 
        Ref: Lütkepohl pp. 96-97 
 
        Returns 
        ------- 
        covs : ndarray (steps x k x k) 
        &quot;&quot;&quot;</span>
        <span class="s1">fc_cov = self.mse(steps)</span>
        <span class="s3">if </span><span class="s1">method == </span><span class="s5">&quot;mse&quot;</span><span class="s1">:</span>
            <span class="s3">pass</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s5">&quot;auto&quot;</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">self.k_exog == </span><span class="s4">1 </span><span class="s3">and </span><span class="s1">self.k_trend &lt; </span><span class="s4">2</span><span class="s1">:</span>
                <span class="s0"># currently only supported if no exog and trend in ['n', 'c']</span>
                <span class="s1">fc_cov += self._omega_forc_cov(steps) / self.nobs</span>
                <span class="s3">import </span><span class="s1">warnings</span>

                <span class="s1">warnings.warn(</span>
                    <span class="s5">&quot;forecast cov takes parameter uncertainty into&quot; &quot;account&quot;</span><span class="s3">,</span>
                    <span class="s1">OutputWarning</span><span class="s3">,</span>
                    <span class="s1">stacklevel = </span><span class="s4">2</span><span class="s3">,</span>
                <span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;method has to be either 'mse' or 'auto'&quot;</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">fc_cov</span>

    <span class="s0"># Monte Carlo irf standard errors</span>
    <span class="s3">def </span><span class="s1">irf_errband_mc(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">orth=</span><span class="s3">False,</span>
        <span class="s1">repl=</span><span class="s4">1000</span><span class="s3">,</span>
        <span class="s1">steps=</span><span class="s4">10</span><span class="s3">,</span>
        <span class="s1">signif=</span><span class="s4">0.05</span><span class="s3">,</span>
        <span class="s1">seed=</span><span class="s3">None,</span>
        <span class="s1">burn=</span><span class="s4">100</span><span class="s3">,</span>
        <span class="s1">cum=</span><span class="s3">False,</span>
    <span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute Monte Carlo integrated error bands assuming normally 
        distributed for impulse response functions 
 
        Parameters 
        ---------- 
        orth : bool, default False 
            Compute orthogonalized impulse response error bands 
        repl : int 
            number of Monte Carlo replications to perform 
        steps : int, default 10 
            number of impulse response periods 
        signif : float (0 &lt; signif &lt;1) 
            Significance level for error bars, defaults to 95% CI 
        seed : int 
            np.random.seed for replications 
        burn : int 
            number of initial observations to discard for simulation 
        cum : bool, default False 
            produce cumulative irf error bands 
 
        Notes 
        ----- 
        Lütkepohl (2005) Appendix D 
 
        Returns 
        ------- 
        Tuple of lower and upper arrays of ma_rep monte carlo standard errors 
        &quot;&quot;&quot;</span>
        <span class="s1">ma_coll = self.irf_resim(</span>
            <span class="s1">orth=orth</span><span class="s3">, </span><span class="s1">repl=repl</span><span class="s3">, </span><span class="s1">steps=steps</span><span class="s3">, </span><span class="s1">seed=seed</span><span class="s3">, </span><span class="s1">burn=burn</span><span class="s3">, </span><span class="s1">cum=cum</span>
        <span class="s1">)</span>

        <span class="s1">ma_sort = np.sort(ma_coll</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)  </span><span class="s0"># sort to get quantiles</span>
        <span class="s0"># python 2: round returns float</span>
        <span class="s1">low_idx = int(round(signif / </span><span class="s4">2 </span><span class="s1">* repl) - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">upp_idx = int(round((</span><span class="s4">1 </span><span class="s1">- signif / </span><span class="s4">2</span><span class="s1">) * repl) - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">lower = ma_sort[low_idx</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s1">upper = ma_sort[upp_idx</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s3">return </span><span class="s1">lower</span><span class="s3">, </span><span class="s1">upper</span>

    <span class="s3">def </span><span class="s1">irf_resim(</span>
        <span class="s1">self</span><span class="s3">, </span><span class="s1">orth=</span><span class="s3">False, </span><span class="s1">repl=</span><span class="s4">1000</span><span class="s3">, </span><span class="s1">steps=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">seed=</span><span class="s3">None, </span><span class="s1">burn=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">cum=</span><span class="s3">False</span>
    <span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Simulates impulse response function, returning an array of simulations. 
        Used for Sims-Zha error band calculation. 
 
        Parameters 
        ---------- 
        orth : bool, default False 
            Compute orthogonalized impulse response error bands 
        repl : int 
            number of Monte Carlo replications to perform 
        steps : int, default 10 
            number of impulse response periods 
        signif : float (0 &lt; signif &lt;1) 
            Significance level for error bars, defaults to 95% CI 
        seed : int 
            np.random.seed for replications 
        burn : int 
            number of initial observations to discard for simulation 
        cum : bool, default False 
            produce cumulative irf error bands 
 
        Notes 
        ----- 
        .. [*] Sims, Christoper A., and Tao Zha. 1999. &quot;Error Bands for Impulse 
           Response.&quot; Econometrica 67: 1113-1155. 
 
        Returns 
        ------- 
        Array of simulated impulse response functions 
        &quot;&quot;&quot;</span>
        <span class="s1">neqs = self.neqs</span>
        <span class="s1">k_ar = self.k_ar</span>
        <span class="s1">coefs = self.coefs</span>
        <span class="s1">sigma_u = self.sigma_u</span>
        <span class="s1">intercept = self.intercept</span>
        <span class="s1">nobs = self.nobs</span>
        <span class="s1">nobs_original = nobs + k_ar</span>

        <span class="s1">ma_coll = np.zeros((repl</span><span class="s3">, </span><span class="s1">steps + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">neqs</span><span class="s3">, </span><span class="s1">neqs))</span>

        <span class="s3">def </span><span class="s1">fill_coll(sim):</span>
            <span class="s1">ret = VAR(sim</span><span class="s3">, </span><span class="s1">exog=self.exog).fit(maxlags=k_ar</span><span class="s3">, </span><span class="s1">trend=self.trend)</span>
            <span class="s1">ret = (</span>
                <span class="s1">ret.orth_ma_rep(maxn=steps) </span><span class="s3">if </span><span class="s1">orth </span><span class="s3">else </span><span class="s1">ret.ma_rep(maxn=steps)</span>
            <span class="s1">)</span>
            <span class="s3">return </span><span class="s1">ret.cumsum(axis=</span><span class="s4">0</span><span class="s1">) </span><span class="s3">if </span><span class="s1">cum </span><span class="s3">else </span><span class="s1">ret</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(repl):</span>
            <span class="s0"># discard first burn to eliminate correct for starting bias</span>
            <span class="s1">sim = util.varsim(</span>
                <span class="s1">coefs</span><span class="s3">,</span>
                <span class="s1">intercept</span><span class="s3">,</span>
                <span class="s1">sigma_u</span><span class="s3">,</span>
                <span class="s1">seed=seed</span><span class="s3">,</span>
                <span class="s1">steps=nobs_original + burn</span><span class="s3">,</span>
            <span class="s1">)</span>
            <span class="s1">sim = sim[burn:]</span>
            <span class="s1">ma_coll[i</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:</span><span class="s3">, </span><span class="s1">:] = fill_coll(sim)</span>

        <span class="s3">return </span><span class="s1">ma_coll</span>

    <span class="s3">def </span><span class="s1">_omega_forc_cov(self</span><span class="s3">, </span><span class="s1">steps):</span>
        <span class="s0"># Approximate MSE matrix \Omega(h) as defined in Lut p97</span>
        <span class="s1">G = self._zz</span>
        <span class="s1">Ginv = np.linalg.inv(G)</span>

        <span class="s0"># memoize powers of B for speedup</span>
        <span class="s0"># TODO: see if can memoize better</span>
        <span class="s0"># TODO: much lower-hanging fruit in caching `np.trace` below.</span>
        <span class="s1">B = self._bmat_forc_cov()</span>
        <span class="s1">_B = {}</span>

        <span class="s3">def </span><span class="s1">bpow(i):</span>
            <span class="s3">if </span><span class="s1">i </span><span class="s3">not in </span><span class="s1">_B:</span>
                <span class="s1">_B[i] = np.linalg.matrix_power(B</span><span class="s3">, </span><span class="s1">i)</span>

            <span class="s3">return </span><span class="s1">_B[i]</span>

        <span class="s1">phis = self.ma_rep(steps)</span>
        <span class="s1">sig_u = self.sigma_u</span>

        <span class="s1">omegas = np.zeros((steps</span><span class="s3">, </span><span class="s1">self.neqs</span><span class="s3">, </span><span class="s1">self.neqs))</span>
        <span class="s3">for </span><span class="s1">h </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">steps + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s3">if </span><span class="s1">h == </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">omegas[h - </span><span class="s4">1</span><span class="s1">] = self.df_model * self.sigma_u</span>
                <span class="s3">continue</span>

            <span class="s1">om = omegas[h - </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(h):</span>
                <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(h):</span>
                    <span class="s1">Bi = bpow(h - </span><span class="s4">1 </span><span class="s1">- i)</span>
                    <span class="s1">Bj = bpow(h - </span><span class="s4">1 </span><span class="s1">- j)</span>
                    <span class="s1">mult = np.trace(Bi.T @ Ginv @ Bj @ G)</span>
                    <span class="s1">om += mult * phis[i] @ sig_u @ phis[j].T</span>
            <span class="s1">omegas[h - </span><span class="s4">1</span><span class="s1">] = om</span>

        <span class="s3">return </span><span class="s1">omegas</span>

    <span class="s3">def </span><span class="s1">_bmat_forc_cov(self):</span>
        <span class="s0"># B as defined on p. 96 of Lut</span>
        <span class="s1">upper = np.zeros((self.k_exog</span><span class="s3">, </span><span class="s1">self.df_model))</span>
        <span class="s1">upper[:</span><span class="s3">, </span><span class="s1">: self.k_exog] = np.eye(self.k_exog)</span>

        <span class="s1">lower_dim = self.neqs * (self.k_ar - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">eye = np.eye(lower_dim)</span>
        <span class="s1">lower = np.column_stack(</span>
            <span class="s1">(</span>
                <span class="s1">np.zeros((lower_dim</span><span class="s3">, </span><span class="s1">self.k_exog))</span><span class="s3">,</span>
                <span class="s1">eye</span><span class="s3">,</span>
                <span class="s1">np.zeros((lower_dim</span><span class="s3">, </span><span class="s1">self.neqs))</span><span class="s3">,</span>
            <span class="s1">)</span>
        <span class="s1">)</span>

        <span class="s3">return </span><span class="s1">np.vstack((upper</span><span class="s3">, </span><span class="s1">self.params.T</span><span class="s3">, </span><span class="s1">lower))</span>

    <span class="s3">def </span><span class="s1">summary(self):</span>
        <span class="s2">&quot;&quot;&quot;Compute console output summary of estimates 
 
        Returns 
        ------- 
        summary : VARSummary 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">VARSummary(self)</span>

    <span class="s3">def </span><span class="s1">irf(self</span><span class="s3">, </span><span class="s1">periods=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">var_decomp=</span><span class="s3">None, </span><span class="s1">var_order=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Analyze impulse responses to shocks in system 
 
        Parameters 
        ---------- 
        periods : int 
        var_decomp : ndarray (k x k), lower triangular 
            Must satisfy Omega = P P', where P is the passed matrix. Defaults 
            to Cholesky decomposition of Omega 
        var_order : sequence 
            Alternate variable order for Cholesky decomposition 
 
        Returns 
        ------- 
        irf : IRAnalysis 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">var_order </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">NotImplementedError(</span>
                <span class="s5">&quot;alternate variable order not implemented&quot; &quot; (yet)&quot;</span>
            <span class="s1">)</span>

        <span class="s3">return </span><span class="s1">IRAnalysis(self</span><span class="s3">, </span><span class="s1">P=var_decomp</span><span class="s3">, </span><span class="s1">periods=periods)</span>

    <span class="s3">def </span><span class="s1">fevd(self</span><span class="s3">, </span><span class="s1">periods=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">var_decomp=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Compute forecast error variance decomposition (&quot;fevd&quot;) 
 
        Returns 
        ------- 
        fevd : FEVD instance 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">FEVD(self</span><span class="s3">, </span><span class="s1">P=var_decomp</span><span class="s3">, </span><span class="s1">periods=periods)</span>

    <span class="s3">def </span><span class="s1">reorder(self</span><span class="s3">, </span><span class="s1">order):</span>
        <span class="s2">&quot;&quot;&quot;Reorder variables for structural specification&quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">len(order) != len(self.params[</span><span class="s4">0</span><span class="s3">, </span><span class="s1">:]):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;Reorder specification length should match &quot;</span>
                <span class="s5">&quot;number of endogenous variables&quot;</span>
            <span class="s1">)</span>
        <span class="s0"># This converts order to list of integers if given as strings</span>
        <span class="s3">if </span><span class="s1">isinstance(order[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">str):</span>
            <span class="s1">order_new = []</span>
            <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">nam </span><span class="s3">in </span><span class="s1">enumerate(order):</span>
                <span class="s1">order_new.append(self.names.index(order[i]))</span>
            <span class="s1">order = order_new</span>
        <span class="s3">return </span><span class="s1">_reordered(self</span><span class="s3">, </span><span class="s1">order)</span>

    <span class="s0"># -----------------------------------------------------------</span>
    <span class="s0"># VAR Diagnostics: Granger-causality, whiteness of residuals,</span>
    <span class="s0">#                  normality, etc</span>

    <span class="s3">def </span><span class="s1">test_causality(self</span><span class="s3">, </span><span class="s1">caused</span><span class="s3">, </span><span class="s1">causing=</span><span class="s3">None, </span><span class="s1">kind=</span><span class="s5">&quot;f&quot;</span><span class="s3">, </span><span class="s1">signif=</span><span class="s4">0.05</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Test Granger causality 
 
        Parameters 
        ---------- 
        caused : int or str or sequence of int or str 
            If int or str, test whether the variable specified via this index 
            (int) or name (str) is Granger-caused by the variable(s) specified 
            by `causing`. 
            If a sequence of int or str, test whether the corresponding 
            variables are Granger-caused by the variable(s) specified 
            by `causing`. 
        causing : int or str or sequence of int or str or None, default: None 
            If int or str, test whether the variable specified via this index 
            (int) or name (str) is Granger-causing the variable(s) specified by 
            `caused`. 
            If a sequence of int or str, test whether the corresponding 
            variables are Granger-causing the variable(s) specified by 
            `caused`. 
            If None, `causing` is assumed to be the complement of `caused`. 
        kind : {'f', 'wald'} 
            Perform F-test or Wald (chi-sq) test 
        signif : float, default 5% 
            Significance level for computing critical values for test, 
            defaulting to standard 0.05 level 
 
        Notes 
        ----- 
        Null hypothesis is that there is no Granger-causality for the indicated 
        variables. The degrees of freedom in the F-test are based on the 
        number of variables in the VAR system, that is, degrees of freedom 
        are equal to the number of equations in the VAR times degree of freedom 
        of a single equation. 
 
        Test for Granger-causality as described in chapter 7.6.3 of [1]_. 
        Test H0: &quot;`causing` does not Granger-cause the remaining variables of 
        the system&quot; against  H1: &quot;`causing` is Granger-causal for the 
        remaining variables&quot;. 
 
        Returns 
        ------- 
        results : CausalityTestResults 
 
        References 
        ---------- 
        .. [1] Lütkepohl, H. 2005. *New Introduction to Multiple Time Series* 
           *Analysis*. Springer. 
        &quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s1">(</span><span class="s4">0 </span><span class="s1">&lt; signif &lt; </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;signif has to be between 0 and 1&quot;</span><span class="s1">)</span>

        <span class="s1">allowed_types = (str</span><span class="s3">, </span><span class="s1">int)</span>

        <span class="s3">if </span><span class="s1">isinstance(caused</span><span class="s3">, </span><span class="s1">allowed_types):</span>
            <span class="s1">caused = [caused]</span>
        <span class="s3">if not </span><span class="s1">all(isinstance(c</span><span class="s3">, </span><span class="s1">allowed_types) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">caused):</span>
            <span class="s3">raise </span><span class="s1">TypeError(</span>
                <span class="s5">&quot;caused has to be of type string or int (or a &quot;</span>
                <span class="s5">&quot;sequence of these types).&quot;</span>
            <span class="s1">)</span>
        <span class="s1">caused = [self.names[c] </span><span class="s3">if </span><span class="s1">type(c) == int </span><span class="s3">else </span><span class="s1">c </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">caused]</span>
        <span class="s1">caused_ind = [util.get_index(self.names</span><span class="s3">, </span><span class="s1">c) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">caused]</span>

        <span class="s3">if </span><span class="s1">causing </span><span class="s3">is not None</span><span class="s1">:</span>

            <span class="s3">if </span><span class="s1">isinstance(causing</span><span class="s3">, </span><span class="s1">allowed_types):</span>
                <span class="s1">causing = [causing]</span>
            <span class="s3">if not </span><span class="s1">all(isinstance(c</span><span class="s3">, </span><span class="s1">allowed_types) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing):</span>
                <span class="s3">raise </span><span class="s1">TypeError(</span>
                    <span class="s5">&quot;causing has to be of type string or int (or &quot;</span>
                    <span class="s5">&quot;a sequence of these types) or None.&quot;</span>
                <span class="s1">)</span>
            <span class="s1">causing = [self.names[c] </span><span class="s3">if </span><span class="s1">type(c) == int </span><span class="s3">else </span><span class="s1">c </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing]</span>
            <span class="s1">causing_ind = [util.get_index(self.names</span><span class="s3">, </span><span class="s1">c) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">causing_ind = [i </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.neqs) </span><span class="s3">if </span><span class="s1">i </span><span class="s3">not in </span><span class="s1">caused_ind]</span>
            <span class="s1">causing = [self.names[c] </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">caused_ind]</span>

        <span class="s1">k</span><span class="s3">, </span><span class="s1">p = self.neqs</span><span class="s3">, </span><span class="s1">self.k_ar</span>
        <span class="s3">if </span><span class="s1">p == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">err = </span><span class="s5">&quot;Cannot test Granger Causality in a model with 0 lags.&quot;</span>
            <span class="s3">raise </span><span class="s1">RuntimeError(err)</span>

        <span class="s0"># number of restrictions</span>
        <span class="s1">num_restr = len(causing) * len(caused) * p</span>
        <span class="s1">num_det_terms = self.k_exog</span>

        <span class="s0"># Make restriction matrix</span>
        <span class="s1">C = np.zeros((num_restr</span><span class="s3">, </span><span class="s1">k * num_det_terms + k ** </span><span class="s4">2 </span><span class="s1">* p)</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s1">cols_det = k * num_det_terms</span>
        <span class="s1">row = </span><span class="s4">0</span>
        <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(p):</span>
            <span class="s3">for </span><span class="s1">ing_ind </span><span class="s3">in </span><span class="s1">causing_ind:</span>
                <span class="s3">for </span><span class="s1">ed_ind </span><span class="s3">in </span><span class="s1">caused_ind:</span>
                    <span class="s1">C[row</span><span class="s3">, </span><span class="s1">cols_det + ed_ind + k * ing_ind + k ** </span><span class="s4">2 </span><span class="s1">* j] = </span><span class="s4">1</span>
                    <span class="s1">row += </span><span class="s4">1</span>

        <span class="s0"># Lütkepohl 3.6.5</span>
        <span class="s1">Cb = np.dot(C</span><span class="s3">, </span><span class="s1">vec(self.params.T))</span>
        <span class="s1">middle = np.linalg.inv(C @ self.cov_params() @ C.T)</span>

        <span class="s0"># wald statistic</span>
        <span class="s1">lam_wald = statistic = Cb @ middle @ Cb</span>

        <span class="s3">if </span><span class="s1">kind.lower() == </span><span class="s5">&quot;wald&quot;</span><span class="s1">:</span>
            <span class="s1">df = num_restr</span>
            <span class="s1">dist = stats.chi2(df)</span>
        <span class="s3">elif </span><span class="s1">kind.lower() == </span><span class="s5">&quot;f&quot;</span><span class="s1">:</span>
            <span class="s1">statistic = lam_wald / num_restr</span>
            <span class="s1">df = (num_restr</span><span class="s3">, </span><span class="s1">k * self.df_resid)</span>
            <span class="s1">dist = stats.f(*df)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;kind %s not recognized&quot; </span><span class="s1">% kind)</span>

        <span class="s1">pvalue = dist.sf(statistic)</span>
        <span class="s1">crit_value = dist.ppf(</span><span class="s4">1 </span><span class="s1">- signif)</span>

        <span class="s3">return </span><span class="s1">CausalityTestResults(</span>
            <span class="s1">causing</span><span class="s3">,</span>
            <span class="s1">caused</span><span class="s3">,</span>
            <span class="s1">statistic</span><span class="s3">,</span>
            <span class="s1">crit_value</span><span class="s3">,</span>
            <span class="s1">pvalue</span><span class="s3">,</span>
            <span class="s1">df</span><span class="s3">,</span>
            <span class="s1">signif</span><span class="s3">,</span>
            <span class="s1">test=</span><span class="s5">&quot;granger&quot;</span><span class="s3">,</span>
            <span class="s1">method=kind</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_inst_causality(self</span><span class="s3">, </span><span class="s1">causing</span><span class="s3">, </span><span class="s1">signif=</span><span class="s4">0.05</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Test for instantaneous causality 
 
        Parameters 
        ---------- 
        causing : 
            If int or str, test whether the corresponding variable is causing 
            the variable(s) specified in caused. 
            If sequence of int or str, test whether the corresponding 
            variables are causing the variable(s) specified in caused. 
        signif : float between 0 and 1, default 5 % 
            Significance level for computing critical values for test, 
            defaulting to standard 0.05 level 
        verbose : bool 
            If True, print a table with the results. 
 
        Returns 
        ------- 
        results : dict 
            A dict holding the test's results. The dict's keys are: 
 
            &quot;statistic&quot; : float 
              The calculated test statistic. 
 
            &quot;crit_value&quot; : float 
              The critical value of the Chi^2-distribution. 
 
            &quot;pvalue&quot; : float 
              The p-value corresponding to the test statistic. 
 
            &quot;df&quot; : float 
              The degrees of freedom of the Chi^2-distribution. 
 
            &quot;conclusion&quot; : str {&quot;reject&quot;, &quot;fail to reject&quot;} 
              Whether H0 can be rejected or not. 
 
            &quot;signif&quot; : float 
              Significance level 
 
        Notes 
        ----- 
        Test for instantaneous causality as described in chapters 3.6.3 and 
        7.6.4 of [1]_. 
        Test H0: &quot;No instantaneous causality between caused and causing&quot; 
        against H1: &quot;Instantaneous causality between caused and causing 
        exists&quot;. 
 
        Instantaneous causality is a symmetric relation (i.e. if causing is 
        &quot;instantaneously causing&quot; caused, then also caused is &quot;instantaneously 
        causing&quot; causing), thus the naming of the parameters (which is chosen 
        to be in accordance with test_granger_causality()) may be misleading. 
 
        This method is not returning the same result as JMulTi. This is 
        because the test is based on a VAR(k_ar) model in statsmodels 
        (in accordance to pp. 104, 320-321 in [1]_) whereas JMulTi seems 
        to be using a VAR(k_ar+1) model. 
 
        References 
        ---------- 
        .. [1] Lütkepohl, H. 2005. *New Introduction to Multiple Time Series* 
           *Analysis*. Springer. 
        &quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s1">(</span><span class="s4">0 </span><span class="s1">&lt; signif &lt; </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;signif has to be between 0 and 1&quot;</span><span class="s1">)</span>

        <span class="s1">allowed_types = (str</span><span class="s3">, </span><span class="s1">int)</span>
        <span class="s3">if </span><span class="s1">isinstance(causing</span><span class="s3">, </span><span class="s1">allowed_types):</span>
            <span class="s1">causing = [causing]</span>
        <span class="s3">if not </span><span class="s1">all(isinstance(c</span><span class="s3">, </span><span class="s1">allowed_types) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing):</span>
            <span class="s3">raise </span><span class="s1">TypeError(</span>
                <span class="s5">&quot;causing has to be of type string or int (or a &quot;</span>
                <span class="s1">+ </span><span class="s5">&quot;a sequence of these types).&quot;</span>
            <span class="s1">)</span>
        <span class="s1">causing = [self.names[c] </span><span class="s3">if </span><span class="s1">type(c) == int </span><span class="s3">else </span><span class="s1">c </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing]</span>
        <span class="s1">causing_ind = [util.get_index(self.names</span><span class="s3">, </span><span class="s1">c) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">causing]</span>

        <span class="s1">caused_ind = [i </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.neqs) </span><span class="s3">if </span><span class="s1">i </span><span class="s3">not in </span><span class="s1">causing_ind]</span>
        <span class="s1">caused = [self.names[c] </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">caused_ind]</span>

        <span class="s0"># Note: JMulTi seems to be using k_ar+1 instead of k_ar</span>
        <span class="s1">k</span><span class="s3">, </span><span class="s1">t</span><span class="s3">, </span><span class="s1">p = self.neqs</span><span class="s3">, </span><span class="s1">self.nobs</span><span class="s3">, </span><span class="s1">self.k_ar</span>

        <span class="s1">num_restr = len(causing) * len(caused)  </span><span class="s0"># called N in Lütkepohl</span>

        <span class="s1">sigma_u = self.sigma_u</span>
        <span class="s1">vech_sigma_u = util.vech(sigma_u)</span>
        <span class="s1">sig_mask = np.zeros(sigma_u.shape)</span>
        <span class="s0"># set =1 twice to ensure, that all the ones needed are below the main</span>
        <span class="s0"># diagonal:</span>
        <span class="s1">sig_mask[causing_ind</span><span class="s3">, </span><span class="s1">caused_ind] = </span><span class="s4">1</span>
        <span class="s1">sig_mask[caused_ind</span><span class="s3">, </span><span class="s1">causing_ind] = </span><span class="s4">1</span>
        <span class="s1">vech_sig_mask = util.vech(sig_mask)</span>
        <span class="s1">inds = np.nonzero(vech_sig_mask)[</span><span class="s4">0</span><span class="s1">]</span>

        <span class="s0"># Make restriction matrix</span>
        <span class="s1">C = np.zeros((num_restr</span><span class="s3">, </span><span class="s1">len(vech_sigma_u))</span><span class="s3">, </span><span class="s1">dtype=float)</span>
        <span class="s3">for </span><span class="s1">row </span><span class="s3">in </span><span class="s1">range(num_restr):</span>
            <span class="s1">C[row</span><span class="s3">, </span><span class="s1">inds[row]] = </span><span class="s4">1</span>
        <span class="s1">Cs = np.dot(C</span><span class="s3">, </span><span class="s1">vech_sigma_u)</span>
        <span class="s1">d = np.linalg.pinv(duplication_matrix(k))</span>
        <span class="s1">Cd = np.dot(C</span><span class="s3">, </span><span class="s1">d)</span>
        <span class="s1">middle = np.linalg.inv(Cd @ np.kron(sigma_u</span><span class="s3">, </span><span class="s1">sigma_u) @ Cd.T) / </span><span class="s4">2</span>

        <span class="s1">wald_statistic = t * (Cs.T @ middle @ Cs)</span>
        <span class="s1">df = num_restr</span>
        <span class="s1">dist = stats.chi2(df)</span>

        <span class="s1">pvalue = dist.sf(wald_statistic)</span>
        <span class="s1">crit_value = dist.ppf(</span><span class="s4">1 </span><span class="s1">- signif)</span>

        <span class="s3">return </span><span class="s1">CausalityTestResults(</span>
            <span class="s1">causing</span><span class="s3">,</span>
            <span class="s1">caused</span><span class="s3">,</span>
            <span class="s1">wald_statistic</span><span class="s3">,</span>
            <span class="s1">crit_value</span><span class="s3">,</span>
            <span class="s1">pvalue</span><span class="s3">,</span>
            <span class="s1">df</span><span class="s3">,</span>
            <span class="s1">signif</span><span class="s3">,</span>
            <span class="s1">test=</span><span class="s5">&quot;inst&quot;</span><span class="s3">,</span>
            <span class="s1">method=</span><span class="s5">&quot;wald&quot;</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_whiteness(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">signif=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">adjusted=</span><span class="s3">False</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Residual whiteness tests using Portmanteau test 
 
        Parameters 
        ---------- 
        nlags : int &gt; 0 
            The number of lags tested must be larger than the number of lags 
            included in the VAR model. 
        signif : float, between 0 and 1 
            The significance level of the test. 
        adjusted : bool, default False 
            Flag indicating to apply small-sample adjustments. 
 
        Returns 
        ------- 
        WhitenessTestResults 
            The test results. 
 
        Notes 
        ----- 
        Test the whiteness of the residuals using the Portmanteau test as 
        described in [1]_, chapter 4.4.3. 
 
        References 
        ---------- 
        .. [1] Lütkepohl, H. 2005. *New Introduction to Multiple Time Series* 
           *Analysis*. Springer. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">nlags - self.k_ar &lt;= </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s5">&quot;The whiteness test can only be used when nlags &quot;</span>
                <span class="s5">&quot;is larger than the number of lags included in &quot;</span>
                <span class="s5">f&quot;the model (</span><span class="s3">{</span><span class="s1">self.k_ar</span><span class="s3">}</span><span class="s5">).&quot;</span>
            <span class="s1">)</span>
        <span class="s1">statistic = </span><span class="s4">0</span>
        <span class="s1">u = np.asarray(self.resid)</span>
        <span class="s1">acov_list = _compute_acov(u</span><span class="s3">, </span><span class="s1">nlags)</span>
        <span class="s1">cov0_inv = np.linalg.inv(acov_list[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">nlags + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s1">ct = acov_list[t]</span>
            <span class="s1">to_add = np.trace(ct.T @ cov0_inv @ ct @ cov0_inv)</span>
            <span class="s3">if </span><span class="s1">adjusted:</span>
                <span class="s1">to_add /= self.nobs - t</span>
            <span class="s1">statistic += to_add</span>
        <span class="s1">statistic *= self.nobs ** </span><span class="s4">2 </span><span class="s3">if </span><span class="s1">adjusted </span><span class="s3">else </span><span class="s1">self.nobs</span>
        <span class="s1">df = self.neqs ** </span><span class="s4">2 </span><span class="s1">* (nlags - self.k_ar)</span>
        <span class="s1">dist = stats.chi2(df)</span>
        <span class="s1">pvalue = dist.sf(statistic)</span>
        <span class="s1">crit_value = dist.ppf(</span><span class="s4">1 </span><span class="s1">- signif)</span>

        <span class="s3">return </span><span class="s1">WhitenessTestResults(</span>
            <span class="s1">statistic</span><span class="s3">, </span><span class="s1">crit_value</span><span class="s3">, </span><span class="s1">pvalue</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">signif</span><span class="s3">, </span><span class="s1">nlags</span><span class="s3">, </span><span class="s1">adjusted</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">plot_acorr(self</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">resid=</span><span class="s3">True, </span><span class="s1">linewidth=</span><span class="s4">8</span><span class="s1">):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Plot autocorrelation of sample (endog) or residuals 
 
        Sample (Y) or Residual autocorrelations are plotted together with the 
        standard :math:`2 / \sqrt{T}` bounds. 
 
        Parameters 
        ---------- 
        nlags : int 
            number of lags to display (excluding 0) 
        resid : bool 
            If True, then the autocorrelation of the residuals is plotted 
            If False, then the autocorrelation of endog is plotted. 
        linewidth : int 
            width of vertical bars 
 
        Returns 
        ------- 
        Figure 
            Figure instance containing the plot. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">resid:</span>
            <span class="s1">acorrs = self.resid_acorr(nlags)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">acorrs = self.sample_acorr(nlags)</span>

        <span class="s1">bound = </span><span class="s4">2 </span><span class="s1">/ np.sqrt(self.nobs)</span>

        <span class="s1">fig = plotting.plot_full_acorr(</span>
            <span class="s1">acorrs[</span><span class="s4">1</span><span class="s1">:]</span><span class="s3">,</span>
            <span class="s1">xlabel=np.arange(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">nlags + </span><span class="s4">1</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">err_bound=bound</span><span class="s3">,</span>
            <span class="s1">linewidth=linewidth</span><span class="s3">,</span>
        <span class="s1">)</span>
        <span class="s1">fig.suptitle(</span><span class="s5">r&quot;ACF plots for residuals with $2 / \sqrt{T}$ bounds &quot;</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>

    <span class="s3">def </span><span class="s1">test_normality(self</span><span class="s3">, </span><span class="s1">signif=</span><span class="s4">0.05</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Test assumption of normal-distributed errors using Jarque-Bera-style 
        omnibus Chi^2 test. 
 
        Parameters 
        ---------- 
        signif : float 
            Test significance level. 
 
        Returns 
        ------- 
        result : NormalityTestResults 
 
        Notes 
        ----- 
        H0 (null) : data are generated by a Gaussian-distributed process 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">test_normality(self</span><span class="s3">, </span><span class="s1">signif=signif)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">detomega(self):</span>
        <span class="s2">r&quot;&quot;&quot; 
        Return determinant of white noise covariance with degrees of freedom 
        correction: 
 
        .. math:: 
 
            \hat \Omega = \frac{T}{T - Kp - 1} \hat \Omega_{\mathrm{MLE}} 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">np.linalg.det(self.sigma_u)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">info_criteria(self):</span>
        <span class="s2">&quot;information criteria for lagorder selection&quot;</span>
        <span class="s1">nobs = self.nobs</span>
        <span class="s1">neqs = self.neqs</span>
        <span class="s1">lag_order = self.k_ar</span>
        <span class="s1">free_params = lag_order * neqs ** </span><span class="s4">2 </span><span class="s1">+ neqs * self.k_exog</span>
        <span class="s3">if </span><span class="s1">self.df_resid:</span>
            <span class="s1">ld = logdet_symm(self.sigma_u_mle)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">ld = -np.inf</span>

        <span class="s0"># See Lütkepohl pp. 146-150</span>

        <span class="s1">aic = ld + (</span><span class="s4">2.0 </span><span class="s1">/ nobs) * free_params</span>
        <span class="s1">bic = ld + (np.log(nobs) / nobs) * free_params</span>
        <span class="s1">hqic = ld + (</span><span class="s4">2.0 </span><span class="s1">* np.log(np.log(nobs)) / nobs) * free_params</span>
        <span class="s3">if </span><span class="s1">self.df_resid:</span>
            <span class="s1">fpe = ((nobs + self.df_model) / self.df_resid) ** neqs * np.exp(ld)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">fpe = np.inf</span>

        <span class="s3">return </span><span class="s1">{</span><span class="s5">&quot;aic&quot;</span><span class="s1">: aic</span><span class="s3">, </span><span class="s5">&quot;bic&quot;</span><span class="s1">: bic</span><span class="s3">, </span><span class="s5">&quot;hqic&quot;</span><span class="s1">: hqic</span><span class="s3">, </span><span class="s5">&quot;fpe&quot;</span><span class="s1">: fpe}</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">aic(self):</span>
        <span class="s2">&quot;&quot;&quot;Akaike information criterion&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.info_criteria[</span><span class="s5">&quot;aic&quot;</span><span class="s1">]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">fpe(self):</span>
        <span class="s2">&quot;&quot;&quot;Final Prediction Error (FPE) 
 
        Lütkepohl p. 147, see info_criteria 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.info_criteria[</span><span class="s5">&quot;fpe&quot;</span><span class="s1">]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">hqic(self):</span>
        <span class="s2">&quot;&quot;&quot;Hannan-Quinn criterion&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.info_criteria[</span><span class="s5">&quot;hqic&quot;</span><span class="s1">]</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">bic(self):</span>
        <span class="s2">&quot;&quot;&quot;Bayesian a.k.a. Schwarz info criterion&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self.info_criteria[</span><span class="s5">&quot;bic&quot;</span><span class="s1">]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s3">def </span><span class="s1">roots(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        The roots of the VAR process are the solution to 
        (I - coefs[0]*z - coefs[1]*z**2 ... - coefs[p-1]*z**k_ar) = 0. 
        Note that the inverse roots are returned, and stability requires that 
        the roots lie outside the unit circle. 
        &quot;&quot;&quot;</span>
        <span class="s1">neqs = self.neqs</span>
        <span class="s1">k_ar = self.k_ar</span>
        <span class="s1">p = neqs * k_ar</span>
        <span class="s1">arr = np.zeros((p</span><span class="s3">, </span><span class="s1">p))</span>
        <span class="s1">arr[:neqs</span><span class="s3">, </span><span class="s1">:] = np.column_stack(self.coefs)</span>
        <span class="s1">arr[neqs:</span><span class="s3">, </span><span class="s1">:-neqs] = np.eye(p - neqs)</span>
        <span class="s1">roots = np.linalg.eig(arr)[</span><span class="s4">0</span><span class="s1">] ** -</span><span class="s4">1</span>
        <span class="s1">idx = np.argsort(np.abs(roots))[::-</span><span class="s4">1</span><span class="s1">]  </span><span class="s0"># sort by reverse modulus</span>
        <span class="s3">return </span><span class="s1">roots[idx]</span>


<span class="s3">class </span><span class="s1">VARResultsWrapper(wrap.ResultsWrapper):</span>
    <span class="s1">_attrs = {</span>
        <span class="s5">&quot;bse&quot;</span><span class="s1">: </span><span class="s5">&quot;columns_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;cov_params&quot;</span><span class="s1">: </span><span class="s5">&quot;cov&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;params&quot;</span><span class="s1">: </span><span class="s5">&quot;columns_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;pvalues&quot;</span><span class="s1">: </span><span class="s5">&quot;columns_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;tvalues&quot;</span><span class="s1">: </span><span class="s5">&quot;columns_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;sigma_u&quot;</span><span class="s1">: </span><span class="s5">&quot;cov_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;sigma_u_mle&quot;</span><span class="s1">: </span><span class="s5">&quot;cov_eq&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;stderr&quot;</span><span class="s1">: </span><span class="s5">&quot;columns_eq&quot;</span><span class="s3">,</span>
    <span class="s1">}</span>
    <span class="s1">_wrap_attrs = wrap.union_dicts(</span>
        <span class="s1">TimeSeriesResultsWrapper._wrap_attrs</span><span class="s3">, </span><span class="s1">_attrs</span>
    <span class="s1">)</span>
    <span class="s1">_methods = {</span><span class="s5">&quot;conf_int&quot;</span><span class="s1">: </span><span class="s5">&quot;multivariate_confint&quot;</span><span class="s1">}</span>
    <span class="s1">_wrap_methods = wrap.union_dicts(</span>
        <span class="s1">TimeSeriesResultsWrapper._wrap_methods</span><span class="s3">, </span><span class="s1">_methods</span>
    <span class="s1">)</span>


<span class="s1">wrap.populate_wrapper(VARResultsWrapper</span><span class="s3">, </span><span class="s1">VARResults)  </span><span class="s0"># noqa:E305</span>


<span class="s3">class </span><span class="s1">FEVD:</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute and plot Forecast error variance decomposition and asymptotic 
    standard errors 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">model</span><span class="s3">, </span><span class="s1">P=</span><span class="s3">None, </span><span class="s1">periods=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.periods = periods</span>

        <span class="s1">self.model = model</span>
        <span class="s1">self.neqs = model.neqs</span>
        <span class="s1">self.names = model.model.endog_names</span>

        <span class="s1">self.irfobj = model.irf(var_decomp=P</span><span class="s3">, </span><span class="s1">periods=periods)</span>
        <span class="s1">self.orth_irfs = self.irfobj.orth_irfs</span>

        <span class="s0"># cumulative impulse responses</span>
        <span class="s1">irfs = (self.orth_irfs[:periods] ** </span><span class="s4">2</span><span class="s1">).cumsum(axis=</span><span class="s4">0</span><span class="s1">)</span>

        <span class="s1">rng = lrange(self.neqs)</span>
        <span class="s1">mse = self.model.mse(periods)[:</span><span class="s3">, </span><span class="s1">rng</span><span class="s3">, </span><span class="s1">rng]</span>

        <span class="s0"># lag x equation x component</span>
        <span class="s1">fevd = np.empty_like(irfs)</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(periods):</span>
            <span class="s1">fevd[i] = (irfs[i].T / mse[i]).T</span>

        <span class="s0"># switch to equation x lag x component</span>
        <span class="s1">self.decomp = fevd.swapaxes(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">summary(self):</span>
        <span class="s1">buf = StringIO()</span>

        <span class="s1">rng = lrange(self.periods)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(self.neqs):</span>
            <span class="s1">ppm = output.pprint_matrix(self.decomp[i]</span><span class="s3">, </span><span class="s1">rng</span><span class="s3">, </span><span class="s1">self.names)</span>

            <span class="s1">buf.write(</span><span class="s5">&quot;FEVD for %s</span><span class="s3">\n</span><span class="s5">&quot; </span><span class="s1">% self.names[i])</span>
            <span class="s1">buf.write(ppm + </span><span class="s5">&quot;</span><span class="s3">\n</span><span class="s5">&quot;</span><span class="s1">)</span>

        <span class="s1">print(buf.getvalue())</span>

    <span class="s3">def </span><span class="s1">cov(self):</span>
        <span class="s2">&quot;&quot;&quot;Compute asymptotic standard errors 
 
        Returns 
        ------- 
        &quot;&quot;&quot;</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError</span>

    <span class="s3">def </span><span class="s1">plot(self</span><span class="s3">, </span><span class="s1">periods=</span><span class="s3">None, </span><span class="s1">figsize=(</span><span class="s4">10</span><span class="s3">, </span><span class="s4">10</span><span class="s1">)</span><span class="s3">, </span><span class="s1">**plot_kwds):</span>
        <span class="s2">&quot;&quot;&quot;Plot graphical display of FEVD 
 
        Parameters 
        ---------- 
        periods : int, default None 
            Defaults to number originally specified. Can be at most that number 
        &quot;&quot;&quot;</span>
        <span class="s3">import </span><span class="s1">matplotlib.pyplot </span><span class="s3">as </span><span class="s1">plt</span>

        <span class="s1">k = self.neqs</span>
        <span class="s1">periods = periods </span><span class="s3">or </span><span class="s1">self.periods</span>

        <span class="s1">fig</span><span class="s3">, </span><span class="s1">axes = plt.subplots(nrows=k</span><span class="s3">, </span><span class="s1">figsize=figsize)</span>

        <span class="s1">fig.suptitle(</span><span class="s5">&quot;Forecast error variance decomposition (FEVD)&quot;</span><span class="s1">)</span>

        <span class="s1">colors = [str(c) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">np.arange(k</span><span class="s3">, </span><span class="s1">dtype=float) / k]</span>
        <span class="s1">ticks = np.arange(periods)</span>

        <span class="s1">limits = self.decomp.cumsum(</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">ax = axes[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k):</span>
            <span class="s1">ax = axes[i]</span>

            <span class="s1">this_limits = limits[i].T</span>

            <span class="s1">handles = []</span>

            <span class="s3">for </span><span class="s1">j </span><span class="s3">in </span><span class="s1">range(k):</span>
                <span class="s1">lower = this_limits[j - </span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">j &gt; </span><span class="s4">0 </span><span class="s3">else </span><span class="s4">0</span>
                <span class="s1">upper = this_limits[j]</span>
                <span class="s1">handle = ax.bar(</span>
                    <span class="s1">ticks</span><span class="s3">,</span>
                    <span class="s1">upper - lower</span><span class="s3">,</span>
                    <span class="s1">bottom=lower</span><span class="s3">,</span>
                    <span class="s1">color=colors[j]</span><span class="s3">,</span>
                    <span class="s1">label=self.names[j]</span><span class="s3">,</span>
                    <span class="s1">**plot_kwds</span><span class="s3">,</span>
                <span class="s1">)</span>

                <span class="s1">handles.append(handle)</span>

            <span class="s1">ax.set_title(self.names[i])</span>

        <span class="s0"># just use the last axis to get handles for plotting</span>
        <span class="s1">handles</span><span class="s3">, </span><span class="s1">labels = ax.get_legend_handles_labels()</span>
        <span class="s1">fig.legend(handles</span><span class="s3">, </span><span class="s1">labels</span><span class="s3">, </span><span class="s1">loc=</span><span class="s5">&quot;upper right&quot;</span><span class="s1">)</span>
        <span class="s1">plotting.adjust_subplots(right=</span><span class="s4">0.85</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">fig</span>


<span class="s0"># -------------------------------------------------------------------------------</span>


<span class="s3">def </span><span class="s1">_compute_acov(x</span><span class="s3">, </span><span class="s1">nlags=</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s1">x = x - x.mean(</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">result = []</span>
    <span class="s3">for </span><span class="s1">lag </span><span class="s3">in </span><span class="s1">range(nlags + </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s3">if </span><span class="s1">lag &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">r = np.dot(x[lag:].T</span><span class="s3">, </span><span class="s1">x[:-lag])</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">r = np.dot(x.T</span><span class="s3">, </span><span class="s1">x)</span>

        <span class="s1">result.append(r)</span>

    <span class="s3">return </span><span class="s1">np.array(result) / len(x)</span>


<span class="s3">def </span><span class="s1">_acovs_to_acorrs(acovs):</span>
    <span class="s1">sd = np.sqrt(np.diag(acovs[</span><span class="s4">0</span><span class="s1">]))</span>
    <span class="s3">return </span><span class="s1">acovs / np.outer(sd</span><span class="s3">, </span><span class="s1">sd)</span>
</pre>
</body>
</html>
<html>
<head>
<title>_shgo.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_shgo.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;shgo: The simplicial homology global optimisation algorithm.&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">namedtuple</span>
<span class="s2">import </span><span class="s1">time</span>
<span class="s2">import </span><span class="s1">logging</span>
<span class="s2">import </span><span class="s1">warnings</span>
<span class="s2">import </span><span class="s1">sys</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">spatial</span>
<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">OptimizeResult</span><span class="s2">, </span><span class="s1">minimize</span><span class="s2">, </span><span class="s1">Bounds</span>
<span class="s2">from </span><span class="s1">scipy.optimize._optimize </span><span class="s2">import </span><span class="s1">MemoizeJac</span>
<span class="s2">from </span><span class="s1">scipy.optimize._constraints </span><span class="s2">import </span><span class="s1">new_bounds_to_old</span>
<span class="s2">from </span><span class="s1">scipy.optimize._minimize </span><span class="s2">import </span><span class="s1">standardize_constraints</span>
<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">_FunctionWrapper</span>

<span class="s2">from </span><span class="s1">scipy.optimize._shgo_lib._complex </span><span class="s2">import </span><span class="s1">Complex</span>

<span class="s1">__all__ = [</span><span class="s3">'shgo'</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">shgo(</span>
    <span class="s1">func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">constraints=</span><span class="s2">None, </span><span class="s1">n=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">iters=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">callback=</span><span class="s2">None,</span>
    <span class="s1">minimizer_kwargs=</span><span class="s2">None, </span><span class="s1">options=</span><span class="s2">None, </span><span class="s1">sampling_method=</span><span class="s3">'simplicial'</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
    <span class="s1">workers=</span><span class="s4">1</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Finds the global minimum of a function using SHG optimization. 
 
    SHGO stands for &quot;simplicial homology global optimization&quot;. 
 
    Parameters 
    ---------- 
    func : callable 
        The objective function to be minimized.  Must be in the form 
        ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array 
        and ``args`` is a tuple of any additional fixed parameters needed to 
        completely specify the function. 
    bounds : sequence or `Bounds` 
        Bounds for variables. There are two ways to specify the bounds: 
 
        1. Instance of `Bounds` class. 
        2. Sequence of ``(min, max)`` pairs for each element in `x`. 
 
    args : tuple, optional 
        Any additional fixed parameters needed to completely specify the 
        objective function. 
    constraints : {Constraint, dict} or List of {Constraint, dict}, optional 
        Constraints definition. Only for COBYLA, SLSQP and trust-constr. 
        See the tutorial [5]_ for further details on specifying constraints. 
 
        .. note:: 
 
           Only COBYLA, SLSQP, and trust-constr local minimize methods 
           currently support constraint arguments. If the ``constraints`` 
           sequence used in the local optimization problem is not defined in 
           ``minimizer_kwargs`` and a constrained method is used then the 
           global ``constraints`` will be used. 
           (Defining a ``constraints`` sequence in ``minimizer_kwargs`` 
           means that ``constraints`` will not be added so if equality 
           constraints and so forth need to be added then the inequality 
           functions in ``constraints`` need to be added to 
           ``minimizer_kwargs`` too). 
           COBYLA only supports inequality constraints. 
 
        .. versionchanged:: 1.11.0 
 
           ``constraints`` accepts `NonlinearConstraint`, `LinearConstraint`. 
 
    n : int, optional 
        Number of sampling points used in the construction of the simplicial 
        complex. For the default ``simplicial`` sampling method 2**dim + 1 
        sampling points are generated instead of the default `n=100`. For all 
        other specified values `n` sampling points are generated. For 
        ``sobol``, ``halton`` and other arbitrary `sampling_methods` `n=100` or 
        another speciefied number of sampling points are generated. 
    iters : int, optional 
        Number of iterations used in the construction of the simplicial 
        complex. Default is 1. 
    callback : callable, optional 
        Called after each iteration, as ``callback(xk)``, where ``xk`` is the 
        current parameter vector. 
    minimizer_kwargs : dict, optional 
        Extra keyword arguments to be passed to the minimizer 
        ``scipy.optimize.minimize`` Some important options could be: 
 
            * method : str 
                The minimization method. If not given, chosen to be one of 
                BFGS, L-BFGS-B, SLSQP, depending on whether or not the 
                problem has constraints or bounds. 
            * args : tuple 
                Extra arguments passed to the objective function (``func``) and 
                its derivatives (Jacobian, Hessian). 
            * options : dict, optional 
                Note that by default the tolerance is specified as 
                ``{ftol: 1e-12}`` 
 
    options : dict, optional 
        A dictionary of solver options. Many of the options specified for the 
        global routine are also passed to the scipy.optimize.minimize routine. 
        The options that are also passed to the local routine are marked with 
        &quot;(L)&quot;. 
 
        Stopping criteria, the algorithm will terminate if any of the specified 
        criteria are met. However, the default algorithm does not require any 
        to be specified: 
 
        * maxfev : int (L) 
            Maximum number of function evaluations in the feasible domain. 
            (Note only methods that support this option will terminate 
            the routine at precisely exact specified value. Otherwise the 
            criterion will only terminate during a global iteration) 
        * f_min 
            Specify the minimum objective function value, if it is known. 
        * f_tol : float 
            Precision goal for the value of f in the stopping 
            criterion. Note that the global routine will also 
            terminate if a sampling point in the global routine is 
            within this tolerance. 
        * maxiter : int 
            Maximum number of iterations to perform. 
        * maxev : int 
            Maximum number of sampling evaluations to perform (includes 
            searching in infeasible points). 
        * maxtime : float 
            Maximum processing runtime allowed 
        * minhgrd : int 
            Minimum homology group rank differential. The homology group of the 
            objective function is calculated (approximately) during every 
            iteration. The rank of this group has a one-to-one correspondence 
            with the number of locally convex subdomains in the objective 
            function (after adequate sampling points each of these subdomains 
            contain a unique global minimum). If the difference in the hgr is 0 
            between iterations for ``maxhgrd`` specified iterations the 
            algorithm will terminate. 
 
        Objective function knowledge: 
 
        * symmetry : list or bool 
            Specify if the objective function contains symmetric variables. 
            The search space (and therefore performance) is decreased by up to 
            O(n!) times in the fully symmetric case. If `True` is specified 
            then all variables will be set symmetric to the first variable. 
            Default 
            is set to False. 
 
            E.g.  f(x) = (x_1 + x_2 + x_3) + (x_4)**2 + (x_5)**2 + (x_6)**2 
 
            In this equation x_2 and x_3 are symmetric to x_1, while x_5 and 
            x_6 are symmetric to x_4, this can be specified to the solver as: 
 
            symmetry = [0,  # Variable 1 
                        0,  # symmetric to variable 1 
                        0,  # symmetric to variable 1 
                        3,  # Variable 4 
                        3,  # symmetric to variable 4 
                        3,  # symmetric to variable 4 
                        ] 
 
        * jac : bool or callable, optional 
            Jacobian (gradient) of objective function. Only for CG, BFGS, 
            Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg. If ``jac`` is a 
            boolean and is True, ``fun`` is assumed to return the gradient 
            along with the objective function. If False, the gradient will be 
            estimated numerically. ``jac`` can also be a callable returning the 
            gradient of the objective. In this case, it must accept the same 
            arguments as ``fun``. (Passed to `scipy.optimize.minmize` 
            automatically) 
 
        * hess, hessp : callable, optional 
            Hessian (matrix of second-order derivatives) of objective function 
            or Hessian of objective function times an arbitrary vector p. 
            Only for Newton-CG, dogleg, trust-ncg. Only one of ``hessp`` or 
            ``hess`` needs to be given. If ``hess`` is provided, then 
            ``hessp`` will be ignored. If neither ``hess`` nor ``hessp`` is 
            provided, then the Hessian product will be approximated using 
            finite differences on ``jac``. ``hessp`` must compute the Hessian 
            times an arbitrary vector. (Passed to `scipy.optimize.minmize` 
            automatically) 
 
        Algorithm settings: 
 
        * minimize_every_iter : bool 
            If True then promising global sampling points will be passed to a 
            local minimization routine every iteration. If True then only the 
            final minimizer pool will be run. Defaults to True. 
        * local_iter : int 
            Only evaluate a few of the best minimizer pool candidates every 
            iteration. If False all potential points are passed to the local 
            minimization routine. 
        * infty_constraints : bool 
            If True then any sampling points generated which are outside will 
            the feasible domain will be saved and given an objective function 
            value of ``inf``. If False then these points will be discarded. 
            Using this functionality could lead to higher performance with 
            respect to function evaluations before the global minimum is found, 
            specifying False will use less memory at the cost of a slight 
            decrease in performance. Defaults to True. 
 
        Feedback: 
 
        * disp : bool (L) 
            Set to True to print convergence messages. 
 
    sampling_method : str or function, optional 
        Current built in sampling method options are ``halton``, ``sobol`` and 
        ``simplicial``. The default ``simplicial`` provides 
        the theoretical guarantee of convergence to the global minimum in 
        finite time. ``halton`` and ``sobol`` method are faster in terms of 
        sampling point generation at the cost of the loss of 
        guaranteed convergence. It is more appropriate for most &quot;easier&quot; 
        problems where the convergence is relatively fast. 
        User defined sampling functions must accept two arguments of ``n`` 
        sampling points of dimension ``dim`` per call and output an array of 
        sampling points with shape `n x dim`. 
 
    workers : int or map-like callable, optional 
        Sample and run the local serial minimizations in parallel. 
        Supply -1 to use all available CPU cores, or an int to use 
        that many Processes (uses `multiprocessing.Pool &lt;multiprocessing&gt;`). 
 
        Alternatively supply a map-like callable, such as 
        `multiprocessing.Pool.map` for parallel evaluation. 
        This evaluation is carried out as ``workers(func, iterable)``. 
        Requires that `func` be pickleable. 
 
        .. versionadded:: 1.11.0 
 
    Returns 
    ------- 
    res : OptimizeResult 
        The optimization result represented as a `OptimizeResult` object. 
        Important attributes are: 
        ``x`` the solution array corresponding to the global minimum, 
        ``fun`` the function output at the global solution, 
        ``xl`` an ordered list of local minima solutions, 
        ``funl`` the function output at the corresponding local solutions, 
        ``success`` a Boolean flag indicating if the optimizer exited 
        successfully, 
        ``message`` which describes the cause of the termination, 
        ``nfev`` the total number of objective function evaluations including 
        the sampling calls, 
        ``nlfev`` the total number of objective function evaluations 
        culminating from all local search optimizations, 
        ``nit`` number of iterations performed by the global routine. 
 
    Notes 
    ----- 
    Global optimization using simplicial homology global optimization [1]_. 
    Appropriate for solving general purpose NLP and blackbox optimization 
    problems to global optimality (low-dimensional problems). 
 
    In general, the optimization problems are of the form:: 
 
        minimize f(x) subject to 
 
        g_i(x) &gt;= 0,  i = 1,...,m 
        h_j(x)  = 0,  j = 1,...,p 
 
    where x is a vector of one or more variables. ``f(x)`` is the objective 
    function ``R^n -&gt; R``, ``g_i(x)`` are the inequality constraints, and 
    ``h_j(x)`` are the equality constraints. 
 
    Optionally, the lower and upper bounds for each element in x can also be 
    specified using the `bounds` argument. 
 
    While most of the theoretical advantages of SHGO are only proven for when 
    ``f(x)`` is a Lipschitz smooth function, the algorithm is also proven to 
    converge to the global optimum for the more general case where ``f(x)`` is 
    non-continuous, non-convex and non-smooth, if the default sampling method 
    is used [1]_. 
 
    The local search method may be specified using the ``minimizer_kwargs`` 
    parameter which is passed on to ``scipy.optimize.minimize``. By default, 
    the ``SLSQP`` method is used. In general, it is recommended to use the 
    ``SLSQP`` or ``COBYLA`` local minimization if inequality constraints 
    are defined for the problem since the other methods do not use constraints. 
 
    The ``halton`` and ``sobol`` method points are generated using 
    `scipy.stats.qmc`. Any other QMC method could be used. 
 
    References 
    ---------- 
    .. [1] Endres, SC, Sandrock, C, Focke, WW (2018) &quot;A simplicial homology 
           algorithm for lipschitz optimisation&quot;, Journal of Global 
           Optimization. 
    .. [2] Joe, SW and Kuo, FY (2008) &quot;Constructing Sobol' sequences with 
           better  two-dimensional projections&quot;, SIAM J. Sci. Comput. 30, 
           2635-2654. 
    .. [3] Hock, W and Schittkowski, K (1981) &quot;Test examples for nonlinear 
           programming codes&quot;, Lecture Notes in Economics and Mathematical 
           Systems, 187. Springer-Verlag, New York. 
           http://www.ai7.uni-bayreuth.de/test_problem_coll.pdf 
    .. [4] Wales, DJ (2015) &quot;Perspective: Insight into reaction coordinates and 
           dynamics from the potential energy landscape&quot;, 
           Journal of Chemical Physics, 142(13), 2015. 
    .. [5] https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize 
 
    Examples 
    -------- 
    First consider the problem of minimizing the Rosenbrock function, `rosen`: 
 
    &gt;&gt;&gt; from scipy.optimize import rosen, shgo 
    &gt;&gt;&gt; bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)] 
    &gt;&gt;&gt; result = shgo(rosen, bounds) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([1., 1., 1., 1., 1.]), 2.920392374190081e-18) 
 
    Note that bounds determine the dimensionality of the objective 
    function and is therefore a required input, however you can specify 
    empty bounds using ``None`` or objects like ``np.inf`` which will be 
    converted to large float numbers. 
 
    &gt;&gt;&gt; bounds = [(None, None), ]*4 
    &gt;&gt;&gt; result = shgo(rosen, bounds) 
    &gt;&gt;&gt; result.x 
    array([0.99999851, 0.99999704, 0.99999411, 0.9999882 ]) 
 
    Next, we consider the Eggholder function, a problem with several local 
    minima and one global minimum. We will demonstrate the use of arguments and 
    the capabilities of `shgo`. 
    (https://en.wikipedia.org/wiki/Test_functions_for_optimization) 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; def eggholder(x): 
    ...     return (-(x[1] + 47.0) 
    ...             * np.sin(np.sqrt(abs(x[0]/2.0 + (x[1] + 47.0)))) 
    ...             - x[0] * np.sin(np.sqrt(abs(x[0] - (x[1] + 47.0)))) 
    ...             ) 
    ... 
    &gt;&gt;&gt; bounds = [(-512, 512), (-512, 512)] 
 
    `shgo` has built-in low discrepancy sampling sequences. First, we will 
    input 64 initial sampling points of the *Sobol'* sequence: 
 
    &gt;&gt;&gt; result = shgo(eggholder, bounds, n=64, sampling_method='sobol') 
    &gt;&gt;&gt; result.x, result.fun 
    (array([512.        , 404.23180824]), -959.6406627208397) 
 
    `shgo` also has a return for any other local minima that was found, these 
    can be called using: 
 
    &gt;&gt;&gt; result.xl 
    array([[ 512.        ,  404.23180824], 
           [ 283.0759062 , -487.12565635], 
           [-294.66820039, -462.01964031], 
           [-105.87688911,  423.15323845], 
           [-242.97926   ,  274.38030925], 
           [-506.25823477,    6.3131022 ], 
           [-408.71980731, -156.10116949], 
           [ 150.23207937,  301.31376595], 
           [  91.00920901, -391.283763  ], 
           [ 202.89662724, -269.38043241], 
           [ 361.66623976, -106.96493868], 
           [-219.40612786, -244.06020508]]) 
 
    &gt;&gt;&gt; result.funl 
    array([-959.64066272, -718.16745962, -704.80659592, -565.99778097, 
           -559.78685655, -557.36868733, -507.87385942, -493.9605115 , 
           -426.48799655, -421.15571437, -419.31194957, -410.98477763]) 
 
    These results are useful in applications where there are many global minima 
    and the values of other global minima are desired or where the local minima 
    can provide insight into the system (for example morphologies 
    in physical chemistry [4]_). 
 
    If we want to find a larger number of local minima, we can increase the 
    number of sampling points or the number of iterations. We'll increase the 
    number of sampling points to 64 and the number of iterations from the 
    default of 1 to 3. Using ``simplicial`` this would have given us 
    64 x 3 = 192 initial sampling points. 
 
    &gt;&gt;&gt; result_2 = shgo(eggholder, 
    ...                 bounds, n=64, iters=3, sampling_method='sobol') 
    &gt;&gt;&gt; len(result.xl), len(result_2.xl) 
    (12, 23) 
 
    Note the difference between, e.g., ``n=192, iters=1`` and ``n=64, 
    iters=3``. 
    In the first case the promising points contained in the minimiser pool 
    are processed only once. In the latter case it is processed every 64 
    sampling points for a total of 3 times. 
 
    To demonstrate solving problems with non-linear constraints consider the 
    following example from Hock and Schittkowski problem 73 (cattle-feed) 
    [3]_:: 
 
        minimize: f = 24.55 * x_1 + 26.75 * x_2 + 39 * x_3 + 40.50 * x_4 
 
        subject to: 2.3 * x_1 + 5.6 * x_2 + 11.1 * x_3 + 1.3 * x_4 - 5    &gt;= 0, 
 
                    12 * x_1 + 11.9 * x_2 + 41.8 * x_3 + 52.1 * x_4 - 21 
                        -1.645 * sqrt(0.28 * x_1**2 + 0.19 * x_2**2 + 
                                      20.5 * x_3**2 + 0.62 * x_4**2)      &gt;= 0, 
 
                    x_1 + x_2 + x_3 + x_4 - 1                             == 0, 
 
                    1 &gt;= x_i &gt;= 0 for all i 
 
    The approximate answer given in [3]_ is:: 
 
        f([0.6355216, -0.12e-11, 0.3127019, 0.05177655]) = 29.894378 
 
    &gt;&gt;&gt; def f(x):  # (cattle-feed) 
    ...     return 24.55*x[0] + 26.75*x[1] + 39*x[2] + 40.50*x[3] 
    ... 
    &gt;&gt;&gt; def g1(x): 
    ...     return 2.3*x[0] + 5.6*x[1] + 11.1*x[2] + 1.3*x[3] - 5  # &gt;=0 
    ... 
    &gt;&gt;&gt; def g2(x): 
    ...     return (12*x[0] + 11.9*x[1] +41.8*x[2] + 52.1*x[3] - 21 
    ...             - 1.645 * np.sqrt(0.28*x[0]**2 + 0.19*x[1]**2 
    ...                             + 20.5*x[2]**2 + 0.62*x[3]**2) 
    ...             ) # &gt;=0 
    ... 
    &gt;&gt;&gt; def h1(x): 
    ...     return x[0] + x[1] + x[2] + x[3] - 1  # == 0 
    ... 
    &gt;&gt;&gt; cons = ({'type': 'ineq', 'fun': g1}, 
    ...         {'type': 'ineq', 'fun': g2}, 
    ...         {'type': 'eq', 'fun': h1}) 
    &gt;&gt;&gt; bounds = [(0, 1.0),]*4 
    &gt;&gt;&gt; res = shgo(f, bounds, n=150, constraints=cons) 
    &gt;&gt;&gt; res 
     message: Optimization terminated successfully. 
     success: True 
         fun: 29.894378159142136 
        funl: [ 2.989e+01] 
           x: [ 6.355e-01  1.137e-13  3.127e-01  5.178e-02] 
          xl: [[ 6.355e-01  1.137e-13  3.127e-01  5.178e-02]] 
         nit: 1 
        nfev: 142 
       nlfev: 35 
       nljev: 5 
       nlhev: 0 
 
    &gt;&gt;&gt; g1(res.x), g2(res.x), h1(res.x) 
    (-5.062616992290714e-14, -2.9594104944408173e-12, 0.0) 
 
    &quot;&quot;&quot;</span>
    <span class="s5"># if necessary, convert bounds class to old bounds</span>
    <span class="s2">if </span><span class="s1">isinstance(bounds</span><span class="s2">, </span><span class="s1">Bounds):</span>
        <span class="s1">bounds = new_bounds_to_old(bounds.lb</span><span class="s2">, </span><span class="s1">bounds.ub</span><span class="s2">, </span><span class="s1">len(bounds.lb))</span>

    <span class="s5"># Initiate SHGO class</span>
    <span class="s5"># use in context manager to make sure that any parallelization</span>
    <span class="s5"># resources are freed.</span>
    <span class="s2">with </span><span class="s1">SHGO(func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=args</span><span class="s2">, </span><span class="s1">constraints=constraints</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">,</span>
               <span class="s1">iters=iters</span><span class="s2">, </span><span class="s1">callback=callback</span><span class="s2">,</span>
               <span class="s1">minimizer_kwargs=minimizer_kwargs</span><span class="s2">,</span>
               <span class="s1">options=options</span><span class="s2">, </span><span class="s1">sampling_method=sampling_method</span><span class="s2">,</span>
               <span class="s1">workers=workers) </span><span class="s2">as </span><span class="s1">shc:</span>
        <span class="s5"># Run the algorithm, process results and test success</span>
        <span class="s1">shc.iterate_all()</span>

    <span class="s2">if not </span><span class="s1">shc.break_routine:</span>
        <span class="s2">if </span><span class="s1">shc.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">&quot;Successfully completed construction of complex.&quot;</span><span class="s1">)</span>

    <span class="s5"># Test post iterations success</span>
    <span class="s2">if </span><span class="s1">len(shc.LMC.xl_maps) == </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s5"># If sampling failed to find pool, return lowest sampled point</span>
        <span class="s5"># with a warning</span>
        <span class="s1">shc.find_lowest_vertex()</span>
        <span class="s1">shc.break_routine = </span><span class="s2">True</span>
        <span class="s1">shc.fail_routine(mes=</span><span class="s3">&quot;Failed to find a feasible minimizer point. &quot;</span>
                             <span class="s3">&quot;Lowest sampling point = {}&quot;</span><span class="s1">.format(shc.f_lowest))</span>
        <span class="s1">shc.res.fun = shc.f_lowest</span>
        <span class="s1">shc.res.x = shc.x_lowest</span>
        <span class="s1">shc.res.nfev = shc.fn</span>
        <span class="s1">shc.res.tnev = shc.n_sampled</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s5"># Test that the optimal solutions do not violate any constraints</span>
        <span class="s2">pass  </span><span class="s5"># TODO</span>

    <span class="s5"># Confirm the routine ran successfully</span>
    <span class="s2">if not </span><span class="s1">shc.break_routine:</span>
        <span class="s1">shc.res.message = </span><span class="s3">'Optimization terminated successfully.'</span>
        <span class="s1">shc.res.success = </span><span class="s2">True</span>

    <span class="s5"># Return the final results</span>
    <span class="s2">return </span><span class="s1">shc.res</span>


<span class="s2">class </span><span class="s1">SHGO:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">constraints=</span><span class="s2">None, </span><span class="s1">n=</span><span class="s2">None,</span>
                 <span class="s1">iters=</span><span class="s2">None, </span><span class="s1">callback=</span><span class="s2">None, </span><span class="s1">minimizer_kwargs=</span><span class="s2">None,</span>
                 <span class="s1">options=</span><span class="s2">None, </span><span class="s1">sampling_method=</span><span class="s3">'simplicial'</span><span class="s2">, </span><span class="s1">workers=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s2">from </span><span class="s1">scipy.stats </span><span class="s2">import </span><span class="s1">qmc</span>
        <span class="s5"># Input checks</span>
        <span class="s1">methods = [</span><span class="s3">'halton'</span><span class="s2">, </span><span class="s3">'sobol'</span><span class="s2">, </span><span class="s3">'simplicial'</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">isinstance(sampling_method</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">and </span><span class="s1">sampling_method </span><span class="s2">not in </span><span class="s1">methods:</span>
            <span class="s2">raise </span><span class="s1">ValueError((</span><span class="s3">&quot;Unknown sampling_method specified.&quot;</span>
                              <span class="s3">&quot; Valid methods: {}&quot;</span><span class="s1">).format(</span><span class="s3">', '</span><span class="s1">.join(methods)))</span>

        <span class="s5"># Split obj func if given with Jac</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">((minimizer_kwargs[</span><span class="s3">'jac'</span><span class="s1">] </span><span class="s2">is True</span><span class="s1">) </span><span class="s2">and</span>
                    <span class="s1">(</span><span class="s2">not </span><span class="s1">callable(minimizer_kwargs[</span><span class="s3">'jac'</span><span class="s1">]))):</span>
                <span class="s1">self.func = MemoizeJac(func)</span>
                <span class="s1">jac = self.func.derivative</span>
                <span class="s1">minimizer_kwargs[</span><span class="s3">'jac'</span><span class="s1">] = jac</span>
                <span class="s1">func = self.func  </span><span class="s5"># .fun</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self.func = func  </span><span class="s5"># Normal definition of objective function</span>
        <span class="s2">except </span><span class="s1">(TypeError</span><span class="s2">, </span><span class="s1">KeyError):</span>
            <span class="s1">self.func = func  </span><span class="s5"># Normal definition of objective function</span>

        <span class="s5"># Initiate class</span>
        <span class="s1">self.func = _FunctionWrapper(func</span><span class="s2">, </span><span class="s1">args)</span>
        <span class="s1">self.bounds = bounds</span>
        <span class="s1">self.args = args</span>
        <span class="s1">self.callback = callback</span>

        <span class="s5"># Bounds</span>
        <span class="s1">abound = np.array(bounds</span><span class="s2">, </span><span class="s1">float)</span>
        <span class="s1">self.dim = np.shape(abound)[</span><span class="s4">0</span><span class="s1">]  </span><span class="s5"># Dimensionality of problem</span>

        <span class="s5"># Set none finite values to large floats</span>
        <span class="s1">infind = ~np.isfinite(abound)</span>
        <span class="s1">abound[infind[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">] = -</span><span class="s4">1e50</span>
        <span class="s1">abound[infind[:</span><span class="s2">, </span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s4">1</span><span class="s1">] = </span><span class="s4">1e50</span>

        <span class="s5"># Check if bounds are correctly specified</span>
        <span class="s1">bnderr = abound[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">] &gt; abound[:</span><span class="s2">, </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">bnderr.any():</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Error: lb &gt; ub in bounds {}.'</span>
                             <span class="s1">.format(</span><span class="s3">', '</span><span class="s1">.join(str(b) </span><span class="s2">for </span><span class="s1">b </span><span class="s2">in </span><span class="s1">bnderr)))</span>

        <span class="s1">self.bounds = abound</span>

        <span class="s5"># Constraints</span>
        <span class="s5"># Process constraint dict sequence:</span>
        <span class="s1">self.constraints = constraints</span>
        <span class="s2">if </span><span class="s1">constraints </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.min_cons = constraints</span>
            <span class="s1">self.g_cons = []</span>
            <span class="s1">self.g_args = []</span>

            <span class="s5"># shgo internals deals with old-style constraints</span>
            <span class="s5"># self.constraints is used to create Complex, so need</span>
            <span class="s5"># to be stored internally in old-style.</span>
            <span class="s5"># `minimize` takes care of normalising these constraints</span>
            <span class="s5"># for slsqp/cobyla/trust-constr.</span>
            <span class="s1">self.constraints = standardize_constraints(</span>
                <span class="s1">constraints</span><span class="s2">,</span>
                <span class="s1">np.empty(self.dim</span><span class="s2">, </span><span class="s1">float)</span><span class="s2">,</span>
                <span class="s3">'old'</span>
            <span class="s1">)</span>
            <span class="s2">for </span><span class="s1">cons </span><span class="s2">in </span><span class="s1">self.constraints:</span>
                <span class="s2">if </span><span class="s1">cons[</span><span class="s3">'type'</span><span class="s1">] </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'ineq'</span><span class="s1">):</span>
                    <span class="s1">self.g_cons.append(cons[</span><span class="s3">'fun'</span><span class="s1">])</span>
                    <span class="s2">try</span><span class="s1">:</span>
                        <span class="s1">self.g_args.append(cons[</span><span class="s3">'args'</span><span class="s1">])</span>
                    <span class="s2">except </span><span class="s1">KeyError:</span>
                        <span class="s1">self.g_args.append(())</span>
            <span class="s1">self.g_cons = tuple(self.g_cons)</span>
            <span class="s1">self.g_args = tuple(self.g_args)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.g_cons = </span><span class="s2">None</span>
            <span class="s1">self.g_args = </span><span class="s2">None</span>

        <span class="s5"># Define local minimization keyword arguments</span>
        <span class="s5"># Start with defaults</span>
        <span class="s1">self.minimizer_kwargs = {</span><span class="s3">'method'</span><span class="s1">: </span><span class="s3">'SLSQP'</span><span class="s2">,</span>
                                 <span class="s3">'bounds'</span><span class="s1">: self.bounds</span><span class="s2">,</span>
                                 <span class="s3">'options'</span><span class="s1">: {}</span><span class="s2">,</span>
                                 <span class="s3">'callback'</span><span class="s1">: self.callback</span>
                                 <span class="s1">}</span>
        <span class="s2">if </span><span class="s1">minimizer_kwargs </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s5"># Overwrite with supplied values</span>
            <span class="s1">self.minimizer_kwargs.update(minimizer_kwargs)</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.minimizer_kwargs[</span><span class="s3">'options'</span><span class="s1">] = {</span><span class="s3">'ftol'</span><span class="s1">: </span><span class="s4">1e-12</span><span class="s1">}</span>

        <span class="s2">if </span><span class="s1">(</span>
            <span class="s1">self.minimizer_kwargs[</span><span class="s3">'method'</span><span class="s1">].lower() </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'slsqp'</span><span class="s2">, </span><span class="s3">'cobyla'</span><span class="s2">, </span><span class="s3">'trust-constr'</span><span class="s1">) </span><span class="s2">and</span>
            <span class="s1">(</span>
                <span class="s1">minimizer_kwargs </span><span class="s2">is not None and</span>
                <span class="s3">'constraints' </span><span class="s2">not in </span><span class="s1">minimizer_kwargs </span><span class="s2">and</span>
                <span class="s1">constraints </span><span class="s2">is not None</span>
            <span class="s1">) </span><span class="s2">or</span>
            <span class="s1">(self.g_cons </span><span class="s2">is not None</span><span class="s1">)</span>
        <span class="s1">):</span>
            <span class="s1">self.minimizer_kwargs[</span><span class="s3">'constraints'</span><span class="s1">] = self.min_cons</span>

        <span class="s5"># Process options dict</span>
        <span class="s2">if </span><span class="s1">options </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.init_options(options)</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s5"># Default settings:</span>
            <span class="s1">self.f_min_true = </span><span class="s2">None</span>
            <span class="s1">self.minimize_every_iter = </span><span class="s2">True</span>

            <span class="s5"># Algorithm limits</span>
            <span class="s1">self.maxiter = </span><span class="s2">None</span>
            <span class="s1">self.maxfev = </span><span class="s2">None</span>
            <span class="s1">self.maxev = </span><span class="s2">None</span>
            <span class="s1">self.maxtime = </span><span class="s2">None</span>
            <span class="s1">self.f_min_true = </span><span class="s2">None</span>
            <span class="s1">self.minhgrd = </span><span class="s2">None</span>

            <span class="s5"># Objective function knowledge</span>
            <span class="s1">self.symmetry = </span><span class="s2">None</span>

            <span class="s5"># Algorithm functionality</span>
            <span class="s1">self.infty_cons_sampl = </span><span class="s2">True</span>
            <span class="s1">self.local_iter = </span><span class="s2">False</span>

            <span class="s5"># Feedback</span>
            <span class="s1">self.disp = </span><span class="s2">False</span>

        <span class="s5"># Remove unknown arguments in self.minimizer_kwargs</span>
        <span class="s5"># Start with arguments all the solvers have in common</span>
        <span class="s1">self.min_solver_args = [</span><span class="s3">'fun'</span><span class="s2">, </span><span class="s3">'x0'</span><span class="s2">, </span><span class="s3">'args'</span><span class="s2">,</span>
                                <span class="s3">'callback'</span><span class="s2">, </span><span class="s3">'options'</span><span class="s2">, </span><span class="s3">'method'</span><span class="s1">]</span>
        <span class="s5"># then add the ones unique to specific solvers</span>
        <span class="s1">solver_args = {</span>
            <span class="s3">'_custom'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s2">, </span><span class="s3">'bounds'</span><span class="s2">, </span><span class="s3">'constraints'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'nelder-mead'</span><span class="s1">: []</span><span class="s2">,</span>
            <span class="s3">'powell'</span><span class="s1">: []</span><span class="s2">,</span>
            <span class="s3">'cg'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'bfgs'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'newton-cg'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'l-bfgs-b'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'bounds'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'tnc'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'bounds'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'cobyla'</span><span class="s1">: [</span><span class="s3">'constraints'</span><span class="s2">, </span><span class="s3">'catol'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'slsqp'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'bounds'</span><span class="s2">, </span><span class="s3">'constraints'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'dogleg'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'trust-ncg'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'trust-krylov'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'trust-exact'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s3">'trust-constr'</span><span class="s1">: [</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s2">, </span><span class="s3">'constraints'</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">}</span>
        <span class="s1">method = self.minimizer_kwargs[</span><span class="s3">'method'</span><span class="s1">]</span>
        <span class="s1">self.min_solver_args += solver_args[method.lower()]</span>

        <span class="s5"># Only retain the known arguments</span>
        <span class="s2">def </span><span class="s1">_restrict_to_keys(dictionary</span><span class="s2">, </span><span class="s1">goodkeys):</span>
            <span class="s0">&quot;&quot;&quot;Remove keys from dictionary if not in goodkeys - inplace&quot;&quot;&quot;</span>
            <span class="s1">existingkeys = set(dictionary)</span>
            <span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">existingkeys - set(goodkeys):</span>
                <span class="s1">dictionary.pop(key</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s1">_restrict_to_keys(self.minimizer_kwargs</span><span class="s2">, </span><span class="s1">self.min_solver_args)</span>
        <span class="s1">_restrict_to_keys(self.minimizer_kwargs[</span><span class="s3">'options'</span><span class="s1">]</span><span class="s2">,</span>
                          <span class="s1">self.min_solver_args + [</span><span class="s3">'ftol'</span><span class="s1">])</span>

        <span class="s5"># Algorithm controls</span>
        <span class="s5"># Global controls</span>
        <span class="s1">self.stop_global = </span><span class="s2">False  </span><span class="s5"># Used in the stopping_criteria method</span>
        <span class="s1">self.break_routine = </span><span class="s2">False  </span><span class="s5"># Break the algorithm globally</span>
        <span class="s1">self.iters = iters  </span><span class="s5"># Iterations to be ran</span>
        <span class="s1">self.iters_done = </span><span class="s4">0  </span><span class="s5"># Iterations completed</span>
        <span class="s1">self.n = n  </span><span class="s5"># Sampling points per iteration</span>
        <span class="s1">self.nc = </span><span class="s4">0  </span><span class="s5"># n  # Sampling points to sample in current iteration</span>
        <span class="s1">self.n_prc = </span><span class="s4">0  </span><span class="s5"># Processed points (used to track Delaunay iters)</span>
        <span class="s1">self.n_sampled = </span><span class="s4">0  </span><span class="s5"># To track no. of sampling points already generated</span>
        <span class="s1">self.fn = </span><span class="s4">0  </span><span class="s5"># Number of feasible sampling points evaluations performed</span>
        <span class="s1">self.hgr = </span><span class="s4">0  </span><span class="s5"># Homology group rank</span>
        <span class="s5"># Initially attempt to build the triangulation incrementally:</span>
        <span class="s1">self.qhull_incremental = </span><span class="s2">True</span>

        <span class="s5"># Default settings if no sampling criteria.</span>
        <span class="s2">if </span><span class="s1">(self.n </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(self.iters </span><span class="s2">is None</span><span class="s1">) \</span>
                <span class="s2">and </span><span class="s1">(sampling_method == </span><span class="s3">'simplicial'</span><span class="s1">):</span>
            <span class="s1">self.n = </span><span class="s4">2 </span><span class="s1">** self.dim + </span><span class="s4">1</span>
            <span class="s1">self.nc = </span><span class="s4">0  </span><span class="s5"># self.n</span>
        <span class="s2">if </span><span class="s1">self.iters </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.iters = </span><span class="s4">1</span>
        <span class="s2">if </span><span class="s1">(self.n </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and not </span><span class="s1">(sampling_method == </span><span class="s3">'simplicial'</span><span class="s1">):</span>
            <span class="s1">self.n = self.n = </span><span class="s4">100</span>
            <span class="s1">self.nc = </span><span class="s4">0  </span><span class="s5"># self.n</span>
        <span class="s2">if </span><span class="s1">(self.n == </span><span class="s4">100</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(sampling_method == </span><span class="s3">'simplicial'</span><span class="s1">):</span>
            <span class="s1">self.n = </span><span class="s4">2 </span><span class="s1">** self.dim + </span><span class="s4">1</span>

        <span class="s2">if not </span><span class="s1">((self.maxiter </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(self.maxfev </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(</span>
                <span class="s1">self.maxev </span><span class="s2">is None</span><span class="s1">)</span>
                <span class="s2">and </span><span class="s1">(self.minhgrd </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(self.f_min_true </span><span class="s2">is None</span><span class="s1">)):</span>
            <span class="s1">self.iters = </span><span class="s2">None</span>

        <span class="s5"># Set complex construction mode based on a provided stopping criteria:</span>
        <span class="s5"># Initialise sampling Complex and function cache</span>
        <span class="s5"># Note that sfield_args=() since args are already wrapped in self.func</span>
        <span class="s5"># using the_FunctionWrapper class.</span>
        <span class="s1">self.HC = Complex(dim=self.dim</span><span class="s2">, </span><span class="s1">domain=self.bounds</span><span class="s2">,</span>
                          <span class="s1">sfield=self.func</span><span class="s2">, </span><span class="s1">sfield_args=()</span><span class="s2">,</span>
                          <span class="s1">symmetry=self.symmetry</span><span class="s2">,</span>
                          <span class="s1">constraints=self.constraints</span><span class="s2">,</span>
                          <span class="s1">workers=workers)</span>

        <span class="s5"># Choose complex constructor</span>
        <span class="s2">if </span><span class="s1">sampling_method == </span><span class="s3">'simplicial'</span><span class="s1">:</span>
            <span class="s1">self.iterate_complex = self.iterate_hypercube</span>
            <span class="s1">self.sampling_method = sampling_method</span>

        <span class="s2">elif </span><span class="s1">sampling_method </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'halton'</span><span class="s2">, </span><span class="s3">'sobol'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">\</span>
                <span class="s2">not </span><span class="s1">isinstance(sampling_method</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">self.iterate_complex = self.iterate_delaunay</span>
            <span class="s5"># Sampling method used</span>
            <span class="s2">if </span><span class="s1">sampling_method </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'halton'</span><span class="s2">, </span><span class="s3">'sobol'</span><span class="s1">]:</span>
                <span class="s2">if </span><span class="s1">sampling_method == </span><span class="s3">'sobol'</span><span class="s1">:</span>
                    <span class="s1">self.n = int(</span><span class="s4">2 </span><span class="s1">** np.ceil(np.log2(self.n)))</span>
                    <span class="s5"># self.n #TODO: Should always be self.n, this is</span>
                    <span class="s5"># unacceptable for shgo, check that nfev behaves as</span>
                    <span class="s5"># expected.</span>
                    <span class="s1">self.nc = </span><span class="s4">0</span>
                    <span class="s1">self.sampling_method = </span><span class="s3">'sobol'</span>
                    <span class="s1">self.qmc_engine = qmc.Sobol(d=self.dim</span><span class="s2">, </span><span class="s1">scramble=</span><span class="s2">False,</span>
                                                <span class="s1">seed=</span><span class="s4">0</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">self.sampling_method = </span><span class="s3">'halton'</span>
                    <span class="s1">self.qmc_engine = qmc.Halton(d=self.dim</span><span class="s2">, </span><span class="s1">scramble=</span><span class="s2">True,</span>
                                                 <span class="s1">seed=</span><span class="s4">0</span><span class="s1">)</span>

                <span class="s2">def </span><span class="s1">sampling_method(n</span><span class="s2">, </span><span class="s1">d):</span>
                    <span class="s2">return </span><span class="s1">self.qmc_engine.random(n)</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s5"># A user defined sampling method:</span>
                <span class="s1">self.sampling_method = </span><span class="s3">'custom'</span>

            <span class="s1">self.sampling = self.sampling_custom</span>
            <span class="s1">self.sampling_function = sampling_method  </span><span class="s5"># F(n, d)</span>

        <span class="s5"># Local controls</span>
        <span class="s1">self.stop_l_iter = </span><span class="s2">False  </span><span class="s5"># Local minimisation iterations</span>
        <span class="s1">self.stop_complex_iter = </span><span class="s2">False  </span><span class="s5"># Sampling iterations</span>

        <span class="s5"># Initiate storage objects used in algorithm classes</span>
        <span class="s1">self.minimizer_pool = []</span>

        <span class="s5"># Cache of local minimizers mapped</span>
        <span class="s1">self.LMC = LMapCache()</span>

        <span class="s5"># Initialize return object</span>
        <span class="s1">self.res = OptimizeResult()  </span><span class="s5"># scipy.optimize.OptimizeResult object</span>
        <span class="s1">self.res.nfev = </span><span class="s4">0  </span><span class="s5"># Includes each sampling point as func evaluation</span>
        <span class="s1">self.res.nlfev = </span><span class="s4">0  </span><span class="s5"># Local function evals for all minimisers</span>
        <span class="s1">self.res.nljev = </span><span class="s4">0  </span><span class="s5"># Local Jacobian evals for all minimisers</span>
        <span class="s1">self.res.nlhev = </span><span class="s4">0  </span><span class="s5"># Local Hessian evals for all minimisers</span>

    <span class="s5"># Initiation aids</span>
    <span class="s2">def </span><span class="s1">init_options(self</span><span class="s2">, </span><span class="s1">options):</span>
        <span class="s0">&quot;&quot;&quot; 
        Initiates the options. 
 
        Can also be useful to change parameters after class initiation. 
 
        Parameters 
        ---------- 
        options : dict 
 
        Returns 
        ------- 
        None 
 
        &quot;&quot;&quot;</span>
        <span class="s5"># Update 'options' dict passed to optimize.minimize</span>
        <span class="s5"># Do this first so we don't mutate `options` below.</span>
        <span class="s1">self.minimizer_kwargs[</span><span class="s3">'options'</span><span class="s1">].update(options)</span>

        <span class="s5"># Ensure that 'jac', 'hess', and 'hessp' are passed directly to</span>
        <span class="s5"># `minimize` as keywords, not as part of its 'options' dictionary.</span>
        <span class="s2">for </span><span class="s1">opt </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'jac'</span><span class="s2">, </span><span class="s3">'hess'</span><span class="s2">, </span><span class="s3">'hessp'</span><span class="s1">]:</span>
            <span class="s2">if </span><span class="s1">opt </span><span class="s2">in </span><span class="s1">self.minimizer_kwargs[</span><span class="s3">'options'</span><span class="s1">]:</span>
                <span class="s1">self.minimizer_kwargs[opt] = (</span>
                    <span class="s1">self.minimizer_kwargs[</span><span class="s3">'options'</span><span class="s1">].pop(opt))</span>

        <span class="s5"># Default settings:</span>
        <span class="s1">self.minimize_every_iter = options.get(</span><span class="s3">'minimize_every_iter'</span><span class="s2">, True</span><span class="s1">)</span>

        <span class="s5"># Algorithm limits</span>
        <span class="s5"># Maximum number of iterations to perform.</span>
        <span class="s1">self.maxiter = options.get(</span><span class="s3">'maxiter'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s5"># Maximum number of function evaluations in the feasible domain</span>
        <span class="s1">self.maxfev = options.get(</span><span class="s3">'maxfev'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s5"># Maximum number of sampling evaluations (includes searching in</span>
        <span class="s5"># infeasible points</span>
        <span class="s1">self.maxev = options.get(</span><span class="s3">'maxev'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s5"># Maximum processing runtime allowed</span>
        <span class="s1">self.init = time.time()</span>
        <span class="s1">self.maxtime = options.get(</span><span class="s3">'maxtime'</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s3">'f_min' </span><span class="s2">in </span><span class="s1">options:</span>
            <span class="s5"># Specify the minimum objective function value, if it is known.</span>
            <span class="s1">self.f_min_true = options[</span><span class="s3">'f_min'</span><span class="s1">]</span>
            <span class="s1">self.f_tol = options.get(</span><span class="s3">'f_tol'</span><span class="s2">, </span><span class="s4">1e-4</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.f_min_true = </span><span class="s2">None</span>

        <span class="s1">self.minhgrd = options.get(</span><span class="s3">'minhgrd'</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s5"># Objective function knowledge</span>
        <span class="s1">self.symmetry = options.get(</span><span class="s3">'symmetry'</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.symmetry:</span>
            <span class="s1">self.symmetry = [</span><span class="s4">0</span><span class="s2">, </span><span class="s1">]*len(self.bounds)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.symmetry = </span><span class="s2">None</span>
        <span class="s5"># Algorithm functionality</span>
        <span class="s5"># Only evaluate a few of the best candiates</span>
        <span class="s1">self.local_iter = options.get(</span><span class="s3">'local_iter'</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s1">self.infty_cons_sampl = options.get(</span><span class="s3">'infty_constraints'</span><span class="s2">, True</span><span class="s1">)</span>

        <span class="s5"># Feedback</span>
        <span class="s1">self.disp = options.get(</span><span class="s3">'disp'</span><span class="s2">, False</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__enter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__exit__(self</span><span class="s2">, </span><span class="s1">*args):</span>
        <span class="s2">return </span><span class="s1">self.HC.V._mapwrapper.__exit__(*args)</span>

    <span class="s5"># Iteration properties</span>
    <span class="s5"># Main construction loop:</span>
    <span class="s2">def </span><span class="s1">iterate_all(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct for `iters` iterations. 
 
        If uniform sampling is used, every iteration adds 'n' sampling points. 
 
        Iterations if a stopping criteria (e.g., sampling points or 
        processing time) has been met. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Splitting first generation'</span><span class="s1">)</span>

        <span class="s2">while not </span><span class="s1">self.stop_global:</span>
            <span class="s2">if </span><span class="s1">self.break_routine:</span>
                <span class="s2">break</span>
            <span class="s5"># Iterate complex, process minimisers</span>
            <span class="s1">self.iterate()</span>
            <span class="s1">self.stopping_criteria()</span>

        <span class="s5"># Build minimiser pool</span>
        <span class="s5"># Final iteration only needed if pools weren't minimised every</span>
        <span class="s5"># iteration</span>
        <span class="s2">if not </span><span class="s1">self.minimize_every_iter:</span>
            <span class="s2">if not </span><span class="s1">self.break_routine:</span>
                <span class="s1">self.find_minima()</span>

        <span class="s1">self.res.nit = self.iters_done  </span><span class="s5"># + 1</span>
        <span class="s1">self.fn = self.HC.V.nfev</span>

    <span class="s2">def </span><span class="s1">find_minima(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct the minimizer pool, map the minimizers to local minima 
        and sort the results into a global return object. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Searching for minimizer pool...'</span><span class="s1">)</span>

        <span class="s1">self.minimizers()</span>

        <span class="s2">if </span><span class="s1">len(self.X_min) != </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s5"># Minimize the pool of minimizers with local minimization methods</span>
            <span class="s5"># Note that if Options['local_iter'] is an `int` instead of default</span>
            <span class="s5"># value False then only that number of candidates will be minimized</span>
            <span class="s1">self.minimise_pool(self.local_iter)</span>
            <span class="s5"># Sort results and build the global return object</span>
            <span class="s1">self.sort_result()</span>

            <span class="s5"># Lowest values used to report in case of failures</span>
            <span class="s1">self.f_lowest = self.res.fun</span>
            <span class="s1">self.x_lowest = self.res.x</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.find_lowest_vertex()</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f&quot;Minimiser pool = SHGO.X_min = </span><span class="s2">{</span><span class="s1">self.X_min</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">find_lowest_vertex(self):</span>
        <span class="s5"># Find the lowest objective function value on one of</span>
        <span class="s5"># the vertices of the simplicial complex</span>
        <span class="s1">self.f_lowest = np.inf</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.HC.V.cache:</span>
            <span class="s2">if </span><span class="s1">self.HC.V[x].f &lt; self.f_lowest:</span>
                <span class="s2">if </span><span class="s1">self.disp:</span>
                    <span class="s1">logging.info(</span><span class="s3">f'self.HC.V[x].f = </span><span class="s2">{</span><span class="s1">self.HC.V[x].f</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
                <span class="s1">self.f_lowest = self.HC.V[x].f</span>
                <span class="s1">self.x_lowest = self.HC.V[x].x_a</span>
        <span class="s2">for </span><span class="s1">lmc </span><span class="s2">in </span><span class="s1">self.LMC.cache:</span>
            <span class="s2">if </span><span class="s1">self.LMC[lmc].f_min &lt; self.f_lowest:</span>
                <span class="s1">self.f_lowest = self.LMC[lmc].f_min</span>
                <span class="s1">self.x_lowest = self.LMC[lmc].x_l</span>

        <span class="s2">if </span><span class="s1">self.f_lowest == np.inf:  </span><span class="s5"># no feasible point</span>
            <span class="s1">self.f_lowest = </span><span class="s2">None</span>
            <span class="s1">self.x_lowest = </span><span class="s2">None</span>

    <span class="s5"># Stopping criteria functions:</span>
    <span class="s2">def </span><span class="s1">finite_iterations(self):</span>
        <span class="s1">mi = min(x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">[self.iters</span><span class="s2">, </span><span class="s1">self.maxiter] </span><span class="s2">if </span><span class="s1">x </span><span class="s2">is not None</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Iterations done = </span><span class="s2">{</span><span class="s1">self.iters_done</span><span class="s2">} </span><span class="s3">/ </span><span class="s2">{</span><span class="s1">mi</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.iters </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.iters_done &gt;= (self.iters):</span>
                <span class="s1">self.stop_global = </span><span class="s2">True</span>

        <span class="s2">if </span><span class="s1">self.maxiter </span><span class="s2">is not None</span><span class="s1">:  </span><span class="s5"># Stop for infeasible sampling</span>
            <span class="s2">if </span><span class="s1">self.iters_done &gt;= (self.maxiter):</span>
                <span class="s1">self.stop_global = </span><span class="s2">True</span>
        <span class="s2">return </span><span class="s1">self.stop_global</span>

    <span class="s2">def </span><span class="s1">finite_fev(self):</span>
        <span class="s5"># Finite function evals in the feasible domain</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Function evaluations done = </span><span class="s2">{</span><span class="s1">self.fn</span><span class="s2">} </span><span class="s3">/ </span><span class="s2">{</span><span class="s1">self.maxfev</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.fn &gt;= self.maxfev:</span>
            <span class="s1">self.stop_global = </span><span class="s2">True</span>
        <span class="s2">return </span><span class="s1">self.stop_global</span>

    <span class="s2">def </span><span class="s1">finite_ev(self):</span>
        <span class="s5"># Finite evaluations including infeasible sampling points</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Sampling evaluations done = </span><span class="s2">{</span><span class="s1">self.n_sampled</span><span class="s2">} </span><span class="s3">'</span>
                         <span class="s3">f'/ </span><span class="s2">{</span><span class="s1">self.maxev</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.n_sampled &gt;= self.maxev:</span>
            <span class="s1">self.stop_global = </span><span class="s2">True</span>

    <span class="s2">def </span><span class="s1">finite_time(self):</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Time elapsed = </span><span class="s2">{</span><span class="s1">time.time() - self.init</span><span class="s2">} </span><span class="s3">'</span>
                         <span class="s3">f'/ </span><span class="s2">{</span><span class="s1">self.maxtime</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">(time.time() - self.init) &gt;= self.maxtime:</span>
            <span class="s1">self.stop_global = </span><span class="s2">True</span>

    <span class="s2">def </span><span class="s1">finite_precision(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Stop the algorithm if the final function value is known 
 
        Specify in options (with ``self.f_min_true = options['f_min']``) 
        and the tolerance with ``f_tol = options['f_tol']`` 
        &quot;&quot;&quot;</span>
        <span class="s5"># If no minimizer has been found use the lowest sampling value</span>
        <span class="s1">self.find_lowest_vertex()</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Lowest function evaluation = </span><span class="s2">{</span><span class="s1">self.f_lowest</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
            <span class="s1">logging.info(</span><span class="s3">f'Specified minimum = </span><span class="s2">{</span><span class="s1">self.f_min_true</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s5"># If no feasible point was return from test</span>
        <span class="s2">if </span><span class="s1">self.f_lowest </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.stop_global</span>

        <span class="s5"># Function to stop algorithm at specified percentage error:</span>
        <span class="s2">if </span><span class="s1">self.f_min_true == </span><span class="s4">0.0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.f_lowest &lt;= self.f_tol:</span>
                <span class="s1">self.stop_global = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">pe = (self.f_lowest - self.f_min_true) / abs(self.f_min_true)</span>
            <span class="s2">if </span><span class="s1">self.f_lowest &lt;= self.f_min_true:</span>
                <span class="s1">self.stop_global = </span><span class="s2">True</span>
                <span class="s5"># 2if (pe - self.f_tol) &lt;= abs(1.0 / abs(self.f_min_true)):</span>
                <span class="s2">if </span><span class="s1">abs(pe) &gt;= </span><span class="s4">2 </span><span class="s1">* self.f_tol:</span>
                    <span class="s1">warnings.warn(</span><span class="s3">&quot;A much lower value than expected f* =&quot; </span><span class="s1">+</span>
                                  <span class="s3">f&quot; </span><span class="s2">{</span><span class="s1">self.f_min_true</span><span class="s2">} </span><span class="s3">than&quot; </span><span class="s1">+</span>
                                  <span class="s3">&quot; the was found f_lowest =&quot; </span><span class="s1">+</span>
                                  <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">self.f_lowest</span><span class="s2">} </span><span class="s3">&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">pe &lt;= self.f_tol:</span>
                <span class="s1">self.stop_global = </span><span class="s2">True</span>

        <span class="s2">return </span><span class="s1">self.stop_global</span>

    <span class="s2">def </span><span class="s1">finite_homology_growth(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Stop the algorithm if homology group rank did not grow in iteration. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.LMC.size == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">return  </span><span class="s5"># pass on no reason to stop yet.</span>
        <span class="s1">self.hgrd = self.LMC.size - self.hgr</span>

        <span class="s1">self.hgr = self.LMC.size</span>
        <span class="s2">if </span><span class="s1">self.hgrd &lt;= self.minhgrd:</span>
            <span class="s1">self.stop_global = </span><span class="s2">True</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Current homology growth = </span><span class="s2">{</span><span class="s1">self.hgrd</span><span class="s2">} </span><span class="s3">'</span>
                         <span class="s3">f' (minimum growth = </span><span class="s2">{</span><span class="s1">self.minhgrd</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self.stop_global</span>

    <span class="s2">def </span><span class="s1">stopping_criteria(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Various stopping criteria ran every iteration 
 
        Returns 
        ------- 
        stop : bool 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.maxiter </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_iterations()</span>
        <span class="s2">if </span><span class="s1">self.iters </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_iterations()</span>
        <span class="s2">if </span><span class="s1">self.maxfev </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_fev()</span>
        <span class="s2">if </span><span class="s1">self.maxev </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_ev()</span>
        <span class="s2">if </span><span class="s1">self.maxtime </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_time()</span>
        <span class="s2">if </span><span class="s1">self.f_min_true </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_precision()</span>
        <span class="s2">if </span><span class="s1">self.minhgrd </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.finite_homology_growth()</span>
        <span class="s2">return </span><span class="s1">self.stop_global</span>

    <span class="s2">def </span><span class="s1">iterate(self):</span>
        <span class="s1">self.iterate_complex()</span>

        <span class="s5"># Build minimizer pool</span>
        <span class="s2">if </span><span class="s1">self.minimize_every_iter:</span>
            <span class="s2">if not </span><span class="s1">self.break_routine:</span>
                <span class="s1">self.find_minima()  </span><span class="s5"># Process minimizer pool</span>

        <span class="s5"># Algorithm updates</span>
        <span class="s1">self.iters_done += </span><span class="s4">1</span>

    <span class="s2">def </span><span class="s1">iterate_hypercube(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Iterate a subdivision of the complex 
 
        Note: called with ``self.iterate_complex()`` after class initiation 
        &quot;&quot;&quot;</span>
        <span class="s5"># Iterate the complex</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Constructing and refining simplicial complex graph '</span>
                         <span class="s3">'structure'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.n </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.HC.refine_all()</span>
            <span class="s1">self.n_sampled = self.HC.V.size()  </span><span class="s5"># nevs counted</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.HC.refine(self.n)</span>
            <span class="s1">self.n_sampled += self.n</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Triangulation completed, evaluating all contraints '</span>
                         <span class="s3">'and objective function values.'</span><span class="s1">)</span>

        <span class="s5"># Readd minimisers to complex</span>
        <span class="s2">if </span><span class="s1">len(self.LMC.xl_maps) &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">xl </span><span class="s2">in </span><span class="s1">self.LMC.cache:</span>
                <span class="s1">v = self.HC.V[xl]</span>
                <span class="s1">v_near = v.star()</span>
                <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">v.nn:</span>
                    <span class="s1">v_near = v_near.union(v.nn)</span>
                <span class="s5"># Reconnect vertices to complex</span>
                <span class="s5"># if self.HC.connect_vertex_non_symm(tuple(self.LMC[xl].x_l),</span>
                <span class="s5">#                                   near=v_near):</span>
                <span class="s5">#    continue</span>
                <span class="s5"># else:</span>
                    <span class="s5"># If failure to find in v_near, then search all vertices</span>
                    <span class="s5"># (very expensive operation:</span>
                <span class="s5">#    self.HC.connect_vertex_non_symm(tuple(self.LMC[xl].x_l)</span>
                <span class="s5">#                                    )</span>

        <span class="s5"># Evaluate all constraints and functions</span>
        <span class="s1">self.HC.V.process_pools()</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Evaluations completed.'</span><span class="s1">)</span>

        <span class="s5"># feasible sampling points counted by the triangulation.py routines</span>
        <span class="s1">self.fn = self.HC.V.nfev</span>
        <span class="s2">return</span>

    <span class="s2">def </span><span class="s1">iterate_delaunay(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Build a complex of Delaunay triangulated points 
 
        Note: called with ``self.iterate_complex()`` after class initiation 
        &quot;&quot;&quot;</span>
        <span class="s1">self.nc += self.n</span>
        <span class="s1">self.sampled_surface(infty_cons_sampl=self.infty_cons_sampl)</span>

        <span class="s5"># Add sampled points to a triangulation, construct self.Tri</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'self.n = </span><span class="s2">{</span><span class="s1">self.n</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
            <span class="s1">logging.info(</span><span class="s3">f'self.nc = </span><span class="s2">{</span><span class="s1">self.nc</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
            <span class="s1">logging.info(</span><span class="s3">'Constructing and refining simplicial complex graph '</span>
                         <span class="s3">'structure from sampling points.'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self.dim &lt; </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s1">self.Ind_sorted = np.argsort(self.C</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">self.Ind_sorted = self.Ind_sorted.flatten()</span>
            <span class="s1">tris = []</span>
            <span class="s2">for </span><span class="s1">ind</span><span class="s2">, </span><span class="s1">ind_s </span><span class="s2">in </span><span class="s1">enumerate(self.Ind_sorted):</span>
                <span class="s2">if </span><span class="s1">ind &gt; </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">tris.append(self.Ind_sorted[ind - </span><span class="s4">1</span><span class="s1">:ind + </span><span class="s4">1</span><span class="s1">])</span>

            <span class="s1">tris = np.array(tris)</span>
            <span class="s5"># Store 1D triangulation:</span>
            <span class="s1">self.Tri = namedtuple(</span><span class="s3">'Tri'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">'points'</span><span class="s2">, </span><span class="s3">'simplices'</span><span class="s1">])(self.C</span><span class="s2">, </span><span class="s1">tris)</span>
            <span class="s1">self.points = {}</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self.C.shape[</span><span class="s4">0</span><span class="s1">] &gt; self.dim + </span><span class="s4">1</span><span class="s1">:  </span><span class="s5"># Ensure a simplex can be built</span>
                <span class="s1">self.delaunay_triangulation(n_prc=self.n_prc)</span>
            <span class="s1">self.n_prc = self.C.shape[</span><span class="s4">0</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Triangulation completed, evaluating all '</span>
                         <span class="s3">'constraints and objective function values.'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'Tri'</span><span class="s1">):</span>
            <span class="s1">self.HC.vf_to_vv(self.Tri.points</span><span class="s2">, </span><span class="s1">self.Tri.simplices)</span>

        <span class="s5"># Process all pools</span>
        <span class="s5"># Evaluate all constraints and functions</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Triangulation completed, evaluating all contraints '</span>
                         <span class="s3">'and objective function values.'</span><span class="s1">)</span>

        <span class="s5"># Evaluate all constraints and functions</span>
        <span class="s1">self.HC.V.process_pools()</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Evaluations completed.'</span><span class="s1">)</span>

        <span class="s5"># feasible sampling points counted by the triangulation.py routines</span>
        <span class="s1">self.fn = self.HC.V.nfev</span>
        <span class="s1">self.n_sampled = self.nc  </span><span class="s5"># nevs counted in triangulation</span>
        <span class="s2">return</span>

    <span class="s5"># Hypercube minimizers</span>
    <span class="s2">def </span><span class="s1">minimizers(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the indexes of all minimizers 
        &quot;&quot;&quot;</span>
        <span class="s1">self.minimizer_pool = []</span>
        <span class="s5"># Note: Can implement parallelization here</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">self.HC.V.cache:</span>
            <span class="s1">in_LMC = </span><span class="s2">False</span>
            <span class="s2">if </span><span class="s1">len(self.LMC.xl_maps) &gt; </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">for </span><span class="s1">xlmi </span><span class="s2">in </span><span class="s1">self.LMC.xl_maps:</span>
                    <span class="s2">if </span><span class="s1">np.all(np.array(x) == np.array(xlmi)):</span>
                        <span class="s1">in_LMC = </span><span class="s2">True</span>
            <span class="s2">if </span><span class="s1">in_LMC:</span>
                <span class="s2">continue</span>

            <span class="s2">if </span><span class="s1">self.HC.V[x].minimiser():</span>
                <span class="s2">if </span><span class="s1">self.disp:</span>
                    <span class="s1">logging.info(</span><span class="s3">'=' </span><span class="s1">* </span><span class="s4">60</span><span class="s1">)</span>
                    <span class="s1">logging.info(</span><span class="s3">f'v.x = </span><span class="s2">{</span><span class="s1">self.HC.V[x].x_a</span><span class="s2">} </span><span class="s3">is minimizer'</span><span class="s1">)</span>
                    <span class="s1">logging.info(</span><span class="s3">f'v.f = </span><span class="s2">{</span><span class="s1">self.HC.V[x].f</span><span class="s2">} </span><span class="s3">is minimizer'</span><span class="s1">)</span>
                    <span class="s1">logging.info(</span><span class="s3">'=' </span><span class="s1">* </span><span class="s4">30</span><span class="s1">)</span>

                <span class="s2">if </span><span class="s1">self.HC.V[x] </span><span class="s2">not in </span><span class="s1">self.minimizer_pool:</span>
                    <span class="s1">self.minimizer_pool.append(self.HC.V[x])</span>

                <span class="s2">if </span><span class="s1">self.disp:</span>
                    <span class="s1">logging.info(</span><span class="s3">'Neighbors:'</span><span class="s1">)</span>
                    <span class="s1">logging.info(</span><span class="s3">'=' </span><span class="s1">* </span><span class="s4">30</span><span class="s1">)</span>
                    <span class="s2">for </span><span class="s1">vn </span><span class="s2">in </span><span class="s1">self.HC.V[x].nn:</span>
                        <span class="s1">logging.info(</span><span class="s3">f'x = </span><span class="s2">{</span><span class="s1">vn.x</span><span class="s2">} </span><span class="s3">|| f = </span><span class="s2">{</span><span class="s1">vn.f</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

                    <span class="s1">logging.info(</span><span class="s3">'=' </span><span class="s1">* </span><span class="s4">60</span><span class="s1">)</span>
        <span class="s1">self.minimizer_pool_F = []</span>
        <span class="s1">self.X_min = []</span>
        <span class="s5"># normalized tuple in the Vertex cache</span>
        <span class="s1">self.X_min_cache = {}  </span><span class="s5"># Cache used in hypercube sampling</span>

        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.minimizer_pool:</span>
            <span class="s1">self.X_min.append(v.x_a)</span>
            <span class="s1">self.minimizer_pool_F.append(v.f)</span>
            <span class="s1">self.X_min_cache[tuple(v.x_a)] = v.x</span>

        <span class="s1">self.minimizer_pool_F = np.array(self.minimizer_pool_F)</span>
        <span class="s1">self.X_min = np.array(self.X_min)</span>

        <span class="s5"># TODO: Only do this if global mode</span>
        <span class="s1">self.sort_min_pool()</span>

        <span class="s2">return </span><span class="s1">self.X_min</span>

    <span class="s5"># Local minimisation</span>
    <span class="s5"># Minimiser pool processing</span>
    <span class="s2">def </span><span class="s1">minimise_pool(self</span><span class="s2">, </span><span class="s1">force_iter=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        This processing method can optionally minimise only the best candidate 
        solutions in the minimiser pool 
 
        Parameters 
        ---------- 
        force_iter : int 
                     Number of starting minimizers to process (can be sepcified 
                     globally or locally) 
 
        &quot;&quot;&quot;</span>
        <span class="s5"># Find first local minimum</span>
        <span class="s5"># NOTE: Since we always minimize this value regardless it is a waste to</span>
        <span class="s5"># build the topograph first before minimizing</span>
        <span class="s1">lres_f_min = self.minimize(self.X_min[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ind=self.minimizer_pool[</span><span class="s4">0</span><span class="s1">])</span>

        <span class="s5"># Trim minimized point from current minimizer set</span>
        <span class="s1">self.trim_min_pool(</span><span class="s4">0</span><span class="s1">)</span>

        <span class="s2">while not </span><span class="s1">self.stop_l_iter:</span>
            <span class="s5"># Global stopping criteria:</span>
            <span class="s1">self.stopping_criteria()</span>

            <span class="s5"># Note first iteration is outside loop:</span>
            <span class="s2">if </span><span class="s1">force_iter:</span>
                <span class="s1">force_iter -= </span><span class="s4">1</span>
                <span class="s2">if </span><span class="s1">force_iter == </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">self.stop_l_iter = </span><span class="s2">True</span>
                    <span class="s2">break</span>

            <span class="s2">if </span><span class="s1">np.shape(self.X_min)[</span><span class="s4">0</span><span class="s1">] == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">self.stop_l_iter = </span><span class="s2">True</span>
                <span class="s2">break</span>

            <span class="s5"># Construct topograph from current minimizer set</span>
            <span class="s5"># (NOTE: This is a very small topograph using only the minizer pool</span>
            <span class="s5">#        , it might be worth using some graph theory tools instead.</span>
            <span class="s1">self.g_topograph(lres_f_min.x</span><span class="s2">, </span><span class="s1">self.X_min)</span>

            <span class="s5"># Find local minimum at the miniser with the greatest Euclidean</span>
            <span class="s5"># distance from the current solution</span>
            <span class="s1">ind_xmin_l = self.Z[:</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">lres_f_min = self.minimize(self.Ss[-</span><span class="s4">1</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">self.minimizer_pool[-</span><span class="s4">1</span><span class="s1">])</span>

            <span class="s5"># Trim minimised point from current minimizer set</span>
            <span class="s1">self.trim_min_pool(ind_xmin_l)</span>

        <span class="s5"># Reset controls</span>
        <span class="s1">self.stop_l_iter = </span><span class="s2">False</span>
        <span class="s2">return</span>

    <span class="s2">def </span><span class="s1">sort_min_pool(self):</span>
        <span class="s5"># Sort to find minimum func value in min_pool</span>
        <span class="s1">self.ind_f_min = np.argsort(self.minimizer_pool_F)</span>
        <span class="s1">self.minimizer_pool = np.array(self.minimizer_pool)[self.ind_f_min]</span>
        <span class="s1">self.minimizer_pool_F = np.array(self.minimizer_pool_F)[</span>
            <span class="s1">self.ind_f_min]</span>
        <span class="s2">return</span>

    <span class="s2">def </span><span class="s1">trim_min_pool(self</span><span class="s2">, </span><span class="s1">trim_ind):</span>
        <span class="s1">self.X_min = np.delete(self.X_min</span><span class="s2">, </span><span class="s1">trim_ind</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">self.minimizer_pool_F = np.delete(self.minimizer_pool_F</span><span class="s2">, </span><span class="s1">trim_ind)</span>
        <span class="s1">self.minimizer_pool = np.delete(self.minimizer_pool</span><span class="s2">, </span><span class="s1">trim_ind)</span>
        <span class="s2">return</span>

    <span class="s2">def </span><span class="s1">g_topograph(self</span><span class="s2">, </span><span class="s1">x_min</span><span class="s2">, </span><span class="s1">X_min):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the topographical vector stemming from the specified value 
        ``x_min`` for the current feasible set ``X_min`` with True boolean 
        values indicating positive entries and False values indicating 
        negative entries. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">x_min = np.array([x_min])</span>
        <span class="s1">self.Y = spatial.distance.cdist(x_min</span><span class="s2">, </span><span class="s1">X_min</span><span class="s2">, </span><span class="s3">'euclidean'</span><span class="s1">)</span>
        <span class="s5"># Find sorted indexes of spatial distances:</span>
        <span class="s1">self.Z = np.argsort(self.Y</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s4">1</span><span class="s1">)</span>

        <span class="s1">self.Ss = X_min[self.Z][</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">self.minimizer_pool = self.minimizer_pool[self.Z]</span>
        <span class="s1">self.minimizer_pool = self.minimizer_pool[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">self.Ss</span>

    <span class="s5"># Local bound functions</span>
    <span class="s2">def </span><span class="s1">construct_lcb_simplicial(self</span><span class="s2">, </span><span class="s1">v_min):</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct locally (approximately) convex bounds 
 
        Parameters 
        ---------- 
        v_min : Vertex object 
                The minimizer vertex 
 
        Returns 
        ------- 
        cbounds : list of lists 
            List of size dimension with length-2 list of bounds for each 
            dimension. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">cbounds = [[x_b_i[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x_b_i[</span><span class="s4">1</span><span class="s1">]] </span><span class="s2">for </span><span class="s1">x_b_i </span><span class="s2">in </span><span class="s1">self.bounds]</span>
        <span class="s5"># Loop over all bounds</span>
        <span class="s2">for </span><span class="s1">vn </span><span class="s2">in </span><span class="s1">v_min.nn:</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">x_i </span><span class="s2">in </span><span class="s1">enumerate(vn.x_a):</span>
                <span class="s5"># Lower bound</span>
                <span class="s2">if </span><span class="s1">(x_i &lt; v_min.x_a[i]) </span><span class="s2">and </span><span class="s1">(x_i &gt; cbounds[i][</span><span class="s4">0</span><span class="s1">]):</span>
                    <span class="s1">cbounds[i][</span><span class="s4">0</span><span class="s1">] = x_i</span>

                <span class="s5"># Upper bound</span>
                <span class="s2">if </span><span class="s1">(x_i &gt; v_min.x_a[i]) </span><span class="s2">and </span><span class="s1">(x_i &lt; cbounds[i][</span><span class="s4">1</span><span class="s1">]):</span>
                    <span class="s1">cbounds[i][</span><span class="s4">1</span><span class="s1">] = x_i</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'cbounds found for v_min.x_a = </span><span class="s2">{</span><span class="s1">v_min.x_a</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
            <span class="s1">logging.info(</span><span class="s3">f'cbounds = </span><span class="s2">{</span><span class="s1">cbounds</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">cbounds</span>

    <span class="s2">def </span><span class="s1">construct_lcb_delaunay(self</span><span class="s2">, </span><span class="s1">v_min</span><span class="s2">, </span><span class="s1">ind=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct locally (approximately) convex bounds 
 
        Parameters 
        ---------- 
        v_min : Vertex object 
                The minimizer vertex 
 
        Returns 
        ------- 
        cbounds : list of lists 
            List of size dimension with length-2 list of bounds for each 
            dimension. 
        &quot;&quot;&quot;</span>
        <span class="s1">cbounds = [[x_b_i[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x_b_i[</span><span class="s4">1</span><span class="s1">]] </span><span class="s2">for </span><span class="s1">x_b_i </span><span class="s2">in </span><span class="s1">self.bounds]</span>

        <span class="s2">return </span><span class="s1">cbounds</span>

    <span class="s5"># Minimize a starting point locally</span>
    <span class="s2">def </span><span class="s1">minimize(self</span><span class="s2">, </span><span class="s1">x_min</span><span class="s2">, </span><span class="s1">ind=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        This function is used to calculate the local minima using the specified 
        sampling point as a starting value. 
 
        Parameters 
        ---------- 
        x_min : vector of floats 
            Current starting point to minimize. 
 
        Returns 
        ------- 
        lres : OptimizeResult 
            The local optimization result represented as a `OptimizeResult` 
            object. 
        &quot;&quot;&quot;</span>
        <span class="s5"># Use minima maps if vertex was already run</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Vertex minimiser maps = </span><span class="s2">{</span><span class="s1">self.LMC.v_maps</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self.LMC[x_min].lres </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">logging.info(</span><span class="s3">f'Found self.LMC[x_min].lres = '</span>
                         <span class="s3">f'</span><span class="s2">{</span><span class="s1">self.LMC[x_min].lres</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self.LMC[x_min].lres</span>

        <span class="s2">if </span><span class="s1">self.callback </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">logging.info(</span><span class="s3">'Callback for '</span>
                  <span class="s3">'minimizer starting at {}:'</span><span class="s1">.format(x_min))</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Starting '</span>
                  <span class="s3">'minimization at {}...'</span><span class="s1">.format(x_min))</span>

        <span class="s2">if </span><span class="s1">self.sampling_method == </span><span class="s3">'simplicial'</span><span class="s1">:</span>
            <span class="s1">x_min_t = tuple(x_min)</span>
            <span class="s5"># Find the normalized tuple in the Vertex cache:</span>
            <span class="s1">x_min_t_norm = self.X_min_cache[tuple(x_min_t)]</span>
            <span class="s1">x_min_t_norm = tuple(x_min_t_norm)</span>
            <span class="s1">g_bounds = self.construct_lcb_simplicial(self.HC.V[x_min_t_norm])</span>
            <span class="s2">if </span><span class="s3">'bounds' </span><span class="s2">in </span><span class="s1">self.min_solver_args:</span>
                <span class="s1">self.minimizer_kwargs[</span><span class="s3">'bounds'</span><span class="s1">] = g_bounds</span>
                <span class="s1">logging.info(self.minimizer_kwargs[</span><span class="s3">'bounds'</span><span class="s1">])</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">g_bounds = self.construct_lcb_delaunay(x_min</span><span class="s2">, </span><span class="s1">ind=ind)</span>
            <span class="s2">if </span><span class="s3">'bounds' </span><span class="s2">in </span><span class="s1">self.min_solver_args:</span>
                <span class="s1">self.minimizer_kwargs[</span><span class="s3">'bounds'</span><span class="s1">] = g_bounds</span>
                <span class="s1">logging.info(self.minimizer_kwargs[</span><span class="s3">'bounds'</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">self.disp </span><span class="s2">and </span><span class="s3">'bounds' </span><span class="s2">in </span><span class="s1">self.minimizer_kwargs:</span>
            <span class="s1">logging.info(</span><span class="s3">'bounds in kwarg:'</span><span class="s1">)</span>
            <span class="s1">logging.info(self.minimizer_kwargs[</span><span class="s3">'bounds'</span><span class="s1">])</span>

        <span class="s5"># Local minimization using scipy.optimize.minimize:</span>
        <span class="s1">lres = minimize(self.func</span><span class="s2">, </span><span class="s1">x_min</span><span class="s2">, </span><span class="s1">**self.minimizer_kwargs)</span>

        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">f'lres = </span><span class="s2">{</span><span class="s1">lres</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

        <span class="s5"># Local function evals for all minimizers</span>
        <span class="s1">self.res.nlfev += lres.nfev</span>
        <span class="s2">if </span><span class="s3">'njev' </span><span class="s2">in </span><span class="s1">lres:</span>
            <span class="s1">self.res.nljev += lres.njev</span>
        <span class="s2">if </span><span class="s3">'nhev' </span><span class="s2">in </span><span class="s1">lres:</span>
            <span class="s1">self.res.nlhev += lres.nhev</span>

        <span class="s2">try</span><span class="s1">:  </span><span class="s5"># Needed because of the brain dead 1x1 NumPy arrays</span>
            <span class="s1">lres.fun = lres.fun[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">except </span><span class="s1">(IndexError</span><span class="s2">, </span><span class="s1">TypeError):</span>
            <span class="s1">lres.fun</span>

        <span class="s5"># Append minima maps</span>
        <span class="s1">self.LMC[x_min]</span>
        <span class="s1">self.LMC.add_res(x_min</span><span class="s2">, </span><span class="s1">lres</span><span class="s2">, </span><span class="s1">bounds=g_bounds)</span>

        <span class="s2">return </span><span class="s1">lres</span>

    <span class="s5"># Post local minimization processing</span>
    <span class="s2">def </span><span class="s1">sort_result(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Sort results and build the global return object 
        &quot;&quot;&quot;</span>
        <span class="s5"># Sort results in local minima cache</span>
        <span class="s1">results = self.LMC.sort_cache_result()</span>
        <span class="s1">self.res.xl = results[</span><span class="s3">'xl'</span><span class="s1">]</span>
        <span class="s1">self.res.funl = results[</span><span class="s3">'funl'</span><span class="s1">]</span>
        <span class="s1">self.res.x = results[</span><span class="s3">'x'</span><span class="s1">]</span>
        <span class="s1">self.res.fun = results[</span><span class="s3">'fun'</span><span class="s1">]</span>

        <span class="s5"># Add local func evals to sampling func evals</span>
        <span class="s5"># Count the number of feasible vertices and add to local func evals:</span>
        <span class="s1">self.res.nfev = self.fn + self.res.nlfev</span>
        <span class="s2">return </span><span class="s1">self.res</span>

    <span class="s5"># Algorithm controls</span>
    <span class="s2">def </span><span class="s1">fail_routine(self</span><span class="s2">, </span><span class="s1">mes=(</span><span class="s3">&quot;Failed to converge&quot;</span><span class="s1">)):</span>
        <span class="s1">self.break_routine = </span><span class="s2">True</span>
        <span class="s1">self.res.success = </span><span class="s2">False</span>
        <span class="s1">self.X_min = [</span><span class="s2">None</span><span class="s1">]</span>
        <span class="s1">self.res.message = mes</span>

    <span class="s2">def </span><span class="s1">sampled_surface(self</span><span class="s2">, </span><span class="s1">infty_cons_sampl=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Sample the function surface. 
 
        There are 2 modes, if ``infty_cons_sampl`` is True then the sampled 
        points that are generated outside the feasible domain will be 
        assigned an ``inf`` value in accordance with SHGO rules. 
        This guarantees convergence and usually requires less objective 
        function evaluations at the computational costs of more Delaunay 
        triangulation points. 
 
        If ``infty_cons_sampl`` is False, then the infeasible points are 
        discarded and only a subspace of the sampled points are used. This 
        comes at the cost of the loss of guaranteed convergence and usually 
        requires more objective function evaluations. 
        &quot;&quot;&quot;</span>
        <span class="s5"># Generate sampling points</span>
        <span class="s2">if </span><span class="s1">self.disp:</span>
            <span class="s1">logging.info(</span><span class="s3">'Generating sampling points'</span><span class="s1">)</span>
        <span class="s1">self.sampling(self.nc</span><span class="s2">, </span><span class="s1">self.dim)</span>
        <span class="s2">if </span><span class="s1">len(self.LMC.xl_maps) &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">self.C = np.vstack((self.C</span><span class="s2">, </span><span class="s1">np.array(self.LMC.xl_maps)))</span>
        <span class="s2">if not </span><span class="s1">infty_cons_sampl:</span>
            <span class="s5"># Find subspace of feasible points</span>
            <span class="s2">if </span><span class="s1">self.g_cons </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">self.sampling_subspace()</span>

        <span class="s5"># Sort remaining samples</span>
        <span class="s1">self.sorted_samples()</span>

        <span class="s5"># Find objective function references</span>
        <span class="s1">self.n_sampled = self.nc</span>

    <span class="s2">def </span><span class="s1">sampling_custom(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">dim):</span>
        <span class="s0">&quot;&quot;&quot; 
        Generates uniform sampling points in a hypercube and scales the points 
        to the bound limits. 
        &quot;&quot;&quot;</span>
        <span class="s5"># Generate sampling points.</span>
        <span class="s5"># Generate uniform sample points in [0, 1]^m \subset R^m</span>
        <span class="s2">if </span><span class="s1">self.n_sampled == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">self.C = self.sampling_function(n</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.C = self.sampling_function(n</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s5"># Distribute over bounds</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(self.bounds)):</span>
            <span class="s1">self.C[:</span><span class="s2">, </span><span class="s1">i] = (self.C[:</span><span class="s2">, </span><span class="s1">i] *</span>
                            <span class="s1">(self.bounds[i][</span><span class="s4">1</span><span class="s1">] - self.bounds[i][</span><span class="s4">0</span><span class="s1">])</span>
                            <span class="s1">+ self.bounds[i][</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s2">return </span><span class="s1">self.C</span>

    <span class="s2">def </span><span class="s1">sampling_subspace(self):</span>
        <span class="s0">&quot;&quot;&quot;Find subspace of feasible points from g_func definition&quot;&quot;&quot;</span>
        <span class="s5"># Subspace of feasible points.</span>
        <span class="s2">for </span><span class="s1">ind</span><span class="s2">, </span><span class="s1">g </span><span class="s2">in </span><span class="s1">enumerate(self.g_cons):</span>
            <span class="s5"># C.shape = (Z, dim) where Z is the number of sampling points to</span>
            <span class="s5"># evaluate and dim is the dimensionality of the problem.</span>
            <span class="s5"># the constraint function may not be vectorised so have to step</span>
            <span class="s5"># through each sampling point sequentially.</span>
            <span class="s1">feasible = np.array(</span>
                <span class="s1">[np.all(g(x_C</span><span class="s2">, </span><span class="s1">*self.g_args[ind]) &gt;= </span><span class="s4">0.0</span><span class="s1">) </span><span class="s2">for </span><span class="s1">x_C </span><span class="s2">in </span><span class="s1">self.C]</span><span class="s2">,</span>
                <span class="s1">dtype=bool</span>
            <span class="s1">)</span>
            <span class="s1">self.C = self.C[feasible]</span>

            <span class="s2">if </span><span class="s1">self.C.size == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">self.res.message = (</span><span class="s3">'No sampling point found within the '</span>
                                    <span class="s1">+ </span><span class="s3">'feasible set. Increasing sampling '</span>
                                    <span class="s1">+ </span><span class="s3">'size.'</span><span class="s1">)</span>
                <span class="s5"># sampling correctly for both 1-D and &gt;1-D cases</span>
                <span class="s2">if </span><span class="s1">self.disp:</span>
                    <span class="s1">logging.info(self.res.message)</span>

    <span class="s2">def </span><span class="s1">sorted_samples(self):  </span><span class="s5"># Validated</span>
        <span class="s0">&quot;&quot;&quot;Find indexes of the sorted sampling points&quot;&quot;&quot;</span>
        <span class="s1">self.Ind_sorted = np.argsort(self.C</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">self.Xs = self.C[self.Ind_sorted]</span>
        <span class="s2">return </span><span class="s1">self.Ind_sorted</span><span class="s2">, </span><span class="s1">self.Xs</span>

    <span class="s2">def </span><span class="s1">delaunay_triangulation(self</span><span class="s2">, </span><span class="s1">n_prc=</span><span class="s4">0</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'Tri'</span><span class="s1">) </span><span class="s2">and </span><span class="s1">self.qhull_incremental:</span>
            <span class="s5"># TODO: Uncertain if n_prc needs to add len(self.LMC.xl_maps)</span>
            <span class="s5"># in self.sampled_surface</span>
            <span class="s1">self.Tri.add_points(self.C[n_prc:</span><span class="s2">, </span><span class="s1">:])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">self.Tri = spatial.Delaunay(self.C</span><span class="s2">,</span>
                                            <span class="s1">incremental=self.qhull_incremental</span><span class="s2">,</span>
                                            <span class="s1">)</span>
            <span class="s2">except </span><span class="s1">spatial.QhullError:</span>
                <span class="s2">if </span><span class="s1">str(sys.exc_info()[</span><span class="s4">1</span><span class="s1">])[:</span><span class="s4">6</span><span class="s1">] == </span><span class="s3">'QH6239'</span><span class="s1">:</span>
                    <span class="s1">logging.warning(</span><span class="s3">'QH6239 Qhull precision error detected, '</span>
                                    <span class="s3">'this usually occurs when no bounds are '</span>
                                    <span class="s3">'specified, Qhull can only run with '</span>
                                    <span class="s3">'handling cocircular/cospherical points'</span>
                                    <span class="s3">' and in this case incremental mode is '</span>
                                    <span class="s3">'switched off. The performance of shgo '</span>
                                    <span class="s3">'will be reduced in this mode.'</span><span class="s1">)</span>
                    <span class="s1">self.qhull_incremental = </span><span class="s2">False</span>
                    <span class="s1">self.Tri = spatial.Delaunay(self.C</span><span class="s2">,</span>
                                                <span class="s1">incremental=</span>
                                                <span class="s1">self.qhull_incremental)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">raise</span>

        <span class="s2">return </span><span class="s1">self.Tri</span>


<span class="s2">class </span><span class="s1">LMap:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">v):</span>
        <span class="s1">self.v = v</span>
        <span class="s1">self.x_l = </span><span class="s2">None</span>
        <span class="s1">self.lres = </span><span class="s2">None</span>
        <span class="s1">self.f_min = </span><span class="s2">None</span>
        <span class="s1">self.lbounds = []</span>


<span class="s2">class </span><span class="s1">LMapCache:</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self.cache = {}</span>

        <span class="s5"># Lists for search queries</span>
        <span class="s1">self.v_maps = []</span>
        <span class="s1">self.xl_maps = []</span>
        <span class="s1">self.xl_maps_set = set()</span>
        <span class="s1">self.f_maps = []</span>
        <span class="s1">self.lbound_maps = []</span>
        <span class="s1">self.size = </span><span class="s4">0</span>

    <span class="s2">def </span><span class="s1">__getitem__(self</span><span class="s2">, </span><span class="s1">v):</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">v = np.ndarray.tolist(v)</span>
        <span class="s2">except </span><span class="s1">TypeError:</span>
            <span class="s2">pass</span>
        <span class="s1">v = tuple(v)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.cache[v]</span>
        <span class="s2">except </span><span class="s1">KeyError:</span>
            <span class="s1">xval = LMap(v)</span>
            <span class="s1">self.cache[v] = xval</span>

            <span class="s2">return </span><span class="s1">self.cache[v]</span>

    <span class="s2">def </span><span class="s1">add_res(self</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">lres</span><span class="s2">, </span><span class="s1">bounds=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">v = np.ndarray.tolist(v)</span>
        <span class="s1">v = tuple(v)</span>
        <span class="s1">self.cache[v].x_l = lres.x</span>
        <span class="s1">self.cache[v].lres = lres</span>
        <span class="s1">self.cache[v].f_min = lres.fun</span>
        <span class="s1">self.cache[v].lbounds = bounds</span>

        <span class="s5"># Update cache size</span>
        <span class="s1">self.size += </span><span class="s4">1</span>

        <span class="s5"># Cache lists for search queries</span>
        <span class="s1">self.v_maps.append(v)</span>
        <span class="s1">self.xl_maps.append(lres.x)</span>
        <span class="s1">self.xl_maps_set.add(tuple(lres.x))</span>
        <span class="s1">self.f_maps.append(lres.fun)</span>
        <span class="s1">self.lbound_maps.append(bounds)</span>

    <span class="s2">def </span><span class="s1">sort_cache_result(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Sort results and build the global return object 
        &quot;&quot;&quot;</span>
        <span class="s1">results = {}</span>
        <span class="s5"># Sort results and save</span>
        <span class="s1">self.xl_maps = np.array(self.xl_maps)</span>
        <span class="s1">self.f_maps = np.array(self.f_maps)</span>

        <span class="s5"># Sorted indexes in Func_min</span>
        <span class="s1">ind_sorted = np.argsort(self.f_maps)</span>

        <span class="s5"># Save ordered list of minima</span>
        <span class="s1">results[</span><span class="s3">'xl'</span><span class="s1">] = self.xl_maps[ind_sorted]  </span><span class="s5"># Ordered x vals</span>
        <span class="s1">self.f_maps = np.array(self.f_maps)</span>
        <span class="s1">results[</span><span class="s3">'funl'</span><span class="s1">] = self.f_maps[ind_sorted]</span>
        <span class="s1">results[</span><span class="s3">'funl'</span><span class="s1">] = results[</span><span class="s3">'funl'</span><span class="s1">].T</span>

        <span class="s5"># Find global of all minimizers</span>
        <span class="s1">results[</span><span class="s3">'x'</span><span class="s1">] = self.xl_maps[ind_sorted[</span><span class="s4">0</span><span class="s1">]]  </span><span class="s5"># Save global minima</span>
        <span class="s1">results[</span><span class="s3">'fun'</span><span class="s1">] = self.f_maps[ind_sorted[</span><span class="s4">0</span><span class="s1">]]  </span><span class="s5"># Save global fun value</span>

        <span class="s1">self.xl_maps = np.ndarray.tolist(self.xl_maps)</span>
        <span class="s1">self.f_maps = np.ndarray.tolist(self.f_maps)</span>
        <span class="s2">return </span><span class="s1">results</span>
</pre>
</body>
</html>
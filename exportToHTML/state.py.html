<html>
<head>
<title>state.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
state.py</font>
</center></td></tr></table>
<pre><span class="s0"># This file is part of Patsy</span>
<span class="s0"># Copyright (C) 2011 Nathaniel Smith &lt;njs@pobox.com&gt;</span>
<span class="s0"># See file LICENSE.txt for license information.</span>

<span class="s0"># Stateful transform protocol:</span>
<span class="s0">#   def __init__(self):</span>
<span class="s0">#       pass</span>
<span class="s0">#   def memorize_chunk(self, input_data):</span>
<span class="s0">#       return None</span>
<span class="s0">#   def memorize_finish(self):</span>
<span class="s0">#       return None</span>
<span class="s0">#   def transform(self, input_data):</span>
<span class="s0">#       return output_data</span>

<span class="s0"># BETTER WAY: always run the first row of data through the builder alone, and</span>
<span class="s0"># check that it gives the same output row as when running the whole block of</span>
<span class="s0"># data through at once. This gives us the same information, but it's robust</span>
<span class="s0"># against people writing their own centering functions.</span>

<span class="s0"># QUESTION: right now we refuse to even fit a model that contains a</span>
<span class="s0"># my_transform(x)-style function. Maybe we should allow it to be fit (with a</span>
<span class="s0"># warning), and only disallow making predictions with it? Need to revisit this</span>
<span class="s0"># question once it's clearer what exactly our public API will look like,</span>
<span class="s0"># because right now I'm not sure how to tell whether we are being called for</span>
<span class="s0"># fitting versus being called for prediction.</span>

<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">wraps</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">patsy.util </span><span class="s2">import </span><span class="s1">(atleast_2d_column_default</span><span class="s2">,</span>
                        <span class="s1">asarray_or_pandas</span><span class="s2">, </span><span class="s1">pandas_friendly_reshape</span><span class="s2">,</span>
                        <span class="s1">wide_dtype_for</span><span class="s2">, </span><span class="s1">safe_issubdtype</span><span class="s2">,</span>
                        <span class="s1">no_pickling</span><span class="s2">, </span><span class="s1">assert_no_pickling)</span>

<span class="s0"># These are made available in the patsy.* namespace</span>
<span class="s1">__all__ = [</span><span class="s3">&quot;stateful_transform&quot;</span><span class="s2">,</span>
           <span class="s3">&quot;center&quot;</span><span class="s2">, </span><span class="s3">&quot;standardize&quot;</span><span class="s2">, </span><span class="s3">&quot;scale&quot;</span><span class="s2">,</span>
           <span class="s1">]</span>

<span class="s2">def </span><span class="s1">stateful_transform(class_):</span>
    <span class="s4">&quot;&quot;&quot;Create a stateful transform callable object from a class that fulfills 
    the :ref:`stateful transform protocol &lt;stateful-transform-protocol&gt;`. 
    &quot;&quot;&quot;</span>
    <span class="s1">@wraps(class_)</span>
    <span class="s2">def </span><span class="s1">stateful_transform_wrapper(*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">transform = class_()</span>
        <span class="s1">transform.memorize_chunk(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">transform.memorize_finish()</span>
        <span class="s2">return </span><span class="s1">transform.transform(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">stateful_transform_wrapper.__patsy_stateful_transform__ = class_</span>
    <span class="s2">return </span><span class="s1">stateful_transform_wrapper</span>

<span class="s0"># class NonIncrementalStatefulTransform(object):</span>
<span class="s0">#     def __init__(self):</span>
<span class="s0">#         self._data = []</span>
<span class="s0">#</span>
<span class="s0">#     def memorize_chunk(self, input_data, *args, **kwargs):</span>
<span class="s0">#         self._data.append(input_data)</span>
<span class="s0">#         self._args = _args</span>
<span class="s0">#         self._kwargs = kwargs</span>
<span class="s0">#</span>
<span class="s0">#     def memorize_finish(self):</span>
<span class="s0">#         all_data = np.row_stack(self._data)</span>
<span class="s0">#         args = self._args</span>
<span class="s0">#         kwargs = self._kwargs</span>
<span class="s0">#         del self._data</span>
<span class="s0">#         del self._args</span>
<span class="s0">#         del self._kwargs</span>
<span class="s0">#         self.memorize_all(all_data, *args, **kwargs)</span>
<span class="s0">#</span>
<span class="s0">#     def memorize_all(self, input_data, *args, **kwargs):</span>
<span class="s0">#         raise NotImplementedError</span>
<span class="s0">#</span>
<span class="s0">#     def transform(self, input_data, *args, **kwargs):</span>
<span class="s0">#         raise NotImplementedError</span>
<span class="s0">#</span>
<span class="s0"># class QuantileEstimatingTransform(NonIncrementalStatefulTransform):</span>
<span class="s0">#     def memorize_all(self, input_data, *args, **kwargs):</span>

<span class="s2">class </span><span class="s1">Center(object):</span>
    <span class="s4">&quot;&quot;&quot;center(x) 
 
    A stateful transform that centers input data, i.e., subtracts the mean. 
 
    If input has multiple columns, centers each column separately. 
 
    Equivalent to ``standardize(x, rescale=False)`` 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self._sum = </span><span class="s2">None</span>
        <span class="s1">self._count = </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">memorize_chunk(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">x = atleast_2d_column_default(x)</span>
        <span class="s1">self._count += x.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">this_total = np.sum(x</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">dtype=wide_dtype_for(x))</span>
        <span class="s0"># This is to handle potentially multi-column x's:</span>
        <span class="s2">if </span><span class="s1">self._sum </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._sum = this_total</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._sum += this_total</span>

    <span class="s2">def </span><span class="s1">memorize_finish(self):</span>
        <span class="s2">pass</span>

    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">x = asarray_or_pandas(x)</span>
        <span class="s0"># This doesn't copy data unless our input is a DataFrame that has</span>
        <span class="s0"># heterogeneous types. And in that case we're going to be munging the</span>
        <span class="s0"># types anyway, so copying isn't a big deal.</span>
        <span class="s1">x_arr = np.asarray(x)</span>
        <span class="s2">if </span><span class="s1">safe_issubdtype(x_arr.dtype</span><span class="s2">, </span><span class="s1">np.integer):</span>
            <span class="s1">dt = float</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dt = x_arr.dtype</span>
        <span class="s1">mean_val = np.asarray(self._sum / self._count</span><span class="s2">, </span><span class="s1">dtype=dt)</span>
        <span class="s1">centered = atleast_2d_column_default(x</span><span class="s2">, </span><span class="s1">preserve_pandas=</span><span class="s2">True</span><span class="s1">) - mean_val</span>
        <span class="s2">return </span><span class="s1">pandas_friendly_reshape(centered</span><span class="s2">, </span><span class="s1">x.shape)</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s1">center = stateful_transform(Center)</span>

<span class="s0"># See:</span>
<span class="s0">#   http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#On-line_algorithm</span>
<span class="s0"># or page 232 of Knuth vol. 3 (3rd ed.).</span>
<span class="s2">class </span><span class="s1">Standardize(object):</span>
    <span class="s4">&quot;&quot;&quot;standardize(x, center=True, rescale=True, ddof=0) 
 
    A stateful transform that standardizes input data, i.e. it subtracts the 
    mean and divides by the sample standard deviation. 
 
    Either centering or rescaling or both can be disabled by use of keyword 
    arguments. The `ddof` argument controls the delta degrees of freedom when 
    computing the standard deviation (cf. :func:`numpy.std`). The default of 
    ``ddof=0`` produces the maximum likelihood estimate; use ``ddof=1`` if you 
    prefer the square root of the unbiased estimate of the variance. 
 
    If input has multiple columns, standardizes each column separately. 
 
    .. note:: This function computes the mean and standard deviation using a 
       memory-efficient online algorithm, making it suitable for use with 
       large incrementally processed data-sets. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self.current_n = </span><span class="s5">0</span>
        <span class="s1">self.current_mean = </span><span class="s2">None</span>
        <span class="s1">self.current_M2 = </span><span class="s2">None</span>

    <span class="s2">def </span><span class="s1">memorize_chunk(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">center=</span><span class="s2">True, </span><span class="s1">rescale=</span><span class="s2">True, </span><span class="s1">ddof=</span><span class="s5">0</span><span class="s1">):</span>
        <span class="s1">x = atleast_2d_column_default(x)</span>
        <span class="s2">if </span><span class="s1">self.current_mean </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.current_mean = np.zeros(x.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=wide_dtype_for(x))</span>
            <span class="s1">self.current_M2 = np.zeros(x.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=wide_dtype_for(x))</span>
        <span class="s0"># XX this can surely be vectorized but I am feeling lazy:</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(x.shape[</span><span class="s5">0</span><span class="s1">]):</span>
            <span class="s1">self.current_n += </span><span class="s5">1</span>
            <span class="s1">delta = x[i</span><span class="s2">, </span><span class="s1">:] - self.current_mean</span>
            <span class="s1">self.current_mean += delta / self.current_n</span>
            <span class="s1">self.current_M2 += delta * (x[i</span><span class="s2">, </span><span class="s1">:] - self.current_mean)</span>

    <span class="s2">def </span><span class="s1">memorize_finish(self):</span>
        <span class="s2">pass</span>

    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">center=</span><span class="s2">True, </span><span class="s1">rescale=</span><span class="s2">True, </span><span class="s1">ddof=</span><span class="s5">0</span><span class="s1">):</span>
        <span class="s0"># XX: this forces all inputs to double-precision real, even if the</span>
        <span class="s0"># input is single- or extended-precision or complex. But I got all</span>
        <span class="s0"># tangled up in knots trying to do that without breaking something</span>
        <span class="s0"># else (e.g. by requiring an extra copy).</span>
        <span class="s1">x = asarray_or_pandas(x</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">True, </span><span class="s1">dtype=float)</span>
        <span class="s1">x_2d = atleast_2d_column_default(x</span><span class="s2">, </span><span class="s1">preserve_pandas=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">center:</span>
            <span class="s1">x_2d -= self.current_mean</span>
        <span class="s2">if </span><span class="s1">rescale:</span>
            <span class="s1">x_2d /= np.sqrt(self.current_M2 / (self.current_n - ddof))</span>
        <span class="s2">return </span><span class="s1">pandas_friendly_reshape(x_2d</span><span class="s2">, </span><span class="s1">x.shape)</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s1">standardize = stateful_transform(Standardize)</span>
<span class="s0"># R compatibility:</span>
<span class="s1">scale = standardize</span>
</pre>
</body>
</html>
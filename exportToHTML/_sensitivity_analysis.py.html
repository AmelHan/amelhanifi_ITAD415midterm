<html>
<head>
<title>_sensitivity_analysis.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_sensitivity_analysis.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>

<span class="s0">import </span><span class="s1">inspect</span>
<span class="s0">from </span><span class="s1">dataclasses </span><span class="s0">import </span><span class="s1">dataclass</span>
<span class="s0">from </span><span class="s1">typing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">Callable</span><span class="s0">, </span><span class="s1">Literal</span><span class="s0">, </span><span class="s1">Protocol</span><span class="s0">, </span><span class="s1">TYPE_CHECKING</span>
<span class="s1">)</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">from </span><span class="s1">scipy.stats._common </span><span class="s0">import </span><span class="s1">ConfidenceInterval</span>
<span class="s0">from </span><span class="s1">scipy.stats._qmc </span><span class="s0">import </span><span class="s1">check_random_state</span>
<span class="s0">from </span><span class="s1">scipy.stats._resampling </span><span class="s0">import </span><span class="s1">BootstrapResult</span>
<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">qmc</span><span class="s0">, </span><span class="s1">bootstrap</span>


<span class="s0">if </span><span class="s1">TYPE_CHECKING:</span>
    <span class="s0">import </span><span class="s1">numpy.typing </span><span class="s0">as </span><span class="s1">npt</span>
    <span class="s0">from </span><span class="s1">scipy._lib._util </span><span class="s0">import </span><span class="s1">DecimalNumber</span><span class="s0">, </span><span class="s1">IntNumber</span><span class="s0">, </span><span class="s1">SeedType</span>


<span class="s1">__all__ = [</span>
    <span class="s2">'sobol_indices'</span>
<span class="s1">]</span>


<span class="s0">def </span><span class="s1">f_ishigami(x: npt.ArrayLike) -&gt; np.ndarray:</span>
    <span class="s3">r&quot;&quot;&quot;Ishigami function. 
 
    .. math:: 
 
        Y(\mathbf{x}) = \sin x_1 + 7 \sin^2 x_2 + 0.1 x_3^4 \sin x_1 
 
    with :math:`\mathbf{x} \in [-\pi, \pi]^3`. 
 
    Parameters 
    ---------- 
    x : array_like ([x1, x2, x3], n) 
 
    Returns 
    ------- 
    f : array_like (n,) 
        Function evaluation. 
 
    References 
    ---------- 
    .. [1] Ishigami, T. and T. Homma. &quot;An importance quantification technique 
       in uncertainty analysis for computer models.&quot; IEEE, 
       :doi:`10.1109/ISUMA.1990.151285`, 1990. 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.atleast_2d(x)</span>
    <span class="s1">f_eval = (</span>
        <span class="s1">np.sin(x[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">+ </span><span class="s4">7 </span><span class="s1">* np.sin(x[</span><span class="s4">1</span><span class="s1">])**</span><span class="s4">2</span>
        <span class="s1">+ </span><span class="s4">0.1 </span><span class="s1">* (x[</span><span class="s4">2</span><span class="s1">]**</span><span class="s4">4</span><span class="s1">) * np.sin(x[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">f_eval</span>


<span class="s0">def </span><span class="s1">sample_A_B(</span>
    <span class="s1">n: IntNumber</span><span class="s0">,</span>
    <span class="s1">dists: list[PPFDist]</span><span class="s0">,</span>
    <span class="s1">random_state: SeedType = </span><span class="s0">None</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s3">&quot;&quot;&quot;Sample two matrices A and B. 
 
    Uses a Sobol' sequence with 2`d` columns to have 2 uncorrelated matrices. 
    This is more efficient than using 2 random draw of Sobol'. 
    See sec. 5 from [1]_. 
 
    Output shape is (d, n). 
 
    References 
    ---------- 
    .. [1] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and 
       S. Tarantola. &quot;Variance based sensitivity analysis of model 
       output. Design and estimator for the total sensitivity index.&quot; 
       Computer Physics Communications, 181(2):259-270, 
       :doi:`10.1016/j.cpc.2009.09.018`, 2010. 
    &quot;&quot;&quot;</span>
    <span class="s1">d = len(dists)</span>
    <span class="s1">A_B = qmc.Sobol(d=</span><span class="s4">2</span><span class="s1">*d</span><span class="s0">, </span><span class="s1">seed=random_state</span><span class="s0">, </span><span class="s1">bits=</span><span class="s4">64</span><span class="s1">).random(n).T</span>
    <span class="s1">A_B = A_B.reshape(</span><span class="s4">2</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">for </span><span class="s1">d_</span><span class="s0">, </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">enumerate(dists):</span>
            <span class="s1">A_B[:</span><span class="s0">, </span><span class="s1">d_] = dist.ppf(A_B[:</span><span class="s0">, </span><span class="s1">d_])</span>
    <span class="s0">except </span><span class="s1">AttributeError </span><span class="s0">as </span><span class="s1">exc:</span>
        <span class="s1">message = </span><span class="s2">&quot;Each distribution in `dists` must have method `ppf`.&quot;</span>
        <span class="s0">raise </span><span class="s1">ValueError(message) </span><span class="s0">from </span><span class="s1">exc</span>
    <span class="s0">return </span><span class="s1">A_B</span>


<span class="s0">def </span><span class="s1">sample_AB(A: np.ndarray</span><span class="s0">, </span><span class="s1">B: np.ndarray) -&gt; np.ndarray:</span>
    <span class="s3">&quot;&quot;&quot;AB matrix. 
 
    AB: rows of B into A. Shape (d, d, n). 
    - Copy A into d &quot;pages&quot; 
    - In the first page, replace 1st rows of A with 1st row of B. 
    ... 
    - In the dth page, replace dth row of A with dth row of B. 
    - return the stack of pages 
    &quot;&quot;&quot;</span>
    <span class="s1">d</span><span class="s0">, </span><span class="s1">n = A.shape</span>
    <span class="s1">AB = np.tile(A</span><span class="s0">, </span><span class="s1">(d</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">i = np.arange(d)</span>
    <span class="s1">AB[i</span><span class="s0">, </span><span class="s1">i] = B[i]</span>
    <span class="s0">return </span><span class="s1">AB</span>


<span class="s0">def </span><span class="s1">saltelli_2010(</span>
    <span class="s1">f_A: np.ndarray</span><span class="s0">, </span><span class="s1">f_B: np.ndarray</span><span class="s0">, </span><span class="s1">f_AB: np.ndarray</span>
<span class="s1">) -&gt; tuple[np.ndarray</span><span class="s0">, </span><span class="s1">np.ndarray]:</span>
    <span class="s3">r&quot;&quot;&quot;Saltelli2010 formulation. 
 
    .. math:: 
 
        S_i = \frac{1}{N} \sum_{j=1}^N 
        f(\mathbf{B})_j (f(\mathbf{AB}^{(i)})_j - f(\mathbf{A})_j) 
 
    .. math:: 
 
        S_{T_i} = \frac{1}{N} \sum_{j=1}^N 
        (f(\mathbf{A})_j - f(\mathbf{AB}^{(i)})_j)^2 
 
    Parameters 
    ---------- 
    f_A, f_B : array_like (s, n) 
        Function values at A and B, respectively 
    f_AB : array_like (d, s, n) 
        Function values at each of the AB pages 
 
    Returns 
    ------- 
    s, st : array_like (s, d) 
        First order and total order Sobol' indices. 
 
    References 
    ---------- 
    .. [1] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and 
       S. Tarantola. &quot;Variance based sensitivity analysis of model 
       output. Design and estimator for the total sensitivity index.&quot; 
       Computer Physics Communications, 181(2):259-270, 
       :doi:`10.1016/j.cpc.2009.09.018`, 2010. 
    &quot;&quot;&quot;</span>
    <span class="s5"># Empirical variance calculated using output from A and B which are</span>
    <span class="s5"># independent. Output of AB is not independent and cannot be used</span>
    <span class="s1">var = np.var([f_A</span><span class="s0">, </span><span class="s1">f_B]</span><span class="s0">, </span><span class="s1">axis=(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">))</span>

    <span class="s5"># We divide by the variance to have a ratio of variance</span>
    <span class="s5"># this leads to eq. 2</span>
    <span class="s1">s = np.mean(f_B * (f_AB - f_A)</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s4">1</span><span class="s1">) / var  </span><span class="s5"># Table 2 (b)</span>
    <span class="s1">st = </span><span class="s4">0.5 </span><span class="s1">* np.mean((f_A - f_AB) ** </span><span class="s4">2</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s4">1</span><span class="s1">) / var  </span><span class="s5"># Table 2 (f)</span>

    <span class="s0">return </span><span class="s1">s.T</span><span class="s0">, </span><span class="s1">st.T</span>


<span class="s1">@dataclass</span>
<span class="s0">class </span><span class="s1">BootstrapSobolResult:</span>
    <span class="s1">first_order: BootstrapResult</span>
    <span class="s1">total_order: BootstrapResult</span>


<span class="s1">@dataclass</span>
<span class="s0">class </span><span class="s1">SobolResult:</span>
    <span class="s1">first_order: np.ndarray</span>
    <span class="s1">total_order: np.ndarray</span>
    <span class="s1">_indices_method: Callable</span>
    <span class="s1">_f_A: np.ndarray</span>
    <span class="s1">_f_B: np.ndarray</span>
    <span class="s1">_f_AB: np.ndarray</span>
    <span class="s1">_A: np.ndarray | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None</span>
    <span class="s1">_B: np.ndarray | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None</span>
    <span class="s1">_AB: np.ndarray | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None</span>
    <span class="s1">_bootstrap_result: BootstrapResult | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None</span>

    <span class="s0">def </span><span class="s1">bootstrap(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">confidence_level: DecimalNumber = </span><span class="s4">0.95</span><span class="s0">,</span>
        <span class="s1">n_resamples: IntNumber = </span><span class="s4">999</span>
    <span class="s1">) -&gt; BootstrapSobolResult:</span>
        <span class="s3">&quot;&quot;&quot;Bootstrap Sobol' indices to provide confidence intervals. 
 
        Parameters 
        ---------- 
        confidence_level : float, default: ``0.95`` 
            The confidence level of the confidence intervals. 
        n_resamples : int, default: ``999`` 
            The number of resamples performed to form the bootstrap 
            distribution of the indices. 
 
        Returns 
        ------- 
        res : BootstrapSobolResult 
            Bootstrap result containing the confidence intervals and the 
            bootstrap distribution of the indices. 
 
            An object with attributes: 
 
            first_order : BootstrapResult 
                Bootstrap result of the first order indices. 
            total_order : BootstrapResult 
                Bootstrap result of the total order indices. 
            See `BootstrapResult` for more details. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">def </span><span class="s1">statistic(idx):</span>
            <span class="s1">f_A_ = self._f_A[:</span><span class="s0">, </span><span class="s1">idx]</span>
            <span class="s1">f_B_ = self._f_B[:</span><span class="s0">, </span><span class="s1">idx]</span>
            <span class="s1">f_AB_ = self._f_AB[...</span><span class="s0">, </span><span class="s1">idx]</span>
            <span class="s0">return </span><span class="s1">self._indices_method(f_A_</span><span class="s0">, </span><span class="s1">f_B_</span><span class="s0">, </span><span class="s1">f_AB_)</span>

        <span class="s1">n = self._f_A.shape[</span><span class="s4">1</span><span class="s1">]</span>

        <span class="s1">res = bootstrap(</span>
            <span class="s1">[np.arange(n)]</span><span class="s0">, </span><span class="s1">statistic=statistic</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;BCa&quot;</span><span class="s0">,</span>
            <span class="s1">n_resamples=n_resamples</span><span class="s0">,</span>
            <span class="s1">confidence_level=confidence_level</span><span class="s0">,</span>
            <span class="s1">bootstrap_result=self._bootstrap_result</span>
        <span class="s1">)</span>
        <span class="s1">self._bootstrap_result = res</span>

        <span class="s1">first_order = BootstrapResult(</span>
            <span class="s1">confidence_interval=ConfidenceInterval(</span>
                <span class="s1">res.confidence_interval.low[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">res.confidence_interval.high[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">)</span><span class="s0">,</span>
            <span class="s1">bootstrap_distribution=res.bootstrap_distribution[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">standard_error=res.standard_error[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">total_order = BootstrapResult(</span>
            <span class="s1">confidence_interval=ConfidenceInterval(</span>
                <span class="s1">res.confidence_interval.low[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">res.confidence_interval.high[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">)</span><span class="s0">,</span>
            <span class="s1">bootstrap_distribution=res.bootstrap_distribution[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">standard_error=res.standard_error[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">)</span>

        <span class="s0">return </span><span class="s1">BootstrapSobolResult(</span>
            <span class="s1">first_order=first_order</span><span class="s0">, </span><span class="s1">total_order=total_order</span>
        <span class="s1">)</span>


<span class="s0">class </span><span class="s1">PPFDist(Protocol):</span>
    <span class="s1">@property</span>
    <span class="s0">def </span><span class="s1">ppf(self) -&gt; Callable[...</span><span class="s0">, </span><span class="s1">float]:</span>
        <span class="s1">...</span>


<span class="s0">def </span><span class="s1">sobol_indices(</span>
    <span class="s1">*</span><span class="s0">,</span>
    <span class="s1">func: Callable[[np.ndarray]</span><span class="s0">, </span><span class="s1">npt.ArrayLike] |</span>
          <span class="s1">dict[Literal[</span><span class="s2">'f_A'</span><span class="s0">, </span><span class="s2">'f_B'</span><span class="s0">, </span><span class="s2">'f_AB'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.ndarray]</span><span class="s0">,  </span><span class="s5"># noqa</span>
    <span class="s1">n: IntNumber</span><span class="s0">,</span>
    <span class="s1">dists: list[PPFDist] | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None,</span>
    <span class="s1">method: Callable | Literal[</span><span class="s2">'saltelli_2010'</span><span class="s1">] = </span><span class="s2">'saltelli_2010'</span><span class="s0">,</span>
    <span class="s1">random_state: SeedType = </span><span class="s0">None</span>
<span class="s1">) -&gt; SobolResult:</span>
    <span class="s3">r&quot;&quot;&quot;Global sensitivity indices of Sobol'. 
 
    Parameters 
    ---------- 
    func : callable or dict(str, array_like) 
        If `func` is a callable, function to compute the Sobol' indices from. 
        Its signature must be:: 
 
            func(x: ArrayLike) -&gt; ArrayLike 
 
        with ``x`` of shape ``(d, n)`` and output of shape ``(s, n)`` where: 
 
        - ``d`` is the input dimensionality of `func` 
          (number of input variables), 
        - ``s`` is the output dimensionality of `func` 
          (number of output variables), and 
        - ``n`` is the number of samples (see `n` below). 
 
        Function evaluation values must be finite. 
 
        If `func` is a dictionary, contains the function evaluations from three 
        different arrays. Keys must be: ``f_A``, ``f_B`` and ``f_AB``. 
        ``f_A`` and ``f_B`` should have a shape ``(s, n)`` and ``f_AB`` 
        should have a shape ``(d, s, n)``. 
        This is an advanced feature and misuse can lead to wrong analysis. 
    n : int 
        Number of samples used to generate the matrices ``A`` and ``B``. 
        Must be a power of 2. The total number of points at which `func` is 
        evaluated will be ``n*(d+2)``. 
    dists : list(distributions), optional 
        List of each parameter's distribution. The distribution of parameters 
        depends on the application and should be carefully chosen. 
        Parameters are assumed to be independently distributed, meaning there 
        is no constraint nor relationship between their values. 
 
        Distributions must be an instance of a class with a ``ppf`` 
        method. 
 
        Must be specified if `func` is a callable, and ignored otherwise. 
    method : Callable or str, default: 'saltelli_2010' 
        Method used to compute the first and total Sobol' indices. 
 
        If a callable, its signature must be:: 
 
            func(f_A: np.ndarray, f_B: np.ndarray, f_AB: np.ndarray) 
            -&gt; Tuple[np.ndarray, np.ndarray] 
 
        with ``f_A, f_B`` of shape ``(s, n)`` and ``f_AB`` of shape 
        ``(d, s, n)``. 
        These arrays contain the function evaluations from three different sets 
        of samples. 
        The output is a tuple of the first and total indices with 
        shape ``(s, d)``. 
        This is an advanced feature and misuse can lead to wrong analysis. 
    random_state : {None, int, `numpy.random.Generator`}, optional 
        If `random_state` is an int or None, a new `numpy.random.Generator` is 
        created using ``np.random.default_rng(random_state)``. 
        If `random_state` is already a ``Generator`` instance, then the 
        provided instance is used. 
 
    Returns 
    ------- 
    res : SobolResult 
        An object with attributes: 
 
        first_order : ndarray of shape (s, d) 
            First order Sobol' indices. 
        total_order : ndarray of shape (s, d) 
            Total order Sobol' indices. 
 
        And method: 
 
        bootstrap(confidence_level: float, n_resamples: int) 
        -&gt; BootstrapSobolResult 
 
            A method providing confidence intervals on the indices. 
            See `scipy.stats.bootstrap` for more details. 
 
            The bootstrapping is done on both first and total order indices, 
            and they are available in `BootstrapSobolResult` as attributes 
            ``first_order`` and ``total_order``. 
 
    Notes 
    ----- 
    The Sobol' method [1]_, [2]_ is a variance-based Sensitivity Analysis which 
    obtains the contribution of each parameter to the variance of the 
    quantities of interest (QoIs; i.e., the outputs of `func`). 
    Respective contributions can be used to rank the parameters and 
    also gauge the complexity of the model by computing the 
    model's effective (or mean) dimension. 
 
    .. note:: 
 
        Parameters are assumed to be independently distributed. Each 
        parameter can still follow any distribution. In fact, the distribution 
        is very important and should match the real distribution of the 
        parameters. 
 
    It uses a functional decomposition of the variance of the function to 
    explore 
 
    .. math:: 
 
        \mathbb{V}(Y) = \sum_{i}^{d} \mathbb{V}_i (Y) + \sum_{i&lt;j}^{d} 
        \mathbb{V}_{ij}(Y) + ... + \mathbb{V}_{1,2,...,d}(Y), 
 
    introducing conditional variances: 
 
    .. math:: 
 
        \mathbb{V}_i(Y) = \mathbb{\mathbb{V}}[\mathbb{E}(Y|x_i)] 
        \qquad 
        \mathbb{V}_{ij}(Y) = \mathbb{\mathbb{V}}[\mathbb{E}(Y|x_i x_j)] 
        - \mathbb{V}_i(Y) - \mathbb{V}_j(Y), 
 
    Sobol' indices are expressed as 
 
    .. math:: 
 
        S_i = \frac{\mathbb{V}_i(Y)}{\mathbb{V}[Y]} 
        \qquad 
        S_{ij} =\frac{\mathbb{V}_{ij}(Y)}{\mathbb{V}[Y]}. 
 
    :math:`S_{i}` corresponds to the first-order term which apprises the 
    contribution of the i-th parameter, while :math:`S_{ij}` corresponds to the 
    second-order term which informs about the contribution of interactions 
    between the i-th and the j-th parameters. These equations can be 
    generalized to compute higher order terms; however, they are expensive to 
    compute and their interpretation is complex. 
    This is why only first order indices are provided. 
 
    Total order indices represent the global contribution of the parameters 
    to the variance of the QoI and are defined as: 
 
    .. math:: 
 
        S_{T_i} = S_i + \sum_j S_{ij} + \sum_{j,k} S_{ijk} + ... 
        = 1 - \frac{\mathbb{V}[\mathbb{E}(Y|x_{\sim i})]}{\mathbb{V}[Y]}. 
 
    First order indices sum to at most 1, while total order indices sum to at 
    least 1. If there are no interactions, then first and total order indices 
    are equal, and both first and total order indices sum to 1. 
 
    .. warning:: 
 
        Negative Sobol' values are due to numerical errors. Increasing the 
        number of points `n` should help. 
 
        The number of sample required to have a good analysis increases with 
        the dimensionality of the problem. e.g. for a 3 dimension problem, 
        consider at minima ``n &gt;= 2**12``. The more complex the model is, 
        the more samples will be needed. 
 
        Even for a purely addiditive model, the indices may not sum to 1 due 
        to numerical noise. 
 
    References 
    ---------- 
    .. [1] Sobol, I. M.. &quot;Sensitivity analysis for nonlinear mathematical 
       models.&quot; Mathematical Modeling and Computational Experiment, 1:407-414, 
       1993. 
    .. [2] Sobol, I. M. (2001). &quot;Global sensitivity indices for nonlinear 
       mathematical models and their Monte Carlo estimates.&quot; Mathematics 
       and Computers in Simulation, 55(1-3):271-280, 
       :doi:`10.1016/S0378-4754(00)00270-6`, 2001. 
    .. [3] Saltelli, A. &quot;Making best use of model evaluations to 
       compute sensitivity indices.&quot;  Computer Physics Communications, 
       145(2):280-297, :doi:`10.1016/S0010-4655(02)00280-1`, 2002. 
    .. [4] Saltelli, A., M. Ratto, T. Andres, F. Campolongo, J. Cariboni, 
       D. Gatelli, M. Saisana, and S. Tarantola. &quot;Global Sensitivity Analysis. 
       The Primer.&quot; 2007. 
    .. [5] Saltelli, A., P. Annoni, I. Azzini, F. Campolongo, M. Ratto, and 
       S. Tarantola. &quot;Variance based sensitivity analysis of model 
       output. Design and estimator for the total sensitivity index.&quot; 
       Computer Physics Communications, 181(2):259-270, 
       :doi:`10.1016/j.cpc.2009.09.018`, 2010. 
    .. [6] Ishigami, T. and T. Homma. &quot;An importance quantification technique 
       in uncertainty analysis for computer models.&quot; IEEE, 
       :doi:`10.1109/ISUMA.1990.151285`, 1990. 
 
    Examples 
    -------- 
    The following is an example with the Ishigami function [6]_ 
 
    .. math:: 
 
        Y(\mathbf{x}) = \sin x_1 + 7 \sin^2 x_2 + 0.1 x_3^4 \sin x_1, 
 
    with :math:`\mathbf{x} \in [-\pi, \pi]^3`. This function exhibits strong 
    non-linearity and non-monotonicity. 
 
    Remember, Sobol' indices assumes that samples are independently 
    distributed. In this case we use a uniform distribution on each marginals. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import sobol_indices, uniform 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; def f_ishigami(x): 
    ...     f_eval = ( 
    ...         np.sin(x[0]) 
    ...         + 7 * np.sin(x[1])**2 
    ...         + 0.1 * (x[2]**4) * np.sin(x[0]) 
    ...     ) 
    ...     return f_eval 
    &gt;&gt;&gt; indices = sobol_indices( 
    ...     func=f_ishigami, n=1024, 
    ...     dists=[ 
    ...         uniform(loc=-np.pi, scale=2*np.pi), 
    ...         uniform(loc=-np.pi, scale=2*np.pi), 
    ...         uniform(loc=-np.pi, scale=2*np.pi) 
    ...     ], 
    ...     random_state=rng 
    ... ) 
    &gt;&gt;&gt; indices.first_order 
    array([0.31637954, 0.43781162, 0.00318825]) 
    &gt;&gt;&gt; indices.total_order 
    array([0.56122127, 0.44287857, 0.24229595]) 
 
    Confidence interval can be obtained using bootstrapping. 
 
    &gt;&gt;&gt; boot = indices.bootstrap() 
 
    Then, this information can be easily visualized. 
 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; fig, axs = plt.subplots(1, 2, figsize=(9, 4)) 
    &gt;&gt;&gt; _ = axs[0].errorbar( 
    ...     [1, 2, 3], indices.first_order, fmt='o', 
    ...     yerr=[ 
    ...         indices.first_order - boot.first_order.confidence_interval.low, 
    ...         boot.first_order.confidence_interval.high - indices.first_order 
    ...     ], 
    ... ) 
    &gt;&gt;&gt; axs[0].set_ylabel(&quot;First order Sobol' indices&quot;) 
    &gt;&gt;&gt; axs[0].set_xlabel('Input parameters') 
    &gt;&gt;&gt; axs[0].set_xticks([1, 2, 3]) 
    &gt;&gt;&gt; _ = axs[1].errorbar( 
    ...     [1, 2, 3], indices.total_order, fmt='o', 
    ...     yerr=[ 
    ...         indices.total_order - boot.total_order.confidence_interval.low, 
    ...         boot.total_order.confidence_interval.high - indices.total_order 
    ...     ], 
    ... ) 
    &gt;&gt;&gt; axs[1].set_ylabel(&quot;Total order Sobol' indices&quot;) 
    &gt;&gt;&gt; axs[1].set_xlabel('Input parameters') 
    &gt;&gt;&gt; axs[1].set_xticks([1, 2, 3]) 
    &gt;&gt;&gt; plt.tight_layout() 
    &gt;&gt;&gt; plt.show() 
 
    .. note:: 
 
        By default, `scipy.stats.uniform` has support ``[0, 1]``. 
        Using the parameters ``loc`` and ``scale``, one obtains the uniform 
        distribution on ``[loc, loc + scale]``. 
 
    This result is particularly interesting because the first order index 
    :math:`S_{x_3} = 0` whereas its total order is :math:`S_{T_{x_3}} = 0.244`. 
    This means that higher order interactions with :math:`x_3` are responsible 
    for the difference. Almost 25% of the observed variance 
    on the QoI is due to the correlations between :math:`x_3` and :math:`x_1`, 
    although :math:`x_3` by itself has no impact on the QoI. 
 
    The following gives a visual explanation of Sobol' indices on this 
    function. Let's generate 1024 samples in :math:`[-\pi, \pi]^3` and 
    calculate the value of the output. 
 
    &gt;&gt;&gt; from scipy.stats import qmc 
    &gt;&gt;&gt; n_dim = 3 
    &gt;&gt;&gt; p_labels = ['$x_1$', '$x_2$', '$x_3$'] 
    &gt;&gt;&gt; sample = qmc.Sobol(d=n_dim, seed=rng).random(1024) 
    &gt;&gt;&gt; sample = qmc.scale( 
    ...     sample=sample, 
    ...     l_bounds=[-np.pi, -np.pi, -np.pi], 
    ...     u_bounds=[np.pi, np.pi, np.pi] 
    ... ) 
    &gt;&gt;&gt; output = f_ishigami(sample.T) 
 
    Now we can do scatter plots of the output with respect to each parameter. 
    This gives a visual way to understand how each parameter impacts the 
    output of the function. 
 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, n_dim, figsize=(12, 4)) 
    &gt;&gt;&gt; for i in range(n_dim): 
    ...     xi = sample[:, i] 
    ...     ax[i].scatter(xi, output, marker='+') 
    ...     ax[i].set_xlabel(p_labels[i]) 
    &gt;&gt;&gt; ax[0].set_ylabel('Y') 
    &gt;&gt;&gt; plt.tight_layout() 
    &gt;&gt;&gt; plt.show() 
 
    Now Sobol' goes a step further: 
    by conditioning the output value by given values of the parameter 
    (black lines), the conditional output mean is computed. It corresponds to 
    the term :math:`\mathbb{E}(Y|x_i)`. Taking the variance of this term gives 
    the numerator of the Sobol' indices. 
 
    &gt;&gt;&gt; mini = np.min(output) 
    &gt;&gt;&gt; maxi = np.max(output) 
    &gt;&gt;&gt; n_bins = 10 
    &gt;&gt;&gt; bins = np.linspace(-np.pi, np.pi, num=n_bins, endpoint=False) 
    &gt;&gt;&gt; dx = bins[1] - bins[0] 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, n_dim, figsize=(12, 4)) 
    &gt;&gt;&gt; for i in range(n_dim): 
    ...     xi = sample[:, i] 
    ...     ax[i].scatter(xi, output, marker='+') 
    ...     ax[i].set_xlabel(p_labels[i]) 
    ...     for bin_ in bins: 
    ...         idx = np.where((bin_ &lt;= xi) &amp; (xi &lt;= bin_ + dx)) 
    ...         xi_ = xi[idx] 
    ...         y_ = output[idx] 
    ...         ave_y_ = np.mean(y_) 
    ...         ax[i].plot([bin_ + dx/2] * 2, [mini, maxi], c='k') 
    ...         ax[i].scatter(bin_ + dx/2, ave_y_, c='r') 
    &gt;&gt;&gt; ax[0].set_ylabel('Y') 
    &gt;&gt;&gt; plt.tight_layout() 
    &gt;&gt;&gt; plt.show() 
 
    Looking at :math:`x_3`, the variance 
    of the mean is zero leading to :math:`S_{x_3} = 0`. But we can further 
    observe that the variance of the output is not constant along the parameter 
    values of :math:`x_3`. This heteroscedasticity is explained by higher order 
    interactions. Moreover, an heteroscedasticity is also noticeable on 
    :math:`x_1` leading to an interaction between :math:`x_3` and :math:`x_1`. 
    On :math:`x_2`, the variance seems to be constant and thus null interaction 
    with this parameter can be supposed. 
 
    This case is fairly simple to analyse visually---although it is only a 
    qualitative analysis. Nevertheless, when the number of input parameters 
    increases such analysis becomes unrealistic as it would be difficult to 
    conclude on high-order terms. Hence the benefit of using Sobol' indices. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">random_state = check_random_state(random_state)</span>

    <span class="s1">n_ = int(n)</span>
    <span class="s0">if not </span><span class="s1">(n_ &amp; (n_ - </span><span class="s4">1</span><span class="s1">) == </span><span class="s4">0</span><span class="s1">) </span><span class="s0">or </span><span class="s1">n != n_:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span>
            <span class="s2">&quot;The balance properties of Sobol' points require 'n' &quot;</span>
            <span class="s2">&quot;to be a power of 2.&quot;</span>
        <span class="s1">)</span>
    <span class="s1">n = n_</span>

    <span class="s0">if not </span><span class="s1">callable(method):</span>
        <span class="s1">indices_methods: dict[str</span><span class="s0">, </span><span class="s1">Callable] = {</span>
            <span class="s2">&quot;saltelli_2010&quot;</span><span class="s1">: saltelli_2010</span><span class="s0">,</span>
        <span class="s1">}</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">method = method.lower()  </span><span class="s5"># type: ignore[assignment]</span>
            <span class="s1">indices_method_ = indices_methods[method]</span>
        <span class="s0">except </span><span class="s1">KeyError </span><span class="s0">as </span><span class="s1">exc:</span>
            <span class="s1">message = (</span>
                <span class="s2">f&quot;</span><span class="s0">{</span><span class="s1">method</span><span class="s0">!r} </span><span class="s2">is not a valid 'method'. It must be one of&quot;</span>
                <span class="s2">f&quot; </span><span class="s0">{</span><span class="s1">set(indices_methods)</span><span class="s0">!r} </span><span class="s2">or a callable.&quot;</span>
            <span class="s1">)</span>
            <span class="s0">raise </span><span class="s1">ValueError(message) </span><span class="s0">from </span><span class="s1">exc</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">indices_method_ = method</span>
        <span class="s1">sig = inspect.signature(indices_method_)</span>

        <span class="s0">if </span><span class="s1">set(sig.parameters) != {</span><span class="s2">'f_A'</span><span class="s0">, </span><span class="s2">'f_B'</span><span class="s0">, </span><span class="s2">'f_AB'</span><span class="s1">}:</span>
            <span class="s1">message = (</span>
                <span class="s2">&quot;If 'method' is a callable, it must have the following&quot;</span>
                <span class="s2">f&quot; signature: </span><span class="s0">{</span><span class="s1">inspect.signature(saltelli_2010)</span><span class="s0">}</span><span class="s2">&quot;</span>
            <span class="s1">)</span>
            <span class="s0">raise </span><span class="s1">ValueError(message)</span>

    <span class="s0">def </span><span class="s1">indices_method(f_A</span><span class="s0">, </span><span class="s1">f_B</span><span class="s0">, </span><span class="s1">f_AB):</span>
        <span class="s3">&quot;&quot;&quot;Wrap indices method to ensure proper output dimension. 
 
        1D when single output, 2D otherwise. 
        &quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">np.squeeze(indices_method_(f_A=f_A</span><span class="s0">, </span><span class="s1">f_B=f_B</span><span class="s0">, </span><span class="s1">f_AB=f_AB))</span>

    <span class="s0">if </span><span class="s1">callable(func):</span>
        <span class="s0">if </span><span class="s1">dists </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">&quot;'dists' must be defined when 'func' is a callable.&quot;</span>
            <span class="s1">)</span>

        <span class="s0">def </span><span class="s1">wrapped_func(x):</span>
            <span class="s0">return </span><span class="s1">np.atleast_2d(func(x))</span>

        <span class="s1">A</span><span class="s0">, </span><span class="s1">B = sample_A_B(n=n</span><span class="s0">, </span><span class="s1">dists=dists</span><span class="s0">, </span><span class="s1">random_state=random_state)</span>
        <span class="s1">AB = sample_AB(A=A</span><span class="s0">, </span><span class="s1">B=B)</span>

        <span class="s1">f_A = wrapped_func(A)</span>

        <span class="s0">if </span><span class="s1">f_A.shape[</span><span class="s4">1</span><span class="s1">] != n:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">&quot;'func' output should have a shape ``(s, -1)`` with ``s`` &quot;</span>
                <span class="s2">&quot;the number of output.&quot;</span>
            <span class="s1">)</span>

        <span class="s0">def </span><span class="s1">funcAB(AB):</span>
            <span class="s1">d</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">n = AB.shape</span>
            <span class="s1">AB = np.moveaxis(AB</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">).reshape(d</span><span class="s0">, </span><span class="s1">n*d)</span>
            <span class="s1">f_AB = wrapped_func(AB)</span>
            <span class="s0">return </span><span class="s1">np.moveaxis(f_AB.reshape((-</span><span class="s4">1</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">d))</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>

        <span class="s1">f_B = wrapped_func(B)</span>
        <span class="s1">f_AB = funcAB(AB)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">message = (</span>
            <span class="s2">&quot;When 'func' is a dictionary, it must contain the following &quot;</span>
            <span class="s2">&quot;keys: 'f_A', 'f_B' and 'f_AB'.&quot;</span>
            <span class="s2">&quot;'f_A' and 'f_B' should have a shape ``(s, n)`` and 'f_AB' &quot;</span>
            <span class="s2">&quot;should have a shape ``(d, s, n)``.&quot;</span>
        <span class="s1">)</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">f_A</span><span class="s0">, </span><span class="s1">f_B</span><span class="s0">, </span><span class="s1">f_AB = np.atleast_2d(</span>
                <span class="s1">func[</span><span class="s2">'f_A'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">func[</span><span class="s2">'f_B'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">func[</span><span class="s2">'f_AB'</span><span class="s1">]</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">KeyError </span><span class="s0">as </span><span class="s1">exc:</span>
            <span class="s0">raise </span><span class="s1">ValueError(message) </span><span class="s0">from </span><span class="s1">exc</span>

        <span class="s0">if </span><span class="s1">f_A.shape[</span><span class="s4">1</span><span class="s1">] != n </span><span class="s0">or </span><span class="s1">f_A.shape != f_B.shape </span><span class="s0">or </span><span class="s1">\</span>
                <span class="s1">f_AB.shape == f_A.shape </span><span class="s0">or </span><span class="s1">f_AB.shape[-</span><span class="s4">1</span><span class="s1">] % n != </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(message)</span>

    <span class="s5"># Normalization by mean</span>
    <span class="s5"># Sobol', I. and Levitan, Y. L. (1999). On the use of variance reducing</span>
    <span class="s5"># multipliers in monte carlo computations of a global sensitivity index.</span>
    <span class="s5"># Computer Physics Communications, 117(1) :52-61.</span>
    <span class="s1">mean = np.mean([f_A</span><span class="s0">, </span><span class="s1">f_B]</span><span class="s0">, </span><span class="s1">axis=(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">)).reshape(-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">f_A -= mean</span>
    <span class="s1">f_B -= mean</span>
    <span class="s1">f_AB -= mean</span>

    <span class="s5"># Compute indices</span>
    <span class="s5"># Filter warnings for constant output as var = 0</span>
    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s2">'ignore'</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s2">'ignore'</span><span class="s1">):</span>
        <span class="s1">first_order</span><span class="s0">, </span><span class="s1">total_order = indices_method(f_A=f_A</span><span class="s0">, </span><span class="s1">f_B=f_B</span><span class="s0">, </span><span class="s1">f_AB=f_AB)</span>

    <span class="s5"># null variance means null indices</span>
    <span class="s1">first_order[~np.isfinite(first_order)] = </span><span class="s4">0</span>
    <span class="s1">total_order[~np.isfinite(total_order)] = </span><span class="s4">0</span>

    <span class="s1">res = dict(</span>
        <span class="s1">first_order=first_order</span><span class="s0">,</span>
        <span class="s1">total_order=total_order</span><span class="s0">,</span>
        <span class="s1">_indices_method=indices_method</span><span class="s0">,</span>
        <span class="s1">_f_A=f_A</span><span class="s0">,</span>
        <span class="s1">_f_B=f_B</span><span class="s0">,</span>
        <span class="s1">_f_AB=f_AB</span>
    <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">callable(func):</span>
        <span class="s1">res.update(</span>
            <span class="s1">dict(</span>
                <span class="s1">_A=A</span><span class="s0">,</span>
                <span class="s1">_B=B</span><span class="s0">,</span>
                <span class="s1">_AB=AB</span><span class="s0">,</span>
            <span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s0">return </span><span class="s1">SobolResult(**res)</span>
</pre>
</body>
</html>
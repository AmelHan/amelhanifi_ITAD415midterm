<html>
<head>
<title>markov_switching.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
markov_switching.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Markov switching models 
 
Author: Chad Fulton 
License: BSD-3 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">scipy.special </span><span class="s2">import </span><span class="s1">logsumexp</span>

<span class="s2">from </span><span class="s1">statsmodels.base.data </span><span class="s2">import </span><span class="s1">PandasData</span>
<span class="s2">import </span><span class="s1">statsmodels.base.wrapper </span><span class="s2">as </span><span class="s1">wrap</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.eval_measures </span><span class="s2">import </span><span class="s1">aic</span><span class="s2">, </span><span class="s1">bic</span><span class="s2">, </span><span class="s1">hqic</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.numdiff </span><span class="s2">import </span><span class="s1">approx_fprime_cs</span><span class="s2">, </span><span class="s1">approx_hess_cs</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">EstimationWarning</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.tools </span><span class="s2">import </span><span class="s1">Bunch</span><span class="s2">, </span><span class="s1">pinv_extended</span>
<span class="s2">import </span><span class="s1">statsmodels.tsa.base.tsa_model </span><span class="s2">as </span><span class="s1">tsbase</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.regime_switching._hamilton_filter </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">chamilton_filter_log</span><span class="s2">,</span>
    <span class="s1">dhamilton_filter_log</span><span class="s2">,</span>
    <span class="s1">shamilton_filter_log</span><span class="s2">,</span>
    <span class="s1">zhamilton_filter_log</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.regime_switching._kim_smoother </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ckim_smoother_log</span><span class="s2">,</span>
    <span class="s1">dkim_smoother_log</span><span class="s2">,</span>
    <span class="s1">skim_smoother_log</span><span class="s2">,</span>
    <span class="s1">zkim_smoother_log</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.tools </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">find_best_blas_type</span><span class="s2">,</span>
    <span class="s1">prepare_exog</span><span class="s2">,</span>
    <span class="s1">_safe_cond</span>
<span class="s1">)</span>

<span class="s1">prefix_hamilton_filter_log_map = {</span>
    <span class="s3">'s'</span><span class="s1">: shamilton_filter_log</span><span class="s2">, </span><span class="s3">'d'</span><span class="s1">: dhamilton_filter_log</span><span class="s2">,</span>
    <span class="s3">'c'</span><span class="s1">: chamilton_filter_log</span><span class="s2">, </span><span class="s3">'z'</span><span class="s1">: zhamilton_filter_log</span>
<span class="s1">}</span>

<span class="s1">prefix_kim_smoother_log_map = {</span>
    <span class="s3">'s'</span><span class="s1">: skim_smoother_log</span><span class="s2">, </span><span class="s3">'d'</span><span class="s1">: dkim_smoother_log</span><span class="s2">,</span>
    <span class="s3">'c'</span><span class="s1">: ckim_smoother_log</span><span class="s2">, </span><span class="s3">'z'</span><span class="s1">: zkim_smoother_log</span>
<span class="s1">}</span>


<span class="s2">def </span><span class="s1">_logistic(x):</span>
    <span class="s0">&quot;&quot;&quot; 
    Note that this is not a vectorized function 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.array(x)</span>
    <span class="s4"># np.exp(x) / (1 + np.exp(x))</span>
    <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">y = np.reshape(x</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># np.exp(x[i]) / (1 + np.sum(np.exp(x[:])))</span>
    <span class="s2">elif </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">y = np.reshape(x</span><span class="s2">, </span><span class="s1">(len(x)</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># np.exp(x[i,t]) / (1 + np.sum(np.exp(x[:,t])))</span>
    <span class="s2">elif </span><span class="s1">x.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">y = np.reshape(x</span><span class="s2">, </span><span class="s1">(x.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">x.shape[</span><span class="s5">1</span><span class="s1">]))</span>
    <span class="s4"># np.exp(x[i,j,t]) / (1 + np.sum(np.exp(x[:,j,t])))</span>
    <span class="s2">elif </span><span class="s1">x.ndim == </span><span class="s5">3</span><span class="s1">:</span>
        <span class="s1">y = x</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">tmp = np.c_[np.zeros((y.shape[-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">y.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span><span class="s2">, </span><span class="s1">y.T].T</span>
    <span class="s1">evaluated = np.reshape(np.exp(y - logsumexp(tmp</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">))</span><span class="s2">, </span><span class="s1">x.shape)</span>

    <span class="s2">return </span><span class="s1">evaluated</span>


<span class="s2">def </span><span class="s1">_partials_logistic(x):</span>
    <span class="s0">&quot;&quot;&quot; 
    Note that this is not a vectorized function 
    &quot;&quot;&quot;</span>
    <span class="s1">tmp = _logistic(x)</span>

    <span class="s4"># k</span>
    <span class="s2">if </span><span class="s1">tmp.ndim == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">tmp - tmp**</span><span class="s5">2</span>
    <span class="s4"># k x k</span>
    <span class="s2">elif </span><span class="s1">tmp.ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">partials = np.diag(tmp - tmp**</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s4"># k x k x t</span>
    <span class="s2">elif </span><span class="s1">tmp.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">partials = [np.diag(tmp[:</span><span class="s2">, </span><span class="s1">t] - tmp[:</span><span class="s2">, </span><span class="s1">t]**</span><span class="s5">2</span><span class="s1">)</span>
                    <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">range(tmp.shape[</span><span class="s5">1</span><span class="s1">])]</span>
        <span class="s1">shape = tmp.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">partials = np.concatenate(partials).reshape(shape).transpose((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s4"># k x k x j x t</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">partials = [[np.diag(tmp[:</span><span class="s2">, </span><span class="s1">j</span><span class="s2">, </span><span class="s1">t] - tmp[:</span><span class="s2">, </span><span class="s1">j</span><span class="s2">, </span><span class="s1">t]**</span><span class="s5">2</span><span class="s1">)</span>
                     <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">range(tmp.shape[</span><span class="s5">2</span><span class="s1">])]</span>
                    <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(tmp.shape[</span><span class="s5">1</span><span class="s1">])]</span>
        <span class="s1">shape = tmp.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp.shape[</span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">partials = np.concatenate(partials).reshape(shape).transpose(</span>
            <span class="s1">(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(tmp.shape[</span><span class="s5">0</span><span class="s1">]):</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(i):</span>
            <span class="s1">partials[i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">, </span><span class="s1">...] = -tmp[i</span><span class="s2">, </span><span class="s1">...] * tmp[j</span><span class="s2">, </span><span class="s1">...]</span>
            <span class="s1">partials[j</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">...] = partials[i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">, </span><span class="s1">...]</span>
    <span class="s2">return </span><span class="s1">partials</span>


<span class="s2">def </span><span class="s1">cy_hamilton_filter_log(initial_probabilities</span><span class="s2">, </span><span class="s1">regime_transition</span><span class="s2">,</span>
                           <span class="s1">conditional_loglikelihoods</span><span class="s2">, </span><span class="s1">model_order):</span>
    <span class="s0">&quot;&quot;&quot; 
    Hamilton filter in log space using Cython inner loop. 
 
    Parameters 
    ---------- 
    initial_probabilities : ndarray 
        Array of initial probabilities, shaped (k_regimes,) giving the 
        distribution of the regime process at time t = -order where order 
        is a nonnegative integer. 
    regime_transition : ndarray 
        Matrix of regime transition probabilities, shaped either 
        (k_regimes, k_regimes, 1) or if there are time-varying transition 
        probabilities (k_regimes, k_regimes, nobs + order).  Entry [i, j, 
        t] contains the probability of moving from j at time t-1 to i at 
        time t, so each matrix regime_transition[:, :, t] should be left 
        stochastic.  The first order entries and initial_probabilities are 
        used to produce the initial joint distribution of dimension order + 
        1 at time t=0. 
    conditional_loglikelihoods : ndarray 
        Array of loglikelihoods conditional on the last `order+1` regimes, 
        shaped (k_regimes,)*(order + 1) + (nobs,). 
 
    Returns 
    ------- 
    filtered_marginal_probabilities : ndarray 
        Array containing Pr[S_t=s_t | Y_t] - the probability of being in each 
        regime conditional on time t information. Shaped (k_regimes, nobs). 
    predicted_joint_probabilities : ndarray 
        Array containing Pr[S_t=s_t, ..., S_{t-order}=s_{t-order} | Y_{t-1}] - 
        the joint probability of the current and previous `order` periods 
        being in each combination of regimes conditional on time t-1 
        information. Shaped (k_regimes,) * (order + 1) + (nobs,). 
    joint_loglikelihoods : ndarray 
        Array of loglikelihoods condition on time t information, 
        shaped (nobs,). 
    filtered_joint_probabilities : ndarray 
        Array containing Pr[S_t=s_t, ..., S_{t-order}=s_{t-order} | Y_{t}] - 
        the joint probability of the current and previous `order` periods 
        being in each combination of regimes conditional on time t 
        information. Shaped (k_regimes,) * (order + 1) + (nobs,). 
    &quot;&quot;&quot;</span>

    <span class="s4"># Dimensions</span>
    <span class="s1">k_regimes = len(initial_probabilities)</span>
    <span class="s1">nobs = conditional_loglikelihoods.shape[-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">order = conditional_loglikelihoods.ndim - </span><span class="s5">2</span>
    <span class="s1">dtype = conditional_loglikelihoods.dtype</span>

    <span class="s4"># Check for compatible shapes.</span>
    <span class="s1">incompatible_shapes = (</span>
        <span class="s1">regime_transition.shape[-</span><span class="s5">1</span><span class="s1">] </span><span class="s2">not in </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">nobs + model_order)</span>
        <span class="s2">or </span><span class="s1">regime_transition.shape[:</span><span class="s5">2</span><span class="s1">] != (k_regimes</span><span class="s2">, </span><span class="s1">k_regimes)</span>
        <span class="s2">or </span><span class="s1">conditional_loglikelihoods.shape[</span><span class="s5">0</span><span class="s1">] != k_regimes)</span>
    <span class="s2">if </span><span class="s1">incompatible_shapes:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Arguments do not have compatible shapes'</span><span class="s1">)</span>

    <span class="s4"># Convert to log space</span>
    <span class="s1">initial_probabilities = np.log(initial_probabilities)</span>
    <span class="s1">regime_transition = np.log(np.maximum(regime_transition</span><span class="s2">, </span><span class="s5">1e-20</span><span class="s1">))</span>

    <span class="s4"># Storage</span>
    <span class="s4"># Pr[S_t = s_t | Y_t]</span>
    <span class="s1">filtered_marginal_probabilities = (</span>
        <span class="s1">np.zeros((k_regimes</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">, </span><span class="s1">dtype=dtype))</span>
    <span class="s4"># Pr[S_t = s_t, ... S_{t-r} = s_{t-r} | Y_{t-1}]</span>
    <span class="s4"># Has k_regimes^(order+1) elements</span>
    <span class="s1">predicted_joint_probabilities = np.zeros(</span>
        <span class="s1">(k_regimes</span><span class="s2">,</span><span class="s1">) * (order + </span><span class="s5">1</span><span class="s1">) + (nobs</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
    <span class="s4"># log(f(y_t | Y_{t-1}))</span>
    <span class="s1">joint_loglikelihoods = np.zeros((nobs</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype)</span>
    <span class="s4"># Pr[S_t = s_t, ... S_{t-r+1} = s_{t-r+1} | Y_t]</span>
    <span class="s4"># Has k_regimes^order elements</span>
    <span class="s1">filtered_joint_probabilities = np.zeros(</span>
        <span class="s1">(k_regimes</span><span class="s2">,</span><span class="s1">) * (order + </span><span class="s5">1</span><span class="s1">) + (nobs + </span><span class="s5">1</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>

    <span class="s4"># Initial probabilities</span>
    <span class="s1">filtered_marginal_probabilities[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = initial_probabilities</span>
    <span class="s1">tmp = np.copy(initial_probabilities)</span>
    <span class="s1">shape = (k_regimes</span><span class="s2">, </span><span class="s1">k_regimes)</span>
    <span class="s1">transition_t = </span><span class="s5">0</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(order):</span>
        <span class="s2">if </span><span class="s1">regime_transition.shape[-</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">transition_t = i</span>
        <span class="s1">tmp = np.reshape(regime_transition[...</span><span class="s2">, </span><span class="s1">transition_t]</span><span class="s2">,</span>
                         <span class="s1">shape + (</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) * i) + tmp</span>
    <span class="s1">filtered_joint_probabilities[...</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = tmp</span>

    <span class="s4"># Get appropriate subset of transition matrix</span>
    <span class="s2">if </span><span class="s1">regime_transition.shape[-</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">regime_transition = regime_transition[...</span><span class="s2">, </span><span class="s1">model_order:]</span>

    <span class="s4"># Run Cython filter iterations</span>
    <span class="s1">prefix</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">_ = find_best_blas_type((</span>
        <span class="s1">regime_transition</span><span class="s2">, </span><span class="s1">conditional_loglikelihoods</span><span class="s2">, </span><span class="s1">joint_loglikelihoods</span><span class="s2">,</span>
        <span class="s1">predicted_joint_probabilities</span><span class="s2">, </span><span class="s1">filtered_joint_probabilities))</span>
    <span class="s1">func = prefix_hamilton_filter_log_map[prefix]</span>
    <span class="s1">func(nobs</span><span class="s2">, </span><span class="s1">k_regimes</span><span class="s2">, </span><span class="s1">order</span><span class="s2">, </span><span class="s1">regime_transition</span><span class="s2">,</span>
         <span class="s1">conditional_loglikelihoods.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">,</span>
         <span class="s1">joint_loglikelihoods</span><span class="s2">,</span>
         <span class="s1">predicted_joint_probabilities.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">,</span>
         <span class="s1">filtered_joint_probabilities.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs+</span><span class="s5">1</span><span class="s1">))</span>

    <span class="s4"># Save log versions for smoother</span>
    <span class="s1">predicted_joint_probabilities_log = predicted_joint_probabilities</span>
    <span class="s1">filtered_joint_probabilities_log = filtered_joint_probabilities</span>

    <span class="s4"># Convert out of log scale</span>
    <span class="s1">predicted_joint_probabilities = np.exp(predicted_joint_probabilities)</span>
    <span class="s1">filtered_joint_probabilities = np.exp(filtered_joint_probabilities)</span>

    <span class="s4"># S_t | t</span>
    <span class="s1">filtered_marginal_probabilities = filtered_joint_probabilities[...</span><span class="s2">, </span><span class="s5">1</span><span class="s1">:]</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">filtered_marginal_probabilities.ndim - </span><span class="s5">1</span><span class="s1">):</span>
        <span class="s1">filtered_marginal_probabilities = np.sum(</span>
            <span class="s1">filtered_marginal_probabilities</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">(filtered_marginal_probabilities</span><span class="s2">, </span><span class="s1">predicted_joint_probabilities</span><span class="s2">,</span>
            <span class="s1">joint_loglikelihoods</span><span class="s2">, </span><span class="s1">filtered_joint_probabilities[...</span><span class="s2">, </span><span class="s5">1</span><span class="s1">:]</span><span class="s2">,</span>
            <span class="s1">predicted_joint_probabilities_log</span><span class="s2">,</span>
            <span class="s1">filtered_joint_probabilities_log[...</span><span class="s2">, </span><span class="s5">1</span><span class="s1">:])</span>


<span class="s2">def </span><span class="s1">cy_kim_smoother_log(regime_transition</span><span class="s2">, </span><span class="s1">predicted_joint_probabilities</span><span class="s2">,</span>
                        <span class="s1">filtered_joint_probabilities):</span>
    <span class="s0">&quot;&quot;&quot; 
    Kim smoother in log space using Cython inner loop. 
 
    Parameters 
    ---------- 
    regime_transition : ndarray 
        Matrix of regime transition probabilities, shaped either 
        (k_regimes, k_regimes, 1) or if there are time-varying transition 
        probabilities (k_regimes, k_regimes, nobs). 
    predicted_joint_probabilities : ndarray 
        Array containing Pr[S_t=s_t, ..., S_{t-order}=s_{t-order} | Y_{t-1}] - 
        the joint probability of the current and previous `order` periods 
        being in each combination of regimes conditional on time t-1 
        information. Shaped (k_regimes,) * (order + 1) + (nobs,). 
    filtered_joint_probabilities : ndarray 
        Array containing Pr[S_t=s_t, ..., S_{t-order}=s_{t-order} | Y_{t}] - 
        the joint probability of the current and previous `order` periods 
        being in each combination of regimes conditional on time t 
        information. Shaped (k_regimes,) * (order + 1) + (nobs,). 
 
    Returns 
    ------- 
    smoothed_joint_probabilities : ndarray 
        Array containing Pr[S_t=s_t, ..., S_{t-order}=s_{t-order} | Y_T] - 
        the joint probability of the current and previous `order` periods 
        being in each combination of regimes conditional on all information. 
        Shaped (k_regimes,) * (order + 1) + (nobs,). 
    smoothed_marginal_probabilities : ndarray 
        Array containing Pr[S_t=s_t | Y_T] - the probability of being in each 
        regime conditional on all information. Shaped (k_regimes, nobs). 
    &quot;&quot;&quot;</span>

    <span class="s4"># Dimensions</span>
    <span class="s1">k_regimes = filtered_joint_probabilities.shape[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">nobs = filtered_joint_probabilities.shape[-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">order = filtered_joint_probabilities.ndim - </span><span class="s5">2</span>
    <span class="s1">dtype = filtered_joint_probabilities.dtype</span>

    <span class="s4"># Storage</span>
    <span class="s1">smoothed_joint_probabilities = np.zeros(</span>
        <span class="s1">(k_regimes</span><span class="s2">,</span><span class="s1">) * (order + </span><span class="s5">1</span><span class="s1">) + (nobs</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>

    <span class="s4"># Get appropriate subset of transition matrix</span>
    <span class="s2">if </span><span class="s1">regime_transition.shape[-</span><span class="s5">1</span><span class="s1">] == nobs + order:</span>
        <span class="s1">regime_transition = regime_transition[...</span><span class="s2">, </span><span class="s1">order:]</span>

    <span class="s4"># Convert to log space</span>
    <span class="s1">regime_transition = np.log(np.maximum(regime_transition</span><span class="s2">, </span><span class="s5">1e-20</span><span class="s1">))</span>

    <span class="s4"># Run Cython smoother iterations</span>
    <span class="s1">prefix</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">_ = find_best_blas_type((</span>
        <span class="s1">regime_transition</span><span class="s2">, </span><span class="s1">predicted_joint_probabilities</span><span class="s2">,</span>
        <span class="s1">filtered_joint_probabilities))</span>
    <span class="s1">func = prefix_kim_smoother_log_map[prefix]</span>
    <span class="s1">func(nobs</span><span class="s2">, </span><span class="s1">k_regimes</span><span class="s2">, </span><span class="s1">order</span><span class="s2">, </span><span class="s1">regime_transition</span><span class="s2">,</span>
         <span class="s1">predicted_joint_probabilities.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">,</span>
         <span class="s1">filtered_joint_probabilities.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">,</span>
         <span class="s1">smoothed_joint_probabilities.reshape(k_regimes**(order+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs))</span>

    <span class="s4"># Convert back from log space</span>
    <span class="s1">smoothed_joint_probabilities = np.exp(smoothed_joint_probabilities)</span>

    <span class="s4"># Get smoothed marginal probabilities S_t | T by integrating out</span>
    <span class="s4"># S_{t-k+1}, S_{t-k+2}, ..., S_{t-1}</span>
    <span class="s1">smoothed_marginal_probabilities = smoothed_joint_probabilities</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">smoothed_marginal_probabilities.ndim - </span><span class="s5">1</span><span class="s1">):</span>
        <span class="s1">smoothed_marginal_probabilities = np.sum(</span>
            <span class="s1">smoothed_marginal_probabilities</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">smoothed_joint_probabilities</span><span class="s2">, </span><span class="s1">smoothed_marginal_probabilities</span>


<span class="s2">class </span><span class="s1">MarkovSwitchingParams:</span>
    <span class="s0">&quot;&quot;&quot; 
    Class to hold parameters in Markov switching models 
 
    Parameters 
    ---------- 
    k_regimes : int 
        The number of regimes between which parameters may switch. 
 
    Notes 
    ----- 
 
    The purpose is to allow selecting parameter indexes / slices based on 
    parameter type, regime number, or both. 
 
    Parameters are lexicographically ordered in the following way: 
 
    1. Named type string (e.g. &quot;autoregressive&quot;) 
    2. Number (e.g. the first autoregressive parameter, then the second) 
    3. Regime (if applicable) 
 
    Parameter blocks are set using dictionary setter notation where the key 
    is the named type string and the value is a list of boolean values 
    indicating whether a given parameter is switching or not. 
 
    For example, consider the following code: 
 
        parameters = MarkovSwitchingParams(k_regimes=2) 
        parameters['regime_transition'] = [1,1] 
        parameters['exog'] = [0, 1] 
 
    This implies the model has 7 parameters: 4 &quot;regime_transition&quot;-related 
    parameters (2 parameters that each switch according to regimes) and 3 
    &quot;exog&quot;-related parameters (1 parameter that does not switch, and one 1 that 
    does). 
 
    The order of parameters is then: 
 
    1. The first &quot;regime_transition&quot; parameter, regime 0 
    2. The first &quot;regime_transition&quot; parameter, regime 1 
    3. The second &quot;regime_transition&quot; parameter, regime 1 
    4. The second &quot;regime_transition&quot; parameter, regime 1 
    5. The first &quot;exog&quot; parameter 
    6. The second &quot;exog&quot; parameter, regime 0 
    7. The second &quot;exog&quot; parameter, regime 1 
 
    Retrieving indexes / slices is done through dictionary getter notation. 
    There are three options for the dictionary key: 
 
    - Regime number (zero-indexed) 
    - Named type string (e.g. &quot;autoregressive&quot;) 
    - Regime number and named type string 
 
    In the above example, consider the following getters: 
 
    &gt;&gt;&gt; parameters[0] 
    array([0, 2, 4, 6]) 
    &gt;&gt;&gt; parameters[1] 
    array([1, 3, 5, 6]) 
    &gt;&gt;&gt; parameters['exog'] 
    slice(4, 7, None) 
    &gt;&gt;&gt; parameters[0, 'exog'] 
    [4, 6] 
    &gt;&gt;&gt; parameters[1, 'exog'] 
    [4, 7] 
 
    Notice that in the last two examples, both lists of indexes include 4. 
    That's because that is the index of the the non-switching first &quot;exog&quot; 
    parameter, which should be selected regardless of the regime. 
 
    In addition to the getter, the `k_parameters` attribute is an dict 
    with the named type strings as the keys. It can be used to get the total 
    number of parameters of each type: 
 
    &gt;&gt;&gt; parameters.k_parameters['regime_transition'] 
    4 
    &gt;&gt;&gt; parameters.k_parameters['exog'] 
    3 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">k_regimes):</span>
        <span class="s1">self.k_regimes = k_regimes</span>

        <span class="s1">self.k_params = </span><span class="s5">0</span>
        <span class="s1">self.k_parameters = {}</span>
        <span class="s1">self.switching = {}</span>
        <span class="s1">self.slices_purpose = {}</span>
        <span class="s1">self.relative_index_regime_purpose = [</span>
            <span class="s1">{} </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes)]</span>
        <span class="s1">self.index_regime_purpose = [</span>
            <span class="s1">{} </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes)]</span>
        <span class="s1">self.index_regime = [[] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes)]</span>

    <span class="s2">def </span><span class="s1">__getitem__(self</span><span class="s2">, </span><span class="s1">key):</span>
        <span class="s1">_type = type(key)</span>

        <span class="s4"># Get a slice for a block of parameters by purpose</span>
        <span class="s2">if </span><span class="s1">_type </span><span class="s2">is </span><span class="s1">str:</span>
            <span class="s2">return </span><span class="s1">self.slices_purpose[key]</span>
        <span class="s4"># Get a slice for a block of parameters by regime</span>
        <span class="s2">elif </span><span class="s1">_type </span><span class="s2">is </span><span class="s1">int:</span>
            <span class="s2">return </span><span class="s1">self.index_regime[key]</span>
        <span class="s2">elif </span><span class="s1">_type </span><span class="s2">is </span><span class="s1">tuple:</span>
            <span class="s2">if not </span><span class="s1">len(key) == </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">IndexError(</span><span class="s3">'Invalid index'</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">type(key[</span><span class="s5">1</span><span class="s1">]) == str </span><span class="s2">and </span><span class="s1">type(key[</span><span class="s5">0</span><span class="s1">]) == int:</span>
                <span class="s2">return </span><span class="s1">self.index_regime_purpose[key[</span><span class="s5">0</span><span class="s1">]][key[</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s2">elif </span><span class="s1">type(key[</span><span class="s5">0</span><span class="s1">]) == str </span><span class="s2">and </span><span class="s1">type(key[</span><span class="s5">1</span><span class="s1">]) == int:</span>
                <span class="s2">return </span><span class="s1">self.index_regime_purpose[key[</span><span class="s5">1</span><span class="s1">]][key[</span><span class="s5">0</span><span class="s1">]]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">IndexError(</span><span class="s3">'Invalid index'</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">IndexError(</span><span class="s3">'Invalid index'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__setitem__(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s1">_type = type(key)</span>

        <span class="s2">if </span><span class="s1">_type </span><span class="s2">is </span><span class="s1">str:</span>
            <span class="s1">value = np.array(value</span><span class="s2">, </span><span class="s1">dtype=bool</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">k_params = self.k_params</span>
            <span class="s1">self.k_parameters[key] = (</span>
                <span class="s1">value.size + np.sum(value) * (self.k_regimes - </span><span class="s5">1</span><span class="s1">))</span>
            <span class="s1">self.k_params += self.k_parameters[key]</span>
            <span class="s1">self.switching[key] = value</span>
            <span class="s1">self.slices_purpose[key] = np.s_[k_params:self.k_params]</span>

            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">self.relative_index_regime_purpose[j][key] = []</span>
                <span class="s1">self.index_regime_purpose[j][key] = []</span>

            <span class="s1">offset = </span><span class="s5">0</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(value.size):</span>
                <span class="s1">switching = value[i]</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                    <span class="s4"># Non-switching parameters</span>
                    <span class="s2">if not </span><span class="s1">switching:</span>
                        <span class="s1">self.relative_index_regime_purpose[j][key].append(</span>
                            <span class="s1">offset)</span>
                    <span class="s4"># Switching parameters</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">self.relative_index_regime_purpose[j][key].append(</span>
                            <span class="s1">offset + j)</span>
                <span class="s1">offset += </span><span class="s5">1 </span><span class="s2">if not </span><span class="s1">switching </span><span class="s2">else </span><span class="s1">self.k_regimes</span>

            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">offset = </span><span class="s5">0</span>
                <span class="s1">indices = []</span>
                <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.relative_index_regime_purpose[j].items():</span>
                    <span class="s1">v = (np.r_[v] + offset).tolist()</span>
                    <span class="s1">self.index_regime_purpose[j][k] = v</span>
                    <span class="s1">indices.append(v)</span>
                    <span class="s1">offset += self.k_parameters[k]</span>
                <span class="s1">self.index_regime[j] = np.concatenate(indices).astype(int)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">IndexError(</span><span class="s3">'Invalid index'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">MarkovSwitching(tsbase.TimeSeriesModel):</span>
    <span class="s0">&quot;&quot;&quot; 
    First-order k-regime Markov switching model 
 
    Parameters 
    ---------- 
    endog : array_like 
        The endogenous variable. 
    k_regimes : int 
        The number of regimes. 
    order : int, optional 
        The order of the model describes the dependence of the likelihood on 
        previous regimes. This depends on the model in question and should be 
        set appropriately by subclasses. 
    exog_tvtp : array_like, optional 
        Array of exogenous or lagged variables to use in calculating 
        time-varying transition probabilities (TVTP). TVTP is only used if this 
        variable is provided. If an intercept is desired, a column of ones must 
        be explicitly included in this array. 
 
    Notes 
    ----- 
    This model is new and API stability is not guaranteed, although changes 
    will be made in a backwards compatible way if possible. 
 
    References 
    ---------- 
    Kim, Chang-Jin, and Charles R. Nelson. 1999. 
    &quot;State-Space Models with Regime Switching: 
    Classical and Gibbs-Sampling Approaches with Applications&quot;. 
    MIT Press Books. The MIT Press. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">k_regimes</span><span class="s2">, </span><span class="s1">order=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">exog_tvtp=</span><span class="s2">None, </span><span class="s1">exog=</span><span class="s2">None,</span>
                 <span class="s1">dates=</span><span class="s2">None, </span><span class="s1">freq=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s3">'none'</span><span class="s1">):</span>

        <span class="s4"># Properties</span>
        <span class="s1">self.k_regimes = k_regimes</span>
        <span class="s1">self.tvtp = exog_tvtp </span><span class="s2">is not None</span>
        <span class="s4"># The order of the model may be overridden in subclasses</span>
        <span class="s1">self.order = order</span>

        <span class="s4"># Exogenous data</span>
        <span class="s4"># TODO add checks for exog_tvtp consistent shape and indices</span>
        <span class="s1">self.k_tvtp</span><span class="s2">, </span><span class="s1">self.exog_tvtp = prepare_exog(exog_tvtp)</span>

        <span class="s4"># Initialize the base model</span>
        <span class="s1">super(MarkovSwitching</span><span class="s2">, </span><span class="s1">self).__init__(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">dates=dates</span><span class="s2">,</span>
                                              <span class="s1">freq=freq</span><span class="s2">, </span><span class="s1">missing=missing)</span>

        <span class="s4"># Dimensions</span>
        <span class="s1">self.nobs = self.endog.shape[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s4"># Sanity checks</span>
        <span class="s2">if </span><span class="s1">self.endog.ndim &gt; </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">self.endog.shape[</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Must have univariate endogenous data.'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.k_regimes &lt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Markov switching models must have at least two'</span>
                             <span class="s3">' regimes.'</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">(self.exog_tvtp </span><span class="s2">is None or</span>
                <span class="s1">self.exog_tvtp.shape[</span><span class="s5">0</span><span class="s1">] == self.nobs):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Time-varying transition probabilities exogenous'</span>
                             <span class="s3">' array must have the same number of observations'</span>
                             <span class="s3">' as the endogenous array.'</span><span class="s1">)</span>

        <span class="s4"># Parameters</span>
        <span class="s1">self.parameters = MarkovSwitchingParams(self.k_regimes)</span>
        <span class="s1">k_transition = self.k_regimes - </span><span class="s5">1</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s1">k_transition *= self.k_tvtp</span>
        <span class="s1">self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">] = [</span><span class="s5">1</span><span class="s1">] * k_transition</span>

        <span class="s4"># Internal model properties: default is steady-state initialization</span>
        <span class="s1">self._initialization = </span><span class="s3">'steady-state'</span>
        <span class="s1">self._initial_probabilities = </span><span class="s2">None</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">k_params(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (int) Number of parameters in the model 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.parameters.k_params</span>

    <span class="s2">def </span><span class="s1">initialize_steady_state(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Set initialization of regime probabilities to be steady-state values 
 
        Notes 
        ----- 
        Only valid if there are not time-varying transition probabilities. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Cannot use steady-state initialization when'</span>
                             <span class="s3">' the regime transition matrix is time-varying.'</span><span class="s1">)</span>

        <span class="s1">self._initialization = </span><span class="s3">'steady-state'</span>
        <span class="s1">self._initial_probabilities = </span><span class="s2">None</span>

    <span class="s2">def </span><span class="s1">initialize_known(self</span><span class="s2">, </span><span class="s1">probabilities</span><span class="s2">, </span><span class="s1">tol=</span><span class="s5">1e-8</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Set initialization of regime probabilities to use known values 
        &quot;&quot;&quot;</span>
        <span class="s1">self._initialization = </span><span class="s3">'known'</span>
        <span class="s1">probabilities = np.array(probabilities</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">probabilities.shape == (self.k_regimes</span><span class="s2">,</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Initial probabilities must be a vector of shape'</span>
                             <span class="s3">' (k_regimes,).'</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">np.abs(np.sum(probabilities) - </span><span class="s5">1</span><span class="s1">) &lt; tol:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Initial probabilities vector must sum to one.'</span><span class="s1">)</span>
        <span class="s1">self._initial_probabilities = probabilities</span>

    <span class="s2">def </span><span class="s1">initial_probabilities(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">regime_transition=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Retrieve initial probabilities 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self._initialization == </span><span class="s3">'steady-state'</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">regime_transition </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">regime_transition = self.regime_transition_matrix(params)</span>
            <span class="s2">if </span><span class="s1">regime_transition.ndim == </span><span class="s5">3</span><span class="s1">:</span>
                <span class="s1">regime_transition = regime_transition[...</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">m = regime_transition.shape[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">A = np.c_[(np.eye(m) - regime_transition).T</span><span class="s2">, </span><span class="s1">np.ones(m)].T</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">probabilities = np.linalg.pinv(A)[:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">'Steady-state probabilities could not be'</span>
                                   <span class="s3">' constructed.'</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">self._initialization == </span><span class="s3">'known'</span><span class="s1">:</span>
            <span class="s1">probabilities = self._initial_probabilities</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">'Invalid initialization method selected.'</span><span class="s1">)</span>

        <span class="s4"># Slightly bound probabilities away from zero (for filters in log</span>
        <span class="s4"># space)</span>
        <span class="s1">probabilities = np.maximum(probabilities</span><span class="s2">, </span><span class="s5">1e-20</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">probabilities</span>

    <span class="s2">def </span><span class="s1">_regime_transition_matrix_tvtp(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog_tvtp=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s1">exog_tvtp </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog_tvtp = self.exog_tvtp</span>
        <span class="s1">nobs = len(exog_tvtp)</span>

        <span class="s1">regime_transition_matrix = np.zeros(</span>
            <span class="s1">(self.k_regimes</span><span class="s2">, </span><span class="s1">self.k_regimes</span><span class="s2">, </span><span class="s1">nobs)</span><span class="s2">,</span>
            <span class="s1">dtype=np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">params.dtype))</span>

        <span class="s4"># Compute the predicted values from the regression</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">coeffs = params[self.parameters[i</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">]]</span>
            <span class="s1">regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">:] = np.dot(</span>
                <span class="s1">exog_tvtp</span><span class="s2">,</span>
                <span class="s1">np.reshape(coeffs</span><span class="s2">, </span><span class="s1">(self.k_regimes-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.k_tvtp)).T).T</span>

        <span class="s4"># Perform the logistic transformation</span>
        <span class="s1">tmp = np.c_[np.zeros((nobs</span><span class="s2">, </span><span class="s1">self.k_regimes</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span><span class="s2">,</span>
                    <span class="s1">regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:].T].T</span>
        <span class="s1">regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.exp(</span>
            <span class="s1">regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] - logsumexp(tmp</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">))</span>

        <span class="s4"># Compute the last column of the transition matrix</span>
        <span class="s1">regime_transition_matrix[-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = (</span>
            <span class="s5">1 </span><span class="s1">- np.sum(regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">))</span>

        <span class="s2">return </span><span class="s1">regime_transition_matrix</span>

    <span class="s2">def </span><span class="s1">regime_transition_matrix(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog_tvtp=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct the left-stochastic transition matrix 
 
        Notes 
        ----- 
        This matrix will either be shaped (k_regimes, k_regimes, 1) or if there 
        are time-varying transition probabilities, it will be shaped 
        (k_regimes, k_regimes, nobs). 
 
        The (i,j)th element of this matrix is the probability of transitioning 
        from regime j to regime i; thus the previous regime is represented in a 
        column and the next regime is represented by a row. 
 
        It is left-stochastic, meaning that each column sums to one (because 
        it is certain that from one regime (j) you will transition to *some 
        other regime*). 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">self.tvtp:</span>
            <span class="s1">regime_transition_matrix = np.zeros(</span>
                <span class="s1">(self.k_regimes</span><span class="s2">, </span><span class="s1">self.k_regimes</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s1">dtype=np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">params.dtype))</span>
            <span class="s1">regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = np.reshape(</span>
                <span class="s1">params[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]]</span><span class="s2">,</span>
                <span class="s1">(self.k_regimes-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.k_regimes))</span>
            <span class="s1">regime_transition_matrix[-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = (</span>
                <span class="s5">1 </span><span class="s1">- np.sum(regime_transition_matrix[:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">regime_transition_matrix = (</span>
                <span class="s1">self._regime_transition_matrix_tvtp(params</span><span class="s2">, </span><span class="s1">exog_tvtp))</span>

        <span class="s2">return </span><span class="s1">regime_transition_matrix</span>

    <span class="s2">def </span><span class="s1">predict(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">end=</span><span class="s2">None, </span><span class="s1">probabilities=</span><span class="s2">None,</span>
                <span class="s1">conditional=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        In-sample prediction and out-of-sample forecasting 
 
        Parameters 
        ---------- 
        params : ndarray 
            Parameters at which to form predictions 
        start : int, str, or datetime, optional 
            Zero-indexed observation number at which to start forecasting, 
            i.e., the first forecast is start. Can also be a date string to 
            parse or a datetime type. Default is the the zeroth observation. 
        end : int, str, or datetime, optional 
            Zero-indexed observation number at which to end forecasting, i.e., 
            the last forecast is end. Can also be a date string to 
            parse or a datetime type. However, if the dates index does not 
            have a fixed frequency, end must be an integer index if you 
            want out of sample prediction. Default is the last observation in 
            the sample. 
        probabilities : str or array_like, optional 
            Specifies the weighting probabilities used in constructing the 
            prediction as a weighted average. If a string, can be 'predicted', 
            'filtered', or 'smoothed'. Otherwise can be an array of 
            probabilities to use. Default is smoothed. 
        conditional : bool or int, optional 
            Whether or not to return predictions conditional on current or 
            past regimes. If False, returns a single vector of weighted 
            predictions. If True or 1, returns predictions conditional on the 
            current regime. For larger integers, returns predictions 
            conditional on the current regime and some number of past regimes. 
 
        Returns 
        ------- 
        predict : ndarray 
            Array of out of in-sample predictions and / or out-of-sample 
            forecasts. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">start </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">start = self._index[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s4"># Handle start, end</span>
        <span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">out_of_sample</span><span class="s2">, </span><span class="s1">prediction_index = (</span>
            <span class="s1">self._get_prediction_index(start</span><span class="s2">, </span><span class="s1">end))</span>

        <span class="s2">if </span><span class="s1">out_of_sample &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError</span>

        <span class="s4"># Perform in-sample prediction</span>
        <span class="s1">predict = self.predict_conditional(params)</span>
        <span class="s1">squeezed = np.squeeze(predict)</span>

        <span class="s4"># Check if we need to do weighted averaging</span>
        <span class="s2">if </span><span class="s1">squeezed.ndim - </span><span class="s5">1 </span><span class="s1">&gt; conditional:</span>
            <span class="s4"># Determine in-sample weighting probabilities</span>
            <span class="s2">if </span><span class="s1">probabilities </span><span class="s2">is None or </span><span class="s1">probabilities == </span><span class="s3">'smoothed'</span><span class="s1">:</span>
                <span class="s1">results = self.smooth(params</span><span class="s2">, </span><span class="s1">return_raw=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s1">probabilities = results.smoothed_joint_probabilities</span>
            <span class="s2">elif </span><span class="s1">probabilities == </span><span class="s3">'filtered'</span><span class="s1">:</span>
                <span class="s1">results = self.filter(params</span><span class="s2">, </span><span class="s1">return_raw=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s1">probabilities = results.filtered_joint_probabilities</span>
            <span class="s2">elif </span><span class="s1">probabilities == </span><span class="s3">'predicted'</span><span class="s1">:</span>
                <span class="s1">results = self.filter(params</span><span class="s2">, </span><span class="s1">return_raw=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s1">probabilities = results.predicted_joint_probabilities</span>

            <span class="s4"># Compute weighted average</span>
            <span class="s1">predict = (predict * probabilities)</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(predict.ndim - </span><span class="s5">1 </span><span class="s1">- int(conditional)):</span>
                <span class="s1">predict = np.sum(predict</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">predict = squeezed</span>

        <span class="s2">return </span><span class="s1">predict[start:end + out_of_sample + </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">predict_conditional(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        In-sample prediction, conditional on the current, and possibly past, 
        regimes 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to perform prediction. 
 
        Returns 
        ------- 
        predict : array_like 
            Array of predictions conditional on current, and possibly past, 
            regimes 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s2">def </span><span class="s1">_conditional_loglikelihoods(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute likelihoods conditional on the current period's regime (and 
        the last self.order periods' regimes if self.order &gt; 0). 
 
        Must be implemented in subclasses. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s2">def </span><span class="s1">_filter(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">regime_transition=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s4"># Get the regime transition matrix if not provided</span>
        <span class="s2">if </span><span class="s1">regime_transition </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">regime_transition = self.regime_transition_matrix(params)</span>
        <span class="s4"># Get the initial probabilities</span>
        <span class="s1">initial_probabilities = self.initial_probabilities(</span>
            <span class="s1">params</span><span class="s2">, </span><span class="s1">regime_transition)</span>

        <span class="s4"># Compute the conditional likelihoods</span>
        <span class="s1">conditional_loglikelihoods = self._conditional_loglikelihoods(params)</span>

        <span class="s4"># Apply the filter</span>
        <span class="s2">return </span><span class="s1">((regime_transition</span><span class="s2">, </span><span class="s1">initial_probabilities</span><span class="s2">,</span>
                 <span class="s1">conditional_loglikelihoods) +</span>
                <span class="s1">cy_hamilton_filter_log(</span>
                    <span class="s1">initial_probabilities</span><span class="s2">, </span><span class="s1">regime_transition</span><span class="s2">,</span>
                    <span class="s1">conditional_loglikelihoods</span><span class="s2">, </span><span class="s1">self.order))</span>

    <span class="s2">def </span><span class="s1">filter(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">cov_type=</span><span class="s2">None, </span><span class="s1">cov_kwds=</span><span class="s2">None,</span>
               <span class="s1">return_raw=</span><span class="s2">False, </span><span class="s1">results_class=</span><span class="s2">None,</span>
               <span class="s1">results_wrapper_class=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Apply the Hamilton filter 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to perform filtering. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        cov_type : str, optional 
            See `fit` for a description of covariance matrix types 
            for results object. 
        cov_kwds : dict or None, optional 
            See `fit` for a description of required keywords for alternative 
            covariance estimators 
        return_raw : bool,optional 
            Whether or not to return only the raw Hamilton filter output or a 
            full results object. Default is to return a full results object. 
        results_class : type, optional 
            A results class to instantiate rather than 
            `MarkovSwitchingResults`. Usually only used internally by 
            subclasses. 
        results_wrapper_class : type, optional 
            A results wrapper class to instantiate rather than 
            `MarkovSwitchingResults`. Usually only used internally by 
            subclasses. 
 
        Returns 
        ------- 
        MarkovSwitchingResults 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">transformed:</span>
            <span class="s1">params = self.transform_params(params)</span>

        <span class="s4"># Save the parameter names</span>
        <span class="s1">self.data.param_names = self.param_names</span>

        <span class="s4"># Get the result</span>
        <span class="s1">names = [</span><span class="s3">'regime_transition'</span><span class="s2">, </span><span class="s3">'initial_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'conditional_loglikelihoods'</span><span class="s2">,</span>
                 <span class="s3">'filtered_marginal_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'predicted_joint_probabilities'</span><span class="s2">, </span><span class="s3">'joint_loglikelihoods'</span><span class="s2">,</span>
                 <span class="s3">'filtered_joint_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'predicted_joint_probabilities_log'</span><span class="s2">,</span>
                 <span class="s3">'filtered_joint_probabilities_log'</span><span class="s1">]</span>
        <span class="s1">result = HamiltonFilterResults(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">Bunch(**dict(zip(names</span><span class="s2">, </span><span class="s1">self._filter(params)))))</span>

        <span class="s4"># Wrap in a results object</span>
        <span class="s2">return </span><span class="s1">self._wrap_results(params</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">return_raw</span><span class="s2">, </span><span class="s1">cov_type</span><span class="s2">,</span>
                                  <span class="s1">cov_kwds</span><span class="s2">, </span><span class="s1">results_class</span><span class="s2">,</span>
                                  <span class="s1">results_wrapper_class)</span>

    <span class="s2">def </span><span class="s1">_smooth(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">predicted_joint_probabilities_log</span><span class="s2">,</span>
                <span class="s1">filtered_joint_probabilities_log</span><span class="s2">, </span><span class="s1">regime_transition=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s4"># Get the regime transition matrix</span>
        <span class="s2">if </span><span class="s1">regime_transition </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">regime_transition = self.regime_transition_matrix(params)</span>

        <span class="s4"># Apply the smoother</span>
        <span class="s2">return </span><span class="s1">cy_kim_smoother_log(regime_transition</span><span class="s2">,</span>
                                   <span class="s1">predicted_joint_probabilities_log</span><span class="s2">,</span>
                                   <span class="s1">filtered_joint_probabilities_log)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_res_classes(self):</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s3">'fit'</span><span class="s1">: (MarkovSwitchingResults</span><span class="s2">, </span><span class="s1">MarkovSwitchingResultsWrapper)}</span>

    <span class="s2">def </span><span class="s1">_wrap_results(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">return_raw</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s2">None,</span>
                      <span class="s1">cov_kwds=</span><span class="s2">None, </span><span class="s1">results_class=</span><span class="s2">None, </span><span class="s1">wrapper_class=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">if not </span><span class="s1">return_raw:</span>
            <span class="s4"># Wrap in a results object</span>
            <span class="s1">result_kwargs = {}</span>
            <span class="s2">if </span><span class="s1">cov_type </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">result_kwargs[</span><span class="s3">'cov_type'</span><span class="s1">] = cov_type</span>
            <span class="s2">if </span><span class="s1">cov_kwds </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">result_kwargs[</span><span class="s3">'cov_kwds'</span><span class="s1">] = cov_kwds</span>

            <span class="s2">if </span><span class="s1">results_class </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">results_class = self._res_classes[</span><span class="s3">'fit'</span><span class="s1">][</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">if </span><span class="s1">wrapper_class </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">wrapper_class = self._res_classes[</span><span class="s3">'fit'</span><span class="s1">][</span><span class="s5">1</span><span class="s1">]</span>

            <span class="s1">res = results_class(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">**result_kwargs)</span>
            <span class="s1">result = wrapper_class(res)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">smooth(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">cov_type=</span><span class="s2">None, </span><span class="s1">cov_kwds=</span><span class="s2">None,</span>
               <span class="s1">return_raw=</span><span class="s2">False, </span><span class="s1">results_class=</span><span class="s2">None,</span>
               <span class="s1">results_wrapper_class=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Apply the Kim smoother and Hamilton filter 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to perform filtering. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        cov_type : str, optional 
            See `fit` for a description of covariance matrix types 
            for results object. 
        cov_kwds : dict or None, optional 
            See `fit` for a description of required keywords for alternative 
            covariance estimators 
        return_raw : bool,optional 
            Whether or not to return only the raw Hamilton filter output or a 
            full results object. Default is to return a full results object. 
        results_class : type, optional 
            A results class to instantiate rather than 
            `MarkovSwitchingResults`. Usually only used internally by 
            subclasses. 
        results_wrapper_class : type, optional 
            A results wrapper class to instantiate rather than 
            `MarkovSwitchingResults`. Usually only used internally by 
            subclasses. 
 
        Returns 
        ------- 
        MarkovSwitchingResults 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">transformed:</span>
            <span class="s1">params = self.transform_params(params)</span>

        <span class="s4"># Save the parameter names</span>
        <span class="s1">self.data.param_names = self.param_names</span>

        <span class="s4"># Hamilton filter</span>
        <span class="s4"># TODO add option to filter to return logged values so that we do not</span>
        <span class="s4"># need to re-log them for smoother</span>
        <span class="s1">names = [</span><span class="s3">'regime_transition'</span><span class="s2">, </span><span class="s3">'initial_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'conditional_loglikelihoods'</span><span class="s2">,</span>
                 <span class="s3">'filtered_marginal_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'predicted_joint_probabilities'</span><span class="s2">, </span><span class="s3">'joint_loglikelihoods'</span><span class="s2">,</span>
                 <span class="s3">'filtered_joint_probabilities'</span><span class="s2">,</span>
                 <span class="s3">'predicted_joint_probabilities_log'</span><span class="s2">,</span>
                 <span class="s3">'filtered_joint_probabilities_log'</span><span class="s1">]</span>
        <span class="s1">result = Bunch(**dict(zip(names</span><span class="s2">, </span><span class="s1">self._filter(params))))</span>

        <span class="s4"># Kim smoother</span>
        <span class="s1">out = self._smooth(params</span><span class="s2">, </span><span class="s1">result.predicted_joint_probabilities_log</span><span class="s2">,</span>
                           <span class="s1">result.filtered_joint_probabilities_log)</span>
        <span class="s1">result[</span><span class="s3">'smoothed_joint_probabilities'</span><span class="s1">] = out[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">result[</span><span class="s3">'smoothed_marginal_probabilities'</span><span class="s1">] = out[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">result = KimSmootherResults(self</span><span class="s2">, </span><span class="s1">result)</span>

        <span class="s4"># Wrap in a results object</span>
        <span class="s2">return </span><span class="s1">self._wrap_results(params</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">return_raw</span><span class="s2">, </span><span class="s1">cov_type</span><span class="s2">,</span>
                                  <span class="s1">cov_kwds</span><span class="s2">, </span><span class="s1">results_class</span><span class="s2">,</span>
                                  <span class="s1">results_wrapper_class)</span>

    <span class="s2">def </span><span class="s1">loglikeobs(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Loglikelihood evaluation for each period 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the loglikelihood 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">transformed:</span>
            <span class="s1">params = self.transform_params(params)</span>

        <span class="s1">results = self._filter(params)</span>

        <span class="s2">return </span><span class="s1">results[</span><span class="s5">5</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">loglike(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Loglikelihood evaluation 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the loglikelihood 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.sum(self.loglikeobs(params</span><span class="s2">, </span><span class="s1">transformed))</span>

    <span class="s2">def </span><span class="s1">score(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute the score function at params. 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the score 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">approx_fprime_cs(params</span><span class="s2">, </span><span class="s1">self.loglike</span><span class="s2">, </span><span class="s1">args=(transformed</span><span class="s2">,</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">score_obs(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute the score per observation, evaluated at params 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the score 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">approx_fprime_cs(params</span><span class="s2">, </span><span class="s1">self.loglikeobs</span><span class="s2">, </span><span class="s1">args=(transformed</span><span class="s2">,</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">hessian(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Hessian matrix of the likelihood function, evaluated at the given 
        parameters 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to evaluate the Hessian 
            function. 
        transformed : bool, optional 
            Whether or not `params` is already transformed. Default is True. 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">approx_hess_cs(params</span><span class="s2">, </span><span class="s1">self.loglike)</span>

    <span class="s2">def </span><span class="s1">fit(self</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">cov_type=</span><span class="s3">'approx'</span><span class="s2">,</span>
            <span class="s1">cov_kwds=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'bfgs'</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">full_output=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">disp=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">callback=</span><span class="s2">None, </span><span class="s1">return_params=</span><span class="s2">False, </span><span class="s1">em_iter=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">search_reps=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">search_iter=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">search_scale=</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fits the model by maximum likelihood via Hamilton filter. 
 
        Parameters 
        ---------- 
        start_params : array_like, optional 
            Initial guess of the solution for the loglikelihood maximization. 
            If None, the default is given by Model.start_params. 
        transformed : bool, optional 
            Whether or not `start_params` is already transformed. Default is 
            True. 
        cov_type : str, optional 
            The type of covariance matrix estimator to use. Can be one of 
            'approx', 'opg', 'robust', or 'none'. Default is 'approx'. 
        cov_kwds : dict or None, optional 
            Keywords for alternative covariance estimators 
        method : str, optional 
            The `method` determines which solver from `scipy.optimize` 
            is used, and it can be chosen from among the following strings: 
 
            - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead 
            - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS) 
            - 'lbfgs' for limited-memory BFGS with optional box constraints 
            - 'powell' for modified Powell's method 
            - 'cg' for conjugate gradient 
            - 'ncg' for Newton-conjugate gradient 
            - 'basinhopping' for global basin-hopping solver 
 
            The explicit arguments in `fit` are passed to the solver, 
            with the exception of the basin-hopping solver. Each 
            solver has several optional arguments that are not the same across 
            solvers. See the notes section below (or scipy.optimize) for the 
            available arguments and for the list of explicit arguments that the 
            basin-hopping solver supports. 
        maxiter : int, optional 
            The maximum number of iterations to perform. 
        full_output : bool, optional 
            Set to True to have all available output in the Results object's 
            mle_retvals attribute. The output is dependent on the solver. 
            See LikelihoodModelResults notes section for more information. 
        disp : bool, optional 
            Set to True to print convergence messages. 
        callback : callable callback(xk), optional 
            Called after each iteration, as callback(xk), where xk is the 
            current parameter vector. 
        return_params : bool, optional 
            Whether or not to return only the array of maximizing parameters. 
            Default is False. 
        em_iter : int, optional 
            Number of initial EM iteration steps used to improve starting 
            parameters. 
        search_reps : int, optional 
            Number of randomly drawn search parameters that are drawn around 
            `start_params` to try and improve starting parameters. Default is 
            0. 
        search_iter : int, optional 
            Number of initial EM iteration steps used to improve each of the 
            search parameter repetitions. 
        search_scale : float or array, optional. 
            Scale of variates for random start parameter search. 
        **kwargs 
            Additional keyword arguments to pass to the optimizer. 
 
        Returns 
        ------- 
        MarkovSwitchingResults 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">start_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">start_params = self.start_params</span>
            <span class="s1">transformed = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">start_params = np.array(start_params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Random search for better start parameters</span>
        <span class="s2">if </span><span class="s1">search_reps &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">start_params = self._start_params_search(</span>
                <span class="s1">search_reps</span><span class="s2">, </span><span class="s1">start_params=start_params</span><span class="s2">,</span>
                <span class="s1">transformed=transformed</span><span class="s2">, </span><span class="s1">em_iter=search_iter</span><span class="s2">,</span>
                <span class="s1">scale=search_scale)</span>
            <span class="s1">transformed = </span><span class="s2">True</span>

        <span class="s4"># Get better start params through EM algorithm</span>
        <span class="s2">if </span><span class="s1">em_iter </span><span class="s2">and not </span><span class="s1">self.tvtp:</span>
            <span class="s1">start_params = self._fit_em(start_params</span><span class="s2">, </span><span class="s1">transformed=transformed</span><span class="s2">,</span>
                                        <span class="s1">maxiter=em_iter</span><span class="s2">, </span><span class="s1">tolerance=</span><span class="s5">0</span><span class="s2">,</span>
                                        <span class="s1">return_params=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">transformed = </span><span class="s2">True</span>

        <span class="s2">if </span><span class="s1">transformed:</span>
            <span class="s1">start_params = self.untransform_params(start_params)</span>

        <span class="s4"># Maximum likelihood estimation by scoring</span>
        <span class="s1">fargs = (</span><span class="s2">False,</span><span class="s1">)</span>
        <span class="s1">mlefit = super(MarkovSwitching</span><span class="s2">, </span><span class="s1">self).fit(start_params</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">,</span>
                                                  <span class="s1">fargs=fargs</span><span class="s2">,</span>
                                                  <span class="s1">maxiter=maxiter</span><span class="s2">,</span>
                                                  <span class="s1">full_output=full_output</span><span class="s2">,</span>
                                                  <span class="s1">disp=disp</span><span class="s2">, </span><span class="s1">callback=callback</span><span class="s2">,</span>
                                                  <span class="s1">skip_hessian=</span><span class="s2">True, </span><span class="s1">**kwargs)</span>

        <span class="s4"># Just return the fitted parameters if requested</span>
        <span class="s2">if </span><span class="s1">return_params:</span>
            <span class="s1">result = self.transform_params(mlefit.params)</span>
        <span class="s4"># Otherwise construct the results class if desired</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self.smooth(mlefit.params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False,</span>
                                 <span class="s1">cov_type=cov_type</span><span class="s2">, </span><span class="s1">cov_kwds=cov_kwds)</span>

            <span class="s1">result.mlefit = mlefit</span>
            <span class="s1">result.mle_retvals = mlefit.mle_retvals</span>
            <span class="s1">result.mle_settings = mlefit.mle_settings</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_fit_em(self</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">cov_type=</span><span class="s3">'none'</span><span class="s2">,</span>
                <span class="s1">cov_kwds=</span><span class="s2">None, </span><span class="s1">maxiter=</span><span class="s5">50</span><span class="s2">, </span><span class="s1">tolerance=</span><span class="s5">1e-6</span><span class="s2">, </span><span class="s1">full_output=</span><span class="s2">True,</span>
                <span class="s1">return_params=</span><span class="s2">False, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fits the model using the Expectation-Maximization (EM) algorithm 
 
        Parameters 
        ---------- 
        start_params : array_like, optional 
            Initial guess of the solution for the loglikelihood maximization. 
            If None, the default is given by `start_params`. 
        transformed : bool, optional 
            Whether or not `start_params` is already transformed. Default is 
            True. 
        cov_type : str, optional 
            The type of covariance matrix estimator to use. Can be one of 
            'approx', 'opg', 'robust', or 'none'. Default is 'none'. 
        cov_kwds : dict or None, optional 
            Keywords for alternative covariance estimators 
        maxiter : int, optional 
            The maximum number of iterations to perform. 
        tolerance : float, optional 
            The iteration stops when the difference between subsequent 
            loglikelihood values is less than this tolerance. 
        full_output : bool, optional 
            Set to True to have all available output in the Results object's 
            mle_retvals attribute. This includes all intermediate values for 
            parameters and loglikelihood values 
        return_params : bool, optional 
            Whether or not to return only the array of maximizing parameters. 
            Default is False. 
        **kwargs 
            Additional keyword arguments to pass to the optimizer. 
 
        Notes 
        ----- 
        This is a private method for finding good starting parameters for MLE 
        by scoring. It has not been tested for a thoroughly correct EM 
        implementation in all cases. It does not support TVTP transition 
        probabilities. 
 
        Returns 
        ------- 
        MarkovSwitchingResults 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">start_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">start_params = self.start_params</span>
            <span class="s1">transformed = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">start_params = np.array(start_params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">transformed:</span>
            <span class="s1">start_params = self.transform_params(start_params)</span>

        <span class="s4"># Perform expectation-maximization</span>
        <span class="s1">llf = []</span>
        <span class="s1">params = [start_params]</span>
        <span class="s1">i = </span><span class="s5">0</span>
        <span class="s1">delta = </span><span class="s5">0</span>
        <span class="s2">while </span><span class="s1">i &lt; maxiter </span><span class="s2">and </span><span class="s1">(i &lt; </span><span class="s5">2 </span><span class="s2">or </span><span class="s1">(delta &gt; tolerance)):</span>
            <span class="s1">out = self._em_iteration(params[-</span><span class="s5">1</span><span class="s1">])</span>
            <span class="s1">llf.append(out[</span><span class="s5">0</span><span class="s1">].llf)</span>
            <span class="s1">params.append(out[</span><span class="s5">1</span><span class="s1">])</span>
            <span class="s2">if </span><span class="s1">i &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">delta = </span><span class="s5">2 </span><span class="s1">* (llf[-</span><span class="s5">1</span><span class="s1">] - llf[-</span><span class="s5">2</span><span class="s1">]) / np.abs((llf[-</span><span class="s5">1</span><span class="s1">] + llf[-</span><span class="s5">2</span><span class="s1">]))</span>
            <span class="s1">i += </span><span class="s5">1</span>

        <span class="s4"># Just return the fitted parameters if requested</span>
        <span class="s2">if </span><span class="s1">return_params:</span>
            <span class="s1">result = params[-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s4"># Otherwise construct the results class if desired</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self.filter(params[-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True,</span>
                                 <span class="s1">cov_type=cov_type</span><span class="s2">, </span><span class="s1">cov_kwds=cov_kwds)</span>

            <span class="s4"># Save the output</span>
            <span class="s2">if </span><span class="s1">full_output:</span>
                <span class="s1">em_retvals = Bunch(**{</span><span class="s3">'params'</span><span class="s1">: np.array(params)</span><span class="s2">,</span>
                                      <span class="s3">'llf'</span><span class="s1">: np.array(llf)</span><span class="s2">,</span>
                                      <span class="s3">'iter'</span><span class="s1">: i})</span>
                <span class="s1">em_settings = Bunch(**{</span><span class="s3">'tolerance'</span><span class="s1">: tolerance</span><span class="s2">,</span>
                                       <span class="s3">'maxiter'</span><span class="s1">: maxiter})</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">em_retvals = </span><span class="s2">None</span>
                <span class="s1">em_settings = </span><span class="s2">None</span>

            <span class="s1">result.mle_retvals = em_retvals</span>
            <span class="s1">result.mle_settings = em_settings</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_em_iteration(self</span><span class="s2">, </span><span class="s1">params0):</span>
        <span class="s0">&quot;&quot;&quot; 
        EM iteration 
 
        Notes 
        ----- 
        The EM iteration in this base class only performs the EM step for 
        non-TVTP transition probabilities. 
        &quot;&quot;&quot;</span>
        <span class="s1">params1 = np.zeros(params0.shape</span><span class="s2">,</span>
                           <span class="s1">dtype=np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">params0.dtype))</span>

        <span class="s4"># Smooth at the given parameters</span>
        <span class="s1">result = self.smooth(params0</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">return_raw=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s4"># The EM with TVTP is not yet supported, just return the previous</span>
        <span class="s4"># iteration parameters</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s1">params1[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = (</span>
                <span class="s1">params0[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">regime_transition = self._em_regime_transition(result)</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">params1[self.parameters[i</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">]] = (</span>
                    <span class="s1">regime_transition[i])</span>

        <span class="s2">return </span><span class="s1">result</span><span class="s2">, </span><span class="s1">params1</span>

    <span class="s2">def </span><span class="s1">_em_regime_transition(self</span><span class="s2">, </span><span class="s1">result):</span>
        <span class="s0">&quot;&quot;&quot; 
        EM step for regime transition probabilities 
        &quot;&quot;&quot;</span>

        <span class="s4"># Marginalize the smoothed joint probabilities to just S_t, S_{t-1} | T</span>
        <span class="s1">tmp = result.smoothed_joint_probabilities</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(tmp.ndim - </span><span class="s5">3</span><span class="s1">):</span>
            <span class="s1">tmp = np.sum(tmp</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">smoothed_joint_probabilities = tmp</span>

        <span class="s4"># Transition parameters (recall we're not yet supporting TVTP here)</span>
        <span class="s1">k_transition = len(self.parameters[</span><span class="s5">0</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">])</span>
        <span class="s1">regime_transition = np.zeros((self.k_regimes</span><span class="s2">, </span><span class="s1">k_transition))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):  </span><span class="s4"># S_{t_1}</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes - </span><span class="s5">1</span><span class="s1">):  </span><span class="s4"># S_t</span>
                <span class="s1">regime_transition[i</span><span class="s2">, </span><span class="s1">j] = (</span>
                    <span class="s1">np.sum(smoothed_joint_probabilities[j</span><span class="s2">, </span><span class="s1">i]) /</span>
                    <span class="s1">np.sum(result.smoothed_marginal_probabilities[i]))</span>

            <span class="s4"># It may be the case that due to rounding error this estimates</span>
            <span class="s4"># transition probabilities that sum to greater than one. If so,</span>
            <span class="s4"># re-scale the probabilities and warn the user that something</span>
            <span class="s4"># is not quite right</span>
            <span class="s1">delta = np.sum(regime_transition[i]) - </span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">delta &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">warnings.warn(</span><span class="s3">'Invalid regime transition probabilities'</span>
                              <span class="s3">' estimated in EM iteration; probabilities have'</span>
                              <span class="s3">' been re-scaled to continue estimation.'</span><span class="s2">,</span>
                              <span class="s1">EstimationWarning)</span>
                <span class="s1">regime_transition[i] /= </span><span class="s5">1 </span><span class="s1">+ delta + </span><span class="s5">1e-6</span>

        <span class="s2">return </span><span class="s1">regime_transition</span>

    <span class="s2">def </span><span class="s1">_start_params_search(self</span><span class="s2">, </span><span class="s1">reps</span><span class="s2">, </span><span class="s1">start_params=</span><span class="s2">None, </span><span class="s1">transformed=</span><span class="s2">True,</span>
                             <span class="s1">em_iter=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">scale=</span><span class="s5">1.</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Search for starting parameters as random permutations of a vector 
 
        Parameters 
        ---------- 
        reps : int 
            Number of random permutations to try. 
        start_params : ndarray, optional 
            Starting parameter vector. If not given, class-level start 
            parameters are used. 
        transformed : bool, optional 
            If `start_params` was provided, whether or not those parameters 
            are already transformed. Default is True. 
        em_iter : int, optional 
            Number of EM iterations to apply to each random permutation. 
        scale : array or float, optional 
            Scale of variates for random start parameter search. Can be given 
            as an array of length equal to the number of parameters or as a 
            single scalar. 
 
        Notes 
        ----- 
        This is a private method for finding good starting parameters for MLE 
        by scoring, where the defaults have been set heuristically. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">start_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">start_params = self.start_params</span>
            <span class="s1">transformed = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">start_params = np.array(start_params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Random search is over untransformed space</span>
        <span class="s2">if </span><span class="s1">transformed:</span>
            <span class="s1">start_params = self.untransform_params(start_params)</span>

        <span class="s4"># Construct the standard deviations</span>
        <span class="s1">scale = np.array(scale</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">scale.size == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">scale = np.ones(self.k_params) * scale</span>
        <span class="s2">if not </span><span class="s1">scale.size == self.k_params:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Scale of variates for random start'</span>
                             <span class="s3">' parameter search must be given for each'</span>
                             <span class="s3">' parameter or as a single scalar.'</span><span class="s1">)</span>

        <span class="s4"># Construct the random variates</span>
        <span class="s1">variates = np.zeros((reps</span><span class="s2">, </span><span class="s1">self.k_params))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_params):</span>
            <span class="s1">variates[:</span><span class="s2">, </span><span class="s1">i] = scale[i] * np.random.uniform(-</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">size=reps)</span>

        <span class="s1">llf = self.loglike(start_params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">params = start_params</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(reps):</span>
            <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
                <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s1">)</span>

                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">proposed_params = self._fit_em(</span>
                        <span class="s1">start_params + variates[i]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False,</span>
                        <span class="s1">maxiter=em_iter</span><span class="s2">, </span><span class="s1">return_params=</span><span class="s2">True</span><span class="s1">)</span>
                    <span class="s1">proposed_llf = self.loglike(proposed_params)</span>

                    <span class="s2">if </span><span class="s1">proposed_llf &gt; llf:</span>
                        <span class="s1">llf = proposed_llf</span>
                        <span class="s1">params = self.untransform_params(proposed_params)</span>
                <span class="s2">except </span><span class="s1">Exception:  </span><span class="s4"># FIXME: catch something specific</span>
                    <span class="s2">pass</span>

        <span class="s4"># Return transformed parameters</span>
        <span class="s2">return </span><span class="s1">self.transform_params(params)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">start_params(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) Starting parameters for maximum likelihood estimation. 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.zeros(self.k_params</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s4"># Transition probabilities</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s1">params[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = </span><span class="s5">0.</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">params[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = </span><span class="s5">1. </span><span class="s1">/ self.k_regimes</span>

        <span class="s2">return </span><span class="s1">params</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">param_names(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (list of str) List of human readable parameter names (for parameters 
        actually included in the model). 
        &quot;&quot;&quot;</span>
        <span class="s1">param_names = np.zeros(self.k_params</span><span class="s2">, </span><span class="s1">dtype=object)</span>

        <span class="s4"># Transition probabilities</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s4"># TODO add support for exog_tvtp_names</span>
            <span class="s1">param_names[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = [</span>
                <span class="s3">'p[%d-&gt;%d].tvtp%d' </span><span class="s1">% (j</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">k)</span>
                <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes-</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(self.k_tvtp)</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes)</span>
                <span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">param_names[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = [</span>
                <span class="s3">'p[%d-&gt;%d]' </span><span class="s1">% (j</span><span class="s2">, </span><span class="s1">i)</span>
                <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes-</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes)]</span>

        <span class="s2">return </span><span class="s1">param_names.tolist()</span>

    <span class="s2">def </span><span class="s1">transform_params(self</span><span class="s2">, </span><span class="s1">unconstrained):</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform unconstrained parameters used by the optimizer to constrained 
        parameters used in likelihood evaluation 
 
        Parameters 
        ---------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer, to be 
            transformed. 
 
        Returns 
        ------- 
        constrained : array_like 
            Array of constrained parameters which may be used in likelihood 
            evaluation. 
 
        Notes 
        ----- 
        In the base class, this only transforms the transition-probability- 
        related parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">constrained = np.array(unconstrained</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">constrained = constrained.astype(</span>
            <span class="s1">np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">constrained.dtype))</span>

        <span class="s4"># Nothing to do for transition probabilities if TVTP</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s1">constrained[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = (</span>
                <span class="s1">unconstrained[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]])</span>
        <span class="s4"># Otherwise do logistic transformation</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># Transition probabilities</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">tmp1 = unconstrained[self.parameters[i</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">]]</span>
                <span class="s1">tmp2 = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">tmp1]</span>
                <span class="s1">constrained[self.parameters[i</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">]] = np.exp(</span>
                    <span class="s1">tmp1 - logsumexp(tmp2))</span>

        <span class="s4"># Do not do anything for the rest of the parameters</span>

        <span class="s2">return </span><span class="s1">constrained</span>

    <span class="s2">def </span><span class="s1">_untransform_logistic(self</span><span class="s2">, </span><span class="s1">unconstrained</span><span class="s2">, </span><span class="s1">constrained):</span>
        <span class="s0">&quot;&quot;&quot; 
        Function to allow using a numerical root-finder to reverse the 
        logistic transform. 
        &quot;&quot;&quot;</span>
        <span class="s1">resid = np.zeros(unconstrained.shape</span><span class="s2">, </span><span class="s1">dtype=unconstrained.dtype)</span>
        <span class="s1">exp = np.exp(unconstrained)</span>
        <span class="s1">sum_exp = np.sum(exp)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(unconstrained)):</span>
            <span class="s1">resid[i] = (unconstrained[i] -</span>
                        <span class="s1">np.log(</span><span class="s5">1 </span><span class="s1">+ sum_exp - exp[i]) +</span>
                        <span class="s1">np.log(</span><span class="s5">1 </span><span class="s1">/ constrained[i] - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">resid</span>

    <span class="s2">def </span><span class="s1">untransform_params(self</span><span class="s2">, </span><span class="s1">constrained):</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform constrained parameters used in likelihood evaluation 
        to unconstrained parameters used by the optimizer 
 
        Parameters 
        ---------- 
        constrained : array_like 
            Array of constrained parameters used in likelihood evaluation, to 
            be transformed. 
 
        Returns 
        ------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer. 
 
        Notes 
        ----- 
        In the base class, this only untransforms the transition-probability- 
        related parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">unconstrained = np.array(constrained</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">unconstrained = unconstrained.astype(</span>
            <span class="s1">np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">unconstrained.dtype))</span>

        <span class="s4"># Nothing to do for transition probabilities if TVTP</span>
        <span class="s2">if </span><span class="s1">self.tvtp:</span>
            <span class="s1">unconstrained[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]] = (</span>
                <span class="s1">constrained[self.parameters[</span><span class="s3">'regime_transition'</span><span class="s1">]])</span>
        <span class="s4"># Otherwise reverse logistic transformation</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">s = self.parameters[i</span><span class="s2">, </span><span class="s3">'regime_transition'</span><span class="s1">]</span>
                <span class="s2">if </span><span class="s1">self.k_regimes == </span><span class="s5">2</span><span class="s1">:</span>
                    <span class="s1">unconstrained[s] = -np.log(</span><span class="s5">1. </span><span class="s1">/ constrained[s] - </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">root</span>
                    <span class="s1">out = root(self._untransform_logistic</span><span class="s2">,</span>
                               <span class="s1">np.zeros(unconstrained[s].shape</span><span class="s2">,</span>
                                        <span class="s1">unconstrained.dtype)</span><span class="s2">,</span>
                               <span class="s1">args=(constrained[s]</span><span class="s2">,</span><span class="s1">))</span>
                    <span class="s2">if not </span><span class="s1">out[</span><span class="s3">'success'</span><span class="s1">]:</span>
                        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Could not untransform parameters.'</span><span class="s1">)</span>
                    <span class="s1">unconstrained[s] = out[</span><span class="s3">'x'</span><span class="s1">]</span>

        <span class="s4"># Do not do anything for the rest of the parameters</span>

        <span class="s2">return </span><span class="s1">unconstrained</span>


<span class="s2">class </span><span class="s1">HamiltonFilterResults:</span>
    <span class="s0">&quot;&quot;&quot; 
    Results from applying the Hamilton filter to a state space model. 
 
    Parameters 
    ---------- 
    model : Representation 
        A Statespace representation 
 
    Attributes 
    ---------- 
    nobs : int 
        Number of observations. 
    k_endog : int 
        The dimension of the observation series. 
    k_regimes : int 
        The number of unobserved regimes. 
    regime_transition : ndarray 
        The regime transition matrix. 
    initialization : str 
        Initialization method for regime probabilities. 
    initial_probabilities : ndarray 
        Initial regime probabilities 
    conditional_loglikelihoods : ndarray 
        The loglikelihood values at each time period, conditional on regime. 
    predicted_joint_probabilities : ndarray 
        Predicted joint probabilities at each time period. 
    filtered_marginal_probabilities : ndarray 
        Filtered marginal probabilities at each time period. 
    filtered_joint_probabilities : ndarray 
        Filtered joint probabilities at each time period. 
    joint_loglikelihoods : ndarray 
        The likelihood values at each time period. 
    llf_obs : ndarray 
        The loglikelihood values at each time period. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">result):</span>

        <span class="s1">self.model = model</span>

        <span class="s1">self.nobs = model.nobs</span>
        <span class="s1">self.order = model.order</span>
        <span class="s1">self.k_regimes = model.k_regimes</span>

        <span class="s1">attributes = [</span><span class="s3">'regime_transition'</span><span class="s2">, </span><span class="s3">'initial_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'conditional_loglikelihoods'</span><span class="s2">,</span>
                      <span class="s3">'predicted_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'filtered_marginal_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'filtered_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'joint_loglikelihoods'</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">attributes:</span>
            <span class="s1">setattr(self</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">getattr(result</span><span class="s2">, </span><span class="s1">name))</span>

        <span class="s1">self.initialization = model._initialization</span>
        <span class="s1">self.llf_obs = self.joint_loglikelihoods</span>
        <span class="s1">self.llf = np.sum(self.llf_obs)</span>

        <span class="s4"># Subset transition if necessary (e.g. for Markov autoregression)</span>
        <span class="s2">if </span><span class="s1">self.regime_transition.shape[-</span><span class="s5">1</span><span class="s1">] &gt; </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">self.regime_transition = self.regime_transition[...</span><span class="s2">, </span><span class="s1">self.order:]</span>

        <span class="s4"># Cache for predicted marginal probabilities</span>
        <span class="s1">self._predicted_marginal_probabilities = </span><span class="s2">None</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">predicted_marginal_probabilities(self):</span>
        <span class="s2">if </span><span class="s1">self._predicted_marginal_probabilities </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._predicted_marginal_probabilities = (</span>
                <span class="s1">self.predicted_joint_probabilities)</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self._predicted_marginal_probabilities.ndim - </span><span class="s5">2</span><span class="s1">):</span>
                <span class="s1">self._predicted_marginal_probabilities = np.sum(</span>
                    <span class="s1">self._predicted_marginal_probabilities</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._predicted_marginal_probabilities</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">expected_durations(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) Expected duration of a regime, possibly time-varying. 
        &quot;&quot;&quot;</span>
        <span class="s4"># It is possible that we will have a degenerate system, so that there</span>
        <span class="s4"># is no possibility of transitioning to a different state. In that</span>
        <span class="s4"># case, we do want the expected duration of one state to be np.inf,</span>
        <span class="s4"># and the expected duration of the other states to be np.nan</span>
        <span class="s1">diag = np.diagonal(self.regime_transition)</span>
        <span class="s1">expected_durations = np.zeros_like(diag)</span>
        <span class="s1">degenerate = np.any(diag == </span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># For non-degenerate states, use the usual computation</span>
        <span class="s1">expected_durations[~degenerate] = </span><span class="s5">1 </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">- diag[~degenerate])</span>

        <span class="s4"># For degenerate states, everything is np.nan, except for the one</span>
        <span class="s4"># state that is np.inf.</span>
        <span class="s1">expected_durations[degenerate] = np.nan</span>
        <span class="s1">expected_durations[diag == </span><span class="s5">1</span><span class="s1">] = np.inf</span>

        <span class="s2">return </span><span class="s1">expected_durations.squeeze()</span>


<span class="s2">class </span><span class="s1">KimSmootherResults(HamiltonFilterResults):</span>
    <span class="s0">&quot;&quot;&quot; 
    Results from applying the Kim smoother to a Markov switching model. 
 
    Parameters 
    ---------- 
    model : MarkovSwitchingModel 
        The model object. 
    result : dict 
        A dictionary containing two keys: 'smoothd_joint_probabilities' and 
        'smoothed_marginal_probabilities'. 
 
    Attributes 
    ---------- 
    nobs : int 
        Number of observations. 
    k_endog : int 
        The dimension of the observation series. 
    k_states : int 
        The dimension of the unobserved state process. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">result):</span>
        <span class="s1">super(KimSmootherResults</span><span class="s2">, </span><span class="s1">self).__init__(model</span><span class="s2">, </span><span class="s1">result)</span>

        <span class="s1">attributes = [</span><span class="s3">'smoothed_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'smoothed_marginal_probabilities'</span><span class="s1">]</span>

        <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">attributes:</span>
            <span class="s1">setattr(self</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">getattr(result</span><span class="s2">, </span><span class="s1">name))</span>


<span class="s2">class </span><span class="s1">MarkovSwitchingResults(tsbase.TimeSeriesModelResults):</span>
    <span class="s0">r&quot;&quot;&quot; 
    Class to hold results from fitting a Markov switching model 
 
    Parameters 
    ---------- 
    model : MarkovSwitching instance 
        The fitted model instance 
    params : ndarray 
        Fitted parameters 
    filter_results : HamiltonFilterResults or KimSmootherResults instance 
        The underlying filter and, optionally, smoother output 
    cov_type : str 
        The type of covariance matrix estimator to use. Can be one of 'approx', 
        'opg', 'robust', or 'none'. 
 
    Attributes 
    ---------- 
    model : Model instance 
        A reference to the model that was fit. 
    filter_results : HamiltonFilterResults or KimSmootherResults instance 
        The underlying filter and, optionally, smoother output 
    nobs : float 
        The number of observations used to fit the model. 
    params : ndarray 
        The parameters of the model. 
    scale : float 
        This is currently set to 1.0 and not used by the model or its results. 
    &quot;&quot;&quot;</span>
    <span class="s1">use_t = </span><span class="s2">False</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">results</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s3">'opg'</span><span class="s2">, </span><span class="s1">cov_kwds=</span><span class="s2">None,</span>
                 <span class="s1">**kwargs):</span>
        <span class="s1">self.data = model.data</span>

        <span class="s1">tsbase.TimeSeriesModelResults.__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">,</span>
                                               <span class="s1">normalized_cov_params=</span><span class="s2">None,</span>
                                               <span class="s1">scale=</span><span class="s5">1.</span><span class="s1">)</span>

        <span class="s4"># Save the filter / smoother output</span>
        <span class="s1">self.filter_results = results</span>
        <span class="s2">if </span><span class="s1">isinstance(results</span><span class="s2">, </span><span class="s1">KimSmootherResults):</span>
            <span class="s1">self.smoother_results = results</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.smoother_results = </span><span class="s2">None</span>

        <span class="s4"># Dimensions</span>
        <span class="s1">self.nobs = model.nobs</span>
        <span class="s1">self.order = model.order</span>
        <span class="s1">self.k_regimes = model.k_regimes</span>

        <span class="s4"># Setup covariance matrix notes dictionary</span>
        <span class="s2">if not </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'cov_kwds'</span><span class="s1">):</span>
            <span class="s1">self.cov_kwds = {}</span>
        <span class="s1">self.cov_type = cov_type</span>

        <span class="s4"># Setup the cache</span>
        <span class="s1">self._cache = {}</span>

        <span class="s4"># Handle covariance matrix calculation</span>
        <span class="s2">if </span><span class="s1">cov_kwds </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov_kwds = {}</span>
        <span class="s1">self._cov_approx_complex_step = (</span>
            <span class="s1">cov_kwds.pop(</span><span class="s3">'approx_complex_step'</span><span class="s2">, True</span><span class="s1">))</span>
        <span class="s1">self._cov_approx_centered = cov_kwds.pop(</span><span class="s3">'approx_centered'</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">self._rank = </span><span class="s2">None</span>
            <span class="s1">self._get_robustcov_results(cov_type=cov_type</span><span class="s2">, </span><span class="s1">use_self=</span><span class="s2">True,</span>
                                        <span class="s1">**cov_kwds)</span>
        <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
            <span class="s1">self._rank = </span><span class="s5">0</span>
            <span class="s1">k_params = len(self.params)</span>
            <span class="s1">self.cov_params_default = np.zeros((k_params</span><span class="s2">, </span><span class="s1">k_params)) * np.nan</span>
            <span class="s1">self.cov_kwds[</span><span class="s3">'cov_type'</span><span class="s1">] = (</span>
                <span class="s3">'Covariance matrix could not be calculated: singular.'</span>
                <span class="s3">' information matrix.'</span><span class="s1">)</span>

        <span class="s4"># Copy over arrays</span>
        <span class="s1">attributes = [</span><span class="s3">'regime_transition'</span><span class="s2">, </span><span class="s3">'initial_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'conditional_loglikelihoods'</span><span class="s2">,</span>
                      <span class="s3">'predicted_marginal_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'predicted_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'filtered_marginal_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'filtered_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'joint_loglikelihoods'</span><span class="s2">, </span><span class="s3">'expected_durations'</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">attributes:</span>
            <span class="s1">setattr(self</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">getattr(self.filter_results</span><span class="s2">, </span><span class="s1">name))</span>

        <span class="s1">attributes = [</span><span class="s3">'smoothed_joint_probabilities'</span><span class="s2">,</span>
                      <span class="s3">'smoothed_marginal_probabilities'</span><span class="s1">]</span>
        <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">attributes:</span>
            <span class="s2">if </span><span class="s1">self.smoother_results </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">setattr(self</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">getattr(self.smoother_results</span><span class="s2">, </span><span class="s1">name))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">setattr(self</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s4"># Reshape some arrays to long-format</span>
        <span class="s1">self.predicted_marginal_probabilities = (</span>
            <span class="s1">self.predicted_marginal_probabilities.T)</span>
        <span class="s1">self.filtered_marginal_probabilities = (</span>
            <span class="s1">self.filtered_marginal_probabilities.T)</span>
        <span class="s2">if </span><span class="s1">self.smoother_results </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.smoothed_marginal_probabilities = (</span>
                <span class="s1">self.smoothed_marginal_probabilities.T)</span>

        <span class="s4"># Make into Pandas arrays if using Pandas data</span>
        <span class="s2">if </span><span class="s1">isinstance(self.data</span><span class="s2">, </span><span class="s1">PandasData):</span>
            <span class="s1">index = self.data.row_labels</span>
            <span class="s2">if </span><span class="s1">self.expected_durations.ndim &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">self.expected_durations = pd.DataFrame(</span>
                    <span class="s1">self.expected_durations</span><span class="s2">, </span><span class="s1">index=index)</span>
            <span class="s1">self.predicted_marginal_probabilities = pd.DataFrame(</span>
                <span class="s1">self.predicted_marginal_probabilities</span><span class="s2">, </span><span class="s1">index=index)</span>
            <span class="s1">self.filtered_marginal_probabilities = pd.DataFrame(</span>
                <span class="s1">self.filtered_marginal_probabilities</span><span class="s2">, </span><span class="s1">index=index)</span>
            <span class="s2">if </span><span class="s1">self.smoother_results </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">self.smoothed_marginal_probabilities = pd.DataFrame(</span>
                    <span class="s1">self.smoothed_marginal_probabilities</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s2">def </span><span class="s1">_get_robustcov_results(self</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s3">'opg'</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">from </span><span class="s1">statsmodels.base.covtype </span><span class="s2">import </span><span class="s1">descriptions</span>

        <span class="s1">use_self = kwargs.pop(</span><span class="s3">'use_self'</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">use_self:</span>
            <span class="s1">res = self</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError</span>
            <span class="s1">res = self.__class__(</span>
                <span class="s1">self.model</span><span class="s2">, </span><span class="s1">self.params</span><span class="s2">,</span>
                <span class="s1">normalized_cov_params=self.normalized_cov_params</span><span class="s2">,</span>
                <span class="s1">scale=self.scale)</span>

        <span class="s4"># Set the new covariance type</span>
        <span class="s1">res.cov_type = cov_type</span>
        <span class="s1">res.cov_kwds = {}</span>

        <span class="s1">approx_type_str = </span><span class="s3">'complex-step'</span>

        <span class="s4"># Calculate the new covariance matrix</span>
        <span class="s1">k_params = len(self.params)</span>
        <span class="s2">if </span><span class="s1">k_params == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">res.cov_params_default = np.zeros((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
            <span class="s1">res._rank = </span><span class="s5">0</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = </span><span class="s3">'No parameters estimated.'</span>
        <span class="s2">elif </span><span class="s1">cov_type == </span><span class="s3">'custom'</span><span class="s1">:</span>
            <span class="s1">res.cov_type = kwargs[</span><span class="s3">'custom_cov_type'</span><span class="s1">]</span>
            <span class="s1">res.cov_params_default = kwargs[</span><span class="s3">'custom_cov_params'</span><span class="s1">]</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = kwargs[</span><span class="s3">'custom_description'</span><span class="s1">]</span>
            <span class="s1">res._rank = np.linalg.matrix_rank(res.cov_params_default)</span>
        <span class="s2">elif </span><span class="s1">cov_type == </span><span class="s3">'none'</span><span class="s1">:</span>
            <span class="s1">res.cov_params_default = np.zeros((k_params</span><span class="s2">, </span><span class="s1">k_params)) * np.nan</span>
            <span class="s1">res._rank = np.nan</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = descriptions[</span><span class="s3">'none'</span><span class="s1">]</span>
        <span class="s2">elif </span><span class="s1">self.cov_type == </span><span class="s3">'approx'</span><span class="s1">:</span>
            <span class="s1">res.cov_params_default = res.cov_params_approx</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = descriptions[</span><span class="s3">'approx'</span><span class="s1">].format(</span>
                                                <span class="s1">approx_type=approx_type_str)</span>
        <span class="s2">elif </span><span class="s1">self.cov_type == </span><span class="s3">'opg'</span><span class="s1">:</span>
            <span class="s1">res.cov_params_default = res.cov_params_opg</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = descriptions[</span><span class="s3">'OPG'</span><span class="s1">].format(</span>
                                                <span class="s1">approx_type=approx_type_str)</span>
        <span class="s2">elif </span><span class="s1">self.cov_type == </span><span class="s3">'robust'</span><span class="s1">:</span>
            <span class="s1">res.cov_params_default = res.cov_params_robust</span>
            <span class="s1">res.cov_kwds[</span><span class="s3">'description'</span><span class="s1">] = descriptions[</span><span class="s3">'robust'</span><span class="s1">].format(</span>
                                                <span class="s1">approx_type=approx_type_str)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">'Invalid covariance matrix type.'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">res</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">aic(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (float) Akaike Information Criterion 
        &quot;&quot;&quot;</span>
        <span class="s4"># return -2*self.llf + 2*self.params.shape[0]</span>
        <span class="s2">return </span><span class="s1">aic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.params.shape[</span><span class="s5">0</span><span class="s1">])</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bic(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (float) Bayes Information Criterion 
        &quot;&quot;&quot;</span>
        <span class="s4"># return -2*self.llf + self.params.shape[0]*np.log(self.nobs)</span>
        <span class="s2">return </span><span class="s1">bic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.params.shape[</span><span class="s5">0</span><span class="s1">])</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cov_params_approx(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) The variance / covariance matrix. Computed using the numerical 
        Hessian approximated by complex step or finite differences methods. 
        &quot;&quot;&quot;</span>
        <span class="s1">evaluated_hessian = self.model.hessian(self.params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">neg_cov</span><span class="s2">, </span><span class="s1">singular_values = pinv_extended(evaluated_hessian)</span>

        <span class="s2">if </span><span class="s1">self._rank </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._rank = np.linalg.matrix_rank(np.diag(singular_values))</span>

        <span class="s2">return </span><span class="s1">-neg_cov</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cov_params_opg(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) The variance / covariance matrix. Computed using the outer 
        product of gradients method. 
        &quot;&quot;&quot;</span>
        <span class="s1">score_obs = self.model.score_obs(self.params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">).T</span>
        <span class="s1">cov_params</span><span class="s2">, </span><span class="s1">singular_values = pinv_extended(</span>
            <span class="s1">np.inner(score_obs</span><span class="s2">, </span><span class="s1">score_obs))</span>

        <span class="s2">if </span><span class="s1">self._rank </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._rank = np.linalg.matrix_rank(np.diag(singular_values))</span>

        <span class="s2">return </span><span class="s1">cov_params</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cov_params_robust(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) The QMLE variance / covariance matrix. Computed using the 
        numerical Hessian as the evaluated hessian. 
        &quot;&quot;&quot;</span>
        <span class="s1">cov_opg = self.cov_params_opg</span>
        <span class="s1">evaluated_hessian = self.model.hessian(self.params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">cov_params</span><span class="s2">, </span><span class="s1">singular_values = pinv_extended(</span>
            <span class="s1">np.dot(np.dot(evaluated_hessian</span><span class="s2">, </span><span class="s1">cov_opg)</span><span class="s2">, </span><span class="s1">evaluated_hessian)</span>
        <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self._rank </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._rank = np.linalg.matrix_rank(np.diag(singular_values))</span>

        <span class="s2">return </span><span class="s1">cov_params</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">fittedvalues(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) The predicted values of the model. An (nobs x k_endog) array. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.predict(self.params)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">hqic(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (float) Hannan-Quinn Information Criterion 
        &quot;&quot;&quot;</span>
        <span class="s4"># return -2*self.llf + 2*np.log(np.log(self.nobs))*self.params.shape[0]</span>
        <span class="s2">return </span><span class="s1">hqic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.params.shape[</span><span class="s5">0</span><span class="s1">])</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">llf_obs(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (float) The value of the log-likelihood function evaluated at `params`. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.loglikeobs(self.params)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">llf(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (float) The value of the log-likelihood function evaluated at `params`. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.loglike(self.params)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) The model residuals. An (nobs x k_endog) array. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.endog - self.fittedvalues</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">joint_likelihoods(self):</span>
        <span class="s2">return </span><span class="s1">np.exp(self.joint_loglikelihoods)</span>

    <span class="s2">def </span><span class="s1">predict(self</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">end=</span><span class="s2">None, </span><span class="s1">probabilities=</span><span class="s2">None,</span>
                <span class="s1">conditional=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        In-sample prediction and out-of-sample forecasting 
 
        Parameters 
        ---------- 
        start : int, str, or datetime, optional 
            Zero-indexed observation number at which to start forecasting, 
            i.e., the first forecast is start. Can also be a date string to 
            parse or a datetime type. Default is the the zeroth observation. 
        end : int, str, or datetime, optional 
            Zero-indexed observation number at which to end forecasting, i.e., 
            the last forecast is end. Can also be a date string to 
            parse or a datetime type. However, if the dates index does not 
            have a fixed frequency, end must be an integer index if you 
            want out of sample prediction. Default is the last observation in 
            the sample. 
        probabilities : str or array_like, optional 
            Specifies the weighting probabilities used in constructing the 
            prediction as a weighted average. If a string, can be 'predicted', 
            'filtered', or 'smoothed'. Otherwise can be an array of 
            probabilities to use. Default is smoothed. 
        conditional : bool or int, optional 
            Whether or not to return predictions conditional on current or 
            past regimes. If False, returns a single vector of weighted 
            predictions. If True or 1, returns predictions conditional on the 
            current regime. For larger integers, returns predictions 
            conditional on the current regime and some number of past regimes. 
 
        Returns 
        ------- 
        predict : ndarray 
            Array of out of in-sample predictions and / or out-of-sample 
            forecasts. An (npredict x k_endog) array. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.predict(self.params</span><span class="s2">, </span><span class="s1">start=start</span><span class="s2">, </span><span class="s1">end=end</span><span class="s2">,</span>
                                  <span class="s1">probabilities=probabilities</span><span class="s2">,</span>
                                  <span class="s1">conditional=conditional)</span>

    <span class="s2">def </span><span class="s1">forecast(self</span><span class="s2">, </span><span class="s1">steps=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Out-of-sample forecasts 
 
        Parameters 
        ---------- 
        steps : int, str, or datetime, optional 
            If an integer, the number of steps to forecast from the end of the 
            sample. Can also be a date string to parse or a datetime type. 
            However, if the dates index does not have a fixed frequency, steps 
            must be an integer. Default 
        **kwargs 
            Additional arguments may required for forecasting beyond the end 
            of the sample. See `FilterResults.predict` for more details. 
 
        Returns 
        ------- 
        forecast : ndarray 
            Array of out of sample forecasts. A (steps x k_endog) array. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">.05</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">title=</span><span class="s2">None, </span><span class="s1">model_name=</span><span class="s2">None,</span>
                <span class="s1">display_params=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Summarize the Model 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            Significance level for the confidence intervals. Default is 0.05. 
        start : int, optional 
            Integer of the start observation. Default is 0. 
        title : str, optional 
            The title of the summary table. 
        model_name : str 
            The name of the model used. Default is to use model class name. 
        display_params : bool, optional 
            Whether or not to display tables of estimated parameters. Default 
            is True. Usually only used internally. 
 
        Returns 
        ------- 
        summary : Summary instance 
            This holds the summary table and text, which can be printed or 
            converted to various output formats. 
 
        See Also 
        -------- 
        statsmodels.iolib.summary.Summary 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">Summary</span>

        <span class="s4"># Model specification results</span>
        <span class="s1">model = self.model</span>
        <span class="s2">if </span><span class="s1">title </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">title = </span><span class="s3">'Markov Switching Model Results'</span>

        <span class="s2">if </span><span class="s1">start </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">start = </span><span class="s5">0</span>
        <span class="s2">if </span><span class="s1">self.data.dates </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">dates = self.data.dates</span>
            <span class="s1">d = dates[start]</span>
            <span class="s1">sample = [</span><span class="s3">'%02d-%02d-%02d' </span><span class="s1">% (d.month</span><span class="s2">, </span><span class="s1">d.day</span><span class="s2">, </span><span class="s1">d.year)]</span>
            <span class="s1">d = dates[-</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">sample += [</span><span class="s3">'- ' </span><span class="s1">+ </span><span class="s3">'%02d-%02d-%02d' </span><span class="s1">% (d.month</span><span class="s2">, </span><span class="s1">d.day</span><span class="s2">, </span><span class="s1">d.year)]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sample = [str(start)</span><span class="s2">, </span><span class="s3">' - ' </span><span class="s1">+ str(self.model.nobs)]</span>

        <span class="s4"># Standardize the model name as a list of str</span>
        <span class="s2">if </span><span class="s1">model_name </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">model_name = model.__class__.__name__</span>

        <span class="s4"># Create the tables</span>
        <span class="s2">if not </span><span class="s1">isinstance(model_name</span><span class="s2">, </span><span class="s1">list):</span>
            <span class="s1">model_name = [model_name]</span>

        <span class="s1">top_left = [(</span><span class="s3">'Dep. Variable:'</span><span class="s2">, None</span><span class="s1">)]</span>
        <span class="s1">top_left.append((</span><span class="s3">'Model:'</span><span class="s2">, </span><span class="s1">[model_name[</span><span class="s5">0</span><span class="s1">]]))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">len(model_name)):</span>
            <span class="s1">top_left.append((</span><span class="s3">''</span><span class="s2">, </span><span class="s1">[</span><span class="s3">'+ ' </span><span class="s1">+ model_name[i]]))</span>
        <span class="s1">top_left += [</span>
            <span class="s1">(</span><span class="s3">'Date:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'Time:'</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'Sample:'</span><span class="s2">, </span><span class="s1">[sample[</span><span class="s5">0</span><span class="s1">]])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">''</span><span class="s2">, </span><span class="s1">[sample[</span><span class="s5">1</span><span class="s1">]])</span>
        <span class="s1">]</span>

        <span class="s1">top_right = [</span>
            <span class="s1">(</span><span class="s3">'No. Observations:'</span><span class="s2">, </span><span class="s1">[self.model.nobs])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'Log Likelihood'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.llf])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'AIC'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.aic])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'BIC'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.bic])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">'HQIC'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.hqic])</span>
        <span class="s1">]</span>

        <span class="s2">if </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'cov_type'</span><span class="s1">):</span>
            <span class="s1">top_left.append((</span><span class="s3">'Covariance Type:'</span><span class="s2">, </span><span class="s1">[self.cov_type]))</span>

        <span class="s1">summary = Summary()</span>
        <span class="s1">summary.add_table_2cols(self</span><span class="s2">, </span><span class="s1">gleft=top_left</span><span class="s2">, </span><span class="s1">gright=top_right</span><span class="s2">,</span>
                                <span class="s1">title=title)</span>

        <span class="s4"># Make parameters tables for each regime</span>
        <span class="s2">import </span><span class="s1">re</span>

        <span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">summary_params</span>

        <span class="s2">def </span><span class="s1">make_table(self</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">title</span><span class="s2">, </span><span class="s1">strip_end=</span><span class="s2">True</span><span class="s1">):</span>
            <span class="s1">res = (self</span><span class="s2">, </span><span class="s1">self.params[mask]</span><span class="s2">, </span><span class="s1">self.bse[mask]</span><span class="s2">,</span>
                   <span class="s1">self.tvalues[mask]</span><span class="s2">, </span><span class="s1">self.pvalues[mask]</span><span class="s2">,</span>
                   <span class="s1">self.conf_int(alpha)[mask])</span>

            <span class="s1">param_names = [</span>
                <span class="s1">re.sub(</span><span class="s3">r'\[\d+\]$'</span><span class="s2">, </span><span class="s3">''</span><span class="s2">, </span><span class="s1">name) </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in</span>
                <span class="s1">np.array(self.data.param_names)[mask].tolist()</span>
            <span class="s1">]</span>

            <span class="s2">return </span><span class="s1">summary_params(res</span><span class="s2">, </span><span class="s1">yname=</span><span class="s2">None, </span><span class="s1">xname=param_names</span><span class="s2">,</span>
                                  <span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False, </span><span class="s1">title=title)</span>

        <span class="s1">params = model.parameters</span>
        <span class="s1">regime_masks = [[] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(model.k_regimes)]</span>
        <span class="s1">other_masks = {}</span>
        <span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">switching </span><span class="s2">in </span><span class="s1">params.switching.items():</span>
            <span class="s1">k_params = len(switching)</span>
            <span class="s2">if </span><span class="s1">key == </span><span class="s3">'regime_transition'</span><span class="s1">:</span>
                <span class="s2">continue</span>
            <span class="s1">other_masks[key] = []</span>

            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(k_params):</span>
                <span class="s2">if </span><span class="s1">switching[i]:</span>
                    <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                        <span class="s1">regime_masks[j].append(params[j</span><span class="s2">, </span><span class="s1">key][i])</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">other_masks[key].append(params[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">key][i])</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">mask = regime_masks[i]</span>
            <span class="s2">if </span><span class="s1">len(mask) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">table = make_table(self</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s3">'Regime %d parameters' </span><span class="s1">% i)</span>
                <span class="s1">summary.tables.append(table)</span>

        <span class="s1">mask = []</span>
        <span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">_mask </span><span class="s2">in </span><span class="s1">other_masks.items():</span>
            <span class="s1">mask.extend(_mask)</span>
        <span class="s2">if </span><span class="s1">len(mask) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">table = make_table(self</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s3">'Non-switching parameters'</span><span class="s1">)</span>
            <span class="s1">summary.tables.append(table)</span>

        <span class="s4"># Transition parameters</span>
        <span class="s1">mask = params[</span><span class="s3">'regime_transition'</span><span class="s1">]</span>
        <span class="s1">table = make_table(self</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s3">'Regime transition parameters'</span><span class="s1">)</span>
        <span class="s1">summary.tables.append(table)</span>

        <span class="s4"># Add warnings/notes, added to text format only</span>
        <span class="s1">etext = []</span>
        <span class="s2">if </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'cov_type'</span><span class="s1">) </span><span class="s2">and </span><span class="s3">'description' </span><span class="s2">in </span><span class="s1">self.cov_kwds:</span>
            <span class="s1">etext.append(self.cov_kwds[</span><span class="s3">'description'</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">self._rank &lt; len(self.params):</span>
            <span class="s1">etext.append(</span><span class="s3">&quot;Covariance matrix is singular or near-singular,&quot;</span>
                         <span class="s3">&quot; with condition number %6.3g. Standard errors may be&quot;</span>
                         <span class="s3">&quot; unstable.&quot; </span><span class="s1">% _safe_cond(self.cov_params()))</span>

        <span class="s2">if </span><span class="s1">etext:</span>
            <span class="s1">etext = [</span><span class="s3">&quot;[{0}] {1}&quot;</span><span class="s1">.format(i + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">text)</span>
                     <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">text </span><span class="s2">in </span><span class="s1">enumerate(etext)]</span>
            <span class="s1">etext.insert(</span><span class="s5">0</span><span class="s2">, </span><span class="s3">&quot;Warnings:&quot;</span><span class="s1">)</span>
            <span class="s1">summary.add_extra_txt(etext)</span>

        <span class="s2">return </span><span class="s1">summary</span>


<span class="s2">class </span><span class="s1">MarkovSwitchingResultsWrapper(wrap.ResultsWrapper):</span>
    <span class="s1">_attrs = {</span>
        <span class="s3">'cov_params_approx'</span><span class="s1">: </span><span class="s3">'cov'</span><span class="s2">,</span>
        <span class="s3">'cov_params_default'</span><span class="s1">: </span><span class="s3">'cov'</span><span class="s2">,</span>
        <span class="s3">'cov_params_opg'</span><span class="s1">: </span><span class="s3">'cov'</span><span class="s2">,</span>
        <span class="s3">'cov_params_robust'</span><span class="s1">: </span><span class="s3">'cov'</span><span class="s2">,</span>
    <span class="s1">}</span>
    <span class="s1">_wrap_attrs = wrap.union_dicts(tsbase.TimeSeriesResultsWrapper._wrap_attrs</span><span class="s2">,</span>
                                   <span class="s1">_attrs)</span>
    <span class="s1">_methods = {</span>
        <span class="s3">'forecast'</span><span class="s1">: </span><span class="s3">'dates'</span><span class="s2">,</span>
    <span class="s1">}</span>
    <span class="s1">_wrap_methods = wrap.union_dicts(</span>
        <span class="s1">tsbase.TimeSeriesResultsWrapper._wrap_methods</span><span class="s2">, </span><span class="s1">_methods)</span>
<span class="s1">wrap.populate_wrapper(MarkovSwitchingResultsWrapper</span><span class="s2">,  </span><span class="s4"># noqa:E305</span>
                      <span class="s1">MarkovSwitchingResults)</span>
</pre>
</body>
</html>
<html>
<head>
<title>_nearest_centroid.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_nearest_centroid.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Nearest Centroid Classification 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Robert Layton &lt;robertlayton@gmail.com&gt;</span>
<span class="s2">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="s2">#</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">sparse </span><span class="s3">as </span><span class="s1">sp</span>

<span class="s3">from </span><span class="s1">sklearn.metrics.pairwise </span><span class="s3">import </span><span class="s1">_VALID_METRICS</span>

<span class="s3">from </span><span class="s1">..base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">ClassifierMixin</span><span class="s3">, </span><span class="s1">_fit_context</span>
<span class="s3">from </span><span class="s1">..metrics.pairwise </span><span class="s3">import </span><span class="s1">pairwise_distances_argmin</span>
<span class="s3">from </span><span class="s1">..preprocessing </span><span class="s3">import </span><span class="s1">LabelEncoder</span>
<span class="s3">from </span><span class="s1">..utils._param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s1">..utils.multiclass </span><span class="s3">import </span><span class="s1">check_classification_targets</span>
<span class="s3">from </span><span class="s1">..utils.sparsefuncs </span><span class="s3">import </span><span class="s1">csc_median_axis_0</span>
<span class="s3">from </span><span class="s1">..utils.validation </span><span class="s3">import </span><span class="s1">check_is_fitted</span>


<span class="s3">class </span><span class="s1">NearestCentroid(ClassifierMixin</span><span class="s3">, </span><span class="s1">BaseEstimator):</span>
    <span class="s0">&quot;&quot;&quot;Nearest centroid classifier. 
 
    Each class is represented by its centroid, with test samples classified to 
    the class with the nearest centroid. 
 
    Read more in the :ref:`User Guide &lt;nearest_centroid_classifier&gt;`. 
 
    Parameters 
    ---------- 
    metric : str or callable, default=&quot;euclidean&quot; 
        Metric to use for distance computation. See the documentation of 
        `scipy.spatial.distance 
        &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and 
        the metrics listed in 
        :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric 
        values. Note that &quot;wminkowski&quot;, &quot;seuclidean&quot; and &quot;mahalanobis&quot; are not 
        supported. 
 
        The centroids for the samples corresponding to each class is 
        the point from which the sum of the distances (according to the metric) 
        of all samples that belong to that particular class are minimized. 
        If the `&quot;manhattan&quot;` metric is provided, this centroid is the median 
        and for all other metrics, the centroid is now set to be the mean. 
 
        .. deprecated:: 1.3 
            Support for metrics other than `euclidean` and `manhattan` and for 
            callables was deprecated in version 1.3 and will be removed in 
            version 1.5. 
 
        .. versionchanged:: 0.19 
            `metric='precomputed'` was deprecated and now raises an error 
 
    shrink_threshold : float, default=None 
        Threshold for shrinking centroids to remove features. 
 
    Attributes 
    ---------- 
    centroids_ : array-like of shape (n_classes, n_features) 
        Centroid of each class. 
 
    classes_ : array of shape (n_classes,) 
        The unique classes labels. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    KNeighborsClassifier : Nearest neighbors classifier. 
 
    Notes 
    ----- 
    When used for text classification with tf-idf vectors, this classifier is 
    also known as the Rocchio classifier. 
 
    References 
    ---------- 
    Tibshirani, R., Hastie, T., Narasimhan, B., &amp; Chu, G. (2002). Diagnosis of 
    multiple cancer types by shrunken centroids of gene expression. Proceedings 
    of the National Academy of Sciences of the United States of America, 
    99(10), 6567-6572. The National Academy of Sciences. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.neighbors import NearestCentroid 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]]) 
    &gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2]) 
    &gt;&gt;&gt; clf = NearestCentroid() 
    &gt;&gt;&gt; clf.fit(X, y) 
    NearestCentroid() 
    &gt;&gt;&gt; print(clf.predict([[-0.8, -1]])) 
    [1] 
    &quot;&quot;&quot;</span>

    <span class="s1">_valid_metrics = set(_VALID_METRICS) - {</span><span class="s4">&quot;mahalanobis&quot;</span><span class="s3">, </span><span class="s4">&quot;seuclidean&quot;</span><span class="s3">, </span><span class="s4">&quot;wminkowski&quot;</span><span class="s1">}</span>

    <span class="s1">_parameter_constraints: dict = {</span>
        <span class="s4">&quot;metric&quot;</span><span class="s1">: [</span>
            <span class="s1">StrOptions(</span>
                <span class="s1">_valid_metrics</span><span class="s3">, </span><span class="s1">deprecated=_valid_metrics - {</span><span class="s4">&quot;manhattan&quot;</span><span class="s3">, </span><span class="s4">&quot;euclidean&quot;</span><span class="s1">}</span>
            <span class="s1">)</span><span class="s3">,</span>
            <span class="s1">callable</span><span class="s3">,</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;shrink_threshold&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s4">&quot;neither&quot;</span><span class="s1">)</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">}</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">metric=</span><span class="s4">&quot;euclidean&quot;</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shrink_threshold=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.metric = metric</span>
        <span class="s1">self.shrink_threshold = shrink_threshold</span>

    <span class="s1">@_fit_context(prefer_skip_nested_validation=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit the NearestCentroid model according to the given training data. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples and 
            `n_features` is the number of features. 
            Note that centroid shrinking cannot be used with sparse matrices. 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">isinstance(self.metric</span><span class="s3">, </span><span class="s1">str) </span><span class="s3">and </span><span class="s1">self.metric </span><span class="s3">not in </span><span class="s1">(</span>
            <span class="s4">&quot;manhattan&quot;</span><span class="s3">,</span>
            <span class="s4">&quot;euclidean&quot;</span><span class="s3">,</span>
        <span class="s1">):</span>
            <span class="s1">warnings.warn(</span>
                <span class="s1">(</span>
                    <span class="s4">&quot;Support for distance metrics other than euclidean and &quot;</span>
                    <span class="s4">&quot;manhattan and for callables was deprecated in version &quot;</span>
                    <span class="s4">&quot;1.3 and will be removed in version 1.5.&quot;</span>
                <span class="s1">)</span><span class="s3">,</span>
                <span class="s1">FutureWarning</span><span class="s3">,</span>
            <span class="s1">)</span>

        <span class="s2"># If X is sparse and the metric is &quot;manhattan&quot;, store it in a csc</span>
        <span class="s2"># format is easier to calculate the median.</span>
        <span class="s3">if </span><span class="s1">self.metric == </span><span class="s4">&quot;manhattan&quot;</span><span class="s1">:</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">y = self._validate_data(X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">accept_sparse=[</span><span class="s4">&quot;csc&quot;</span><span class="s1">])</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">X</span><span class="s3">, </span><span class="s1">y = self._validate_data(X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">accept_sparse=[</span><span class="s4">&quot;csr&quot;</span><span class="s3">, </span><span class="s4">&quot;csc&quot;</span><span class="s1">])</span>
        <span class="s1">is_X_sparse = sp.issparse(X)</span>
        <span class="s3">if </span><span class="s1">is_X_sparse </span><span class="s3">and </span><span class="s1">self.shrink_threshold:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;threshold shrinking not supported for sparse input&quot;</span><span class="s1">)</span>
        <span class="s1">check_classification_targets(y)</span>

        <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features = X.shape</span>
        <span class="s1">le = LabelEncoder()</span>
        <span class="s1">y_ind = le.fit_transform(y)</span>
        <span class="s1">self.classes_ = classes = le.classes_</span>
        <span class="s1">n_classes = classes.size</span>
        <span class="s3">if </span><span class="s1">n_classes &lt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;The number of classes has to be greater than one; got %d class&quot;</span>
                <span class="s1">% (n_classes)</span>
            <span class="s1">)</span>

        <span class="s2"># Mask mapping each class to its members.</span>
        <span class="s1">self.centroids_ = np.empty((n_classes</span><span class="s3">, </span><span class="s1">n_features)</span><span class="s3">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s2"># Number of clusters in each class.</span>
        <span class="s1">nk = np.zeros(n_classes)</span>

        <span class="s3">for </span><span class="s1">cur_class </span><span class="s3">in </span><span class="s1">range(n_classes):</span>
            <span class="s1">center_mask = y_ind == cur_class</span>
            <span class="s1">nk[cur_class] = np.sum(center_mask)</span>
            <span class="s3">if </span><span class="s1">is_X_sparse:</span>
                <span class="s1">center_mask = np.where(center_mask)[</span><span class="s5">0</span><span class="s1">]</span>

            <span class="s3">if </span><span class="s1">self.metric == </span><span class="s4">&quot;manhattan&quot;</span><span class="s1">:</span>
                <span class="s2"># NumPy does not calculate median of sparse matrices.</span>
                <span class="s3">if not </span><span class="s1">is_X_sparse:</span>
                    <span class="s1">self.centroids_[cur_class] = np.median(X[center_mask]</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s2"># TODO(1.5) remove warning when metric is only manhattan or euclidean</span>
                <span class="s3">if </span><span class="s1">self.metric != </span><span class="s4">&quot;euclidean&quot;</span><span class="s1">:</span>
                    <span class="s1">warnings.warn(</span>
                        <span class="s4">&quot;Averaging for metrics other than &quot;</span>
                        <span class="s4">&quot;euclidean and manhattan not supported. &quot;</span>
                        <span class="s4">&quot;The average is set to be the mean.&quot;</span>
                    <span class="s1">)</span>
                <span class="s1">self.centroids_[cur_class] = X[center_mask].mean(axis=</span><span class="s5">0</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">self.shrink_threshold:</span>
            <span class="s3">if </span><span class="s1">np.all(np.ptp(X</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">) == </span><span class="s5">0</span><span class="s1">):</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;All features have zero variance. Division by zero.&quot;</span><span class="s1">)</span>
            <span class="s1">dataset_centroid_ = np.mean(X</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

            <span class="s2"># m parameter for determining deviation</span>
            <span class="s1">m = np.sqrt((</span><span class="s5">1.0 </span><span class="s1">/ nk) - (</span><span class="s5">1.0 </span><span class="s1">/ n_samples))</span>
            <span class="s2"># Calculate deviation using the standard deviation of centroids.</span>
            <span class="s1">variance = (X - self.centroids_[y_ind]) ** </span><span class="s5">2</span>
            <span class="s1">variance = variance.sum(axis=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">s = np.sqrt(variance / (n_samples - n_classes))</span>
            <span class="s1">s += np.median(s)  </span><span class="s2"># To deter outliers from affecting the results.</span>
            <span class="s1">mm = m.reshape(len(m)</span><span class="s3">, </span><span class="s5">1</span><span class="s1">)  </span><span class="s2"># Reshape to allow broadcasting.</span>
            <span class="s1">ms = mm * s</span>
            <span class="s1">deviation = (self.centroids_ - dataset_centroid_) / ms</span>
            <span class="s2"># Soft thresholding: if the deviation crosses 0 during shrinking,</span>
            <span class="s2"># it becomes zero.</span>
            <span class="s1">signs = np.sign(deviation)</span>
            <span class="s1">deviation = np.abs(deviation) - self.shrink_threshold</span>
            <span class="s1">np.clip(deviation</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, None, </span><span class="s1">out=deviation)</span>
            <span class="s1">deviation *= signs</span>
            <span class="s2"># Now adjust the centroids using the deviation</span>
            <span class="s1">msd = ms * deviation</span>
            <span class="s1">self.centroids_ = dataset_centroid_[np.newaxis</span><span class="s3">, </span><span class="s1">:] + msd</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s2"># TODO(1.5) remove note about precomputed metric</span>
    <span class="s3">def </span><span class="s1">predict(self</span><span class="s3">, </span><span class="s1">X):</span>
        <span class="s0">&quot;&quot;&quot;Perform classification on an array of test vectors `X`. 
 
        The predicted class `C` for each sample in `X` is returned. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Test samples. 
 
        Returns 
        ------- 
        C : ndarray of shape (n_samples,) 
            The predicted classes. 
 
        Notes 
        ----- 
        If the metric constructor parameter is `&quot;precomputed&quot;`, `X` is assumed 
        to be the distance matrix between the data to be predicted and 
        `self.centroids_`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted(self)</span>

        <span class="s1">X = self._validate_data(X</span><span class="s3">, </span><span class="s1">accept_sparse=</span><span class="s4">&quot;csr&quot;</span><span class="s3">, </span><span class="s1">reset=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">self.classes_[</span>
            <span class="s1">pairwise_distances_argmin(X</span><span class="s3">, </span><span class="s1">self.centroids_</span><span class="s3">, </span><span class="s1">metric=self.metric)</span>
        <span class="s1">]</span>
</pre>
</body>
</html>
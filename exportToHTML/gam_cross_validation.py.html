<html>
<head>
<title>gam_cross_validation.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
gam_cross_validation.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Cross-validation classes for GAM 
 
Author: Luca Puggini 
 
&quot;&quot;&quot;</span>

<span class="s3">from </span><span class="s1">abc </span><span class="s3">import </span><span class="s1">ABCMeta</span><span class="s3">, </span><span class="s1">abstractmethod</span>
<span class="s3">from </span><span class="s1">statsmodels.compat.python </span><span class="s3">import </span><span class="s1">with_metaclass</span>
<span class="s3">import </span><span class="s1">itertools</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">statsmodels.gam.smooth_basis </span><span class="s3">import </span><span class="s1">(GenericSmoothers</span><span class="s3">,</span>
                                          <span class="s1">UnivariateGenericSmoother)</span>


<span class="s3">class </span><span class="s1">BaseCV(with_metaclass(ABCMeta)):</span>
    <span class="s2">&quot;&quot;&quot; 
    BaseCV class. It computes the cross validation error of a given model. 
    All the cross validation classes can be derived by this one 
    (e.g. GamCV, LassoCV,...) 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">cv_iterator</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog):</span>
        <span class="s1">self.cv_iterator = cv_iterator</span>
        <span class="s1">self.exog = exog</span>
        <span class="s1">self.endog = endog</span>
        <span class="s0"># TODO: cv_iterator.split only needs nobs from endog or exog</span>
        <span class="s1">self.train_test_cv_indices = self.cv_iterator.split(self.exog</span><span class="s3">,</span>
                                                            <span class="s1">self.endog</span><span class="s3">,</span>
                                                            <span class="s1">label=</span><span class="s3">None</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s0"># kwargs are the input values for the fit method of the</span>
        <span class="s0"># cross-validated object</span>

        <span class="s1">cv_err = []</span>

        <span class="s3">for </span><span class="s1">train_index</span><span class="s3">, </span><span class="s1">test_index </span><span class="s3">in </span><span class="s1">self.train_test_cv_indices:</span>
            <span class="s1">cv_err.append(self._error(train_index</span><span class="s3">, </span><span class="s1">test_index</span><span class="s3">, </span><span class="s1">**kwargs))</span>

        <span class="s3">return </span><span class="s1">np.array(cv_err)</span>

    <span class="s1">@abstractmethod</span>
    <span class="s3">def </span><span class="s1">_error(self</span><span class="s3">, </span><span class="s1">train_index</span><span class="s3">, </span><span class="s1">test_index</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s0"># train the model on the train set</span>
        <span class="s0">#   and returns the error on the test set</span>
        <span class="s3">pass</span>


<span class="s3">def </span><span class="s1">_split_train_test_smoothers(x</span><span class="s3">, </span><span class="s1">smoother</span><span class="s3">, </span><span class="s1">train_index</span><span class="s3">, </span><span class="s1">test_index):</span>
    <span class="s2">&quot;&quot;&quot;split smoothers in test and train sets and create GenericSmoothers 
 
    Note: this does not take exog_linear into account 
    &quot;&quot;&quot;</span>
    <span class="s1">train_smoothers = []</span>
    <span class="s1">test_smoothers = []</span>
    <span class="s3">for </span><span class="s1">smoother </span><span class="s3">in </span><span class="s1">smoother.smoothers:</span>
        <span class="s1">train_basis = smoother.basis[train_index]</span>
        <span class="s1">train_der_basis = smoother.der_basis[train_index]</span>
        <span class="s1">train_der2_basis = smoother.der2_basis[train_index]</span>
        <span class="s1">train_cov_der2 = smoother.cov_der2</span>
        <span class="s0"># TODO: Double check this part. cov_der2 is calculated with all data</span>
        <span class="s1">train_x = smoother.x[train_index]</span>

        <span class="s1">train_smoothers.append(</span>
            <span class="s1">UnivariateGenericSmoother(</span>
                <span class="s1">train_x</span><span class="s3">, </span><span class="s1">train_basis</span><span class="s3">, </span><span class="s1">train_der_basis</span><span class="s3">, </span><span class="s1">train_der2_basis</span><span class="s3">,</span>
                <span class="s1">train_cov_der2</span><span class="s3">, </span><span class="s1">smoother.variable_name + </span><span class="s4">' train'</span><span class="s1">))</span>

        <span class="s1">test_basis = smoother.basis[test_index]</span>
        <span class="s1">test_der_basis = smoother.der_basis[test_index]</span>
        <span class="s1">test_cov_der2 = smoother.cov_der2</span>
        <span class="s0"># TODO: Double check this part. cov_der2 is calculated with all data</span>
        <span class="s1">test_x = smoother.x[test_index]</span>

        <span class="s1">test_smoothers.append(</span>
            <span class="s1">UnivariateGenericSmoother(</span>
                <span class="s1">test_x</span><span class="s3">, </span><span class="s1">test_basis</span><span class="s3">, </span><span class="s1">test_der_basis</span><span class="s3">, </span><span class="s1">train_der2_basis</span><span class="s3">,</span>
                <span class="s1">test_cov_der2</span><span class="s3">, </span><span class="s1">smoother.variable_name + </span><span class="s4">' test'</span><span class="s1">))</span>

    <span class="s1">train_multivariate_smoothers = GenericSmoothers(x[train_index]</span><span class="s3">,</span>
                                                    <span class="s1">train_smoothers)</span>
    <span class="s1">test_multivariate_smoothers = GenericSmoothers(x[test_index]</span><span class="s3">,</span>
                                                   <span class="s1">test_smoothers)</span>

    <span class="s3">return </span><span class="s1">train_multivariate_smoothers</span><span class="s3">, </span><span class="s1">test_multivariate_smoothers</span>


<span class="s3">class </span><span class="s1">MultivariateGAMCV(BaseCV):</span>
    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">smoother</span><span class="s3">, </span><span class="s1">alphas</span><span class="s3">, </span><span class="s1">gam</span><span class="s3">, </span><span class="s1">cost</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">cv_iterator):</span>
        <span class="s1">self.cost = cost</span>
        <span class="s1">self.gam = gam</span>
        <span class="s1">self.smoother = smoother</span>
        <span class="s1">self.exog_linear = exog</span>
        <span class="s1">self.alphas = alphas</span>
        <span class="s1">self.cv_iterator = cv_iterator</span>
        <span class="s0"># TODO: super does not do anything with endog, exog, except get nobs</span>
        <span class="s0"># refactor to clean up what where `exog` and `exog_linear` is attached</span>
        <span class="s1">super(MultivariateGAMCV</span><span class="s3">, </span><span class="s1">self).__init__(cv_iterator</span><span class="s3">,</span>
                                                <span class="s1">endog</span><span class="s3">,</span>
                                                <span class="s0"># exog,  # not used in super</span>
                                                <span class="s1">self.smoother.basis)</span>

    <span class="s3">def </span><span class="s1">_error(self</span><span class="s3">, </span><span class="s1">train_index</span><span class="s3">, </span><span class="s1">test_index</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s1">train_smoother</span><span class="s3">, </span><span class="s1">test_smoother = _split_train_test_smoothers(</span>
            <span class="s1">self.smoother.x</span><span class="s3">, </span><span class="s1">self.smoother</span><span class="s3">, </span><span class="s1">train_index</span><span class="s3">, </span><span class="s1">test_index)</span>

        <span class="s1">endog_train = self.endog[train_index]</span>
        <span class="s1">endog_test = self.endog[test_index]</span>
        <span class="s3">if </span><span class="s1">self.exog_linear </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">exog_linear_train = self.exog_linear[train_index]</span>
            <span class="s1">exog_linear_test = self.exog_linear[test_index]</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">exog_linear_train = </span><span class="s3">None</span>
            <span class="s1">exog_linear_test = </span><span class="s3">None</span>

        <span class="s1">gam = self.gam(endog_train</span><span class="s3">, </span><span class="s1">exog=exog_linear_train</span><span class="s3">,</span>
                       <span class="s1">smoother=train_smoother</span><span class="s3">, </span><span class="s1">alpha=self.alphas)</span>
        <span class="s1">gam_res = gam.fit(**kwargs)</span>
        <span class="s0"># exog_linear_test and test_smoother.basis will be column_stacked</span>
        <span class="s0">#     but not transformed in predict</span>
        <span class="s1">endog_est = gam_res.predict(exog_linear_test</span><span class="s3">, </span><span class="s1">test_smoother.basis</span><span class="s3">,</span>
                                    <span class="s1">transform=</span><span class="s3">False</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">self.cost(endog_test</span><span class="s3">, </span><span class="s1">endog_est)</span>


<span class="s3">class </span><span class="s1">BasePenaltiesPathCV(with_metaclass(ABCMeta)):</span>
    <span class="s2">&quot;&quot;&quot; 
    Base class for cross validation over a grid of parameters. 
 
    The best parameter is saved in alpha_cv 
 
    This class is currently not used 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">alphas):</span>
        <span class="s1">self.alphas = alphas</span>
        <span class="s1">self.alpha_cv = </span><span class="s3">None</span>
        <span class="s1">self.cv_error = </span><span class="s3">None</span>
        <span class="s1">self.cv_std = </span><span class="s3">None</span>

    <span class="s3">def </span><span class="s1">plot_path(self):</span>
        <span class="s3">from </span><span class="s1">statsmodels.graphics.utils </span><span class="s3">import </span><span class="s1">_import_mpl</span>
        <span class="s1">plt = _import_mpl()</span>
        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error</span><span class="s3">, </span><span class="s1">c=</span><span class="s4">'black'</span><span class="s1">)</span>
        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error + </span><span class="s5">1.96 </span><span class="s1">* self.cv_std</span><span class="s3">,</span>
                 <span class="s1">c=</span><span class="s4">'blue'</span><span class="s1">)</span>
        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error - </span><span class="s5">1.96 </span><span class="s1">* self.cv_std</span><span class="s3">,</span>
                 <span class="s1">c=</span><span class="s4">'blue'</span><span class="s1">)</span>

        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error</span><span class="s3">, </span><span class="s4">'o'</span><span class="s3">, </span><span class="s1">c=</span><span class="s4">'black'</span><span class="s1">)</span>
        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error + </span><span class="s5">1.96 </span><span class="s1">* self.cv_std</span><span class="s3">, </span><span class="s4">'o'</span><span class="s3">,</span>
                 <span class="s1">c=</span><span class="s4">'blue'</span><span class="s1">)</span>
        <span class="s1">plt.plot(self.alphas</span><span class="s3">, </span><span class="s1">self.cv_error - </span><span class="s5">1.96 </span><span class="s1">* self.cv_std</span><span class="s3">, </span><span class="s4">'o'</span><span class="s3">,</span>
                 <span class="s1">c=</span><span class="s4">'blue'</span><span class="s1">)</span>

        <span class="s3">return</span>
        <span class="s0"># TODO add return</span>


<span class="s3">class </span><span class="s1">MultivariateGAMCVPath:</span>
    <span class="s2">&quot;&quot;&quot;k-fold cross-validation for GAM 
 
    Warning: The API of this class is preliminary and will change. 
 
    Parameters 
    ---------- 
    smoother : additive smoother instance 
    alphas : list of iteratables 
        list of alpha for smooths. The product space will be used as alpha 
        grid for cross-validation 
    gam : model class 
        model class for creating a model with k-fole training data 
    cost : function 
        cost function for the prediction error 
    endog : ndarray 
        dependent (response) variable of the model 
    cv_iterator : instance of cross-validation iterator 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">smoother</span><span class="s3">, </span><span class="s1">alphas</span><span class="s3">, </span><span class="s1">gam</span><span class="s3">, </span><span class="s1">cost</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">cv_iterator):</span>
        <span class="s1">self.cost = cost</span>
        <span class="s1">self.smoother = smoother</span>
        <span class="s1">self.gam = gam</span>
        <span class="s1">self.alphas = alphas</span>
        <span class="s1">self.alphas_grid = list(itertools.product(*self.alphas))</span>
        <span class="s1">self.endog = endog</span>
        <span class="s1">self.exog = exog</span>
        <span class="s1">self.cv_iterator = cv_iterator</span>
        <span class="s1">self.cv_error = np.zeros(shape=(len(self.alphas_grid</span><span class="s3">, </span><span class="s1">)))</span>
        <span class="s1">self.cv_std = np.zeros(shape=(len(self.alphas_grid</span><span class="s3">, </span><span class="s1">)))</span>
        <span class="s1">self.alpha_cv = </span><span class="s3">None</span>

    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">**kwargs):</span>
        <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">alphas_i </span><span class="s3">in </span><span class="s1">enumerate(self.alphas_grid):</span>
            <span class="s1">gam_cv = MultivariateGAMCV(smoother=self.smoother</span><span class="s3">,</span>
                                       <span class="s1">alphas=alphas_i</span><span class="s3">,</span>
                                       <span class="s1">gam=self.gam</span><span class="s3">,</span>
                                       <span class="s1">cost=self.cost</span><span class="s3">,</span>
                                       <span class="s1">endog=self.endog</span><span class="s3">,</span>
                                       <span class="s1">exog=self.exog</span><span class="s3">,</span>
                                       <span class="s1">cv_iterator=self.cv_iterator)</span>
            <span class="s1">cv_err = gam_cv.fit(**kwargs)</span>
            <span class="s1">self.cv_error[i] = cv_err.mean()</span>
            <span class="s1">self.cv_std[i] = cv_err.std()</span>

        <span class="s1">self.alpha_cv = self.alphas_grid[np.argmin(self.cv_error)]</span>
        <span class="s3">return </span><span class="s1">self</span>
</pre>
</body>
</html>
<html>
<head>
<title>DATASET_PROPOSAL.txt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #a9b7c6;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
DATASET_PROPOSAL.txt</font>
</center></td></tr></table>
<pre><span class="s0">This was copied from</span>
<span class="s0">http://projects.scipy.org/scikits/browser/trunk/learn/scikits/learn/datasets/</span>


<span class="s0">.. Last Change: Mon Sep 17 04:00 PM 2007 J</span>
<span class="s0">.. vim:syntax=rest</span>

<span class="s0">Dataset for scipy: design proposal</span>
<span class="s0">==================================</span>

<span class="s0">One of the thing numpy/scipy is missing now is a set of datasets, available for</span>
<span class="s0">demo, courses, etc. For example, R has a set of dataset available at the core.</span>

<span class="s0">The expected usage of the datasets are the following:</span>

        <span class="s0">- machine learning: eg the data contain also class information (discrete or continuous)</span>
        <span class="s0">- descriptive statistics</span>
        <span class="s0">- others ?</span>

<span class="s0">That is, a dataset is not only data, but also some meta-data. The goal of this</span>
<span class="s0">proposal is to propose common practices for organizing the data, in a way which</span>
<span class="s0">is both straightforward, and does not prevent specific usage of the data.</span>

<span class="s0">Organization</span>
<span class="s0">------------</span>

<span class="s0">A preliminary set of datasets is available at the following address:</span>

<span class="s0">http://projects.scipy.org/scipy/scikits/browser/trunk/learn/scikits/learn/datasets</span>

<span class="s0">Each dataset is a directory and defines a python package (e.g. has the</span>
<span class="s0">__init__.py file). Each package is expected to define the function load, returning</span>
<span class="s0">the corresponding data. For example, to access datasets data1, you should be able to do:</span>

<span class="s0">&gt;&gt;&gt; from datasets.data1 import load</span>
<span class="s0">&gt;&gt;&gt; d = load() # -&gt; d contains the data.</span>

<span class="s0">load can do whatever it wants: fetching data from a file (python script, csv</span>
<span class="s0">file, etc...), from the internet, etc... Some special variables must be defined</span>
<span class="s0">for each package, containing a python string:</span>

    <span class="s0">- COPYRIGHT: copyright informations</span>
    <span class="s0">- SOURCE: where the data are coming from</span>
    <span class="s0">- DESCHOSRT: short description</span>
    <span class="s0">- DESCLONG: long description</span>
    <span class="s0">- NOTE: some notes on the datasets.</span>

<span class="s0">Format of the data</span>
<span class="s0">------------------</span>

<span class="s0">Here, I suggest a common practice for the returned value by the load function.</span>
<span class="s0">Instead of using classes to provide meta-data, I propose to use a dictionnary</span>
<span class="s0">of arrays, with some values mandatory. The key goals are:</span>

        <span class="s0">- for people who just want the data, there is no extra burden (&quot;just</span>
          <span class="s0">give me the data !&quot; MOTO).</span>
        <span class="s0">- for people who need more, they can easily extract what they need from</span>
          <span class="s0">the returned values. More high level abstractions can be built easily</span>
          <span class="s0">from this model.</span>
        <span class="s0">- all possible dataset should fit into this model.</span>
        <span class="s0">- In particular, I want to be able to be able to convert our dataset to</span>
          <span class="s0">Orange Dataset representation (or other machine learning tool), and</span>
          <span class="s0">vice-versa.</span>

<span class="s0">For the datasets to be useful in the learn scikits, which is the project which</span>
<span class="s0">initiated this datasets package, the data returned by load has to be a dict</span>
<span class="s0">with the following conventions:</span>

    <span class="s0">- 'data': this value should be a record array containing the actual data.</span>
    <span class="s0">- 'label': this value should be a rank 1 array of integers, contains the</span>
      <span class="s0">label index for each sample, that is label[i] should be the label index</span>
      <span class="s0">of data[i]. If it contains float values, it is used for regression instead.</span>
    <span class="s0">- 'class': a record array such as class[i] is the class name. In other</span>
      <span class="s0">words, this makes the correspondance label name &gt; label index.</span>

<span class="s0">As an example, I use the famouse IRIS dataset: the dataset contains 3 classes</span>
<span class="s0">of flowers, and for each flower, 4 measures (called attributes in machine</span>
<span class="s0">learning vocabulary) are available (sepal width and length, petal width and</span>
<span class="s0">length). In this case, the values returned by load would be:</span>

        <span class="s0">- 'data': a record array containing all the flowers' measurements. For</span>
          <span class="s0">descriptive statistics, that's all you may need. You can easily find</span>
          <span class="s0">the attributes from the dtype (a function to find the attributes is</span>
          <span class="s0">also available: it returns a list of the attributes).</span>
        <span class="s0">- 'labels': an array of integers (for class information) or float (for</span>
          <span class="s0">regression). each class is encoded as an integer, and labels[i]</span>
          <span class="s0">returns this integer for the sample i.</span>
        <span class="s0">- 'class': a record array, which returns the integer code for each</span>
          <span class="s0">class. For example, class['Iris-versicolor'] will return the integer</span>
          <span class="s0">used in label, and all samples i such as label[i] ==</span>
          <span class="s0">class['Iris-versicolor'] are of the class 'Iris-versicolor'.</span>
	
<span class="s0">This contains enough information to get all useful information through</span>
<span class="s0">introspection and simple functions. I already implemented a small module to do</span>
<span class="s0">basic things such as:</span>
	
        <span class="s0">- selecting only a subset of all samples.</span>
        <span class="s0">- selecting only a subset of the attributes (only sepal length and</span>
          <span class="s0">width, for example).</span>
        <span class="s0">- selecting only the samples of a given class.</span>
        <span class="s0">- small summary of the dataset.</span>
	
<span class="s0">This is implemented in less than 100 lines, which tends to show that the above</span>
<span class="s0">design is not too simplistic.</span>
	
<span class="s0">Remaining problems:</span>
<span class="s0">-------------------</span>

<span class="s0">I see mainly two big problems:</span>

        <span class="s0">- if the dataset is big and cannot fit into memory, what kind of API do</span>
          <span class="s0">we want to avoid loading all the data in memory ? Can we use memory</span>
          <span class="s0">mapped arrays ?</span>
        <span class="s0">- Missing data: I thought about subclassing both record arrays and</span>
          <span class="s0">masked arrays classes, but I don't know if this is feasable, or even</span>
          <span class="s0">makes sense. I have the feeling that some Data mining software use</span>
          <span class="s0">Nan (for example, weka seems to use float internally), but this</span>
          <span class="s0">prevents them from representing integer data.</span>

<span class="s0">Current implementation</span>
<span class="s0">----------------------</span>
	
<span class="s0">An implementation following the above design is available in</span>
<span class="s0">scikits.learn.datasets. If you installed scikits.learn, you can execute the</span>
<span class="s0">file learn/utils/attrselect.py, which shows the information you can easily</span>
<span class="s0">extract for now from this model.</span>
	
<span class="s0">Also, once the above problems are solved, an arff converter will be available:</span>
<span class="s0">arff is the format used by WEKA, and many datasets are available at this</span>
<span class="s0">format:</span>
	
<span class="s0">http://weka.sourceforge.net/wekadoc/index.php/en:ARFF_%283.5.4%29</span>
<span class="s0">http://www.cs.waikato.ac.nz/ml/weka/index_datasets.html</span>
	
<span class="s0">Note</span>
<span class="s0">----</span>
	
<span class="s0">Although the datasets package emerged from the learn package, I try to keep it</span>
<span class="s0">independant from everything else, that is once we agree on the remaining</span>
<span class="s0">problems and where the package should go, it can easily be put elsewhere</span>
<span class="s0">without too much trouble.</span>
</pre>
</body>
</html>
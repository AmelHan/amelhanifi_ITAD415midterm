<html>
<head>
<title>test_pprint.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_pprint.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">re</span>
<span class="s0">from </span><span class="s1">pprint </span><span class="s0">import </span><span class="s1">PrettyPrinter</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">from </span><span class="s1">sklearn.utils._pprint </span><span class="s0">import </span><span class="s1">_EstimatorPrettyPrinter</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LogisticRegressionCV</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">BaseEstimator</span><span class="s0">, </span><span class="s1">TransformerMixin</span>
<span class="s0">from </span><span class="s1">sklearn.feature_selection </span><span class="s0">import </span><span class="s1">SelectKBest</span><span class="s0">, </span><span class="s1">chi2</span>
<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">config_context</span>


<span class="s2"># Ignore flake8 (lots of line too long issues)</span>
<span class="s2"># ruff: noqa</span>


<span class="s2"># Constructors excerpted to test pprinting</span>
<span class="s0">class </span><span class="s1">LogisticRegression(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">penalty=</span><span class="s3">&quot;l2&quot;</span><span class="s0">,</span>
        <span class="s1">dual=</span><span class="s0">False,</span>
        <span class="s1">tol=</span><span class="s4">1e-4</span><span class="s0">,</span>
        <span class="s1">C=</span><span class="s4">1.0</span><span class="s0">,</span>
        <span class="s1">fit_intercept=</span><span class="s0">True,</span>
        <span class="s1">intercept_scaling=</span><span class="s4">1</span><span class="s0">,</span>
        <span class="s1">class_weight=</span><span class="s0">None,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
        <span class="s1">solver=</span><span class="s3">&quot;warn&quot;</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s4">100</span><span class="s0">,</span>
        <span class="s1">multi_class=</span><span class="s3">&quot;warn&quot;</span><span class="s0">,</span>
        <span class="s1">verbose=</span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">warm_start=</span><span class="s0">False,</span>
        <span class="s1">n_jobs=</span><span class="s0">None,</span>
        <span class="s1">l1_ratio=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.penalty = penalty</span>
        <span class="s1">self.dual = dual</span>
        <span class="s1">self.tol = tol</span>
        <span class="s1">self.C = C</span>
        <span class="s1">self.fit_intercept = fit_intercept</span>
        <span class="s1">self.intercept_scaling = intercept_scaling</span>
        <span class="s1">self.class_weight = class_weight</span>
        <span class="s1">self.random_state = random_state</span>
        <span class="s1">self.solver = solver</span>
        <span class="s1">self.max_iter = max_iter</span>
        <span class="s1">self.multi_class = multi_class</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.warm_start = warm_start</span>
        <span class="s1">self.n_jobs = n_jobs</span>
        <span class="s1">self.l1_ratio = l1_ratio</span>

    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s0">return </span><span class="s1">self</span>


<span class="s0">class </span><span class="s1">StandardScaler(TransformerMixin</span><span class="s0">, </span><span class="s1">BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">True, </span><span class="s1">with_mean=</span><span class="s0">True, </span><span class="s1">with_std=</span><span class="s0">True</span><span class="s1">):</span>
        <span class="s1">self.with_mean = with_mean</span>
        <span class="s1">self.with_std = with_std</span>
        <span class="s1">self.copy = copy</span>

    <span class="s0">def </span><span class="s1">transform(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">self</span>


<span class="s0">class </span><span class="s1">RFE(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">estimator</span><span class="s0">, </span><span class="s1">n_features_to_select=</span><span class="s0">None, </span><span class="s1">step=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">verbose=</span><span class="s4">0</span><span class="s1">):</span>
        <span class="s1">self.estimator = estimator</span>
        <span class="s1">self.n_features_to_select = n_features_to_select</span>
        <span class="s1">self.step = step</span>
        <span class="s1">self.verbose = verbose</span>


<span class="s0">class </span><span class="s1">GridSearchCV(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">estimator</span><span class="s0">,</span>
        <span class="s1">param_grid</span><span class="s0">,</span>
        <span class="s1">scoring=</span><span class="s0">None,</span>
        <span class="s1">n_jobs=</span><span class="s0">None,</span>
        <span class="s1">iid=</span><span class="s3">&quot;warn&quot;</span><span class="s0">,</span>
        <span class="s1">refit=</span><span class="s0">True,</span>
        <span class="s1">cv=</span><span class="s3">&quot;warn&quot;</span><span class="s0">,</span>
        <span class="s1">verbose=</span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">pre_dispatch=</span><span class="s3">&quot;2*n_jobs&quot;</span><span class="s0">,</span>
        <span class="s1">error_score=</span><span class="s3">&quot;raise-deprecating&quot;</span><span class="s0">,</span>
        <span class="s1">return_train_score=</span><span class="s0">False,</span>
    <span class="s1">):</span>
        <span class="s1">self.estimator = estimator</span>
        <span class="s1">self.param_grid = param_grid</span>
        <span class="s1">self.scoring = scoring</span>
        <span class="s1">self.n_jobs = n_jobs</span>
        <span class="s1">self.iid = iid</span>
        <span class="s1">self.refit = refit</span>
        <span class="s1">self.cv = cv</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.pre_dispatch = pre_dispatch</span>
        <span class="s1">self.error_score = error_score</span>
        <span class="s1">self.return_train_score = return_train_score</span>


<span class="s0">class </span><span class="s1">CountVectorizer(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">input=</span><span class="s3">&quot;content&quot;</span><span class="s0">,</span>
        <span class="s1">encoding=</span><span class="s3">&quot;utf-8&quot;</span><span class="s0">,</span>
        <span class="s1">decode_error=</span><span class="s3">&quot;strict&quot;</span><span class="s0">,</span>
        <span class="s1">strip_accents=</span><span class="s0">None,</span>
        <span class="s1">lowercase=</span><span class="s0">True,</span>
        <span class="s1">preprocessor=</span><span class="s0">None,</span>
        <span class="s1">tokenizer=</span><span class="s0">None,</span>
        <span class="s1">stop_words=</span><span class="s0">None,</span>
        <span class="s1">token_pattern=</span><span class="s3">r&quot;(?u)\b\w\w+\b&quot;</span><span class="s0">,</span>
        <span class="s1">ngram_range=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">analyzer=</span><span class="s3">&quot;word&quot;</span><span class="s0">,</span>
        <span class="s1">max_df=</span><span class="s4">1.0</span><span class="s0">,</span>
        <span class="s1">min_df=</span><span class="s4">1</span><span class="s0">,</span>
        <span class="s1">max_features=</span><span class="s0">None,</span>
        <span class="s1">vocabulary=</span><span class="s0">None,</span>
        <span class="s1">binary=</span><span class="s0">False,</span>
        <span class="s1">dtype=np.int64</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">self.input = input</span>
        <span class="s1">self.encoding = encoding</span>
        <span class="s1">self.decode_error = decode_error</span>
        <span class="s1">self.strip_accents = strip_accents</span>
        <span class="s1">self.preprocessor = preprocessor</span>
        <span class="s1">self.tokenizer = tokenizer</span>
        <span class="s1">self.analyzer = analyzer</span>
        <span class="s1">self.lowercase = lowercase</span>
        <span class="s1">self.token_pattern = token_pattern</span>
        <span class="s1">self.stop_words = stop_words</span>
        <span class="s1">self.max_df = max_df</span>
        <span class="s1">self.min_df = min_df</span>
        <span class="s1">self.max_features = max_features</span>
        <span class="s1">self.ngram_range = ngram_range</span>
        <span class="s1">self.vocabulary = vocabulary</span>
        <span class="s1">self.binary = binary</span>
        <span class="s1">self.dtype = dtype</span>


<span class="s0">class </span><span class="s1">Pipeline(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">steps</span><span class="s0">, </span><span class="s1">memory=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">self.steps = steps</span>
        <span class="s1">self.memory = memory</span>


<span class="s0">class </span><span class="s1">SVC(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">C=</span><span class="s4">1.0</span><span class="s0">,</span>
        <span class="s1">kernel=</span><span class="s3">&quot;rbf&quot;</span><span class="s0">,</span>
        <span class="s1">degree=</span><span class="s4">3</span><span class="s0">,</span>
        <span class="s1">gamma=</span><span class="s3">&quot;auto_deprecated&quot;</span><span class="s0">,</span>
        <span class="s1">coef0=</span><span class="s4">0.0</span><span class="s0">,</span>
        <span class="s1">shrinking=</span><span class="s0">True,</span>
        <span class="s1">probability=</span><span class="s0">False,</span>
        <span class="s1">tol=</span><span class="s4">1e-3</span><span class="s0">,</span>
        <span class="s1">cache_size=</span><span class="s4">200</span><span class="s0">,</span>
        <span class="s1">class_weight=</span><span class="s0">None,</span>
        <span class="s1">verbose=</span><span class="s0">False,</span>
        <span class="s1">max_iter=-</span><span class="s4">1</span><span class="s0">,</span>
        <span class="s1">decision_function_shape=</span><span class="s3">&quot;ovr&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.kernel = kernel</span>
        <span class="s1">self.degree = degree</span>
        <span class="s1">self.gamma = gamma</span>
        <span class="s1">self.coef0 = coef0</span>
        <span class="s1">self.tol = tol</span>
        <span class="s1">self.C = C</span>
        <span class="s1">self.shrinking = shrinking</span>
        <span class="s1">self.probability = probability</span>
        <span class="s1">self.cache_size = cache_size</span>
        <span class="s1">self.class_weight = class_weight</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.max_iter = max_iter</span>
        <span class="s1">self.decision_function_shape = decision_function_shape</span>
        <span class="s1">self.random_state = random_state</span>


<span class="s0">class </span><span class="s1">PCA(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">n_components=</span><span class="s0">None,</span>
        <span class="s1">copy=</span><span class="s0">True,</span>
        <span class="s1">whiten=</span><span class="s0">False,</span>
        <span class="s1">svd_solver=</span><span class="s3">&quot;auto&quot;</span><span class="s0">,</span>
        <span class="s1">tol=</span><span class="s4">0.0</span><span class="s0">,</span>
        <span class="s1">iterated_power=</span><span class="s3">&quot;auto&quot;</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.n_components = n_components</span>
        <span class="s1">self.copy = copy</span>
        <span class="s1">self.whiten = whiten</span>
        <span class="s1">self.svd_solver = svd_solver</span>
        <span class="s1">self.tol = tol</span>
        <span class="s1">self.iterated_power = iterated_power</span>
        <span class="s1">self.random_state = random_state</span>


<span class="s0">class </span><span class="s1">NMF(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">n_components=</span><span class="s0">None,</span>
        <span class="s1">init=</span><span class="s0">None,</span>
        <span class="s1">solver=</span><span class="s3">&quot;cd&quot;</span><span class="s0">,</span>
        <span class="s1">beta_loss=</span><span class="s3">&quot;frobenius&quot;</span><span class="s0">,</span>
        <span class="s1">tol=</span><span class="s4">1e-4</span><span class="s0">,</span>
        <span class="s1">max_iter=</span><span class="s4">200</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
        <span class="s1">alpha=</span><span class="s4">0.0</span><span class="s0">,</span>
        <span class="s1">l1_ratio=</span><span class="s4">0.0</span><span class="s0">,</span>
        <span class="s1">verbose=</span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">shuffle=</span><span class="s0">False,</span>
    <span class="s1">):</span>
        <span class="s1">self.n_components = n_components</span>
        <span class="s1">self.init = init</span>
        <span class="s1">self.solver = solver</span>
        <span class="s1">self.beta_loss = beta_loss</span>
        <span class="s1">self.tol = tol</span>
        <span class="s1">self.max_iter = max_iter</span>
        <span class="s1">self.random_state = random_state</span>
        <span class="s1">self.alpha = alpha</span>
        <span class="s1">self.l1_ratio = l1_ratio</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.shuffle = shuffle</span>


<span class="s0">class </span><span class="s1">SimpleImputer(BaseEstimator):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">missing_values=np.nan</span><span class="s0">,</span>
        <span class="s1">strategy=</span><span class="s3">&quot;mean&quot;</span><span class="s0">,</span>
        <span class="s1">fill_value=</span><span class="s0">None,</span>
        <span class="s1">verbose=</span><span class="s4">0</span><span class="s0">,</span>
        <span class="s1">copy=</span><span class="s0">True,</span>
    <span class="s1">):</span>
        <span class="s1">self.missing_values = missing_values</span>
        <span class="s1">self.strategy = strategy</span>
        <span class="s1">self.fill_value = fill_value</span>
        <span class="s1">self.verbose = verbose</span>
        <span class="s1">self.copy = copy</span>


<span class="s0">def </span><span class="s1">test_basic(print_changed_only_false):</span>
    <span class="s2"># Basic pprint test</span>
    <span class="s1">lr = LogisticRegression()</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, 
                   intercept_scaling=1, l1_ratio=None, max_iter=100, 
                   multi_class='warn', n_jobs=None, penalty='l2', 
                   random_state=None, solver='warn', tol=0.0001, verbose=0, 
                   warm_start=False)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">lr.__repr__() == expected</span>


<span class="s0">def </span><span class="s1">test_changed_only():</span>
    <span class="s2"># Make sure the changed_only param is correctly used when True (default)</span>
    <span class="s1">lr = LogisticRegression(C=</span><span class="s4">99</span><span class="s1">)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot;LogisticRegression(C=99)&quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">lr.__repr__() == expected</span>

    <span class="s2"># Check with a repr that doesn't fit on a single line</span>
    <span class="s1">lr = LogisticRegression(</span>
        <span class="s1">C=</span><span class="s4">99</span><span class="s0">, </span><span class="s1">class_weight=</span><span class="s4">0.4</span><span class="s0">, </span><span class="s1">fit_intercept=</span><span class="s0">False, </span><span class="s1">tol=</span><span class="s4">1234</span><span class="s0">, </span><span class="s1">verbose=</span><span class="s0">True</span>
    <span class="s1">)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=99, class_weight=0.4, fit_intercept=False, tol=1234, 
                   verbose=True)&quot;&quot;&quot;</span>
    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">lr.__repr__() == expected</span>

    <span class="s1">imputer = SimpleImputer(missing_values=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot;SimpleImputer(missing_values=0)&quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">imputer.__repr__() == expected</span>

    <span class="s2"># Defaults to np.nan, trying with float('NaN')</span>
    <span class="s1">imputer = SimpleImputer(missing_values=float(</span><span class="s3">&quot;NaN&quot;</span><span class="s1">))</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot;SimpleImputer()&quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">imputer.__repr__() == expected</span>

    <span class="s2"># make sure array parameters don't throw error (see #13583)</span>
    <span class="s1">repr(LogisticRegressionCV(Cs=np.array([</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])))</span>


<span class="s0">def </span><span class="s1">test_pipeline(print_changed_only_false):</span>
    <span class="s2"># Render a pipeline object</span>
    <span class="s1">pipeline = make_pipeline(StandardScaler()</span><span class="s0">, </span><span class="s1">LogisticRegression(C=</span><span class="s4">999</span><span class="s1">))</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
Pipeline(memory=None, 
         steps=[('standardscaler', 
                 StandardScaler(copy=True, with_mean=True, with_std=True)), 
                ('logisticregression', 
                 LogisticRegression(C=999, class_weight=None, dual=False, 
                                    fit_intercept=True, intercept_scaling=1, 
                                    l1_ratio=None, max_iter=100, 
                                    multi_class='warn', n_jobs=None, 
                                    penalty='l2', random_state=None, 
                                    solver='warn', tol=0.0001, verbose=0, 
                                    warm_start=False))], 
         verbose=False)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">pipeline.__repr__() == expected</span>


<span class="s0">def </span><span class="s1">test_deeply_nested(print_changed_only_false):</span>
    <span class="s2"># Render a deeply nested estimator</span>
    <span class="s1">rfe = RFE(RFE(RFE(RFE(RFE(RFE(RFE(LogisticRegression())))))))</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
RFE(estimator=RFE(estimator=RFE(estimator=RFE(estimator=RFE(estimator=RFE(estimator=RFE(estimator=LogisticRegression(C=1.0, 
                                                                                                                     class_weight=None, 
                                                                                                                     dual=False, 
                                                                                                                     fit_intercept=True, 
                                                                                                                     intercept_scaling=1, 
                                                                                                                     l1_ratio=None, 
                                                                                                                     max_iter=100, 
                                                                                                                     multi_class='warn', 
                                                                                                                     n_jobs=None, 
                                                                                                                     penalty='l2', 
                                                                                                                     random_state=None, 
                                                                                                                     solver='warn', 
                                                                                                                     tol=0.0001, 
                                                                                                                     verbose=0, 
                                                                                                                     warm_start=False), 
                                                                                        n_features_to_select=None, 
                                                                                        step=1, 
                                                                                        verbose=0), 
                                                                          n_features_to_select=None, 
                                                                          step=1, 
                                                                          verbose=0), 
                                                            n_features_to_select=None, 
                                                            step=1, verbose=0), 
                                              n_features_to_select=None, step=1, 
                                              verbose=0), 
                                n_features_to_select=None, step=1, verbose=0), 
                  n_features_to_select=None, step=1, verbose=0), 
    n_features_to_select=None, step=1, verbose=0)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">rfe.__repr__() == expected</span>


<span class="s0">def </span><span class="s1">test_gridsearch(print_changed_only_false):</span>
    <span class="s2"># render a gridsearch</span>
    <span class="s1">param_grid = [</span>
        <span class="s1">{</span><span class="s3">&quot;kernel&quot;</span><span class="s1">: [</span><span class="s3">&quot;rbf&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;gamma&quot;</span><span class="s1">: [</span><span class="s4">1e-3</span><span class="s0">, </span><span class="s4">1e-4</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;C&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s4">1000</span><span class="s1">]}</span><span class="s0">,</span>
        <span class="s1">{</span><span class="s3">&quot;kernel&quot;</span><span class="s1">: [</span><span class="s3">&quot;linear&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;C&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s4">1000</span><span class="s1">]}</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">gs = GridSearchCV(SVC()</span><span class="s0">, </span><span class="s1">param_grid</span><span class="s0">, </span><span class="s1">cv=</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
GridSearchCV(cv=5, error_score='raise-deprecating', 
             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, 
                           decision_function_shape='ovr', degree=3, 
                           gamma='auto_deprecated', kernel='rbf', max_iter=-1, 
                           probability=False, random_state=None, shrinking=True, 
                           tol=0.001, verbose=False), 
             iid='warn', n_jobs=None, 
             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 
                          'kernel': ['rbf']}, 
                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}], 
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False, 
             scoring=None, verbose=0)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">gs.__repr__() == expected</span>


<span class="s0">def </span><span class="s1">test_gridsearch_pipeline(print_changed_only_false):</span>
    <span class="s2"># render a pipeline inside a gridsearch</span>
    <span class="s1">pp = _EstimatorPrettyPrinter(compact=</span><span class="s0">True, </span><span class="s1">indent=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">indent_at_name=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s1">pipeline = Pipeline([(</span><span class="s3">&quot;reduce_dim&quot;</span><span class="s0">, </span><span class="s1">PCA())</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;classify&quot;</span><span class="s0">, </span><span class="s1">SVC())])</span>
    <span class="s1">N_FEATURES_OPTIONS = [</span><span class="s4">2</span><span class="s0">, </span><span class="s4">4</span><span class="s0">, </span><span class="s4">8</span><span class="s1">]</span>
    <span class="s1">C_OPTIONS = [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s4">100</span><span class="s0">, </span><span class="s4">1000</span><span class="s1">]</span>
    <span class="s1">param_grid = [</span>
        <span class="s1">{</span>
            <span class="s3">&quot;reduce_dim&quot;</span><span class="s1">: [PCA(iterated_power=</span><span class="s4">7</span><span class="s1">)</span><span class="s0">, </span><span class="s1">NMF()]</span><span class="s0">,</span>
            <span class="s3">&quot;reduce_dim__n_components&quot;</span><span class="s1">: N_FEATURES_OPTIONS</span><span class="s0">,</span>
            <span class="s3">&quot;classify__C&quot;</span><span class="s1">: C_OPTIONS</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
        <span class="s1">{</span>
            <span class="s3">&quot;reduce_dim&quot;</span><span class="s1">: [SelectKBest(chi2)]</span><span class="s0">,</span>
            <span class="s3">&quot;reduce_dim__k&quot;</span><span class="s1">: N_FEATURES_OPTIONS</span><span class="s0">,</span>
            <span class="s3">&quot;classify__C&quot;</span><span class="s1">: C_OPTIONS</span><span class="s0">,</span>
        <span class="s1">}</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">gspipline = GridSearchCV(pipeline</span><span class="s0">, </span><span class="s1">cv=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">param_grid=param_grid)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
GridSearchCV(cv=3, error_score='raise-deprecating', 
             estimator=Pipeline(memory=None, 
                                steps=[('reduce_dim', 
                                        PCA(copy=True, iterated_power='auto', 
                                            n_components=None, 
                                            random_state=None, 
                                            svd_solver='auto', tol=0.0, 
                                            whiten=False)), 
                                       ('classify', 
                                        SVC(C=1.0, cache_size=200, 
                                            class_weight=None, coef0=0.0, 
                                            decision_function_shape='ovr', 
                                            degree=3, gamma='auto_deprecated', 
                                            kernel='rbf', max_iter=-1, 
                                            probability=False, 
                                            random_state=None, shrinking=True, 
                                            tol=0.001, verbose=False))]), 
             iid='warn', n_jobs=1, 
             param_grid=[{'classify__C': [1, 10, 100, 1000], 
                          'reduce_dim': [PCA(copy=True, iterated_power=7, 
                                             n_components=None, 
                                             random_state=None, 
                                             svd_solver='auto', tol=0.0, 
                                             whiten=False), 
                                         NMF(alpha=0.0, beta_loss='frobenius', 
                                             init=None, l1_ratio=0.0, 
                                             max_iter=200, n_components=None, 
                                             random_state=None, shuffle=False, 
                                             solver='cd', tol=0.0001, 
                                             verbose=0)], 
                          'reduce_dim__n_components': [2, 4, 8]}, 
                         {'classify__C': [1, 10, 100, 1000], 
                          'reduce_dim': [SelectKBest(k=10, 
                                                     score_func=&lt;function chi2 at some_address&gt;)], 
                          'reduce_dim__k': [2, 4, 8]}], 
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False, 
             scoring=None, verbose=0)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s1">repr_ = pp.pformat(gspipline)</span>
    <span class="s2"># Remove address of '&lt;function chi2 at 0x.....&gt;' for reproducibility</span>
    <span class="s1">repr_ = re.sub(</span><span class="s3">&quot;function chi2 at 0x.*&gt;&quot;</span><span class="s0">, </span><span class="s3">&quot;function chi2 at some_address&gt;&quot;</span><span class="s0">, </span><span class="s1">repr_)</span>
    <span class="s0">assert </span><span class="s1">repr_ == expected</span>


<span class="s0">def </span><span class="s1">test_n_max_elements_to_show(print_changed_only_false):</span>
    <span class="s1">n_max_elements_to_show = </span><span class="s4">30</span>
    <span class="s1">pp = _EstimatorPrettyPrinter(</span>
        <span class="s1">compact=</span><span class="s0">True,</span>
        <span class="s1">indent=</span><span class="s4">1</span><span class="s0">,</span>
        <span class="s1">indent_at_name=</span><span class="s0">True,</span>
        <span class="s1">n_max_elements_to_show=n_max_elements_to_show</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s2"># No ellipsis</span>
    <span class="s1">vocabulary = {i: i </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n_max_elements_to_show)}</span>
    <span class="s1">vectorizer = CountVectorizer(vocabulary=vocabulary)</span>

    <span class="s1">expected = </span><span class="s3">r&quot;&quot;&quot; 
CountVectorizer(analyzer='word', binary=False, decode_error='strict', 
                dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content', 
                lowercase=True, max_df=1.0, max_features=None, min_df=1, 
                ngram_range=(1, 1), preprocessor=None, stop_words=None, 
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b', 
                tokenizer=None, 
                vocabulary={0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 
                            8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 
                            15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 
                            21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 
                            27: 27, 28: 28, 29: 29})&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">pp.pformat(vectorizer) == expected</span>

    <span class="s2"># Now with ellipsis</span>
    <span class="s1">vocabulary = {i: i </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n_max_elements_to_show + </span><span class="s4">1</span><span class="s1">)}</span>
    <span class="s1">vectorizer = CountVectorizer(vocabulary=vocabulary)</span>

    <span class="s1">expected = </span><span class="s3">r&quot;&quot;&quot; 
CountVectorizer(analyzer='word', binary=False, decode_error='strict', 
                dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content', 
                lowercase=True, max_df=1.0, max_features=None, min_df=1, 
                ngram_range=(1, 1), preprocessor=None, stop_words=None, 
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b', 
                tokenizer=None, 
                vocabulary={0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 
                            8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 
                            15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 
                            21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 
                            27: 27, 28: 28, 29: 29, ...})&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">pp.pformat(vectorizer) == expected</span>

    <span class="s2"># Also test with lists</span>
    <span class="s1">param_grid = {</span><span class="s3">&quot;C&quot;</span><span class="s1">: list(range(n_max_elements_to_show))}</span>
    <span class="s1">gs = GridSearchCV(SVC()</span><span class="s0">, </span><span class="s1">param_grid)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
GridSearchCV(cv='warn', error_score='raise-deprecating', 
             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, 
                           decision_function_shape='ovr', degree=3, 
                           gamma='auto_deprecated', kernel='rbf', max_iter=-1, 
                           probability=False, random_state=None, shrinking=True, 
                           tol=0.001, verbose=False), 
             iid='warn', n_jobs=None, 
             param_grid={'C': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 
                               15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 
                               27, 28, 29]}, 
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False, 
             scoring=None, verbose=0)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">pp.pformat(gs) == expected</span>

    <span class="s2"># Now with ellipsis</span>
    <span class="s1">param_grid = {</span><span class="s3">&quot;C&quot;</span><span class="s1">: list(range(n_max_elements_to_show + </span><span class="s4">1</span><span class="s1">))}</span>
    <span class="s1">gs = GridSearchCV(SVC()</span><span class="s0">, </span><span class="s1">param_grid)</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
GridSearchCV(cv='warn', error_score='raise-deprecating', 
             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, 
                           decision_function_shape='ovr', degree=3, 
                           gamma='auto_deprecated', kernel='rbf', max_iter=-1, 
                           probability=False, random_state=None, shrinking=True, 
                           tol=0.001, verbose=False), 
             iid='warn', n_jobs=None, 
             param_grid={'C': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 
                               15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 
                               27, 28, 29, ...]}, 
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False, 
             scoring=None, verbose=0)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">pp.pformat(gs) == expected</span>


<span class="s0">def </span><span class="s1">test_bruteforce_ellipsis(print_changed_only_false):</span>
    <span class="s2"># Check that the bruteforce ellipsis (used when the number of non-blank</span>
    <span class="s2"># characters exceeds N_CHAR_MAX) renders correctly.</span>

    <span class="s1">lr = LogisticRegression()</span>

    <span class="s2"># test when the left and right side of the ellipsis aren't on the same</span>
    <span class="s2"># line.</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, 
                   in... 
                   multi_class='warn', n_jobs=None, penalty='l2', 
                   random_state=None, solver='warn', tol=0.0001, verbose=0, 
                   warm_start=False)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">expected == lr.__repr__(N_CHAR_MAX=</span><span class="s4">150</span><span class="s1">)</span>

    <span class="s2"># test with very small N_CHAR_MAX</span>
    <span class="s2"># Note that N_CHAR_MAX is not strictly enforced, but it's normal: to avoid</span>
    <span class="s2"># weird reprs we still keep the whole line of the right part (after the</span>
    <span class="s2"># ellipsis).</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
Lo... 
                   warm_start=False)&quot;&quot;&quot;</span>

    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">expected == lr.__repr__(N_CHAR_MAX=</span><span class="s4">4</span><span class="s1">)</span>

    <span class="s2"># test with N_CHAR_MAX == number of non-blank characters: In this case we</span>
    <span class="s2"># don't want ellipsis</span>
    <span class="s1">full_repr = lr.__repr__(N_CHAR_MAX=float(</span><span class="s3">&quot;inf&quot;</span><span class="s1">))</span>
    <span class="s1">n_nonblank = len(</span><span class="s3">&quot;&quot;</span><span class="s1">.join(full_repr.split()))</span>
    <span class="s0">assert </span><span class="s1">lr.__repr__(N_CHAR_MAX=n_nonblank) == full_repr</span>
    <span class="s0">assert </span><span class="s3">&quot;...&quot; </span><span class="s0">not in </span><span class="s1">full_repr</span>

    <span class="s2"># test with N_CHAR_MAX == number of non-blank characters - 10: the left and</span>
    <span class="s2"># right side of the ellispsis are on different lines. In this case we</span>
    <span class="s2"># want to expend the whole line of the right side</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, 
                   intercept_scaling=1, l1_ratio=None, max_i... 
                   multi_class='warn', n_jobs=None, penalty='l2', 
                   random_state=None, solver='warn', tol=0.0001, verbose=0, 
                   warm_start=False)&quot;&quot;&quot;</span>
    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">expected == lr.__repr__(N_CHAR_MAX=n_nonblank - </span><span class="s4">10</span><span class="s1">)</span>

    <span class="s2"># test with N_CHAR_MAX == number of non-blank characters - 10: the left and</span>
    <span class="s2"># right side of the ellispsis are on the same line. In this case we don't</span>
    <span class="s2"># want to expend the whole line of the right side, just add the ellispsis</span>
    <span class="s2"># between the 2 sides.</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, 
                   intercept_scaling=1, l1_ratio=None, max_iter..., 
                   multi_class='warn', n_jobs=None, penalty='l2', 
                   random_state=None, solver='warn', tol=0.0001, verbose=0, 
                   warm_start=False)&quot;&quot;&quot;</span>
    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">expected == lr.__repr__(N_CHAR_MAX=n_nonblank - </span><span class="s4">4</span><span class="s1">)</span>

    <span class="s2"># test with N_CHAR_MAX == number of non-blank characters - 2: the left and</span>
    <span class="s2"># right side of the ellispsis are on the same line, but adding the ellipsis</span>
    <span class="s2"># would actually make the repr longer. So we don't add the ellipsis.</span>
    <span class="s1">expected = </span><span class="s3">&quot;&quot;&quot; 
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, 
                   intercept_scaling=1, l1_ratio=None, max_iter=100, 
                   multi_class='warn', n_jobs=None, penalty='l2', 
                   random_state=None, solver='warn', tol=0.0001, verbose=0, 
                   warm_start=False)&quot;&quot;&quot;</span>
    <span class="s1">expected = expected[</span><span class="s4">1</span><span class="s1">:]  </span><span class="s2"># remove first \n</span>
    <span class="s0">assert </span><span class="s1">expected == lr.__repr__(N_CHAR_MAX=n_nonblank - </span><span class="s4">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_builtin_prettyprinter():</span>
    <span class="s2"># non regression test than ensures we can still use the builtin</span>
    <span class="s2"># PrettyPrinter class for estimators (as done e.g. by joblib).</span>
    <span class="s2"># Used to be a bug</span>

    <span class="s1">PrettyPrinter().pprint(LogisticRegression())</span>


<span class="s0">def </span><span class="s1">test_kwargs_in_init():</span>
    <span class="s2"># Make sure the changed_only=True mode is OK when an argument is passed as</span>
    <span class="s2"># kwargs.</span>
    <span class="s2"># Non-regression test for</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/17206</span>

    <span class="s0">class </span><span class="s1">WithKWargs(BaseEstimator):</span>
        <span class="s2"># Estimator with a kwargs argument. These need to hack around</span>
        <span class="s2"># set_params and get_params. Here we mimic what LightGBM does.</span>
        <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">a=</span><span class="s3">&quot;willchange&quot;</span><span class="s0">, </span><span class="s1">b=</span><span class="s3">&quot;unchanged&quot;</span><span class="s0">, </span><span class="s1">**kwargs):</span>
            <span class="s1">self.a = a</span>
            <span class="s1">self.b = b</span>
            <span class="s1">self._other_params = {}</span>
            <span class="s1">self.set_params(**kwargs)</span>

        <span class="s0">def </span><span class="s1">get_params(self</span><span class="s0">, </span><span class="s1">deep=</span><span class="s0">True</span><span class="s1">):</span>
            <span class="s1">params = super().get_params(deep=deep)</span>
            <span class="s1">params.update(self._other_params)</span>
            <span class="s0">return </span><span class="s1">params</span>

        <span class="s0">def </span><span class="s1">set_params(self</span><span class="s0">, </span><span class="s1">**params):</span>
            <span class="s0">for </span><span class="s1">key</span><span class="s0">, </span><span class="s1">value </span><span class="s0">in </span><span class="s1">params.items():</span>
                <span class="s1">setattr(self</span><span class="s0">, </span><span class="s1">key</span><span class="s0">, </span><span class="s1">value)</span>
                <span class="s1">self._other_params[key] = value</span>
            <span class="s0">return </span><span class="s1">self</span>

    <span class="s1">est = WithKWargs(a=</span><span class="s3">&quot;something&quot;</span><span class="s0">, </span><span class="s1">c=</span><span class="s3">&quot;abcd&quot;</span><span class="s0">, </span><span class="s1">d=</span><span class="s0">None</span><span class="s1">)</span>

    <span class="s1">expected = </span><span class="s3">&quot;WithKWargs(a='something', c='abcd', d=None)&quot;</span>
    <span class="s0">assert </span><span class="s1">expected == est.__repr__()</span>

    <span class="s0">with </span><span class="s1">config_context(print_changed_only=</span><span class="s0">False</span><span class="s1">):</span>
        <span class="s1">expected = </span><span class="s3">&quot;WithKWargs(a='something', b='unchanged', c='abcd', d=None)&quot;</span>
        <span class="s0">assert </span><span class="s1">expected == est.__repr__()</span>


<span class="s0">def </span><span class="s1">test_complexity_print_changed_only():</span>
    <span class="s2"># Make sure `__repr__` is called the same amount of times</span>
    <span class="s2"># whether `print_changed_only` is True or False</span>
    <span class="s2"># Non-regression test for</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/18490</span>

    <span class="s0">class </span><span class="s1">DummyEstimator(TransformerMixin</span><span class="s0">, </span><span class="s1">BaseEstimator):</span>
        <span class="s1">nb_times_repr_called = </span><span class="s4">0</span>

        <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">estimator=</span><span class="s0">None</span><span class="s1">):</span>
            <span class="s1">self.estimator = estimator</span>

        <span class="s0">def </span><span class="s1">__repr__(self):</span>
            <span class="s1">DummyEstimator.nb_times_repr_called += </span><span class="s4">1</span>
            <span class="s0">return </span><span class="s1">super().__repr__()</span>

        <span class="s0">def </span><span class="s1">transform(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">None</span><span class="s1">):  </span><span class="s2"># pragma: no cover</span>
            <span class="s0">return </span><span class="s1">X</span>

    <span class="s1">estimator = DummyEstimator(</span>
        <span class="s1">make_pipeline(DummyEstimator(DummyEstimator())</span><span class="s0">, </span><span class="s1">DummyEstimator()</span><span class="s0">, </span><span class="s3">&quot;passthrough&quot;</span><span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">config_context(print_changed_only=</span><span class="s0">False</span><span class="s1">):</span>
        <span class="s1">repr(estimator)</span>
        <span class="s1">nb_repr_print_changed_only_false = DummyEstimator.nb_times_repr_called</span>

    <span class="s1">DummyEstimator.nb_times_repr_called = </span><span class="s4">0</span>
    <span class="s0">with </span><span class="s1">config_context(print_changed_only=</span><span class="s0">True</span><span class="s1">):</span>
        <span class="s1">repr(estimator)</span>
        <span class="s1">nb_repr_print_changed_only_true = DummyEstimator.nb_times_repr_called</span>

    <span class="s0">assert </span><span class="s1">nb_repr_print_changed_only_false == nb_repr_print_changed_only_true</span>
</pre>
</body>
</html>
<html>
<head>
<title>example_gls.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
example_gls.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Example: scikis.statsmodels.GLS 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">scikits.statsmodels </span><span class="s2">as </span><span class="s1">sm</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s1">data = sm.datasets.longley.Load()</span>
<span class="s1">data.exog = sm.add_constant(data.exog)</span>

<span class="s3"># The Longley dataset is a time series dataset</span>
<span class="s3"># Let's assume that the data is heteroskedastic and that we know</span>
<span class="s3"># the nature of the heteroskedasticity.  We can then define</span>
<span class="s3"># `sigma` and use it to give us a GLS model</span>

<span class="s3"># First we will obtain the residuals from an OLS fit</span>

<span class="s1">ols_resid = sm.OLS(data.endog</span><span class="s2">, </span><span class="s1">data.exog).fit().resid</span>

<span class="s3"># Assume that the error terms follow an AR(1) process with a trend</span>
<span class="s3"># resid[i] = beta_0 + rho*resid[i-1] + e[i]</span>
<span class="s3"># where e ~ N(0,some_sigma**2)</span>
<span class="s3"># and that rho is simply the correlation of the residuals</span>
<span class="s3"># a consistent estimator for rho is to regress the residuals</span>
<span class="s3"># on the lagged residuals</span>

<span class="s1">resid_fit = sm.OLS(ols_resid[</span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">sm.add_constant(ols_resid[:-</span><span class="s4">1</span><span class="s1">])).fit()</span>
<span class="s1">print resid_fit.t(</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">print resid_fit.pvalues[</span><span class="s4">0</span><span class="s1">]</span>
<span class="s3"># While we don't have strong evidence that the errors follow an AR(1)</span>
<span class="s3"># process we continue</span>

<span class="s1">rho = resid_fit.params[</span><span class="s4">0</span><span class="s1">]</span>

<span class="s3"># As we know, an AR(1) process means that near-neighbors have a stronger</span>
<span class="s3"># relation so we can give this structure by using a toeplitz matrix</span>

<span class="s2">from </span><span class="s1">scipy.linalg </span><span class="s2">import </span><span class="s1">toeplitz</span>

<span class="s3"># # for example</span>
<span class="s3"># &gt;&gt;&gt; toeplitz(range(5))</span>
<span class="s3"># array([[0, 1, 2, 3, 4],</span>
<span class="s3">#       [1, 0, 1, 2, 3],</span>
<span class="s3">#       [2, 1, 0, 1, 2],</span>
<span class="s3">#       [3, 2, 1, 0, 1],</span>
<span class="s3">#       [4, 3, 2, 1, 0]])</span>

<span class="s1">order = toeplitz(range(len(ols_resid)))</span>

<span class="s3"># so that our error covariance structure is actually rho**order</span>
<span class="s3"># which defines an autocorrelation structure</span>

<span class="s1">sigma = rho**order</span>

<span class="s1">gls_model = sm.GLS(data.endog</span><span class="s2">, </span><span class="s1">data.exog</span><span class="s2">, </span><span class="s1">sigma=sigma)</span>
<span class="s1">gls_results = gls_model.fit()</span>

<span class="s3"># of course, the exact rho in this instance is not known so it </span>
<span class="s3"># it might make more sense to use feasible gls, which currently only</span>
<span class="s3"># has experimental support</span>

<span class="s3"># We can use the GLSAR model with one lag, to get to a similar result</span>

<span class="s1">glsar_model = sm.GLSAR(data.endog</span><span class="s2">, </span><span class="s1">data.exog</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">glsar_results = glsar_model.iterative_fit(</span><span class="s4">1</span><span class="s1">)</span>

<span class="s3"># comparing gls and glsar results, we see that there are some small</span>
<span class="s3"># differences in the parameter estimates and the resulting standard</span>
<span class="s3"># errors of the parameter estimate. This might be do to the numerical</span>
<span class="s3"># differences in the algorithm, e.g. the treatment of initial conditions,</span>
<span class="s3"># because of the small number of observations in the longley dataset.</span>
<span class="s1">print gls_results.params</span>
<span class="s1">print glsar_results.params</span>
<span class="s1">print gls_results.bse</span>
<span class="s1">print glsar_results.bse</span>

</pre>
</body>
</html>
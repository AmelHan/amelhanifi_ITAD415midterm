<html>
<head>
<title>test_representation.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_representation.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for python wrapper of state space representation and filtering 
 
Author: Chad Fulton 
License: Simplified-BSD 
 
References 
---------- 
 
Kim, Chang-Jin, and Charles R. Nelson. 1999. 
&quot;State-Space Models with Regime Switching: 
Classical and Gibbs-Sampling Approaches with Applications&quot;. 
MIT Press Books. The MIT Press. 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.representation </span><span class="s2">import </span><span class="s1">Representation</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.kalman_filter </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">KalmanFilter</span><span class="s2">, </span><span class="s1">FilterResults</span><span class="s2">, </span><span class="s1">PredictionResults)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.simulation_smoother </span><span class="s2">import </span><span class="s1">SimulationSmoother</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace </span><span class="s2">import </span><span class="s1">tools</span><span class="s2">, </span><span class="s1">sarimax</span>
<span class="s2">from </span><span class="s1">.results </span><span class="s2">import </span><span class="s1">results_kalman_filter</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">assert_equal</span><span class="s2">, </span><span class="s1">assert_almost_equal</span><span class="s2">, </span><span class="s1">assert_raises</span><span class="s2">, </span><span class="s1">assert_allclose)</span>

<span class="s1">current_path = os.path.dirname(os.path.abspath(__file__))</span>

<span class="s1">clark1989_path = os.path.join(</span><span class="s3">'results'</span><span class="s2">, </span><span class="s3">'results_clark1989_R.csv'</span><span class="s1">)</span>
<span class="s1">clark1989_results = pd.read_csv(os.path.join(current_path</span><span class="s2">, </span><span class="s1">clark1989_path))</span>


<span class="s2">class </span><span class="s1">Clark1987:</span>
    <span class="s0">&quot;&quot;&quot; 
    Clark's (1987) univariate unobserved components model of real GDP (as 
    presented in Kim and Nelson, 1999) 
 
    Test data produced using GAUSS code described in Kim and Nelson (1999) and 
    found at http://econ.korea.ac.kr/~cjkim/SSMARKOV.htm 
 
    See `results.results_kalman_filter` for more information. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls</span><span class="s2">, </span><span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">cls.true = results_kalman_filter.uc_uni</span>
        <span class="s1">cls.true_states = pd.DataFrame(cls.true[</span><span class="s3">'states'</span><span class="s1">])</span>

        <span class="s4"># GDP, Quarterly, 1947.1 - 1995.3</span>
        <span class="s1">data = pd.DataFrame(</span>
            <span class="s1">cls.true[</span><span class="s3">'data'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">index=pd.date_range(</span><span class="s3">'1947-01-01'</span><span class="s2">, </span><span class="s3">'1995-07-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s3">'QS'</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">columns=[</span><span class="s3">'GDP'</span><span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s1">data[</span><span class="s3">'lgdp'</span><span class="s1">] = np.log(data[</span><span class="s3">'GDP'</span><span class="s1">])</span>

        <span class="s4"># Construct the statespace representation</span>
        <span class="s1">k_states = </span><span class="s5">4</span>
        <span class="s1">cls.model = KalmanFilter(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">cls.model.bind(data[</span><span class="s3">'lgdp'</span><span class="s1">].values)</span>

        <span class="s1">cls.model.design[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">cls.model.transition[([</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">,</span>
                              <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">,</span>
                              <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])] = [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">cls.model.selection = np.eye(cls.model.k_states)</span>

        <span class="s4"># Update matrices with given parameters</span>
        <span class="s1">(sigma_v</span><span class="s2">, </span><span class="s1">sigma_e</span><span class="s2">, </span><span class="s1">sigma_w</span><span class="s2">, </span><span class="s1">phi_1</span><span class="s2">, </span><span class="s1">phi_2) = np.array(</span>
            <span class="s1">cls.true[</span><span class="s3">'parameters'</span><span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.transition[([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])] = [phi_1</span><span class="s2">, </span><span class="s1">phi_2]</span>
        <span class="s1">cls.model.state_cov[</span>
            <span class="s1">np.diag_indices(k_states)+(np.zeros(k_states</span><span class="s2">, </span><span class="s1">dtype=int)</span><span class="s2">,</span><span class="s1">)] = [</span>
            <span class="s1">sigma_v**</span><span class="s5">2</span><span class="s2">, </span><span class="s1">sigma_e**</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">sigma_w**</span><span class="s5">2</span>
        <span class="s1">]</span>

        <span class="s4"># Initialization</span>
        <span class="s1">initial_state = np.zeros((k_states</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s1">initial_state_cov = np.eye(k_states)*</span><span class="s5">100</span>

        <span class="s4"># Initialization: modification</span>
        <span class="s1">initial_state_cov = np.dot(</span>
            <span class="s1">np.dot(cls.model.transition[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">initial_state_cov)</span><span class="s2">,</span>
            <span class="s1">cls.model.transition[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">].T</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">run_filter(cls):</span>
        <span class="s4"># Filter the data</span>
        <span class="s2">return </span><span class="s1">cls.model.filter()</span>

    <span class="s2">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.llf_obs[self.true[</span><span class="s3">'start'</span><span class="s1">]:].sum()</span><span class="s2">,</span>
            <span class="s1">self.true[</span><span class="s3">'loglike'</span><span class="s1">]</span><span class="s2">, </span><span class="s5">5</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">3</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1987Single(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic single precision test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">pytest.skip(</span><span class="s3">'Not implemented'</span><span class="s1">)</span>
        <span class="s1">super(TestClark1987Single</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=np.float32</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987Double(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double precision test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987Double</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s1">@pytest.mark.skip(</span><span class="s3">'Not implemented'</span><span class="s1">)</span>
<span class="s2">class </span><span class="s1">TestClark1987SingleComplex(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic single precision complex test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987SingleComplex</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=np.complex64</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987DoubleComplex(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double precision complex test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987DoubleComplex</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=complex</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987Conserve(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987Conserve</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">Clark1987Forecast(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Forecasting test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls</span><span class="s2">, </span><span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">nforecast=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span><span class="s1">):</span>
        <span class="s1">super(Clark1987Forecast</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">conserve_memory=conserve_memory</span>
        <span class="s1">)</span>
        <span class="s1">cls.nforecast = nforecast</span>

        <span class="s4"># Add missing observations to the end (to forecast)</span>
        <span class="s1">cls.model.endog = np.array(</span>
            <span class="s1">np.r_[cls.model.endog[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">[np.nan]*nforecast]</span><span class="s2">,</span>
            <span class="s1">ndmin=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">order=</span><span class="s3">&quot;F&quot;</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.nobs = cls.model.endog.shape[</span><span class="s5">1</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">3</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1987ForecastDouble(Clark1987Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double forecasting test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987ForecastDouble</span><span class="s2">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987ForecastDoubleComplex(Clark1987Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double complex forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987ForecastDoubleComplex</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=complex</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987ForecastConserve(Clark1987Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987ForecastConserve</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1987ConserveAll(Clark1987):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1987ConserveAll</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02 </span><span class="s1">| </span><span class="s5">0x04 </span><span class="s1">| </span><span class="s5">0x08</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.loglikelihood_burn = cls.true[</span><span class="s3">'start'</span><span class="s1">]</span>
        <span class="s1">cls.results = cls.run_filter()</span>

    <span class="s2">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.llf</span><span class="s2">, </span><span class="s1">self.true[</span><span class="s3">'loglike'</span><span class="s1">]</span><span class="s2">, </span><span class="s5">5</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">end = self.true_states.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">Clark1989:</span>
    <span class="s0">&quot;&quot;&quot; 
    Clark's (1989) bivariate unobserved components model of real GDP (as 
    presented in Kim and Nelson, 1999) 
 
    Tests two-dimensional observation data. 
 
    Test data produced using GAUSS code described in Kim and Nelson (1999) and 
    found at http://econ.korea.ac.kr/~cjkim/SSMARKOV.htm 
 
    See `results.results_kalman_filter` for more information. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls</span><span class="s2">, </span><span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">cls.true = results_kalman_filter.uc_bi</span>
        <span class="s1">cls.true_states = pd.DataFrame(cls.true[</span><span class="s3">'states'</span><span class="s1">])</span>

        <span class="s4"># GDP and Unemployment, Quarterly, 1948.1 - 1995.3</span>
        <span class="s1">data = pd.DataFrame(</span>
            <span class="s1">cls.true[</span><span class="s3">'data'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">index=pd.date_range(</span><span class="s3">'1947-01-01'</span><span class="s2">, </span><span class="s3">'1995-07-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s3">'QS'</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">columns=[</span><span class="s3">'GDP'</span><span class="s2">, </span><span class="s3">'UNEMP'</span><span class="s1">]</span>
        <span class="s1">)[</span><span class="s5">4</span><span class="s1">:]</span>
        <span class="s1">data[</span><span class="s3">'GDP'</span><span class="s1">] = np.log(data[</span><span class="s3">'GDP'</span><span class="s1">])</span>
        <span class="s1">data[</span><span class="s3">'UNEMP'</span><span class="s1">] = (data[</span><span class="s3">'UNEMP'</span><span class="s1">]/</span><span class="s5">100</span><span class="s1">)</span>

        <span class="s1">k_states = </span><span class="s5">6</span>
        <span class="s1">cls.model = KalmanFilter(k_endog=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">cls.model.bind(np.ascontiguousarray(data.values))</span>

        <span class="s4"># Statespace representation</span>
        <span class="s1">cls.model.design[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = [[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]]</span>
        <span class="s1">cls.model.transition[</span>
            <span class="s1">([</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">5</span><span class="s1">]</span><span class="s2">,</span>
             <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">5</span><span class="s1">]</span><span class="s2">,</span>
             <span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">] = [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">cls.model.selection = np.eye(cls.model.k_states)</span>

        <span class="s4"># Update matrices with given parameters</span>
        <span class="s1">(sigma_v</span><span class="s2">, </span><span class="s1">sigma_e</span><span class="s2">, </span><span class="s1">sigma_w</span><span class="s2">, </span><span class="s1">sigma_vl</span><span class="s2">, </span><span class="s1">sigma_ec</span><span class="s2">,</span>
         <span class="s1">phi_1</span><span class="s2">, </span><span class="s1">phi_2</span><span class="s2">, </span><span class="s1">alpha_1</span><span class="s2">, </span><span class="s1">alpha_2</span><span class="s2">, </span><span class="s1">alpha_3) = np.array(</span>
            <span class="s1">cls.true[</span><span class="s3">'parameters'</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.design[([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])] = [</span>
            <span class="s1">alpha_1</span><span class="s2">, </span><span class="s1">alpha_2</span><span class="s2">, </span><span class="s1">alpha_3</span>
        <span class="s1">]</span>
        <span class="s1">cls.model.transition[([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])] = [phi_1</span><span class="s2">, </span><span class="s1">phi_2]</span>
        <span class="s1">cls.model.obs_cov[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = sigma_ec**</span><span class="s5">2</span>
        <span class="s1">cls.model.state_cov[</span>
            <span class="s1">np.diag_indices(k_states)+(np.zeros(k_states</span><span class="s2">, </span><span class="s1">dtype=int)</span><span class="s2">,</span><span class="s1">)] = [</span>
            <span class="s1">sigma_v**</span><span class="s5">2</span><span class="s2">, </span><span class="s1">sigma_e**</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">sigma_w**</span><span class="s5">2</span><span class="s2">, </span><span class="s1">sigma_vl**</span><span class="s5">2</span>
        <span class="s1">]</span>

        <span class="s4"># Initialization</span>
        <span class="s1">initial_state = np.zeros((k_states</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s1">initial_state_cov = np.eye(k_states)*</span><span class="s5">100</span>

        <span class="s4"># Initialization: cls.modelification</span>
        <span class="s1">initial_state_cov = np.dot(</span>
            <span class="s1">np.dot(cls.model.transition[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">initial_state_cov)</span><span class="s2">,</span>
            <span class="s1">cls.model.transition[:</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">].T</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">run_filter(cls):</span>
        <span class="s4"># Filter the data</span>
        <span class="s2">return </span><span class="s1">cls.model.filter()</span>

    <span class="s2">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s4"># self.results.llf_obs[self.true['start']:].sum(),</span>
            <span class="s1">self.results.llf_obs[</span><span class="s5">0</span><span class="s1">:].sum()</span><span class="s2">,</span>
            <span class="s1">self.true[</span><span class="s3">'loglike'</span><span class="s1">]</span><span class="s2">, </span><span class="s5">2</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">4</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">5</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1989(Clark1989):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double precision test for the loglikelihood and filtered 
    states with two-dimensional observation vector. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989</span><span class="s2">, </span><span class="s1">cls).setup_class(dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>

    <span class="s2">def </span><span class="s1">test_kalman_gain(self):</span>
        <span class="s1">assert_allclose(self.results.kalman_gain.sum(axis=</span><span class="s5">1</span><span class="s1">).sum(axis=</span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                        <span class="s1">clark1989_results[</span><span class="s3">'V1'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-4</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1989Conserve(Clark1989):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation test for the loglikelihood and filtered states with 
    two-dimensional observation vector. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989Conserve</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">Clark1989Forecast(Clark1989):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation test for the loglikelihood and filtered states with 
    two-dimensional observation vector. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls</span><span class="s2">, </span><span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">nforecast=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0</span><span class="s1">):</span>
        <span class="s1">super(Clark1989Forecast</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">conserve_memory=conserve_memory</span>
        <span class="s1">)</span>
        <span class="s1">cls.nforecast = nforecast</span>

        <span class="s4"># Add missing observations to the end (to forecast)</span>
        <span class="s1">cls.model.endog = np.array(</span>
            <span class="s1">np.c_[</span>
                <span class="s1">cls.model.endog</span><span class="s2">,</span>
                <span class="s1">np.r_[[np.nan</span><span class="s2">, </span><span class="s1">np.nan]*nforecast].reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">nforecast)</span>
            <span class="s1">]</span><span class="s2">,</span>
            <span class="s1">ndmin=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">order=</span><span class="s3">&quot;F&quot;</span>
        <span class="s1">)</span>
        <span class="s1">cls.model.nobs = cls.model.endog.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">cls.results = cls.run_filter()</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">4</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">5</span><span class="s1">][self.true[</span><span class="s3">'start'</span><span class="s1">]:-self.nforecast]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[:</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1989ForecastDouble(Clark1989Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double forecasting test for the loglikelihood and filtered states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989ForecastDouble</span><span class="s2">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1989ForecastDoubleComplex(Clark1989Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Basic double complex forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989ForecastDoubleComplex</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=complex</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1989ForecastConserve(Clark1989Forecast):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989ForecastConserve</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02</span>
        <span class="s1">)</span>
        <span class="s1">cls.results = cls.run_filter()</span>


<span class="s2">class </span><span class="s1">TestClark1989ConserveAll(Clark1989):</span>
    <span class="s0">&quot;&quot;&quot; 
    Memory conservation forecasting test for the loglikelihood and filtered 
    states. 
    &quot;&quot;&quot;</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989ConserveAll</span><span class="s2">, </span><span class="s1">cls).setup_class(</span>
            <span class="s1">dtype=float</span><span class="s2">, </span><span class="s1">conserve_memory=</span><span class="s5">0x01 </span><span class="s1">| </span><span class="s5">0x02 </span><span class="s1">| </span><span class="s5">0x04 </span><span class="s1">| </span><span class="s5">0x08</span>
        <span class="s1">)</span>
        <span class="s4"># cls.model.loglikelihood_burn = cls.true['start']</span>
        <span class="s1">cls.model.loglikelihood_burn = </span><span class="s5">0</span>
        <span class="s1">cls.results = cls.run_filter()</span>

    <span class="s2">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.llf</span><span class="s2">, </span><span class="s1">self.true[</span><span class="s3">'loglike'</span><span class="s1">]</span><span class="s2">, </span><span class="s5">2</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s1">end = self.true_states.shape[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">0</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">1</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">4</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.results.filtered_state[</span><span class="s5">5</span><span class="s1">][-</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">self.true_states.iloc[end-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s5">4</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">TestClark1989PartialMissing(Clark1989):</span>
    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestClark1989PartialMissing</span><span class="s2">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">endog = cls.model.endog</span>
        <span class="s1">endog[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">51</span><span class="s1">:] = np.NaN</span>
        <span class="s1">cls.model.bind(endog)</span>

        <span class="s1">cls.results = cls.run_filter()</span>

    <span class="s2">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_allclose(self.results.llf_obs[</span><span class="s5">0</span><span class="s1">:].sum()</span><span class="s2">, </span><span class="s5">1232.113456</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_filtered_state(self):</span>
        <span class="s4"># Could do this, but no need really.</span>
        <span class="s2">pass</span>

    <span class="s2">def </span><span class="s1">test_predicted_state(self):</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">self.results.predicted_state.T[</span><span class="s5">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">clark1989_results.iloc[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">:]</span><span class="s2">,</span>
            <span class="s1">atol=</span><span class="s5">1e-8</span>
        <span class="s1">)</span>


<span class="s4"># Miscellaneous coverage-related tests</span>
<span class="s2">def </span><span class="s1">test_slice_notation():</span>
    <span class="s4"># Test setting and getting state space representation matrices using the</span>
    <span class="s4"># slice notation.</span>

    <span class="s1">endog = np.arange(</span><span class="s5">10</span><span class="s1">)*</span><span class="s5">1.0</span>
    <span class="s1">mod = KalmanFilter(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod.bind(endog)</span>

    <span class="s4"># Test invalid __setitem__</span>
    <span class="s2">def </span><span class="s1">set_designs():</span>
        <span class="s1">mod[</span><span class="s3">'designs'</span><span class="s1">] = </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">set_designs2():</span>
        <span class="s1">mod[</span><span class="s3">'designs'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">set_designs3():</span>
        <span class="s1">mod[</span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>

    <span class="s1">assert_raises(IndexError</span><span class="s2">, </span><span class="s1">set_designs)</span>
    <span class="s1">assert_raises(IndexError</span><span class="s2">, </span><span class="s1">set_designs2)</span>
    <span class="s1">assert_raises(IndexError</span><span class="s2">, </span><span class="s1">set_designs3)</span>

    <span class="s4"># Test invalid __getitem__</span>
    <span class="s1">assert_raises(IndexError</span><span class="s2">, lambda</span><span class="s1">: mod[</span><span class="s3">'designs'</span><span class="s1">])</span>
    <span class="s1">assert_raises(IndexError</span><span class="s2">, lambda</span><span class="s1">: mod[</span><span class="s3">'designs'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">assert_raises(IndexError</span><span class="s2">, lambda</span><span class="s1">: mod[</span><span class="s5">0</span><span class="s1">])</span>

    <span class="s4"># Test valid __setitem__, __getitem__</span>
    <span class="s1">assert_equal(mod.design[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">assert_equal(mod[</span><span class="s3">'design'</span><span class="s1">].sum()</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.design[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Test valid __setitem__, __getitem__ with unspecified time index</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s1">] = np.zeros(mod[</span><span class="s3">'design'</span><span class="s1">].shape)</span>
    <span class="s1">assert_equal(mod.design[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">assert_equal(mod.design[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_representation():</span>
    <span class="s4"># Test Representation construction</span>

    <span class="s4"># Test an invalid number of states</span>
    <span class="s2">def </span><span class="s1">zero_kstates():</span>
        <span class="s1">Representation(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">zero_kstates)</span>

    <span class="s4"># Test an invalid endogenous array</span>
    <span class="s2">def </span><span class="s1">empty_endog():</span>
        <span class="s1">endog = np.zeros((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
        <span class="s1">Representation(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">empty_endog)</span>

    <span class="s4"># Test a Fortran-ordered endogenous array (which will be assumed to be in</span>
    <span class="s4"># wide format: k_endog x nobs)</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">arr = np.arange(nobs*k_endog).reshape(k_endog</span><span class="s2">, </span><span class="s1">nobs)*</span><span class="s5">1.</span>
    <span class="s1">endog = np.asfortranarray(arr)</span>
    <span class="s1">mod = Representation(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.nobs</span><span class="s2">, </span><span class="s1">nobs)</span>
    <span class="s1">assert_equal(mod.k_endog</span><span class="s2">, </span><span class="s1">k_endog)</span>

    <span class="s4"># Test a C-ordered endogenous array (which will be assumed to be in</span>
    <span class="s4"># tall format: nobs x k_endog)</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">endog = np.arange(nobs*k_endog).reshape(nobs</span><span class="s2">, </span><span class="s1">k_endog)*</span><span class="s5">1.</span>
    <span class="s1">mod = Representation(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.nobs</span><span class="s2">, </span><span class="s1">nobs)</span>
    <span class="s1">assert_equal(mod.k_endog</span><span class="s2">, </span><span class="s1">k_endog)</span>

    <span class="s4"># Test getting the statespace representation</span>
    <span class="s1">assert_equal(mod._statespace</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">mod._initialize_representation()</span>
    <span class="s1">assert_equal(mod._statespace </span><span class="s2">is not None, True</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_bind():</span>
    <span class="s4"># Test binding endogenous data to Kalman filter</span>

    <span class="s1">mod = Representation(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s4"># Test invalid endogenous array (it must be ndarray)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, lambda</span><span class="s1">: mod.bind([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]))</span>

    <span class="s4"># Test valid (nobs x 1) endogenous array</span>
    <span class="s1">mod.bind(np.arange(</span><span class="s5">10</span><span class="s1">).reshape((</span><span class="s5">5</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))*</span><span class="s5">1.</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.nobs</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span>

    <span class="s4"># Test valid (k_endog x 0) endogenous array</span>
    <span class="s1">mod.bind(np.zeros((</span><span class="s5">0</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.float64))</span>

    <span class="s4"># Test invalid (3-dim) endogenous array</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">mod.bind(np.arange(</span><span class="s5">12</span><span class="s1">).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)*</span><span class="s5">1.</span><span class="s1">)</span>

    <span class="s4"># Test valid F-contiguous</span>
    <span class="s1">mod.bind(np.asfortranarray(np.arange(</span><span class="s5">10</span><span class="s1">).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)))</span>
    <span class="s1">assert_equal(mod.nobs</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span>

    <span class="s4"># Test valid C-contiguous</span>
    <span class="s1">mod.bind(np.arange(</span><span class="s5">10</span><span class="s1">).reshape(</span><span class="s5">5</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">assert_equal(mod.nobs</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span>

    <span class="s4"># Test invalid F-contiguous</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">mod.bind(np.asfortranarray(np.arange(</span><span class="s5">10</span><span class="s1">).reshape(</span><span class="s5">5</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)))</span>

    <span class="s4"># Test invalid C-contiguous</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, lambda</span><span class="s1">: mod.bind(np.arange(</span><span class="s5">10</span><span class="s1">).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)))</span>


<span class="s2">def </span><span class="s1">test_initialization():</span>
    <span class="s4"># Test Kalman filter initialization</span>

    <span class="s1">mod = Representation(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s4"># Test invalid state initialization</span>
    <span class="s2">with </span><span class="s1">pytest.raises(RuntimeError):</span>
        <span class="s1">mod._initialize_state()</span>

    <span class="s4"># Test valid initialization</span>
    <span class="s1">initial_state = np.zeros(</span><span class="s5">2</span><span class="s2">,</span><span class="s1">) + </span><span class="s5">1.5</span>
    <span class="s1">initial_state_cov = np.eye(</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">3.</span>
    <span class="s1">mod.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>
    <span class="s1">assert_equal(mod.initialization.constant.sum()</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.initialization.stationary_cov.diagonal().sum()</span><span class="s2">, </span><span class="s5">6</span><span class="s1">)</span>

    <span class="s4"># Test invalid initial_state</span>
    <span class="s1">initial_state = np.zeros(</span><span class="s5">10</span><span class="s2">,</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">mod.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>
    <span class="s1">initial_state = np.zeros((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">mod.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>

    <span class="s4"># Test invalid initial_state_cov</span>
    <span class="s1">initial_state = np.zeros(</span><span class="s5">2</span><span class="s2">,</span><span class="s1">) + </span><span class="s5">1.5</span>
    <span class="s1">initial_state_cov = np.eye(</span><span class="s5">3</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">mod.initialize_known(initial_state</span><span class="s2">, </span><span class="s1">initial_state_cov)</span>


<span class="s2">def </span><span class="s1">test_init_matrices_time_invariant():</span>
    <span class="s4"># Test setting state space system matrices in __init__, with time-invariant</span>
    <span class="s4"># matrices</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">k_states = </span><span class="s5">3</span>
    <span class="s1">k_posdef = </span><span class="s5">1</span>

    <span class="s1">endog = np.zeros((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">obs_intercept = np.arange(k_endog) * </span><span class="s5">1.0</span>
    <span class="s1">design = np.reshape(</span>
        <span class="s1">np.arange(k_endog * k_states) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_states))</span>
    <span class="s1">obs_cov = np.reshape(np.arange(k_endog**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_endog))</span>
    <span class="s1">state_intercept = np.arange(k_states) * </span><span class="s5">1.0</span>
    <span class="s1">transition = np.reshape(np.arange(k_states**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_states))</span>
    <span class="s1">selection = np.reshape(</span>
        <span class="s1">np.arange(k_states * k_posdef) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_posdef))</span>
    <span class="s1">state_cov = np.reshape(np.arange(k_posdef**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_posdef</span><span class="s2">, </span><span class="s1">k_posdef))</span>

    <span class="s1">mod = Representation(endog</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">k_posdef=k_posdef</span><span class="s2">,</span>
                         <span class="s1">obs_intercept=obs_intercept</span><span class="s2">, </span><span class="s1">design=design</span><span class="s2">,</span>
                         <span class="s1">obs_cov=obs_cov</span><span class="s2">, </span><span class="s1">state_intercept=state_intercept</span><span class="s2">,</span>
                         <span class="s1">transition=transition</span><span class="s2">, </span><span class="s1">selection=selection</span><span class="s2">,</span>
                         <span class="s1">state_cov=state_cov)</span>

    <span class="s1">assert_allclose(mod[</span><span class="s3">'obs_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'design'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">design)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'obs_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_cov)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'state_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'transition'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transition)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'selection'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">selection)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'state_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_cov)</span>


<span class="s2">def </span><span class="s1">test_init_matrices_time_varying():</span>
    <span class="s4"># Test setting state space system matrices in __init__, with time-varying</span>
    <span class="s4"># matrices</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">k_states = </span><span class="s5">3</span>
    <span class="s1">k_posdef = </span><span class="s5">1</span>

    <span class="s1">endog = np.zeros((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">obs_intercept = np.reshape(np.arange(k_endog * nobs) * </span><span class="s5">1.0</span><span class="s2">,</span>
                               <span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">design = np.reshape(</span>
        <span class="s1">np.arange(k_endog * k_states * nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">obs_cov = np.reshape(</span>
        <span class="s1">np.arange(k_endog**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_endog</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">state_intercept = np.reshape(</span>
        <span class="s1">np.arange(k_states * nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">transition = np.reshape(</span>
        <span class="s1">np.arange(k_states**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">selection = np.reshape(</span>
        <span class="s1">np.arange(k_states * k_posdef * nobs) * </span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_posdef</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">state_cov = np.reshape(</span>
        <span class="s1">np.arange(k_posdef**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_posdef</span><span class="s2">, </span><span class="s1">k_posdef</span><span class="s2">, </span><span class="s1">nobs))</span>

    <span class="s1">mod = Representation(endog</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">k_posdef=k_posdef</span><span class="s2">,</span>
                         <span class="s1">obs_intercept=obs_intercept</span><span class="s2">, </span><span class="s1">design=design</span><span class="s2">,</span>
                         <span class="s1">obs_cov=obs_cov</span><span class="s2">, </span><span class="s1">state_intercept=state_intercept</span><span class="s2">,</span>
                         <span class="s1">transition=transition</span><span class="s2">, </span><span class="s1">selection=selection</span><span class="s2">,</span>
                         <span class="s1">state_cov=state_cov)</span>

    <span class="s1">assert_allclose(mod[</span><span class="s3">'obs_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'design'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">design)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'obs_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_cov)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'state_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'transition'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transition)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'selection'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">selection)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s3">'state_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_cov)</span>


<span class="s2">def </span><span class="s1">test_no_endog():</span>
    <span class="s4"># Test for RuntimeError when no endog is provided by the time filtering</span>
    <span class="s4"># is initialized.</span>

    <span class="s1">mod = KalmanFilter(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># directly call the _initialize_filter function</span>
    <span class="s1">assert_raises(RuntimeError</span><span class="s2">, </span><span class="s1">mod._initialize_filter)</span>
    <span class="s4"># indirectly call it through filtering</span>
    <span class="s1">mod.initialize_approximate_diffuse()</span>
    <span class="s1">assert_raises(RuntimeError</span><span class="s2">, </span><span class="s1">mod.filter)</span>


<span class="s2">def </span><span class="s1">test_cython():</span>
    <span class="s4"># Test the cython _kalman_filter creation, re-creation, calling, etc.</span>

    <span class="s4"># Check that datatypes are correct:</span>
    <span class="s2">for </span><span class="s1">prefix</span><span class="s2">, </span><span class="s1">dtype </span><span class="s2">in </span><span class="s1">tools.prefix_dtype_map.items():</span>
        <span class="s1">endog = np.array(</span><span class="s5">1.</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
        <span class="s1">mod = KalmanFilter(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>

        <span class="s4"># Bind data and initialize the ?KalmanFilter object</span>
        <span class="s1">mod.bind(endog)</span>
        <span class="s1">mod._initialize_filter()</span>

        <span class="s4"># Check that the dtype and prefix are correct</span>
        <span class="s1">assert_equal(mod.prefix</span><span class="s2">, </span><span class="s1">prefix)</span>
        <span class="s1">assert_equal(mod.dtype</span><span class="s2">, </span><span class="s1">dtype)</span>

        <span class="s4"># Test that a dKalmanFilter instance was created</span>
        <span class="s1">assert_equal(prefix </span><span class="s2">in </span><span class="s1">mod._kalman_filters</span><span class="s2">, True</span><span class="s1">)</span>
        <span class="s1">kf = mod._kalman_filters[prefix]</span>
        <span class="s2">assert </span><span class="s1">isinstance(kf</span><span class="s2">, </span><span class="s1">tools.prefix_kalman_filter_map[prefix])</span>

        <span class="s4"># Test that the default returned _kalman_filter is the above instance</span>
        <span class="s1">assert_equal(mod._kalman_filter</span><span class="s2">, </span><span class="s1">kf)</span>

    <span class="s4"># Check that upcasting datatypes / ?KalmanFilter works (e.g. d -&gt; z)</span>
    <span class="s1">mod = KalmanFilter(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Default dtype is float</span>
    <span class="s1">assert_equal(mod.prefix</span><span class="s2">, </span><span class="s3">'d'</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.dtype</span><span class="s2">, </span><span class="s1">np.float64)</span>

    <span class="s4"># Prior to initialization, no ?KalmanFilter exists</span>
    <span class="s1">assert_equal(mod._kalman_filter</span><span class="s2">, None</span><span class="s1">)</span>

    <span class="s4"># Bind data and initialize the ?KalmanFilter object</span>
    <span class="s1">endog = np.ascontiguousarray(np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=np.float64))</span>
    <span class="s1">mod.bind(endog)</span>
    <span class="s1">mod._initialize_filter()</span>
    <span class="s1">kf = mod._kalman_filters[</span><span class="s3">'d'</span><span class="s1">]</span>

    <span class="s4"># Rebind data, still float, check that we have not changed</span>
    <span class="s1">mod.bind(endog)</span>
    <span class="s1">mod._initialize_filter()</span>
    <span class="s1">assert_equal(mod._kalman_filter</span><span class="s2">, </span><span class="s1">kf)</span>

    <span class="s4"># Force creating new ?Statespace and ?KalmanFilter, by changing the</span>
    <span class="s4"># time-varying character of an array</span>
    <span class="s1">mod.design = np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">mod._initialize_filter()</span>
    <span class="s1">assert_equal(mod._kalman_filter == kf</span><span class="s2">, False</span><span class="s1">)</span>
    <span class="s1">kf = mod._kalman_filters[</span><span class="s3">'d'</span><span class="s1">]</span>

    <span class="s4"># Rebind data, now complex, check that the ?KalmanFilter instance has</span>
    <span class="s4"># changed</span>
    <span class="s1">endog = np.ascontiguousarray(np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=np.complex128))</span>
    <span class="s1">mod.bind(endog)</span>
    <span class="s1">assert_equal(mod._kalman_filter == kf</span><span class="s2">, False</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_filter():</span>
    <span class="s4"># Tests of invalid calls to the filter function</span>

    <span class="s1">endog = np.ones((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod = KalmanFilter(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>

    <span class="s4"># Test default filter results</span>
    <span class="s1">res = mod.filter()</span>
    <span class="s1">assert_equal(isinstance(res</span><span class="s2">, </span><span class="s1">FilterResults)</span><span class="s2">, True</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_loglike():</span>
    <span class="s4"># Tests of invalid calls to the loglike function</span>

    <span class="s1">endog = np.ones((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod = KalmanFilter(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>

    <span class="s4"># Test that self.memory_no_likelihood = True raises an error</span>
    <span class="s1">mod.memory_no_likelihood = </span><span class="s2">True</span>
    <span class="s1">assert_raises(RuntimeError</span><span class="s2">, </span><span class="s1">mod.loglikeobs)</span>


<span class="s2">def </span><span class="s1">test_predict():</span>
    <span class="s4"># Tests of invalid calls to the predict function</span>

    <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;always&quot;</span><span class="s1">)</span>

    <span class="s1">endog = np.ones((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod = KalmanFilter(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_intercept'</span><span class="s1">] = np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>

    <span class="s4"># Check that we need both forecasts and predicted output for dynamic</span>
    <span class="s4"># prediction</span>
    <span class="s1">mod.memory_no_forecast = </span><span class="s2">True</span>
    <span class="s1">res = mod.filter()</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict)</span>
    <span class="s1">mod.memory_no_forecast = </span><span class="s2">False</span>

    <span class="s1">mod.memory_no_predicted = </span><span class="s2">True</span>
    <span class="s1">res = mod.filter()</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">mod.memory_no_predicted = </span><span class="s2">False</span>

    <span class="s4"># Now get a clean filter object</span>
    <span class="s1">res = mod.filter()</span>

    <span class="s4"># Check that start &lt; 0 is an error</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">start=-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Check that end &lt; start is an error</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">start=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">end=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Check that dynamic &lt; 0 is an error</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">dynamic=-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Check that dynamic &gt; end is an warning</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s2">True</span><span class="s1">) </span><span class="s2">as </span><span class="s1">w:</span>
        <span class="s1">res.predict(end=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">message = (</span><span class="s3">'Dynamic prediction specified to begin after the end of'</span>
                   <span class="s3">' prediction, and so has no effect.'</span><span class="s1">)</span>
        <span class="s1">assert_equal(str(w[</span><span class="s5">0</span><span class="s1">].message)</span><span class="s2">, </span><span class="s1">message)</span>

    <span class="s4"># Check that dynamic &gt; nobs is an warning</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s2">True</span><span class="s1">) </span><span class="s2">as </span><span class="s1">w:</span>
        <span class="s1">res.predict(end=</span><span class="s5">11</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s5">11</span><span class="s2">, </span><span class="s1">obs_intercept=np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)))</span>
        <span class="s1">message = (</span><span class="s3">'Dynamic prediction specified to begin during'</span>
                   <span class="s3">' out-of-sample forecasting period, and so has no'</span>
                   <span class="s3">' effect.'</span><span class="s1">)</span>
        <span class="s1">assert_equal(str(w[</span><span class="s5">0</span><span class="s1">].message)</span><span class="s2">, </span><span class="s1">message)</span>

    <span class="s4"># Check for a warning when providing a non-used statespace matrix</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">res.predict(end=res.nobs+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">design=</span><span class="s2">True,</span>
                    <span class="s1">obs_intercept=np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)))</span>

    <span class="s4"># Check that an error is raised when a new time-varying matrix is not</span>
    <span class="s4"># provided</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">end=res.nobs+</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Check that an error is raised when an obs_intercept with incorrect length</span>
    <span class="s4"># is given</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">end=res.nobs+</span><span class="s5">1</span><span class="s2">,</span>
                  <span class="s1">obs_intercept=np.zeros(</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s4"># Check that start=None gives start=0 and end=None gives end=nobs</span>
    <span class="s1">assert_equal(res.predict().forecasts.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">res.nobs))</span>

    <span class="s4"># Check that dynamic=True begins dynamic prediction immediately</span>
    <span class="s4"># TODO just a smoke test</span>
    <span class="s1">res.predict(dynamic=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s4"># Check that on success, PredictionResults object is returned</span>
    <span class="s1">prediction_results = res.predict(start=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">end=</span><span class="s5">5</span><span class="s1">)</span>
    <span class="s1">assert_equal(isinstance(prediction_results</span><span class="s2">, </span><span class="s1">PredictionResults)</span><span class="s2">, True</span><span class="s1">)</span>

    <span class="s4"># Check for correctly subset representation arrays</span>
    <span class="s4"># (k_endog, npredictions) = (1, 2)</span>
    <span class="s1">assert_equal(prediction_results.endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_endog, npredictions) = (1, 2)</span>
    <span class="s1">assert_equal(prediction_results.obs_intercept.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_endog, k_states) = (1, 1)</span>
    <span class="s1">assert_equal(prediction_results.design.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># (k_endog, k_endog) = (1, 1)</span>
    <span class="s1">assert_equal(prediction_results.obs_cov.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># (k_state,) = (1,)</span>
    <span class="s1">assert_equal(prediction_results.state_intercept.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s4"># (k_state, npredictions) = (1, 2)</span>
    <span class="s1">assert_equal(prediction_results.obs_intercept.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_state, k_state) = (1, 1)</span>
    <span class="s1">assert_equal(prediction_results.transition.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># (k_state, k_posdef) = (1, 1)</span>
    <span class="s1">assert_equal(prediction_results.selection.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s4"># (k_posdef, k_posdef) = (1, 1)</span>
    <span class="s1">assert_equal(prediction_results.state_cov.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s4"># Check for correctly subset filter output arrays</span>
    <span class="s4"># (k_endog, npredictions) = (1, 2)</span>
    <span class="s1">assert_equal(prediction_results.forecasts.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">assert_equal(prediction_results.forecasts_error.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_states, npredictions) = (1, 2)</span>
    <span class="s1">assert_equal(prediction_results.filtered_state.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">assert_equal(prediction_results.predicted_state.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_endog, k_endog, npredictions) = (1, 1, 2)</span>
    <span class="s1">assert_equal(prediction_results.forecasts_error_cov.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s4"># (k_states, k_states, npredictions) = (1, 1, 2)</span>
    <span class="s1">assert_equal(prediction_results.filtered_state_cov.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">assert_equal(prediction_results.predicted_state_cov.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>

    <span class="s4"># Check for invalid attribute</span>
    <span class="s1">assert_raises(AttributeError</span><span class="s2">, </span><span class="s1">getattr</span><span class="s2">, </span><span class="s1">prediction_results</span><span class="s2">, </span><span class="s3">'test'</span><span class="s1">)</span>

    <span class="s4"># Check that an error is raised when a non-two-dimensional obs_cov</span>
    <span class="s4"># is given</span>
    <span class="s4"># ...and...</span>
    <span class="s4"># Check that an error is raised when an obs_cov that is too short is given</span>
    <span class="s1">mod = KalmanFilter(endog</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_cov'</span><span class="s1">] = np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">res = mod.filter()</span>

    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">end=res.nobs + </span><span class="s5">2</span><span class="s2">,</span>
                  <span class="s1">obs_cov=np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)))</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">end=res.nobs + </span><span class="s5">2</span><span class="s2">,</span>
                  <span class="s1">obs_cov=np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)))</span>


<span class="s2">def </span><span class="s1">test_standardized_forecasts_error():</span>
    <span class="s4"># Simple test that standardized forecasts errors are calculated correctly.</span>

    <span class="s4"># Just uses a different calculation method on a univariate series.</span>

    <span class="s4"># Get the dataset</span>
    <span class="s1">true = results_kalman_filter.uc_uni</span>
    <span class="s1">data = pd.DataFrame(</span>
        <span class="s1">true[</span><span class="s3">'data'</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">index=pd.date_range(</span><span class="s3">'1947-01-01'</span><span class="s2">, </span><span class="s3">'1995-07-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s3">'QS'</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">columns=[</span><span class="s3">'GDP'</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">data[</span><span class="s3">'lgdp'</span><span class="s1">] = np.log(data[</span><span class="s3">'GDP'</span><span class="s1">])</span>

    <span class="s4"># Fit an ARIMA(1, 1, 0) to log GDP</span>
    <span class="s1">mod = sarimax.SARIMAX(data[</span><span class="s3">'lgdp'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s1">use_exact_diffuse=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">res = mod.fit(disp=-</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">d = np.maximum(res.loglikelihood_burn</span><span class="s2">, </span><span class="s1">res.nobs_diffuse)</span>

    <span class="s1">standardized_forecasts_error = (</span>
        <span class="s1">res.filter_results.forecasts_error[</span><span class="s5">0</span><span class="s1">] /</span>
        <span class="s1">np.sqrt(res.filter_results.forecasts_error_cov[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">res.filter_results.standardized_forecasts_error[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">d:]</span><span class="s2">,</span>
        <span class="s1">standardized_forecasts_error[...</span><span class="s2">, </span><span class="s1">d:]</span><span class="s2">,</span>
    <span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_simulate():</span>
    <span class="s4"># Test for simulation of new time-series</span>
    <span class="s2">from </span><span class="s1">scipy.signal </span><span class="s2">import </span><span class="s1">lfilter</span>

    <span class="s4"># Common parameters</span>
    <span class="s1">nsimulations = </span><span class="s5">10</span>
    <span class="s1">sigma2 = </span><span class="s5">2</span>
    <span class="s1">measurement_shocks = np.zeros(nsimulations)</span>
    <span class="s1">state_shocks = np.random.normal(scale=sigma2**</span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">size=nsimulations)</span>

    <span class="s4"># Random walk model, so simulated series is just the cumulative sum of</span>
    <span class="s4"># the shocks</span>
    <span class="s1">mod = SimulationSmoother(np.r_[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>

    <span class="s1">actual = mod.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=measurement_shocks</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks)[</span><span class="s5">0</span><span class="s1">].squeeze()</span>
    <span class="s1">desired = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.cumsum(state_shocks)[:-</span><span class="s5">1</span><span class="s1">]]</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Local level model, so simulated series is just the cumulative sum of</span>
    <span class="s4"># the shocks plus the measurement shock</span>
    <span class="s1">mod = SimulationSmoother(np.r_[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>

    <span class="s1">actual = mod.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=np.ones(nsimulations)</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks)[</span><span class="s5">0</span><span class="s1">].squeeze()</span>
    <span class="s1">desired = np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.cumsum(state_shocks)[:-</span><span class="s5">1</span><span class="s1">] + </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Local level-like model with observation and state intercepts, so</span>
    <span class="s4"># simulated series is just the cumulative sum of the shocks minus the state</span>
    <span class="s4"># intercept, plus the observation intercept and the measurement shock</span>
    <span class="s1">mod = SimulationSmoother(np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
                             <span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'obs_intercept'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">5.</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_intercept'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = -</span><span class="s5">2.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>

    <span class="s1">actual = mod.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=np.ones(nsimulations)</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks)[</span><span class="s5">0</span><span class="s1">].squeeze()</span>
    <span class="s1">desired = np.r_[</span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">5</span><span class="s2">, </span><span class="s1">np.cumsum(state_shocks - </span><span class="s5">2</span><span class="s1">)[:-</span><span class="s5">1</span><span class="s1">] + </span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">5</span><span class="s1">]</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Model with time-varying observation intercept</span>
    <span class="s1">mod = SimulationSmoother(np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">nobs=</span><span class="s5">10</span><span class="s2">,</span>
                             <span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'obs_intercept'</span><span class="s1">] = (np.arange(</span><span class="s5">10</span><span class="s1">)*</span><span class="s5">1.</span><span class="s1">).reshape(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>

    <span class="s1">actual = mod.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=measurement_shocks</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks)[</span><span class="s5">0</span><span class="s1">].squeeze()</span>
    <span class="s1">desired = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.cumsum(state_shocks)[:-</span><span class="s5">1</span><span class="s1">] + np.arange(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">)]</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Model with time-varying observation intercept, check that error is raised</span>
    <span class="s4"># if more simulations are requested than are nobs.</span>
    <span class="s1">mod = SimulationSmoother(np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">))</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">nobs=</span><span class="s5">10</span><span class="s2">,</span>
                             <span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'obs_intercept'</span><span class="s1">] = (np.arange(</span><span class="s5">10</span><span class="s1">)*</span><span class="s5">1.</span><span class="s1">).reshape(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">mod.simulate</span><span class="s2">, </span><span class="s1">nsimulations+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">measurement_shocks</span><span class="s2">,</span>
                  <span class="s1">state_shocks)</span>

    <span class="s4"># ARMA(1, 1): phi = [0.1], theta = [0.5], sigma^2 = 2</span>
    <span class="s1">phi = </span><span class="s5">0.1</span>
    <span class="s1">theta = </span><span class="s5">0.5</span>
    <span class="s1">mod = sarimax.SARIMAX([</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod.update(np.r_[phi</span><span class="s2">, </span><span class="s1">theta</span><span class="s2">, </span><span class="s1">sigma2])</span>

    <span class="s1">actual = mod.ssm.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=measurement_shocks</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks</span><span class="s2">,</span>
        <span class="s1">initial_state=np.zeros(mod.k_states))[</span><span class="s5">0</span><span class="s1">].squeeze()</span>
    <span class="s1">desired = lfilter([</span><span class="s5">1</span><span class="s2">, </span><span class="s1">theta]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-phi]</span><span class="s2">, </span><span class="s1">np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">state_shocks[:-</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># SARIMAX(1, 0, 1)x(1, 0, 1, 4), this time using the results object call</span>
    <span class="s1">mod = sarimax.SARIMAX([</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">-</span><span class="s5">0.2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s1">seasonal_order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))</span>
    <span class="s1">res = mod.filter([</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.2</span><span class="s2">, </span><span class="s1">-</span><span class="s5">0.3</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])</span>

    <span class="s1">actual = res.simulate(</span>
        <span class="s1">nsimulations</span><span class="s2">, </span><span class="s1">measurement_shocks=measurement_shocks</span><span class="s2">,</span>
        <span class="s1">state_shocks=state_shocks</span><span class="s2">, </span><span class="s1">initial_state=np.zeros(mod.k_states))</span>
    <span class="s1">desired = lfilter(</span>
        <span class="s1">res.polynomial_reduced_ma</span><span class="s2">, </span><span class="s1">res.polynomial_reduced_ar</span><span class="s2">,</span>
        <span class="s1">np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">state_shocks[:-</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>


<span class="s2">def </span><span class="s1">test_impulse_responses():</span>
    <span class="s4"># Test for impulse response functions</span>

    <span class="s4"># Random walk: 1-unit impulse response (i.e. non-orthogonalized irf) is 1</span>
    <span class="s4"># for all periods</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2.</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Random walk: 2-unit impulse response (i.e. non-orthogonalized irf) is 2</span>
    <span class="s4"># for all periods</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2.</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">2</span><span class="s1">])</span>
    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)) * </span><span class="s5">2</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Random walk: 1-standard-deviation response (i.e. orthogonalized irf) is</span>
    <span class="s4"># sigma for all periods (here sigma^2 = 2)</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2.</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">**</span><span class="s5">0.5</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Random walk: 1-standard-deviation cumulative response (i.e. cumulative</span>
    <span class="s4"># orthogonalized irf)</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2.</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True,</span>
                                   <span class="s1">cumulative=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">desired = np.cumsum(np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">**</span><span class="s5">0.5</span><span class="s1">)[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True,</span>
                                   <span class="s1">cumulative=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">desired = np.cumsum(np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">**</span><span class="s5">0.5</span><span class="s1">)[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Random walk: 1-unit impulse response (i.e. non-orthogonalized irf) is 1</span>
    <span class="s4"># for all periods, even when intercepts are present</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'state_intercept'</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">100.</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'obs_intercept'</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = -</span><span class="s5">1000.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2.</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Univariate model (random walk): test that an error is thrown when</span>
    <span class="s4"># a multivariate or empty &quot;impulse&quot; is sent</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">mod.impulse_responses</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">mod.impulse_responses</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">mod.impulse_responses</span><span class="s2">, </span><span class="s1">impulse=[])</span>

    <span class="s4"># Univariate model with two uncorrelated shocks</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:</span><span class="s5">2</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># In this case (with sigma=sigma^2=1), orthogonalized is the same as not</span>
    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(</span>
        <span class="s1">steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(</span>
        <span class="s1">steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Univariate model with two correlated shocks</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">:</span><span class="s5">2</span><span class="s1">] = </span><span class="s5">1.</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.array([[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1.25</span><span class="s1">]])</span>

    <span class="s1">desired = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s4"># Non-orthogonalized (i.e. 1-unit) impulses still just generate 1's</span>
    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Orthogonalized (i.e. 1-std-dev) impulses now generate different responses</span>
    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired + desired * </span><span class="s5">0.5</span><span class="s1">)</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Multivariate model with two correlated shocks</span>
    <span class="s1">mod = SimulationSmoother(k_endog=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">initialization=</span><span class="s3">'diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.array([[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1.25</span><span class="s1">]])</span>

    <span class="s1">ones = np.ones((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">zeros = np.zeros((</span><span class="s5">11</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s4"># Non-orthogonalized (i.e. 1-unit) impulses still just generate 1's, but</span>
    <span class="s4"># only for the appropriate series</span>
    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">np.c_[ones</span><span class="s2">, </span><span class="s1">zeros])</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">np.c_[zeros</span><span class="s2">, </span><span class="s1">ones])</span>

    <span class="s4"># Orthogonalized (i.e. 1-std-dev) impulses now generate different</span>
    <span class="s4"># responses, and only for the appropriate series</span>
    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">np.c_[ones</span><span class="s2">, </span><span class="s1">ones * </span><span class="s5">0.5</span><span class="s1">])</span>

    <span class="s1">actual = mod.impulse_responses(steps=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">impulse=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">orthogonalized=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">np.c_[zeros</span><span class="s2">, </span><span class="s1">ones])</span>

    <span class="s4"># AR(1) model generates a geometrically declining series</span>
    <span class="s1">mod = sarimax.SARIMAX([</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">-</span><span class="s5">0.2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">phi = </span><span class="s5">0.5</span>
    <span class="s1">mod.update([phi</span><span class="s2">, </span><span class="s5">1</span><span class="s1">])</span>

    <span class="s1">desired = np.cumprod(np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">[phi]*</span><span class="s5">10</span><span class="s1">])</span>

    <span class="s4"># Test going through the model directly</span>
    <span class="s1">actual = mod.ssm.impulse_responses(steps=</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s4"># Test going through the results object</span>
    <span class="s1">res = mod.filter([phi</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">])</span>
    <span class="s1">actual = res.impulse_responses(steps=</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>


<span class="s2">def </span><span class="s1">test_missing():</span>
    <span class="s4"># Datasets</span>
    <span class="s1">endog = np.arange(</span><span class="s5">10</span><span class="s1">).reshape(</span><span class="s5">10</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">endog_pre_na = np.ascontiguousarray(np.c_[</span>
        <span class="s1">endog.copy() * np.nan</span><span class="s2">, </span><span class="s1">endog.copy() * np.nan</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">endog])</span>
    <span class="s1">endog_post_na = np.ascontiguousarray(np.c_[</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">endog.copy() * np.nan</span><span class="s2">, </span><span class="s1">endog.copy() * np.nan])</span>
    <span class="s1">endog_inject_na = np.ascontiguousarray(np.c_[</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">endog.copy() * np.nan</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">endog.copy() * np.nan])</span>

    <span class="s4"># Base model</span>
    <span class="s1">mod = KalmanFilter(np.ascontiguousarray(np.c_[endog</span><span class="s2">, </span><span class="s1">endog])</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
                       <span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(mod.k_endog)*</span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">llf = mod.loglikeobs()</span>

    <span class="s4"># Model with prepended nans</span>
    <span class="s1">mod = KalmanFilter(endog_pre_na</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
                       <span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(mod.k_endog)*</span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">llf_pre_na = mod.loglikeobs()</span>

    <span class="s1">assert_allclose(llf_pre_na</span><span class="s2">, </span><span class="s1">llf)</span>

    <span class="s4"># Model with appended nans</span>
    <span class="s1">mod = KalmanFilter(endog_post_na</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
                       <span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(mod.k_endog)*</span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">llf_post_na = mod.loglikeobs()</span>

    <span class="s1">assert_allclose(llf_post_na</span><span class="s2">, </span><span class="s1">llf)</span>

    <span class="s4"># Model with injected nans</span>
    <span class="s1">mod = KalmanFilter(endog_inject_na</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
                       <span class="s1">initialization=</span><span class="s3">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">mod[</span><span class="s3">'design'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'obs_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = np.eye(mod.k_endog)*</span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'transition'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">mod[</span><span class="s3">'selection'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">1</span>
    <span class="s1">mod[</span><span class="s3">'state_cov'</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">0.5</span>
    <span class="s1">llf_inject_na = mod.loglikeobs()</span>

    <span class="s1">assert_allclose(llf_inject_na</span><span class="s2">, </span><span class="s1">llf)</span>
</pre>
</body>
</html>
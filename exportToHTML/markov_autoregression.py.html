<html>
<head>
<title>markov_autoregression.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
markov_autoregression.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Markov switching autoregression models 
 
Author: Chad Fulton 
License: BSD-3 
&quot;&quot;&quot;</span>


<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">statsmodels.base.wrapper </span><span class="s2">as </span><span class="s1">wrap</span>

<span class="s2">from </span><span class="s1">statsmodels.tsa.tsatools </span><span class="s2">import </span><span class="s1">lagmat</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.regime_switching </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">markov_switching</span><span class="s2">, </span><span class="s1">markov_regression)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.tools </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">constrain_stationary_univariate</span><span class="s2">, </span><span class="s1">unconstrain_stationary_univariate)</span>


<span class="s2">class </span><span class="s1">MarkovAutoregression(markov_regression.MarkovRegression):</span>
    <span class="s0">r&quot;&quot;&quot; 
    Markov switching regression model 
 
    Parameters 
    ---------- 
    endog : array_like 
        The endogenous variable. 
    k_regimes : int 
        The number of regimes. 
    order : int 
        The order of the autoregressive lag polynomial. 
    trend : {'n', 'c', 't', 'ct'} 
        Whether or not to include a trend. To include an constant, time trend, 
        or both, set `trend='c'`, `trend='t'`, or `trend='ct'`. For no trend, 
        set `trend='n'`. Default is a constant. 
    exog : array_like, optional 
        Array of exogenous regressors, shaped nobs x k. 
    exog_tvtp : array_like, optional 
        Array of exogenous or lagged variables to use in calculating 
        time-varying transition probabilities (TVTP). TVTP is only used if this 
        variable is provided. If an intercept is desired, a column of ones must 
        be explicitly included in this array. 
    switching_ar : bool or iterable, optional 
        If a boolean, sets whether or not all autoregressive coefficients are 
        switching across regimes. If an iterable, should be of length equal 
        to `order`, where each element is a boolean describing whether the 
        corresponding coefficient is switching. Default is True. 
    switching_trend : bool or iterable, optional 
        If a boolean, sets whether or not all trend coefficients are 
        switching across regimes. If an iterable, should be of length equal 
        to the number of trend variables, where each element is 
        a boolean describing whether the corresponding coefficient is 
        switching. Default is True. 
    switching_exog : bool or iterable, optional 
        If a boolean, sets whether or not all regression coefficients are 
        switching across regimes. If an iterable, should be of length equal 
        to the number of exogenous variables, where each element is 
        a boolean describing whether the corresponding coefficient is 
        switching. Default is True. 
    switching_variance : bool, optional 
        Whether or not there is regime-specific heteroskedasticity, i.e. 
        whether or not the error term has a switching variance. Default is 
        False. 
 
    Notes 
    ----- 
    This model is new and API stability is not guaranteed, although changes 
    will be made in a backwards compatible way if possible. 
 
    The model can be written as: 
 
    .. math:: 
 
        y_t = a_{S_t} + x_t' \beta_{S_t} + \phi_{1, S_t} 
        (y_{t-1} - a_{S_{t-1}} - x_{t-1}' \beta_{S_{t-1}}) + \dots + 
        \phi_{p, S_t} (y_{t-p} - a_{S_{t-p}} - x_{t-p}' \beta_{S_{t-p}}) + 
        \varepsilon_t \\ 
        \varepsilon_t \sim N(0, \sigma_{S_t}^2) 
 
    i.e. the model is an autoregression with where the autoregressive 
    coefficients, the mean of the process (possibly including trend or 
    regression effects) and the variance of the error term may be switching 
    across regimes. 
 
    The `trend` is accommodated by prepending columns to the `exog` array. Thus 
    if `trend='c'`, the passed `exog` array should not already have a column of 
    ones. 
 
    See the notebook `Markov switching autoregression 
    &lt;../examples/notebooks/generated/markov_autoregression.html&gt;`__ 
    for an overview. 
 
    References 
    ---------- 
    Kim, Chang-Jin, and Charles R. Nelson. 1999. 
    &quot;State-Space Models with Regime Switching: 
    Classical and Gibbs-Sampling Approaches with Applications&quot;. 
    MIT Press Books. The MIT Press. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">k_regimes</span><span class="s2">, </span><span class="s1">order</span><span class="s2">, </span><span class="s1">trend=</span><span class="s3">'c'</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None,</span>
                 <span class="s1">exog_tvtp=</span><span class="s2">None, </span><span class="s1">switching_ar=</span><span class="s2">True, </span><span class="s1">switching_trend=</span><span class="s2">True,</span>
                 <span class="s1">switching_exog=</span><span class="s2">False, </span><span class="s1">switching_variance=</span><span class="s2">False,</span>
                 <span class="s1">dates=</span><span class="s2">None, </span><span class="s1">freq=</span><span class="s2">None, </span><span class="s1">missing=</span><span class="s3">'none'</span><span class="s1">):</span>

        <span class="s4"># Properties</span>
        <span class="s1">self.switching_ar = switching_ar</span>

        <span class="s4"># Switching options</span>
        <span class="s2">if </span><span class="s1">self.switching_ar </span><span class="s2">is True or </span><span class="s1">self.switching_ar </span><span class="s2">is False</span><span class="s1">:</span>
            <span class="s1">self.switching_ar = [self.switching_ar] * order</span>
        <span class="s2">elif not </span><span class="s1">len(self.switching_ar) == order:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Invalid iterable passed to `switching_ar`.'</span><span class="s1">)</span>

        <span class="s4"># Initialize the base model</span>
        <span class="s1">super().__init__(</span>
            <span class="s1">endog</span><span class="s2">, </span><span class="s1">k_regimes</span><span class="s2">, </span><span class="s1">trend=trend</span><span class="s2">, </span><span class="s1">exog=exog</span><span class="s2">, </span><span class="s1">order=order</span><span class="s2">,</span>
            <span class="s1">exog_tvtp=exog_tvtp</span><span class="s2">, </span><span class="s1">switching_trend=switching_trend</span><span class="s2">,</span>
            <span class="s1">switching_exog=switching_exog</span><span class="s2">,</span>
            <span class="s1">switching_variance=switching_variance</span><span class="s2">, </span><span class="s1">dates=dates</span><span class="s2">, </span><span class="s1">freq=freq</span><span class="s2">,</span>
            <span class="s1">missing=missing)</span>

        <span class="s4"># Sanity checks</span>
        <span class="s2">if </span><span class="s1">self.nobs &lt;= self.order:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Must have more observations than the order of'</span>
                             <span class="s3">' the autoregression.'</span><span class="s1">)</span>

        <span class="s4"># Autoregressive exog</span>
        <span class="s1">self.exog_ar = lagmat(endog</span><span class="s2">, </span><span class="s1">self.order)[self.order:]</span>

        <span class="s4"># Reshape other datasets</span>
        <span class="s1">self.nobs -= self.order</span>
        <span class="s1">self.orig_endog = self.endog</span>
        <span class="s1">self.endog = self.endog[self.order:]</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">self.orig_exog = self.exog</span>
            <span class="s1">self.exog = self.exog[self.order:]</span>

        <span class="s4"># Reset the ModelData datasets</span>
        <span class="s1">self.data.endog</span><span class="s2">, </span><span class="s1">self.data.exog = (</span>
            <span class="s1">self.data._convert_endog_exog(self.endog</span><span class="s2">, </span><span class="s1">self.exog))</span>

        <span class="s4"># Reset indexes, if provided</span>
        <span class="s2">if </span><span class="s1">self.data.row_labels </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.data._cache[</span><span class="s3">'row_labels'</span><span class="s1">] = (</span>
                <span class="s1">self.data.row_labels[self.order:])</span>
        <span class="s2">if </span><span class="s1">self._index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self._index_generated:</span>
                <span class="s1">self._index = self._index[:-self.order]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self._index = self._index[self.order:]</span>

        <span class="s4"># Parameters</span>
        <span class="s1">self.parameters[</span><span class="s3">'autoregressive'</span><span class="s1">] = self.switching_ar</span>

        <span class="s4"># Cache an array for holding slices</span>
        <span class="s1">self._predict_slices = [slice(</span><span class="s2">None, None, None</span><span class="s1">)] * (self.order + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">predict_conditional(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        In-sample prediction, conditional on the current and previous regime 
 
        Parameters 
        ---------- 
        params : array_like 
            Array of parameters at which to create predictions. 
 
        Returns 
        ------- 
        predict : array_like 
            Array of predictions conditional on current, and possibly past, 
            regimes 
        &quot;&quot;&quot;</span>
        <span class="s1">params = np.array(params</span><span class="s2">, </span><span class="s1">ndmin=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Prediction is based on:</span>
        <span class="s4"># y_t = x_t beta^{(S_t)} +</span>
        <span class="s4">#       \phi_1^{(S_t)} (y_{t-1} - x_{t-1} beta^{(S_t-1)}) + ...</span>
        <span class="s4">#       \phi_p^{(S_t)} (y_{t-p} - x_{t-p} beta^{(S_t-p)}) + eps_t</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">xb = []</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">coeffs = params[self.parameters[i</span><span class="s2">, </span><span class="s3">'exog'</span><span class="s1">]]</span>
                <span class="s1">xb.append(np.dot(self.orig_exog</span><span class="s2">, </span><span class="s1">coeffs))</span>

        <span class="s1">predict = np.zeros(</span>
            <span class="s1">(self.k_regimes</span><span class="s2">,</span><span class="s1">) * (self.order + </span><span class="s5">1</span><span class="s1">) + (self.nobs</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">dtype=np.promote_types(np.float64</span><span class="s2">, </span><span class="s1">params.dtype))</span>
        <span class="s4"># Iterate over S_{t} = i</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">ar_coeffs = params[self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]]</span>

            <span class="s4"># y_t - x_t beta^{(S_t)}</span>
            <span class="s1">ix = self._predict_slices[:]</span>
            <span class="s1">ix[</span><span class="s5">0</span><span class="s1">] = i</span>
            <span class="s1">ix = tuple(ix)</span>
            <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">predict[ix] += xb[i][self.order:]</span>

            <span class="s4"># Iterate over j = 2, .., p</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.order + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                    <span class="s4"># This gets a specific time-period / regime slice:</span>
                    <span class="s4"># S_{t} = i, S_{t-j} = k, across all other time-period /</span>
                    <span class="s4"># regime slices.</span>
                    <span class="s1">ix = self._predict_slices[:]</span>
                    <span class="s1">ix[</span><span class="s5">0</span><span class="s1">] = i</span>
                    <span class="s1">ix[j] = k</span>
                    <span class="s1">ix = tuple(ix)</span>

                    <span class="s1">start = self.order - j</span>
                    <span class="s1">end = -j</span>
                    <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
                        <span class="s1">predict[ix] += ar_coeffs[j-</span><span class="s5">1</span><span class="s1">] * (</span>
                            <span class="s1">self.orig_endog[start:end] - xb[k][start:end])</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">predict[ix] += ar_coeffs[j-</span><span class="s5">1</span><span class="s1">] * (</span>
                            <span class="s1">self.orig_endog[start:end])</span>

        <span class="s2">return </span><span class="s1">predict</span>

    <span class="s2">def </span><span class="s1">_resid(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s2">return </span><span class="s1">self.endog - self.predict_conditional(params)</span>

    <span class="s2">def </span><span class="s1">_conditional_loglikelihoods(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute loglikelihoods conditional on the current period's regime and 
        the last `self.order` regimes. 
        &quot;&quot;&quot;</span>
        <span class="s4"># Get the residuals</span>
        <span class="s1">resid = self._resid(params)</span>

        <span class="s4"># Compute the conditional likelihoods</span>
        <span class="s1">variance = params[self.parameters[</span><span class="s3">'variance'</span><span class="s1">]].squeeze()</span>
        <span class="s2">if </span><span class="s1">self.switching_variance:</span>
            <span class="s1">variance = np.reshape(variance</span><span class="s2">, </span><span class="s1">(self.k_regimes</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

        <span class="s1">conditional_loglikelihoods = (</span>
            <span class="s1">-</span><span class="s5">0.5 </span><span class="s1">* resid**</span><span class="s5">2 </span><span class="s1">/ variance - </span><span class="s5">0.5 </span><span class="s1">* np.log(</span><span class="s5">2 </span><span class="s1">* np.pi * variance))</span>

        <span class="s2">return </span><span class="s1">conditional_loglikelihoods</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_res_classes(self):</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s3">'fit'</span><span class="s1">: (MarkovAutoregressionResults</span><span class="s2">,</span>
                        <span class="s1">MarkovAutoregressionResultsWrapper)}</span>

    <span class="s2">def </span><span class="s1">_em_iteration(self</span><span class="s2">, </span><span class="s1">params0):</span>
        <span class="s0">&quot;&quot;&quot; 
        EM iteration 
        &quot;&quot;&quot;</span>
        <span class="s4"># Inherited parameters</span>
        <span class="s1">result</span><span class="s2">, </span><span class="s1">params1 = markov_switching.MarkovSwitching._em_iteration(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">params0)</span>

        <span class="s1">tmp = np.sqrt(result.smoothed_marginal_probabilities)</span>

        <span class="s4"># Regression coefficients</span>
        <span class="s1">coeffs = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">coeffs = self._em_exog(result</span><span class="s2">, </span><span class="s1">self.endog</span><span class="s2">, </span><span class="s1">self.exog</span><span class="s2">,</span>
                                   <span class="s1">self.parameters.switching[</span><span class="s3">'exog'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tmp)</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">params1[self.parameters[i</span><span class="s2">, </span><span class="s3">'exog'</span><span class="s1">]] = coeffs[i]</span>

        <span class="s4"># Autoregressive</span>
        <span class="s2">if </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">ar_coeffs</span><span class="s2">, </span><span class="s1">variance = self._em_autoregressive(</span>
                    <span class="s1">result</span><span class="s2">, </span><span class="s1">coeffs)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">ar_coeffs = self._em_exog(</span>
                    <span class="s1">result</span><span class="s2">, </span><span class="s1">self.endog</span><span class="s2">, </span><span class="s1">self.exog_ar</span><span class="s2">,</span>
                    <span class="s1">self.parameters.switching[</span><span class="s3">'autoregressive'</span><span class="s1">])</span>
                <span class="s1">variance = self._em_variance(</span>
                    <span class="s1">result</span><span class="s2">, </span><span class="s1">self.endog</span><span class="s2">, </span><span class="s1">self.exog_ar</span><span class="s2">, </span><span class="s1">ar_coeffs</span><span class="s2">, </span><span class="s1">tmp)</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">params1[self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]] = ar_coeffs[i]</span>
            <span class="s1">params1[self.parameters[</span><span class="s3">'variance'</span><span class="s1">]] = variance</span>

        <span class="s2">return </span><span class="s1">result</span><span class="s2">, </span><span class="s1">params1</span>

    <span class="s2">def </span><span class="s1">_em_autoregressive(self</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">betas</span><span class="s2">, </span><span class="s1">tmp=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        EM step for autoregressive coefficients and variances 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">tmp </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">tmp = np.sqrt(result.smoothed_marginal_probabilities)</span>

        <span class="s1">resid = np.zeros((self.k_regimes</span><span class="s2">, </span><span class="s1">self.nobs + self.order))</span>
        <span class="s1">resid[:] = self.orig_endog</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">resid[i] -= np.dot(self.orig_exog</span><span class="s2">, </span><span class="s1">betas[i])</span>

        <span class="s4"># The difference between this and `_em_exog` is that here we have a</span>
        <span class="s4"># different endog and exog for each regime</span>
        <span class="s1">coeffs = np.zeros((self.k_regimes</span><span class="s2">,</span><span class="s1">) + (self.order</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s1">variance = np.zeros((self.k_regimes</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s1">exog = np.zeros((self.nobs</span><span class="s2">, </span><span class="s1">self.order))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">endog = resid[i</span><span class="s2">, </span><span class="s1">self.order:]</span>
            <span class="s1">exog = lagmat(resid[i]</span><span class="s2">, </span><span class="s1">self.order)[self.order:]</span>
            <span class="s1">tmp_endog = tmp[i] * endog</span>
            <span class="s1">tmp_exog = tmp[i][:</span><span class="s2">, None</span><span class="s1">] * exog</span>

            <span class="s1">coeffs[i] = np.dot(np.linalg.pinv(tmp_exog)</span><span class="s2">, </span><span class="s1">tmp_endog)</span>

            <span class="s2">if </span><span class="s1">self.switching_variance:</span>
                <span class="s1">tmp_resid = endog - np.dot(exog</span><span class="s2">, </span><span class="s1">coeffs[i])</span>
                <span class="s1">variance[i] = (np.sum(</span>
                    <span class="s1">tmp_resid**</span><span class="s5">2 </span><span class="s1">* result.smoothed_marginal_probabilities[i]) /</span>
                    <span class="s1">np.sum(result.smoothed_marginal_probabilities[i]))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">tmp_resid = tmp_endog - np.dot(tmp_exog</span><span class="s2">, </span><span class="s1">coeffs[i])</span>
                <span class="s1">variance[i] = np.sum(tmp_resid**</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s4"># Variances</span>
        <span class="s2">if not </span><span class="s1">self.switching_variance:</span>
            <span class="s1">variance = variance.sum() / self.nobs</span>

        <span class="s2">return </span><span class="s1">coeffs</span><span class="s2">, </span><span class="s1">variance</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">start_params(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (array) Starting parameters for maximum likelihood estimation. 
        &quot;&quot;&quot;</span>
        <span class="s4"># Inherited parameters</span>
        <span class="s1">params = markov_switching.MarkovSwitching.start_params.fget(self)</span>

        <span class="s4"># OLS for starting parameters</span>
        <span class="s1">endog = self.endog.copy()</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">exog = np.c_[self.exog</span><span class="s2">, </span><span class="s1">self.exog_ar]</span>
        <span class="s2">elif </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">exog = self.exog</span>
        <span class="s2">elif </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">exog = self.exog_ar</span>

        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">beta = np.dot(np.linalg.pinv(exog)</span><span class="s2">, </span><span class="s1">endog)</span>
            <span class="s1">variance = np.var(endog - np.dot(exog</span><span class="s2">, </span><span class="s1">beta))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">variance = np.var(endog)</span>

        <span class="s4"># Regression coefficients</span>
        <span class="s2">if </span><span class="s1">self._k_exog &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">np.any(self.switching_coeffs):</span>
                <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                    <span class="s1">params[self.parameters[i</span><span class="s2">, </span><span class="s3">'exog'</span><span class="s1">]] = (</span>
                        <span class="s1">beta[:self._k_exog] * (i / self.k_regimes))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">params[self.parameters[</span><span class="s3">'exog'</span><span class="s1">]] = beta[:self._k_exog]</span>

        <span class="s4"># Autoregressive</span>
        <span class="s2">if </span><span class="s1">self.order &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">np.any(self.switching_ar):</span>
                <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                    <span class="s1">params[self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]] = (</span>
                        <span class="s1">beta[self._k_exog:] * (i / self.k_regimes))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">params[self.parameters[</span><span class="s3">'autoregressive'</span><span class="s1">]] = beta[self._k_exog:]</span>

        <span class="s4"># Variance</span>
        <span class="s2">if </span><span class="s1">self.switching_variance:</span>
            <span class="s1">params[self.parameters[</span><span class="s3">'variance'</span><span class="s1">]] = (</span>
                <span class="s1">np.linspace(variance / </span><span class="s5">10.</span><span class="s2">, </span><span class="s1">variance</span><span class="s2">, </span><span class="s1">num=self.k_regimes))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">params[self.parameters[</span><span class="s3">'variance'</span><span class="s1">]] = variance</span>

        <span class="s2">return </span><span class="s1">params</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">param_names(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        (list of str) List of human readable parameter names (for parameters 
        actually included in the model). 
        &quot;&quot;&quot;</span>
        <span class="s4"># Inherited parameters</span>
        <span class="s1">param_names = np.array(</span>
            <span class="s1">markov_regression.MarkovRegression.param_names.fget(self)</span><span class="s2">,</span>
            <span class="s1">dtype=object)</span>

        <span class="s4"># Autoregressive</span>
        <span class="s2">if </span><span class="s1">np.any(self.switching_ar):</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
                <span class="s1">param_names[self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]] = [</span>
                    <span class="s3">'ar.L%d[%d]' </span><span class="s1">% (j+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">i) </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.order)]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">param_names[self.parameters[</span><span class="s3">'autoregressive'</span><span class="s1">]] = [</span>
                <span class="s3">'ar.L%d' </span><span class="s1">% (j+</span><span class="s5">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.order)]</span>

        <span class="s2">return </span><span class="s1">param_names.tolist()</span>

    <span class="s2">def </span><span class="s1">transform_params(self</span><span class="s2">, </span><span class="s1">unconstrained):</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform unconstrained parameters used by the optimizer to constrained 
        parameters used in likelihood evaluation 
 
        Parameters 
        ---------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer, to be 
            transformed. 
 
        Returns 
        ------- 
        constrained : array_like 
            Array of constrained parameters which may be used in likelihood 
            evaluation. 
        &quot;&quot;&quot;</span>
        <span class="s4"># Inherited parameters</span>
        <span class="s1">constrained = super(MarkovAutoregression</span><span class="s2">, </span><span class="s1">self).transform_params(</span>
            <span class="s1">unconstrained)</span>

        <span class="s4"># Autoregressive</span>
        <span class="s4"># TODO may provide unexpected results when some coefficients are not</span>
        <span class="s4"># switching</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">s = self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]</span>
            <span class="s1">constrained[s] = constrain_stationary_univariate(</span>
                <span class="s1">unconstrained[s])</span>

        <span class="s2">return </span><span class="s1">constrained</span>

    <span class="s2">def </span><span class="s1">untransform_params(self</span><span class="s2">, </span><span class="s1">constrained):</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform constrained parameters used in likelihood evaluation 
        to unconstrained parameters used by the optimizer 
 
        Parameters 
        ---------- 
        constrained : array_like 
            Array of constrained parameters used in likelihood evaluation, to 
            be transformed. 
 
        Returns 
        ------- 
        unconstrained : array_like 
            Array of unconstrained parameters used by the optimizer. 
        &quot;&quot;&quot;</span>
        <span class="s4"># Inherited parameters</span>
        <span class="s1">unconstrained = super(MarkovAutoregression</span><span class="s2">, </span><span class="s1">self).untransform_params(</span>
            <span class="s1">constrained)</span>

        <span class="s4"># Autoregressive</span>
        <span class="s4"># TODO may provide unexpected results when some coefficients are not</span>
        <span class="s4"># switching</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.k_regimes):</span>
            <span class="s1">s = self.parameters[i</span><span class="s2">, </span><span class="s3">'autoregressive'</span><span class="s1">]</span>
            <span class="s1">unconstrained[s] = unconstrain_stationary_univariate(</span>
                <span class="s1">constrained[s])</span>

        <span class="s2">return </span><span class="s1">unconstrained</span>


<span class="s2">class </span><span class="s1">MarkovAutoregressionResults(markov_regression.MarkovRegressionResults):</span>
    <span class="s0">r&quot;&quot;&quot; 
    Class to hold results from fitting a Markov switching autoregression model 
 
    Parameters 
    ---------- 
    model : MarkovAutoregression instance 
        The fitted model instance 
    params : ndarray 
        Fitted parameters 
    filter_results : HamiltonFilterResults or KimSmootherResults instance 
        The underlying filter and, optionally, smoother output 
    cov_type : str 
        The type of covariance matrix estimator to use. Can be one of 'approx', 
        'opg', 'robust', or 'none'. 
 
    Attributes 
    ---------- 
    model : Model instance 
        A reference to the model that was fit. 
    filter_results : HamiltonFilterResults or KimSmootherResults instance 
        The underlying filter and, optionally, smoother output 
    nobs : float 
        The number of observations used to fit the model. 
    params : ndarray 
        The parameters of the model. 
    scale : float 
        This is currently set to 1.0 and not used by the model or its results. 
    &quot;&quot;&quot;</span>
    <span class="s2">pass</span>


<span class="s2">class </span><span class="s1">MarkovAutoregressionResultsWrapper(</span>
        <span class="s1">markov_regression.MarkovRegressionResultsWrapper):</span>
    <span class="s2">pass</span>
<span class="s1">wrap.populate_wrapper(MarkovAutoregressionResultsWrapper</span><span class="s2">,  </span><span class="s4"># noqa:E305</span>
                      <span class="s1">MarkovAutoregressionResults)</span>
</pre>
</body>
</html>
<html>
<head>
<title>infix_parser.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
infix_parser.py</font>
</center></td></tr></table>
<pre><span class="s0"># This file is part of Patsy</span>
<span class="s0"># Copyright (C) 2011 Nathaniel Smith &lt;njs@pobox.com&gt;</span>
<span class="s0"># See file LICENSE.txt for license information.</span>

<span class="s0"># This file implements a simple &quot;shunting yard algorithm&quot; parser for infix</span>
<span class="s0"># languages with parentheses. It is used as the core of our parser for</span>
<span class="s0"># formulas, but is generic enough to be used for other purposes as well</span>
<span class="s0"># (e.g. parsing linear constraints). It just builds a parse tree; semantics</span>
<span class="s0"># are somebody else's problem.</span>
<span class="s0">#</span>
<span class="s0"># Plus it spends energy on tracking where each item in the parse tree comes</span>
<span class="s0"># from, to allow high-quality error reporting.</span>
<span class="s0">#</span>
<span class="s0"># You are expected to provide an collection of Operators, a collection of</span>
<span class="s0"># atomic types, and an iterator that provides Tokens. Each Operator should</span>
<span class="s0"># have a unique token_type (which is an arbitrary Python object), and each</span>
<span class="s0"># Token should have a matching token_type, or one of the special types</span>
<span class="s0"># Token.LPAREN, Token.RPAREN. Each Token is required to have a valid Origin</span>
<span class="s0"># attached, for error reporting.</span>

<span class="s0"># XX: still seriously consider putting the magic intercept handling into the</span>
<span class="s0"># tokenizer. we'd still need separate term-sets that get pasted together by ~</span>
<span class="s0"># to create the modeldesc, though... heck maybe we should just have a</span>
<span class="s0"># modeldesc be 1-or-more termsets, with the convention that if it's 1, then</span>
<span class="s0"># it's a rhs, and if it's 2, it's (lhs, rhs), and otherwise you're on your</span>
<span class="s0"># own. Test: would this be useful for multiple-group log-linear models,</span>
<span class="s0"># maybe? Answer: Perhaps. outcome ~ x1 + x2 ~ group. But lots of other</span>
<span class="s0"># plausible, maybe better ways to write this -- (outcome | group) ~ x1 + x2?</span>
<span class="s0"># &quot;outcome ~ x1 + x2&quot;, group=&quot;group&quot;? etc.</span>

<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">print_function</span>

<span class="s1">__all__ = [</span><span class="s3">&quot;Token&quot;</span><span class="s2">, </span><span class="s3">&quot;ParseNode&quot;</span><span class="s2">, </span><span class="s3">&quot;Operator&quot;</span><span class="s2">, </span><span class="s3">&quot;parse&quot;</span><span class="s1">]</span>

<span class="s2">from </span><span class="s1">patsy </span><span class="s2">import </span><span class="s1">PatsyError</span>
<span class="s2">from </span><span class="s1">patsy.origin </span><span class="s2">import </span><span class="s1">Origin</span>
<span class="s2">from </span><span class="s1">patsy.util </span><span class="s2">import </span><span class="s1">(repr_pretty_delegate</span><span class="s2">, </span><span class="s1">repr_pretty_impl</span><span class="s2">,</span>
                        <span class="s1">no_pickling</span><span class="s2">, </span><span class="s1">assert_no_pickling)</span>

<span class="s2">class </span><span class="s1">_UniqueValue(object):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">print_as):</span>
        <span class="s1">self._print_as = print_as</span>

    <span class="s2">def </span><span class="s1">__repr__(self):</span>
        <span class="s2">return </span><span class="s3">&quot;%s(%r)&quot; </span><span class="s1">% (self.__class__.__name__</span><span class="s2">, </span><span class="s1">self._print_as)</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s2">class </span><span class="s1">Token(object):</span>
    <span class="s4">&quot;&quot;&quot;A token with possible payload. 
 
    .. attribute:: type 
 
       An arbitrary object indicating the type of this token. Should be 
      :term:`hashable`, but otherwise it can be whatever you like. 
    &quot;&quot;&quot;</span>
    <span class="s1">LPAREN = _UniqueValue(</span><span class="s3">&quot;LPAREN&quot;</span><span class="s1">)</span>
    <span class="s1">RPAREN = _UniqueValue(</span><span class="s3">&quot;RPAREN&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">type</span><span class="s2">, </span><span class="s1">origin</span><span class="s2">, </span><span class="s1">extra=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">self.type = type</span>
        <span class="s1">self.origin = origin</span>
        <span class="s1">self.extra = extra</span>

    <span class="s1">__repr__ = repr_pretty_delegate</span>
    <span class="s2">def </span><span class="s1">_repr_pretty_(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">cycle):</span>
        <span class="s2">assert not </span><span class="s1">cycle</span>
        <span class="s1">kwargs = []</span>
        <span class="s2">if </span><span class="s1">self.extra </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">kwargs = [(</span><span class="s3">&quot;extra&quot;</span><span class="s2">, </span><span class="s1">self.extra)]</span>
        <span class="s2">return </span><span class="s1">repr_pretty_impl(p</span><span class="s2">, </span><span class="s1">self</span><span class="s2">, </span><span class="s1">[self.type</span><span class="s2">, </span><span class="s1">self.origin]</span><span class="s2">, </span><span class="s1">kwargs)</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s2">class </span><span class="s1">ParseNode(object):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">type</span><span class="s2">, </span><span class="s1">token</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">origin):</span>
        <span class="s1">self.type = type</span>
        <span class="s1">self.token = token</span>
        <span class="s1">self.args = args</span>
        <span class="s1">self.origin = origin</span>

    <span class="s1">__repr__ = repr_pretty_delegate</span>
    <span class="s2">def </span><span class="s1">_repr_pretty_(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">cycle):</span>
        <span class="s2">return </span><span class="s1">repr_pretty_impl(p</span><span class="s2">, </span><span class="s1">self</span><span class="s2">, </span><span class="s1">[self.type</span><span class="s2">, </span><span class="s1">self.token</span><span class="s2">, </span><span class="s1">self.args])</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s2">class </span><span class="s1">Operator(object):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">token_type</span><span class="s2">, </span><span class="s1">arity</span><span class="s2">, </span><span class="s1">precedence):</span>
        <span class="s1">self.token_type = token_type</span>
        <span class="s1">self.arity = arity</span>
        <span class="s1">self.precedence = precedence</span>

    <span class="s2">def </span><span class="s1">__repr__(self):</span>
        <span class="s2">return </span><span class="s3">&quot;%s(%r, %r, %r)&quot; </span><span class="s1">% (self.__class__.__name__</span><span class="s2">,</span>
                                   <span class="s1">self.token_type</span><span class="s2">, </span><span class="s1">self.arity</span><span class="s2">, </span><span class="s1">self.precedence)</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s2">class </span><span class="s1">_StackOperator(object):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">op</span><span class="s2">, </span><span class="s1">token):</span>
        <span class="s1">self.op = op</span>
        <span class="s1">self.token = token</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s1">_open_paren = Operator(Token.LPAREN</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">9999999</span><span class="s1">)</span>

<span class="s2">class </span><span class="s1">_ParseContext(object):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">unary_ops</span><span class="s2">, </span><span class="s1">binary_ops</span><span class="s2">, </span><span class="s1">atomic_types</span><span class="s2">, </span><span class="s1">trace):</span>
        <span class="s1">self.op_stack = []</span>
        <span class="s1">self.noun_stack = []</span>
        <span class="s1">self.unary_ops = unary_ops</span>
        <span class="s1">self.binary_ops = binary_ops</span>
        <span class="s1">self.atomic_types = atomic_types</span>
        <span class="s1">self.trace = trace</span>

    <span class="s1">__getstate__ = no_pickling</span>

<span class="s2">def </span><span class="s1">_read_noun_context(token</span><span class="s2">, </span><span class="s1">c):</span>
    <span class="s2">if </span><span class="s1">token.type == Token.LPAREN:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Pushing open-paren&quot;</span><span class="s1">)</span>
        <span class="s1">c.op_stack.append(_StackOperator(_open_paren</span><span class="s2">, </span><span class="s1">token))</span>
        <span class="s2">return True</span>
    <span class="s2">elif </span><span class="s1">token.type </span><span class="s2">in </span><span class="s1">c.unary_ops:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Pushing unary op %r&quot; </span><span class="s1">% (token.type</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s1">c.op_stack.append(_StackOperator(c.unary_ops[token.type]</span><span class="s2">, </span><span class="s1">token))</span>
        <span class="s2">return True</span>
    <span class="s2">elif </span><span class="s1">token.type </span><span class="s2">in </span><span class="s1">c.atomic_types:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Pushing noun %r (%r)&quot; </span><span class="s1">% (token.type</span><span class="s2">, </span><span class="s1">token.extra))</span>
        <span class="s1">c.noun_stack.append(ParseNode(token.type</span><span class="s2">, </span><span class="s1">token</span><span class="s2">, </span><span class="s1">[]</span><span class="s2">,</span>
                                      <span class="s1">token.origin))</span>
        <span class="s2">return False</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">PatsyError(</span><span class="s3">&quot;expected a noun, not '%s'&quot;</span>
                            <span class="s1">% (token.origin.relevant_code()</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                            <span class="s1">token)</span>

<span class="s2">def </span><span class="s1">_run_op(c):</span>
    <span class="s2">assert </span><span class="s1">c.op_stack</span>
    <span class="s1">stackop = c.op_stack.pop()</span>
    <span class="s1">args = []</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(stackop.op.arity):</span>
        <span class="s1">args.append(c.noun_stack.pop())</span>
    <span class="s1">args.reverse()</span>
    <span class="s2">if </span><span class="s1">c.trace:</span>
        <span class="s1">print(</span><span class="s3">&quot;Reducing %r (%r)&quot; </span><span class="s1">% (stackop.op.token_type</span><span class="s2">, </span><span class="s1">args))</span>
    <span class="s1">node = ParseNode(stackop.op.token_type</span><span class="s2">, </span><span class="s1">stackop.token</span><span class="s2">, </span><span class="s1">args</span><span class="s2">,</span>
                     <span class="s1">Origin.combine([stackop.token] + args))</span>
    <span class="s1">c.noun_stack.append(node)</span>

<span class="s2">def </span><span class="s1">_read_op_context(token</span><span class="s2">, </span><span class="s1">c):</span>
    <span class="s2">if </span><span class="s1">token.type == Token.RPAREN:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Found close-paren&quot;</span><span class="s1">)</span>
        <span class="s2">while </span><span class="s1">c.op_stack </span><span class="s2">and </span><span class="s1">c.op_stack[-</span><span class="s5">1</span><span class="s1">].op.token_type != Token.LPAREN:</span>
            <span class="s1">_run_op(c)</span>
        <span class="s2">if not </span><span class="s1">c.op_stack:</span>
            <span class="s2">raise </span><span class="s1">PatsyError(</span><span class="s3">&quot;missing '(' or extra ')'&quot;</span><span class="s2">, </span><span class="s1">token)</span>
        <span class="s2">assert </span><span class="s1">c.op_stack[-</span><span class="s5">1</span><span class="s1">].op.token_type == Token.LPAREN</span>
        <span class="s0"># Expand the origin of the item on top of the noun stack to include</span>
        <span class="s0"># the open and close parens:</span>
        <span class="s1">combined = Origin.combine([c.op_stack[-</span><span class="s5">1</span><span class="s1">].token</span><span class="s2">,</span>
                                   <span class="s1">c.noun_stack[-</span><span class="s5">1</span><span class="s1">].token</span><span class="s2">,</span>
                                   <span class="s1">token])</span>
        <span class="s1">c.noun_stack[-</span><span class="s5">1</span><span class="s1">].origin = combined</span>
        <span class="s0"># Pop the open-paren</span>
        <span class="s1">c.op_stack.pop()</span>
        <span class="s2">return False</span>
    <span class="s2">elif </span><span class="s1">token.type </span><span class="s2">in </span><span class="s1">c.binary_ops:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Found binary operator %r&quot; </span><span class="s1">% (token.type))</span>
        <span class="s1">stackop = _StackOperator(c.binary_ops[token.type]</span><span class="s2">, </span><span class="s1">token)</span>
        <span class="s2">while </span><span class="s1">(c.op_stack</span>
               <span class="s2">and </span><span class="s1">stackop.op.precedence &lt;= c.op_stack[-</span><span class="s5">1</span><span class="s1">].op.precedence):</span>
            <span class="s1">_run_op(c)</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Pushing binary operator %r&quot; </span><span class="s1">% (token.type))</span>
        <span class="s1">c.op_stack.append(stackop)</span>
        <span class="s2">return True</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">PatsyError(</span><span class="s3">&quot;expected an operator, not '%s'&quot;</span>
                            <span class="s1">% (token.origin.relevant_code()</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                            <span class="s1">token)</span>

<span class="s2">def </span><span class="s1">infix_parse(tokens</span><span class="s2">, </span><span class="s1">operators</span><span class="s2">, </span><span class="s1">atomic_types</span><span class="s2">, </span><span class="s1">trace=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s1">token_source = iter(tokens)</span>

    <span class="s1">unary_ops = {}</span>
    <span class="s1">binary_ops = {}</span>
    <span class="s2">for </span><span class="s1">op </span><span class="s2">in </span><span class="s1">operators:</span>
        <span class="s2">assert </span><span class="s1">op.precedence &gt; _open_paren.precedence</span>
        <span class="s2">if </span><span class="s1">op.arity == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">unary_ops[op.token_type] = op</span>
        <span class="s2">elif </span><span class="s1">op.arity == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">binary_ops[op.token_type] = op</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;operators must be unary or binary&quot;</span><span class="s1">)</span>

    <span class="s1">c = _ParseContext(unary_ops</span><span class="s2">, </span><span class="s1">binary_ops</span><span class="s2">, </span><span class="s1">atomic_types</span><span class="s2">, </span><span class="s1">trace)</span>

    <span class="s0"># This is an implementation of Dijkstra's shunting yard algorithm:</span>
    <span class="s0">#   http://en.wikipedia.org/wiki/Shunting_yard_algorithm</span>
    <span class="s0">#   http://www.engr.mun.ca/~theo/Misc/exp_parsing.htm</span>

    <span class="s1">want_noun = </span><span class="s2">True</span>
    <span class="s2">for </span><span class="s1">token </span><span class="s2">in </span><span class="s1">token_source:</span>
        <span class="s2">if </span><span class="s1">c.trace:</span>
            <span class="s1">print(</span><span class="s3">&quot;Reading next token (want_noun=%r)&quot; </span><span class="s1">% (want_noun</span><span class="s2">,</span><span class="s1">))</span>
        <span class="s2">if </span><span class="s1">want_noun:</span>
            <span class="s1">want_noun = _read_noun_context(token</span><span class="s2">, </span><span class="s1">c)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">want_noun = _read_op_context(token</span><span class="s2">, </span><span class="s1">c)</span>
    <span class="s2">if </span><span class="s1">c.trace:</span>
        <span class="s1">print(</span><span class="s3">&quot;End of token stream&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">want_noun:</span>
        <span class="s2">raise </span><span class="s1">PatsyError(</span><span class="s3">&quot;expected a noun, but instead the expression ended&quot;</span><span class="s2">,</span>
                            <span class="s1">c.op_stack[-</span><span class="s5">1</span><span class="s1">].token.origin)</span>

    <span class="s2">while </span><span class="s1">c.op_stack:</span>
        <span class="s2">if </span><span class="s1">c.op_stack[-</span><span class="s5">1</span><span class="s1">].op.token_type == Token.LPAREN:</span>
            <span class="s2">raise </span><span class="s1">PatsyError(</span><span class="s3">&quot;Unmatched '('&quot;</span><span class="s2">, </span><span class="s1">c.op_stack[-</span><span class="s5">1</span><span class="s1">].token)</span>
        <span class="s1">_run_op(c)</span>

    <span class="s2">assert </span><span class="s1">len(c.noun_stack) == </span><span class="s5">1</span>
    <span class="s2">return </span><span class="s1">c.noun_stack.pop()</span>

<span class="s0"># Much more thorough tests in parse_formula.py, this is just a smoke test:</span>
<span class="s2">def </span><span class="s1">test_infix_parse():</span>
    <span class="s1">ops = [Operator(</span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">10</span><span class="s1">)</span><span class="s2">,</span>
           <span class="s1">Operator(</span><span class="s3">&quot;*&quot;</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">20</span><span class="s1">)</span><span class="s2">,</span>
           <span class="s1">Operator(</span><span class="s3">&quot;-&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">30</span><span class="s1">)]</span>
    <span class="s1">atomic = [</span><span class="s3">&quot;ATOM1&quot;</span><span class="s2">, </span><span class="s3">&quot;ATOM2&quot;</span><span class="s1">]</span>
    <span class="s0"># a + -b * (c + d)</span>
    <span class="s1">mock_origin = Origin(</span><span class="s3">&quot;asdf&quot;</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span>
    <span class="s1">tokens = [Token(</span><span class="s3">&quot;ATOM1&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;a&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;-&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;-&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;ATOM2&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;b&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;*&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;*&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(Token.LPAREN</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;(&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;ATOM1&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(</span><span class="s3">&quot;ATOM2&quot;</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;d&quot;</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">Token(Token.RPAREN</span><span class="s2">, </span><span class="s1">mock_origin</span><span class="s2">, </span><span class="s3">&quot;)&quot;</span><span class="s1">)]</span>
    <span class="s1">tree = infix_parse(tokens</span><span class="s2">, </span><span class="s1">ops</span><span class="s2">, </span><span class="s1">atomic)</span>
    <span class="s2">def </span><span class="s1">te(tree</span><span class="s2">, </span><span class="s1">type</span><span class="s2">, </span><span class="s1">extra):</span>
        <span class="s2">assert </span><span class="s1">tree.type == type</span>
        <span class="s2">assert </span><span class="s1">tree.token.extra == extra</span>
    <span class="s1">te(tree</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s1">)</span>
    <span class="s1">te(tree.args[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;ATOM1&quot;</span><span class="s2">, </span><span class="s3">&quot;a&quot;</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">tree.args[</span><span class="s5">0</span><span class="s1">].args == []</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;*&quot;</span><span class="s2">, </span><span class="s3">&quot;*&quot;</span><span class="s1">)</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;-&quot;</span><span class="s2">, </span><span class="s3">&quot;-&quot;</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">len(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">0</span><span class="s1">].args) == </span><span class="s5">1</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">0</span><span class="s1">].args[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;ATOM2&quot;</span><span class="s2">, </span><span class="s3">&quot;b&quot;</span><span class="s1">)</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s3">&quot;+&quot;</span><span class="s1">)</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;ATOM1&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s1">)</span>
    <span class="s1">te(tree.args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">1</span><span class="s1">].args[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s3">&quot;ATOM2&quot;</span><span class="s2">, </span><span class="s3">&quot;d&quot;</span><span class="s1">)</span>

    <span class="s2">import </span><span class="s1">pytest</span>
    <span class="s0"># No ternary ops</span>
    <span class="s1">pytest.raises(ValueError</span><span class="s2">,</span>
                  <span class="s1">infix_parse</span><span class="s2">, </span><span class="s1">[]</span><span class="s2">, </span><span class="s1">[Operator(</span><span class="s3">&quot;+&quot;</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">10</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;ATOMIC&quot;</span><span class="s1">])</span>

    <span class="s0"># smoke test just to make sure there are no egregious bugs in 'trace'</span>
    <span class="s1">infix_parse(tokens</span><span class="s2">, </span><span class="s1">ops</span><span class="s2">, </span><span class="s1">atomic</span><span class="s2">, </span><span class="s1">trace=</span><span class="s2">True</span><span class="s1">)</span>
</pre>
</body>
</html>
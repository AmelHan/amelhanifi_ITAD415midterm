<html>
<head>
<title>_scipy_multivariate_t.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_scipy_multivariate_t.py</font>
</center></td></tr></table>
<pre><span class="s0"># flake8: noqa: E501</span>
<span class="s0">#</span>
<span class="s0"># Author: Joris Vankerschaver 2013</span>
<span class="s0">#</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">scipy.linalg</span>
<span class="s2">from </span><span class="s1">scipy._lib </span><span class="s2">import </span><span class="s1">doccer</span>
<span class="s2">from </span><span class="s1">scipy.special </span><span class="s2">import </span><span class="s1">gammaln</span>

<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">check_random_state</span>

<span class="s2">from </span><span class="s1">scipy.stats </span><span class="s2">import </span><span class="s1">mvn</span>

<span class="s1">_LOG_2PI = np.log(</span><span class="s3">2 </span><span class="s1">* np.pi)</span>
<span class="s1">_LOG_2 = np.log(</span><span class="s3">2</span><span class="s1">)</span>
<span class="s1">_LOG_PI = np.log(np.pi)</span>


<span class="s1">_doc_random_state = </span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
</span><span class="s4">random_state : {None, int, np.random.RandomState, np.random.Generator}, optional 
    Used for drawing random variates. 
    If `seed` is `None` the `~np.random.RandomState` singleton is used. 
    If `seed` is an int, a new ``RandomState`` instance is used, seeded 
    with seed. 
    If `seed` is already a ``RandomState`` or ``Generator`` instance, 
    then that object is used. 
    Default is None. 
&quot;&quot;&quot;</span>


<span class="s2">def </span><span class="s1">_squeeze_output(out):</span>
    <span class="s5">&quot;&quot;&quot; 
    Remove single-dimensional entries from array and convert to scalar, 
    if necessary. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">out = out.squeeze()</span>
    <span class="s2">if </span><span class="s1">out.ndim == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s1">out = out[()]</span>
    <span class="s2">return </span><span class="s1">out</span>


<span class="s2">def </span><span class="s1">_eigvalsh_to_eps(spectrum</span><span class="s2">, </span><span class="s1">cond=</span><span class="s2">None, </span><span class="s1">rcond=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Determine which eigenvalues are &quot;small&quot; given the spectrum. 
 
    This is for compatibility across various linear algebra functions 
    that should agree about whether or not a Hermitian matrix is numerically 
    singular and what is its numerical matrix rank. 
    This is designed to be compatible with scipy.linalg.pinvh. 
 
    Parameters 
    ---------- 
    spectrum : 1d ndarray 
        Array of eigenvalues of a Hermitian matrix. 
    cond, rcond : float, optional 
        Cutoff for small eigenvalues. 
        Singular values smaller than rcond * largest_eigenvalue are 
        considered zero. 
        If None or -1, suitable machine precision is used. 
 
    Returns 
    ------- 
    eps : float 
        Magnitude cutoff for numerical negligibility. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">rcond </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">cond = rcond</span>
    <span class="s2">if </span><span class="s1">cond </span><span class="s2">in </span><span class="s1">[</span><span class="s2">None, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]:</span>
        <span class="s1">t = spectrum.dtype.char.lower()</span>
        <span class="s1">factor = {</span><span class="s4">'f'</span><span class="s1">: </span><span class="s3">1E3</span><span class="s2">, </span><span class="s4">'d'</span><span class="s1">: </span><span class="s3">1E6</span><span class="s1">}</span>
        <span class="s1">cond = factor[t] * np.finfo(t).eps</span>
    <span class="s1">eps = cond * np.max(abs(spectrum))</span>
    <span class="s2">return </span><span class="s1">eps</span>


<span class="s2">def </span><span class="s1">_pinv_1d(v</span><span class="s2">, </span><span class="s1">eps=</span><span class="s3">1e-5</span><span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    A helper function for computing the pseudoinverse. 
 
    Parameters 
    ---------- 
    v : iterable of numbers 
        This may be thought of as a vector of eigenvalues or singular values. 
    eps : float 
        Values with magnitude no greater than eps are considered negligible. 
 
    Returns 
    ------- 
    v_pinv : 1d float ndarray 
        A vector of pseudo-inverted numbers. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">np.array([</span><span class="s3">0 </span><span class="s2">if </span><span class="s1">abs(x) &lt;= eps </span><span class="s2">else </span><span class="s3">1</span><span class="s1">/x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">v]</span><span class="s2">, </span><span class="s1">dtype=float)</span>


<span class="s2">class </span><span class="s1">_PSD:</span>
    <span class="s5">&quot;&quot;&quot; 
    Compute coordinated functions of a symmetric positive semidefinite matrix. 
 
    This class addresses two issues.  Firstly it allows the pseudoinverse, 
    the logarithm of the pseudo-determinant, and the rank of the matrix 
    to be computed using one call to eigh instead of three. 
    Secondly it allows these functions to be computed in a way 
    that gives mutually compatible results. 
    All of the functions are computed with a common understanding as to 
    which of the eigenvalues are to be considered negligibly small. 
    The functions are designed to coordinate with scipy.linalg.pinvh() 
    but not necessarily with np.linalg.det() or with np.linalg.matrix_rank(). 
 
    Parameters 
    ---------- 
    M : array_like 
        Symmetric positive semidefinite matrix (2-D). 
    cond, rcond : float, optional 
        Cutoff for small eigenvalues. 
        Singular values smaller than rcond * largest_eigenvalue are 
        considered zero. 
        If None or -1, suitable machine precision is used. 
    lower : bool, optional 
        Whether the pertinent array data is taken from the lower 
        or upper triangle of M. (Default: lower) 
    check_finite : bool, optional 
        Whether to check that the input matrices contain only finite 
        numbers. Disabling may give a performance gain, but may result 
        in problems (crashes, non-termination) if the inputs do contain 
        infinities or NaNs. 
    allow_singular : bool, optional 
        Whether to allow a singular matrix.  (Default: True) 
 
    Notes 
    ----- 
    The arguments are similar to those of scipy.linalg.pinvh(). 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">cond=</span><span class="s2">None, </span><span class="s1">rcond=</span><span class="s2">None, </span><span class="s1">lower=</span><span class="s2">True,</span>
                 <span class="s1">check_finite=</span><span class="s2">True, </span><span class="s1">allow_singular=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0"># Compute the symmetric eigendecomposition.</span>
        <span class="s0"># Note that eigh takes care of array conversion, chkfinite,</span>
        <span class="s0"># and assertion that the matrix is square.</span>
        <span class="s1">s</span><span class="s2">, </span><span class="s1">u = scipy.linalg.eigh(M</span><span class="s2">, </span><span class="s1">lower=lower</span><span class="s2">, </span><span class="s1">check_finite=check_finite)</span>

        <span class="s1">eps = _eigvalsh_to_eps(s</span><span class="s2">, </span><span class="s1">cond</span><span class="s2">, </span><span class="s1">rcond)</span>
        <span class="s2">if </span><span class="s1">np.min(s) &lt; -eps:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">'the input matrix must be positive semidefinite'</span><span class="s1">)</span>
        <span class="s1">d = s[s &gt; eps]</span>
        <span class="s2">if </span><span class="s1">len(d) &lt; len(s) </span><span class="s2">and not </span><span class="s1">allow_singular:</span>
            <span class="s2">raise </span><span class="s1">np.linalg.LinAlgError(</span><span class="s4">'singular matrix'</span><span class="s1">)</span>
        <span class="s1">s_pinv = _pinv_1d(s</span><span class="s2">, </span><span class="s1">eps)</span>
        <span class="s1">U = np.multiply(u</span><span class="s2">, </span><span class="s1">np.sqrt(s_pinv))</span>

        <span class="s0"># Initialize the eagerly precomputed attributes.</span>
        <span class="s1">self.rank = len(d)</span>
        <span class="s1">self.U = U</span>
        <span class="s1">self.log_pdet = np.sum(np.log(d))</span>

        <span class="s0"># Initialize an attribute to be lazily computed.</span>
        <span class="s1">self._pinv = </span><span class="s2">None</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">pinv(self):</span>
        <span class="s2">if </span><span class="s1">self._pinv </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._pinv = np.dot(self.U</span><span class="s2">, </span><span class="s1">self.U.T)</span>
        <span class="s2">return </span><span class="s1">self._pinv</span>


<span class="s2">class </span><span class="s1">multi_rv_generic:</span>
    <span class="s5">&quot;&quot;&quot; 
    Class which encapsulates common functionality between all multivariate 
    distributions. 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">super(multi_rv_generic</span><span class="s2">, </span><span class="s1">self).__init__()</span>
        <span class="s1">self._random_state = check_random_state(seed)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">random_state(self):</span>
        <span class="s5">&quot;&quot;&quot; Get or set the RandomState object for generating random variates. 
 
        This can be either None, int, a RandomState instance, or a 
        np.random.Generator instance. 
 
        If None (or np.random), use the RandomState singleton used by 
        np.random. 
        If already a RandomState or Generator instance, use it. 
        If an int, use a new RandomState instance seeded with seed. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._random_state</span>

    <span class="s1">@random_state.setter</span>
    <span class="s2">def </span><span class="s1">random_state(self</span><span class="s2">, </span><span class="s1">seed):</span>
        <span class="s1">self._random_state = check_random_state(seed)</span>

    <span class="s2">def </span><span class="s1">_get_random_state(self</span><span class="s2">, </span><span class="s1">random_state):</span>
        <span class="s2">if </span><span class="s1">random_state </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">check_random_state(random_state)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._random_state</span>


<span class="s2">class </span><span class="s1">multi_rv_frozen:</span>
    <span class="s5">&quot;&quot;&quot; 
    Class which encapsulates common functionality between all frozen 
    multivariate distributions. 
    &quot;&quot;&quot;</span>
    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">random_state(self):</span>
        <span class="s2">return </span><span class="s1">self._dist._random_state</span>

    <span class="s1">@random_state.setter</span>
    <span class="s2">def </span><span class="s1">random_state(self</span><span class="s2">, </span><span class="s1">seed):</span>
        <span class="s1">self._dist._random_state = check_random_state(seed)</span>


<span class="s1">_mvn_doc_default_callparams = </span><span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
</span><span class="s4">mean : array_like, optional 
    Mean of the distribution (default zero) 
cov : array_like, optional 
    Covariance matrix of the distribution (default one) 
allow_singular : bool, optional 
    Whether to allow a singular covariance matrix.  (Default: False) 
&quot;&quot;&quot;</span>

<span class="s1">_mvn_doc_callparams_note = \</span>
    <span class="s4">&quot;&quot;&quot;Setting the parameter `mean` to `None` is equivalent to having `mean` 
    be the zero-vector. The parameter `cov` can be a scalar, in which case 
    the covariance matrix is the identity times that value, a vector of 
    diagonal entries for the covariance matrix, or a two-dimensional 
    array_like. 
    &quot;&quot;&quot;</span>

<span class="s1">_mvn_doc_frozen_callparams = </span><span class="s4">&quot;&quot;</span>

<span class="s1">_mvn_doc_frozen_callparams_note = \</span>
    <span class="s4">&quot;&quot;&quot;See class definition for a detailed description of parameters.&quot;&quot;&quot;</span>

<span class="s1">mvn_docdict_params = {</span>
    <span class="s4">'_mvn_doc_default_callparams'</span><span class="s1">: _mvn_doc_default_callparams</span><span class="s2">,</span>
    <span class="s4">'_mvn_doc_callparams_note'</span><span class="s1">: _mvn_doc_callparams_note</span><span class="s2">,</span>
    <span class="s4">'_doc_random_state'</span><span class="s1">: _doc_random_state</span>
<span class="s1">}</span>

<span class="s1">mvn_docdict_noparams = {</span>
    <span class="s4">'_mvn_doc_default_callparams'</span><span class="s1">: _mvn_doc_frozen_callparams</span><span class="s2">,</span>
    <span class="s4">'_mvn_doc_callparams_note'</span><span class="s1">: _mvn_doc_frozen_callparams_note</span><span class="s2">,</span>
    <span class="s4">'_doc_random_state'</span><span class="s1">: _doc_random_state</span>
<span class="s1">}</span>


<span class="s2">class </span><span class="s1">multivariate_normal_gen(multi_rv_generic):</span>
    <span class="s5">r&quot;&quot;&quot; 
    A multivariate normal random variable. 
 
    The `mean` keyword specifies the mean. The `cov` keyword specifies the 
    covariance matrix. 
 
    Methods 
    ------- 
    ``pdf(x, mean=None, cov=1, allow_singular=False)`` 
        Probability density function. 
    ``logpdf(x, mean=None, cov=1, allow_singular=False)`` 
        Log of the probability density function. 
    ``cdf(x, mean=None, cov=1, allow_singular=False, maxpts=1000000*dim, abseps=1e-5, releps=1e-5)`` 
        Cumulative distribution function. 
    ``logcdf(x, mean=None, cov=1, allow_singular=False, maxpts=1000000*dim, abseps=1e-5, releps=1e-5)`` 
        Log of the cumulative distribution function. 
    ``rvs(mean=None, cov=1, size=1, random_state=None)`` 
        Draw random samples from a multivariate normal distribution. 
    ``entropy()`` 
        Compute the differential entropy of the multivariate normal. 
 
    Parameters 
    ---------- 
    x : array_like 
        Quantiles, with the last axis of `x` denoting the components. 
    %(_mvn_doc_default_callparams)s 
    %(_doc_random_state)s 
 
    Alternatively, the object may be called (as a function) to fix the mean 
    and covariance parameters, returning a &quot;frozen&quot; multivariate normal 
    random variable: 
 
    rv = multivariate_normal(mean=None, cov=1, allow_singular=False) 
        - Frozen object with the same methods but holding the given 
          mean and covariance fixed. 
 
    Notes 
    ----- 
    %(_mvn_doc_callparams_note)s 
 
    The covariance matrix `cov` must be a (symmetric) positive 
    semi-definite matrix. The determinant and inverse of `cov` are computed 
    as the pseudo-determinant and pseudo-inverse, respectively, so 
    that `cov` does not need to have full rank. 
 
    The probability density function for `multivariate_normal` is 
 
    .. math:: 
 
        f(x) = \frac{1}{\sqrt{(2 \pi)^k \det \Sigma}} 
               \exp\left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right), 
 
    where :math:`\mu` is the mean, :math:`\Sigma` the covariance matrix, 
    and :math:`k` is the dimension of the space where :math:`x` takes values. 
 
    .. versionadded:: 0.14.0 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.stats import multivariate_normal 
 
    &gt;&gt;&gt; x = np.linspace(0, 5, 10, endpoint=False) 
    &gt;&gt;&gt; y = multivariate_normal.pdf(x, mean=2.5, cov=0.5); y 
    array([ 0.00108914,  0.01033349,  0.05946514,  0.20755375,  0.43939129, 
            0.56418958,  0.43939129,  0.20755375,  0.05946514,  0.01033349]) 
    &gt;&gt;&gt; fig1 = plt.figure() 
    &gt;&gt;&gt; ax = fig1.add_subplot(111) 
    &gt;&gt;&gt; ax.plot(x, y) 
 
    The input quantiles can be any shape of array, as long as the last 
    axis labels the components.  This allows us for instance to 
    display the frozen pdf for a non-isotropic random variable in 2D as 
    follows: 
 
    &gt;&gt;&gt; x, y = np.mgrid[-1:1:.01, -1:1:.01] 
    &gt;&gt;&gt; pos = np.dstack((x, y)) 
    &gt;&gt;&gt; rv = multivariate_normal([0.5, -0.2], [[2.0, 0.3], [0.3, 0.5]]) 
    &gt;&gt;&gt; fig2 = plt.figure() 
    &gt;&gt;&gt; ax2 = fig2.add_subplot(111) 
    &gt;&gt;&gt; ax2.contourf(x, y, rv.pdf(pos)) 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">super(multivariate_normal_gen</span><span class="s2">, </span><span class="s1">self).__init__(seed)</span>
        <span class="s1">self.__doc__ = doccer.docformat(self.__doc__</span><span class="s2">, </span><span class="s1">mvn_docdict_params)</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False, </span><span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Create a frozen multivariate normal distribution. 
 
        See `multivariate_normal_frozen` for more information. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">multivariate_normal_frozen(mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">,</span>
                                          <span class="s1">allow_singular=allow_singular</span><span class="s2">,</span>
                                          <span class="s1">seed=seed)</span>

    <span class="s2">def </span><span class="s1">_process_parameters(self</span><span class="s2">, </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov):</span>
        <span class="s5">&quot;&quot;&quot; 
        Infer dimensionality from mean or covariance matrix, ensure that 
        mean and covariance are full vector resp. matrix. 
 
        &quot;&quot;&quot;</span>

        <span class="s0"># Try to infer dimensionality</span>
        <span class="s2">if </span><span class="s1">dim </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">mean </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">cov </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s1">dim = </span><span class="s3">1</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">cov = np.asarray(cov</span><span class="s2">, </span><span class="s1">dtype=float)</span>
                    <span class="s2">if </span><span class="s1">cov.ndim &lt; </span><span class="s3">2</span><span class="s1">:</span>
                        <span class="s1">dim = </span><span class="s3">1</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">dim = cov.shape[</span><span class="s3">0</span><span class="s1">]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">mean = np.asarray(mean</span><span class="s2">, </span><span class="s1">dtype=float)</span>
                <span class="s1">dim = mean.size</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">np.isscalar(dim):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Dimension of random variable must be &quot;</span>
                                 <span class="s4">&quot;a scalar.&quot;</span><span class="s1">)</span>

        <span class="s0"># Check input sizes and return full arrays for mean and cov if</span>
        <span class="s0"># necessary</span>
        <span class="s2">if </span><span class="s1">mean </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">mean = np.zeros(dim)</span>
        <span class="s1">mean = np.asarray(mean</span><span class="s2">, </span><span class="s1">dtype=float)</span>

        <span class="s2">if </span><span class="s1">cov </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cov = </span><span class="s3">1.0</span>
        <span class="s1">cov = np.asarray(cov</span><span class="s2">, </span><span class="s1">dtype=float)</span>

        <span class="s2">if </span><span class="s1">dim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">mean.shape = (</span><span class="s3">1</span><span class="s2">,</span><span class="s1">)</span>
            <span class="s1">cov.shape = (</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">mean.ndim != </span><span class="s3">1 </span><span class="s2">or </span><span class="s1">mean.shape[</span><span class="s3">0</span><span class="s1">] != dim:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Array 'mean' must be a vector of length %d.&quot; </span><span class="s1">%</span>
                             <span class="s1">dim)</span>
        <span class="s2">if </span><span class="s1">cov.ndim == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">cov = cov * np.eye(dim)</span>
        <span class="s2">elif </span><span class="s1">cov.ndim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">cov = np.diag(cov)</span>
        <span class="s2">elif </span><span class="s1">cov.ndim == </span><span class="s3">2 </span><span class="s2">and </span><span class="s1">cov.shape != (dim</span><span class="s2">, </span><span class="s1">dim):</span>
            <span class="s1">rows</span><span class="s2">, </span><span class="s1">cols = cov.shape</span>
            <span class="s2">if </span><span class="s1">rows != cols:</span>
                <span class="s1">msg = (</span><span class="s4">&quot;Array 'cov' must be square if it is two dimensional,&quot;</span>
                       <span class="s4">&quot; but cov.shape = %s.&quot; </span><span class="s1">% str(cov.shape))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">msg = (</span><span class="s4">&quot;Dimension mismatch: array 'cov' is of shape %s,&quot;</span>
                       <span class="s4">&quot; but 'mean' is a vector of length %d.&quot;</span><span class="s1">)</span>
                <span class="s1">msg = msg % (str(cov.shape)</span><span class="s2">, </span><span class="s1">len(mean))</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
        <span class="s2">elif </span><span class="s1">cov.ndim &gt; </span><span class="s3">2</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Array 'cov' must be at most two-dimensional,&quot;</span>
                             <span class="s4">&quot; but cov.ndim = %d&quot; </span><span class="s1">% cov.ndim)</span>

        <span class="s2">return </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov</span>

    <span class="s2">def </span><span class="s1">_process_quantiles(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dim):</span>
        <span class="s5">&quot;&quot;&quot; 
        Adjust quantiles array so that last axis labels the components of 
        each data point. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">x = np.asarray(x</span><span class="s2">, </span><span class="s1">dtype=float)</span>

        <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">x = x[np.newaxis]</span>
        <span class="s2">elif </span><span class="s1">x.ndim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">dim == </span><span class="s3">1</span><span class="s1">:</span>
                <span class="s1">x = x[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">x = x[np.newaxis</span><span class="s2">, </span><span class="s1">:]</span>

        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">prec_U</span><span class="s2">, </span><span class="s1">log_det_cov</span><span class="s2">, </span><span class="s1">rank):</span>
        <span class="s5">&quot;&quot;&quot; 
        Parameters 
        ---------- 
        x : ndarray 
            Points at which to evaluate the log of the probability 
            density function 
        mean : ndarray 
            Mean of the distribution 
        prec_U : ndarray 
            A decomposition such that np.dot(prec_U, prec_U.T) 
            is the precision matrix, i.e. inverse of the covariance matrix. 
        log_det_cov : float 
            Logarithm of the determinant of the covariance matrix 
        rank : int 
            Rank of the covariance matrix. 
 
        Notes 
        ----- 
        As this function does no argument checking, it should not be 
        called directly; use 'logpdf' instead. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dev = x - mean</span>
        <span class="s1">maha = np.sum(np.square(np.dot(dev</span><span class="s2">, </span><span class="s1">prec_U))</span><span class="s2">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s3">0.5 </span><span class="s1">* (rank * _LOG_2PI + log_det_cov + maha)</span>

    <span class="s2">def </span><span class="s1">logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Log of the multivariate normal probability density function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Quantiles, with the last axis of `x` denoting the components. 
        %(_mvn_doc_default_callparams)s 
 
        Returns 
        ------- 
        pdf : ndarray or scalar 
            Log of the probability density function evaluated at `x` 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s1">psd = _PSD(cov</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s1">out = self._logpdf(x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">psd.U</span><span class="s2">, </span><span class="s1">psd.log_pdet</span><span class="s2">, </span><span class="s1">psd.rank)</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Multivariate normal probability density function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Quantiles, with the last axis of `x` denoting the components. 
        %(_mvn_doc_default_callparams)s 
 
        Returns 
        ------- 
        pdf : ndarray or scalar 
            Probability density function evaluated at `x` 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s1">psd = _PSD(cov</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s1">out = np.exp(self._logpdf(x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">psd.U</span><span class="s2">, </span><span class="s1">psd.log_pdet</span><span class="s2">, </span><span class="s1">psd.rank))</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">, </span><span class="s1">maxpts</span><span class="s2">, </span><span class="s1">abseps</span><span class="s2">, </span><span class="s1">releps):</span>
        <span class="s5">&quot;&quot;&quot; 
        Parameters 
        ---------- 
        x : ndarray 
            Points at which to evaluate the cumulative distribution function. 
        mean : ndarray 
            Mean of the distribution 
        cov : array_like 
            Covariance matrix of the distribution 
        maxpts: integer 
            The maximum number of points to use for integration 
        abseps: float 
            Absolute error tolerance 
        releps: float 
            Relative error tolerance 
 
        Notes 
        ----- 
        As this function does no argument checking, it should not be 
        called directly; use 'cdf' instead. 
 
        .. versionadded:: 1.0.0 
 
        &quot;&quot;&quot;</span>
        <span class="s1">lower = np.full(mean.shape</span><span class="s2">, </span><span class="s1">-np.inf)</span>
        <span class="s0"># mvnun expects 1-d arguments, so process points sequentially</span>
        <span class="s1">func1d = </span><span class="s2">lambda </span><span class="s1">x_slice: mvn.mvnun(lower</span><span class="s2">, </span><span class="s1">x_slice</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">,</span>
                                           <span class="s1">maxpts</span><span class="s2">, </span><span class="s1">abseps</span><span class="s2">, </span><span class="s1">releps)[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">out = np.apply_along_axis(func1d</span><span class="s2">, </span><span class="s1">-</span><span class="s3">1</span><span class="s2">, </span><span class="s1">x)</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False, </span><span class="s1">maxpts=</span><span class="s2">None,</span>
               <span class="s1">abseps=</span><span class="s3">1e-5</span><span class="s2">, </span><span class="s1">releps=</span><span class="s3">1e-5</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Log of the multivariate normal cumulative distribution function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Quantiles, with the last axis of `x` denoting the components. 
        %(_mvn_doc_default_callparams)s 
        maxpts: integer, optional 
            The maximum number of points to use for integration 
            (default `1000000*dim`) 
        abseps: float, optional 
            Absolute error tolerance (default 1e-5) 
        releps: float, optional 
            Relative error tolerance (default 1e-5) 
 
        Returns 
        ------- 
        cdf : ndarray or scalar 
            Log of the cumulative distribution function evaluated at `x` 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        .. versionadded:: 1.0.0 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s0"># Use _PSD to check covariance matrix</span>
        <span class="s1">_PSD(cov</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s2">if not </span><span class="s1">maxpts:</span>
            <span class="s1">maxpts = </span><span class="s3">1000000 </span><span class="s1">* dim</span>
        <span class="s1">out = np.log(self._cdf(x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">, </span><span class="s1">maxpts</span><span class="s2">, </span><span class="s1">abseps</span><span class="s2">, </span><span class="s1">releps))</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False, </span><span class="s1">maxpts=</span><span class="s2">None,</span>
            <span class="s1">abseps=</span><span class="s3">1e-5</span><span class="s2">, </span><span class="s1">releps=</span><span class="s3">1e-5</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Multivariate normal cumulative distribution function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Quantiles, with the last axis of `x` denoting the components. 
        %(_mvn_doc_default_callparams)s 
        maxpts: integer, optional 
            The maximum number of points to use for integration 
            (default `1000000*dim`) 
        abseps: float, optional 
            Absolute error tolerance (default 1e-5) 
        releps: float, optional 
            Relative error tolerance (default 1e-5) 
 
        Returns 
        ------- 
        cdf : ndarray or scalar 
            Cumulative distribution function evaluated at `x` 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        .. versionadded:: 1.0.0 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s0"># Use _PSD to check covariance matrix</span>
        <span class="s1">_PSD(cov</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s2">if not </span><span class="s1">maxpts:</span>
            <span class="s1">maxpts = </span><span class="s3">1000000 </span><span class="s1">* dim</span>
        <span class="s1">out = self._cdf(x</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">, </span><span class="s1">maxpts</span><span class="s2">, </span><span class="s1">abseps</span><span class="s2">, </span><span class="s1">releps)</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">size=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Draw random samples from a multivariate normal distribution. 
 
        Parameters 
        ---------- 
        %(_mvn_doc_default_callparams)s 
        size : integer, optional 
            Number of samples to draw (default 1). 
        %(_doc_random_state)s 
 
        Returns 
        ------- 
        rvs : ndarray or scalar 
            Random variates of size (`size`, `N`), where `N` is the 
            dimension of the random variable. 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>

        <span class="s1">random_state = self._get_random_state(random_state)</span>
        <span class="s1">out = random_state.multivariate_normal(mean</span><span class="s2">, </span><span class="s1">cov</span><span class="s2">, </span><span class="s1">size)</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">entropy(self</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Compute the differential entropy of the multivariate normal. 
 
        Parameters 
        ---------- 
        %(_mvn_doc_default_callparams)s 
 
        Returns 
        ------- 
        h : scalar 
            Entropy of the multivariate normal distribution 
 
        Notes 
        ----- 
        %(_mvn_doc_callparams_note)s 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov = self._process_parameters(</span><span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">logdet = np.linalg.slogdet(</span><span class="s3">2 </span><span class="s1">* np.pi * np.e * cov)</span>
        <span class="s2">return </span><span class="s3">0.5 </span><span class="s1">* logdet</span>


<span class="s1">multivariate_normal = multivariate_normal_gen()</span>


<span class="s2">class </span><span class="s1">multivariate_normal_frozen(multi_rv_frozen):</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">mean=</span><span class="s2">None, </span><span class="s1">cov=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False, </span><span class="s1">seed=</span><span class="s2">None,</span>
                 <span class="s1">maxpts=</span><span class="s2">None, </span><span class="s1">abseps=</span><span class="s3">1e-5</span><span class="s2">, </span><span class="s1">releps=</span><span class="s3">1e-5</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Create a frozen multivariate normal distribution. 
 
        Parameters 
        ---------- 
        mean : array_like, optional 
            Mean of the distribution (default zero) 
        cov : array_like, optional 
            Covariance matrix of the distribution (default one) 
        allow_singular : bool, optional 
            If this flag is True then tolerate a singular 
            covariance matrix (default False). 
        seed : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional 
            This parameter defines the object to use for drawing random 
            variates. 
            If `seed` is `None` the `~np.random.RandomState` singleton is used. 
            If `seed` is an int, a new ``RandomState`` instance is used, seeded 
            with seed. 
            If `seed` is already a ``RandomState`` or ``Generator`` instance, 
            then that object is used. 
            Default is None. 
        maxpts: integer, optional 
            The maximum number of points to use for integration of the 
            cumulative distribution function (default `1000000*dim`) 
        abseps: float, optional 
            Absolute error tolerance for the cumulative distribution function 
            (default 1e-5) 
        releps: float, optional 
            Relative error tolerance for the cumulative distribution function 
            (default 1e-5) 
 
        Examples 
        -------- 
        When called with the default parameters, this will create a 1D random 
        variable with mean 0 and covariance 1: 
 
        &gt;&gt;&gt; from scipy.stats import multivariate_normal 
        &gt;&gt;&gt; r = multivariate_normal() 
        &gt;&gt;&gt; r.mean 
        array([ 0.]) 
        &gt;&gt;&gt; r.cov 
        array([[1.]]) 
 
        &quot;&quot;&quot;</span>
        <span class="s1">self._dist = multivariate_normal_gen(seed)</span>
        <span class="s1">self.dim</span><span class="s2">, </span><span class="s1">self.mean</span><span class="s2">, </span><span class="s1">self.cov = self._dist._process_parameters(</span>
                                                            <span class="s2">None, </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">cov)</span>
        <span class="s1">self.cov_info = _PSD(self.cov</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s2">if not </span><span class="s1">maxpts:</span>
            <span class="s1">maxpts = </span><span class="s3">1000000 </span><span class="s1">* self.dim</span>
        <span class="s1">self.maxpts = maxpts</span>
        <span class="s1">self.abseps = abseps</span>
        <span class="s1">self.releps = releps</span>

    <span class="s2">def </span><span class="s1">logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">x = self._dist._process_quantiles(x</span><span class="s2">, </span><span class="s1">self.dim)</span>
        <span class="s1">out = self._dist._logpdf(x</span><span class="s2">, </span><span class="s1">self.mean</span><span class="s2">, </span><span class="s1">self.cov_info.U</span><span class="s2">,</span>
                                 <span class="s1">self.cov_info.log_pdet</span><span class="s2">, </span><span class="s1">self.cov_info.rank)</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(self.logpdf(x))</span>

    <span class="s2">def </span><span class="s1">logcdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.log(self.cdf(x))</span>

    <span class="s2">def </span><span class="s1">cdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">x = self._dist._process_quantiles(x</span><span class="s2">, </span><span class="s1">self.dim)</span>
        <span class="s1">out = self._dist._cdf(x</span><span class="s2">, </span><span class="s1">self.mean</span><span class="s2">, </span><span class="s1">self.cov</span><span class="s2">, </span><span class="s1">self.maxpts</span><span class="s2">, </span><span class="s1">self.abseps</span><span class="s2">,</span>
                              <span class="s1">self.releps)</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(out)</span>

    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">self._dist.rvs(self.mean</span><span class="s2">, </span><span class="s1">self.cov</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state)</span>

    <span class="s2">def </span><span class="s1">entropy(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        Computes the differential entropy of the multivariate normal. 
 
        Returns 
        ------- 
        h : scalar 
            Entropy of the multivariate normal distribution 
 
        &quot;&quot;&quot;</span>
        <span class="s1">log_pdet = self.cov_info.log_pdet</span>
        <span class="s1">rank = self.cov_info.rank</span>
        <span class="s2">return </span><span class="s3">0.5 </span><span class="s1">* (rank * (_LOG_2PI + </span><span class="s3">1</span><span class="s1">) + log_pdet)</span>


<span class="s1">_mvt_doc_default_callparams = \</span>
<span class="s4">&quot;&quot;&quot; 
loc : array_like, optional 
    Location of the distribution. (default ``0``) 
shape : array_like, optional 
    Positive semidefinite matrix of the distribution. (default ``1``) 
df : float, optional 
    Degrees of freedom of the distribution; must be greater than zero. 
    If ``np.inf`` then results are multivariate normal. The default is ``1``. 
allow_singular : bool, optional 
    Whether to allow a singular matrix. (default ``False``) 
&quot;&quot;&quot;</span>

<span class="s1">_mvt_doc_callparams_note = \</span>
<span class="s4">&quot;&quot;&quot;Setting the parameter `loc` to ``None`` is equivalent to having `loc` 
be the zero-vector. The parameter `shape` can be a scalar, in which case 
the shape matrix is the identity times that value, a vector of 
diagonal entries for the shape matrix, or a two-dimensional array_like. 
&quot;&quot;&quot;</span>

<span class="s1">_mvt_doc_frozen_callparams_note = \</span>
<span class="s4">&quot;&quot;&quot;See class definition for a detailed description of parameters.&quot;&quot;&quot;</span>

<span class="s1">mvt_docdict_params = {</span>
    <span class="s4">'_mvt_doc_default_callparams'</span><span class="s1">: _mvt_doc_default_callparams</span><span class="s2">,</span>
    <span class="s4">'_mvt_doc_callparams_note'</span><span class="s1">: _mvt_doc_callparams_note</span><span class="s2">,</span>
    <span class="s4">'_doc_random_state'</span><span class="s1">: _doc_random_state</span>
<span class="s1">}</span>

<span class="s1">mvt_docdict_noparams = {</span>
    <span class="s4">'_mvt_doc_default_callparams'</span><span class="s1">: </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">'_mvt_doc_callparams_note'</span><span class="s1">: _mvt_doc_frozen_callparams_note</span><span class="s2">,</span>
    <span class="s4">'_doc_random_state'</span><span class="s1">: _doc_random_state</span>
<span class="s1">}</span>


<span class="s2">class </span><span class="s1">multivariate_t_gen(multi_rv_generic):</span>
    <span class="s5">r&quot;&quot;&quot; 
    A multivariate t-distributed random variable. 
 
    The `loc` parameter specifies the location. The `shape` parameter specifies 
    the positive semidefinite shape matrix. The `df` parameter specifies the 
    degrees of freedom. 
 
    In addition to calling the methods below, the object itself may be called 
    as a function to fix the location, shape matrix, and degrees of freedom 
    parameters, returning a &quot;frozen&quot; multivariate t-distribution random. 
 
    Methods 
    ------- 
    ``pdf(x, loc=None, shape=1, df=1, allow_singular=False)`` 
        Probability density function. 
    ``logpdf(x, loc=None, shape=1, df=1, allow_singular=False)`` 
        Log of the probability density function. 
    ``rvs(loc=None, shape=1, df=1, size=1, random_state=None)`` 
        Draw random samples from a multivariate t-distribution. 
 
    Parameters 
    ---------- 
    x : array_like 
        Quantiles, with the last axis of `x` denoting the components. 
    %(_mvt_doc_default_callparams)s 
    %(_doc_random_state)s 
 
    Notes 
    ----- 
    %(_mvt_doc_callparams_note)s 
    The matrix `shape` must be a (symmetric) positive semidefinite matrix. The 
    determinant and inverse of `shape` are computed as the pseudo-determinant 
    and pseudo-inverse, respectively, so that `shape` does not need to have 
    full rank. 
 
    The probability density function for `multivariate_t` is 
 
    .. math:: 
 
        f(x) = \frac{\Gamma(\nu + p)/2}{\Gamma(\nu/2)\nu^{p/2}\pi^{p/2}|\Sigma|^{1/2}} 
               \exp\left[1 + \frac{1}{\nu} (\mathbf{x} - \boldsymbol{\mu})^{\top} 
               \boldsymbol{\Sigma}^{-1} 
               (\mathbf{x} - \boldsymbol{\mu}) \right]^{-(\nu + p)/2}, 
 
    where :math:`p` is the dimension of :math:`\mathbf{x}`, 
    :math:`\boldsymbol{\mu}` is the :math:`p`-dimensional location, 
    :math:`\boldsymbol{\Sigma}` the :math:`p \times p`-dimensional shape 
    matrix, and :math:`\nu` is the degrees of freedom. 
 
    .. versionadded:: 1.6.0 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy.stats import multivariate_t 
    &gt;&gt;&gt; x, y = np.mgrid[-1:3:.01, -2:1.5:.01] 
    &gt;&gt;&gt; pos = np.dstack((x, y)) 
    &gt;&gt;&gt; rv = multivariate_t([1.0, -0.5], [[2.1, 0.3], [0.3, 1.5]], df=2) 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
    &gt;&gt;&gt; ax.set_aspect('equal') 
    &gt;&gt;&gt; plt.contourf(x, y, rv.pdf(pos)) 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Initialize a multivariate t-distributed random variable. 
 
        Parameters 
        ---------- 
        seed : Random state. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">super(multivariate_t_gen</span><span class="s2">, </span><span class="s1">self).__init__(seed)</span>
        <span class="s1">self.__doc__ = doccer.docformat(self.__doc__</span><span class="s2">, </span><span class="s1">mvt_docdict_params)</span>
        <span class="s1">self._random_state = check_random_state(seed)</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">loc=</span><span class="s2">None, </span><span class="s1">shape=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">df=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False,</span>
                 <span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Create a frozen multivariate t-distribution. See 
        `multivariate_t_frozen` for parameters. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">df == np.inf:</span>
            <span class="s2">return </span><span class="s1">multivariate_normal_frozen(mean=loc</span><span class="s2">, </span><span class="s1">cov=shape</span><span class="s2">,</span>
                                              <span class="s1">allow_singular=allow_singular</span><span class="s2">,</span>
                                              <span class="s1">seed=seed)</span>
        <span class="s2">return </span><span class="s1">multivariate_t_frozen(loc=loc</span><span class="s2">, </span><span class="s1">shape=shape</span><span class="s2">, </span><span class="s1">df=df</span><span class="s2">,</span>
                                     <span class="s1">allow_singular=allow_singular</span><span class="s2">, </span><span class="s1">seed=seed)</span>

    <span class="s2">def </span><span class="s1">pdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">loc=</span><span class="s2">None, </span><span class="s1">shape=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">df=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Multivariate t-distribution probability density function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Points at which to evaluate the probability density function. 
        %(_mvt_doc_default_callparams)s 
 
        Returns 
        ------- 
        pdf : Probability density function evaluated at `x`. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; from scipy.stats import multivariate_t 
        &gt;&gt;&gt; x = [0.4, 5] 
        &gt;&gt;&gt; loc = [0, 1] 
        &gt;&gt;&gt; shape = [[1, 0.1], [0.1, 1]] 
        &gt;&gt;&gt; df = 7 
        &gt;&gt;&gt; multivariate_t.pdf(x, loc, shape, df) 
        array([0.00075713]) 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df = self._process_parameters(loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s1">shape_info = _PSD(shape</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>
        <span class="s1">logpdf = self._logpdf(x</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape_info.U</span><span class="s2">, </span><span class="s1">shape_info.log_pdet</span><span class="s2">, </span><span class="s1">df</span><span class="s2">,</span>
                              <span class="s1">dim</span><span class="s2">, </span><span class="s1">shape_info.rank)</span>
        <span class="s2">return </span><span class="s1">np.exp(logpdf)</span>

    <span class="s2">def </span><span class="s1">logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">loc=</span><span class="s2">None, </span><span class="s1">shape=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">df=</span><span class="s3">1</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Log of the multivariate t-distribution probability density function. 
 
        Parameters 
        ---------- 
        x : array_like 
            Points at which to evaluate the log of the probability density 
            function. 
        %(_mvt_doc_default_callparams)s 
 
        Returns 
        ------- 
        logpdf : Log of the probability density function evaluated at `x`. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; from scipy.stats import multivariate_t 
        &gt;&gt;&gt; x = [0.4, 5] 
        &gt;&gt;&gt; loc = [0, 1] 
        &gt;&gt;&gt; shape = [[1, 0.1], [0.1, 1]] 
        &gt;&gt;&gt; df = 7 
        &gt;&gt;&gt; multivariate_t.logpdf(x, loc, shape, df) 
        array([-7.1859802]) 
 
        See Also 
        -------- 
        pdf : Probability density function. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df = self._process_parameters(loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df)</span>
        <span class="s1">x = self._process_quantiles(x</span><span class="s2">, </span><span class="s1">dim)</span>
        <span class="s1">shape_info = _PSD(shape)</span>
        <span class="s2">return </span><span class="s1">self._logpdf(x</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape_info.U</span><span class="s2">, </span><span class="s1">shape_info.log_pdet</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">dim</span><span class="s2">,</span>
                            <span class="s1">shape_info.rank)</span>

    <span class="s2">def </span><span class="s1">_logpdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">prec_U</span><span class="s2">, </span><span class="s1">log_pdet</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">rank):</span>
        <span class="s5">&quot;&quot;&quot;Utility method `pdf`, `logpdf` for parameters. 
 
        Parameters 
        ---------- 
        x : ndarray 
            Points at which to evaluate the log of the probability density 
            function. 
        loc : ndarray 
            Location of the distribution. 
        prec_U : ndarray 
            A decomposition such that `np.dot(prec_U, prec_U.T)` is the inverse 
            of the shape matrix. 
        log_pdet : float 
            Logarithm of the determinant of the shape matrix. 
        df : float 
            Degrees of freedom of the distribution. 
        dim : int 
            Dimension of the quantiles x. 
        rank : int 
            Rank of the shape matrix. 
 
        Notes 
        ----- 
        As this function does no argument checking, it should not be called 
        directly; use 'logpdf' instead. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">df == np.inf:</span>
            <span class="s2">return </span><span class="s1">multivariate_normal._logpdf(x</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">prec_U</span><span class="s2">, </span><span class="s1">log_pdet</span><span class="s2">, </span><span class="s1">rank)</span>

        <span class="s1">dev = x - loc</span>
        <span class="s1">maha = np.square(np.dot(dev</span><span class="s2">, </span><span class="s1">prec_U)).sum(axis=-</span><span class="s3">1</span><span class="s1">)</span>

        <span class="s1">t = </span><span class="s3">0.5 </span><span class="s1">* (df + dim)</span>
        <span class="s1">A = gammaln(t)</span>
        <span class="s1">B = gammaln(</span><span class="s3">0.5 </span><span class="s1">* df)</span>
        <span class="s1">C = dim/</span><span class="s3">2. </span><span class="s1">* np.log(df * np.pi)</span>
        <span class="s1">D = </span><span class="s3">0.5 </span><span class="s1">* log_pdet</span>
        <span class="s1">E = -t * np.log(</span><span class="s3">1 </span><span class="s1">+ (</span><span class="s3">1.</span><span class="s1">/df) * maha)</span>

        <span class="s2">return </span><span class="s1">_squeeze_output(A - B - C - D + E)</span>

    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">loc=</span><span class="s2">None, </span><span class="s1">shape=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">df=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">size=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Draw random samples from a multivariate t-distribution. 
 
        Parameters 
        ---------- 
        %(_mvt_doc_default_callparams)s 
        size : integer, optional 
            Number of samples to draw (default 1). 
        %(_doc_random_state)s 
 
        Returns 
        ------- 
        rvs : ndarray or scalar 
            Random variates of size (`size`, `P`), where `P` is the 
            dimension of the random variable. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; from scipy.stats import multivariate_t 
        &gt;&gt;&gt; x = [0.4, 5] 
        &gt;&gt;&gt; loc = [0, 1] 
        &gt;&gt;&gt; shape = [[1, 0.1], [0.1, 1]] 
        &gt;&gt;&gt; df = 7 
        &gt;&gt;&gt; multivariate_t.rvs(loc, shape, df) 
        array([[0.93477495, 3.00408716]]) 
 
        &quot;&quot;&quot;</span>
        <span class="s0"># For implementation details, see equation (3):</span>
        <span class="s0">#</span>
        <span class="s0">#    Hofert, &quot;On Sampling from the Multivariatet Distribution&quot;, 2013</span>
        <span class="s0">#     http://rjournal.github.io/archive/2013-2/hofert.pdf</span>
        <span class="s0">#</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df = self._process_parameters(loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df)</span>
        <span class="s2">if </span><span class="s1">random_state </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">rng = check_random_state(random_state)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">rng = self._random_state</span>

        <span class="s2">if </span><span class="s1">np.isinf(df):</span>
            <span class="s1">x = np.ones(size)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">x = rng.chisquare(df</span><span class="s2">, </span><span class="s1">size=size) / df</span>

        <span class="s1">z = rng.multivariate_normal(np.zeros(dim)</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">size=size)</span>
        <span class="s1">samples = loc + z / np.sqrt(x)[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">_squeeze_output(samples)</span>

    <span class="s2">def </span><span class="s1">_process_quantiles(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">dim):</span>
        <span class="s5">&quot;&quot;&quot; 
        Adjust quantiles array so that last axis labels the components of 
        each data point. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">x = np.asarray(x</span><span class="s2">, </span><span class="s1">dtype=float)</span>
        <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">x = x[np.newaxis]</span>
        <span class="s2">elif </span><span class="s1">x.ndim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">dim == </span><span class="s3">1</span><span class="s1">:</span>
                <span class="s1">x = x[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">x = x[np.newaxis</span><span class="s2">, </span><span class="s1">:]</span>
        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">def </span><span class="s1">_process_parameters(self</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df):</span>
        <span class="s5">&quot;&quot;&quot; 
        Infer dimensionality from location array and shape matrix, handle 
        defaults, and ensure compatible dimensions. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">loc </span><span class="s2">is None and </span><span class="s1">shape </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">loc = np.asarray(</span><span class="s3">0</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">shape = np.asarray(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">dim = </span><span class="s3">1</span>
        <span class="s2">elif </span><span class="s1">loc </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">shape = np.asarray(shape</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s2">if </span><span class="s1">shape.ndim &lt; </span><span class="s3">2</span><span class="s1">:</span>
                <span class="s1">dim = </span><span class="s3">1</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">dim = shape.shape[</span><span class="s3">0</span><span class="s1">]</span>
            <span class="s1">loc = np.zeros(dim)</span>
        <span class="s2">elif </span><span class="s1">shape </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">loc = np.asarray(loc</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">dim = loc.size</span>
            <span class="s1">shape = np.eye(dim)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">shape = np.asarray(shape</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">loc = np.asarray(loc</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">dim = loc.size</span>

        <span class="s2">if </span><span class="s1">dim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">loc.shape = (</span><span class="s3">1</span><span class="s2">,</span><span class="s1">)</span>
            <span class="s1">shape.shape = (</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">loc.ndim != </span><span class="s3">1 </span><span class="s2">or </span><span class="s1">loc.shape[</span><span class="s3">0</span><span class="s1">] != dim:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Array 'loc' must be a vector of length %d.&quot; </span><span class="s1">%</span>
                             <span class="s1">dim)</span>
        <span class="s2">if </span><span class="s1">shape.ndim == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">shape = shape * np.eye(dim)</span>
        <span class="s2">elif </span><span class="s1">shape.ndim == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">shape = np.diag(shape)</span>
        <span class="s2">elif </span><span class="s1">shape.ndim == </span><span class="s3">2 </span><span class="s2">and </span><span class="s1">shape.shape != (dim</span><span class="s2">, </span><span class="s1">dim):</span>
            <span class="s1">rows</span><span class="s2">, </span><span class="s1">cols = shape.shape</span>
            <span class="s2">if </span><span class="s1">rows != cols:</span>
                <span class="s1">msg = (</span><span class="s4">&quot;Array 'cov' must be square if it is two dimensional,&quot;</span>
                       <span class="s4">&quot; but cov.shape = %s.&quot; </span><span class="s1">% str(shape.shape))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">msg = (</span><span class="s4">&quot;Dimension mismatch: array 'cov' is of shape %s,&quot;</span>
                       <span class="s4">&quot; but 'loc' is a vector of length %d.&quot;</span><span class="s1">)</span>
                <span class="s1">msg = msg % (str(shape.shape)</span><span class="s2">, </span><span class="s1">len(loc))</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
        <span class="s2">elif </span><span class="s1">shape.ndim &gt; </span><span class="s3">2</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Array 'cov' must be at most two-dimensional,&quot;</span>
                             <span class="s4">&quot; but cov.ndim = %d&quot; </span><span class="s1">% shape.ndim)</span>

        <span class="s0"># Process degrees of freedom.</span>
        <span class="s2">if </span><span class="s1">df </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">df = </span><span class="s3">1</span>
        <span class="s2">elif </span><span class="s1">df &lt;= </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;'df' must be greater than zero.&quot;</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">np.isnan(df):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;'df' is 'nan' but must be greater than zero or 'np.inf'.&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df</span>


<span class="s2">class </span><span class="s1">multivariate_t_frozen(multi_rv_frozen):</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">loc=</span><span class="s2">None, </span><span class="s1">shape=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">df=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">allow_singular=</span><span class="s2">False,</span>
                 <span class="s1">seed=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Create a frozen multivariate t distribution. 
 
        Parameters 
        ---------- 
        %(_mvt_doc_default_callparams)s 
 
        Examples 
        -------- 
        &gt;&gt;&gt; loc = np.zeros(3) 
        &gt;&gt;&gt; shape = np.eye(3) 
        &gt;&gt;&gt; df = 10 
        &gt;&gt;&gt; dist = multivariate_t(loc, shape, df) 
        &gt;&gt;&gt; dist.rvs() 
        array([[ 0.81412036, -1.53612361,  0.42199647]]) 
        &gt;&gt;&gt; dist.pdf([1, 1, 1]) 
        array([0.01237803]) 
 
        &quot;&quot;&quot;</span>
        <span class="s1">self._dist = multivariate_t_gen(seed)</span>
        <span class="s1">dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df = self._dist._process_parameters(loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df)</span>
        <span class="s1">self.dim</span><span class="s2">, </span><span class="s1">self.loc</span><span class="s2">, </span><span class="s1">self.shape</span><span class="s2">, </span><span class="s1">self.df = dim</span><span class="s2">, </span><span class="s1">loc</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">df</span>
        <span class="s1">self.shape_info = _PSD(shape</span><span class="s2">, </span><span class="s1">allow_singular=allow_singular)</span>

    <span class="s2">def </span><span class="s1">logpdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s1">x = self._dist._process_quantiles(x</span><span class="s2">, </span><span class="s1">self.dim)</span>
        <span class="s1">U = self.shape_info.U</span>
        <span class="s1">log_pdet = self.shape_info.log_pdet</span>
        <span class="s2">return </span><span class="s1">self._dist._logpdf(x</span><span class="s2">, </span><span class="s1">self.loc</span><span class="s2">, </span><span class="s1">U</span><span class="s2">, </span><span class="s1">log_pdet</span><span class="s2">, </span><span class="s1">self.df</span><span class="s2">, </span><span class="s1">self.dim</span><span class="s2">,</span>
                                  <span class="s1">self.shape_info.rank)</span>

    <span class="s2">def </span><span class="s1">pdf(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.exp(self.logpdf(x))</span>

    <span class="s2">def </span><span class="s1">rvs(self</span><span class="s2">, </span><span class="s1">size=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">self._dist.rvs(loc=self.loc</span><span class="s2">,</span>
                              <span class="s1">shape=self.shape</span><span class="s2">,</span>
                              <span class="s1">df=self.df</span><span class="s2">,</span>
                              <span class="s1">size=size</span><span class="s2">,</span>
                              <span class="s1">random_state=random_state)</span>


<span class="s1">multivariate_t = multivariate_t_gen()</span>


<span class="s0"># Set frozen generator docstrings from corresponding docstrings in</span>
<span class="s0"># matrix_normal_gen and fill in default strings in class docstrings</span>
<span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">'logpdf'</span><span class="s2">, </span><span class="s4">'pdf'</span><span class="s2">, </span><span class="s4">'rvs'</span><span class="s1">]:</span>
    <span class="s1">method = multivariate_t_gen.__dict__[name]</span>
    <span class="s1">method_frozen = multivariate_t_frozen.__dict__[name]</span>
    <span class="s1">method_frozen.__doc__ = doccer.docformat(method.__doc__</span><span class="s2">,</span>
                                             <span class="s1">mvt_docdict_noparams)</span>
    <span class="s1">method.__doc__ = doccer.docformat(method.__doc__</span><span class="s2">, </span><span class="s1">mvt_docdict_params)</span>
</pre>
</body>
</html>
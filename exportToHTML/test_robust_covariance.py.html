<html>
<head>
<title>test_robust_covariance.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_robust_covariance.py</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="s0">#         Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="s0">#         Virgile Fritsch &lt;virgile.fritsch@inria.fr&gt;</span>
<span class="s0">#</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">itertools</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">sklearn </span><span class="s2">import </span><span class="s1">datasets</span>
<span class="s2">from </span><span class="s1">sklearn.covariance </span><span class="s2">import </span><span class="s1">MinCovDet</span><span class="s2">, </span><span class="s1">empirical_covariance</span><span class="s2">, </span><span class="s1">fast_mcd</span>
<span class="s2">from </span><span class="s1">sklearn.utils._testing </span><span class="s2">import </span><span class="s1">assert_array_almost_equal</span>

<span class="s1">X = datasets.load_iris().data</span>
<span class="s1">X_1d = X[:</span><span class="s2">, </span><span class="s3">0</span><span class="s1">]</span>
<span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features = X.shape</span>


<span class="s2">def </span><span class="s1">test_mcd(global_random_seed):</span>
    <span class="s0"># Tests the FastMCD algorithm implementation</span>
    <span class="s0"># Small data set</span>
    <span class="s0"># test without outliers (random independent normal data)</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">100</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, </span><span class="s3">0.02</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">75</span><span class="s2">, </span><span class="s1">global_random_seed)</span>
    <span class="s0"># test with a contaminated data set (medium contamination)</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">100</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">20</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">65</span><span class="s2">, </span><span class="s1">global_random_seed)</span>
    <span class="s0"># test with a contaminated data set (strong contamination)</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">100</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">40</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">50</span><span class="s2">, </span><span class="s1">global_random_seed)</span>

    <span class="s0"># Medium data set</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">1000</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">450</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">540</span><span class="s2">, </span><span class="s1">global_random_seed)</span>

    <span class="s0"># Large data set</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">1700</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">800</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">870</span><span class="s2">, </span><span class="s1">global_random_seed)</span>

    <span class="s0"># 1D data set</span>
    <span class="s1">launch_mcd_on_dataset(</span><span class="s3">500</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">100</span><span class="s2">, </span><span class="s3">0.02</span><span class="s2">, </span><span class="s3">0.02</span><span class="s2">, </span><span class="s3">350</span><span class="s2">, </span><span class="s1">global_random_seed)</span>


<span class="s2">def </span><span class="s1">test_fast_mcd_on_invalid_input():</span>
    <span class="s1">X = np.arange(</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">msg = </span><span class="s4">&quot;Expected 2D array, got 1D array instead&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
        <span class="s1">fast_mcd(X)</span>


<span class="s2">def </span><span class="s1">test_mcd_class_on_invalid_input():</span>
    <span class="s1">X = np.arange(</span><span class="s3">100</span><span class="s1">)</span>
    <span class="s1">mcd = MinCovDet()</span>
    <span class="s1">msg = </span><span class="s4">&quot;Expected 2D array, got 1D array instead&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
        <span class="s1">mcd.fit(X)</span>


<span class="s2">def </span><span class="s1">launch_mcd_on_dataset(</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_outliers</span><span class="s2">, </span><span class="s1">tol_loc</span><span class="s2">, </span><span class="s1">tol_cov</span><span class="s2">, </span><span class="s1">tol_support</span><span class="s2">, </span><span class="s1">seed</span>
<span class="s1">):</span>
    <span class="s1">rand_gen = np.random.RandomState(seed)</span>
    <span class="s1">data = rand_gen.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>
    <span class="s0"># add some outliers</span>
    <span class="s1">outliers_index = rand_gen.permutation(n_samples)[:n_outliers]</span>
    <span class="s1">outliers_offset = </span><span class="s3">10.0 </span><span class="s1">* (rand_gen.randint(</span><span class="s3">2</span><span class="s2">, </span><span class="s1">size=(n_outliers</span><span class="s2">, </span><span class="s1">n_features)) - </span><span class="s3">0.5</span><span class="s1">)</span>
    <span class="s1">data[outliers_index] += outliers_offset</span>
    <span class="s1">inliers_mask = np.ones(n_samples).astype(bool)</span>
    <span class="s1">inliers_mask[outliers_index] = </span><span class="s2">False</span>

    <span class="s1">pure_data = data[inliers_mask]</span>
    <span class="s0"># compute MCD by fitting an object</span>
    <span class="s1">mcd_fit = MinCovDet(random_state=seed).fit(data)</span>
    <span class="s1">T = mcd_fit.location_</span>
    <span class="s1">S = mcd_fit.covariance_</span>
    <span class="s1">H = mcd_fit.support_</span>
    <span class="s0"># compare with the estimates learnt from the inliers</span>
    <span class="s1">error_location = np.mean((pure_data.mean(</span><span class="s3">0</span><span class="s1">) - T) ** </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">error_location &lt; tol_loc</span>
    <span class="s1">error_cov = np.mean((empirical_covariance(pure_data) - S) ** </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">error_cov &lt; tol_cov</span>
    <span class="s2">assert </span><span class="s1">np.sum(H) &gt;= tol_support</span>
    <span class="s1">assert_array_almost_equal(mcd_fit.mahalanobis(data)</span><span class="s2">, </span><span class="s1">mcd_fit.dist_)</span>


<span class="s2">def </span><span class="s1">test_mcd_issue1127():</span>
    <span class="s0"># Check that the code does not break with X.shape = (3, 1)</span>
    <span class="s0"># (i.e. n_support = n_samples)</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X = rnd.normal(size=(</span><span class="s3">3</span><span class="s2">, </span><span class="s3">1</span><span class="s1">))</span>
    <span class="s1">mcd = MinCovDet()</span>
    <span class="s1">mcd.fit(X)</span>


<span class="s2">def </span><span class="s1">test_mcd_issue3367(global_random_seed):</span>
    <span class="s0"># Check that MCD completes when the covariance matrix is singular</span>
    <span class="s0"># i.e. one of the rows and columns are all zeros</span>
    <span class="s1">rand_gen = np.random.RandomState(global_random_seed)</span>

    <span class="s0"># Think of these as the values for X and Y -&gt; 10 values between -5 and 5</span>
    <span class="s1">data_values = np.linspace(-</span><span class="s3">5</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">10</span><span class="s1">).tolist()</span>
    <span class="s0"># Get the cartesian product of all possible coordinate pairs from above set</span>
    <span class="s1">data = np.array(list(itertools.product(data_values</span><span class="s2">, </span><span class="s1">data_values)))</span>

    <span class="s0"># Add a third column that's all zeros to make our data a set of point</span>
    <span class="s0"># within a plane, which means that the covariance matrix will be singular</span>
    <span class="s1">data = np.hstack((data</span><span class="s2">, </span><span class="s1">np.zeros((data.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s2">, </span><span class="s3">1</span><span class="s1">))))</span>

    <span class="s0"># The below line of code should raise an exception if the covariance matrix</span>
    <span class="s0"># is singular. As a further test, since we have points in XYZ, the</span>
    <span class="s0"># principle components (Eigenvectors) of these directly relate to the</span>
    <span class="s0"># geometry of the points. Since it's a plane, we should be able to test</span>
    <span class="s0"># that the Eigenvector that corresponds to the smallest Eigenvalue is the</span>
    <span class="s0"># plane normal, specifically [0, 0, 1], since everything is in the XY plane</span>
    <span class="s0"># (as I've set it up above). To do this one would start by:</span>
    <span class="s0">#</span>
    <span class="s0">#     evals, evecs = np.linalg.eigh(mcd_fit.covariance_)</span>
    <span class="s0">#     normal = evecs[:, np.argmin(evals)]</span>
    <span class="s0">#</span>
    <span class="s0"># After which we need to assert that our `normal` is equal to [0, 0, 1].</span>
    <span class="s0"># Do note that there is floating point error associated with this, so it's</span>
    <span class="s0"># best to subtract the two and then compare some small tolerance (e.g.</span>
    <span class="s0"># 1e-12).</span>
    <span class="s1">MinCovDet(random_state=rand_gen).fit(data)</span>


<span class="s2">def </span><span class="s1">test_mcd_support_covariance_is_zero():</span>
    <span class="s0"># Check that MCD returns a ValueError with informative message when the</span>
    <span class="s0"># covariance of the support data is equal to 0.</span>
    <span class="s1">X_1 = np.array([</span><span class="s3">0.5</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.957</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s2">, </span><span class="s3">0.4285</span><span class="s2">, </span><span class="s3">0.1</span><span class="s1">])</span>
    <span class="s1">X_1 = X_1.reshape(-</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">X_2 = np.array([</span><span class="s3">0.5</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.957</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.3</span><span class="s2">, </span><span class="s3">0.4285</span><span class="s2">, </span><span class="s3">0.3</span><span class="s1">])</span>
    <span class="s1">X_2 = X_2.reshape(-</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">msg = (</span>
        <span class="s4">&quot;The covariance matrix of the support data is equal to 0, try to &quot;</span>
        <span class="s4">&quot;increase support_fraction&quot;</span>
    <span class="s1">)</span>
    <span class="s2">for </span><span class="s1">X </span><span class="s2">in </span><span class="s1">[X_1</span><span class="s2">, </span><span class="s1">X_2]:</span>
        <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s1">MinCovDet().fit(X)</span>


<span class="s2">def </span><span class="s1">test_mcd_increasing_det_warning(global_random_seed):</span>
    <span class="s0"># Check that a warning is raised if we observe increasing determinants</span>
    <span class="s0"># during the c_step. In theory the sequence of determinants should be</span>
    <span class="s0"># decreasing. Increasing determinants are likely due to ill-conditioned</span>
    <span class="s0"># covariance matrices that result in poor precision matrices.</span>

    <span class="s1">X = [</span>
        <span class="s1">[</span><span class="s3">5.1</span><span class="s2">, </span><span class="s3">3.5</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.9</span><span class="s2">, </span><span class="s3">3.0</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.7</span><span class="s2">, </span><span class="s3">3.2</span><span class="s2">, </span><span class="s3">1.3</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.6</span><span class="s2">, </span><span class="s3">3.1</span><span class="s2">, </span><span class="s3">1.5</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.0</span><span class="s2">, </span><span class="s3">3.6</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.6</span><span class="s2">, </span><span class="s3">3.4</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.0</span><span class="s2">, </span><span class="s3">3.4</span><span class="s2">, </span><span class="s3">1.5</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.4</span><span class="s2">, </span><span class="s3">2.9</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.9</span><span class="s2">, </span><span class="s3">3.1</span><span class="s2">, </span><span class="s3">1.5</span><span class="s2">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.4</span><span class="s2">, </span><span class="s3">3.7</span><span class="s2">, </span><span class="s3">1.5</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.8</span><span class="s2">, </span><span class="s3">3.4</span><span class="s2">, </span><span class="s3">1.6</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.8</span><span class="s2">, </span><span class="s3">3.0</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.3</span><span class="s2">, </span><span class="s3">3.0</span><span class="s2">, </span><span class="s3">1.1</span><span class="s2">, </span><span class="s3">0.1</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.1</span><span class="s2">, </span><span class="s3">3.5</span><span class="s2">, </span><span class="s3">1.4</span><span class="s2">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.7</span><span class="s2">, </span><span class="s3">3.8</span><span class="s2">, </span><span class="s3">1.7</span><span class="s2">, </span><span class="s3">0.3</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.4</span><span class="s2">, </span><span class="s3">3.4</span><span class="s2">, </span><span class="s3">1.7</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">4.6</span><span class="s2">, </span><span class="s3">3.6</span><span class="s2">, </span><span class="s3">1.0</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.0</span><span class="s2">, </span><span class="s3">3.0</span><span class="s2">, </span><span class="s3">1.6</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">[</span><span class="s3">5.2</span><span class="s2">, </span><span class="s3">3.5</span><span class="s2">, </span><span class="s3">1.5</span><span class="s2">, </span><span class="s3">0.2</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">]</span>

    <span class="s1">mcd = MinCovDet(support_fraction=</span><span class="s3">0.5</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">warn_msg = </span><span class="s4">&quot;Determinant has increased&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s2">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">mcd.fit(X)</span>
</pre>
</body>
</html>
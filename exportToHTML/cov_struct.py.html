<html>
<head>
<title>cov_struct.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
cov_struct.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Covariance models and estimators for GEE. 
 
Some details for the covariance calculations can be found in the Stata 
docs: 
 
http://www.stata.com/manuals13/xtxtgee.pdf 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">statsmodels.compat.pandas </span><span class="s2">import </span><span class="s1">Appender</span>

<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">defaultdict</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">linalg </span><span class="s2">as </span><span class="s1">spl</span>

<span class="s2">from </span><span class="s1">statsmodels.stats.correlation_tools </span><span class="s2">import </span><span class="s1">cov_nearest</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ConvergenceWarning</span><span class="s2">,</span>
    <span class="s1">NotImplementedWarning</span><span class="s2">,</span>
    <span class="s1">OutputWarning</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.validation </span><span class="s2">import </span><span class="s1">bool_like</span>


<span class="s2">class </span><span class="s1">CovStruct:</span>
    <span class="s0">&quot;&quot;&quot; 
    Base class for correlation and covariance structures. 
 
    An implementation of this class takes the residuals from a 
    regression model that has been fit to grouped data, and uses 
    them to estimate the within-group dependence structure of the 
    random errors in the model. 
 
    The current state of the covariance structure is represented 
    through the value of the `dep_params` attribute. 
 
    The default state of a newly-created instance should always be 
    the identity correlation matrix. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">cov_nearest_method=</span><span class="s3">&quot;clipped&quot;</span><span class="s1">):</span>

        <span class="s4"># Parameters describing the dependency structure</span>
        <span class="s1">self.dep_params = </span><span class="s2">None</span>

        <span class="s4"># Keep track of the number of times that the covariance was</span>
        <span class="s4"># adjusted.</span>
        <span class="s1">self.cov_adjust = []</span>

        <span class="s4"># Method for projecting the covariance matrix if it is not</span>
        <span class="s4"># PSD.</span>
        <span class="s1">self.cov_nearest_method = cov_nearest_method</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>
        <span class="s0">&quot;&quot;&quot; 
        Called by GEE, used by implementations that need additional 
        setup prior to running `fit`. 
 
        Parameters 
        ---------- 
        model : GEE class 
            A reference to the parent GEE class instance. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.model = model</span>

    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Update the association parameter values based on the current 
        regression coefficients. 
 
        Parameters 
        ---------- 
        params : array_like 
            Working values for the regression parameters. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the working covariance or correlation matrix for a 
        given cluster of data. 
 
        Parameters 
        ---------- 
        endog_expval : array_like 
           The expected values of endog for the cluster for which the 
           covariance or correlation matrix will be returned 
        index : int 
           The index of the cluster for which the covariance or 
           correlation matrix will be returned 
 
        Returns 
        ------- 
        M : matrix 
            The covariance or correlation matrix of endog 
        is_cor : bool 
            True if M is a correlation matrix, False if M is a 
            covariance matrix 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s2">def </span><span class="s1">covariance_matrix_solve(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Solves matrix equations of the form `covmat * soln = rhs` and 
        returns the values of `soln`, where `covmat` is the covariance 
        matrix represented by this class. 
 
        Parameters 
        ---------- 
        expval : array_like 
           The expected value of endog for each observed value in the 
           group. 
        index : int 
           The group index. 
        stdev : array_like 
            The standard deviation of endog for each observation in 
            the group. 
        rhs : list/tuple of array_like 
            A set of right-hand sides; each defines a matrix equation 
            to be solved. 
 
        Returns 
        ------- 
        soln : list/tuple of array_like 
            The solutions to the matrix equations. 
 
        Notes 
        ----- 
        Returns None if the solver fails. 
 
        Some dependence structures do not use `expval` and/or `index` 
        to determine the correlation matrix.  Some families 
        (e.g. binomial) do not use the `stdev` parameter when forming 
        the covariance matrix. 
 
        If the covariance matrix is singular or not SPD, it is 
        projected to the nearest such matrix.  These projection events 
        are recorded in the fit_history attribute of the GEE model. 
 
        Systems of linear equations with the covariance matrix as the 
        left hand side (LHS) are solved for different right hand sides 
        (RHS); the LHS is only factorized once to save time. 
 
        This is a default implementation, it can be reimplemented in 
        subclasses to optimize the linear algebra according to the 
        structure of the covariance matrix. 
        &quot;&quot;&quot;</span>

        <span class="s1">vmat</span><span class="s2">, </span><span class="s1">is_cor = self.covariance_matrix(expval</span><span class="s2">, </span><span class="s1">index)</span>
        <span class="s2">if </span><span class="s1">is_cor:</span>
            <span class="s1">vmat *= np.outer(stdev</span><span class="s2">, </span><span class="s1">stdev)</span>

        <span class="s4"># Factor the covariance matrix.  If the factorization fails,</span>
        <span class="s4"># attempt to condition it into a factorizable matrix.</span>
        <span class="s1">threshold = </span><span class="s5">1e-2</span>
        <span class="s1">success = </span><span class="s2">False</span>
        <span class="s1">cov_adjust = </span><span class="s5">0</span>
        <span class="s2">for </span><span class="s1">itr </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">20</span><span class="s1">):</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">vco = spl.cho_factor(vmat)</span>
                <span class="s1">success = </span><span class="s2">True</span>
                <span class="s2">break</span>
            <span class="s2">except </span><span class="s1">np.linalg.LinAlgError:</span>
                <span class="s1">vmat = cov_nearest(vmat</span><span class="s2">, </span><span class="s1">method=self.cov_nearest_method</span><span class="s2">,</span>
                                   <span class="s1">threshold=threshold)</span>
                <span class="s1">threshold *= </span><span class="s5">2</span>
                <span class="s1">cov_adjust += </span><span class="s5">1</span>
                <span class="s1">msg = </span><span class="s3">&quot;At least one covariance matrix was not PSD &quot;</span>
                <span class="s1">msg += </span><span class="s3">&quot;and required projection.&quot;</span>
                <span class="s1">warnings.warn(msg)</span>

        <span class="s1">self.cov_adjust.append(cov_adjust)</span>

        <span class="s4"># Last resort if we still cannot factor the covariance matrix.</span>
        <span class="s2">if not </span><span class="s1">success:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;Unable to condition covariance matrix to an SPD &quot;</span>
                <span class="s3">&quot;matrix using cov_nearest&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning)</span>
            <span class="s1">vmat = np.diag(np.diag(vmat))</span>
            <span class="s1">vco = spl.cho_factor(vmat)</span>

        <span class="s1">soln = [spl.cho_solve(vco</span><span class="s2">, </span><span class="s1">x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs]</span>
        <span class="s2">return </span><span class="s1">soln</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a text summary of the current estimate of the 
        dependence structure. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>


<span class="s2">class </span><span class="s1">Independence(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    An independence working dependence structure. 
    &quot;&quot;&quot;</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s4"># Nothing to update</span>
        <span class="s2">return</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s1">dim = len(expval)</span>
        <span class="s2">return </span><span class="s1">np.eye(dim</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span><span class="s2">, True</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix_solve.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix_solve(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs):</span>
        <span class="s1">v = stdev ** </span><span class="s5">2</span>
        <span class="s1">rslt = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs:</span>
            <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">rslt.append(x / v)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">rslt.append(x / v[:</span><span class="s2">, None</span><span class="s1">])</span>
        <span class="s2">return </span><span class="s1">rslt</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s3">&quot;Observations within a cluster are modeled &quot;</span>
                <span class="s3">&quot;as being independent.&quot;</span><span class="s1">)</span>

<span class="s2">class </span><span class="s1">Unstructured(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    An unstructured dependence structure. 
 
    To use the unstructured dependence structure, a `time` 
    argument must be provided when creating the GEE.  The 
    time argument must be of integer dtype, and indicates 
    which position in a complete data vector is occupied 
    by each observed value. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">cov_nearest_method=</span><span class="s3">&quot;clipped&quot;</span><span class="s1">):</span>

        <span class="s1">super(Unstructured</span><span class="s2">, </span><span class="s1">self).__init__(cov_nearest_method)</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>

        <span class="s1">self.model = model</span>

        <span class="s2">import </span><span class="s1">numbers</span>
        <span class="s2">if not </span><span class="s1">issubclass(self.model.time.dtype.type</span><span class="s2">, </span><span class="s1">numbers.Integral):</span>
            <span class="s1">msg = </span><span class="s3">&quot;time must be provided and must have integer dtype&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s1">q = self.model.time[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">].max() + </span><span class="s5">1</span>

        <span class="s1">self.dep_params = np.eye(q)</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s2">if </span><span class="s1">hasattr(self.model</span><span class="s2">, </span><span class="s3">&quot;time&quot;</span><span class="s1">):</span>
            <span class="s1">time_li = self.model.time_li</span>
            <span class="s1">ix = time_li[index][:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">return </span><span class="s1">self.dep_params[np.ix_(ix</span><span class="s2">, </span><span class="s1">ix)]</span><span class="s2">,True</span>

        <span class="s2">return </span><span class="s1">self.dep_params</span><span class="s2">, True</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">nobs = self.model.nobs</span>
        <span class="s1">varfunc = self.model.family.variance</span>
        <span class="s1">cached_means = self.model.cached_means</span>
        <span class="s1">has_weights = self.model.weights </span><span class="s2">is not None</span>
        <span class="s1">weights_li = self.model.weights</span>

        <span class="s1">time_li = self.model.time_li</span>
        <span class="s1">q = self.model.time.max() + </span><span class="s5">1</span>
        <span class="s1">csum = np.zeros((q</span><span class="s2">, </span><span class="s1">q))</span>
        <span class="s1">wsum = </span><span class="s5">0.</span>
        <span class="s1">cov = np.zeros((q</span><span class="s2">, </span><span class="s1">q))</span>

        <span class="s1">scale = </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s4"># Get the Pearson residuals</span>
            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">ix = time_li[i][:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">m = np.outer(resid</span><span class="s2">, </span><span class="s1">resid)</span>
            <span class="s1">ssr = np.sum(np.diag(m))</span>

            <span class="s1">w = weights_li[i] </span><span class="s2">if </span><span class="s1">has_weights </span><span class="s2">else </span><span class="s5">1.</span>
            <span class="s1">csum[np.ix_(ix</span><span class="s2">, </span><span class="s1">ix)] += w</span>
            <span class="s1">wsum += w * len(ix)</span>
            <span class="s1">cov[np.ix_(ix</span><span class="s2">, </span><span class="s1">ix)] += w * m</span>
            <span class="s1">scale += w * ssr</span>
        <span class="s1">ddof = self.model.ddof_scale</span>
        <span class="s1">scale /= wsum * (nobs - ddof) / float(nobs)</span>
        <span class="s1">cov /= (csum - ddof)</span>

        <span class="s1">sd = np.sqrt(np.diag(cov))</span>
        <span class="s1">cov /= np.outer(sd</span><span class="s2">, </span><span class="s1">sd)</span>

        <span class="s1">self.dep_params = cov</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s1">print(</span><span class="s3">&quot;Estimated covariance structure:&quot;</span><span class="s1">)</span>
        <span class="s1">print(self.dep_params)</span>


<span class="s2">class </span><span class="s1">Exchangeable(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    An exchangeable working dependence structure. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self):</span>

        <span class="s1">super(Exchangeable</span><span class="s2">, </span><span class="s1">self).__init__()</span>

        <span class="s4"># The correlation between any two values in the same cluster</span>
        <span class="s1">self.dep_params = </span><span class="s5">0.</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>

        <span class="s1">nobs = self.model.nobs</span>

        <span class="s1">varfunc = self.model.family.variance</span>

        <span class="s1">cached_means = self.model.cached_means</span>

        <span class="s1">has_weights = self.model.weights </span><span class="s2">is not None</span>
        <span class="s1">weights_li = self.model.weights</span>

        <span class="s1">residsq_sum</span><span class="s2">, </span><span class="s1">scale = </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span>
        <span class="s1">fsum1</span><span class="s2">, </span><span class="s1">fsum2</span><span class="s2">, </span><span class="s1">n_pairs = </span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>
            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>
            <span class="s1">f = weights_li[i] </span><span class="s2">if </span><span class="s1">has_weights </span><span class="s2">else </span><span class="s5">1.</span>

            <span class="s1">ssr = np.sum(resid * resid)</span>
            <span class="s1">scale += f * ssr</span>
            <span class="s1">fsum1 += f * len(endog[i])</span>

            <span class="s1">residsq_sum += f * (resid.sum() ** </span><span class="s5">2 </span><span class="s1">- ssr) / </span><span class="s5">2</span>
            <span class="s1">ngrp = len(resid)</span>
            <span class="s1">npr = </span><span class="s5">0.5 </span><span class="s1">* ngrp * (ngrp - </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">fsum2 += f * npr</span>
            <span class="s1">n_pairs += npr</span>

        <span class="s1">ddof = self.model.ddof_scale</span>
        <span class="s1">scale /= (fsum1 * (nobs - ddof) / float(nobs))</span>
        <span class="s1">residsq_sum /= scale</span>
        <span class="s1">self.dep_params = residsq_sum / \</span>
            <span class="s1">(fsum2 * (n_pairs - ddof) / float(n_pairs))</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s1">dim = len(expval)</span>
        <span class="s1">dp = self.dep_params * np.ones((dim</span><span class="s2">, </span><span class="s1">dim)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">np.fill_diagonal(dp</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">dp</span><span class="s2">, True</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix_solve.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix_solve(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs):</span>

        <span class="s1">k = len(expval)</span>
        <span class="s1">c = self.dep_params / (</span><span class="s5">1. </span><span class="s1">- self.dep_params)</span>
        <span class="s1">c /= </span><span class="s5">1. </span><span class="s1">+ self.dep_params * (k - </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s1">rslt = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs:</span>
            <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">x1 = x / stdev</span>
                <span class="s1">y = x1 / (</span><span class="s5">1. </span><span class="s1">- self.dep_params)</span>
                <span class="s1">y -= c * sum(x1)</span>
                <span class="s1">y /= stdev</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">x1 = x / stdev[:</span><span class="s2">, None</span><span class="s1">]</span>
                <span class="s1">y = x1 / (</span><span class="s5">1. </span><span class="s1">- self.dep_params)</span>
                <span class="s1">y -= c * x1.sum(</span><span class="s5">0</span><span class="s1">)</span>
                <span class="s1">y /= stdev[:</span><span class="s2">, None</span><span class="s1">]</span>
            <span class="s1">rslt.append(y)</span>

        <span class="s2">return </span><span class="s1">rslt</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s3">&quot;The correlation between two observations in the &quot; </span><span class="s1">+</span>
                <span class="s3">&quot;same cluster is %.3f&quot; </span><span class="s1">% self.dep_params)</span>


<span class="s2">class </span><span class="s1">Nested(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    A nested working dependence structure. 
 
    A nested working dependence structure captures unique variance 
    associated with each level in a hierarchy of partitions of the 
    cases.  For each level of the hierarchy, there is a set of iid 
    random effects with mean zero, and with variance that is specific 
    to the level.  These variance parameters are estimated from the 
    data using the method of moments. 
 
    The top level of the hierarchy is always defined by the required 
    `groups` argument to GEE. 
 
    The `dep_data` argument used to create the GEE defines the 
    remaining levels of the hierarchy.  it should be either an array, 
    or if using the formula interface, a string that contains a 
    formula.  If an array, it should contain a `n_obs x k` matrix of 
    labels, corresponding to the k levels of partitioning that are 
    nested under the top-level `groups` of the GEE instance.  These 
    subgroups should be nested from left to right, so that two 
    observations with the same label for column j of `dep_data` should 
    also have the same label for all columns j' &lt; j (this only applies 
    to observations in the same top-level cluster given by the 
    `groups` argument to GEE). 
 
    If `dep_data` is a formula, it should usually be of the form `0 + 
    a + b + ...`, where `a`, `b`, etc. contain labels defining group 
    membership.  The `0 + ` should be included to prevent creation of 
    an intercept.  The variable values are interpreted as labels for 
    group membership, but the variables should not be explicitly coded 
    as categorical, i.e. use `0 + a` not `0 + C(a)`. 
 
    Notes 
    ----- 
    The calculations for the nested structure involve all pairs of 
    observations within the top level `group` passed to GEE.  Large 
    group sizes will result in slow iterations. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>
        <span class="s0">&quot;&quot;&quot; 
        Called on the first call to update 
 
        `ilabels` is a list of n_i x n_i matrices containing integer 
        labels that correspond to specific correlation parameters. 
        Two elements of ilabels[i] with the same label share identical 
        variance components. 
 
        `designx` is a matrix, with each row containing dummy 
        variables indicating which variance components are associated 
        with the corresponding element of QY. 
        &quot;&quot;&quot;</span>

        <span class="s1">super(Nested</span><span class="s2">, </span><span class="s1">self).initialize(model)</span>

        <span class="s2">if </span><span class="s1">self.model.weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;weights not implemented for nested cov_struct, &quot;</span>
                          <span class="s3">&quot;using unweighted covariance estimate&quot;</span><span class="s2">,</span>
                          <span class="s1">NotImplementedWarning)</span>

        <span class="s4"># A bit of processing of the nest data</span>
        <span class="s1">id_matrix = np.asarray(self.model.dep_data)</span>
        <span class="s2">if </span><span class="s1">id_matrix.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">id_matrix = id_matrix[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">self.id_matrix = id_matrix</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">designx</span><span class="s2">, </span><span class="s1">ilabels = []</span><span class="s2">, </span><span class="s1">[]</span>

        <span class="s4"># The number of layers of nesting</span>
        <span class="s1">n_nest = self.id_matrix.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>
            <span class="s1">ngrp = len(endog[i])</span>
            <span class="s1">glab = self.model.group_labels[i]</span>
            <span class="s1">rix = self.model.group_indices[glab]</span>

            <span class="s4"># Determine the number of common variance components</span>
            <span class="s4"># shared by each pair of observations.</span>
            <span class="s1">ix1</span><span class="s2">, </span><span class="s1">ix2 = np.tril_indices(ngrp</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">ncm = (self.id_matrix[rix[ix1]</span><span class="s2">, </span><span class="s1">:] ==</span>
                   <span class="s1">self.id_matrix[rix[ix2]</span><span class="s2">, </span><span class="s1">:]).sum(</span><span class="s5">1</span><span class="s1">)</span>

            <span class="s4"># This is used to construct the working correlation</span>
            <span class="s4"># matrix.</span>
            <span class="s1">ilabel = np.zeros((ngrp</span><span class="s2">, </span><span class="s1">ngrp)</span><span class="s2">, </span><span class="s1">dtype=np.int32)</span>
            <span class="s1">ilabel[(ix1</span><span class="s2">, </span><span class="s1">ix2)] = ncm + </span><span class="s5">1</span>
            <span class="s1">ilabel[(ix2</span><span class="s2">, </span><span class="s1">ix1)] = ncm + </span><span class="s5">1</span>
            <span class="s1">ilabels.append(ilabel)</span>

            <span class="s4"># This is used to estimate the variance components.</span>
            <span class="s1">dsx = np.zeros((len(ix1)</span><span class="s2">, </span><span class="s1">n_nest + </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
            <span class="s1">dsx[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">np.unique(ncm):</span>
                <span class="s1">ii = np.flatnonzero(ncm == k)</span>
                <span class="s1">dsx[ii</span><span class="s2">, </span><span class="s5">1</span><span class="s1">:k + </span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
            <span class="s1">designx.append(dsx)</span>

        <span class="s1">self.designx = np.concatenate(designx</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">self.ilabels = ilabels</span>

        <span class="s1">svd = np.linalg.svd(self.designx</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">self.designx_u = svd[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">self.designx_s = svd[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">self.designx_v = svd[</span><span class="s5">2</span><span class="s1">].T</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>

        <span class="s1">nobs = self.model.nobs</span>
        <span class="s1">dim = len(params)</span>

        <span class="s2">if </span><span class="s1">self.designx </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self._compute_design(self.model)</span>

        <span class="s1">cached_means = self.model.cached_means</span>

        <span class="s1">varfunc = self.model.family.variance</span>

        <span class="s1">dvmat = []</span>
        <span class="s1">scale = </span><span class="s5">0.</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>

            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">ix1</span><span class="s2">, </span><span class="s1">ix2 = np.tril_indices(len(resid)</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">dvmat.append(resid[ix1] * resid[ix2])</span>

            <span class="s1">scale += np.sum(resid ** </span><span class="s5">2</span><span class="s1">)</span>

        <span class="s1">dvmat = np.concatenate(dvmat)</span>
        <span class="s1">scale /= (nobs - dim)</span>

        <span class="s4"># Use least squares regression to estimate the variance</span>
        <span class="s4"># components</span>
        <span class="s1">vcomp_coeff = np.dot(self.designx_v</span><span class="s2">, </span><span class="s1">np.dot(self.designx_u.T</span><span class="s2">,</span>
                                                    <span class="s1">dvmat) / self.designx_s)</span>

        <span class="s1">self.vcomp_coeff = np.clip(vcomp_coeff</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">self.scale = scale</span>

        <span class="s1">self.dep_params = self.vcomp_coeff.copy()</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s1">dim = len(expval)</span>

        <span class="s4"># First iteration</span>
        <span class="s2">if </span><span class="s1">self.dep_params </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.eye(dim</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span><span class="s2">, True</span>

        <span class="s1">ilabel = self.ilabels[index]</span>

        <span class="s1">c = np.r_[self.scale</span><span class="s2">, </span><span class="s1">np.cumsum(self.vcomp_coeff)]</span>
        <span class="s1">vmat = c[ilabel]</span>
        <span class="s1">vmat /= self.scale</span>
        <span class="s2">return </span><span class="s1">vmat</span><span class="s2">, True</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a summary string describing the state of the 
        dependence structure. 
        &quot;&quot;&quot;</span>

        <span class="s1">dep_names = [</span><span class="s3">&quot;Groups&quot;</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">hasattr(self.model</span><span class="s2">, </span><span class="s3">&quot;_dep_data_names&quot;</span><span class="s1">):</span>
            <span class="s1">dep_names.extend(self.model._dep_data_names)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dep_names.extend([</span><span class="s3">&quot;Component %d:&quot; </span><span class="s1">% (k + </span><span class="s5">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(len(self.vcomp_coeff) - </span><span class="s5">1</span><span class="s1">)])</span>
        <span class="s2">if </span><span class="s1">hasattr(self.model</span><span class="s2">, </span><span class="s3">&quot;_groups_name&quot;</span><span class="s1">):</span>
            <span class="s1">dep_names[</span><span class="s5">0</span><span class="s1">] = self.model._groups_name</span>
        <span class="s1">dep_names.append(</span><span class="s3">&quot;Residual&quot;</span><span class="s1">)</span>

        <span class="s1">vc = self.vcomp_coeff.tolist()</span>
        <span class="s1">vc.append(self.scale - np.sum(vc))</span>

        <span class="s1">smry = pd.DataFrame({</span><span class="s3">&quot;Variance&quot;</span><span class="s1">: vc}</span><span class="s2">, </span><span class="s1">index=dep_names)</span>

        <span class="s2">return </span><span class="s1">smry</span>


<span class="s2">class </span><span class="s1">Stationary(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    A stationary covariance structure. 
 
    The correlation between two observations is an arbitrary function 
    of the distance between them.  Distances up to a given maximum 
    value are included in the covariance model. 
 
    Parameters 
    ---------- 
    max_lag : float 
        The largest distance that is included in the covariance model. 
    grid : bool 
        If True, the index positions in the data (after dropping missing 
        values) are used to define distances, and the `time` variable is 
        ignored. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">max_lag=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">grid=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s1">super(Stationary</span><span class="s2">, </span><span class="s1">self).__init__()</span>
        <span class="s1">grid = bool_like(grid</span><span class="s2">, </span><span class="s3">&quot;grid&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">grid </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;grid=True will become default in a future version&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span>
            <span class="s1">)</span>

        <span class="s1">self.max_lag = max_lag</span>
        <span class="s1">self.grid = bool(grid)</span>
        <span class="s1">self.dep_params = np.zeros(max_lag + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>

        <span class="s1">super(Stationary</span><span class="s2">, </span><span class="s1">self).initialize(model)</span>

        <span class="s4"># Time used as an index needs to be integer type.</span>
        <span class="s2">if not </span><span class="s1">self.grid:</span>
            <span class="s1">time = self.model.time[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">].astype(np.int32)</span>
            <span class="s1">self.time = self.model.cluster_list(time)</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s2">if </span><span class="s1">self.grid:</span>
            <span class="s1">self.update_grid(params)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.update_nogrid(params)</span>

    <span class="s2">def </span><span class="s1">update_grid(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">cached_means = self.model.cached_means</span>
        <span class="s1">varfunc = self.model.family.variance</span>

        <span class="s1">dep_params = np.zeros(self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">dep_params[</span><span class="s5">0</span><span class="s1">] += np.sum(resid * resid) / len(resid)</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.max_lag + </span><span class="s5">1</span><span class="s1">):</span>
                <span class="s1">v = resid[j:]</span>
                <span class="s1">dep_params[j] += np.sum(resid[</span><span class="s5">0</span><span class="s1">:-j] * v) / len(v)</span>

        <span class="s1">dep_params /= dep_params[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">self.dep_params = dep_params</span>

    <span class="s2">def </span><span class="s1">update_nogrid(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">cached_means = self.model.cached_means</span>
        <span class="s1">varfunc = self.model.family.variance</span>

        <span class="s1">dep_params = np.zeros(self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">dn = np.zeros(self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">resid_ssq = </span><span class="s5">0</span>
        <span class="s1">resid_ssq_n = </span><span class="s5">0</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">j1</span><span class="s2">, </span><span class="s1">j2 = np.tril_indices(len(expval)</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">dx = np.abs(self.time[i][j1] - self.time[i][j2])</span>
            <span class="s1">ii = np.flatnonzero(dx &lt;= self.max_lag)</span>
            <span class="s1">j1 = j1[ii]</span>
            <span class="s1">j2 = j2[ii]</span>
            <span class="s1">dx = dx[ii]</span>

            <span class="s1">vs = np.bincount(dx</span><span class="s2">, </span><span class="s1">weights=resid[j1] * resid[j2]</span><span class="s2">,</span>
                             <span class="s1">minlength=self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">vd = np.bincount(dx</span><span class="s2">, </span><span class="s1">minlength=self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">resid_ssq += np.sum(resid**</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">resid_ssq_n += len(resid)</span>

            <span class="s1">ii = np.flatnonzero(vd &gt; </span><span class="s5">0</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">len(ii) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">dn[ii] += </span><span class="s5">1</span>
                <span class="s1">dep_params[ii] += vs[ii] / vd[ii]</span>

        <span class="s1">i0 = np.flatnonzero(dn &gt; </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">dep_params[i0] /= dn[i0]</span>
        <span class="s1">resid_msq = resid_ssq / resid_ssq_n</span>
        <span class="s1">dep_params /= resid_msq</span>
        <span class="s1">self.dep_params = dep_params</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s2">if </span><span class="s1">self.grid:</span>
            <span class="s2">return </span><span class="s1">self.covariance_matrix_grid(endog_expval</span><span class="s2">, </span><span class="s1">index)</span>

        <span class="s1">j1</span><span class="s2">, </span><span class="s1">j2 = np.tril_indices(len(endog_expval)</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">dx = np.abs(self.time[index][j1] - self.time[index][j2])</span>
        <span class="s1">ii = np.flatnonzero(dx &lt;= self.max_lag)</span>
        <span class="s1">j1 = j1[ii]</span>
        <span class="s1">j2 = j2[ii]</span>
        <span class="s1">dx = dx[ii]</span>

        <span class="s1">cmat = np.eye(len(endog_expval))</span>
        <span class="s1">cmat[j1</span><span class="s2">, </span><span class="s1">j2] = self.dep_params[dx]</span>
        <span class="s1">cmat[j2</span><span class="s2">, </span><span class="s1">j1] = self.dep_params[dx]</span>

        <span class="s2">return </span><span class="s1">cmat</span><span class="s2">, True</span>

    <span class="s2">def </span><span class="s1">covariance_matrix_grid(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s2">from </span><span class="s1">scipy.linalg </span><span class="s2">import </span><span class="s1">toeplitz</span>
        <span class="s1">r = np.zeros(len(endog_expval))</span>
        <span class="s1">r[</span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
        <span class="s1">r[</span><span class="s5">1</span><span class="s1">:self.max_lag + </span><span class="s5">1</span><span class="s1">] = self.dep_params[</span><span class="s5">1</span><span class="s1">:]</span>
        <span class="s2">return </span><span class="s1">toeplitz(r)</span><span class="s2">, True</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix_solve.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix_solve(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs):</span>

        <span class="s2">if not </span><span class="s1">self.grid:</span>
            <span class="s2">return </span><span class="s1">super(Stationary</span><span class="s2">, </span><span class="s1">self).covariance_matrix_solve(</span>
                <span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs)</span>

        <span class="s2">from </span><span class="s1">statsmodels.tools.linalg </span><span class="s2">import </span><span class="s1">stationary_solve</span>
        <span class="s1">r = np.zeros(len(expval))</span>
        <span class="s1">r[</span><span class="s5">0</span><span class="s1">:self.max_lag] = self.dep_params[</span><span class="s5">1</span><span class="s1">:]</span>

        <span class="s1">rslt = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs:</span>
            <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">y = x / stdev</span>
                <span class="s1">rslt.append(stationary_solve(r</span><span class="s2">, </span><span class="s1">y) / stdev)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">y = x / stdev[:</span><span class="s2">, None</span><span class="s1">]</span>
                <span class="s1">rslt.append(stationary_solve(r</span><span class="s2">, </span><span class="s1">y) / stdev[:</span><span class="s2">, None</span><span class="s1">])</span>

        <span class="s2">return </span><span class="s1">rslt</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>

        <span class="s1">lag = np.arange(self.max_lag + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">pd.DataFrame({</span><span class="s3">&quot;Lag&quot;</span><span class="s1">: lag</span><span class="s2">, </span><span class="s3">&quot;Cov&quot;</span><span class="s1">: self.dep_params})</span>


<span class="s2">class </span><span class="s1">Autoregressive(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    A first-order autoregressive working dependence structure. 
 
    The dependence is defined in terms of the `time` component of the 
    parent GEE class, which defaults to the index position of each 
    value within its cluster, based on the order of values in the 
    input data set.  Time represents a potentially multidimensional 
    index from which distances between pairs of observations can be 
    determined. 
 
    The correlation between two observations in the same cluster is 
    dep_params^distance, where `dep_params` contains the (scalar) 
    autocorrelation parameter to be estimated, and `distance` is the 
    distance between the two observations, calculated from their 
    corresponding time values.  `time` is stored as an n_obs x k 
    matrix, where `k` represents the number of dimensions in the time 
    index. 
 
    The autocorrelation parameter is estimated using weighted 
    nonlinear least squares, regressing each value within a cluster on 
    each preceding value in the same cluster. 
 
    Parameters 
    ---------- 
    dist_func : function from R^k x R^k to R^+, optional 
        A function that computes the distance between the two 
        observations based on their `time` values. 
 
    References 
    ---------- 
    B Rosner, A Munoz.  Autoregressive modeling for the analysis of 
    longitudinal data with unequally spaced examinations.  Statistics 
    in medicine. Vol 7, 59-71, 1988. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">dist_func=</span><span class="s2">None, </span><span class="s1">grid=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s1">super(Autoregressive</span><span class="s2">, </span><span class="s1">self).__init__()</span>
        <span class="s1">grid = bool_like(grid</span><span class="s2">, </span><span class="s3">&quot;grid&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s4"># The function for determining distances based on time</span>
        <span class="s2">if </span><span class="s1">dist_func </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">self.dist_func = </span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: np.abs(x - y).sum()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.dist_func = dist_func</span>

        <span class="s2">if </span><span class="s1">grid </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;grid=True will become default in a future version&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span>
            <span class="s1">)</span>
        <span class="s1">self.grid = bool(grid)</span>
        <span class="s2">if not </span><span class="s1">self.grid:</span>
            <span class="s1">self.designx = </span><span class="s2">None</span>

        <span class="s4"># The autocorrelation parameter</span>
        <span class="s1">self.dep_params = </span><span class="s5">0.</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s2">if </span><span class="s1">self.model.weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;weights not implemented for autoregressive &quot;</span>
                          <span class="s3">&quot;cov_struct, using unweighted covariance estimate&quot;</span><span class="s2">,</span>
                          <span class="s1">NotImplementedWarning)</span>

        <span class="s2">if </span><span class="s1">self.grid:</span>
            <span class="s1">self._update_grid(params)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._update_nogrid(params)</span>

    <span class="s2">def </span><span class="s1">_update_grid(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">cached_means = self.model.cached_means</span>
        <span class="s1">scale = self.model.estimate_scale()</span>
        <span class="s1">varfunc = self.model.family.variance</span>
        <span class="s1">endog = self.model.endog_li</span>

        <span class="s1">lag0</span><span class="s2">, </span><span class="s1">lag1 = </span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">0.0</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(scale * varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">n = len(resid)</span>
            <span class="s2">if </span><span class="s1">n &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">lag1 += np.sum(resid[</span><span class="s5">0</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">] * resid[</span><span class="s5">1</span><span class="s1">:]) / (n - </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">lag0 += np.sum(resid**</span><span class="s5">2</span><span class="s1">) / n</span>

        <span class="s1">self.dep_params = lag1 / lag0</span>

    <span class="s2">def </span><span class="s1">_update_nogrid(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">time = self.model.time_li</span>

        <span class="s4"># Only need to compute this once</span>
        <span class="s2">if </span><span class="s1">self.designx </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">designx = self.designx</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">designx = []</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

                <span class="s1">ngrp = len(endog[i])</span>
                <span class="s2">if </span><span class="s1">ngrp == </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s2">continue</span>

                <span class="s4"># Loop over pairs of observations within a cluster</span>
                <span class="s2">for </span><span class="s1">j1 </span><span class="s2">in </span><span class="s1">range(ngrp):</span>
                    <span class="s2">for </span><span class="s1">j2 </span><span class="s2">in </span><span class="s1">range(j1):</span>
                        <span class="s1">designx.append(self.dist_func(time[i][j1</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">,</span>
                                                      <span class="s1">time[i][j2</span><span class="s2">, </span><span class="s1">:]))</span>

            <span class="s1">designx = np.array(designx)</span>
            <span class="s1">self.designx = designx</span>

        <span class="s1">scale = self.model.estimate_scale()</span>
        <span class="s1">varfunc = self.model.family.variance</span>
        <span class="s1">cached_means = self.model.cached_means</span>

        <span class="s4"># Weights</span>
        <span class="s1">var = </span><span class="s5">1. </span><span class="s1">- self.dep_params ** (</span><span class="s5">2 </span><span class="s1">* designx)</span>
        <span class="s1">var /= </span><span class="s5">1. </span><span class="s1">- self.dep_params ** </span><span class="s5">2</span>
        <span class="s1">wts = </span><span class="s5">1. </span><span class="s1">/ var</span>
        <span class="s1">wts /= wts.sum()</span>

        <span class="s1">residmat = []</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>
            <span class="s1">stdev = np.sqrt(scale * varfunc(expval))</span>
            <span class="s1">resid = (endog[i] - expval) / stdev</span>

            <span class="s1">ngrp = len(resid)</span>
            <span class="s2">for </span><span class="s1">j1 </span><span class="s2">in </span><span class="s1">range(ngrp):</span>
                <span class="s2">for </span><span class="s1">j2 </span><span class="s2">in </span><span class="s1">range(j1):</span>
                    <span class="s1">residmat.append([resid[j1]</span><span class="s2">, </span><span class="s1">resid[j2]])</span>

        <span class="s1">residmat = np.array(residmat)</span>

        <span class="s4"># Need to minimize this</span>
        <span class="s2">def </span><span class="s1">fitfunc(a):</span>
            <span class="s1">dif = residmat[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] - (a ** designx) * residmat[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
            <span class="s2">return </span><span class="s1">np.dot(dif ** </span><span class="s5">2</span><span class="s2">, </span><span class="s1">wts)</span>

        <span class="s4"># Left bracket point</span>
        <span class="s1">b_lft</span><span class="s2">, </span><span class="s1">f_lft = </span><span class="s5">0.</span><span class="s2">, </span><span class="s1">fitfunc(</span><span class="s5">0.</span><span class="s1">)</span>

        <span class="s4"># Center bracket point</span>
        <span class="s1">b_ctr</span><span class="s2">, </span><span class="s1">f_ctr = </span><span class="s5">0.5</span><span class="s2">, </span><span class="s1">fitfunc(</span><span class="s5">0.5</span><span class="s1">)</span>
        <span class="s2">while </span><span class="s1">f_ctr &gt; f_lft:</span>
            <span class="s1">b_ctr /= </span><span class="s5">2</span>
            <span class="s1">f_ctr = fitfunc(b_ctr)</span>
            <span class="s2">if </span><span class="s1">b_ctr &lt; </span><span class="s5">1e-8</span><span class="s1">:</span>
                <span class="s1">self.dep_params = </span><span class="s5">0</span>
                <span class="s2">return</span>

        <span class="s4"># Right bracket point</span>
        <span class="s1">b_rgt</span><span class="s2">, </span><span class="s1">f_rgt = </span><span class="s5">0.75</span><span class="s2">, </span><span class="s1">fitfunc(</span><span class="s5">0.75</span><span class="s1">)</span>
        <span class="s2">while </span><span class="s1">f_rgt &lt; f_ctr:</span>
            <span class="s1">b_rgt = b_rgt + (</span><span class="s5">1. </span><span class="s1">- b_rgt) / </span><span class="s5">2</span>
            <span class="s1">f_rgt = fitfunc(b_rgt)</span>
            <span class="s2">if </span><span class="s1">b_rgt &gt; </span><span class="s5">1. </span><span class="s1">- </span><span class="s5">1e-6</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;Autoregressive: unable to find right bracket&quot;</span><span class="s1">)</span>

        <span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">brent</span>
        <span class="s1">self.dep_params = brent(fitfunc</span><span class="s2">, </span><span class="s1">brack=[b_lft</span><span class="s2">, </span><span class="s1">b_ctr</span><span class="s2">, </span><span class="s1">b_rgt])</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s1">ngrp = len(endog_expval)</span>
        <span class="s2">if </span><span class="s1">self.dep_params == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.eye(ngrp</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span><span class="s2">, True</span>
        <span class="s1">idx = np.arange(ngrp)</span>
        <span class="s1">cmat = self.dep_params ** np.abs(idx[:</span><span class="s2">, None</span><span class="s1">] - idx[</span><span class="s2">None, </span><span class="s1">:])</span>
        <span class="s2">return </span><span class="s1">cmat</span><span class="s2">, True</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix_solve.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix_solve(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">stdev</span><span class="s2">, </span><span class="s1">rhs):</span>
        <span class="s4"># The inverse of an AR(1) covariance matrix is tri-diagonal.</span>

        <span class="s1">k = len(expval)</span>
        <span class="s1">r = self.dep_params</span>
        <span class="s1">soln = []</span>

        <span class="s4"># RHS has 1 row</span>
        <span class="s2">if </span><span class="s1">k == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">[x / stdev ** </span><span class="s5">2 </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs]</span>

        <span class="s4"># RHS has 2 rows</span>
        <span class="s2">if </span><span class="s1">k == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">mat = np.array([[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-r]</span><span class="s2">, </span><span class="s1">[-r</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]])</span>
            <span class="s1">mat /= (</span><span class="s5">1. </span><span class="s1">- r ** </span><span class="s5">2</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs:</span>
                <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s1">x1 = x / stdev</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">x1 = x / stdev[:</span><span class="s2">, None</span><span class="s1">]</span>
                <span class="s1">x1 = np.dot(mat</span><span class="s2">, </span><span class="s1">x1)</span>
                <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s1">x1 /= stdev</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">x1 /= stdev[:</span><span class="s2">, None</span><span class="s1">]</span>
                <span class="s1">soln.append(x1)</span>
            <span class="s2">return </span><span class="s1">soln</span>

        <span class="s4"># RHS has &gt;= 3 rows: values c0, c1, c2 defined below give</span>
        <span class="s4"># the inverse.  c0 is on the diagonal, except for the first</span>
        <span class="s4"># and last position.  c1 is on the first and last position of</span>
        <span class="s4"># the diagonal.  c2 is on the sub/super diagonal.</span>
        <span class="s1">c0 = (</span><span class="s5">1. </span><span class="s1">+ r ** </span><span class="s5">2</span><span class="s1">) / (</span><span class="s5">1. </span><span class="s1">- r ** </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">c1 = </span><span class="s5">1. </span><span class="s1">/ (</span><span class="s5">1. </span><span class="s1">- r ** </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">c2 = -r / (</span><span class="s5">1. </span><span class="s1">- r ** </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">soln = []</span>
        <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">rhs:</span>
            <span class="s1">flatten = </span><span class="s2">False</span>
            <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">x = x[:</span><span class="s2">, None</span><span class="s1">]</span>
                <span class="s1">flatten = </span><span class="s2">True</span>
            <span class="s1">x1 = x / stdev[:</span><span class="s2">, None</span><span class="s1">]</span>

            <span class="s1">z0 = np.zeros((</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x1.shape[</span><span class="s5">1</span><span class="s1">]))</span>
            <span class="s1">rhs1 = np.concatenate((x1[</span><span class="s5">1</span><span class="s1">:</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">z0)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">rhs2 = np.concatenate((z0</span><span class="s2">, </span><span class="s1">x1[</span><span class="s5">0</span><span class="s1">:-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:])</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

            <span class="s1">y = c0 * x1 + c2 * rhs1 + c2 * rhs2</span>
            <span class="s1">y[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:] = c1 * x1[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:] + c2 * x1[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:]</span>
            <span class="s1">y[-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:] = c1 * x1[-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">:] + c2 * x1[-</span><span class="s5">2</span><span class="s2">, </span><span class="s1">:]</span>

            <span class="s1">y /= stdev[:</span><span class="s2">, None</span><span class="s1">]</span>

            <span class="s2">if </span><span class="s1">flatten:</span>
                <span class="s1">y = np.squeeze(y)</span>

            <span class="s1">soln.append(y)</span>

        <span class="s2">return </span><span class="s1">soln</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>

        <span class="s2">return </span><span class="s1">(</span><span class="s3">&quot;Autoregressive(1) dependence parameter: %.3f</span><span class="s2">\n</span><span class="s3">&quot; </span><span class="s1">%</span>
                <span class="s1">self.dep_params)</span>


<span class="s2">class </span><span class="s1">CategoricalCovStruct(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    Parent class for covariance structure for categorical data models. 
 
    Attributes 
    ---------- 
    nlevel : int 
        The number of distinct levels for the outcome variable. 
    ibd : list 
        A list whose i^th element ibd[i] is an array whose rows 
        contain integer pairs (a,b), where endog_li[i][a:b] is the 
        subvector of binary indicators derived from the same ordinal 
        value. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>

        <span class="s1">super(CategoricalCovStruct</span><span class="s2">, </span><span class="s1">self).initialize(model)</span>

        <span class="s1">self.nlevel = len(model.endog_values)</span>
        <span class="s1">self._ncut = self.nlevel - </span><span class="s5">1</span>

        <span class="s2">from </span><span class="s1">numpy.lib.stride_tricks </span><span class="s2">import </span><span class="s1">as_strided</span>
        <span class="s1">b = np.dtype(np.int64).itemsize</span>

        <span class="s1">ibd = []</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">model.endog_li:</span>
            <span class="s1">jj = np.arange(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">len(v) + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">self._ncut</span><span class="s2">, </span><span class="s1">dtype=np.int64)</span>
            <span class="s1">jj = as_strided(jj</span><span class="s2">, </span><span class="s1">shape=(len(jj) - </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">strides=(b</span><span class="s2">, </span><span class="s1">b))</span>
            <span class="s1">ibd.append(jj)</span>

        <span class="s1">self.ibd = ibd</span>


<span class="s2">class </span><span class="s1">GlobalOddsRatio(CategoricalCovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    Estimate the global odds ratio for a GEE with ordinal or nominal 
    data. 
 
    References 
    ---------- 
    PJ Heagerty and S Zeger. &quot;Marginal Regression Models for Clustered 
    Ordinal Measurements&quot;. Journal of the American Statistical 
    Association Vol. 91, Issue 435 (1996). 
 
    Thomas Lumley. Generalized Estimating Equations for Ordinal Data: 
    A Note on Working Correlation Structures. Biometrics Vol. 52, 
    No. 1 (Mar., 1996), pp. 354-361 
    http://www.jstor.org/stable/2533173 
 
    Notes 
    ----- 
    The following data structures are calculated in the class: 
 
    'ibd' is a list whose i^th element ibd[i] is a sequence of integer 
    pairs (a,b), where endog_li[i][a:b] is the subvector of binary 
    indicators derived from the same ordinal value. 
 
    `cpp` is a dictionary where cpp[group] is a map from cut-point 
    pairs (c,c') to the indices of all between-subject pairs derived 
    from the given cut points. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog_type):</span>
        <span class="s1">super(GlobalOddsRatio</span><span class="s2">, </span><span class="s1">self).__init__()</span>
        <span class="s1">self.endog_type = endog_type</span>
        <span class="s1">self.dep_params = </span><span class="s5">0.</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>

        <span class="s1">super(GlobalOddsRatio</span><span class="s2">, </span><span class="s1">self).initialize(model)</span>

        <span class="s2">if </span><span class="s1">self.model.weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;weights not implemented for GlobalOddsRatio &quot;</span>
                          <span class="s3">&quot;cov_struct, using unweighted covariance estimate&quot;</span><span class="s2">,</span>
                          <span class="s1">NotImplementedWarning)</span>

        <span class="s4"># Need to restrict to between-subject pairs</span>
        <span class="s1">cpp = []</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">model.endog_li:</span>

            <span class="s4"># Number of subjects in this group</span>
            <span class="s1">m = int(len(v) / self._ncut)</span>
            <span class="s1">i1</span><span class="s2">, </span><span class="s1">i2 = np.tril_indices(m</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">cpp1 = {}</span>
            <span class="s2">for </span><span class="s1">k1 </span><span class="s2">in </span><span class="s1">range(self._ncut):</span>
                <span class="s2">for </span><span class="s1">k2 </span><span class="s2">in </span><span class="s1">range(k1 + </span><span class="s5">1</span><span class="s1">):</span>
                    <span class="s1">jj = np.zeros((len(i1)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.int64)</span>
                    <span class="s1">jj[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = i1 * self._ncut + k1</span>
                    <span class="s1">jj[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = i2 * self._ncut + k2</span>
                    <span class="s1">cpp1[(k2</span><span class="s2">, </span><span class="s1">k1)] = jj</span>

            <span class="s1">cpp.append(cpp1)</span>

        <span class="s1">self.cpp = cpp</span>

        <span class="s4"># Initialize the dependence parameters</span>
        <span class="s1">self.crude_or = self.observed_crude_oddsratio()</span>
        <span class="s2">if </span><span class="s1">self.model.update_dep:</span>
            <span class="s1">self.dep_params = self.crude_or</span>

    <span class="s2">def </span><span class="s1">pooled_odds_ratio(self</span><span class="s2">, </span><span class="s1">tables):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the pooled odds ratio for a list of 2x2 tables. 
 
        The pooled odds ratio is the inverse variance weighted average 
        of the sample odds ratios of the tables. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">len(tables) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s5">1.</span>

        <span class="s4"># Get the sampled odds ratios and variances</span>
        <span class="s1">log_oddsratio</span><span class="s2">, </span><span class="s1">var = []</span><span class="s2">, </span><span class="s1">[]</span>
        <span class="s2">for </span><span class="s1">table </span><span class="s2">in </span><span class="s1">tables:</span>
            <span class="s1">lor = np.log(table[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]) + np.log(table[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]) -\</span>
                <span class="s1">np.log(table[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]) - np.log(table[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
            <span class="s1">log_oddsratio.append(lor)</span>
            <span class="s1">var.append((</span><span class="s5">1 </span><span class="s1">/ table.astype(np.float64)).sum())</span>

        <span class="s4"># Calculate the inverse variance weighted average</span>
        <span class="s1">wts = [</span><span class="s5">1 </span><span class="s1">/ v </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">var]</span>
        <span class="s1">wtsum = sum(wts)</span>
        <span class="s1">wts = [w / wtsum </span><span class="s2">for </span><span class="s1">w </span><span class="s2">in </span><span class="s1">wts]</span>
        <span class="s1">log_pooled_or = sum([w * e </span><span class="s2">for </span><span class="s1">w</span><span class="s2">, </span><span class="s1">e </span><span class="s2">in </span><span class="s1">zip(wts</span><span class="s2">, </span><span class="s1">log_oddsratio)])</span>

        <span class="s2">return </span><span class="s1">np.exp(log_pooled_or)</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expected_value</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s1">vmat = self.get_eyy(expected_value</span><span class="s2">, </span><span class="s1">index)</span>
        <span class="s1">vmat -= np.outer(expected_value</span><span class="s2">, </span><span class="s1">expected_value)</span>
        <span class="s2">return </span><span class="s1">vmat</span><span class="s2">, False</span>

    <span class="s2">def </span><span class="s1">observed_crude_oddsratio(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        To obtain the crude (global) odds ratio, first pool all binary 
        indicators corresponding to a given pair of cut points (c,c'), 
        then calculate the odds ratio for this 2x2 table.  The crude 
        odds ratio is the inverse variance weighted average of these 
        odds ratios.  Since the covariate effects are ignored, this OR 
        will generally be greater than the stratified OR. 
        &quot;&quot;&quot;</span>

        <span class="s1">cpp = self.cpp</span>
        <span class="s1">endog = self.model.endog_li</span>

        <span class="s4"># Storage for the contingency tables for each (c,c')</span>
        <span class="s1">tables = {}</span>
        <span class="s2">for </span><span class="s1">ii </span><span class="s2">in </span><span class="s1">cpp[</span><span class="s5">0</span><span class="s1">].keys():</span>
            <span class="s1">tables[ii] = np.zeros((</span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s4"># Get the observed crude OR</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(endog)):</span>

            <span class="s4"># The observed joint values for the current cluster</span>
            <span class="s1">yvec = endog[i]</span>
            <span class="s1">endog_11 = np.outer(yvec</span><span class="s2">, </span><span class="s1">yvec)</span>
            <span class="s1">endog_10 = np.outer(yvec</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">- yvec)</span>
            <span class="s1">endog_01 = np.outer(</span><span class="s5">1. </span><span class="s1">- yvec</span><span class="s2">, </span><span class="s1">yvec)</span>
            <span class="s1">endog_00 = np.outer(</span><span class="s5">1. </span><span class="s1">- yvec</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">- yvec)</span>

            <span class="s1">cpp1 = cpp[i]</span>
            <span class="s2">for </span><span class="s1">ky </span><span class="s2">in </span><span class="s1">cpp1.keys():</span>
                <span class="s1">ix = cpp1[ky]</span>
                <span class="s1">tables[ky][</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] += endog_11[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] += endog_10[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] += endog_01[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] += endog_00[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>

        <span class="s2">return </span><span class="s1">self.pooled_odds_ratio(list(tables.values()))</span>

    <span class="s2">def </span><span class="s1">get_eyy(self</span><span class="s2">, </span><span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a matrix V such that V[i,j] is the joint probability 
        that endog[i] = 1 and endog[j] = 1, based on the marginal 
        probabilities of endog and the global odds ratio `current_or`. 
        &quot;&quot;&quot;</span>

        <span class="s1">current_or = self.dep_params</span>
        <span class="s1">ibd = self.ibd[index]</span>

        <span class="s4"># The between-observation joint probabilities</span>
        <span class="s2">if </span><span class="s1">current_or == </span><span class="s5">1.0</span><span class="s1">:</span>
            <span class="s1">vmat = np.outer(endog_expval</span><span class="s2">, </span><span class="s1">endog_expval)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">psum = endog_expval[:</span><span class="s2">, None</span><span class="s1">] + endog_expval[</span><span class="s2">None, </span><span class="s1">:]</span>
            <span class="s1">pprod = endog_expval[:</span><span class="s2">, None</span><span class="s1">] * endog_expval[</span><span class="s2">None, </span><span class="s1">:]</span>
            <span class="s1">pfac = np.sqrt((</span><span class="s5">1. </span><span class="s1">+ psum * (current_or - </span><span class="s5">1.</span><span class="s1">)) ** </span><span class="s5">2 </span><span class="s1">+</span>
                           <span class="s5">4 </span><span class="s1">* current_or * (</span><span class="s5">1. </span><span class="s1">- current_or) * pprod)</span>
            <span class="s1">vmat = </span><span class="s5">1. </span><span class="s1">+ psum * (current_or - </span><span class="s5">1.</span><span class="s1">) - pfac</span>
            <span class="s1">vmat /= </span><span class="s5">2. </span><span class="s1">* (current_or - </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Fix E[YY'] for elements that belong to same observation</span>
        <span class="s2">for </span><span class="s1">bdl </span><span class="s2">in </span><span class="s1">ibd:</span>
            <span class="s1">evy = endog_expval[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s2">if </span><span class="s1">self.endog_type == </span><span class="s3">&quot;ordinal&quot;</span><span class="s1">:</span>
                <span class="s1">vmat[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]] =\</span>
                    <span class="s1">np.minimum.outer(evy</span><span class="s2">, </span><span class="s1">evy)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">vmat[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]] = np.diag(evy)</span>

        <span class="s2">return </span><span class="s1">vmat</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s0">&quot;&quot;&quot; 
        Update the global odds ratio based on the current value of 
        params. 
        &quot;&quot;&quot;</span>

        <span class="s1">cpp = self.cpp</span>
        <span class="s1">cached_means = self.model.cached_means</span>

        <span class="s4"># This will happen if all the clusters have only</span>
        <span class="s4"># one observation</span>
        <span class="s2">if </span><span class="s1">len(cpp[</span><span class="s5">0</span><span class="s1">]) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return</span>

        <span class="s1">tables = {}</span>
        <span class="s2">for </span><span class="s1">ii </span><span class="s2">in </span><span class="s1">cpp[</span><span class="s5">0</span><span class="s1">]:</span>
            <span class="s1">tables[ii] = np.zeros((</span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.model.num_group):</span>

            <span class="s1">endog_expval</span><span class="s2">, </span><span class="s1">_ = cached_means[i]</span>

            <span class="s1">emat_11 = self.get_eyy(endog_expval</span><span class="s2">, </span><span class="s1">i)</span>
            <span class="s1">emat_10 = endog_expval[:</span><span class="s2">, None</span><span class="s1">] - emat_11</span>
            <span class="s1">emat_01 = -emat_11 + endog_expval</span>
            <span class="s1">emat_00 = </span><span class="s5">1. </span><span class="s1">- (emat_11 + emat_10 + emat_01)</span>

            <span class="s1">cpp1 = cpp[i]</span>
            <span class="s2">for </span><span class="s1">ky </span><span class="s2">in </span><span class="s1">cpp1.keys():</span>
                <span class="s1">ix = cpp1[ky]</span>
                <span class="s1">tables[ky][</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] += emat_11[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] += emat_10[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] += emat_01[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>
                <span class="s1">tables[ky][</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] += emat_00[ix[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ix[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]].sum()</span>

        <span class="s1">cor_expval = self.pooled_odds_ratio(list(tables.values()))</span>

        <span class="s1">self.dep_params *= self.crude_or / cor_expval</span>
        <span class="s2">if not </span><span class="s1">np.isfinite(self.dep_params):</span>
            <span class="s1">self.dep_params = </span><span class="s5">1.</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;dep_params became inf, resetting to 1&quot;</span><span class="s2">,</span>
                          <span class="s1">ConvergenceWarning)</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>
        <span class="s2">return </span><span class="s3">&quot;Global odds ratio: %.3f</span><span class="s2">\n</span><span class="s3">&quot; </span><span class="s1">% self.dep_params</span>


<span class="s2">class </span><span class="s1">OrdinalIndependence(CategoricalCovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    An independence covariance structure for ordinal models. 
 
    The working covariance between indicators derived from different 
    observations is zero.  The working covariance between indicators 
    derived form a common observation is determined from their current 
    mean values. 
 
    There are no parameters to estimate in this covariance structure. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expected_value</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s1">ibd = self.ibd[index]</span>
        <span class="s1">n = len(expected_value)</span>
        <span class="s1">vmat = np.zeros((n</span><span class="s2">, </span><span class="s1">n))</span>

        <span class="s2">for </span><span class="s1">bdl </span><span class="s2">in </span><span class="s1">ibd:</span>
            <span class="s1">ev = expected_value[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s1">vmat[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]] =\</span>
                <span class="s1">np.minimum.outer(ev</span><span class="s2">, </span><span class="s1">ev) - np.outer(ev</span><span class="s2">, </span><span class="s1">ev)</span>

        <span class="s2">return </span><span class="s1">vmat</span><span class="s2">, False</span>

    <span class="s4"># Nothing to update</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s2">pass</span>


<span class="s2">class </span><span class="s1">NominalIndependence(CategoricalCovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    An independence covariance structure for nominal models. 
 
    The working covariance between indicators derived from different 
    observations is zero.  The working covariance between indicators 
    derived form a common observation is determined from their current 
    mean values. 
 
    There are no parameters to estimate in this covariance structure. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expected_value</span><span class="s2">, </span><span class="s1">index):</span>

        <span class="s1">ibd = self.ibd[index]</span>
        <span class="s1">n = len(expected_value)</span>
        <span class="s1">vmat = np.zeros((n</span><span class="s2">, </span><span class="s1">n))</span>

        <span class="s2">for </span><span class="s1">bdl </span><span class="s2">in </span><span class="s1">ibd:</span>
            <span class="s1">ev = expected_value[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s1">vmat[bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">bdl[</span><span class="s5">0</span><span class="s1">]:bdl[</span><span class="s5">1</span><span class="s1">]] =\</span>
                <span class="s1">np.diag(ev) - np.outer(ev</span><span class="s2">, </span><span class="s1">ev)</span>

        <span class="s2">return </span><span class="s1">vmat</span><span class="s2">, False</span>

    <span class="s4"># Nothing to update</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>
        <span class="s2">pass</span>


<span class="s2">class </span><span class="s1">Equivalence(CovStruct):</span>
    <span class="s0">&quot;&quot;&quot; 
    A covariance structure defined in terms of equivalence classes. 
 
    An 'equivalence class' is a set of pairs of observations such that 
    the covariance of every pair within the equivalence class has a 
    common value. 
 
    Parameters 
    ---------- 
    pairs : dict-like 
      A dictionary of dictionaries, where `pairs[group][label]` 
      provides the indices of all pairs of observations in the group 
      that have the same covariance value.  Specifically, 
      `pairs[group][label]` is a tuple `(j1, j2)`, where `j1` and `j2` 
      are integer arrays of the same length.  `j1[i], j2[i]` is one 
      index pair that belongs to the `label` equivalence class.  Only 
      one triangle of each covariance matrix should be included. 
      Positions where j1 and j2 have the same value are variance 
      parameters. 
    labels : array_like 
      An array of labels such that every distinct pair of labels 
      defines an equivalence class.  Either `labels` or `pairs` must 
      be provided.  When the two labels in a pair are equal two 
      equivalence classes are defined: one for the diagonal elements 
      (corresponding to variances) and one for the off-diagonal 
      elements (corresponding to covariances). 
    return_cov : bool 
      If True, `covariance_matrix` returns an estimate of the 
      covariance matrix, otherwise returns an estimate of the 
      correlation matrix. 
 
    Notes 
    ----- 
    Using `labels` to define the class is much easier than using 
    `pairs`, but is less general. 
 
    Any pair of values not contained in `pairs` will be assigned zero 
    covariance. 
 
    The index values in `pairs` are row indices into the `exog` 
    matrix.  They are not updated if missing data are present.  When 
    using this covariance structure, missing data should be removed 
    before constructing the model. 
 
    If using `labels`, after a model is defined using the covariance 
    structure it is possible to remove a label pair from the second 
    level of the `pairs` dictionary to force the corresponding 
    covariance to be zero. 
 
    Examples 
    -------- 
    The following sets up the `pairs` dictionary for a model with two 
    groups, equal variance for all observations, and constant 
    covariance for all pairs of observations within each group. 
 
    &gt;&gt; pairs = {0: {}, 1: {}} 
    &gt;&gt; pairs[0][0] = (np.r_[0, 1, 2], np.r_[0, 1, 2]) 
    &gt;&gt; pairs[0][1] = np.tril_indices(3, -1) 
    &gt;&gt; pairs[1][0] = (np.r_[3, 4, 5], np.r_[3, 4, 5]) 
    &gt;&gt; pairs[1][2] = 3 + np.tril_indices(3, -1) 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">pairs=</span><span class="s2">None, </span><span class="s1">labels=</span><span class="s2">None, </span><span class="s1">return_cov=</span><span class="s2">False</span><span class="s1">):</span>

        <span class="s1">super(Equivalence</span><span class="s2">, </span><span class="s1">self).__init__()</span>

        <span class="s2">if </span><span class="s1">(pairs </span><span class="s2">is None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(labels </span><span class="s2">is None</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Equivalence cov_struct requires either `pairs` or `labels`&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">(pairs </span><span class="s2">is not None</span><span class="s1">) </span><span class="s2">and </span><span class="s1">(labels </span><span class="s2">is not None</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Equivalence cov_struct accepts only one of `pairs` &quot;</span>
                <span class="s3">&quot;and `labels`&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">pairs </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">import </span><span class="s1">copy</span>
            <span class="s1">self.pairs = copy.deepcopy(pairs)</span>

        <span class="s2">if </span><span class="s1">labels </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.labels = np.asarray(labels)</span>

        <span class="s1">self.return_cov = return_cov</span>

    <span class="s2">def </span><span class="s1">_make_pairs(self</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">j):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create arrays containing all unique ordered pairs of i, j. 
 
        The arrays i and j must be one-dimensional containing non-negative 
        integers. 
        &quot;&quot;&quot;</span>

        <span class="s1">mat = np.zeros((len(i) * len(j)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dtype=np.int32)</span>

        <span class="s4"># Create the pairs and order them</span>
        <span class="s1">f = np.ones(len(j))</span>
        <span class="s1">mat[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = np.kron(f</span><span class="s2">, </span><span class="s1">i).astype(np.int32)</span>
        <span class="s1">f = np.ones(len(i))</span>
        <span class="s1">mat[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = np.kron(j</span><span class="s2">, </span><span class="s1">f).astype(np.int32)</span>
        <span class="s1">mat.sort(</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s4"># Remove repeated rows</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">dtype = np.dtype((np.void</span><span class="s2">, </span><span class="s1">mat.dtype.itemsize * mat.shape[</span><span class="s5">1</span><span class="s1">]))</span>
            <span class="s1">bmat = np.ascontiguousarray(mat).view(dtype)</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">idx = np.unique(bmat</span><span class="s2">, </span><span class="s1">return_index=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">except </span><span class="s1">TypeError:</span>
            <span class="s4"># workaround for old numpy that cannot call unique with complex</span>
            <span class="s4"># dtypes</span>
            <span class="s1">rs = np.random.RandomState(</span><span class="s5">4234</span><span class="s1">)</span>
            <span class="s1">bmat = np.dot(mat</span><span class="s2">, </span><span class="s1">rs.uniform(size=mat.shape[</span><span class="s5">1</span><span class="s1">]))</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">idx = np.unique(bmat</span><span class="s2">, </span><span class="s1">return_index=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">mat = mat[idx</span><span class="s2">, </span><span class="s1">:]</span>

        <span class="s2">return </span><span class="s1">mat[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">mat[:</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">_pairs_from_labels(self):</span>

        <span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">defaultdict</span>
        <span class="s1">pairs = defaultdict(</span><span class="s2">lambda</span><span class="s1">: defaultdict(</span><span class="s2">lambda</span><span class="s1">: </span><span class="s2">None</span><span class="s1">))</span>

        <span class="s1">model = self.model</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s3">&quot;labels&quot;</span><span class="s1">: self.labels</span><span class="s2">, </span><span class="s3">&quot;groups&quot;</span><span class="s1">: model.groups})</span>
        <span class="s1">gb = df.groupby([</span><span class="s3">&quot;groups&quot;</span><span class="s2">, </span><span class="s3">&quot;labels&quot;</span><span class="s1">])</span>

        <span class="s1">ulabels = np.unique(self.labels)</span>

        <span class="s2">for </span><span class="s1">g_ix</span><span class="s2">, </span><span class="s1">g_lb </span><span class="s2">in </span><span class="s1">enumerate(model.group_labels):</span>

            <span class="s4"># Loop over label pairs</span>
            <span class="s2">for </span><span class="s1">lx1 </span><span class="s2">in </span><span class="s1">range(len(ulabels)):</span>
                <span class="s2">for </span><span class="s1">lx2 </span><span class="s2">in </span><span class="s1">range(lx1 + </span><span class="s5">1</span><span class="s1">):</span>

                    <span class="s1">lb1 = ulabels[lx1]</span>
                    <span class="s1">lb2 = ulabels[lx2]</span>

                    <span class="s2">try</span><span class="s1">:</span>
                        <span class="s1">i1 = gb.groups[(g_lb</span><span class="s2">, </span><span class="s1">lb1)]</span>
                        <span class="s1">i2 = gb.groups[(g_lb</span><span class="s2">, </span><span class="s1">lb2)]</span>
                    <span class="s2">except </span><span class="s1">KeyError:</span>
                        <span class="s2">continue</span>

                    <span class="s1">i1</span><span class="s2">, </span><span class="s1">i2 = self._make_pairs(i1</span><span class="s2">, </span><span class="s1">i2)</span>

                    <span class="s1">clabel = str(lb1) + </span><span class="s3">&quot;/&quot; </span><span class="s1">+ str(lb2)</span>

                    <span class="s4"># Variance parameters belong in their own equiv class.</span>
                    <span class="s1">jj = np.flatnonzero(i1 == i2)</span>
                    <span class="s2">if </span><span class="s1">len(jj) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                        <span class="s1">clabelv = clabel + </span><span class="s3">&quot;/v&quot;</span>
                        <span class="s1">pairs[g_lb][clabelv] = (i1[jj]</span><span class="s2">, </span><span class="s1">i2[jj])</span>

                    <span class="s4"># Covariance parameters</span>
                    <span class="s1">jj = np.flatnonzero(i1 != i2)</span>
                    <span class="s2">if </span><span class="s1">len(jj) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                        <span class="s1">i1 = i1[jj]</span>
                        <span class="s1">i2 = i2[jj]</span>
                        <span class="s1">pairs[g_lb][clabel] = (i1</span><span class="s2">, </span><span class="s1">i2)</span>

        <span class="s1">self.pairs = pairs</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model):</span>

        <span class="s1">super(Equivalence</span><span class="s2">, </span><span class="s1">self).initialize(model)</span>

        <span class="s2">if </span><span class="s1">self.model.weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;weights not implemented for equalence cov_struct, &quot;</span>
                          <span class="s3">&quot;using unweighted covariance estimate&quot;</span><span class="s2">,</span>
                          <span class="s1">NotImplementedWarning)</span>

        <span class="s2">if not </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s3">'pairs'</span><span class="s1">):</span>
            <span class="s1">self._pairs_from_labels()</span>

        <span class="s4"># Initialize so that any equivalence class containing a</span>
        <span class="s4"># variance parameter has value 1.</span>
        <span class="s1">self.dep_params = defaultdict(</span><span class="s2">lambda</span><span class="s1">: </span><span class="s5">0.</span><span class="s1">)</span>
        <span class="s1">self._var_classes = set()</span>
        <span class="s2">for </span><span class="s1">gp </span><span class="s2">in </span><span class="s1">self.model.group_labels:</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self.pairs[gp]:</span>
                <span class="s1">j1</span><span class="s2">, </span><span class="s1">j2 = self.pairs[gp][lb]</span>
                <span class="s2">if </span><span class="s1">np.any(j1 == j2):</span>
                    <span class="s2">if not </span><span class="s1">np.all(j1 == j2):</span>
                        <span class="s1">warnings.warn(</span>
                            <span class="s3">&quot;equivalence class contains both variance &quot;</span>
                            <span class="s3">&quot;and covariance parameters&quot;</span><span class="s2">, </span><span class="s1">OutputWarning)</span>
                    <span class="s1">self._var_classes.add(lb)</span>
                    <span class="s1">self.dep_params[lb] = </span><span class="s5">1</span>

        <span class="s4"># Need to start indexing at 0 within each group.</span>
        <span class="s4"># rx maps olds indices to new indices</span>
        <span class="s1">rx = -</span><span class="s5">1 </span><span class="s1">* np.ones(len(self.model.endog)</span><span class="s2">, </span><span class="s1">dtype=np.int32)</span>
        <span class="s2">for </span><span class="s1">g_ix</span><span class="s2">, </span><span class="s1">g_lb </span><span class="s2">in </span><span class="s1">enumerate(self.model.group_labels):</span>
            <span class="s1">ii = self.model.group_indices[g_lb]</span>
            <span class="s1">rx[ii] = np.arange(len(ii)</span><span class="s2">, </span><span class="s1">dtype=np.int32)</span>

        <span class="s4"># Reindex</span>
        <span class="s2">for </span><span class="s1">gp </span><span class="s2">in </span><span class="s1">self.model.group_labels:</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self.pairs[gp].keys():</span>
                <span class="s1">a</span><span class="s2">, </span><span class="s1">b = self.pairs[gp][lb]</span>
                <span class="s1">self.pairs[gp][lb] = (rx[a]</span><span class="s2">, </span><span class="s1">rx[b])</span>

    <span class="s1">@Appender(CovStruct.update.__doc__)</span>
    <span class="s2">def </span><span class="s1">update(self</span><span class="s2">, </span><span class="s1">params):</span>

        <span class="s1">endog = self.model.endog_li</span>
        <span class="s1">varfunc = self.model.family.variance</span>
        <span class="s1">cached_means = self.model.cached_means</span>
        <span class="s1">dep_params = defaultdict(</span><span class="s2">lambda</span><span class="s1">: [</span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0.</span><span class="s1">])</span>
        <span class="s1">n_pairs = defaultdict(</span><span class="s2">lambda</span><span class="s1">: </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">dim = len(params)</span>

        <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">gp </span><span class="s2">in </span><span class="s1">enumerate(self.model.group_labels):</span>
            <span class="s1">expval</span><span class="s2">, </span><span class="s1">_ = cached_means[k]</span>
            <span class="s1">stdev = np.sqrt(varfunc(expval))</span>
            <span class="s1">resid = (endog[k] - expval) / stdev</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self.pairs[gp].keys():</span>
                <span class="s2">if </span><span class="s1">(</span><span class="s2">not </span><span class="s1">self.return_cov) </span><span class="s2">and </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self._var_classes:</span>
                    <span class="s2">continue</span>
                <span class="s1">jj = self.pairs[gp][lb]</span>
                <span class="s1">dep_params[lb][</span><span class="s5">0</span><span class="s1">] += np.sum(resid[jj[</span><span class="s5">0</span><span class="s1">]] * resid[jj[</span><span class="s5">1</span><span class="s1">]])</span>
                <span class="s2">if not </span><span class="s1">self.return_cov:</span>
                    <span class="s1">dep_params[lb][</span><span class="s5">1</span><span class="s1">] += np.sum(resid[jj[</span><span class="s5">0</span><span class="s1">]] ** </span><span class="s5">2</span><span class="s1">)</span>
                    <span class="s1">dep_params[lb][</span><span class="s5">2</span><span class="s1">] += np.sum(resid[jj[</span><span class="s5">1</span><span class="s1">]] ** </span><span class="s5">2</span><span class="s1">)</span>
                <span class="s1">n_pairs[lb] += len(jj[</span><span class="s5">0</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">self.return_cov:</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">dep_params.keys():</span>
                <span class="s1">dep_params[lb] = dep_params[lb][</span><span class="s5">0</span><span class="s1">] / (n_pairs[lb] - dim)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">dep_params.keys():</span>
                <span class="s1">den = np.sqrt(dep_params[lb][</span><span class="s5">1</span><span class="s1">] * dep_params[lb][</span><span class="s5">2</span><span class="s1">])</span>
                <span class="s1">dep_params[lb] = dep_params[lb][</span><span class="s5">0</span><span class="s1">] / den</span>
            <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self._var_classes:</span>
                <span class="s1">dep_params[lb] = </span><span class="s5">1.</span>

        <span class="s1">self.dep_params = dep_params</span>
        <span class="s1">self.n_pairs = n_pairs</span>

    <span class="s1">@Appender(CovStruct.covariance_matrix.__doc__)</span>
    <span class="s2">def </span><span class="s1">covariance_matrix(self</span><span class="s2">, </span><span class="s1">expval</span><span class="s2">, </span><span class="s1">index):</span>
        <span class="s1">dim = len(expval)</span>
        <span class="s1">cmat = np.zeros((dim</span><span class="s2">, </span><span class="s1">dim))</span>
        <span class="s1">g_lb = self.model.group_labels[index]</span>

        <span class="s2">for </span><span class="s1">lb </span><span class="s2">in </span><span class="s1">self.pairs[g_lb].keys():</span>
            <span class="s1">j1</span><span class="s2">, </span><span class="s1">j2 = self.pairs[g_lb][lb]</span>
            <span class="s1">cmat[j1</span><span class="s2">, </span><span class="s1">j2] = self.dep_params[lb]</span>

        <span class="s1">cmat = cmat + cmat.T</span>
        <span class="s1">np.fill_diagonal(cmat</span><span class="s2">, </span><span class="s1">cmat.diagonal() / </span><span class="s5">2</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">cmat</span><span class="s2">, not </span><span class="s1">self.return_cov</span>
</pre>
</body>
</html>
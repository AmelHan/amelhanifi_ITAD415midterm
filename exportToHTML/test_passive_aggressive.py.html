<html>
<head>
<title>test_passive_aggressive.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_passive_aggressive.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">scipy.sparse </span><span class="s0">as </span><span class="s1">sp</span>

<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">ClassifierMixin</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">load_iris</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">PassiveAggressiveClassifier</span><span class="s0">, </span><span class="s1">PassiveAggressiveRegressor</span>
<span class="s0">from </span><span class="s1">sklearn.utils </span><span class="s0">import </span><span class="s1">check_random_state</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
<span class="s1">)</span>

<span class="s1">iris = load_iris()</span>
<span class="s1">random_state = check_random_state(</span><span class="s2">12</span><span class="s1">)</span>
<span class="s1">indices = np.arange(iris.data.shape[</span><span class="s2">0</span><span class="s1">])</span>
<span class="s1">random_state.shuffle(indices)</span>
<span class="s1">X = iris.data[indices]</span>
<span class="s1">y = iris.target[indices]</span>
<span class="s1">X_csr = sp.csr_matrix(X)</span>


<span class="s0">class </span><span class="s1">MyPassiveAggressive(ClassifierMixin):</span>
    <span class="s0">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s0">,</span>
        <span class="s1">C=</span><span class="s2">1.0</span><span class="s0">,</span>
        <span class="s1">epsilon=</span><span class="s2">0.01</span><span class="s0">,</span>
        <span class="s1">loss=</span><span class="s3">&quot;hinge&quot;</span><span class="s0">,</span>
        <span class="s1">fit_intercept=</span><span class="s0">True,</span>
        <span class="s1">n_iter=</span><span class="s2">1</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s0">None,</span>
    <span class="s1">):</span>
        <span class="s1">self.C = C</span>
        <span class="s1">self.epsilon = epsilon</span>
        <span class="s1">self.loss = loss</span>
        <span class="s1">self.fit_intercept = fit_intercept</span>
        <span class="s1">self.n_iter = n_iter</span>

    <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features = X.shape</span>
        <span class="s1">self.w = np.zeros(n_features</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">self.b = </span><span class="s2">0.0</span>

        <span class="s0">for </span><span class="s1">t </span><span class="s0">in </span><span class="s1">range(self.n_iter):</span>
            <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(n_samples):</span>
                <span class="s1">p = self.project(X[i])</span>
                <span class="s0">if </span><span class="s1">self.loss </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;hinge&quot;</span><span class="s0">, </span><span class="s3">&quot;squared_hinge&quot;</span><span class="s1">):</span>
                    <span class="s1">loss = max(</span><span class="s2">1 </span><span class="s1">- y[i] * p</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">loss = max(np.abs(p - y[i]) - self.epsilon</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>

                <span class="s1">sqnorm = np.dot(X[i]</span><span class="s0">, </span><span class="s1">X[i])</span>

                <span class="s0">if </span><span class="s1">self.loss </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;hinge&quot;</span><span class="s0">, </span><span class="s3">&quot;epsilon_insensitive&quot;</span><span class="s1">):</span>
                    <span class="s1">step = min(self.C</span><span class="s0">, </span><span class="s1">loss / sqnorm)</span>
                <span class="s0">elif </span><span class="s1">self.loss </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;squared_hinge&quot;</span><span class="s0">, </span><span class="s3">&quot;squared_epsilon_insensitive&quot;</span><span class="s1">):</span>
                    <span class="s1">step = loss / (sqnorm + </span><span class="s2">1.0 </span><span class="s1">/ (</span><span class="s2">2 </span><span class="s1">* self.C))</span>

                <span class="s0">if </span><span class="s1">self.loss </span><span class="s0">in </span><span class="s1">(</span><span class="s3">&quot;hinge&quot;</span><span class="s0">, </span><span class="s3">&quot;squared_hinge&quot;</span><span class="s1">):</span>
                    <span class="s1">step *= y[i]</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">step *= np.sign(y[i] - p)</span>

                <span class="s1">self.w += step * X[i]</span>
                <span class="s0">if </span><span class="s1">self.fit_intercept:</span>
                    <span class="s1">self.b += step</span>

    <span class="s0">def </span><span class="s1">project(self</span><span class="s0">, </span><span class="s1">X):</span>
        <span class="s0">return </span><span class="s1">np.dot(X</span><span class="s0">, </span><span class="s1">self.w) + self.b</span>


<span class="s0">def </span><span class="s1">test_classifier_accuracy():</span>
    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s0">for </span><span class="s1">fit_intercept </span><span class="s0">in </span><span class="s1">(</span><span class="s0">True, False</span><span class="s1">):</span>
            <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">(</span><span class="s0">False, True</span><span class="s1">):</span>
                <span class="s1">clf = PassiveAggressiveClassifier(</span>
                    <span class="s1">C=</span><span class="s2">1.0</span><span class="s0">,</span>
                    <span class="s1">max_iter=</span><span class="s2">30</span><span class="s0">,</span>
                    <span class="s1">fit_intercept=fit_intercept</span><span class="s0">,</span>
                    <span class="s1">random_state=</span><span class="s2">1</span><span class="s0">,</span>
                    <span class="s1">average=average</span><span class="s0">,</span>
                    <span class="s1">tol=</span><span class="s0">None,</span>
                <span class="s1">)</span>
                <span class="s1">clf.fit(data</span><span class="s0">, </span><span class="s1">y)</span>
                <span class="s1">score = clf.score(data</span><span class="s0">, </span><span class="s1">y)</span>
                <span class="s0">assert </span><span class="s1">score &gt; </span><span class="s2">0.79</span>
                <span class="s0">if </span><span class="s1">average:</span>
                    <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_classifier_partial_fit():</span>
    <span class="s1">classes = np.unique(y)</span>
    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">(</span><span class="s0">False, True</span><span class="s1">):</span>
            <span class="s1">clf = PassiveAggressiveClassifier(</span>
                <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">5</span>
            <span class="s1">)</span>
            <span class="s0">for </span><span class="s1">t </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">30</span><span class="s1">):</span>
                <span class="s1">clf.partial_fit(data</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">classes)</span>
            <span class="s1">score = clf.score(data</span><span class="s0">, </span><span class="s1">y)</span>
            <span class="s0">assert </span><span class="s1">score &gt; </span><span class="s2">0.79</span>
            <span class="s0">if </span><span class="s1">average:</span>
                <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(clf</span><span class="s0">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_classifier_refit():</span>
    <span class="s4"># Classifier can be retrained on different labels and features.</span>
    <span class="s1">clf = PassiveAggressiveClassifier(max_iter=</span><span class="s2">5</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">assert_array_equal(clf.classes_</span><span class="s0">, </span><span class="s1">np.unique(y))</span>

    <span class="s1">clf.fit(X[:</span><span class="s0">, </span><span class="s1">:-</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">iris.target_names[y])</span>
    <span class="s1">assert_array_equal(clf.classes_</span><span class="s0">, </span><span class="s1">iris.target_names)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;loss&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;hinge&quot;</span><span class="s0">, </span><span class="s3">&quot;squared_hinge&quot;</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_classifier_correctness(loss):</span>
    <span class="s1">y_bin = y.copy()</span>
    <span class="s1">y_bin[y != </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">1</span>

    <span class="s1">clf1 = MyPassiveAggressive(loss=loss</span><span class="s0">, </span><span class="s1">n_iter=</span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">clf1.fit(X</span><span class="s0">, </span><span class="s1">y_bin)</span>

    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s1">clf2 = PassiveAggressiveClassifier(</span>
            <span class="s1">loss=loss</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">shuffle=</span><span class="s0">False, </span><span class="s1">tol=</span><span class="s0">None</span>
        <span class="s1">)</span>
        <span class="s1">clf2.fit(data</span><span class="s0">, </span><span class="s1">y_bin)</span>

        <span class="s1">assert_array_almost_equal(clf1.w</span><span class="s0">, </span><span class="s1">clf2.coef_.ravel()</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;predict_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;predict_log_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;transform&quot;</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_classifier_undefined_methods(response_method):</span>
    <span class="s1">clf = PassiveAggressiveClassifier(max_iter=</span><span class="s2">100</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(AttributeError):</span>
        <span class="s1">getattr(clf</span><span class="s0">, </span><span class="s1">response_method)</span>


<span class="s0">def </span><span class="s1">test_class_weights():</span>
    <span class="s4"># Test class weights.</span>
    <span class="s1">X2 = np.array([[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">0.8</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]])</span>
    <span class="s1">y2 = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span>

    <span class="s1">clf = PassiveAggressiveClassifier(</span>
        <span class="s1">C=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">100</span><span class="s0">, </span><span class="s1">class_weight=</span><span class="s0">None, </span><span class="s1">random_state=</span><span class="s2">100</span>
    <span class="s1">)</span>
    <span class="s1">clf.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>
    <span class="s1">assert_array_equal(clf.predict([[</span><span class="s2">0.2</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">1</span><span class="s1">]))</span>

    <span class="s4"># we give a small weights to class 1</span>
    <span class="s1">clf = PassiveAggressiveClassifier(</span>
        <span class="s1">C=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">100</span><span class="s0">, </span><span class="s1">class_weight={</span><span class="s2">1</span><span class="s1">: </span><span class="s2">0.001</span><span class="s1">}</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s2">100</span>
    <span class="s1">)</span>
    <span class="s1">clf.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>

    <span class="s4"># now the hyperplane should rotate clock-wise and</span>
    <span class="s4"># the prediction on this point should shift</span>
    <span class="s1">assert_array_equal(clf.predict([[</span><span class="s2">0.2</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">np.array([-</span><span class="s2">1</span><span class="s1">]))</span>


<span class="s0">def </span><span class="s1">test_partial_fit_weight_class_balanced():</span>
    <span class="s4"># partial_fit with class_weight='balanced' not supported</span>
    <span class="s1">clf = PassiveAggressiveClassifier(class_weight=</span><span class="s3">&quot;balanced&quot;</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">100</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">clf.partial_fit(X</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">classes=np.unique(y))</span>


<span class="s0">def </span><span class="s1">test_equal_class_weight():</span>
    <span class="s1">X2 = [[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]]</span>
    <span class="s1">y2 = [</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">clf = PassiveAggressiveClassifier(C=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">tol=</span><span class="s0">None, </span><span class="s1">class_weight=</span><span class="s0">None</span><span class="s1">)</span>
    <span class="s1">clf.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>

    <span class="s4"># Already balanced, so &quot;balanced&quot; weights should have no effect</span>
    <span class="s1">clf_balanced = PassiveAggressiveClassifier(C=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">tol=</span><span class="s0">None, </span><span class="s1">class_weight=</span><span class="s3">&quot;balanced&quot;</span><span class="s1">)</span>
    <span class="s1">clf_balanced.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>

    <span class="s1">clf_weighted = PassiveAggressiveClassifier(</span>
        <span class="s1">C=</span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">tol=</span><span class="s0">None, </span><span class="s1">class_weight={</span><span class="s2">0</span><span class="s1">: </span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">1</span><span class="s1">: </span><span class="s2">0.5</span><span class="s1">}</span>
    <span class="s1">)</span>
    <span class="s1">clf_weighted.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>

    <span class="s4"># should be similar up to some epsilon due to learning rate schedule</span>
    <span class="s1">assert_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">clf_weighted.coef_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">clf_balanced.coef_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_wrong_class_weight_label():</span>
    <span class="s4"># ValueError due to wrong class_weight label.</span>
    <span class="s1">X2 = np.array([[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">0.8</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]])</span>
    <span class="s1">y2 = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span>

    <span class="s1">clf = PassiveAggressiveClassifier(class_weight={</span><span class="s2">0</span><span class="s1">: </span><span class="s2">0.5</span><span class="s1">}</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">100</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">clf.fit(X2</span><span class="s0">, </span><span class="s1">y2)</span>


<span class="s0">def </span><span class="s1">test_regressor_mse():</span>
    <span class="s1">y_bin = y.copy()</span>
    <span class="s1">y_bin[y != </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">1</span>

    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s0">for </span><span class="s1">fit_intercept </span><span class="s0">in </span><span class="s1">(</span><span class="s0">True, False</span><span class="s1">):</span>
            <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">(</span><span class="s0">False, True</span><span class="s1">):</span>
                <span class="s1">reg = PassiveAggressiveRegressor(</span>
                    <span class="s1">C=</span><span class="s2">1.0</span><span class="s0">,</span>
                    <span class="s1">fit_intercept=fit_intercept</span><span class="s0">,</span>
                    <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">,</span>
                    <span class="s1">average=average</span><span class="s0">,</span>
                    <span class="s1">max_iter=</span><span class="s2">5</span><span class="s0">,</span>
                <span class="s1">)</span>
                <span class="s1">reg.fit(data</span><span class="s0">, </span><span class="s1">y_bin)</span>
                <span class="s1">pred = reg.predict(data)</span>
                <span class="s0">assert </span><span class="s1">np.mean((pred - y_bin) ** </span><span class="s2">2</span><span class="s1">) &lt; </span><span class="s2">1.7</span>
                <span class="s0">if </span><span class="s1">average:</span>
                    <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s1">)</span>
                    <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_regressor_partial_fit():</span>
    <span class="s1">y_bin = y.copy()</span>
    <span class="s1">y_bin[y != </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">1</span>

    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s0">for </span><span class="s1">average </span><span class="s0">in </span><span class="s1">(</span><span class="s0">False, True</span><span class="s1">):</span>
            <span class="s1">reg = PassiveAggressiveRegressor(</span>
                <span class="s1">random_state=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">average=average</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">100</span>
            <span class="s1">)</span>
            <span class="s0">for </span><span class="s1">t </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">50</span><span class="s1">):</span>
                <span class="s1">reg.partial_fit(data</span><span class="s0">, </span><span class="s1">y_bin)</span>
            <span class="s1">pred = reg.predict(data)</span>
            <span class="s0">assert </span><span class="s1">np.mean((pred - y_bin) ** </span><span class="s2">2</span><span class="s1">) &lt; </span><span class="s2">1.7</span>
            <span class="s0">if </span><span class="s1">average:</span>
                <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s1">)</span>
                <span class="s0">assert </span><span class="s1">hasattr(reg</span><span class="s0">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;loss&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;epsilon_insensitive&quot;</span><span class="s0">, </span><span class="s3">&quot;squared_epsilon_insensitive&quot;</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">test_regressor_correctness(loss):</span>
    <span class="s1">y_bin = y.copy()</span>
    <span class="s1">y_bin[y != </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">1</span>

    <span class="s1">reg1 = MyPassiveAggressive(loss=loss</span><span class="s0">, </span><span class="s1">n_iter=</span><span class="s2">2</span><span class="s1">)</span>
    <span class="s1">reg1.fit(X</span><span class="s0">, </span><span class="s1">y_bin)</span>

    <span class="s0">for </span><span class="s1">data </span><span class="s0">in </span><span class="s1">(X</span><span class="s0">, </span><span class="s1">X_csr):</span>
        <span class="s1">reg2 = PassiveAggressiveRegressor(</span>
            <span class="s1">tol=</span><span class="s0">None, </span><span class="s1">loss=loss</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s2">2</span><span class="s0">, </span><span class="s1">shuffle=</span><span class="s0">False</span>
        <span class="s1">)</span>
        <span class="s1">reg2.fit(data</span><span class="s0">, </span><span class="s1">y_bin)</span>

        <span class="s1">assert_array_almost_equal(reg1.w</span><span class="s0">, </span><span class="s1">reg2.coef_.ravel()</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s2">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_regressor_undefined_methods():</span>
    <span class="s1">reg = PassiveAggressiveRegressor(max_iter=</span><span class="s2">100</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(AttributeError):</span>
        <span class="s1">reg.transform(X)</span>
</pre>
</body>
</html>
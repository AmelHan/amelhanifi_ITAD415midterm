<html>
<head>
<title>example_glm.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
example_glm.py</font>
</center></td></tr></table>
<pre><span class="s0">'''Examples: scikits.statsmodels.GLM 
 
Note: uncomment plt.show() to display graphs 
'''</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">scikits.statsmodels </span><span class="s2">as </span><span class="s1">sm</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>
<span class="s2">from </span><span class="s1">matplotlib </span><span class="s2">import </span><span class="s1">pyplot </span><span class="s2">as </span><span class="s1">plt</span>

<span class="s3">### Example for using GLM on binomial response data</span>
<span class="s3">### the input response vector in this case is N by 2 (success, failure)</span>
<span class="s3"># This data is taken with permission from </span>
<span class="s3"># Jeff Gill (2000) Generalized linear models: A unified approach</span>
<span class="s3"># The dataset can be described by uncommenting</span>

<span class="s3"># print sm.datasets.star98.DESCRLONG</span>

<span class="s3"># The response variable is</span>
<span class="s3"># (# of students above the math national median, # of students below)</span>

<span class="s3"># The explanatory variables are (in column order)</span>
<span class="s3"># The proportion of low income families &quot;LOWINC&quot;</span>
<span class="s3"># The proportions of minority students,&quot;PERASIAN&quot;,&quot;PERBLACK&quot;,&quot;PERHISP&quot;</span>
<span class="s3"># The percentage of minority teachers &quot;PERMINTE&quot;,</span>
<span class="s3"># The median teacher salary including benefits in 1000s &quot;AVSALK&quot;</span>
<span class="s3"># The mean teacher experience in years &quot;AVYRSEXP&quot;,</span>
<span class="s3"># The per-pupil expenditures in thousands &quot;PERSPENK&quot;</span>
<span class="s3"># The parent-teacher ratio &quot;PTRATIO&quot;</span>
<span class="s3"># The percent of students taking college credit courses &quot;PCTAF&quot;,</span>
<span class="s3"># The percentage of charter schools in the districut &quot;PCTCHRT&quot;</span>
<span class="s3"># The percent of schools in the district operating year round &quot;PCTYRRND&quot;</span>
<span class="s3"># The following are interaction terms &quot;PERMINTE_AVYRSEXP&quot;,&quot;PERMINTE_AVSAL&quot;,</span>
<span class="s3"># &quot;AVYRSEXP_AVSAL&quot;,&quot;PERSPEN_PTRATIO&quot;,&quot;PERSPEN_PCTAF&quot;,&quot;PTRATIO_PCTAF&quot;,</span>
<span class="s3"># &quot;PERMINTE_AVYRSEXP_AVSAL&quot;,&quot;PERSPEN_PTRATIO_PCTAF&quot;</span>

<span class="s1">data = sm.datasets.star98.Load()</span>
<span class="s1">data.exog = sm.add_constant(data.exog)</span>

<span class="s1">print </span><span class="s4">&quot;&quot;&quot;The response variable is (success, failure).  Eg., the first  
observation is &quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">data.endog[</span><span class="s5">0</span><span class="s1">]</span>
<span class="s1">print</span><span class="s4">&quot;&quot;&quot;Giving a total number of trials for this observation of 
&quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">data.endog[</span><span class="s5">0</span><span class="s1">].sum()</span>

<span class="s1">glm_binom = sm.GLM(data.endog</span><span class="s2">, </span><span class="s1">data.exog</span><span class="s2">, </span><span class="s1">family=sm.family.Binomial())</span>

<span class="s3">### In order to fit this model, you must (for now) specify the number of </span>
<span class="s3">### trials per observation ie., success + failure</span>
<span class="s3">### This is the only time the data_weights argument should be used.</span>

<span class="s1">trials = data.endog.sum(axis=</span><span class="s5">1</span><span class="s1">)</span>
<span class="s1">binom_results = glm_binom.fit(data_weights=trials)</span>
<span class="s1">print </span><span class="s4">&quot;&quot;&quot;The fitted values are 
&quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">binom_results.params</span>
<span class="s1">print </span><span class="s4">&quot;&quot;&quot;The corresponding t-values are 
&quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">binom_results.t()</span>

<span class="s3"># It is common in GLMs with interactions to compare first differences.</span>
<span class="s3"># We are interested in the difference of the impact of the explanatory variable</span>
<span class="s3"># on the response variable.  This example uses interquartile differences for</span>
<span class="s3"># the percentage of low income households while holding the other values</span>
<span class="s3"># constant at their mean.</span>


<span class="s1">means = data.exog.mean(axis=</span><span class="s5">0</span><span class="s1">)</span>
<span class="s1">means25 = means.copy()</span>
<span class="s1">means25[</span><span class="s5">0</span><span class="s1">] = stats.scoreatpercentile(data.exog[:</span><span class="s2">,</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">25</span><span class="s1">)</span>
<span class="s1">means75 = means.copy()</span>
<span class="s1">means75[</span><span class="s5">0</span><span class="s1">] = lowinc_75per = stats.scoreatpercentile(data.exog[:</span><span class="s2">,</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">75</span><span class="s1">)</span>
<span class="s1">resp_25 = glm_binom.family.fitted(np.inner(means25</span><span class="s2">, </span><span class="s1">binom_results.params)) </span>
<span class="s1">resp_75 = glm_binom.family.fitted(np.inner(means75</span><span class="s2">, </span><span class="s1">binom_results.params)) </span>
<span class="s1">diff = resp_75 - resp_25</span>
<span class="s1">print </span><span class="s4">&quot;&quot;&quot;The interquartile first difference for the percentage of low income 
households in a school district is %2.4f %%&quot;&quot;&quot; </span><span class="s1">% (diff*</span><span class="s5">100</span><span class="s1">)</span>

<span class="s1">means0 = means.copy()</span>
<span class="s1">means100 = means.copy()</span>
<span class="s1">means0[</span><span class="s5">0</span><span class="s1">] = data.exog[:</span><span class="s2">,</span><span class="s5">0</span><span class="s1">].min()</span>
<span class="s1">means100[</span><span class="s5">0</span><span class="s1">] = data.exog[:</span><span class="s2">,</span><span class="s5">0</span><span class="s1">].max()</span>
<span class="s1">resp_0 = glm_binom.family.fitted(np.inner(means0</span><span class="s2">, </span><span class="s1">binom_results.params)) </span>
<span class="s1">resp_100 = glm_binom.family.fitted(np.inner(means100</span><span class="s2">, </span><span class="s1">binom_results.params)) </span>
<span class="s1">diff_full = resp_100 - resp_0</span>
<span class="s1">print </span><span class="s4">&quot;&quot;&quot;The full range difference is %2.4f %%&quot;&quot;&quot; </span><span class="s1">% (diff_full*</span><span class="s5">100</span><span class="s1">)</span>

<span class="s1">nobs = binom_results.nobs</span>
<span class="s1">y = data.endog[:</span><span class="s2">,</span><span class="s5">0</span><span class="s1">]/trials</span>
<span class="s1">yhat = binom_results.mu</span>

<span class="s3"># Plot of yhat vs y</span>
<span class="s1">plt.figure()</span>
<span class="s1">plt.scatter(yhat</span><span class="s2">, </span><span class="s1">y)</span>
<span class="s1">line_fit = sm.OLS(y</span><span class="s2">, </span><span class="s1">sm.add_constant(yhat)).fit().params</span>
<span class="s1">fit = </span><span class="s2">lambda </span><span class="s1">x: line_fit[</span><span class="s5">1</span><span class="s1">]+line_fit[</span><span class="s5">0</span><span class="s1">]*x </span><span class="s3"># better way in scipy?</span>
<span class="s1">plt.plot(np.linspace(</span><span class="s5">0</span><span class="s2">,</span><span class="s5">1</span><span class="s2">,</span><span class="s1">nobs)</span><span class="s2">, </span><span class="s1">fit(np.linspace(</span><span class="s5">0</span><span class="s2">,</span><span class="s5">1</span><span class="s2">,</span><span class="s1">nobs)))</span>
<span class="s1">plt.title(</span><span class="s4">'Model Fit Plot'</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s4">'Observed values'</span><span class="s1">)</span>
<span class="s1">plt.xlabel(</span><span class="s4">'Fitted values'</span><span class="s1">)</span>

<span class="s3"># Plot of yhat vs. Pearson residuals</span>
<span class="s1">plt.figure()</span>
<span class="s1">plt.scatter(yhat</span><span class="s2">, </span><span class="s1">binom_results.resid_pearson)</span>
<span class="s1">plt.plot([</span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">[</span><span class="s5">0.0</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">'k-'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s4">'Residual Dependence Plot'</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s4">'Pearson Residuals'</span><span class="s1">)</span>
<span class="s1">plt.xlabel(</span><span class="s4">'Fitted values'</span><span class="s1">)</span>

<span class="s3"># Histogram of standardized deviance residuals</span>
<span class="s1">plt.figure()</span>
<span class="s1">res = binom_results.resid_deviance.copy()</span>
<span class="s1">stdres = (res - res.mean())/res.std()</span>
<span class="s1">plt.hist(stdres</span><span class="s2">, </span><span class="s1">bins=</span><span class="s5">25</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s4">'Histogram of standardized deviance residuals'</span><span class="s1">)</span>

<span class="s3"># QQ Plot of Deviance Residuals</span>
<span class="s1">plt.figure()</span>
<span class="s1">res.sort()</span>
<span class="s1">p = np.linspace(</span><span class="s5">0 </span><span class="s1">+ </span><span class="s5">1.</span><span class="s1">/(nobs-</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">-</span><span class="s5">1.</span><span class="s1">/(nobs-</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">nobs)</span>
<span class="s1">quants = np.zeros_like(res)</span>
<span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(nobs):</span>
    <span class="s1">quants[i] = stats.scoreatpercentile(res</span><span class="s2">, </span><span class="s1">p[i]*</span><span class="s5">100</span><span class="s1">)</span>
<span class="s1">mu = res.mean()</span>
<span class="s1">sigma = res.std()</span>
<span class="s1">y = stats.norm.ppf(p</span><span class="s2">, </span><span class="s1">loc=mu</span><span class="s2">, </span><span class="s1">scale=sigma)</span>
<span class="s1">plt.scatter(y</span><span class="s2">, </span><span class="s1">quants)</span>
<span class="s1">plt.plot([y.min()</span><span class="s2">,</span><span class="s1">y.max()]</span><span class="s2">,</span><span class="s1">[y.min()</span><span class="s2">,</span><span class="s1">y.max()]</span><span class="s2">,</span><span class="s4">'r--'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s4">'Normal - Quantile Plot'</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s4">'Deviance Residuals Quantiles'</span><span class="s1">)</span>
<span class="s1">plt.xlabel(</span><span class="s4">'Quantiles of N(0,1)'</span><span class="s1">)</span>
<span class="s3"># in branch *-skipper</span>
<span class="s3">#from scikits.statsmodels.sandbox import graphics</span>
<span class="s3">#img = graphics.qqplot(res)</span>

<span class="s3">#plt.show()</span>
<span class="s3">#plt.close('all')</span>


<span class="s3">### Example for using GLM Gamma for a proportional count response</span>
<span class="s3"># Brief description of the data and design</span>
<span class="s3"># print sm.datasets.scotland.DESCRLONG</span>
<span class="s1">data2 = sm.datasets.scotland.Load()</span>
<span class="s1">data2.exog = sm.add_constant(data2.exog)</span>
<span class="s1">glm_gamma = sm.GLM(data2.endog</span><span class="s2">, </span><span class="s1">data2.exog</span><span class="s2">, </span><span class="s1">family=sm.family.Gamma())</span>
<span class="s1">glm_results = glm_gamma.fit()</span>

<span class="s3">### Example for Gaussian distribution with a noncanonical link</span>
<span class="s1">nobs2 = </span><span class="s5">100</span>
<span class="s1">x = np.arange(nobs2)</span>
<span class="s1">np.random.seed(</span><span class="s5">54321</span><span class="s1">)</span>
<span class="s1">X = np.column_stack((x</span><span class="s2">,</span><span class="s1">x**</span><span class="s5">2</span><span class="s1">))</span>
<span class="s1">X = sm.add_constant(X)</span>
<span class="s1">lny = np.exp(-(</span><span class="s5">.03</span><span class="s1">*x + </span><span class="s5">.0001</span><span class="s1">*x**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">1.0</span><span class="s1">)) + </span><span class="s5">.001 </span><span class="s1">* np.random.rand(nobs2)</span>
<span class="s1">gauss_log = sm.GLM(lny</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">family=sm.family.Gaussian(sm.family.links.log))</span>
<span class="s1">gauss_log_results = gauss_log.fit()</span>
</pre>
</body>
</html>
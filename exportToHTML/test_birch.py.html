<html>
<head>
<title>test_birch.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_birch.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for the birch clustering algorithm. 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">sparse</span>

<span class="s2">from </span><span class="s1">sklearn.cluster </span><span class="s2">import </span><span class="s1">AgglomerativeClustering</span><span class="s2">, </span><span class="s1">Birch</span>
<span class="s2">from </span><span class="s1">sklearn.cluster.tests.common </span><span class="s2">import </span><span class="s1">generate_clustered_data</span>
<span class="s2">from </span><span class="s1">sklearn.datasets </span><span class="s2">import </span><span class="s1">make_blobs</span>
<span class="s2">from </span><span class="s1">sklearn.exceptions </span><span class="s2">import </span><span class="s1">ConvergenceWarning</span>
<span class="s2">from </span><span class="s1">sklearn.metrics </span><span class="s2">import </span><span class="s1">pairwise_distances_argmin</span><span class="s2">, </span><span class="s1">v_measure_score</span>
<span class="s2">from </span><span class="s1">sklearn.utils._testing </span><span class="s2">import </span><span class="s1">assert_allclose</span><span class="s2">, </span><span class="s1">assert_array_equal</span>


<span class="s2">def </span><span class="s1">test_n_samples_leaves_roots(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Sanity check for the number of samples in leaves and roots</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">brc = Birch()</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">n_samples_root = sum([sc.n_samples_ </span><span class="s2">for </span><span class="s1">sc </span><span class="s2">in </span><span class="s1">brc.root_.subclusters_])</span>
    <span class="s1">n_samples_leaves = sum(</span>
        <span class="s1">[sc.n_samples_ </span><span class="s2">for </span><span class="s1">leaf </span><span class="s2">in </span><span class="s1">brc._get_leaves() </span><span class="s2">for </span><span class="s1">sc </span><span class="s2">in </span><span class="s1">leaf.subclusters_]</span>
    <span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">n_samples_leaves == X.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s2">assert </span><span class="s1">n_samples_root == X.shape[</span><span class="s4">0</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">test_partial_fit(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test that fit is equivalent to calling partial_fit multiple times</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">brc_partial = Birch(n_clusters=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">brc_partial.partial_fit(X[:</span><span class="s4">50</span><span class="s1">])</span>
    <span class="s1">brc_partial.partial_fit(X[</span><span class="s4">50</span><span class="s1">:])</span>
    <span class="s1">assert_allclose(brc_partial.subcluster_centers_</span><span class="s2">, </span><span class="s1">brc.subcluster_centers_)</span>

    <span class="s3"># Test that same global labels are obtained after calling partial_fit</span>
    <span class="s3"># with None</span>
    <span class="s1">brc_partial.set_params(n_clusters=</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">brc_partial.partial_fit(</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">assert_array_equal(brc_partial.subcluster_labels_</span><span class="s2">, </span><span class="s1">brc.subcluster_labels_)</span>


<span class="s2">def </span><span class="s1">test_birch_predict(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test the predict method predicts the nearest centroid.</span>
    <span class="s1">rng = np.random.RandomState(global_random_seed)</span>
    <span class="s1">X = generate_clustered_data(n_clusters=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">n_features=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">n_samples_per_cluster=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s3"># n_samples * n_samples_per_cluster</span>
    <span class="s1">shuffle_indices = np.arange(</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">rng.shuffle(shuffle_indices)</span>
    <span class="s1">X_shuffle = X[shuffle_indices</span><span class="s2">, </span><span class="s1">:]</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s4">1.0</span><span class="s1">)</span>
    <span class="s1">brc.fit(X_shuffle)</span>

    <span class="s3"># Birch must preserve inputs' dtype</span>
    <span class="s2">assert </span><span class="s1">brc.subcluster_centers_.dtype == global_dtype</span>

    <span class="s1">assert_array_equal(brc.labels_</span><span class="s2">, </span><span class="s1">brc.predict(X_shuffle))</span>
    <span class="s1">centroids = brc.subcluster_centers_</span>
    <span class="s1">nearest_centroid = brc.subcluster_labels_[</span>
        <span class="s1">pairwise_distances_argmin(X_shuffle</span><span class="s2">, </span><span class="s1">centroids)</span>
    <span class="s1">]</span>
    <span class="s1">assert_allclose(v_measure_score(nearest_centroid</span><span class="s2">, </span><span class="s1">brc.labels_)</span><span class="s2">, </span><span class="s4">1.0</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_n_clusters(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test that n_clusters param works properly</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">centers=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">brc1 = Birch(n_clusters=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">brc1.fit(X)</span>
    <span class="s2">assert </span><span class="s1">len(brc1.subcluster_centers_) &gt; </span><span class="s4">10</span>
    <span class="s2">assert </span><span class="s1">len(np.unique(brc1.labels_)) == </span><span class="s4">10</span>

    <span class="s3"># Test that n_clusters = Agglomerative Clustering gives</span>
    <span class="s3"># the same results.</span>
    <span class="s1">gc = AgglomerativeClustering(n_clusters=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">brc2 = Birch(n_clusters=gc)</span>
    <span class="s1">brc2.fit(X)</span>
    <span class="s1">assert_array_equal(brc1.subcluster_labels_</span><span class="s2">, </span><span class="s1">brc2.subcluster_labels_)</span>
    <span class="s1">assert_array_equal(brc1.labels_</span><span class="s2">, </span><span class="s1">brc2.labels_)</span>

    <span class="s3"># Test that a small number of clusters raises a warning.</span>
    <span class="s1">brc4 = Birch(threshold=</span><span class="s4">10000.0</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.warns(ConvergenceWarning):</span>
        <span class="s1">brc4.fit(X)</span>


<span class="s2">def </span><span class="s1">test_sparse_X(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test that sparse and dense data give same results</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">centers=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>

    <span class="s1">csr = sparse.csr_matrix(X)</span>
    <span class="s1">brc_sparse = Birch(n_clusters=</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">brc_sparse.fit(csr)</span>

    <span class="s3"># Birch must preserve inputs' dtype</span>
    <span class="s2">assert </span><span class="s1">brc_sparse.subcluster_centers_.dtype == global_dtype</span>

    <span class="s1">assert_array_equal(brc.labels_</span><span class="s2">, </span><span class="s1">brc_sparse.labels_)</span>
    <span class="s1">assert_allclose(brc.subcluster_centers_</span><span class="s2">, </span><span class="s1">brc_sparse.subcluster_centers_)</span>


<span class="s2">def </span><span class="s1">test_partial_fit_second_call_error_checks():</span>
    <span class="s3"># second partial fit calls will error when n_features is not consistent</span>
    <span class="s3"># with the first call</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">3</span><span class="s1">)</span>
    <span class="s1">brc.partial_fit(X</span><span class="s2">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s5">&quot;X has 1 features, but Birch is expecting 2 features&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
        <span class="s1">brc.partial_fit(X[:</span><span class="s2">, </span><span class="s1">[</span><span class="s4">0</span><span class="s1">]]</span><span class="s2">, </span><span class="s1">y)</span>


<span class="s2">def </span><span class="s1">check_branching_factor(node</span><span class="s2">, </span><span class="s1">branching_factor):</span>
    <span class="s1">subclusters = node.subclusters_</span>
    <span class="s2">assert </span><span class="s1">branching_factor &gt;= len(subclusters)</span>
    <span class="s2">for </span><span class="s1">cluster </span><span class="s2">in </span><span class="s1">subclusters:</span>
        <span class="s2">if </span><span class="s1">cluster.child_:</span>
            <span class="s1">check_branching_factor(cluster.child_</span><span class="s2">, </span><span class="s1">branching_factor)</span>


<span class="s2">def </span><span class="s1">test_branching_factor(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test that nodes have at max branching_factor number of subclusters</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">branching_factor = </span><span class="s4">9</span>

    <span class="s3"># Purposefully set a low threshold to maximize the subclusters.</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s2">None, </span><span class="s1">branching_factor=branching_factor</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s4">0.01</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">check_branching_factor(brc.root_</span><span class="s2">, </span><span class="s1">branching_factor)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">branching_factor=branching_factor</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s4">0.01</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">check_branching_factor(brc.root_</span><span class="s2">, </span><span class="s1">branching_factor)</span>


<span class="s2">def </span><span class="s1">check_threshold(birch_instance</span><span class="s2">, </span><span class="s1">threshold):</span>
    <span class="s0">&quot;&quot;&quot;Use the leaf linked list for traversal&quot;&quot;&quot;</span>
    <span class="s1">current_leaf = birch_instance.dummy_leaf_.next_leaf_</span>
    <span class="s2">while </span><span class="s1">current_leaf:</span>
        <span class="s1">subclusters = current_leaf.subclusters_</span>
        <span class="s2">for </span><span class="s1">sc </span><span class="s2">in </span><span class="s1">subclusters:</span>
            <span class="s2">assert </span><span class="s1">threshold &gt;= sc.radius</span>
        <span class="s1">current_leaf = current_leaf.next_leaf_</span>


<span class="s2">def </span><span class="s1">test_threshold(global_random_seed</span><span class="s2">, </span><span class="s1">global_dtype):</span>
    <span class="s3"># Test that the leaf subclusters have a threshold lesser than radius</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y = make_blobs(n_samples=</span><span class="s4">80</span><span class="s2">, </span><span class="s1">centers=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">X = X.astype(global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">brc = Birch(threshold=</span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">n_clusters=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">check_threshold(brc</span><span class="s2">, </span><span class="s4">0.5</span><span class="s1">)</span>

    <span class="s1">brc = Birch(threshold=</span><span class="s4">5.0</span><span class="s2">, </span><span class="s1">n_clusters=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">check_threshold(brc</span><span class="s2">, </span><span class="s4">5.0</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_birch_n_clusters_long_int():</span>
    <span class="s3"># Check that birch supports n_clusters with np.int64 dtype, for instance</span>
    <span class="s3"># coming from np.arange. #16484</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">_ = make_blobs(random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">n_clusters = np.int64(</span><span class="s4">5</span><span class="s1">)</span>
    <span class="s1">Birch(n_clusters=n_clusters).fit(X)</span>


<span class="s2">def </span><span class="s1">test_feature_names_out():</span>
    <span class="s0">&quot;&quot;&quot;Check `get_feature_names_out` for `Birch`.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">_ = make_blobs(n_samples=</span><span class="s4">80</span><span class="s2">, </span><span class="s1">n_features=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">4</span><span class="s1">)</span>
    <span class="s1">brc.fit(X)</span>
    <span class="s1">n_clusters = brc.subcluster_centers_.shape[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">names_out = brc.get_feature_names_out()</span>
    <span class="s1">assert_array_equal([</span><span class="s5">f&quot;birch</span><span class="s2">{</span><span class="s1">i</span><span class="s2">}</span><span class="s5">&quot; </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(n_clusters)]</span><span class="s2">, </span><span class="s1">names_out)</span>


<span class="s2">def </span><span class="s1">test_transform_match_across_dtypes(global_random_seed):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">_ = make_blobs(n_samples=</span><span class="s4">80</span><span class="s2">, </span><span class="s1">n_features=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">random_state=global_random_seed)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s4">1.1</span><span class="s1">)</span>
    <span class="s1">Y_64 = brc.fit_transform(X)</span>
    <span class="s1">Y_32 = brc.fit_transform(X.astype(np.float32))</span>

    <span class="s1">assert_allclose(Y_64</span><span class="s2">, </span><span class="s1">Y_32</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_subcluster_dtype(global_dtype):</span>
    <span class="s1">X = make_blobs(n_samples=</span><span class="s4">80</span><span class="s2">, </span><span class="s1">n_features=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">].astype(</span>
        <span class="s1">global_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span>
    <span class="s1">)</span>
    <span class="s1">brc = Birch(n_clusters=</span><span class="s4">4</span><span class="s1">)</span>
    <span class="s2">assert </span><span class="s1">brc.fit(X).subcluster_centers_.dtype == global_dtype</span>


<span class="s2">def </span><span class="s1">test_both_subclusters_updated():</span>
    <span class="s0">&quot;&quot;&quot;Check that both subclusters are updated when a node a split, even when there are 
    duplicated data points. Non-regression test for #23269. 
    &quot;&quot;&quot;</span>

    <span class="s1">X = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[-</span><span class="s4">2.6192791</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.5053215</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.9993038</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.6863596</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.336792</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3417323</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.4089134</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3290224</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">3.364009</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.8846745</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.617677</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.5003285</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.2960556</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3260119</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.5459878</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.4533926</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.25979</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3003055</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.4089134</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3290224</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.4089134</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3290224</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.5459878</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.4533926</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.9720619</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.7058647</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.336792</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3417323</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s4">2.3724914</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1.3438171</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span><span class="s2">,</span>
        <span class="s1">dtype=np.float32</span><span class="s2">,</span>
    <span class="s1">)</span>

    <span class="s3"># no error</span>
    <span class="s1">Birch(branching_factor=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s4">1e-5</span><span class="s2">, </span><span class="s1">n_clusters=</span><span class="s2">None</span><span class="s1">).fit(X)</span>
</pre>
</body>
</html>
<html>
<head>
<title>from_dataframe.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
from_dataframe.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>

<span class="s0">import </span><span class="s1">ctypes</span>
<span class="s0">import </span><span class="s1">re</span>
<span class="s0">from </span><span class="s1">typing </span><span class="s0">import </span><span class="s1">Any</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">from </span><span class="s1">pandas.compat._optional </span><span class="s0">import </span><span class="s1">import_optional_dependency</span>
<span class="s0">from </span><span class="s1">pandas.errors </span><span class="s0">import </span><span class="s1">SettingWithCopyError</span>

<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>
<span class="s0">from </span><span class="s1">pandas.core.interchange.dataframe_protocol </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">Buffer</span><span class="s0">,</span>
    <span class="s1">Column</span><span class="s0">,</span>
    <span class="s1">ColumnNullType</span><span class="s0">,</span>
    <span class="s1">DataFrame </span><span class="s0">as </span><span class="s1">DataFrameXchg</span><span class="s0">,</span>
    <span class="s1">DtypeKind</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">pandas.core.interchange.utils </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">ArrowCTypes</span><span class="s0">,</span>
    <span class="s1">Endianness</span><span class="s0">,</span>
<span class="s1">)</span>

<span class="s1">_NP_DTYPES: dict[DtypeKind</span><span class="s0">, </span><span class="s1">dict[int</span><span class="s0">, </span><span class="s1">Any]] = {</span>
    <span class="s1">DtypeKind.INT: {</span><span class="s2">8</span><span class="s1">: np.int8</span><span class="s0">, </span><span class="s2">16</span><span class="s1">: np.int16</span><span class="s0">, </span><span class="s2">32</span><span class="s1">: np.int32</span><span class="s0">, </span><span class="s2">64</span><span class="s1">: np.int64}</span><span class="s0">,</span>
    <span class="s1">DtypeKind.UINT: {</span><span class="s2">8</span><span class="s1">: np.uint8</span><span class="s0">, </span><span class="s2">16</span><span class="s1">: np.uint16</span><span class="s0">, </span><span class="s2">32</span><span class="s1">: np.uint32</span><span class="s0">, </span><span class="s2">64</span><span class="s1">: np.uint64}</span><span class="s0">,</span>
    <span class="s1">DtypeKind.FLOAT: {</span><span class="s2">32</span><span class="s1">: np.float32</span><span class="s0">, </span><span class="s2">64</span><span class="s1">: np.float64}</span><span class="s0">,</span>
    <span class="s1">DtypeKind.BOOL: {</span><span class="s2">1</span><span class="s1">: bool</span><span class="s0">, </span><span class="s2">8</span><span class="s1">: bool}</span><span class="s0">,</span>
<span class="s1">}</span>


<span class="s0">def </span><span class="s1">from_dataframe(df</span><span class="s0">, </span><span class="s1">allow_copy: bool = </span><span class="s0">True</span><span class="s1">) -&gt; pd.DataFrame:</span>
    <span class="s3">&quot;&quot;&quot; 
    Build a ``pd.DataFrame`` from any DataFrame supporting the interchange protocol. 
 
    Parameters 
    ---------- 
    df : DataFrameXchg 
        Object supporting the interchange protocol, i.e. `__dataframe__` method. 
    allow_copy : bool, default: True 
        Whether to allow copying the memory to perform the conversion 
        (if false then zero-copy approach is requested). 
 
    Returns 
    ------- 
    pd.DataFrame 
 
    Examples 
    -------- 
    &gt;&gt;&gt; df_not_necessarily_pandas = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}) 
    &gt;&gt;&gt; interchange_object = df_not_necessarily_pandas.__dataframe__() 
    &gt;&gt;&gt; interchange_object.column_names() 
    Index(['A', 'B'], dtype='object') 
    &gt;&gt;&gt; df_pandas = (pd.api.interchange.from_dataframe 
    ...              (interchange_object.select_columns_by_name(['A']))) 
    &gt;&gt;&gt; df_pandas 
         A 
    0    1 
    1    2 
 
    These methods (``column_names``, ``select_columns_by_name``) should work 
    for any dataframe library which implements the interchange protocol. 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">isinstance(df</span><span class="s0">, </span><span class="s1">pd.DataFrame):</span>
        <span class="s0">return </span><span class="s1">df</span>

    <span class="s0">if not </span><span class="s1">hasattr(df</span><span class="s0">, </span><span class="s4">&quot;__dataframe__&quot;</span><span class="s1">):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;`df` does not support __dataframe__&quot;</span><span class="s1">)</span>

    <span class="s0">return </span><span class="s1">_from_dataframe(</span>
        <span class="s1">df.__dataframe__(allow_copy=allow_copy)</span><span class="s0">, </span><span class="s1">allow_copy=allow_copy</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">_from_dataframe(df: DataFrameXchg</span><span class="s0">, </span><span class="s1">allow_copy: bool = </span><span class="s0">True</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Build a ``pd.DataFrame`` from the DataFrame interchange object. 
 
    Parameters 
    ---------- 
    df : DataFrameXchg 
        Object supporting the interchange protocol, i.e. `__dataframe__` method. 
    allow_copy : bool, default: True 
        Whether to allow copying the memory to perform the conversion 
        (if false then zero-copy approach is requested). 
 
    Returns 
    ------- 
    pd.DataFrame 
    &quot;&quot;&quot;</span>
    <span class="s1">pandas_dfs = []</span>
    <span class="s0">for </span><span class="s1">chunk </span><span class="s0">in </span><span class="s1">df.get_chunks():</span>
        <span class="s1">pandas_df = protocol_df_chunk_to_pandas(chunk)</span>
        <span class="s1">pandas_dfs.append(pandas_df)</span>

    <span class="s0">if not </span><span class="s1">allow_copy </span><span class="s0">and </span><span class="s1">len(pandas_dfs) &gt; </span><span class="s2">1</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">RuntimeError(</span>
            <span class="s4">&quot;To join chunks a copy is required which is forbidden by allow_copy=False&quot;</span>
        <span class="s1">)</span>
    <span class="s0">if not </span><span class="s1">pandas_dfs:</span>
        <span class="s1">pandas_df = protocol_df_chunk_to_pandas(df)</span>
    <span class="s0">elif </span><span class="s1">len(pandas_dfs) == </span><span class="s2">1</span><span class="s1">:</span>
        <span class="s1">pandas_df = pandas_dfs[</span><span class="s2">0</span><span class="s1">]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">pandas_df = pd.concat(pandas_dfs</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">ignore_index=</span><span class="s0">True, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s1">index_obj = df.metadata.get(</span><span class="s4">&quot;pandas.index&quot;</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">index_obj </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">pandas_df.index = index_obj</span>

    <span class="s0">return </span><span class="s1">pandas_df</span>


<span class="s0">def </span><span class="s1">protocol_df_chunk_to_pandas(df: DataFrameXchg) -&gt; pd.DataFrame:</span>
    <span class="s3">&quot;&quot;&quot; 
    Convert interchange protocol chunk to ``pd.DataFrame``. 
 
    Parameters 
    ---------- 
    df : DataFrameXchg 
 
    Returns 
    ------- 
    pd.DataFrame 
    &quot;&quot;&quot;</span>
    <span class="s5"># We need a dict of columns here, with each column being a NumPy array (at</span>
    <span class="s5"># least for now, deal with non-NumPy dtypes later).</span>
    <span class="s1">columns: dict[str</span><span class="s0">, </span><span class="s1">Any] = {}</span>
    <span class="s1">buffers = []  </span><span class="s5"># hold on to buffers, keeps memory alive</span>
    <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">df.column_names():</span>
        <span class="s0">if not </span><span class="s1">isinstance(name</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;Column </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s4">is not a string&quot;</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s0">in </span><span class="s1">columns:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;Column </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s4">is not unique&quot;</span><span class="s1">)</span>
        <span class="s1">col = df.get_column_by_name(name)</span>
        <span class="s1">dtype = col.dtype[</span><span class="s2">0</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s1">dtype </span><span class="s0">in </span><span class="s1">(</span>
            <span class="s1">DtypeKind.INT</span><span class="s0">,</span>
            <span class="s1">DtypeKind.UINT</span><span class="s0">,</span>
            <span class="s1">DtypeKind.FLOAT</span><span class="s0">,</span>
            <span class="s1">DtypeKind.BOOL</span><span class="s0">,</span>
        <span class="s1">):</span>
            <span class="s1">columns[name]</span><span class="s0">, </span><span class="s1">buf = primitive_column_to_ndarray(col)</span>
        <span class="s0">elif </span><span class="s1">dtype == DtypeKind.CATEGORICAL:</span>
            <span class="s1">columns[name]</span><span class="s0">, </span><span class="s1">buf = categorical_column_to_series(col)</span>
        <span class="s0">elif </span><span class="s1">dtype == DtypeKind.STRING:</span>
            <span class="s1">columns[name]</span><span class="s0">, </span><span class="s1">buf = string_column_to_ndarray(col)</span>
        <span class="s0">elif </span><span class="s1">dtype == DtypeKind.DATETIME:</span>
            <span class="s1">columns[name]</span><span class="s0">, </span><span class="s1">buf = datetime_column_to_ndarray(col)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">f&quot;Data type </span><span class="s0">{</span><span class="s1">dtype</span><span class="s0">} </span><span class="s4">not handled yet&quot;</span><span class="s1">)</span>

        <span class="s1">buffers.append(buf)</span>

    <span class="s1">pandas_df = pd.DataFrame(columns)</span>
    <span class="s1">pandas_df.attrs[</span><span class="s4">&quot;_INTERCHANGE_PROTOCOL_BUFFERS&quot;</span><span class="s1">] = buffers</span>
    <span class="s0">return </span><span class="s1">pandas_df</span>


<span class="s0">def </span><span class="s1">primitive_column_to_ndarray(col: Column) -&gt; tuple[np.ndarray</span><span class="s0">, </span><span class="s1">Any]:</span>
    <span class="s3">&quot;&quot;&quot; 
    Convert a column holding one of the primitive dtypes to a NumPy array. 
 
    A primitive type is one of: int, uint, float, bool. 
 
    Parameters 
    ---------- 
    col : Column 
 
    Returns 
    ------- 
    tuple 
        Tuple of np.ndarray holding the data and the memory owner object 
        that keeps the memory alive. 
    &quot;&quot;&quot;</span>
    <span class="s1">buffers = col.get_buffers()</span>

    <span class="s1">data_buff</span><span class="s0">, </span><span class="s1">data_dtype = buffers[</span><span class="s4">&quot;data&quot;</span><span class="s1">]</span>
    <span class="s1">data = buffer_to_ndarray(</span>
        <span class="s1">data_buff</span><span class="s0">, </span><span class="s1">data_dtype</span><span class="s0">, </span><span class="s1">offset=col.offset</span><span class="s0">, </span><span class="s1">length=col.size()</span>
    <span class="s1">)</span>

    <span class="s1">data = set_nulls(data</span><span class="s0">, </span><span class="s1">col</span><span class="s0">, </span><span class="s1">buffers[</span><span class="s4">&quot;validity&quot;</span><span class="s1">])</span>
    <span class="s0">return </span><span class="s1">data</span><span class="s0">, </span><span class="s1">buffers</span>


<span class="s0">def </span><span class="s1">categorical_column_to_series(col: Column) -&gt; tuple[pd.Series</span><span class="s0">, </span><span class="s1">Any]:</span>
    <span class="s3">&quot;&quot;&quot; 
    Convert a column holding categorical data to a pandas Series. 
 
    Parameters 
    ---------- 
    col : Column 
 
    Returns 
    ------- 
    tuple 
        Tuple of pd.Series holding the data and the memory owner object 
        that keeps the memory alive. 
    &quot;&quot;&quot;</span>
    <span class="s1">categorical = col.describe_categorical</span>

    <span class="s0">if not </span><span class="s1">categorical[</span><span class="s4">&quot;is_dictionary&quot;</span><span class="s1">]:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">&quot;Non-dictionary categoricals not supported yet&quot;</span><span class="s1">)</span>

    <span class="s1">cat_column = categorical[</span><span class="s4">&quot;categories&quot;</span><span class="s1">]</span>
    <span class="s0">if </span><span class="s1">hasattr(cat_column</span><span class="s0">, </span><span class="s4">&quot;_col&quot;</span><span class="s1">):</span>
        <span class="s5"># Item &quot;Column&quot; of &quot;Optional[Column]&quot; has no attribute &quot;_col&quot;</span>
        <span class="s5"># Item &quot;None&quot; of &quot;Optional[Column]&quot; has no attribute &quot;_col&quot;</span>
        <span class="s1">categories = np.array(cat_column._col)  </span><span class="s5"># type: ignore[union-attr]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s4">&quot;Interchanging categorical columns isn't supported yet, and our &quot;</span>
            <span class="s4">&quot;fallback of using the `col._col` attribute (a ndarray) failed.&quot;</span>
        <span class="s1">)</span>
    <span class="s1">buffers = col.get_buffers()</span>

    <span class="s1">codes_buff</span><span class="s0">, </span><span class="s1">codes_dtype = buffers[</span><span class="s4">&quot;data&quot;</span><span class="s1">]</span>
    <span class="s1">codes = buffer_to_ndarray(</span>
        <span class="s1">codes_buff</span><span class="s0">, </span><span class="s1">codes_dtype</span><span class="s0">, </span><span class="s1">offset=col.offset</span><span class="s0">, </span><span class="s1">length=col.size()</span>
    <span class="s1">)</span>

    <span class="s5"># Doing module in order to not get ``IndexError`` for</span>
    <span class="s5"># out-of-bounds sentinel values in `codes`</span>
    <span class="s0">if </span><span class="s1">len(categories) &gt; </span><span class="s2">0</span><span class="s1">:</span>
        <span class="s1">values = categories[codes % len(categories)]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">values = codes</span>

    <span class="s1">cat = pd.Categorical(</span>
        <span class="s1">values</span><span class="s0">, </span><span class="s1">categories=categories</span><span class="s0">, </span><span class="s1">ordered=categorical[</span><span class="s4">&quot;is_ordered&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">data = pd.Series(cat)</span>

    <span class="s1">data = set_nulls(data</span><span class="s0">, </span><span class="s1">col</span><span class="s0">, </span><span class="s1">buffers[</span><span class="s4">&quot;validity&quot;</span><span class="s1">])</span>
    <span class="s0">return </span><span class="s1">data</span><span class="s0">, </span><span class="s1">buffers</span>


<span class="s0">def </span><span class="s1">string_column_to_ndarray(col: Column) -&gt; tuple[np.ndarray</span><span class="s0">, </span><span class="s1">Any]:</span>
    <span class="s3">&quot;&quot;&quot; 
    Convert a column holding string data to a NumPy array. 
 
    Parameters 
    ---------- 
    col : Column 
 
    Returns 
    ------- 
    tuple 
        Tuple of np.ndarray holding the data and the memory owner object 
        that keeps the memory alive. 
    &quot;&quot;&quot;</span>
    <span class="s1">null_kind</span><span class="s0">, </span><span class="s1">sentinel_val = col.describe_null</span>

    <span class="s0">if </span><span class="s1">null_kind </span><span class="s0">not in </span><span class="s1">(</span>
        <span class="s1">ColumnNullType.NON_NULLABLE</span><span class="s0">,</span>
        <span class="s1">ColumnNullType.USE_BITMASK</span><span class="s0">,</span>
        <span class="s1">ColumnNullType.USE_BYTEMASK</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">null_kind</span><span class="s0">} </span><span class="s4">null kind is not yet supported for string columns.&quot;</span>
        <span class="s1">)</span>

    <span class="s1">buffers = col.get_buffers()</span>

    <span class="s0">assert </span><span class="s1">buffers[</span><span class="s4">&quot;offsets&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;String buffers must contain offsets&quot;</span>
    <span class="s5"># Retrieve the data buffer containing the UTF-8 code units</span>
    <span class="s1">data_buff</span><span class="s0">, </span><span class="s1">protocol_data_dtype = buffers[</span><span class="s4">&quot;data&quot;</span><span class="s1">]</span>
    <span class="s5"># We're going to reinterpret the buffer as uint8, so make sure we can do it safely</span>
    <span class="s0">assert </span><span class="s1">protocol_data_dtype[</span><span class="s2">1</span><span class="s1">] == </span><span class="s2">8</span>
    <span class="s0">assert </span><span class="s1">protocol_data_dtype[</span><span class="s2">2</span><span class="s1">] </span><span class="s0">in </span><span class="s1">(</span>
        <span class="s1">ArrowCTypes.STRING</span><span class="s0">,</span>
        <span class="s1">ArrowCTypes.LARGE_STRING</span><span class="s0">,</span>
    <span class="s1">)  </span><span class="s5"># format_str == utf-8</span>
    <span class="s5"># Convert the buffers to NumPy arrays. In order to go from STRING to</span>
    <span class="s5"># an equivalent ndarray, we claim that the buffer is uint8 (i.e., a byte array)</span>
    <span class="s1">data_dtype = (</span>
        <span class="s1">DtypeKind.UINT</span><span class="s0">,</span>
        <span class="s2">8</span><span class="s0">,</span>
        <span class="s1">ArrowCTypes.UINT8</span><span class="s0">,</span>
        <span class="s1">Endianness.NATIVE</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s5"># Specify zero offset as we don't want to chunk the string data</span>
    <span class="s1">data = buffer_to_ndarray(data_buff</span><span class="s0">, </span><span class="s1">data_dtype</span><span class="s0">, </span><span class="s1">offset=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">length=data_buff.bufsize)</span>

    <span class="s5"># Retrieve the offsets buffer containing the index offsets demarcating</span>
    <span class="s5"># the beginning and the ending of each string</span>
    <span class="s1">offset_buff</span><span class="s0">, </span><span class="s1">offset_dtype = buffers[</span><span class="s4">&quot;offsets&quot;</span><span class="s1">]</span>
    <span class="s5"># Offsets buffer contains start-stop positions of strings in the data buffer,</span>
    <span class="s5"># meaning that it has more elements than in the data buffer, do `col.size() + 1`</span>
    <span class="s5"># here to pass a proper offsets buffer size</span>
    <span class="s1">offsets = buffer_to_ndarray(</span>
        <span class="s1">offset_buff</span><span class="s0">, </span><span class="s1">offset_dtype</span><span class="s0">, </span><span class="s1">offset=col.offset</span><span class="s0">, </span><span class="s1">length=col.size() + </span><span class="s2">1</span>
    <span class="s1">)</span>

    <span class="s1">null_pos = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">null_kind </span><span class="s0">in </span><span class="s1">(ColumnNullType.USE_BITMASK</span><span class="s0">, </span><span class="s1">ColumnNullType.USE_BYTEMASK):</span>
        <span class="s0">assert </span><span class="s1">buffers[</span><span class="s4">&quot;validity&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;Validity buffers cannot be empty for masks&quot;</span>
        <span class="s1">valid_buff</span><span class="s0">, </span><span class="s1">valid_dtype = buffers[</span><span class="s4">&quot;validity&quot;</span><span class="s1">]</span>
        <span class="s1">null_pos = buffer_to_ndarray(</span>
            <span class="s1">valid_buff</span><span class="s0">, </span><span class="s1">valid_dtype</span><span class="s0">, </span><span class="s1">offset=col.offset</span><span class="s0">, </span><span class="s1">length=col.size()</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">sentinel_val == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">null_pos = ~null_pos</span>

    <span class="s5"># Assemble the strings from the code units</span>
    <span class="s1">str_list: list[</span><span class="s0">None </span><span class="s1">| float | str] = [</span><span class="s0">None</span><span class="s1">] * col.size()</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(col.size()):</span>
        <span class="s5"># Check for missing values</span>
        <span class="s0">if </span><span class="s1">null_pos </span><span class="s0">is not None and </span><span class="s1">null_pos[i]:</span>
            <span class="s1">str_list[i] = np.nan</span>
            <span class="s0">continue</span>

        <span class="s5"># Extract a range of code units</span>
        <span class="s1">units = data[offsets[i] : offsets[i + </span><span class="s2">1</span><span class="s1">]]</span>

        <span class="s5"># Convert the list of code units to bytes</span>
        <span class="s1">str_bytes = bytes(units)</span>

        <span class="s5"># Create the string</span>
        <span class="s1">string = str_bytes.decode(encoding=</span><span class="s4">&quot;utf-8&quot;</span><span class="s1">)</span>

        <span class="s5"># Add to our list of strings</span>
        <span class="s1">str_list[i] = string</span>

    <span class="s5"># Convert the string list to a NumPy array</span>
    <span class="s0">return </span><span class="s1">np.asarray(str_list</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s4">&quot;object&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s1">buffers</span>


<span class="s0">def </span><span class="s1">parse_datetime_format_str(format_str</span><span class="s0">, </span><span class="s1">data) -&gt; pd.Series | np.ndarray:</span>
    <span class="s3">&quot;&quot;&quot;Parse datetime `format_str` to interpret the `data`.&quot;&quot;&quot;</span>
    <span class="s5"># timestamp 'ts{unit}:tz'</span>
    <span class="s1">timestamp_meta = re.match(</span><span class="s4">r&quot;ts([smun]):(.*)&quot;</span><span class="s0">, </span><span class="s1">format_str)</span>
    <span class="s0">if </span><span class="s1">timestamp_meta:</span>
        <span class="s1">unit</span><span class="s0">, </span><span class="s1">tz = timestamp_meta.group(</span><span class="s2">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">timestamp_meta.group(</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">unit != </span><span class="s4">&quot;s&quot;</span><span class="s1">:</span>
            <span class="s5"># the format string describes only a first letter of the unit, so</span>
            <span class="s5"># add one extra letter to convert the unit to numpy-style:</span>
            <span class="s5"># 'm' -&gt; 'ms', 'u' -&gt; 'us', 'n' -&gt; 'ns'</span>
            <span class="s1">unit += </span><span class="s4">&quot;s&quot;</span>
        <span class="s1">data = data.astype(</span><span class="s4">f&quot;datetime64[</span><span class="s0">{</span><span class="s1">unit</span><span class="s0">}</span><span class="s4">]&quot;</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">tz != </span><span class="s4">&quot;&quot;</span><span class="s1">:</span>
            <span class="s1">data = pd.Series(data).dt.tz_localize(</span><span class="s4">&quot;UTC&quot;</span><span class="s1">).dt.tz_convert(tz)</span>
        <span class="s0">return </span><span class="s1">data</span>

    <span class="s5"># date 'td{Days/Ms}'</span>
    <span class="s1">date_meta = re.match(</span><span class="s4">r&quot;td([Dm])&quot;</span><span class="s0">, </span><span class="s1">format_str)</span>
    <span class="s0">if </span><span class="s1">date_meta:</span>
        <span class="s1">unit = date_meta.group(</span><span class="s2">1</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">unit == </span><span class="s4">&quot;D&quot;</span><span class="s1">:</span>
            <span class="s5"># NumPy doesn't support DAY unit, so converting days to seconds</span>
            <span class="s5"># (converting to uint64 to avoid overflow)</span>
            <span class="s1">data = (data.astype(np.uint64) * (</span><span class="s2">24 </span><span class="s1">* </span><span class="s2">60 </span><span class="s1">* </span><span class="s2">60</span><span class="s1">)).astype(</span><span class="s4">&quot;datetime64[s]&quot;</span><span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">unit == </span><span class="s4">&quot;m&quot;</span><span class="s1">:</span>
            <span class="s1">data = data.astype(</span><span class="s4">&quot;datetime64[ms]&quot;</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">f&quot;Date unit is not supported: </span><span class="s0">{</span><span class="s1">unit</span><span class="s0">}</span><span class="s4">&quot;</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">data</span>

    <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">f&quot;DateTime kind is not supported: </span><span class="s0">{</span><span class="s1">format_str</span><span class="s0">}</span><span class="s4">&quot;</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">datetime_column_to_ndarray(col: Column) -&gt; tuple[np.ndarray | pd.Series</span><span class="s0">, </span><span class="s1">Any]:</span>
    <span class="s3">&quot;&quot;&quot; 
    Convert a column holding DateTime data to a NumPy array. 
 
    Parameters 
    ---------- 
    col : Column 
 
    Returns 
    ------- 
    tuple 
        Tuple of np.ndarray holding the data and the memory owner object 
        that keeps the memory alive. 
    &quot;&quot;&quot;</span>
    <span class="s1">buffers = col.get_buffers()</span>

    <span class="s1">_</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">format_str</span><span class="s0">, </span><span class="s1">_ = col.dtype</span>
    <span class="s1">dbuf</span><span class="s0">, </span><span class="s1">dtype = buffers[</span><span class="s4">&quot;data&quot;</span><span class="s1">]</span>
    <span class="s5"># Consider dtype being `uint` to get number of units passed since the 01.01.1970</span>
    <span class="s1">data = buffer_to_ndarray(</span>
        <span class="s1">dbuf</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">DtypeKind.UINT</span><span class="s0">,</span>
            <span class="s1">dtype[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">getattr(ArrowCTypes</span><span class="s0">, </span><span class="s4">f&quot;UINT</span><span class="s0">{</span><span class="s1">dtype[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">}</span><span class="s4">&quot;</span><span class="s1">)</span><span class="s0">,</span>
            <span class="s1">Endianness.NATIVE</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">offset=col.offset</span><span class="s0">,</span>
        <span class="s1">length=col.size()</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">data = parse_datetime_format_str(format_str</span><span class="s0">, </span><span class="s1">data)  </span><span class="s5"># type: ignore[assignment]</span>
    <span class="s1">data = set_nulls(data</span><span class="s0">, </span><span class="s1">col</span><span class="s0">, </span><span class="s1">buffers[</span><span class="s4">&quot;validity&quot;</span><span class="s1">])</span>
    <span class="s0">return </span><span class="s1">data</span><span class="s0">, </span><span class="s1">buffers</span>


<span class="s0">def </span><span class="s1">buffer_to_ndarray(</span>
    <span class="s1">buffer: Buffer</span><span class="s0">,</span>
    <span class="s1">dtype: tuple[DtypeKind</span><span class="s0">, </span><span class="s1">int</span><span class="s0">, </span><span class="s1">str</span><span class="s0">, </span><span class="s1">str]</span><span class="s0">,</span>
    <span class="s1">*</span><span class="s0">,</span>
    <span class="s1">length: int</span><span class="s0">,</span>
    <span class="s1">offset: int = </span><span class="s2">0</span><span class="s0">,</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s3">&quot;&quot;&quot; 
    Build a NumPy array from the passed buffer. 
 
    Parameters 
    ---------- 
    buffer : Buffer 
        Buffer to build a NumPy array from. 
    dtype : tuple 
        Data type of the buffer conforming protocol dtypes format. 
    offset : int, default: 0 
        Number of elements to offset from the start of the buffer. 
    length : int, optional 
        If the buffer is a bit-mask, specifies a number of bits to read 
        from the buffer. Has no effect otherwise. 
 
    Returns 
    ------- 
    np.ndarray 
 
    Notes 
    ----- 
    The returned array doesn't own the memory. The caller of this function is 
    responsible for keeping the memory owner object alive as long as 
    the returned NumPy array is being used. 
    &quot;&quot;&quot;</span>
    <span class="s1">kind</span><span class="s0">, </span><span class="s1">bit_width</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">_ = dtype</span>

    <span class="s1">column_dtype = _NP_DTYPES.get(kind</span><span class="s0">, </span><span class="s1">{}).get(bit_width</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">column_dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">f&quot;Conversion for </span><span class="s0">{</span><span class="s1">dtype</span><span class="s0">} </span><span class="s4">is not yet supported.&quot;</span><span class="s1">)</span>

    <span class="s5"># TODO: No DLPack yet, so need to construct a new ndarray from the data pointer</span>
    <span class="s5"># and size in the buffer plus the dtype on the column. Use DLPack as NumPy supports</span>
    <span class="s5"># it since https://github.com/numpy/numpy/pull/19083</span>
    <span class="s1">ctypes_type = np.ctypeslib.as_ctypes_type(column_dtype)</span>

    <span class="s0">if </span><span class="s1">bit_width == </span><span class="s2">1</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">length </span><span class="s0">is not None, </span><span class="s4">&quot;`length` must be specified for a bit-mask buffer.&quot;</span>
        <span class="s1">pa = import_optional_dependency(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
        <span class="s1">arr = pa.BooleanArray.from_buffers(</span>
            <span class="s1">pa.bool_()</span><span class="s0">,</span>
            <span class="s1">length</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s0">None, </span><span class="s1">pa.foreign_buffer(buffer.ptr</span><span class="s0">, </span><span class="s1">length)]</span><span class="s0">,</span>
            <span class="s1">offset=offset</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s0">return </span><span class="s1">np.asarray(arr)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">data_pointer = ctypes.cast(</span>
            <span class="s1">buffer.ptr + (offset * bit_width // </span><span class="s2">8</span><span class="s1">)</span><span class="s0">, </span><span class="s1">ctypes.POINTER(ctypes_type)</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">length &gt; </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">np.ctypeslib.as_array(data_pointer</span><span class="s0">, </span><span class="s1">shape=(length</span><span class="s0">,</span><span class="s1">))</span>
        <span class="s0">return </span><span class="s1">np.array([]</span><span class="s0">, </span><span class="s1">dtype=ctypes_type)</span>


<span class="s0">def </span><span class="s1">set_nulls(</span>
    <span class="s1">data: np.ndarray | pd.Series</span><span class="s0">,</span>
    <span class="s1">col: Column</span><span class="s0">,</span>
    <span class="s1">validity: tuple[Buffer</span><span class="s0">, </span><span class="s1">tuple[DtypeKind</span><span class="s0">, </span><span class="s1">int</span><span class="s0">, </span><span class="s1">str</span><span class="s0">, </span><span class="s1">str]] | </span><span class="s0">None,</span>
    <span class="s1">allow_modify_inplace: bool = </span><span class="s0">True,</span>
<span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Set null values for the data according to the column null kind. 
 
    Parameters 
    ---------- 
    data : np.ndarray or pd.Series 
        Data to set nulls in. 
    col : Column 
        Column object that describes the `data`. 
    validity : tuple(Buffer, dtype) or None 
        The return value of ``col.buffers()``. We do not access the ``col.buffers()`` 
        here to not take the ownership of the memory of buffer objects. 
    allow_modify_inplace : bool, default: True 
        Whether to modify the `data` inplace when zero-copy is possible (True) or always 
        modify a copy of the `data` (False). 
 
    Returns 
    ------- 
    np.ndarray or pd.Series 
        Data with the nulls being set. 
    &quot;&quot;&quot;</span>
    <span class="s1">null_kind</span><span class="s0">, </span><span class="s1">sentinel_val = col.describe_null</span>
    <span class="s1">null_pos = </span><span class="s0">None</span>

    <span class="s0">if </span><span class="s1">null_kind == ColumnNullType.USE_SENTINEL:</span>
        <span class="s1">null_pos = pd.Series(data) == sentinel_val</span>
    <span class="s0">elif </span><span class="s1">null_kind </span><span class="s0">in </span><span class="s1">(ColumnNullType.USE_BITMASK</span><span class="s0">, </span><span class="s1">ColumnNullType.USE_BYTEMASK):</span>
        <span class="s0">assert </span><span class="s1">validity</span><span class="s0">, </span><span class="s4">&quot;Expected to have a validity buffer for the mask&quot;</span>
        <span class="s1">valid_buff</span><span class="s0">, </span><span class="s1">valid_dtype = validity</span>
        <span class="s1">null_pos = buffer_to_ndarray(</span>
            <span class="s1">valid_buff</span><span class="s0">, </span><span class="s1">valid_dtype</span><span class="s0">, </span><span class="s1">offset=col.offset</span><span class="s0">, </span><span class="s1">length=col.size()</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">sentinel_val == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">null_pos = ~null_pos</span>
    <span class="s0">elif </span><span class="s1">null_kind </span><span class="s0">in </span><span class="s1">(ColumnNullType.NON_NULLABLE</span><span class="s0">, </span><span class="s1">ColumnNullType.USE_NAN):</span>
        <span class="s0">pass</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span><span class="s4">f&quot;Null kind </span><span class="s0">{</span><span class="s1">null_kind</span><span class="s0">} </span><span class="s4">is not yet supported.&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">null_pos </span><span class="s0">is not None and </span><span class="s1">np.any(null_pos):</span>
        <span class="s0">if not </span><span class="s1">allow_modify_inplace:</span>
            <span class="s1">data = data.copy()</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">data[null_pos] = </span><span class="s0">None</span>
        <span class="s0">except </span><span class="s1">TypeError:</span>
            <span class="s5"># TypeError happens if the `data` dtype appears to be non-nullable</span>
            <span class="s5"># in numpy notation (bool, int, uint). If this happens,</span>
            <span class="s5"># cast the `data` to nullable float dtype.</span>
            <span class="s1">data = data.astype(float)</span>
            <span class="s1">data[null_pos] = </span><span class="s0">None</span>
        <span class="s0">except </span><span class="s1">SettingWithCopyError:</span>
            <span class="s5"># `SettingWithCopyError` may happen for datetime-like with missing values.</span>
            <span class="s1">data = data.copy()</span>
            <span class="s1">data[null_pos] = </span><span class="s0">None</span>

    <span class="s0">return </span><span class="s1">data</span>
</pre>
</body>
</html>
<html>
<head>
<title>backends.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
backends.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>

<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">collections.abc </span><span class="s0">import </span><span class="s1">Iterable</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>
<span class="s0">from </span><span class="s1">pandas.api.types </span><span class="s0">import </span><span class="s1">is_scalar</span><span class="s0">, </span><span class="s1">union_categoricals</span>

<span class="s0">from </span><span class="s1">dask.array.core </span><span class="s0">import </span><span class="s1">Array</span>
<span class="s0">from </span><span class="s1">dask.array.dispatch </span><span class="s0">import </span><span class="s1">percentile_lookup</span>
<span class="s0">from </span><span class="s1">dask.array.percentile </span><span class="s0">import </span><span class="s1">_percentile</span>
<span class="s0">from </span><span class="s1">dask.backends </span><span class="s0">import </span><span class="s1">CreationDispatch</span><span class="s0">, </span><span class="s1">DaskBackendEntrypoint</span>
<span class="s0">from </span><span class="s1">dask.dataframe._compat </span><span class="s0">import </span><span class="s1">is_any_real_numeric_dtype</span>
<span class="s0">from </span><span class="s1">dask.dataframe.core </span><span class="s0">import </span><span class="s1">DataFrame</span><span class="s0">, </span><span class="s1">Index</span><span class="s0">, </span><span class="s1">Scalar</span><span class="s0">, </span><span class="s1">Series</span><span class="s0">, </span><span class="s1">_Frame</span>
<span class="s0">from </span><span class="s1">dask.dataframe.dispatch </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">categorical_dtype_dispatch</span><span class="s0">,</span>
    <span class="s1">concat</span><span class="s0">,</span>
    <span class="s1">concat_dispatch</span><span class="s0">,</span>
    <span class="s1">from_pyarrow_table_dispatch</span><span class="s0">,</span>
    <span class="s1">get_parallel_type</span><span class="s0">,</span>
    <span class="s1">group_split_dispatch</span><span class="s0">,</span>
    <span class="s1">grouper_dispatch</span><span class="s0">,</span>
    <span class="s1">hash_object_dispatch</span><span class="s0">,</span>
    <span class="s1">is_categorical_dtype_dispatch</span><span class="s0">,</span>
    <span class="s1">make_meta_dispatch</span><span class="s0">,</span>
    <span class="s1">make_meta_obj</span><span class="s0">,</span>
    <span class="s1">meta_lib_from_array</span><span class="s0">,</span>
    <span class="s1">meta_nonempty</span><span class="s0">,</span>
    <span class="s1">partd_encode_dispatch</span><span class="s0">,</span>
    <span class="s1">pyarrow_schema_dispatch</span><span class="s0">,</span>
    <span class="s1">to_pandas_dispatch</span><span class="s0">,</span>
    <span class="s1">to_pyarrow_table_dispatch</span><span class="s0">,</span>
    <span class="s1">tolist_dispatch</span><span class="s0">,</span>
    <span class="s1">union_categoricals_dispatch</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">dask.dataframe.extensions </span><span class="s0">import </span><span class="s1">make_array_nonempty</span><span class="s0">, </span><span class="s1">make_scalar</span>
<span class="s0">from </span><span class="s1">dask.dataframe.utils </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">_empty_series</span><span class="s0">,</span>
    <span class="s1">_nonempty_scalar</span><span class="s0">,</span>
    <span class="s1">_scalar_from_dtype</span><span class="s0">,</span>
    <span class="s1">is_float_na_dtype</span><span class="s0">,</span>
    <span class="s1">is_integer_na_dtype</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">dask.sizeof </span><span class="s0">import </span><span class="s1">SimpleSizeof</span><span class="s0">, </span><span class="s1">sizeof</span>
<span class="s0">from </span><span class="s1">dask.utils </span><span class="s0">import </span><span class="s1">is_arraylike</span><span class="s0">, </span><span class="s1">is_series_like</span><span class="s0">, </span><span class="s1">typename</span>


<span class="s0">class </span><span class="s1">DataFrameBackendEntrypoint(DaskBackendEntrypoint):</span>
    <span class="s2">&quot;&quot;&quot;Dask-DataFrame version of ``DaskBackendEntrypoint`` 
 
    See Also 
    -------- 
    PandasBackendEntrypoint 
    &quot;&quot;&quot;</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">from_dict(data: dict</span><span class="s0">, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">npartitions: int</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Create a DataFrame collection from a dictionary 
 
        Parameters 
        ---------- 
        data : dict 
            Of the form {field : array-like} or {field : dict}. 
        npartitions : int 
            The desired number of output partitions. 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.io.from_dict 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">read_parquet(path: str | list</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Read Parquet files into a DataFrame collection 
 
        Parameters 
        ---------- 
        path : str or list 
            Source path(s). 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.parquet.core.read_parquet 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">read_json(url_path: str | list</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Read json files into a DataFrame collection 
 
        Parameters 
        ---------- 
        url_path : str or list 
            Source path(s). 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.json.read_json 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">read_orc(path: str | list</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Read ORC files into a DataFrame collection 
 
        Parameters 
        ---------- 
        path : str or list 
            Source path(s). 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.orc.core.read_orc 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">read_csv(urlpath: str | list</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Read CSV files into a DataFrame collection 
 
        Parameters 
        ---------- 
        urlpath : str or list 
            Source path(s). 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.csv.read_csv 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@staticmethod</span>
    <span class="s0">def </span><span class="s1">read_hdf(pattern: str | list</span><span class="s0">, </span><span class="s1">key: str</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s2">&quot;&quot;&quot;Read HDF5 files into a DataFrame collection 
 
        Parameters 
        ---------- 
        pattern : str or list 
            Source path(s). 
        key : str 
            Group identifier in the store. 
        **kwargs : 
            Optional backend kwargs. 
 
        See Also 
        -------- 
        dask.dataframe.io.hdf.read_hdf 
        &quot;&quot;&quot;</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>


<span class="s1">dataframe_creation_dispatch = CreationDispatch(</span>
    <span class="s1">module_name=</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">,</span>
    <span class="s1">default=</span><span class="s3">&quot;pandas&quot;</span><span class="s0">,</span>
    <span class="s1">entrypoint_class=DataFrameBackendEntrypoint</span><span class="s0">,</span>
    <span class="s1">name=</span><span class="s3">&quot;dataframe_creation_dispatch&quot;</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s4">##########</span>
<span class="s4"># Pandas #</span>
<span class="s4">##########</span>


<span class="s1">@make_scalar.register(np.dtype)</span>
<span class="s0">def </span><span class="s1">_(dtype):</span>
    <span class="s0">return </span><span class="s1">_scalar_from_dtype(dtype)</span>


<span class="s1">@make_scalar.register(pd.Timestamp)</span>
<span class="s1">@make_scalar.register(pd.Timedelta)</span>
<span class="s1">@make_scalar.register(pd.Period)</span>
<span class="s1">@make_scalar.register(pd.Interval)</span>
<span class="s0">def </span><span class="s1">_(x):</span>
    <span class="s0">return </span><span class="s1">x</span>


<span class="s1">@make_meta_dispatch.register((pd.Series</span><span class="s0">, </span><span class="s1">pd.DataFrame))</span>
<span class="s0">def </span><span class="s1">_(x</span><span class="s0">, </span><span class="s1">index=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s1">out = x.iloc[:</span><span class="s5">0</span><span class="s1">].copy(deep=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s4"># index isn't copied by default in pandas, even if deep=true</span>
    <span class="s1">out.index = out.index.copy(deep=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">out</span>


<span class="s1">@make_meta_dispatch.register(pd.Index)</span>
<span class="s0">def </span><span class="s1">_(x</span><span class="s0">, </span><span class="s1">index=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">x[</span><span class="s5">0</span><span class="s1">:</span><span class="s5">0</span><span class="s1">].copy(deep=</span><span class="s0">True</span><span class="s1">)</span>


<span class="s1">meta_object_types: tuple[type</span><span class="s0">, </span><span class="s1">...] = (pd.Series</span><span class="s0">, </span><span class="s1">pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Index</span><span class="s0">, </span><span class="s1">pd.MultiIndex)</span>
<span class="s0">try</span><span class="s1">:</span>
    <span class="s0">import </span><span class="s1">scipy.sparse </span><span class="s0">as </span><span class="s1">sp</span>

    <span class="s1">meta_object_types += (sp.spmatrix</span><span class="s0">,</span><span class="s1">)</span>
<span class="s0">except </span><span class="s1">ImportError:</span>
    <span class="s0">pass</span>


<span class="s1">@pyarrow_schema_dispatch.register((pd.DataFrame</span><span class="s0">,</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">get_pyarrow_schema_pandas(obj</span><span class="s0">, </span><span class="s1">preserve_index=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">import </span><span class="s1">pyarrow </span><span class="s0">as </span><span class="s1">pa</span>

    <span class="s0">return </span><span class="s1">pa.Schema.from_pandas(obj</span><span class="s0">, </span><span class="s1">preserve_index=preserve_index)</span>


<span class="s1">@to_pyarrow_table_dispatch.register((pd.DataFrame</span><span class="s0">,</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">get_pyarrow_table_from_pandas(obj</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s4"># `kwargs` must be supported by `pyarrow.Table.to_pandas`</span>
    <span class="s0">import </span><span class="s1">pyarrow </span><span class="s0">as </span><span class="s1">pa</span>

    <span class="s0">return </span><span class="s1">pa.Table.from_pandas(obj</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s1">@from_pyarrow_table_dispatch.register((pd.DataFrame</span><span class="s0">,</span><span class="s1">))</span>
<span class="s0">def </span><span class="s1">get_pandas_dataframe_from_pyarrow(meta</span><span class="s0">, </span><span class="s1">table</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s4"># `kwargs` must be supported by `pyarrow.Table.to_pandas`</span>
    <span class="s0">import </span><span class="s1">pyarrow </span><span class="s0">as </span><span class="s1">pa</span>

    <span class="s0">def </span><span class="s1">default_types_mapper(pyarrow_dtype: pa.DataType) -&gt; object:</span>
        <span class="s4"># Avoid converting strings from `string[pyarrow]` to</span>
        <span class="s4"># `string[python]` if we have *any* `string[pyarrow]`</span>
        <span class="s0">if </span><span class="s1">(</span>
            <span class="s1">pyarrow_dtype </span><span class="s0">in </span><span class="s1">{pa.large_string()</span><span class="s0">, </span><span class="s1">pa.string()}</span>
            <span class="s0">and </span><span class="s1">pd.StringDtype(</span><span class="s3">&quot;pyarrow&quot;</span><span class="s1">) </span><span class="s0">in </span><span class="s1">meta.dtypes.values</span>
        <span class="s1">):</span>
            <span class="s0">return </span><span class="s1">pd.StringDtype(</span><span class="s3">&quot;pyarrow&quot;</span><span class="s1">)</span>
        <span class="s0">return None</span>

    <span class="s1">types_mapper = kwargs.pop(</span><span class="s3">&quot;types_mapper&quot;</span><span class="s0">, </span><span class="s1">default_types_mapper)</span>
    <span class="s0">return </span><span class="s1">table.to_pandas(types_mapper=types_mapper</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s1">@partd_encode_dispatch.register(pd.DataFrame)</span>
<span class="s0">def </span><span class="s1">partd_pandas_blocks(_):</span>
    <span class="s0">from </span><span class="s1">partd </span><span class="s0">import </span><span class="s1">PandasBlocks</span>

    <span class="s0">return </span><span class="s1">PandasBlocks</span>


<span class="s1">@meta_nonempty.register(pd.DatetimeTZDtype)</span>
<span class="s1">@make_meta_dispatch.register(pd.DatetimeTZDtype)</span>
<span class="s0">def </span><span class="s1">make_meta_pandas_datetime_tz(x</span><span class="s0">, </span><span class="s1">index=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">_nonempty_scalar(x)</span>


<span class="s1">@make_meta_obj.register(meta_object_types)</span>
<span class="s0">def </span><span class="s1">make_meta_object(x</span><span class="s0">, </span><span class="s1">index=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Create an empty pandas object containing the desired metadata. 
 
    Parameters 
    ---------- 
    x : dict, tuple, list, pd.Series, pd.DataFrame, pd.Index, dtype, scalar 
        To create a DataFrame, provide a `dict` mapping of `{name: dtype}`, or 
        an iterable of `(name, dtype)` tuples. To create a `Series`, provide a 
        tuple of `(name, dtype)`. If a pandas object, names, dtypes, and index 
        should match the desired output. If a dtype or scalar, a scalar of the 
        same dtype is returned. 
    index :  pd.Index, optional 
        Any pandas index to use in the metadata. If none provided, a 
        `RangeIndex` will be used. 
 
    Examples 
    -------- 
 
    &gt;&gt;&gt; make_meta_object([('a', 'i8'), ('b', 'O')]) 
    Empty DataFrame 
    Columns: [a, b] 
    Index: [] 
    &gt;&gt;&gt; make_meta_object(('a', 'f8')) 
    Series([], Name: a, dtype: float64) 
    &gt;&gt;&gt; make_meta_object('i8') 
    1 
    &quot;&quot;&quot;</span>

    <span class="s0">if </span><span class="s1">is_arraylike(x) </span><span class="s0">and </span><span class="s1">x.shape:</span>
        <span class="s0">return </span><span class="s1">x[:</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s0">if </span><span class="s1">index </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">index = make_meta_dispatch(index)</span>

    <span class="s0">if </span><span class="s1">isinstance(x</span><span class="s0">, </span><span class="s1">dict):</span>
        <span class="s0">return </span><span class="s1">pd.DataFrame(</span>
            <span class="s1">{c: _empty_series(c</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">index=index) </span><span class="s0">for </span><span class="s1">(c</span><span class="s0">, </span><span class="s1">d) </span><span class="s0">in </span><span class="s1">x.items()}</span><span class="s0">, </span><span class="s1">index=index</span>
        <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">isinstance(x</span><span class="s0">, </span><span class="s1">tuple) </span><span class="s0">and </span><span class="s1">len(x) == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">_empty_series(x[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x[</span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">index=index)</span>
    <span class="s0">elif </span><span class="s1">isinstance(x</span><span class="s0">, </span><span class="s1">Iterable) </span><span class="s0">and not </span><span class="s1">isinstance(x</span><span class="s0">, </span><span class="s1">str):</span>
        <span class="s0">if not </span><span class="s1">all(isinstance(i</span><span class="s0">, </span><span class="s1">tuple) </span><span class="s0">and </span><span class="s1">len(i) == </span><span class="s5">2 </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">x):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;Expected iterable of tuples of (name, dtype), got </span><span class="s0">{</span><span class="s1">x</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">pd.DataFrame(</span>
            <span class="s1">{c: _empty_series(c</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">index=index) </span><span class="s0">for </span><span class="s1">(c</span><span class="s0">, </span><span class="s1">d) </span><span class="s0">in </span><span class="s1">x}</span><span class="s0">,</span>
            <span class="s1">columns=[c </span><span class="s0">for </span><span class="s1">c</span><span class="s0">, </span><span class="s1">d </span><span class="s0">in </span><span class="s1">x]</span><span class="s0">,</span>
            <span class="s1">index=index</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s0">elif not </span><span class="s1">hasattr(x</span><span class="s0">, </span><span class="s3">&quot;dtype&quot;</span><span class="s1">) </span><span class="s0">and </span><span class="s1">x </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s4"># could be a string, a dtype object, or a python type. Skip `None`,</span>
        <span class="s4"># because it is implictly converted to `dtype('f8')`, which we don't</span>
        <span class="s4"># want here.</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">dtype = np.dtype(x)</span>
            <span class="s0">return </span><span class="s1">_scalar_from_dtype(dtype)</span>
        <span class="s0">except </span><span class="s1">Exception:</span>
            <span class="s4"># Continue on to next check</span>
            <span class="s0">pass</span>

    <span class="s0">if </span><span class="s1">is_scalar(x):</span>
        <span class="s0">return </span><span class="s1">_nonempty_scalar(x)</span>

    <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s3">f&quot;Don't know how to create metadata from </span><span class="s0">{</span><span class="s1">x</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>


<span class="s1">@meta_nonempty.register(object)</span>
<span class="s0">def </span><span class="s1">meta_nonempty_object(x):</span>
    <span class="s2">&quot;&quot;&quot;Create a nonempty pandas object from the given metadata. 
 
    Returns a pandas DataFrame, Series, or Index that contains two rows 
    of fake data. 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">is_scalar(x):</span>
        <span class="s0">return </span><span class="s1">_nonempty_scalar(x)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span>
            <span class="s3">&quot;Expected Pandas-like Index, Series, DataFrame, or scalar, &quot;</span>
            <span class="s3">f&quot;got </span><span class="s0">{</span><span class="s1">typename(type(x))</span><span class="s0">}</span><span class="s3">&quot;</span>
        <span class="s1">)</span>


<span class="s1">@meta_nonempty.register(pd.DataFrame)</span>
<span class="s0">def </span><span class="s1">meta_nonempty_dataframe(x):</span>
    <span class="s1">idx = meta_nonempty(x.index)</span>
    <span class="s1">dt_s_dict = dict()</span>
    <span class="s1">data = dict()</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(len(x.columns)):</span>
        <span class="s1">series = x.iloc[:</span><span class="s0">, </span><span class="s1">i]</span>
        <span class="s1">dt = series.dtype</span>
        <span class="s0">if </span><span class="s1">dt </span><span class="s0">not in </span><span class="s1">dt_s_dict:</span>
            <span class="s1">dt_s_dict[dt] = _nonempty_series(x.iloc[:</span><span class="s0">, </span><span class="s1">i]</span><span class="s0">, </span><span class="s1">idx=idx)</span>
        <span class="s1">data[i] = dt_s_dict[dt]</span>
    <span class="s1">res = pd.DataFrame(data</span><span class="s0">, </span><span class="s1">index=idx</span><span class="s0">, </span><span class="s1">columns=np.arange(len(x.columns)))</span>
    <span class="s1">res.columns = x.columns</span>
    <span class="s1">res.attrs = x.attrs</span>
    <span class="s0">return </span><span class="s1">res</span>


<span class="s1">@meta_nonempty.register(pd.Index)</span>
<span class="s0">def </span><span class="s1">_nonempty_index(idx):</span>
    <span class="s1">typ = type(idx)</span>
    <span class="s0">if </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.RangeIndex:</span>
        <span class="s0">return </span><span class="s1">pd.RangeIndex(</span><span class="s5">2</span><span class="s0">, </span><span class="s1">name=idx.name</span><span class="s0">, </span><span class="s1">dtype=idx.dtype)</span>
    <span class="s0">elif </span><span class="s1">is_any_real_numeric_dtype(idx):</span>
        <span class="s0">return </span><span class="s1">typ([</span><span class="s5">1</span><span class="s0">, </span><span class="s5">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">name=idx.name</span><span class="s0">, </span><span class="s1">dtype=idx.dtype)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.DatetimeIndex:</span>
        <span class="s1">start = </span><span class="s3">&quot;1970-01-01&quot;</span>
        <span class="s4"># Need a non-monotonic decreasing index to avoid issues with</span>
        <span class="s4"># partial string indexing see https://github.com/dask/dask/issues/2389</span>
        <span class="s4"># and https://github.com/pandas-dev/pandas/issues/16515</span>
        <span class="s4"># This doesn't mean `_meta_nonempty` should ever rely on</span>
        <span class="s4"># `self.monotonic_increasing` or `self.monotonic_decreasing`</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">pd.date_range(</span>
                <span class="s1">start=start</span><span class="s0">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">freq=idx.freq</span><span class="s0">, </span><span class="s1">tz=idx.tz</span><span class="s0">, </span><span class="s1">name=idx.name</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">ValueError:  </span><span class="s4"># older pandas versions</span>
            <span class="s1">data = [start</span><span class="s0">, </span><span class="s3">&quot;1970-01-02&quot;</span><span class="s1">] </span><span class="s0">if </span><span class="s1">idx.freq </span><span class="s0">is None else None</span>
            <span class="s0">return </span><span class="s1">pd.DatetimeIndex(</span>
                <span class="s1">data</span><span class="s0">, </span><span class="s1">start=start</span><span class="s0">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">freq=idx.freq</span><span class="s0">, </span><span class="s1">tz=idx.tz</span><span class="s0">, </span><span class="s1">name=idx.name</span>
            <span class="s1">)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.PeriodIndex:</span>
        <span class="s0">return </span><span class="s1">pd.period_range(</span>
            <span class="s1">start=</span><span class="s3">&quot;1970-01-01&quot;</span><span class="s0">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">freq=idx.freq</span><span class="s0">, </span><span class="s1">name=idx.name</span>
        <span class="s1">)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.TimedeltaIndex:</span>
        <span class="s1">start = np.timedelta64(</span><span class="s5">1</span><span class="s0">, </span><span class="s3">&quot;D&quot;</span><span class="s1">)</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">pd.timedelta_range(</span>
                <span class="s1">start=start</span><span class="s0">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">freq=idx.freq</span><span class="s0">, </span><span class="s1">name=idx.name</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">ValueError:  </span><span class="s4"># older pandas versions</span>
            <span class="s1">start = np.timedelta64(</span><span class="s5">1</span><span class="s0">, </span><span class="s3">&quot;D&quot;</span><span class="s1">)</span>
            <span class="s1">data = [start</span><span class="s0">, </span><span class="s1">start + </span><span class="s5">1</span><span class="s1">] </span><span class="s0">if </span><span class="s1">idx.freq </span><span class="s0">is None else None</span>
            <span class="s0">return </span><span class="s1">pd.TimedeltaIndex(</span>
                <span class="s1">data</span><span class="s0">, </span><span class="s1">start=start</span><span class="s0">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s0">, </span><span class="s1">freq=idx.freq</span><span class="s0">, </span><span class="s1">name=idx.name</span>
            <span class="s1">)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.CategoricalIndex:</span>
        <span class="s0">if </span><span class="s1">len(idx.categories) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">data = pd.Categorical(_nonempty_index(idx.categories)</span><span class="s0">, </span><span class="s1">ordered=idx.ordered)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">data = pd.Categorical.from_codes(</span>
                <span class="s1">[-</span><span class="s5">1</span><span class="s0">, </span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">categories=idx.categories</span><span class="s0">, </span><span class="s1">ordered=idx.ordered</span>
            <span class="s1">)</span>
        <span class="s0">return </span><span class="s1">pd.CategoricalIndex(data</span><span class="s0">, </span><span class="s1">name=idx.name)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.MultiIndex:</span>
        <span class="s1">levels = [_nonempty_index(l) </span><span class="s0">for </span><span class="s1">l </span><span class="s0">in </span><span class="s1">idx.levels]</span>
        <span class="s1">codes = [[</span><span class="s5">0</span><span class="s0">, </span><span class="s5">0</span><span class="s1">] </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">idx.levels]</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">pd.MultiIndex(levels=levels</span><span class="s0">, </span><span class="s1">codes=codes</span><span class="s0">, </span><span class="s1">names=idx.names)</span>
        <span class="s0">except </span><span class="s1">TypeError:  </span><span class="s4"># older pandas versions</span>
            <span class="s0">return </span><span class="s1">pd.MultiIndex(levels=levels</span><span class="s0">, </span><span class="s1">labels=codes</span><span class="s0">, </span><span class="s1">names=idx.names)</span>
    <span class="s0">elif </span><span class="s1">typ </span><span class="s0">is </span><span class="s1">pd.Index:</span>
        <span class="s0">if </span><span class="s1">type(idx.dtype) </span><span class="s0">in </span><span class="s1">make_array_nonempty._lookup:</span>
            <span class="s0">return </span><span class="s1">pd.Index(</span>
                <span class="s1">make_array_nonempty(idx.dtype)</span><span class="s0">, </span><span class="s1">dtype=idx.dtype</span><span class="s0">, </span><span class="s1">name=idx.name</span>
            <span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">idx.dtype == bool:</span>
            <span class="s4"># pd 1.5 introduce bool dtypes and respect non-uniqueness</span>
            <span class="s0">return </span><span class="s1">pd.Index([</span><span class="s0">True, False</span><span class="s1">]</span><span class="s0">, </span><span class="s1">name=idx.name)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># for pd 1.5 in the case of bool index this would be cast as [True, True]</span>
            <span class="s4"># breaking uniqueness</span>
            <span class="s0">return </span><span class="s1">pd.Index([</span><span class="s3">&quot;a&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">name=idx.name</span><span class="s0">, </span><span class="s1">dtype=idx.dtype)</span>

    <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s3">f&quot;Don't know how to handle index of type </span><span class="s0">{</span><span class="s1">typename(type(idx))</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s1">)</span>


<span class="s1">@meta_nonempty.register(pd.Series)</span>
<span class="s0">def </span><span class="s1">_nonempty_series(s</span><span class="s0">, </span><span class="s1">idx=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4"># TODO: Use register dtypes with make_array_nonempty</span>
    <span class="s0">if </span><span class="s1">idx </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">idx = _nonempty_index(s.index)</span>
    <span class="s1">dtype = s.dtype</span>
    <span class="s0">if </span><span class="s1">len(s) &gt; </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s4"># use value from meta if provided</span>
        <span class="s1">data = [s.iloc[</span><span class="s5">0</span><span class="s1">]] * </span><span class="s5">2</span>
    <span class="s0">elif </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.DatetimeTZDtype):</span>
        <span class="s1">entry = pd.Timestamp(</span><span class="s3">&quot;1970-01-01&quot;</span><span class="s0">, </span><span class="s1">tz=dtype.tz)</span>
        <span class="s1">data = [entry</span><span class="s0">, </span><span class="s1">entry]</span>
    <span class="s0">elif </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.CategoricalDtype):</span>
        <span class="s0">if </span><span class="s1">len(s.cat.categories):</span>
            <span class="s1">data = [s.cat.categories[</span><span class="s5">0</span><span class="s1">]] * </span><span class="s5">2</span>
            <span class="s1">cats = s.cat.categories</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">data = _nonempty_index(s.cat.categories)</span>
            <span class="s1">cats = s.cat.categories[:</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">data = pd.Categorical(data</span><span class="s0">, </span><span class="s1">categories=cats</span><span class="s0">, </span><span class="s1">ordered=s.cat.ordered)</span>
    <span class="s0">elif </span><span class="s1">is_integer_na_dtype(dtype):</span>
        <span class="s1">data = pd.array([</span><span class="s5">1</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">elif </span><span class="s1">is_float_na_dtype(dtype):</span>
        <span class="s1">data = pd.array([</span><span class="s5">1.0</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">elif </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.PeriodDtype):</span>
        <span class="s4"># pandas 0.24.0+ should infer this to be Series[Period[freq]]</span>
        <span class="s1">freq = dtype.freq</span>
        <span class="s1">data = [pd.Period(</span><span class="s3">&quot;2000&quot;</span><span class="s0">, </span><span class="s1">freq)</span><span class="s0">, </span><span class="s1">pd.Period(</span><span class="s3">&quot;2001&quot;</span><span class="s0">, </span><span class="s1">freq)]</span>
    <span class="s0">elif </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.SparseDtype):</span>
        <span class="s1">entry = _scalar_from_dtype(dtype.subtype)</span>
        <span class="s1">data = pd.array([entry</span><span class="s0">, </span><span class="s1">entry]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">elif </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.IntervalDtype):</span>
        <span class="s1">entry = _scalar_from_dtype(dtype.subtype)</span>
        <span class="s1">data = pd.array([entry</span><span class="s0">, </span><span class="s1">entry]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">elif </span><span class="s1">type(dtype) </span><span class="s0">in </span><span class="s1">make_array_nonempty._lookup:</span>
        <span class="s1">data = make_array_nonempty(dtype)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">entry = _scalar_from_dtype(dtype)</span>
        <span class="s1">data = np.array([entry</span><span class="s0">, </span><span class="s1">entry]</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>

    <span class="s1">out = pd.Series(data</span><span class="s0">, </span><span class="s1">name=s.name</span><span class="s0">, </span><span class="s1">index=idx)</span>
    <span class="s1">out.attrs = s.attrs</span>
    <span class="s0">return </span><span class="s1">out</span>


<span class="s1">@meta_lib_from_array.register(Array)</span>
<span class="s0">def </span><span class="s1">_meta_lib_from_array_da(x):</span>
    <span class="s4"># Use x._meta for dask arrays</span>
    <span class="s0">return </span><span class="s1">meta_lib_from_array(x._meta)</span>


<span class="s1">@meta_lib_from_array.register(np.ndarray)</span>
<span class="s0">def </span><span class="s1">_meta_lib_from_array_numpy(x):</span>
    <span class="s4"># numpy -&gt; pandas</span>
    <span class="s0">return </span><span class="s1">pd</span>


<span class="s1">@union_categoricals_dispatch.register(</span>
    <span class="s1">(pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index</span><span class="s0">, </span><span class="s1">pd.Categorical)</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">union_categoricals_pandas(to_union</span><span class="s0">, </span><span class="s1">sort_categories=</span><span class="s0">False, </span><span class="s1">ignore_order=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">pd.api.types.union_categoricals(</span>
        <span class="s1">to_union</span><span class="s0">, </span><span class="s1">sort_categories=sort_categories</span><span class="s0">, </span><span class="s1">ignore_order=ignore_order</span>
    <span class="s1">)</span>


<span class="s1">@get_parallel_type.register(pd.Series)</span>
<span class="s0">def </span><span class="s1">get_parallel_type_series(_):</span>
    <span class="s0">return </span><span class="s1">Series</span>


<span class="s1">@get_parallel_type.register(pd.DataFrame)</span>
<span class="s0">def </span><span class="s1">get_parallel_type_dataframe(_):</span>
    <span class="s0">return </span><span class="s1">DataFrame</span>


<span class="s1">@get_parallel_type.register(pd.Index)</span>
<span class="s0">def </span><span class="s1">get_parallel_type_index(_):</span>
    <span class="s0">return </span><span class="s1">Index</span>


<span class="s1">@get_parallel_type.register(_Frame)</span>
<span class="s0">def </span><span class="s1">get_parallel_type_frame(o):</span>
    <span class="s0">return </span><span class="s1">get_parallel_type(o._meta)</span>


<span class="s1">@get_parallel_type.register(object)</span>
<span class="s0">def </span><span class="s1">get_parallel_type_object(_):</span>
    <span class="s0">return </span><span class="s1">Scalar</span>


<span class="s1">@hash_object_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">hash_object_pandas(</span>
    <span class="s1">obj</span><span class="s0">, </span><span class="s1">index=</span><span class="s0">True, </span><span class="s1">encoding=</span><span class="s3">&quot;utf8&quot;</span><span class="s0">, </span><span class="s1">hash_key=</span><span class="s0">None, </span><span class="s1">categorize=</span><span class="s0">True</span>
<span class="s1">):</span>
    <span class="s0">return </span><span class="s1">pd.util.hash_pandas_object(</span>
        <span class="s1">obj</span><span class="s0">, </span><span class="s1">index=index</span><span class="s0">, </span><span class="s1">encoding=encoding</span><span class="s0">, </span><span class="s1">hash_key=hash_key</span><span class="s0">, </span><span class="s1">categorize=categorize</span>
    <span class="s1">)</span>


<span class="s0">class </span><span class="s1">ShuffleGroupResult(SimpleSizeof</span><span class="s0">, </span><span class="s1">dict):</span>
    <span class="s0">def </span><span class="s1">__sizeof__(self) -&gt; int:</span>
        <span class="s2">&quot;&quot;&quot; 
        The result of the shuffle split are typically small dictionaries 
        (#keys &lt;&lt; 100; typically &lt;= 32) The splits are often non-uniformly 
        distributed. Some of the splits may even be empty. Sampling the 
        dictionary for size estimation can cause severe errors. 
 
        See also https://github.com/dask/distributed/issues/4962 
        &quot;&quot;&quot;</span>
        <span class="s1">total_size = super().__sizeof__()</span>
        <span class="s0">for </span><span class="s1">k</span><span class="s0">, </span><span class="s1">df </span><span class="s0">in </span><span class="s1">self.items():</span>
            <span class="s1">total_size += sizeof(k)</span>
            <span class="s1">total_size += sizeof(df)</span>
        <span class="s0">return </span><span class="s1">total_size</span>


<span class="s1">@group_split_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">group_split_pandas(df</span><span class="s0">, </span><span class="s1">c</span><span class="s0">, </span><span class="s1">k</span><span class="s0">, </span><span class="s1">ignore_index=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">is_series_like(c):</span>
        <span class="s1">c = c.values</span>
    <span class="s1">indexer</span><span class="s0">, </span><span class="s1">locations = pd._libs.algos.groupsort_indexer(</span>
        <span class="s1">c.astype(np.intp</span><span class="s0">, </span><span class="s1">copy=</span><span class="s0">False</span><span class="s1">)</span><span class="s0">, </span><span class="s1">k</span>
    <span class="s1">)</span>
    <span class="s1">df2 = df.take(indexer)</span>
    <span class="s1">locations = locations.cumsum()</span>
    <span class="s1">parts = [</span>
        <span class="s1">df2.iloc[a:b].reset_index(drop=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">if </span><span class="s1">ignore_index </span><span class="s0">else </span><span class="s1">df2.iloc[a:b]</span>
        <span class="s0">for </span><span class="s1">a</span><span class="s0">, </span><span class="s1">b </span><span class="s0">in </span><span class="s1">zip(locations[:-</span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">locations[</span><span class="s5">1</span><span class="s1">:])</span>
    <span class="s1">]</span>
    <span class="s0">return </span><span class="s1">ShuffleGroupResult(zip(range(k)</span><span class="s0">, </span><span class="s1">parts))</span>


<span class="s1">@concat_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">concat_pandas(</span>
    <span class="s1">dfs</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s5">0</span><span class="s0">,</span>
    <span class="s1">join=</span><span class="s3">&quot;outer&quot;</span><span class="s0">,</span>
    <span class="s1">uniform=</span><span class="s0">False,</span>
    <span class="s1">filter_warning=</span><span class="s0">True,</span>
    <span class="s1">ignore_index=</span><span class="s0">False,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s1">ignore_order = kwargs.pop(</span><span class="s3">&quot;ignore_order&quot;</span><span class="s0">, False</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">pd.concat(dfs</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">join=join</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s4"># Support concatenating indices along axis 0</span>
    <span class="s0">if </span><span class="s1">isinstance(dfs[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pd.Index):</span>
        <span class="s0">if </span><span class="s1">isinstance(dfs[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pd.CategoricalIndex):</span>
            <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s0">, </span><span class="s1">len(dfs)):</span>
                <span class="s0">if not </span><span class="s1">isinstance(dfs[i]</span><span class="s0">, </span><span class="s1">pd.CategoricalIndex):</span>
                    <span class="s1">dfs[i] = dfs[i].astype(</span><span class="s3">&quot;category&quot;</span><span class="s1">)</span>
            <span class="s0">return </span><span class="s1">pd.CategoricalIndex(</span>
                <span class="s1">union_categoricals(dfs</span><span class="s0">, </span><span class="s1">ignore_order=ignore_order)</span><span class="s0">, </span><span class="s1">name=dfs[</span><span class="s5">0</span><span class="s1">].name</span>
            <span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">isinstance(dfs[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pd.MultiIndex):</span>
            <span class="s1">first</span><span class="s0">, </span><span class="s1">rest = dfs[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dfs[</span><span class="s5">1</span><span class="s1">:]</span>
            <span class="s0">if </span><span class="s1">all(</span>
                <span class="s1">(isinstance(o</span><span class="s0">, </span><span class="s1">pd.MultiIndex) </span><span class="s0">and </span><span class="s1">o.nlevels &gt;= first.nlevels)</span>
                <span class="s0">for </span><span class="s1">o </span><span class="s0">in </span><span class="s1">rest</span>
            <span class="s1">):</span>
                <span class="s1">arrays = [</span>
                    <span class="s1">concat([i._get_level_values(n) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">dfs])</span>
                    <span class="s0">for </span><span class="s1">n </span><span class="s0">in </span><span class="s1">range(first.nlevels)</span>
                <span class="s1">]</span>
                <span class="s0">return </span><span class="s1">pd.MultiIndex.from_arrays(arrays</span><span class="s0">, </span><span class="s1">names=first.names)</span>

            <span class="s1">to_concat = (first.values</span><span class="s0">,</span><span class="s1">) + tuple(k._values </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">rest)</span>
            <span class="s1">new_tuples = np.concatenate(to_concat)</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">pd.MultiIndex.from_tuples(new_tuples</span><span class="s0">, </span><span class="s1">names=first.names)</span>
            <span class="s0">except </span><span class="s1">Exception:</span>
                <span class="s0">return </span><span class="s1">pd.Index(new_tuples)</span>
        <span class="s0">return </span><span class="s1">dfs[</span><span class="s5">0</span><span class="s1">].append(dfs[</span><span class="s5">1</span><span class="s1">:])</span>

    <span class="s4"># Handle categorical index separately</span>
    <span class="s1">dfs0_index = dfs[</span><span class="s5">0</span><span class="s1">].index</span>

    <span class="s1">has_categoricalindex = isinstance(dfs0_index</span><span class="s0">, </span><span class="s1">pd.CategoricalIndex) </span><span class="s0">or </span><span class="s1">(</span>
        <span class="s1">isinstance(dfs0_index</span><span class="s0">, </span><span class="s1">pd.MultiIndex)</span>
        <span class="s0">and </span><span class="s1">any(isinstance(i</span><span class="s0">, </span><span class="s1">pd.CategoricalIndex) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">dfs0_index.levels)</span>
    <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">has_categoricalindex:</span>
        <span class="s1">dfs2 = [df.reset_index(drop=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs]</span>
        <span class="s1">ind = concat([df.index </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dfs2 = dfs</span>
        <span class="s1">ind = </span><span class="s0">None</span>

    <span class="s4"># Concatenate the partitions together, handling categories as needed</span>
    <span class="s0">if </span><span class="s1">(</span>
        <span class="s1">isinstance(dfs2[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pd.DataFrame)</span>
        <span class="s0">if </span><span class="s1">uniform</span>
        <span class="s0">else </span><span class="s1">any(isinstance(df</span><span class="s0">, </span><span class="s1">pd.DataFrame) </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs2)</span>
    <span class="s1">):</span>
        <span class="s0">if </span><span class="s1">uniform:</span>
            <span class="s1">dfs3 = dfs2</span>
            <span class="s1">cat_mask = dfs2[</span><span class="s5">0</span><span class="s1">].dtypes == </span><span class="s3">&quot;category&quot;</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># When concatenating mixed dataframes and series on axis 1, Pandas</span>
            <span class="s4"># converts series to dataframes with a single column named 0, then</span>
            <span class="s4"># concatenates.</span>
            <span class="s1">dfs3 = [</span>
                <span class="s1">df</span>
                <span class="s0">if </span><span class="s1">isinstance(df</span><span class="s0">, </span><span class="s1">pd.DataFrame)</span>
                <span class="s0">else </span><span class="s1">df.to_frame().rename(columns={df.name: </span><span class="s5">0</span><span class="s1">})</span>
                <span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs2</span>
            <span class="s1">]</span>
            <span class="s4"># pandas may raise a RuntimeWarning for comparing ints and strs</span>
            <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
                <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
                <span class="s0">if </span><span class="s1">filter_warning:</span>
                    <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">FutureWarning)</span>
                <span class="s1">cat_mask = pd.concat(</span>
                    <span class="s1">[(df.dtypes == </span><span class="s3">&quot;category&quot;</span><span class="s1">).to_frame().T </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs3]</span><span class="s0">,</span>
                    <span class="s1">join=join</span><span class="s0">,</span>
                    <span class="s1">**kwargs</span><span class="s0">,</span>
                <span class="s1">).any()</span>

        <span class="s0">if </span><span class="s1">cat_mask.any():</span>
            <span class="s1">not_cat = cat_mask[~cat_mask].index</span>
            <span class="s4"># this should be aligned, so no need to filter warning</span>
            <span class="s1">out = pd.concat(</span>
                <span class="s1">[df[df.columns.intersection(not_cat)] </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs3]</span><span class="s0">,</span>
                <span class="s1">join=join</span><span class="s0">,</span>
                <span class="s1">**kwargs</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">temp_ind = out.index</span>
            <span class="s0">for </span><span class="s1">col </span><span class="s0">in </span><span class="s1">cat_mask.index.difference(not_cat):</span>
                <span class="s4"># Find an example of categoricals in this column</span>
                <span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs3:</span>
                    <span class="s1">sample = df.get(col)</span>
                    <span class="s0">if </span><span class="s1">sample </span><span class="s0">is not None</span><span class="s1">:</span>
                        <span class="s0">break</span>
                <span class="s4"># Extract partitions, subbing in missing if needed</span>
                <span class="s1">parts = []</span>
                <span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs3:</span>
                    <span class="s0">if </span><span class="s1">col </span><span class="s0">in </span><span class="s1">df.columns:</span>
                        <span class="s1">parts.append(df[col])</span>
                    <span class="s0">else</span><span class="s1">:</span>
                        <span class="s1">codes = np.full(len(df)</span><span class="s0">, </span><span class="s1">-</span><span class="s5">1</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s3">&quot;i8&quot;</span><span class="s1">)</span>
                        <span class="s1">data = pd.Categorical.from_codes(</span>
                            <span class="s1">codes</span><span class="s0">, </span><span class="s1">sample.cat.categories</span><span class="s0">, </span><span class="s1">sample.cat.ordered</span>
                        <span class="s1">)</span>
                        <span class="s1">parts.append(data)</span>
                <span class="s1">out[col] = union_categoricals(parts</span><span class="s0">, </span><span class="s1">ignore_order=ignore_order)</span>
                <span class="s4"># Pandas resets index type on assignment if frame is empty</span>
                <span class="s4"># https://github.com/pandas-dev/pandas/issues/17101</span>
                <span class="s0">if not </span><span class="s1">len(temp_ind):</span>
                    <span class="s1">out.index = temp_ind</span>
            <span class="s1">out = out.reindex(columns=cat_mask.index)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># pandas may raise a RuntimeWarning for comparing ints and strs</span>
            <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
                <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning)</span>
                <span class="s0">if </span><span class="s1">filter_warning:</span>
                    <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">FutureWarning)</span>
                <span class="s1">out = pd.concat(dfs3</span><span class="s0">, </span><span class="s1">join=join</span><span class="s0">, </span><span class="s1">sort=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">isinstance(dfs2[</span><span class="s5">0</span><span class="s1">].dtype</span><span class="s0">, </span><span class="s1">pd.CategoricalDtype):</span>
            <span class="s0">if </span><span class="s1">ind </span><span class="s0">is None</span><span class="s1">:</span>
                <span class="s1">ind = concat([df.index </span><span class="s0">for </span><span class="s1">df </span><span class="s0">in </span><span class="s1">dfs2])</span>
            <span class="s0">return </span><span class="s1">pd.Series(</span>
                <span class="s1">union_categoricals(dfs2</span><span class="s0">, </span><span class="s1">ignore_order=ignore_order)</span><span class="s0">,</span>
                <span class="s1">index=ind</span><span class="s0">,</span>
                <span class="s1">name=dfs2[</span><span class="s5">0</span><span class="s1">].name</span><span class="s0">,</span>
            <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s0">if </span><span class="s1">filter_warning:</span>
                <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">FutureWarning)</span>

            <span class="s1">out = pd.concat(dfs2</span><span class="s0">, </span><span class="s1">join=join</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s4"># Re-add the index if needed</span>
    <span class="s0">if </span><span class="s1">ind </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">out.index = ind</span>
    <span class="s0">return </span><span class="s1">out</span>


<span class="s1">@categorical_dtype_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">categorical_dtype_pandas(categories=</span><span class="s0">None, </span><span class="s1">ordered=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">pd.api.types.CategoricalDtype(categories=categories</span><span class="s0">, </span><span class="s1">ordered=ordered)</span>


<span class="s1">@tolist_dispatch.register((np.ndarray</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index</span><span class="s0">, </span><span class="s1">pd.Categorical))</span>
<span class="s0">def </span><span class="s1">tolist_numpy_or_pandas(obj):</span>
    <span class="s0">return </span><span class="s1">obj.tolist()</span>


<span class="s1">@is_categorical_dtype_dispatch.register(</span>
    <span class="s1">(pd.Series</span><span class="s0">, </span><span class="s1">pd.Index</span><span class="s0">, </span><span class="s1">pd.api.extensions.ExtensionDtype</span><span class="s0">, </span><span class="s1">np.dtype)</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">is_categorical_dtype_pandas(obj):</span>
    <span class="s0">if </span><span class="s1">hasattr(obj</span><span class="s0">, </span><span class="s3">&quot;dtype&quot;</span><span class="s1">):</span>
        <span class="s1">dtype = obj.dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dtype = obj</span>
    <span class="s0">return </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">pd.CategoricalDtype)</span>


<span class="s1">@grouper_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series))</span>
<span class="s0">def </span><span class="s1">get_grouper_pandas(obj):</span>
    <span class="s0">return </span><span class="s1">pd.core.groupby.Grouper</span>


<span class="s1">@percentile_lookup.register((pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">percentile(a</span><span class="s0">, </span><span class="s1">q</span><span class="s0">, </span><span class="s1">interpolation=</span><span class="s3">&quot;linear&quot;</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">_percentile(a</span><span class="s0">, </span><span class="s1">q</span><span class="s0">, </span><span class="s1">interpolation)</span>


<span class="s1">@to_pandas_dispatch.register((pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index))</span>
<span class="s0">def </span><span class="s1">to_pandas_dispatch_from_pandas(data</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s0">return </span><span class="s1">data</span>


<span class="s0">class </span><span class="s1">PandasBackendEntrypoint(DataFrameBackendEntrypoint):</span>
    <span class="s2">&quot;&quot;&quot;Pandas-Backend Entrypoint Class for Dask-DataFrame 
 
    Note that all DataFrame-creation functions are defined 
    and registered 'in-place' within the ``dask.dataframe`` 
    ``io`` module. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s0">def </span><span class="s1">to_backend_dispatch(cls):</span>
        <span class="s0">return </span><span class="s1">to_pandas_dispatch</span>

    <span class="s1">@classmethod</span>
    <span class="s0">def </span><span class="s1">to_backend(cls</span><span class="s0">, </span><span class="s1">data: _Frame</span><span class="s0">, </span><span class="s1">**kwargs):</span>
        <span class="s0">if </span><span class="s1">isinstance(data._meta</span><span class="s0">, </span><span class="s1">(pd.DataFrame</span><span class="s0">, </span><span class="s1">pd.Series</span><span class="s0">, </span><span class="s1">pd.Index)):</span>
            <span class="s4"># Already a pandas-backed collection</span>
            <span class="s0">return </span><span class="s1">data</span>
        <span class="s0">return </span><span class="s1">data.map_partitions(cls.to_backend_dispatch()</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s1">dataframe_creation_dispatch.register_backend(</span><span class="s3">&quot;pandas&quot;</span><span class="s0">, </span><span class="s1">PandasBackendEntrypoint())</span>


<span class="s4">######################################</span>
<span class="s4"># cuDF: Pandas Dataframes on the GPU #</span>
<span class="s4">######################################</span>


<span class="s1">@concat_dispatch.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@hash_object_dispatch.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@group_split_dispatch.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@get_parallel_type.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@meta_nonempty.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@make_meta_dispatch.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@make_meta_obj.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@percentile_lookup.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s1">@tolist_dispatch.register_lazy(</span><span class="s3">&quot;cudf&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">_register_cudf():</span>
    <span class="s0">import </span><span class="s1">dask_cudf  </span><span class="s4"># noqa: F401</span>


<span class="s1">@meta_lib_from_array.register_lazy(</span><span class="s3">&quot;cupy&quot;</span><span class="s1">)</span>
<span class="s1">@tolist_dispatch.register_lazy(</span><span class="s3">&quot;cupy&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">_register_cupy_to_cudf():</span>
    <span class="s4"># Handle cupy.ndarray -&gt; cudf.DataFrame dispatching</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">import </span><span class="s1">cudf</span>
        <span class="s0">import </span><span class="s1">cupy</span>

        <span class="s1">@meta_lib_from_array.register(cupy.ndarray)</span>
        <span class="s0">def </span><span class="s1">meta_lib_from_array_cupy(x):</span>
            <span class="s4"># cupy -&gt; cudf</span>
            <span class="s0">return </span><span class="s1">cudf</span>

        <span class="s1">@tolist_dispatch.register(cupy.ndarray)</span>
        <span class="s0">def </span><span class="s1">tolist_cupy(x):</span>
            <span class="s0">return </span><span class="s1">x.tolist()</span>

    <span class="s0">except </span><span class="s1">ImportError:</span>
        <span class="s0">pass</span>
</pre>
</body>
</html>
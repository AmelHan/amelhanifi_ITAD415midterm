<html>
<head>
<title>test_fit.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_fit.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">os</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">numpy.testing </span><span class="s0">as </span><span class="s1">npt</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_equal</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">stats</span>
<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">differential_evolution</span>

<span class="s0">from </span><span class="s1">.test_continuous_basic </span><span class="s0">import </span><span class="s1">distcont</span>
<span class="s0">from </span><span class="s1">scipy.stats._distn_infrastructure </span><span class="s0">import </span><span class="s1">FitError</span>
<span class="s0">from </span><span class="s1">scipy.stats._distr_params </span><span class="s0">import </span><span class="s1">distdiscrete</span>
<span class="s0">from </span><span class="s1">scipy.stats </span><span class="s0">import </span><span class="s1">goodness_of_fit</span>


<span class="s2"># this is not a proper statistical test for convergence, but only</span>
<span class="s2"># verifies that the estimate and true values don't differ by too much</span>

<span class="s1">fit_sizes = [</span><span class="s3">1000</span><span class="s0">, </span><span class="s3">5000</span><span class="s0">, </span><span class="s3">10000</span><span class="s1">]  </span><span class="s2"># sample sizes to try</span>

<span class="s1">thresh_percent = </span><span class="s3">0.25  </span><span class="s2"># percent of true parameters for fail cut-off</span>
<span class="s1">thresh_min = </span><span class="s3">0.75  </span><span class="s2"># minimum difference estimate - true to fail test</span>

<span class="s1">mle_failing_fits = [</span>
        <span class="s4">'gausshyper'</span><span class="s0">,</span>
        <span class="s4">'genexpon'</span><span class="s0">,</span>
        <span class="s4">'gengamma'</span><span class="s0">,</span>
        <span class="s4">'kappa4'</span><span class="s0">,</span>
        <span class="s4">'ksone'</span><span class="s0">,</span>
        <span class="s4">'kstwo'</span><span class="s0">,</span>
        <span class="s4">'ncf'</span><span class="s0">,</span>
        <span class="s4">'ncx2'</span><span class="s0">,</span>
        <span class="s4">'truncexpon'</span><span class="s0">,</span>
        <span class="s4">'tukeylambda'</span><span class="s0">,</span>
        <span class="s4">'vonmises'</span><span class="s0">,</span>
        <span class="s4">'levy_stable'</span><span class="s0">,</span>
        <span class="s4">'trapezoid'</span><span class="s0">,</span>
        <span class="s4">'truncweibull_min'</span><span class="s0">,</span>
        <span class="s4">'studentized_range'</span><span class="s0">,</span>
<span class="s1">]</span>

<span class="s2"># The MLE fit method of these distributions doesn't perform well when all</span>
<span class="s2"># parameters are fit, so test them with the location fixed at 0.</span>
<span class="s1">mle_use_floc0 = [</span>
    <span class="s4">'burr'</span><span class="s0">,</span>
    <span class="s4">'chi'</span><span class="s0">,</span>
    <span class="s4">'chi2'</span><span class="s0">,</span>
    <span class="s4">'mielke'</span><span class="s0">,</span>
    <span class="s4">'pearson3'</span><span class="s0">,</span>
    <span class="s4">'genhalflogistic'</span><span class="s0">,</span>
    <span class="s4">'rdist'</span><span class="s0">,</span>
    <span class="s4">'pareto'</span><span class="s0">,</span>
    <span class="s4">'powerlaw'</span><span class="s0">,  </span><span class="s2"># distfn.nnlf(est2, rvs) &gt; distfn.nnlf(est1, rvs) otherwise</span>
    <span class="s4">'powerlognorm'</span><span class="s0">,</span>
    <span class="s4">'wrapcauchy'</span><span class="s0">,</span>
    <span class="s4">'rel_breitwigner'</span><span class="s0">,</span>
<span class="s1">]</span>

<span class="s1">mm_failing_fits = [</span><span class="s4">'alpha'</span><span class="s0">, </span><span class="s4">'betaprime'</span><span class="s0">, </span><span class="s4">'burr'</span><span class="s0">, </span><span class="s4">'burr12'</span><span class="s0">, </span><span class="s4">'cauchy'</span><span class="s0">, </span><span class="s4">'chi'</span><span class="s0">,</span>
                   <span class="s4">'chi2'</span><span class="s0">, </span><span class="s4">'crystalball'</span><span class="s0">, </span><span class="s4">'dgamma'</span><span class="s0">, </span><span class="s4">'dweibull'</span><span class="s0">, </span><span class="s4">'f'</span><span class="s0">,</span>
                   <span class="s4">'fatiguelife'</span><span class="s0">, </span><span class="s4">'fisk'</span><span class="s0">, </span><span class="s4">'foldcauchy'</span><span class="s0">, </span><span class="s4">'genextreme'</span><span class="s0">,</span>
                   <span class="s4">'gengamma'</span><span class="s0">, </span><span class="s4">'genhyperbolic'</span><span class="s0">, </span><span class="s4">'gennorm'</span><span class="s0">, </span><span class="s4">'genpareto'</span><span class="s0">,</span>
                   <span class="s4">'halfcauchy'</span><span class="s0">, </span><span class="s4">'invgamma'</span><span class="s0">, </span><span class="s4">'invweibull'</span><span class="s0">, </span><span class="s4">'johnsonsu'</span><span class="s0">,</span>
                   <span class="s4">'kappa3'</span><span class="s0">, </span><span class="s4">'ksone'</span><span class="s0">, </span><span class="s4">'kstwo'</span><span class="s0">, </span><span class="s4">'levy'</span><span class="s0">, </span><span class="s4">'levy_l'</span><span class="s0">,</span>
                   <span class="s4">'levy_stable'</span><span class="s0">, </span><span class="s4">'loglaplace'</span><span class="s0">, </span><span class="s4">'lomax'</span><span class="s0">, </span><span class="s4">'mielke'</span><span class="s0">, </span><span class="s4">'nakagami'</span><span class="s0">,</span>
                   <span class="s4">'ncf'</span><span class="s0">, </span><span class="s4">'nct'</span><span class="s0">, </span><span class="s4">'ncx2'</span><span class="s0">, </span><span class="s4">'pareto'</span><span class="s0">, </span><span class="s4">'powerlognorm'</span><span class="s0">, </span><span class="s4">'powernorm'</span><span class="s0">,</span>
                   <span class="s4">'rel_breitwigner'</span><span class="s0">, </span><span class="s4">'skewcauchy'</span><span class="s0">, </span><span class="s4">'t'</span><span class="s0">, </span><span class="s4">'trapezoid'</span><span class="s0">, </span><span class="s4">'triang'</span><span class="s0">,</span>
                   <span class="s4">'truncpareto'</span><span class="s0">, </span><span class="s4">'truncweibull_min'</span><span class="s0">, </span><span class="s4">'tukeylambda'</span><span class="s0">,</span>
                   <span class="s4">'studentized_range'</span><span class="s1">]</span>

<span class="s2"># not sure if these fail, but they caused my patience to fail</span>
<span class="s1">mm_slow_fits = [</span><span class="s4">'argus'</span><span class="s0">, </span><span class="s4">'exponpow'</span><span class="s0">, </span><span class="s4">'exponweib'</span><span class="s0">, </span><span class="s4">'gausshyper'</span><span class="s0">, </span><span class="s4">'genexpon'</span><span class="s0">,</span>
                <span class="s4">'genhalflogistic'</span><span class="s0">, </span><span class="s4">'halfgennorm'</span><span class="s0">, </span><span class="s4">'gompertz'</span><span class="s0">, </span><span class="s4">'johnsonsb'</span><span class="s0">,</span>
                <span class="s4">'kappa4'</span><span class="s0">, </span><span class="s4">'kstwobign'</span><span class="s0">, </span><span class="s4">'recipinvgauss'</span><span class="s0">,</span>
                <span class="s4">'truncexpon'</span><span class="s0">, </span><span class="s4">'vonmises'</span><span class="s0">, </span><span class="s4">'vonmises_line'</span><span class="s1">]</span>

<span class="s1">failing_fits = {</span><span class="s4">&quot;MM&quot;</span><span class="s1">: mm_failing_fits + mm_slow_fits</span><span class="s0">, </span><span class="s4">&quot;MLE&quot;</span><span class="s1">: mle_failing_fits}</span>
<span class="s1">fail_interval_censored = {</span><span class="s4">&quot;truncpareto&quot;</span><span class="s1">}</span>

<span class="s2"># Don't run the fit test on these:</span>
<span class="s1">skip_fit = [</span>
    <span class="s4">'erlang'</span><span class="s0">,  </span><span class="s2"># Subclass of gamma, generates a warning.</span>
    <span class="s4">'genhyperbolic'</span><span class="s0">,  </span><span class="s2"># too slow</span>
<span class="s1">]</span>


<span class="s0">def </span><span class="s1">cases_test_cont_fit():</span>
    <span class="s2"># this tests the closeness of the estimated parameters to the true</span>
    <span class="s2"># parameters with fit method of continuous distributions</span>
    <span class="s2"># Note: is slow, some distributions don't converge with sample</span>
    <span class="s2"># size &lt;= 10000</span>
    <span class="s0">for </span><span class="s1">distname</span><span class="s0">, </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">distcont:</span>
        <span class="s0">if </span><span class="s1">distname </span><span class="s0">not in </span><span class="s1">skip_fit:</span>
            <span class="s0">yield </span><span class="s1">distname</span><span class="s0">, </span><span class="s1">arg</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">'distname,arg'</span><span class="s0">, </span><span class="s1">cases_test_cont_fit())</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">'method'</span><span class="s0">, </span><span class="s1">[</span><span class="s4">&quot;MLE&quot;</span><span class="s0">, </span><span class="s4">&quot;MM&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_cont_fit(distname</span><span class="s0">, </span><span class="s1">arg</span><span class="s0">, </span><span class="s1">method):</span>
    <span class="s0">if </span><span class="s1">distname </span><span class="s0">in </span><span class="s1">failing_fits[method]:</span>
        <span class="s2"># Skip failing fits unless overridden</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">xfail = </span><span class="s0">not </span><span class="s1">int(os.environ[</span><span class="s4">'SCIPY_XFAIL'</span><span class="s1">])</span>
        <span class="s0">except </span><span class="s1">Exception:</span>
            <span class="s1">xfail = </span><span class="s0">True</span>
        <span class="s0">if </span><span class="s1">xfail:</span>
            <span class="s1">msg = </span><span class="s4">&quot;Fitting %s doesn't work reliably yet&quot; </span><span class="s1">% distname</span>
            <span class="s1">msg += (</span><span class="s4">&quot; [Set environment variable SCIPY_XFAIL=1 to run this&quot;</span>
                    <span class="s4">&quot; test nevertheless.]&quot;</span><span class="s1">)</span>
            <span class="s1">pytest.xfail(msg)</span>

    <span class="s1">distfn = getattr(stats</span><span class="s0">, </span><span class="s1">distname)</span>

    <span class="s1">truearg = np.hstack([arg</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">]])</span>
    <span class="s1">diffthreshold = np.max(np.vstack([truearg*thresh_percent</span><span class="s0">,</span>
                                      <span class="s1">np.full(distfn.numargs+</span><span class="s3">2</span><span class="s0">, </span><span class="s1">thresh_min)])</span><span class="s0">,</span>
                           <span class="s3">0</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">fit_size </span><span class="s0">in </span><span class="s1">fit_sizes:</span>
        <span class="s2"># Note that if a fit succeeds, the other fit_sizes are skipped</span>
        <span class="s1">np.random.seed(</span><span class="s3">1234</span><span class="s1">)</span>

        <span class="s0">with </span><span class="s1">np.errstate(all=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">rvs = distfn.rvs(size=fit_size</span><span class="s0">, </span><span class="s1">*arg)</span>
            <span class="s0">if </span><span class="s1">method == </span><span class="s4">'MLE' </span><span class="s0">and </span><span class="s1">distfn.name </span><span class="s0">in </span><span class="s1">mle_use_floc0:</span>
                <span class="s1">kwds = {</span><span class="s4">'floc'</span><span class="s1">: </span><span class="s3">0</span><span class="s1">}</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">kwds = {}</span>
            <span class="s2"># start with default values</span>
            <span class="s1">est = distfn.fit(rvs</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">, </span><span class="s1">**kwds)</span>
            <span class="s0">if </span><span class="s1">method == </span><span class="s4">'MLE'</span><span class="s1">:</span>
                <span class="s2"># Trivial test of the use of CensoredData.  The fit() method</span>
                <span class="s2"># will check that data contains no actual censored data, and</span>
                <span class="s2"># do a regular uncensored fit.</span>
                <span class="s1">data1 = stats.CensoredData(rvs)</span>
                <span class="s1">est1 = distfn.fit(data1</span><span class="s0">, </span><span class="s1">**kwds)</span>
                <span class="s1">msg = (</span><span class="s4">'Different results fitting uncensored data wrapped as'</span>
                       <span class="s4">f' CensoredData: </span><span class="s0">{</span><span class="s1">distfn.name</span><span class="s0">}</span><span class="s4">: est=</span><span class="s0">{</span><span class="s1">est</span><span class="s0">} </span><span class="s4">est1=</span><span class="s0">{</span><span class="s1">est1</span><span class="s0">}</span><span class="s4">'</span><span class="s1">)</span>
                <span class="s1">assert_allclose(est1</span><span class="s0">, </span><span class="s1">est</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-10</span><span class="s0">, </span><span class="s1">err_msg=msg)</span>
            <span class="s0">if </span><span class="s1">method == </span><span class="s4">'MLE' </span><span class="s0">and </span><span class="s1">distname </span><span class="s0">not in </span><span class="s1">fail_interval_censored:</span>
                <span class="s2"># Convert the first `nic` values in rvs to interval-censored</span>
                <span class="s2"># values. The interval is small, so est2 should be close to</span>
                <span class="s2"># est.</span>
                <span class="s1">nic = </span><span class="s3">15</span>
                <span class="s1">interval = np.column_stack((rvs</span><span class="s0">, </span><span class="s1">rvs))</span>
                <span class="s1">interval[:nic</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] *= </span><span class="s3">0.99</span>
                <span class="s1">interval[:nic</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] *= </span><span class="s3">1.01</span>
                <span class="s1">interval.sort(axis=</span><span class="s3">1</span><span class="s1">)</span>
                <span class="s1">data2 = stats.CensoredData(interval=interval)</span>
                <span class="s1">est2 = distfn.fit(data2</span><span class="s0">, </span><span class="s1">**kwds)</span>
                <span class="s1">msg = (</span><span class="s4">'Different results fitting interval-censored'</span>
                       <span class="s4">f' data: </span><span class="s0">{</span><span class="s1">distfn.name</span><span class="s0">}</span><span class="s4">: est=</span><span class="s0">{</span><span class="s1">est</span><span class="s0">} </span><span class="s4">est2=</span><span class="s0">{</span><span class="s1">est2</span><span class="s0">}</span><span class="s4">'</span><span class="s1">)</span>
                <span class="s1">assert_allclose(est2</span><span class="s0">, </span><span class="s1">est</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">0.05</span><span class="s0">, </span><span class="s1">err_msg=msg)</span>

        <span class="s1">diff = est - truearg</span>

        <span class="s2"># threshold for location</span>
        <span class="s1">diffthreshold[-</span><span class="s3">2</span><span class="s1">] = np.max([np.abs(rvs.mean())*thresh_percent</span><span class="s0">,</span>
                                    <span class="s1">thresh_min])</span>

        <span class="s0">if </span><span class="s1">np.any(np.isnan(est)):</span>
            <span class="s0">raise </span><span class="s1">AssertionError(</span><span class="s4">'nan returned in fit'</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">np.all(np.abs(diff) &lt;= diffthreshold):</span>
                <span class="s0">break</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">txt = </span><span class="s4">'parameter: %s</span><span class="s0">\n</span><span class="s4">' </span><span class="s1">% str(truearg)</span>
        <span class="s1">txt += </span><span class="s4">'estimated: %s</span><span class="s0">\n</span><span class="s4">' </span><span class="s1">% str(est)</span>
        <span class="s1">txt += </span><span class="s4">'diff     : %s</span><span class="s0">\n</span><span class="s4">' </span><span class="s1">% str(diff)</span>
        <span class="s0">raise </span><span class="s1">AssertionError(</span><span class="s4">'fit not very good in %s</span><span class="s0">\n</span><span class="s4">' </span><span class="s1">% distfn.name + txt)</span>


<span class="s0">def </span><span class="s1">_check_loc_scale_mle_fit(name</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">desired</span><span class="s0">, </span><span class="s1">atol=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s1">d = getattr(stats</span><span class="s0">, </span><span class="s1">name)</span>
    <span class="s1">actual = d.fit(data)[-</span><span class="s3">2</span><span class="s1">:]</span>
    <span class="s1">assert_allclose(actual</span><span class="s0">, </span><span class="s1">desired</span><span class="s0">, </span><span class="s1">atol=atol</span><span class="s0">,</span>
                    <span class="s1">err_msg=</span><span class="s4">'poor mle fit of (loc, scale) in %s' </span><span class="s1">% name)</span>


<span class="s0">def </span><span class="s1">test_non_default_loc_scale_mle_fit():</span>
    <span class="s1">data = np.array([</span><span class="s3">1.01</span><span class="s0">, </span><span class="s3">1.78</span><span class="s0">, </span><span class="s3">1.78</span><span class="s0">, </span><span class="s3">1.78</span><span class="s0">, </span><span class="s3">1.88</span><span class="s0">, </span><span class="s3">1.88</span><span class="s0">, </span><span class="s3">1.88</span><span class="s0">, </span><span class="s3">2.00</span><span class="s1">])</span>
    <span class="s1">_check_loc_scale_mle_fit(</span><span class="s4">'uniform'</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.01</span><span class="s0">, </span><span class="s3">0.99</span><span class="s1">]</span><span class="s0">, </span><span class="s3">1e-3</span><span class="s1">)</span>
    <span class="s1">_check_loc_scale_mle_fit(</span><span class="s4">'expon'</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.01</span><span class="s0">, </span><span class="s3">0.73875</span><span class="s1">]</span><span class="s0">, </span><span class="s3">1e-3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_expon_fit():</span>
    <span class="s5">&quot;&quot;&quot;gh-6167&quot;&quot;&quot;</span>
    <span class="s1">data = [</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span>
    <span class="s1">phat = stats.expon.fit(data</span><span class="s0">, </span><span class="s1">floc=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(phat</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_fit_error():</span>
    <span class="s1">data = np.concatenate([np.zeros(</span><span class="s3">29</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.ones(</span><span class="s3">21</span><span class="s1">)])</span>
    <span class="s1">message = </span><span class="s4">&quot;Optimization converged to parameters that are...&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(FitError</span><span class="s0">, </span><span class="s1">match=message)</span><span class="s0">, </span><span class="s1">\</span>
            <span class="s1">pytest.warns(RuntimeWarning):</span>
        <span class="s1">stats.beta.fit(data)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;dist, params&quot;</span><span class="s0">,</span>
                         <span class="s1">[(stats.norm</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">2.5</span><span class="s1">))</span><span class="s0">,  </span><span class="s2"># type: ignore[attr-defined] # noqa</span>
                          <span class="s1">(stats.binom</span><span class="s0">, </span><span class="s1">(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))])  </span><span class="s2"># type: ignore[attr-defined] # noqa</span>
<span class="s0">def </span><span class="s1">test_nnlf_and_related_methods(dist</span><span class="s0">, </span><span class="s1">params):</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">983459824</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">hasattr(dist</span><span class="s0">, </span><span class="s4">'pdf'</span><span class="s1">):</span>
        <span class="s1">logpxf = dist.logpdf</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">logpxf = dist.logpmf</span>

    <span class="s1">x = dist.rvs(*params</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
    <span class="s1">ref = -logpxf(x</span><span class="s0">, </span><span class="s1">*params).sum()</span>
    <span class="s1">res1 = dist.nnlf(params</span><span class="s0">, </span><span class="s1">x)</span>
    <span class="s1">res2 = dist._penalized_nnlf(params</span><span class="s0">, </span><span class="s1">x)</span>
    <span class="s1">assert_allclose(res1</span><span class="s0">, </span><span class="s1">ref)</span>
    <span class="s1">assert_allclose(res2</span><span class="s0">, </span><span class="s1">ref)</span>


<span class="s0">def </span><span class="s1">cases_test_fit_mle():</span>
    <span class="s2"># These fail default test or hang</span>
    <span class="s1">skip_basic_fit = {</span><span class="s4">'argus'</span><span class="s0">, </span><span class="s4">'foldnorm'</span><span class="s0">, </span><span class="s4">'truncpareto'</span><span class="s0">, </span><span class="s4">'truncweibull_min'</span><span class="s0">,</span>
                      <span class="s4">'ksone'</span><span class="s0">, </span><span class="s4">'levy_stable'</span><span class="s0">, </span><span class="s4">'studentized_range'</span><span class="s0">, </span><span class="s4">'kstwo'</span><span class="s1">}</span>

    <span class="s2"># Please keep this list in alphabetical order...</span>
    <span class="s1">slow_basic_fit = {</span><span class="s4">'alpha'</span><span class="s0">, </span><span class="s4">'arcsine'</span><span class="s0">,</span>
                      <span class="s4">'betaprime'</span><span class="s0">, </span><span class="s4">'binom'</span><span class="s0">, </span><span class="s4">'bradford'</span><span class="s0">, </span><span class="s4">'burr12'</span><span class="s0">,</span>
                      <span class="s4">'chi'</span><span class="s0">, </span><span class="s4">'crystalball'</span><span class="s0">, </span><span class="s4">'dweibull'</span><span class="s0">, </span><span class="s4">'exponpow'</span><span class="s0">,</span>
                      <span class="s4">'f'</span><span class="s0">, </span><span class="s4">'fatiguelife'</span><span class="s0">, </span><span class="s4">'fisk'</span><span class="s0">, </span><span class="s4">'foldcauchy'</span><span class="s0">,</span>
                      <span class="s4">'genexpon'</span><span class="s0">, </span><span class="s4">'genextreme'</span><span class="s0">, </span><span class="s4">'gennorm'</span><span class="s0">, </span><span class="s4">'genpareto'</span><span class="s0">,</span>
                      <span class="s4">'gompertz'</span><span class="s0">, </span><span class="s4">'halfgennorm'</span><span class="s0">, </span><span class="s4">'invgauss'</span><span class="s0">, </span><span class="s4">'invweibull'</span><span class="s0">,</span>
                      <span class="s4">'johnsonsb'</span><span class="s0">, </span><span class="s4">'johnsonsu'</span><span class="s0">, </span><span class="s4">'kappa3'</span><span class="s0">, </span><span class="s4">'kstwobign'</span><span class="s0">,</span>
                      <span class="s4">'loglaplace'</span><span class="s0">, </span><span class="s4">'lognorm'</span><span class="s0">, </span><span class="s4">'lomax'</span><span class="s0">, </span><span class="s4">'mielke'</span><span class="s0">,</span>
                      <span class="s4">'nakagami'</span><span class="s0">, </span><span class="s4">'nbinom'</span><span class="s0">, </span><span class="s4">'norminvgauss'</span><span class="s0">,</span>
                      <span class="s4">'pareto'</span><span class="s0">, </span><span class="s4">'pearson3'</span><span class="s0">, </span><span class="s4">'powerlaw'</span><span class="s0">, </span><span class="s4">'powernorm'</span><span class="s0">,</span>
                      <span class="s4">'randint'</span><span class="s0">, </span><span class="s4">'rdist'</span><span class="s0">, </span><span class="s4">'recipinvgauss'</span><span class="s0">, </span><span class="s4">'rice'</span><span class="s0">,</span>
                      <span class="s4">'t'</span><span class="s0">, </span><span class="s4">'uniform'</span><span class="s0">, </span><span class="s4">'weibull_max'</span><span class="s0">, </span><span class="s4">'wrapcauchy'</span><span class="s1">}</span>

    <span class="s2"># Please keep this list in alphabetical order...</span>
    <span class="s1">xslow_basic_fit = {</span><span class="s4">'beta'</span><span class="s0">, </span><span class="s4">'betabinom'</span><span class="s0">, </span><span class="s4">'burr'</span><span class="s0">, </span><span class="s4">'exponweib'</span><span class="s0">,</span>
                       <span class="s4">'gausshyper'</span><span class="s0">, </span><span class="s4">'gengamma'</span><span class="s0">, </span><span class="s4">'genhalflogistic'</span><span class="s0">,</span>
                       <span class="s4">'genhyperbolic'</span><span class="s0">, </span><span class="s4">'geninvgauss'</span><span class="s0">,</span>
                       <span class="s4">'hypergeom'</span><span class="s0">, </span><span class="s4">'kappa4'</span><span class="s0">, </span><span class="s4">'loguniform'</span><span class="s0">,</span>
                       <span class="s4">'ncf'</span><span class="s0">, </span><span class="s4">'nchypergeom_fisher'</span><span class="s0">, </span><span class="s4">'nchypergeom_wallenius'</span><span class="s0">,</span>
                       <span class="s4">'nct'</span><span class="s0">, </span><span class="s4">'ncx2'</span><span class="s0">, </span><span class="s4">'nhypergeom'</span><span class="s0">,</span>
                       <span class="s4">'powerlognorm'</span><span class="s0">, </span><span class="s4">'reciprocal'</span><span class="s0">, </span><span class="s4">'rel_breitwigner'</span><span class="s0">,</span>
                       <span class="s4">'skellam'</span><span class="s0">, </span><span class="s4">'trapezoid'</span><span class="s0">, </span><span class="s4">'triang'</span><span class="s0">, </span><span class="s4">'truncnorm'</span><span class="s0">,</span>
                       <span class="s4">'tukeylambda'</span><span class="s0">, </span><span class="s4">'zipfian'</span><span class="s1">}</span>

    <span class="s0">for </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">dict(distdiscrete + distcont):</span>
        <span class="s0">if </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">skip_basic_fit </span><span class="s0">or not </span><span class="s1">isinstance(dist</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">reason = </span><span class="s4">&quot;tested separately&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.skip(reason=reason))</span>
        <span class="s0">elif </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">slow_basic_fit:</span>
            <span class="s1">reason = </span><span class="s4">&quot;too slow (&gt;= 0.25s)&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.slow(reason=reason))</span>
        <span class="s0">elif </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">xslow_basic_fit:</span>
            <span class="s1">reason = </span><span class="s4">&quot;too slow (&gt;= 1.0s)&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.xslow(reason=reason))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">yield </span><span class="s1">dist</span>


<span class="s0">def </span><span class="s1">cases_test_fit_mse():</span>
    <span class="s2"># the first four are so slow that I'm not sure whether they would pass</span>
    <span class="s1">skip_basic_fit = {</span><span class="s4">'levy_stable'</span><span class="s0">, </span><span class="s4">'studentized_range'</span><span class="s0">, </span><span class="s4">'ksone'</span><span class="s0">, </span><span class="s4">'skewnorm'</span><span class="s0">,</span>
                      <span class="s4">'norminvgauss'</span><span class="s0">,  </span><span class="s2"># super slow (~1 hr) but passes</span>
                      <span class="s4">'kstwo'</span><span class="s0">,  </span><span class="s2"># very slow (~25 min) but passes</span>
                      <span class="s4">'geninvgauss'</span><span class="s0">,  </span><span class="s2"># quite slow (~4 minutes) but passes</span>
                      <span class="s4">'gausshyper'</span><span class="s0">, </span><span class="s4">'genhyperbolic'</span><span class="s0">,  </span><span class="s2"># integration warnings</span>
                      <span class="s4">'argus'</span><span class="s0">,  </span><span class="s2"># close, but doesn't meet tolerance</span>
                      <span class="s4">'vonmises'</span><span class="s1">}  </span><span class="s2"># can have negative CDF; doesn't play nice</span>

    <span class="s2"># Please keep this list in alphabetical order...</span>
    <span class="s1">slow_basic_fit = {</span><span class="s4">'alpha'</span><span class="s0">, </span><span class="s4">'anglit'</span><span class="s0">, </span><span class="s4">'arcsine'</span><span class="s0">, </span><span class="s4">'betabinom'</span><span class="s0">, </span><span class="s4">'bradford'</span><span class="s0">,</span>
                      <span class="s4">'chi'</span><span class="s0">, </span><span class="s4">'chi2'</span><span class="s0">, </span><span class="s4">'crystalball'</span><span class="s0">, </span><span class="s4">'dgamma'</span><span class="s0">, </span><span class="s4">'dweibull'</span><span class="s0">,</span>
                      <span class="s4">'erlang'</span><span class="s0">, </span><span class="s4">'exponnorm'</span><span class="s0">, </span><span class="s4">'exponpow'</span><span class="s0">, </span><span class="s4">'exponweib'</span><span class="s0">,</span>
                      <span class="s4">'fatiguelife'</span><span class="s0">, </span><span class="s4">'fisk'</span><span class="s0">, </span><span class="s4">'foldcauchy'</span><span class="s0">, </span><span class="s4">'foldnorm'</span><span class="s0">,</span>
                      <span class="s4">'gamma'</span><span class="s0">, </span><span class="s4">'genexpon'</span><span class="s0">, </span><span class="s4">'genextreme'</span><span class="s0">, </span><span class="s4">'genhalflogistic'</span><span class="s0">,</span>
                      <span class="s4">'genlogistic'</span><span class="s0">, </span><span class="s4">'genpareto'</span><span class="s0">, </span><span class="s4">'gompertz'</span><span class="s0">,</span>
                      <span class="s4">'hypergeom'</span><span class="s0">, </span><span class="s4">'invweibull'</span><span class="s0">, </span><span class="s4">'johnsonsb'</span><span class="s0">, </span><span class="s4">'johnsonsu'</span><span class="s0">,</span>
                      <span class="s4">'kappa3'</span><span class="s0">, </span><span class="s4">'kstwobign'</span><span class="s0">,</span>
                      <span class="s4">'laplace_asymmetric'</span><span class="s0">, </span><span class="s4">'loggamma'</span><span class="s0">, </span><span class="s4">'loglaplace'</span><span class="s0">,</span>
                      <span class="s4">'lognorm'</span><span class="s0">, </span><span class="s4">'lomax'</span><span class="s0">,</span>
                      <span class="s4">'maxwell'</span><span class="s0">, </span><span class="s4">'mielke'</span><span class="s0">, </span><span class="s4">'nakagami'</span><span class="s0">, </span><span class="s4">'nhypergeom'</span><span class="s0">,</span>
                      <span class="s4">'pareto'</span><span class="s0">, </span><span class="s4">'powernorm'</span><span class="s0">, </span><span class="s4">'randint'</span><span class="s0">, </span><span class="s4">'recipinvgauss'</span><span class="s0">,</span>
                      <span class="s4">'semicircular'</span><span class="s0">,</span>
                      <span class="s4">'t'</span><span class="s0">, </span><span class="s4">'triang'</span><span class="s0">, </span><span class="s4">'truncexpon'</span><span class="s0">, </span><span class="s4">'truncpareto'</span><span class="s0">,</span>
                      <span class="s4">'truncweibull_min'</span><span class="s0">,</span>
                      <span class="s4">'uniform'</span><span class="s0">, </span><span class="s4">'vonmises_line'</span><span class="s0">,</span>
                      <span class="s4">'wald'</span><span class="s0">, </span><span class="s4">'weibull_max'</span><span class="s0">, </span><span class="s4">'weibull_min'</span><span class="s0">, </span><span class="s4">'wrapcauchy'</span><span class="s1">}</span>

    <span class="s2"># Please keep this list in alphabetical order...</span>
    <span class="s1">xslow_basic_fit = {</span><span class="s4">'beta'</span><span class="s0">, </span><span class="s4">'betaprime'</span><span class="s0">, </span><span class="s4">'burr'</span><span class="s0">, </span><span class="s4">'burr12'</span><span class="s0">,</span>
                       <span class="s4">'f'</span><span class="s0">, </span><span class="s4">'gengamma'</span><span class="s0">, </span><span class="s4">'gennorm'</span><span class="s0">,</span>
                       <span class="s4">'halfgennorm'</span><span class="s0">, </span><span class="s4">'invgamma'</span><span class="s0">, </span><span class="s4">'invgauss'</span><span class="s0">,</span>
                       <span class="s4">'kappa4'</span><span class="s0">, </span><span class="s4">'loguniform'</span><span class="s0">,</span>
                       <span class="s4">'ncf'</span><span class="s0">, </span><span class="s4">'nchypergeom_fisher'</span><span class="s0">, </span><span class="s4">'nchypergeom_wallenius'</span><span class="s0">,</span>
                       <span class="s4">'nct'</span><span class="s0">, </span><span class="s4">'ncx2'</span><span class="s0">,</span>
                       <span class="s4">'pearson3'</span><span class="s0">, </span><span class="s4">'powerlaw'</span><span class="s0">, </span><span class="s4">'powerlognorm'</span><span class="s0">,</span>
                       <span class="s4">'rdist'</span><span class="s0">, </span><span class="s4">'reciprocal'</span><span class="s0">, </span><span class="s4">'rel_breitwigner'</span><span class="s0">, </span><span class="s4">'rice'</span><span class="s0">,</span>
                       <span class="s4">'trapezoid'</span><span class="s0">, </span><span class="s4">'truncnorm'</span><span class="s0">, </span><span class="s4">'tukeylambda'</span><span class="s0">,</span>
                       <span class="s4">'zipfian'</span><span class="s1">}</span>

    <span class="s1">warns_basic_fit = {</span><span class="s4">'skellam'</span><span class="s1">}  </span><span class="s2"># can remove mark after gh-14901 is resolved</span>

    <span class="s0">for </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">dict(distdiscrete + distcont):</span>
        <span class="s0">if </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">skip_basic_fit </span><span class="s0">or not </span><span class="s1">isinstance(dist</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">reason = </span><span class="s4">&quot;Fails. Oh well.&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.skip(reason=reason))</span>
        <span class="s0">elif </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">slow_basic_fit:</span>
            <span class="s1">reason = </span><span class="s4">&quot;too slow (&gt;= 0.25s)&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.slow(reason=reason))</span>
        <span class="s0">elif </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">xslow_basic_fit:</span>
            <span class="s1">reason = </span><span class="s4">&quot;too slow (&gt;= 1.0s)&quot;</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=pytest.mark.xslow(reason=reason))</span>
        <span class="s0">elif </span><span class="s1">dist </span><span class="s0">in </span><span class="s1">warns_basic_fit:</span>
            <span class="s1">mark = pytest.mark.filterwarnings(</span><span class="s4">'ignore::RuntimeWarning'</span><span class="s1">)</span>
            <span class="s0">yield </span><span class="s1">pytest.param(dist</span><span class="s0">, </span><span class="s1">marks=mark)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">yield </span><span class="s1">dist</span>


<span class="s0">def </span><span class="s1">cases_test_fitstart():</span>
    <span class="s0">for </span><span class="s1">distname</span><span class="s0">, </span><span class="s1">shapes </span><span class="s0">in </span><span class="s1">dict(distcont).items():</span>
        <span class="s0">if </span><span class="s1">(</span><span class="s0">not </span><span class="s1">isinstance(distname</span><span class="s0">, </span><span class="s1">str) </span><span class="s0">or</span>
                <span class="s1">distname </span><span class="s0">in </span><span class="s1">{</span><span class="s4">'studentized_range'</span><span class="s0">, </span><span class="s4">'recipinvgauss'</span><span class="s1">}):  </span><span class="s2"># slow</span>
            <span class="s0">continue</span>
        <span class="s0">yield </span><span class="s1">distname</span><span class="s0">, </span><span class="s1">shapes</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">'distname, shapes'</span><span class="s0">, </span><span class="s1">cases_test_fitstart())</span>
<span class="s0">def </span><span class="s1">test_fitstart(distname</span><span class="s0">, </span><span class="s1">shapes):</span>
    <span class="s1">dist = getattr(stats</span><span class="s0">, </span><span class="s1">distname)</span>
    <span class="s1">rng = np.random.default_rng(</span><span class="s3">216342614</span><span class="s1">)</span>
    <span class="s1">data = rng.random(</span><span class="s3">10</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">np.errstate(invalid=</span><span class="s4">'ignore'</span><span class="s0">, </span><span class="s1">divide=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s2"># irrelevant to test</span>
        <span class="s1">guess = dist._fitstart(data)</span>

    <span class="s0">assert </span><span class="s1">dist._argcheck(*guess[:-</span><span class="s3">2</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">params1</span><span class="s0">, </span><span class="s1">params0</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-7</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">0</span><span class="s0">,</span>
                              <span class="s1">nlff_name=</span><span class="s4">'nnlf'</span><span class="s1">):</span>
    <span class="s1">nlff = getattr(dist</span><span class="s0">, </span><span class="s1">nlff_name)</span>
    <span class="s1">nlff1 = nlff(params1</span><span class="s0">, </span><span class="s1">data)</span>
    <span class="s1">nlff0 = nlff(params0</span><span class="s0">, </span><span class="s1">data)</span>
    <span class="s0">if not </span><span class="s1">(nlff1 &lt; nlff0):</span>
        <span class="s1">np.testing.assert_allclose(nlff1</span><span class="s0">, </span><span class="s1">nlff0</span><span class="s0">, </span><span class="s1">rtol=rtol</span><span class="s0">, </span><span class="s1">atol=atol)</span>


<span class="s0">class </span><span class="s1">TestFit:</span>
    <span class="s1">dist = stats.binom  </span><span class="s2"># type: ignore[attr-defined]</span>
    <span class="s1">seed = </span><span class="s3">654634816187</span>
    <span class="s1">rng = np.random.default_rng(seed)</span>
    <span class="s1">data = stats.binom.rvs(</span><span class="s3">5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)  </span><span class="s2"># type: ignore[attr-defined] # noqa</span>
    <span class="s1">shape_bounds_a = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
    <span class="s1">shape_bounds_d = {</span><span class="s4">'n'</span><span class="s1">: (</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)}</span>
    <span class="s1">atol = </span><span class="s3">5e-2</span>
    <span class="s1">rtol = </span><span class="s3">1e-2</span>
    <span class="s1">tols = {</span><span class="s4">'atol'</span><span class="s1">: atol</span><span class="s0">, </span><span class="s4">'rtol'</span><span class="s1">: rtol}</span>

    <span class="s0">def </span><span class="s1">opt(self</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds):</span>
        <span class="s0">return </span><span class="s1">differential_evolution(*args</span><span class="s0">, </span><span class="s1">seed=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">**kwds)</span>

    <span class="s0">def </span><span class="s1">test_dist_iv(self):</span>
        <span class="s1">message = </span><span class="s4">&quot;`dist` must be an instance of...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(</span><span class="s3">10</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_a)</span>

    <span class="s0">def </span><span class="s1">test_data_iv(self):</span>
        <span class="s1">message = </span><span class="s4">&quot;`data` must be exactly one-dimensional.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">[[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]]</span><span class="s0">, </span><span class="s1">self.shape_bounds_a)</span>

        <span class="s1">message = </span><span class="s4">&quot;All elements of `data` must be finite numbers.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">np.nan]</span><span class="s0">, </span><span class="s1">self.shape_bounds_a)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">np.inf]</span><span class="s0">, </span><span class="s1">self.shape_bounds_a)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">[</span><span class="s4">'1'</span><span class="s0">, </span><span class="s4">'2'</span><span class="s0">, </span><span class="s4">'3'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">self.shape_bounds_a)</span>

    <span class="s0">def </span><span class="s1">test_bounds_iv(self):</span>
        <span class="s1">message = </span><span class="s4">&quot;Bounds provided for the following unrecognized...&quot;</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'n'</span><span class="s1">: (</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'1'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)}</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;Each element of a `bounds` sequence must be a tuple...&quot;</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;Each element of `bounds` must be a tuple specifying...&quot;</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>
        <span class="s1">shape_bounds = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;A `bounds` sequence must contain at least 2 elements...&quot;</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;A `bounds` sequence may not contain more than 3 elements...&quot;</span>
        <span class="s1">bounds = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;There are no values for `p` on the interval...&quot;</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'n'</span><span class="s1">: (</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: (</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)}</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;There are no values for `n` on the interval...&quot;</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;There are no integer values for `n` on the interval...&quot;</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">1.4</span><span class="s0">, </span><span class="s3">1.6</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

        <span class="s1">message = </span><span class="s4">&quot;The intersection of user-provided bounds for `n`&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data)</span>
        <span class="s1">shape_bounds = [(-np.inf</span><span class="s0">, </span><span class="s1">np.inf)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">shape_bounds)</span>

    <span class="s0">def </span><span class="s1">test_guess_iv(self):</span>
        <span class="s1">message = </span><span class="s4">&quot;Guesses provided for the following unrecognized...&quot;</span>
        <span class="s1">guess = {</span><span class="s4">'n'</span><span class="s1">: </span><span class="s3">1</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: </span><span class="s3">0.5</span><span class="s0">, </span><span class="s4">'1'</span><span class="s1">: </span><span class="s3">255</span><span class="s1">}</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;Each element of `guess` must be a scalar...&quot;</span>
        <span class="s1">guess = {</span><span class="s4">'n'</span><span class="s1">: </span><span class="s3">1</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: </span><span class="s4">'hi'</span><span class="s1">}</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>
        <span class="s1">guess = [</span><span class="s3">1</span><span class="s0">, </span><span class="s4">'f'</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>
        <span class="s1">guess = [[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;A `guess` sequence must contain at least 2...&quot;</span>
        <span class="s1">guess = [</span><span class="s3">1</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;A `guess` sequence may not contain more than 3...&quot;</span>
        <span class="s1">guess = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;Guess for parameter `n` rounded...&quot;</span>
        <span class="s1">guess = {</span><span class="s4">'n'</span><span class="s1">: </span><span class="s3">4.5</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: -</span><span class="s3">0.5</span><span class="s1">}</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;Guess for parameter `loc` rounded...&quot;</span>
        <span class="s1">guess = [</span><span class="s3">5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;Guess for parameter `p` clipped...&quot;</span>
        <span class="s1">guess = {</span><span class="s4">'n'</span><span class="s1">: </span><span class="s3">5</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: -</span><span class="s3">0.5</span><span class="s1">}</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

        <span class="s1">message = </span><span class="s4">&quot;Guess for parameter `loc` clipped...&quot;</span>
        <span class="s1">guess = [</span><span class="s3">5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span>
        <span class="s0">with </span><span class="s1">pytest.warns(RuntimeWarning</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">stats.fit(self.dist</span><span class="s0">, </span><span class="s1">self.data</span><span class="s0">, </span><span class="s1">self.shape_bounds_d</span><span class="s0">, </span><span class="s1">guess=guess)</span>

    <span class="s0">def </span><span class="s1">basic_fit_test(self</span><span class="s0">, </span><span class="s1">dist_name</span><span class="s0">, </span><span class="s1">method):</span>

        <span class="s1">N = </span><span class="s3">5000</span>
        <span class="s1">dist_data = dict(distcont + distdiscrete)</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = getattr(stats</span><span class="s0">, </span><span class="s1">dist_name)</span>
        <span class="s1">shapes = np.array(dist_data[dist_name])</span>
        <span class="s1">bounds = np.empty((len(shapes) + </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">bounds[:-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s1">] = shapes/</span><span class="s3">10.</span><span class="s1">**np.sign(shapes)</span>
        <span class="s1">bounds[:-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] = shapes*</span><span class="s3">10.</span><span class="s1">**np.sign(shapes)</span>
        <span class="s1">bounds[-</span><span class="s3">2</span><span class="s1">] = (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">bounds[-</span><span class="s3">1</span><span class="s1">] = (</span><span class="s3">1e-16</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span>
        <span class="s1">loc = rng.uniform(*bounds[-</span><span class="s3">2</span><span class="s1">])</span>
        <span class="s1">scale = rng.uniform(*bounds[-</span><span class="s3">1</span><span class="s1">])</span>
        <span class="s1">ref = list(dist_data[dist_name]) + [loc</span><span class="s0">, </span><span class="s1">scale]</span>

        <span class="s0">if </span><span class="s1">getattr(dist</span><span class="s0">, </span><span class="s4">'pmf'</span><span class="s0">, False</span><span class="s1">):</span>
            <span class="s1">ref = ref[:-</span><span class="s3">1</span><span class="s1">]</span>
            <span class="s1">ref[-</span><span class="s3">1</span><span class="s1">] = np.floor(loc)</span>
            <span class="s1">data = dist.rvs(*ref</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
            <span class="s1">bounds = bounds[:-</span><span class="s3">1</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s1">getattr(dist</span><span class="s0">, </span><span class="s4">'pdf'</span><span class="s0">, False</span><span class="s1">):</span>
            <span class="s1">data = dist.rvs(*ref</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

        <span class="s0">with </span><span class="s1">npt.suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
            <span class="s1">sup.filter(RuntimeWarning</span><span class="s0">, </span><span class="s4">&quot;overflow encountered&quot;</span><span class="s1">)</span>
            <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">method=method</span><span class="s0">,</span>
                            <span class="s1">optimizer=self.opt)</span>

        <span class="s1">nlff_names = {</span><span class="s4">'mle'</span><span class="s1">: </span><span class="s4">'nnlf'</span><span class="s0">, </span><span class="s4">'mse'</span><span class="s1">: </span><span class="s4">'_penalized_nlpsf'</span><span class="s1">}</span>
        <span class="s1">nlff_name = nlff_names[method]</span>
        <span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">res.params</span><span class="s0">, </span><span class="s1">ref</span><span class="s0">, </span><span class="s1">**self.tols</span><span class="s0">,</span>
                                  <span class="s1">nlff_name=nlff_name)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;dist_name&quot;</span><span class="s0">, </span><span class="s1">cases_test_fit_mle())</span>
    <span class="s0">def </span><span class="s1">test_basic_fit_mle(self</span><span class="s0">, </span><span class="s1">dist_name):</span>
        <span class="s1">self.basic_fit_test(dist_name</span><span class="s0">, </span><span class="s4">&quot;mle&quot;</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;dist_name&quot;</span><span class="s0">, </span><span class="s1">cases_test_fit_mse())</span>
    <span class="s0">def </span><span class="s1">test_basic_fit_mse(self</span><span class="s0">, </span><span class="s1">dist_name):</span>
        <span class="s1">self.basic_fit_test(dist_name</span><span class="s0">, </span><span class="s4">&quot;mse&quot;</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_argus(self):</span>
        <span class="s2"># Can't guarantee that all distributions will fit all data with</span>
        <span class="s2"># arbitrary bounds. This distribution just happens to fail above.</span>
        <span class="s2"># Try something slightly different.</span>
        <span class="s1">N = </span><span class="s3">1000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = stats.argus</span>
        <span class="s1">shapes = (</span><span class="s3">1.</span><span class="s0">, </span><span class="s3">2.</span><span class="s0">, </span><span class="s3">3.</span><span class="s1">)</span>
        <span class="s1">data = dist.rvs(*shapes</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'chi'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'loc'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>

        <span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">res.params</span><span class="s0">, </span><span class="s1">shapes</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_foldnorm(self):</span>
        <span class="s2"># Can't guarantee that all distributions will fit all data with</span>
        <span class="s2"># arbitrary bounds. This distribution just happens to fail above.</span>
        <span class="s2"># Try something slightly different.</span>
        <span class="s1">N = </span><span class="s3">1000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = stats.foldnorm</span>
        <span class="s1">shapes = (</span><span class="s3">1.952125337355587</span><span class="s0">, </span><span class="s3">2.</span><span class="s0">, </span><span class="s3">3.</span><span class="s1">)</span>
        <span class="s1">data = dist.rvs(*shapes</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'c'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'loc'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: (</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>

        <span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">res.params</span><span class="s0">, </span><span class="s1">shapes</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_truncpareto(self):</span>
        <span class="s2"># Can't guarantee that all distributions will fit all data with</span>
        <span class="s2"># arbitrary bounds. This distribution just happens to fail above.</span>
        <span class="s2"># Try something slightly different.</span>
        <span class="s1">N = </span><span class="s3">1000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = stats.truncpareto</span>
        <span class="s1">shapes = (</span><span class="s3">1.8</span><span class="s0">, </span><span class="s3">5.3</span><span class="s0">, </span><span class="s3">2.3</span><span class="s0">, </span><span class="s3">4.1</span><span class="s1">)</span>
        <span class="s1">data = dist.rvs(*shapes</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]*</span><span class="s3">4</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>

        <span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">res.params</span><span class="s0">, </span><span class="s1">shapes</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_truncweibull_min(self):</span>
        <span class="s2"># Can't guarantee that all distributions will fit all data with</span>
        <span class="s2"># arbitrary bounds. This distribution just happens to fail above.</span>
        <span class="s2"># Try something slightly different.</span>
        <span class="s1">N = </span><span class="s3">1000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = stats.truncweibull_min</span>
        <span class="s1">shapes = (</span><span class="s3">2.5</span><span class="s0">, </span><span class="s3">0.25</span><span class="s0">, </span><span class="s3">1.75</span><span class="s0">, </span><span class="s3">2.</span><span class="s0">, </span><span class="s3">3.</span><span class="s1">)</span>
        <span class="s1">data = dist.rvs(*shapes</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = [(</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]*</span><span class="s3">5</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>

        <span class="s1">assert_nlff_less_or_close(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">res.params</span><span class="s0">, </span><span class="s1">shapes</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_missing_shape_bounds(self):</span>
        <span class="s2"># some distributions have a small domain w.r.t. a parameter, e.g.</span>
        <span class="s2"># $p \in [0, 1]$ for binomial distribution</span>
        <span class="s2"># User does not need to provide these because the intersection of the</span>
        <span class="s2"># user's bounds (none) and the distribution's domain is finite</span>
        <span class="s1">N = </span><span class="s3">1000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>

        <span class="s1">dist = stats.binom</span>
        <span class="s1">n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc = </span><span class="s3">10</span><span class="s0">, </span><span class="s3">0.65</span><span class="s0">, </span><span class="s3">0</span>
        <span class="s1">data = dist.rvs(n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc=loc</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'n'</span><span class="s1">: np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">20</span><span class="s1">])}  </span><span class="s2"># check arrays are OK, too</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s1">dist = stats.bernoulli</span>
        <span class="s1">p</span><span class="s0">, </span><span class="s1">loc = </span><span class="s3">0.314159</span><span class="s0">, </span><span class="s3">0</span>
        <span class="s1">data = dist.rvs(p</span><span class="s0">, </span><span class="s1">loc=loc</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(p</span><span class="s0">, </span><span class="s1">loc)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_fit_only_loc_scale(self):</span>
        <span class="s2"># fit only loc</span>
        <span class="s1">N = </span><span class="s3">5000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>

        <span class="s1">dist = stats.norm</span>
        <span class="s1">loc</span><span class="s0">, </span><span class="s1">scale = </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">1</span>
        <span class="s1">data = dist.rvs(loc=loc</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">loc_bounds = (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
        <span class="s1">bounds = {</span><span class="s4">'loc'</span><span class="s1">: loc_bounds}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(loc</span><span class="s0">, </span><span class="s1">scale)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s2"># fit only scale</span>
        <span class="s1">loc</span><span class="s0">, </span><span class="s1">scale = </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2.5</span>
        <span class="s1">data = dist.rvs(scale=scale</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">scale_bounds = (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span>
        <span class="s1">bounds = {</span><span class="s4">'scale'</span><span class="s1">: scale_bounds}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(loc</span><span class="s0">, </span><span class="s1">scale)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s2"># fit only loc and scale</span>
        <span class="s1">dist = stats.norm</span>
        <span class="s1">loc</span><span class="s0">, </span><span class="s1">scale = </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2.5</span>
        <span class="s1">data = dist.rvs(loc=loc</span><span class="s0">, </span><span class="s1">scale=scale</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">bounds = {</span><span class="s4">'loc'</span><span class="s1">: loc_bounds</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: scale_bounds}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(loc</span><span class="s0">, </span><span class="s1">scale)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_everything_fixed(self):</span>
        <span class="s1">N = </span><span class="s3">5000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>

        <span class="s1">dist = stats.norm</span>
        <span class="s1">loc</span><span class="s0">, </span><span class="s1">scale = </span><span class="s3">1.5</span><span class="s0">, </span><span class="s3">2.5</span>
        <span class="s1">data = dist.rvs(loc=loc</span><span class="s0">, </span><span class="s1">scale=scale</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

        <span class="s2"># loc, scale fixed to 0, 1 by default</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s2"># loc, scale explicitly fixed</span>
        <span class="s1">bounds = {</span><span class="s4">'loc'</span><span class="s1">: (loc</span><span class="s0">, </span><span class="s1">loc)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: (scale</span><span class="s0">, </span><span class="s1">scale)}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(loc</span><span class="s0">, </span><span class="s1">scale)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s2"># `n` gets fixed during polishing</span>
        <span class="s1">dist = stats.binom</span>
        <span class="s1">n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc = </span><span class="s3">10</span><span class="s0">, </span><span class="s3">0.65</span><span class="s0">, </span><span class="s3">0</span>
        <span class="s1">data = dist.rvs(n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc=loc</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">shape_bounds = {</span><span class="s4">'n'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">20</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'p'</span><span class="s1">: (</span><span class="s3">0.65</span><span class="s0">, </span><span class="s3">0.65</span><span class="s1">)}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">shape_bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">(n</span><span class="s0">, </span><span class="s1">p</span><span class="s0">, </span><span class="s1">loc)</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_failure(self):</span>
        <span class="s1">N = </span><span class="s3">5000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>

        <span class="s1">dist = stats.nbinom</span>
        <span class="s1">shapes = (</span><span class="s3">5</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span>
        <span class="s1">data = dist.rvs(*shapes</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

        <span class="s0">assert </span><span class="s1">data.min() == </span><span class="s3">0</span>
        <span class="s2"># With lower bounds on location at 0.5, likelihood is zero</span>
        <span class="s1">bounds = [(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">30</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.5</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds)</span>
        <span class="s1">message = </span><span class="s4">&quot;Optimization converged to parameter values that are&quot;</span>
        <span class="s0">assert </span><span class="s1">res.message.startswith(message)</span>
        <span class="s0">assert </span><span class="s1">res.success </span><span class="s0">is False</span>

    <span class="s1">@pytest.mark.xslow</span>
    <span class="s0">def </span><span class="s1">test_guess(self):</span>
        <span class="s2"># Test that guess helps DE find the desired solution</span>
        <span class="s1">N = </span><span class="s3">2000</span>
        <span class="s1">rng = np.random.default_rng(self.seed)</span>
        <span class="s1">dist = stats.nhypergeom</span>
        <span class="s1">params = (</span><span class="s3">20</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">12</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">bounds = [(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">200</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0.7</span><span class="s0">, </span><span class="s3">70</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1.2</span><span class="s0">, </span><span class="s3">120</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)]</span>

        <span class="s1">data = dist.rvs(*params</span><span class="s0">, </span><span class="s1">size=N</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s0">assert not </span><span class="s1">np.allclose(res.params</span><span class="s0">, </span><span class="s1">params</span><span class="s0">, </span><span class="s1">**self.tols)</span>

        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">guess=params</span><span class="s0">, </span><span class="s1">optimizer=self.opt)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">params</span><span class="s0">, </span><span class="s1">**self.tols)</span>

    <span class="s0">def </span><span class="s1">test_mse_accuracy_1(self):</span>
        <span class="s2"># Test maximum spacing estimation against example from Wikipedia</span>
        <span class="s2"># https://en.wikipedia.org/wiki/Maximum_spacing_estimation#Examples</span>
        <span class="s1">data = [</span><span class="s3">2</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span>
        <span class="s1">dist = stats.expon</span>
        <span class="s1">bounds = {</span><span class="s4">'loc'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: (</span><span class="s3">1e-8</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)}</span>
        <span class="s1">res_mle = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds=bounds</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'mle'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res_mle.params.scale</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-3</span><span class="s1">)</span>
        <span class="s1">res_mse = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds=bounds</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'mse'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res_mse.params.scale</span><span class="s0">, </span><span class="s3">3.915</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_mse_accuracy_2(self):</span>
        <span class="s2"># Test maximum spacing estimation against example from Wikipedia</span>
        <span class="s2"># https://en.wikipedia.org/wiki/Maximum_spacing_estimation#Examples</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">9843212616816518964</span><span class="s1">)</span>

        <span class="s1">dist = stats.uniform</span>
        <span class="s1">n = </span><span class="s3">10</span>
        <span class="s1">data = dist(</span><span class="s3">3</span><span class="s0">, </span><span class="s3">6</span><span class="s1">).rvs(size=n</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">bounds = {</span><span class="s4">'loc'</span><span class="s1">: (</span><span class="s3">0</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: (</span><span class="s3">1e-8</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)}</span>
        <span class="s1">res = stats.fit(dist</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds=bounds</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'mse'</span><span class="s1">)</span>
        <span class="s2"># (loc=3.608118420015416, scale=5.509323262055043)</span>

        <span class="s1">x = np.sort(data)</span>
        <span class="s1">a = (n*x[</span><span class="s3">0</span><span class="s1">] - x[-</span><span class="s3">1</span><span class="s1">])/(n - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">b = (n*x[-</span><span class="s3">1</span><span class="s1">] - x[</span><span class="s3">0</span><span class="s1">])/(n - </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">ref = a</span><span class="s0">, </span><span class="s1">b-a  </span><span class="s2"># (3.6081133632151503, 5.509328130317254)</span>
        <span class="s1">assert_allclose(res.params</span><span class="s0">, </span><span class="s1">ref</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-4</span><span class="s1">)</span>


<span class="s2"># Data from Matlab: https://www.mathworks.com/help/stats/lillietest.html</span>
<span class="s1">examgrades = [</span><span class="s3">65</span><span class="s0">, </span><span class="s3">61</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">88</span><span class="s0">, </span><span class="s3">69</span><span class="s0">, </span><span class="s3">89</span><span class="s0">, </span><span class="s3">55</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">86</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">78</span><span class="s0">, </span><span class="s3">67</span><span class="s0">,</span>
              <span class="s3">96</span><span class="s0">, </span><span class="s3">66</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">59</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">69</span><span class="s0">, </span><span class="s3">63</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">76</span><span class="s0">, </span><span class="s3">63</span><span class="s0">, </span><span class="s3">85</span><span class="s0">, </span><span class="s3">87</span><span class="s0">, </span><span class="s3">88</span><span class="s0">, </span><span class="s3">80</span><span class="s0">, </span><span class="s3">71</span><span class="s0">,</span>
              <span class="s3">65</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">64</span><span class="s0">, </span><span class="s3">65</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">77</span><span class="s0">, </span><span class="s3">70</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">84</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">92</span><span class="s0">,</span>
              <span class="s3">90</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">80</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">58</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">64</span><span class="s0">, </span><span class="s3">77</span><span class="s0">, </span><span class="s3">82</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">59</span><span class="s0">, </span><span class="s3">54</span><span class="s0">, </span><span class="s3">82</span><span class="s0">,</span>
              <span class="s3">57</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">79</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">74</span><span class="s0">, </span><span class="s3">82</span><span class="s0">, </span><span class="s3">63</span><span class="s0">, </span><span class="s3">64</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">69</span><span class="s0">, </span><span class="s3">87</span><span class="s0">, </span><span class="s3">68</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">83</span><span class="s0">, </span><span class="s3">73</span><span class="s0">,</span>
              <span class="s3">80</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">73</span><span class="s0">, </span><span class="s3">71</span><span class="s0">, </span><span class="s3">66</span><span class="s0">, </span><span class="s3">78</span><span class="s0">, </span><span class="s3">64</span><span class="s0">, </span><span class="s3">74</span><span class="s0">, </span><span class="s3">68</span><span class="s0">, </span><span class="s3">67</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">80</span><span class="s0">, </span><span class="s3">85</span><span class="s0">, </span><span class="s3">74</span><span class="s0">, </span><span class="s3">76</span><span class="s0">,</span>
              <span class="s3">80</span><span class="s0">, </span><span class="s3">77</span><span class="s0">, </span><span class="s3">93</span><span class="s0">, </span><span class="s3">70</span><span class="s0">, </span><span class="s3">86</span><span class="s0">, </span><span class="s3">80</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">83</span><span class="s0">, </span><span class="s3">68</span><span class="s0">, </span><span class="s3">60</span><span class="s0">, </span><span class="s3">85</span><span class="s0">, </span><span class="s3">64</span><span class="s0">, </span><span class="s3">74</span><span class="s0">, </span><span class="s3">82</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">77</span><span class="s0">,</span>
              <span class="s3">66</span><span class="s0">, </span><span class="s3">85</span><span class="s0">, </span><span class="s3">75</span><span class="s0">, </span><span class="s3">81</span><span class="s0">, </span><span class="s3">69</span><span class="s0">, </span><span class="s3">60</span><span class="s0">, </span><span class="s3">83</span><span class="s0">, </span><span class="s3">72</span><span class="s1">]</span>


<span class="s0">class </span><span class="s1">TestGoodnessOfFit:</span>

    <span class="s0">def </span><span class="s1">test_gof_iv(self):</span>
        <span class="s1">dist = stats.norm</span>
        <span class="s1">x = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span>

        <span class="s1">message = </span><span class="s4">r&quot;`dist` must be a \(non-frozen\) instance of...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">goodness_of_fit(stats.norm()</span><span class="s0">, </span><span class="s1">x)</span>

        <span class="s1">message = </span><span class="s4">&quot;`data` must be a one-dimensional array of numbers.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">goodness_of_fit(dist</span><span class="s0">, </span><span class="s1">[[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]])</span>

        <span class="s1">message = </span><span class="s4">&quot;`statistic` must be one of...&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">goodness_of_fit(dist</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">statistic=</span><span class="s4">'mm'</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s4">&quot;`n_mc_samples` must be an integer.&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(TypeError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">goodness_of_fit(dist</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">n_mc_samples=</span><span class="s3">1000.5</span><span class="s1">)</span>

        <span class="s1">message = </span><span class="s4">&quot;'herring' cannot be used to seed a&quot;</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
            <span class="s1">goodness_of_fit(dist</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">'herring'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_ks(self):</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">8517426291317196949</span><span class="s1">)</span>
        <span class="s1">x = examgrades</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: np.mean(x)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: np.std(x</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)}</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                              <span class="s1">statistic=</span><span class="s4">'ks'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">ref = stats.kstest(x</span><span class="s0">, </span><span class="s1">stats.norm(**known_params).cdf</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'exact'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic)  </span><span class="s2"># ~0.0848</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)  </span><span class="s2"># ~0.335</span>

    <span class="s0">def </span><span class="s1">test_against_lilliefors(self):</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">2291803665717442724</span><span class="s1">)</span>
        <span class="s1">x = examgrades</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">statistic=</span><span class="s4">'ks'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: np.mean(x)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: np.std(x</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)}</span>
        <span class="s1">ref = stats.kstest(x</span><span class="s0">, </span><span class="s1">stats.norm(**known_params).cdf</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'exact'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic)  </span><span class="s2"># ~0.0848</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.0348</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_cvm(self):</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">8674330857509546614</span><span class="s1">)</span>
        <span class="s1">x = examgrades</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: np.mean(x)</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: np.std(x</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)}</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                              <span class="s1">statistic=</span><span class="s4">'cvm'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">ref = stats.cramervonmises(x</span><span class="s0">, </span><span class="s1">stats.norm(**known_params).cdf)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic)  </span><span class="s2"># ~0.090</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref.pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)  </span><span class="s2"># ~0.636</span>

    <span class="s0">def </span><span class="s1">test_against_anderson_case_0(self):</span>
        <span class="s2"># &quot;Case 0&quot; is where loc and scale are known [1]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">7384539336846690410</span><span class="s1">)</span>
        <span class="s1">x = np.arange(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">101</span><span class="s1">)</span>
        <span class="s2"># loc that produced critical value of statistic found w/ root_scalar</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: </span><span class="s3">45.01575354024957</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">30</span><span class="s1">}</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                              <span class="s1">statistic=</span><span class="s4">'ad'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">2.492</span><span class="s1">)  </span><span class="s2"># See [1] Table 1A 1.0</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.05</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_anderson_case_1(self):</span>
        <span class="s2"># &quot;Case 1&quot; is where scale is known and loc is fit [1]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">5040212485680146248</span><span class="s1">)</span>
        <span class="s1">x = np.arange(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">101</span><span class="s1">)</span>
        <span class="s2"># scale that produced critical value of statistic found w/ root_scalar</span>
        <span class="s1">known_params = {</span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">29.957112639101933</span><span class="s1">}</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                              <span class="s1">statistic=</span><span class="s4">'ad'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">0.908</span><span class="s1">)  </span><span class="s2"># See [1] Table 1B 1.1</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_anderson_case_2(self):</span>
        <span class="s2"># &quot;Case 2&quot; is where loc is known and scale is fit [1]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">726693985720914083</span><span class="s1">)</span>
        <span class="s1">x = np.arange(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">101</span><span class="s1">)</span>
        <span class="s2"># loc that produced critical value of statistic found w/ root_scalar</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: </span><span class="s3">44.5680212261933</span><span class="s1">}</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                              <span class="s1">statistic=</span><span class="s4">'ad'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">2.904</span><span class="s1">)  </span><span class="s2"># See [1] Table 1B 1.2</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.025</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_anderson_case_3(self):</span>
        <span class="s2"># &quot;Case 3&quot; is where both loc and scale are fit [1]</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">6763691329830218206</span><span class="s1">)</span>
        <span class="s2"># c that produced critical value of statistic found w/ root_scalar</span>
        <span class="s1">x = stats.skewnorm.rvs(</span><span class="s3">1.4477847789132101</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">,</span>
                               <span class="s1">random_state=rng)</span>
        <span class="s1">res = goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">statistic=</span><span class="s4">'ad'</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">0.559</span><span class="s1">)  </span><span class="s2"># See [1] Table 1B 1.2</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.15</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.slow</span>
    <span class="s0">def </span><span class="s1">test_against_anderson_gumbel_r(self):</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">7302761058217743</span><span class="s1">)</span>
        <span class="s2"># c that produced critical value of statistic found w/ root_scalar</span>
        <span class="s1">x = stats.genextreme(</span><span class="s3">0.051896837188595134</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">0.5</span><span class="s0">,</span>
                             <span class="s1">scale=</span><span class="s3">1.5</span><span class="s1">).rvs(size=</span><span class="s3">1000</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">res = goodness_of_fit(stats.gumbel_r</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">statistic=</span><span class="s4">'ad'</span><span class="s0">,</span>
                              <span class="s1">random_state=rng)</span>
        <span class="s1">ref = stats.anderson(x</span><span class="s0">, </span><span class="s1">dist=</span><span class="s4">'gumbel_r'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.critical_values[</span><span class="s3">0</span><span class="s1">])</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref.significance_level[</span><span class="s3">0</span><span class="s1">]/</span><span class="s3">100</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">5e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_against_filliben_norm(self):</span>
        <span class="s2"># Test against `stats.fit` ref. [7] Section 8 &quot;Example&quot;</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">8024266430745011915</span><span class="s1">)</span>
        <span class="s1">y = [</span><span class="s3">6</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">4</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s1">-</span><span class="s3">2</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: </span><span class="s3">0</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span>
        <span class="s1">res = stats.goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                                    <span class="s1">statistic=</span><span class="s4">&quot;filliben&quot;</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s2"># Slight discrepancy presumably due to roundoff in Filliben's</span>
        <span class="s2"># calculation. Using exact order statistic medians instead of</span>
        <span class="s2"># Filliben's approximation doesn't account for it.</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">0.98538</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-4</span><span class="s1">)</span>
        <span class="s0">assert </span><span class="s3">0.75 </span><span class="s1">&lt; res.pvalue &lt; </span><span class="s3">0.9</span>

        <span class="s2"># Using R's ppcc library:</span>
        <span class="s2"># library(ppcc)</span>
        <span class="s2"># options(digits=16)</span>
        <span class="s2"># x &lt; - c(6, 1, -4, 8, -2, 5, 0)</span>
        <span class="s2"># set.seed(100)</span>
        <span class="s2"># ppccTest(x, &quot;qnorm&quot;, ppos=&quot;Filliben&quot;)</span>
        <span class="s2"># Discrepancy with</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s3">0.98540957187084</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">2e-5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s3">0.8875</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">2e-3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_filliben_property(self):</span>
        <span class="s2"># Filliben's statistic should be independent of data location and scale</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">8535677809395478813</span><span class="s1">)</span>
        <span class="s1">x = rng.normal(loc=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">0.5</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s1">)</span>
        <span class="s1">res = stats.goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">,</span>
                                    <span class="s1">statistic=</span><span class="s4">&quot;filliben&quot;</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: </span><span class="s3">0</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span>
        <span class="s1">ref = stats.goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                                    <span class="s1">statistic=</span><span class="s4">&quot;filliben&quot;</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref.statistic</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-15</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'case'</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">25</span><span class="s0">, </span><span class="s1">[</span><span class="s3">.928</span><span class="s0">, </span><span class="s3">.937</span><span class="s0">, </span><span class="s3">.950</span><span class="s0">, </span><span class="s3">.958</span><span class="s0">, </span><span class="s3">.966</span><span class="s1">])</span><span class="s0">,</span>
                                      <span class="s1">(</span><span class="s3">50</span><span class="s0">, </span><span class="s1">[</span><span class="s3">.959</span><span class="s0">, </span><span class="s3">.965</span><span class="s0">, </span><span class="s3">.972</span><span class="s0">, </span><span class="s3">.977</span><span class="s0">, </span><span class="s3">.981</span><span class="s1">])</span><span class="s0">,</span>
                                      <span class="s1">(</span><span class="s3">95</span><span class="s0">, </span><span class="s1">[</span><span class="s3">.977</span><span class="s0">, </span><span class="s3">.979</span><span class="s0">, </span><span class="s3">.983</span><span class="s0">, </span><span class="s3">.986</span><span class="s0">, </span><span class="s3">.989</span><span class="s1">])])</span>
    <span class="s0">def </span><span class="s1">test_against_filliben_norm_table(self</span><span class="s0">, </span><span class="s1">case):</span>
        <span class="s2"># Test against `stats.fit` ref. [7] Table 1</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">504569995557928957</span><span class="s1">)</span>
        <span class="s1">n</span><span class="s0">, </span><span class="s1">ref = case</span>
        <span class="s1">x = rng.random(n)</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: </span><span class="s3">0</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">1</span><span class="s1">}</span>
        <span class="s1">res = stats.goodness_of_fit(stats.norm</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">known_params=known_params</span><span class="s0">,</span>
                                    <span class="s1">statistic=</span><span class="s4">&quot;filliben&quot;</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">percentiles = np.array([</span><span class="s3">0.005</span><span class="s0">, </span><span class="s3">0.01</span><span class="s0">, </span><span class="s3">0.025</span><span class="s0">, </span><span class="s3">0.05</span><span class="s0">, </span><span class="s3">0.1</span><span class="s1">])</span>
        <span class="s1">res = stats.scoreatpercentile(res.null_distribution</span><span class="s0">, </span><span class="s1">percentiles*</span><span class="s3">100</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res</span><span class="s0">, </span><span class="s1">ref</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">2e-3</span><span class="s1">)</span>

    <span class="s1">@pytest.mark.slow</span>
    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">'case'</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">5</span><span class="s0">, </span><span class="s3">0.95772790260469</span><span class="s0">, </span><span class="s3">0.4755</span><span class="s1">)</span><span class="s0">,</span>
                                      <span class="s1">(</span><span class="s3">6</span><span class="s0">, </span><span class="s3">0.95398832257958</span><span class="s0">, </span><span class="s3">0.3848</span><span class="s1">)</span><span class="s0">,</span>
                                      <span class="s1">(</span><span class="s3">7</span><span class="s0">, </span><span class="s3">0.9432692889277</span><span class="s0">, </span><span class="s3">0.2328</span><span class="s1">)])</span>
    <span class="s0">def </span><span class="s1">test_against_ppcc(self</span><span class="s0">, </span><span class="s1">case):</span>
        <span class="s2"># Test against R ppcc, e.g.</span>
        <span class="s2"># library(ppcc)</span>
        <span class="s2"># options(digits=16)</span>
        <span class="s2"># x &lt; - c(0.52325412, 1.06907699, -0.36084066, 0.15305959, 0.99093194)</span>
        <span class="s2"># set.seed(100)</span>
        <span class="s2"># ppccTest(x, &quot;qrayleigh&quot;, ppos=&quot;Filliben&quot;)</span>
        <span class="s1">n</span><span class="s0">, </span><span class="s1">ref_statistic</span><span class="s0">, </span><span class="s1">ref_pvalue = case</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">7777775561439803116</span><span class="s1">)</span>
        <span class="s1">x = rng.normal(size=n)</span>
        <span class="s1">res = stats.goodness_of_fit(stats.rayleigh</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">statistic=</span><span class="s4">&quot;filliben&quot;</span><span class="s0">,</span>
                                    <span class="s1">random_state=rng)</span>
        <span class="s1">assert_allclose(res.statistic</span><span class="s0">, </span><span class="s1">ref_statistic</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.pvalue</span><span class="s0">, </span><span class="s1">ref_pvalue</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1.5e-2</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_params_effects(self):</span>
        <span class="s2"># Ensure that `guessed_params`, `fit_params`, and `known_params` have</span>
        <span class="s2"># the intended effects.</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">9121950977643805391</span><span class="s1">)</span>
        <span class="s1">x = stats.skewnorm.rvs(-</span><span class="s3">5.044559778383153</span><span class="s0">, </span><span class="s1">loc=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">scale=</span><span class="s3">2</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">50</span><span class="s0">,</span>
                               <span class="s1">random_state=rng)</span>

        <span class="s2"># Show that `guessed_params` don't fit to the guess,</span>
        <span class="s2"># but `fit_params` and `known_params` respect the provided fit</span>
        <span class="s1">guessed_params = {</span><span class="s4">'c'</span><span class="s1">: </span><span class="s3">13.4</span><span class="s1">}</span>
        <span class="s1">fit_params = {</span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">13.73</span><span class="s1">}</span>
        <span class="s1">known_params = {</span><span class="s4">'loc'</span><span class="s1">: -</span><span class="s3">13.85</span><span class="s1">}</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">9121950977643805391</span><span class="s1">)</span>
        <span class="s1">res1 = goodness_of_fit(stats.weibull_min</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">n_mc_samples=</span><span class="s3">2</span><span class="s0">,</span>
                               <span class="s1">guessed_params=guessed_params</span><span class="s0">,</span>
                               <span class="s1">fit_params=fit_params</span><span class="s0">,</span>
                               <span class="s1">known_params=known_params</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s0">assert not </span><span class="s1">np.allclose(res1.fit_result.params.c</span><span class="s0">, </span><span class="s3">13.4</span><span class="s1">)</span>
        <span class="s1">assert_equal(res1.fit_result.params.scale</span><span class="s0">, </span><span class="s3">13.73</span><span class="s1">)</span>
        <span class="s1">assert_equal(res1.fit_result.params.loc</span><span class="s0">, </span><span class="s1">-</span><span class="s3">13.85</span><span class="s1">)</span>

        <span class="s2"># Show that changing the guess changes the parameter that gets fit,</span>
        <span class="s2"># and it changes the null distribution</span>
        <span class="s1">guessed_params = {</span><span class="s4">'c'</span><span class="s1">: </span><span class="s3">2</span><span class="s1">}</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">9121950977643805391</span><span class="s1">)</span>
        <span class="s1">res2 = goodness_of_fit(stats.weibull_min</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">n_mc_samples=</span><span class="s3">2</span><span class="s0">,</span>
                               <span class="s1">guessed_params=guessed_params</span><span class="s0">,</span>
                               <span class="s1">fit_params=fit_params</span><span class="s0">,</span>
                               <span class="s1">known_params=known_params</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s0">assert not </span><span class="s1">np.allclose(res2.fit_result.params.c</span><span class="s0">,</span>
                               <span class="s1">res1.fit_result.params.c</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-8</span><span class="s1">)</span>
        <span class="s0">assert not </span><span class="s1">np.allclose(res2.null_distribution</span><span class="s0">,</span>
                               <span class="s1">res1.null_distribution</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-8</span><span class="s1">)</span>
        <span class="s1">assert_equal(res2.fit_result.params.scale</span><span class="s0">, </span><span class="s3">13.73</span><span class="s1">)</span>
        <span class="s1">assert_equal(res2.fit_result.params.loc</span><span class="s0">, </span><span class="s1">-</span><span class="s3">13.85</span><span class="s1">)</span>

        <span class="s2"># If we set all parameters as fit_params and known_params,</span>
        <span class="s2"># they're all fixed to those values, but the null distribution</span>
        <span class="s2"># varies.</span>
        <span class="s1">fit_params = {</span><span class="s4">'c'</span><span class="s1">: </span><span class="s3">13.4</span><span class="s0">, </span><span class="s4">'scale'</span><span class="s1">: </span><span class="s3">13.73</span><span class="s1">}</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">9121950977643805391</span><span class="s1">)</span>
        <span class="s1">res3 = goodness_of_fit(stats.weibull_min</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">n_mc_samples=</span><span class="s3">2</span><span class="s0">,</span>
                               <span class="s1">guessed_params=guessed_params</span><span class="s0">,</span>
                               <span class="s1">fit_params=fit_params</span><span class="s0">,</span>
                               <span class="s1">known_params=known_params</span><span class="s0">, </span><span class="s1">random_state=rng)</span>
        <span class="s1">assert_equal(res3.fit_result.params.c</span><span class="s0">, </span><span class="s3">13.4</span><span class="s1">)</span>
        <span class="s1">assert_equal(res3.fit_result.params.scale</span><span class="s0">, </span><span class="s3">13.73</span><span class="s1">)</span>
        <span class="s1">assert_equal(res3.fit_result.params.loc</span><span class="s0">, </span><span class="s1">-</span><span class="s3">13.85</span><span class="s1">)</span>
        <span class="s0">assert not </span><span class="s1">np.allclose(res3.null_distribution</span><span class="s0">, </span><span class="s1">res1.null_distribution)</span>


<span class="s0">class </span><span class="s1">TestFitResult:</span>
    <span class="s0">def </span><span class="s1">test_plot_iv(self):</span>
        <span class="s1">rng = np.random.default_rng(</span><span class="s3">1769658657308472721</span><span class="s1">)</span>
        <span class="s1">data = stats.norm.rvs(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">random_state=rng)</span>

        <span class="s0">def </span><span class="s1">optimizer(*args</span><span class="s0">, </span><span class="s1">**kwargs):</span>
            <span class="s0">return </span><span class="s1">differential_evolution(*args</span><span class="s0">, </span><span class="s1">**kwargs</span><span class="s0">, </span><span class="s1">seed=rng)</span>

        <span class="s1">bounds = [(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">30</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
        <span class="s1">res = stats.fit(stats.norm</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">, </span><span class="s1">optimizer=optimizer)</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">import </span><span class="s1">matplotlib  </span><span class="s2"># noqa</span>
            <span class="s1">message = </span><span class="s4">r&quot;`plot_type` must be one of \{'...&quot;</span>
            <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=message):</span>
                <span class="s1">res.plot(plot_type=</span><span class="s4">'llama'</span><span class="s1">)</span>
        <span class="s0">except </span><span class="s1">(ModuleNotFoundError</span><span class="s0">, </span><span class="s1">ImportError):</span>
            <span class="s1">message = </span><span class="s4">r&quot;matplotlib must be installed to use method `plot`.&quot;</span>
            <span class="s0">with </span><span class="s1">pytest.raises(ModuleNotFoundError</span><span class="s0">, </span><span class="s1">match=message):</span>
                <span class="s1">res.plot(plot_type=</span><span class="s4">'llama'</span><span class="s1">)</span>
</pre>
</body>
</html>
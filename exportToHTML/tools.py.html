<html>
<head>
<title>tools.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
tools.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Thu Feb 11 09:19:30 2021 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>
<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">interpolate</span><span class="s3">, </span><span class="s1">stats</span>

<span class="s0"># helper functions to work on a grid of cdf and pdf, histogram</span>

<span class="s3">class </span><span class="s1">_Grid:</span>
    <span class="s2">&quot;&quot;&quot;Create Grid values and indices, grid in [0, 1]^d 
 
    This class creates a regular grid in a d dimensional hyper cube. 
 
    Intended for internal use, implementation might change without warning. 
 
 
    Parameters 
    ---------- 
    k_grid : tuple or array_like 
        number of elements for axes, this defines k_grid - 1 equal sized 
        intervals of [0, 1] for each axis. 
    eps : float 
        If eps is not zero, then x values will be clipped to [eps, 1 - eps], 
        i.e. to the interior of the unit interval or hyper cube. 
 
 
    Attributes 
    ---------- 
    k_grid : list of number of grid points 
    x_marginal: list of 1-dimensional marginal values 
    idx_flat: integer array with indices 
    x_flat: flattened grid values, 
        rows are grid points, columns represent variables or axis. 
        ``x_flat`` is currently also 2-dim in the univariate 1-dim grid case. 
 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">k_grid</span><span class="s3">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">):</span>
        <span class="s1">self.k_grid = k_grid</span>

        <span class="s1">x_marginal = [np.arange(ki) / (ki - </span><span class="s4">1</span><span class="s1">) </span><span class="s3">for </span><span class="s1">ki </span><span class="s3">in </span><span class="s1">k_grid]</span>

        <span class="s1">idx_flat = np.column_stack(</span>
                <span class="s1">np.unravel_index(np.arange(np.prod(k_grid))</span><span class="s3">, </span><span class="s1">k_grid)</span>
                <span class="s1">).astype(float)</span>
        <span class="s1">x_flat = idx_flat / idx_flat.max(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">eps != </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">x_marginal = [np.clip(xi</span><span class="s3">, </span><span class="s1">eps</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">- eps) </span><span class="s3">for </span><span class="s1">xi </span><span class="s3">in </span><span class="s1">x_marginal]</span>
            <span class="s1">x_flat = np.clip(x_flat</span><span class="s3">, </span><span class="s1">eps</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">- eps)</span>

        <span class="s1">self.x_marginal = x_marginal</span>
        <span class="s1">self.idx_flat = idx_flat</span>
        <span class="s1">self.x_flat = x_flat</span>


<span class="s3">def </span><span class="s1">prob2cdf_grid(probs):</span>
    <span class="s2">&quot;&quot;&quot;Cumulative probabilities from cell provabilites on a grid 
 
    Parameters 
    ---------- 
    probs : array_like 
        Rectangular grid of cell probabilities. 
 
    Returns 
    ------- 
    cdf : ndarray 
        Grid of cumulative probabilities with same shape as probs. 
    &quot;&quot;&quot;</span>
    <span class="s1">cdf = np.asarray(probs).copy()</span>
    <span class="s1">k = cdf.ndim</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k):</span>
        <span class="s1">cdf = cdf.cumsum(axis=i)</span>

    <span class="s3">return </span><span class="s1">cdf</span>


<span class="s3">def </span><span class="s1">cdf2prob_grid(cdf</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s4">0</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Cell probabilities from cumulative probabilities on a grid. 
 
    Parameters 
    ---------- 
    cdf : array_like 
        Grid of cumulative probabilities with same shape as probs. 
 
    Returns 
    ------- 
    probs : ndarray 
        Rectangular grid of cell probabilities. 
 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">prepend </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">prepend = np._NoValue</span>
    <span class="s1">prob = np.asarray(cdf).copy()</span>
    <span class="s1">k = prob.ndim</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k):</span>
        <span class="s1">prob = np.diff(prob</span><span class="s3">, </span><span class="s1">prepend=prepend</span><span class="s3">, </span><span class="s1">axis=i)</span>

    <span class="s3">return </span><span class="s1">prob</span>


<span class="s3">def </span><span class="s1">average_grid(values</span><span class="s3">, </span><span class="s1">coords=</span><span class="s3">None, </span><span class="s1">_method=</span><span class="s5">&quot;slicing&quot;</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Compute average for each cell in grid using endpoints 
 
    Parameters 
    ---------- 
    values : array_like 
        Values on a grid that will average over corner points of each cell. 
    coords : None or list of array_like 
        Grid coordinates for each axis use to compute volumne of cell. 
        If None, then averaged values are not rescaled. 
    _method : {&quot;slicing&quot;, &quot;convolve&quot;} 
        Grid averaging is implemented using numpy &quot;slicing&quot; or using 
        scipy.signal &quot;convolve&quot;. 
 
    Returns 
    ------- 
    Grid with averaged cell values. 
    &quot;&quot;&quot;</span>
    <span class="s1">k_dim = values.ndim</span>
    <span class="s3">if </span><span class="s1">_method == </span><span class="s5">&quot;slicing&quot;</span><span class="s1">:</span>
        <span class="s1">p = values.copy()</span>

        <span class="s3">for </span><span class="s1">d </span><span class="s3">in </span><span class="s1">range(k_dim):</span>
            <span class="s0"># average (p[:-1] + p[1:]) / 2 over each axis</span>
            <span class="s1">sl1 = [slice(</span><span class="s3">None, None, None</span><span class="s1">)] * k_dim</span>
            <span class="s1">sl2 = [slice(</span><span class="s3">None, None, None</span><span class="s1">)] * k_dim</span>
            <span class="s1">sl1[d] = slice(</span><span class="s3">None, </span><span class="s1">-</span><span class="s4">1</span><span class="s3">, None</span><span class="s1">)</span>
            <span class="s1">sl2[d] = slice(</span><span class="s4">1</span><span class="s3">, None, None</span><span class="s1">)</span>
            <span class="s1">sl1 = tuple(sl1)</span>
            <span class="s1">sl2 = tuple(sl2)</span>

            <span class="s1">p = (p[sl1] + p[sl2]) / </span><span class="s4">2</span>

    <span class="s3">elif </span><span class="s1">_method == </span><span class="s5">&quot;convolve&quot;</span><span class="s1">:</span>
        <span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">signal</span>
        <span class="s1">p = signal.convolve(values</span><span class="s3">, </span><span class="s4">0.5</span><span class="s1">**k_dim * np.ones([</span><span class="s4">2</span><span class="s1">] * k_dim)</span><span class="s3">,</span>
                            <span class="s1">mode=</span><span class="s5">&quot;valid&quot;</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">coords </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">dx = np.array(</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s3">for </span><span class="s1">d </span><span class="s3">in </span><span class="s1">range(k_dim):</span>
            <span class="s1">dx = dx[...</span><span class="s3">, None</span><span class="s1">] * np.diff(coords[d])</span>

        <span class="s1">p = p * dx</span>

    <span class="s3">return </span><span class="s1">p</span>


<span class="s3">def </span><span class="s1">nearest_matrix_margins(mat</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">tol=</span><span class="s4">1e-8</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;nearest matrix with uniform margins 
 
    Parameters 
    ---------- 
    mat : array_like, 2-D 
        Matrix that will be converted to have uniform margins. 
        Currently, `mat` has to be two dimensional. 
    maxiter : in 
        Maximum number of iterations. 
    tol : float 
        Tolerance for convergence, defined for difference between largest and 
        smallest margin in each dimension. 
 
    Returns 
    ------- 
    ndarray, nearest matrix with uniform margins. 
 
    Notes 
    ----- 
    This function is intended for internal use and will be generalized in 
    future. API will change. 
 
    changed in 0.14 to support k_dim &gt; 2. 
 
 
    &quot;&quot;&quot;</span>
    <span class="s1">pc = np.asarray(mat)</span>
    <span class="s1">converged = </span><span class="s3">False</span>

    <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range(maxiter):</span>
        <span class="s1">pc0 = pc.copy()</span>
        <span class="s3">for </span><span class="s1">ax </span><span class="s3">in </span><span class="s1">range(pc.ndim):</span>
            <span class="s1">axs = tuple([i </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(pc.ndim) </span><span class="s3">if not </span><span class="s1">i == ax])</span>
            <span class="s1">pc0 /= pc.sum(axis=axs</span><span class="s3">, </span><span class="s1">keepdims=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s1">pc = pc0</span>
        <span class="s1">pc /= pc.sum()</span>

        <span class="s0"># check convergence</span>
        <span class="s1">mptps = []</span>
        <span class="s3">for </span><span class="s1">ax </span><span class="s3">in </span><span class="s1">range(pc.ndim):</span>
            <span class="s1">axs = tuple([i </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(pc.ndim) </span><span class="s3">if not </span><span class="s1">i == ax])</span>
            <span class="s1">marg = pc.sum(axis=axs</span><span class="s3">, </span><span class="s1">keepdims=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">mptps.append(np.ptp(marg))</span>
        <span class="s3">if </span><span class="s1">max(mptps) &lt; tol:</span>
            <span class="s1">converged = </span><span class="s3">True</span>
            <span class="s3">break</span>

    <span class="s3">if not </span><span class="s1">converged:</span>
        <span class="s3">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>
        <span class="s1">warnings.warn(</span><span class="s5">&quot;Iterations did not converge, maxiter reached&quot;</span><span class="s3">,</span>
                      <span class="s1">ConvergenceWarning)</span>
    <span class="s3">return </span><span class="s1">pc</span>


<span class="s3">def </span><span class="s1">_rankdata_no_ties(x):</span>
    <span class="s2">&quot;&quot;&quot;rankdata without ties for 2-d array 
 
    This is a simplified version for ranking data if there are no ties. 
    Works vectorized across columns. 
 
    See Also 
    -------- 
    scipy.stats.rankdata 
 
    &quot;&quot;&quot;</span>
    <span class="s1">nobs</span><span class="s3">, </span><span class="s1">k_vars = x.shape</span>
    <span class="s1">ranks = np.ones((nobs</span><span class="s3">, </span><span class="s1">k_vars))</span>
    <span class="s1">sidx = np.argsort(x</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">ranks[sidx</span><span class="s3">, </span><span class="s1">np.arange(k_vars)] = np.arange(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">nobs + </span><span class="s4">1</span><span class="s1">)[:</span><span class="s3">, None</span><span class="s1">]</span>
    <span class="s3">return </span><span class="s1">ranks</span>


<span class="s3">def </span><span class="s1">frequencies_fromdata(data</span><span class="s3">, </span><span class="s1">k_bins</span><span class="s3">, </span><span class="s1">use_ranks=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;count of observations in bins (histogram) 
 
    currently only for bivariate data 
 
    Parameters 
    ---------- 
    data : array_like 
        Bivariate data with observations in rows and two columns. Binning is 
        in unit rectangle [0, 1]^2. If use_rank is False, then data should be 
        in unit interval. 
    k_bins : int 
        Number of bins along each dimension in the histogram 
    use_ranks : bool 
        If use_rank is True, then data will be converted to ranks without 
        tie handling. 
 
    Returns 
    ------- 
    bin counts : ndarray 
        Frequencies are the number of observations in a given bin. 
        Bin counts are a 2-dim array with k_bins rows and k_bins columns. 
 
    Notes 
    ----- 
    This function is intended for internal use and will be generalized in 
    future. API will change. 
    &quot;&quot;&quot;</span>
    <span class="s1">data = np.asarray(data)</span>
    <span class="s1">k_dim = data.shape[-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">k = k_bins + </span><span class="s4">1</span>
    <span class="s1">g2 = _Grid([k] * k_dim</span><span class="s3">, </span><span class="s1">eps=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s3">if </span><span class="s1">use_ranks:</span>
        <span class="s1">data = _rankdata_no_ties(data) / (data.shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s0"># alternatives: scipy handles ties, but uses np.apply_along_axis</span>
        <span class="s0"># rvs = stats.rankdata(rvs, axis=0) / (rvs.shape[0] + 1)</span>
        <span class="s0"># rvs = (np.argsort(np.argsort(rvs, axis=0), axis=0) + 1</span>
        <span class="s0">#                              ) / (rvs.shape[0] + 1)</span>
    <span class="s1">freqr</span><span class="s3">, </span><span class="s1">_ = np.histogramdd(data</span><span class="s3">, </span><span class="s1">bins=g2.x_marginal)</span>
    <span class="s3">return </span><span class="s1">freqr</span>


<span class="s3">def </span><span class="s1">approx_copula_pdf(copula</span><span class="s3">, </span><span class="s1">k_bins=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">force_uniform=</span><span class="s3">True, </span><span class="s1">use_pdf=</span><span class="s3">False</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Histogram probabilities as approximation to a copula density. 
 
    Parameters 
    ---------- 
    copula : instance 
        Instance of a copula class. Only the ``pdf`` method is used. 
    k_bins : int 
        Number of bins along each dimension in the approximating histogram. 
    force_uniform : bool 
        If true, then the pdf grid will be adjusted to have uniform margins 
        using `nearest_matrix_margin`. 
        If false, then no adjustment is done and the margins may not be exactly 
        uniform. 
    use_pdf : bool 
        If false, then the grid cell probabilities will be computed from the 
        copula cdf. 
        If true, then the density, ``pdf``, is used and cell probabilities 
        are approximated by averaging the pdf of the cell corners. This is 
        only useful if the cdf is not available. 
 
    Returns 
    ------- 
    bin probabilites : ndarray 
        Probability that random variable falls in given bin. This corresponds 
        to a discrete distribution, and is not scaled to bin size to form a 
        piecewise uniform, histogram density. 
        Bin probabilities are a k-dim array with k_bins segments in each 
        dimensionrows. 
 
    Notes 
    ----- 
    This function is intended for internal use and will be generalized in 
    future. API will change. 
    &quot;&quot;&quot;</span>
    <span class="s1">k_dim = copula.k_dim</span>
    <span class="s1">k = k_bins + </span><span class="s4">1</span>
    <span class="s1">ks = tuple([k] * k_dim)</span>

    <span class="s3">if </span><span class="s1">use_pdf:</span>
        <span class="s1">g = _Grid([k] * k_dim</span><span class="s3">, </span><span class="s1">eps=</span><span class="s4">0.1 </span><span class="s1">/ k_bins)</span>
        <span class="s1">pdfg = copula.pdf(g.x_flat).reshape(*ks)</span>
        <span class="s0"># correct for bin size</span>
        <span class="s1">pdfg *= </span><span class="s4">1 </span><span class="s1">/ k**k_dim</span>
        <span class="s1">ag = average_grid(pdfg)</span>
        <span class="s3">if </span><span class="s1">force_uniform:</span>
            <span class="s1">pdf_grid = nearest_matrix_margins(ag</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">tol=</span><span class="s4">1e-8</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">pdf_grid = ag / ag.sum()</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">g = _Grid([k] * k_dim</span><span class="s3">, </span><span class="s1">eps=</span><span class="s4">1e-6</span><span class="s1">)</span>
        <span class="s1">cdfg = copula.cdf(g.x_flat).reshape(*ks)</span>
        <span class="s0"># correct for bin size</span>
        <span class="s1">pdf_grid = cdf2prob_grid(cdfg</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">None</span><span class="s1">)</span>
        <span class="s0"># TODO: check boundary approximation, eg. undefined at zero</span>
        <span class="s0"># for now just normalize</span>
        <span class="s1">pdf_grid /= pdf_grid.sum()</span>

    <span class="s3">return </span><span class="s1">pdf_grid</span>


<span class="s0"># functions to evaluate bernstein polynomials</span>

<span class="s3">def </span><span class="s1">_eval_bernstein_1d(x</span><span class="s3">, </span><span class="s1">fvals</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">&quot;binom&quot;</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Evaluate 1-dimensional bernstein polynomial given grid of values. 
 
    experimental, comparing methods 
 
    Parameters 
    ---------- 
    x : array_like 
        Values at which to evaluate the Bernstein polynomial. 
    fvals : ndarray 
        Grid values of coefficients for Bernstein polynomial basis in the 
        weighted sum. 
    method: &quot;binom&quot;, &quot;beta&quot; or &quot;bpoly&quot; 
        Method to construct Bernstein polynomial basis, used for comparison 
        of parameterizations. 
 
        - &quot;binom&quot; uses pmf of Binomial distribution 
        - &quot;beta&quot; uses pdf of Beta distribution 
        - &quot;bpoly&quot; uses one interval in scipy.interpolate.BPoly 
 
    Returns 
    ------- 
    Bernstein polynomial at evaluation points, weighted sum of Bernstein 
    polynomial basis. 
    &quot;&quot;&quot;</span>
    <span class="s1">k_terms = fvals.shape[-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">xx = np.asarray(x)</span>
    <span class="s1">k = np.arange(k_terms).astype(float)</span>
    <span class="s1">n = k_terms - </span><span class="s4">1.</span>

    <span class="s3">if </span><span class="s1">method.lower() == </span><span class="s5">&quot;binom&quot;</span><span class="s1">:</span>
        <span class="s0"># Divide by 0 RuntimeWarning here</span>
        <span class="s3">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;ignore&quot;</span><span class="s3">, </span><span class="s1">RuntimeWarning)</span>
            <span class="s1">poly_base = stats.binom.pmf(k</span><span class="s3">, </span><span class="s1">n</span><span class="s3">, </span><span class="s1">xx[...</span><span class="s3">, None</span><span class="s1">])</span>
        <span class="s1">bp_values = (fvals * poly_base).sum(-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s3">elif </span><span class="s1">method.lower() == </span><span class="s5">&quot;bpoly&quot;</span><span class="s1">:</span>
        <span class="s1">bpb = interpolate.BPoly(fvals[:</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0.</span><span class="s3">, </span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">bp_values = bpb(x)</span>
    <span class="s3">elif </span><span class="s1">method.lower() == </span><span class="s5">&quot;beta&quot;</span><span class="s1">:</span>
        <span class="s0"># Divide by 0 RuntimeWarning here</span>
        <span class="s3">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.simplefilter(</span><span class="s5">&quot;ignore&quot;</span><span class="s3">, </span><span class="s1">RuntimeWarning)</span>
            <span class="s1">poly_base = stats.beta.pdf(xx[...</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">, </span><span class="s1">k + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n - k + </span><span class="s4">1</span><span class="s1">) / (n + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">bp_values = (fvals * poly_base).sum(-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;method not recogized&quot;</span><span class="s1">)</span>

    <span class="s3">return </span><span class="s1">bp_values</span>


<span class="s3">def </span><span class="s1">_eval_bernstein_2d(x</span><span class="s3">, </span><span class="s1">fvals):</span>
    <span class="s2">&quot;&quot;&quot;Evaluate 2-dimensional bernstein polynomial given grid of values 
 
    experimental 
 
    Parameters 
    ---------- 
    x : array_like 
        Values at which to evaluate the Bernstein polynomial. 
    fvals : ndarray 
        Grid values of coefficients for Bernstein polynomial basis in the 
        weighted sum. 
 
    Returns 
    ------- 
    Bernstein polynomial at evaluation points, weighted sum of Bernstein 
    polynomial basis. 
    &quot;&quot;&quot;</span>
    <span class="s1">k_terms = fvals.shape</span>
    <span class="s1">k_dim = fvals.ndim</span>
    <span class="s3">if </span><span class="s1">k_dim != </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;`fval` needs to be 2-dimensional&quot;</span><span class="s1">)</span>
    <span class="s1">xx = np.atleast_2d(x)</span>
    <span class="s3">if </span><span class="s1">xx.shape[</span><span class="s4">1</span><span class="s1">] != </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;x needs to be bivariate and have 2 columns&quot;</span><span class="s1">)</span>

    <span class="s1">x1</span><span class="s3">, </span><span class="s1">x2 = xx.T</span>
    <span class="s1">n1</span><span class="s3">, </span><span class="s1">n2 = k_terms[</span><span class="s4">0</span><span class="s1">] - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">k_terms[</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">1</span>
    <span class="s1">k1 = np.arange(k_terms[</span><span class="s4">0</span><span class="s1">]).astype(float)</span>
    <span class="s1">k2 = np.arange(k_terms[</span><span class="s4">1</span><span class="s1">]).astype(float)</span>

    <span class="s0"># we are building a nobs x n1 x n2 array</span>
    <span class="s1">poly_base = (stats.binom.pmf(k1[</span><span class="s3">None, </span><span class="s1">:</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">, </span><span class="s1">n1</span><span class="s3">, </span><span class="s1">x1[:</span><span class="s3">, None, None</span><span class="s1">]) *</span>
                 <span class="s1">stats.binom.pmf(k2[</span><span class="s3">None, None, </span><span class="s1">:]</span><span class="s3">, </span><span class="s1">n2</span><span class="s3">, </span><span class="s1">x2[:</span><span class="s3">, None, None</span><span class="s1">]))</span>
    <span class="s1">bp_values = (fvals * poly_base).sum(-</span><span class="s4">1</span><span class="s1">).sum(-</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s3">return </span><span class="s1">bp_values</span>


<span class="s3">def </span><span class="s1">_eval_bernstein_dd(x</span><span class="s3">, </span><span class="s1">fvals):</span>
    <span class="s2">&quot;&quot;&quot;Evaluate d-dimensional bernstein polynomial given grid of valuesv 
 
    experimental 
 
    Parameters 
    ---------- 
    x : array_like 
        Values at which to evaluate the Bernstein polynomial. 
    fvals : ndarray 
        Grid values of coefficients for Bernstein polynomial basis in the 
        weighted sum. 
 
    Returns 
    ------- 
    Bernstein polynomial at evaluation points, weighted sum of Bernstein 
    polynomial basis. 
    &quot;&quot;&quot;</span>
    <span class="s1">k_terms = fvals.shape</span>
    <span class="s1">k_dim = fvals.ndim</span>
    <span class="s1">xx = np.atleast_2d(x)</span>

    <span class="s0"># The following loop is a tricky</span>
    <span class="s0"># we add terms for each x and expand dimension of poly base in each</span>
    <span class="s0"># iteration using broadcasting</span>

    <span class="s1">poly_base = np.zeros(x.shape[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k_dim):</span>
        <span class="s1">ki = np.arange(k_terms[i]).astype(float)</span>
        <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range(i+</span><span class="s4">1</span><span class="s1">):</span>
            <span class="s1">ki = ki[...</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">ni = k_terms[i] - </span><span class="s4">1</span>
        <span class="s1">xi = xx[:</span><span class="s3">, </span><span class="s1">i]</span>
        <span class="s1">poly_base = poly_base[</span><span class="s3">None, </span><span class="s1">...] + stats.binom._logpmf(ki</span><span class="s3">, </span><span class="s1">ni</span><span class="s3">, </span><span class="s1">xi)</span>

    <span class="s1">poly_base = np.exp(poly_base)</span>
    <span class="s1">bp_values = fvals.T[...</span><span class="s3">, None</span><span class="s1">] * poly_base</span>

    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(k_dim):</span>
        <span class="s1">bp_values = bp_values.sum(</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3">return </span><span class="s1">bp_values</span>


<span class="s3">def </span><span class="s1">_ecdf_mv(data</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">&quot;seq&quot;</span><span class="s3">, </span><span class="s1">use_ranks=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Multivariate empiricial distribution function, empirical copula 
 
 
    Notes 
    ----- 
    Method &quot;seq&quot; is faster than method &quot;brute&quot;, but supports mainly bivariate 
    case. Speed advantage of &quot;seq&quot; is increasing in number of observations 
    and decreasing in number of variables. 
    (see Segers ...) 
 
    Warning: This does not handle ties. The ecdf is based on univariate ranks 
    without ties. The assignment of ranks to ties depends on the sorting 
    algorithm and the initial ordering of the data. 
 
    When the original data is used instead of ranks, then method &quot;brute&quot; 
    computes the correct ecdf counts even in the case of ties. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.asarray(data)</span>
    <span class="s1">n = x.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s3">if </span><span class="s1">use_ranks:</span>
        <span class="s1">x = _rankdata_no_ties(x) / n</span>
    <span class="s3">if </span><span class="s1">method == </span><span class="s5">&quot;brute&quot;</span><span class="s1">:</span>
        <span class="s1">count = [((x &lt;= x[i]).all(</span><span class="s4">1</span><span class="s1">)).sum() </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(n)]</span>
        <span class="s1">count = np.asarray(count)</span>
    <span class="s3">elif </span><span class="s1">method.startswith(</span><span class="s5">&quot;seq&quot;</span><span class="s1">):</span>
        <span class="s1">sort_idx0 = np.argsort(x[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">x_s0 = x[sort_idx0]</span>
        <span class="s1">x1 = x_s0[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span>
        <span class="s1">count_smaller = [(x1[:i] &lt;= x1[i]).all(</span><span class="s4">1</span><span class="s1">).sum() + </span><span class="s4">1 </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(n)]</span>
        <span class="s1">count = np.empty(x.shape[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">count[sort_idx0] = count_smaller</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;method not available&quot;</span><span class="s1">)</span>

    <span class="s3">return </span><span class="s1">count</span><span class="s3">, </span><span class="s1">x</span>
</pre>
</body>
</html>
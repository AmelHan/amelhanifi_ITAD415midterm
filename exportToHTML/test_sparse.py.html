<html>
<head>
<title>test_sparse.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_sparse.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_array_almost_equal</span><span class="s0">, </span><span class="s1">assert_array_equal</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">sparse</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">base</span><span class="s0">, </span><span class="s1">datasets</span><span class="s0">, </span><span class="s1">linear_model</span><span class="s0">, </span><span class="s1">svm</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">load_digits</span><span class="s0">, </span><span class="s1">make_blobs</span><span class="s0">, </span><span class="s1">make_classification</span>
<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn.svm.tests </span><span class="s0">import </span><span class="s1">test_svm</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">ignore_warnings</span><span class="s0">, </span><span class="s1">skip_if_32bit</span>
<span class="s0">from </span><span class="s1">sklearn.utils.extmath </span><span class="s0">import </span><span class="s1">safe_sparse_dot</span>

<span class="s2"># test sample 1</span>
<span class="s1">X = np.array([[-</span><span class="s3">2</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]])</span>
<span class="s1">X_sp = sparse.lil_matrix(X)</span>
<span class="s1">Y = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span>
<span class="s1">T = np.array([[-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]])</span>
<span class="s1">true_result = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span>

<span class="s2"># test sample 2</span>
<span class="s1">X2 = np.array(</span>
    <span class="s1">[</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">X2_sp = sparse.dok_matrix(X2)</span>
<span class="s1">Y2 = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span>
<span class="s1">T2 = np.array([[-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]])</span>
<span class="s1">true_result2 = [</span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span>


<span class="s1">iris = datasets.load_iris()</span>
<span class="s2"># permute</span>
<span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
<span class="s1">perm = rng.permutation(iris.target.size)</span>
<span class="s1">iris.data = iris.data[perm]</span>
<span class="s1">iris.target = iris.target[perm]</span>
<span class="s2"># sparsify</span>
<span class="s1">iris.data = sparse.csr_matrix(iris.data)</span>


<span class="s0">def </span><span class="s1">check_svm_model_equal(dense_svm</span><span class="s0">, </span><span class="s1">sparse_svm</span><span class="s0">, </span><span class="s1">X_train</span><span class="s0">, </span><span class="s1">y_train</span><span class="s0">, </span><span class="s1">X_test):</span>
    <span class="s1">dense_svm.fit(X_train.toarray()</span><span class="s0">, </span><span class="s1">y_train)</span>
    <span class="s0">if </span><span class="s1">sparse.issparse(X_test):</span>
        <span class="s1">X_test_dense = X_test.toarray()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">X_test_dense = X_test</span>
    <span class="s1">sparse_svm.fit(X_train</span><span class="s0">, </span><span class="s1">y_train)</span>
    <span class="s0">assert </span><span class="s1">sparse.issparse(sparse_svm.support_vectors_)</span>
    <span class="s0">assert </span><span class="s1">sparse.issparse(sparse_svm.dual_coef_)</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">dense_svm.support_vectors_</span><span class="s0">, </span><span class="s1">sparse_svm.support_vectors_.toarray()</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(dense_svm.dual_coef_</span><span class="s0">, </span><span class="s1">sparse_svm.dual_coef_.toarray())</span>
    <span class="s0">if </span><span class="s1">dense_svm.kernel == </span><span class="s4">&quot;linear&quot;</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">sparse.issparse(sparse_svm.coef_)</span>
        <span class="s1">assert_array_almost_equal(dense_svm.coef_</span><span class="s0">, </span><span class="s1">sparse_svm.coef_.toarray())</span>
    <span class="s1">assert_array_almost_equal(dense_svm.support_</span><span class="s0">, </span><span class="s1">sparse_svm.support_)</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">dense_svm.predict(X_test_dense)</span><span class="s0">, </span><span class="s1">sparse_svm.predict(X_test)</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">dense_svm.decision_function(X_test_dense)</span><span class="s0">, </span><span class="s1">sparse_svm.decision_function(X_test)</span>
    <span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">dense_svm.decision_function(X_test_dense)</span><span class="s0">,</span>
        <span class="s1">sparse_svm.decision_function(X_test_dense)</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">isinstance(dense_svm</span><span class="s0">, </span><span class="s1">svm.OneClassSVM):</span>
        <span class="s1">msg = </span><span class="s4">&quot;cannot use sparse input in 'OneClassSVM' trained on dense data&quot;</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">assert_array_almost_equal(</span>
            <span class="s1">dense_svm.predict_proba(X_test_dense)</span><span class="s0">, </span><span class="s1">sparse_svm.predict_proba(X_test)</span><span class="s0">, </span><span class="s3">4</span>
        <span class="s1">)</span>
        <span class="s1">msg = </span><span class="s4">&quot;cannot use sparse input in 'SVC' trained on dense data&quot;</span>
    <span class="s0">if </span><span class="s1">sparse.issparse(X_test):</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">dense_svm.predict(X_test)</span>


<span class="s1">@skip_if_32bit</span>
<span class="s0">def </span><span class="s1">test_svc():</span>
    <span class="s5">&quot;&quot;&quot;Check that sparse SVC gives the same result as SVC&quot;&quot;&quot;</span>
    <span class="s2"># many class dataset:</span>
    <span class="s1">X_blobs</span><span class="s0">, </span><span class="s1">y_blobs = make_blobs(n_samples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">centers=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X_blobs = sparse.csr_matrix(X_blobs)</span>

    <span class="s1">datasets = [</span>
        <span class="s1">[X_sp</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">T]</span><span class="s0">,</span>
        <span class="s1">[X2_sp</span><span class="s0">, </span><span class="s1">Y2</span><span class="s0">, </span><span class="s1">T2]</span><span class="s0">,</span>
        <span class="s1">[X_blobs[:</span><span class="s3">80</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y_blobs[:</span><span class="s3">80</span><span class="s1">]</span><span class="s0">, </span><span class="s1">X_blobs[</span><span class="s3">80</span><span class="s1">:]]</span><span class="s0">,</span>
        <span class="s1">[iris.data</span><span class="s0">, </span><span class="s1">iris.target</span><span class="s0">, </span><span class="s1">iris.data]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">kernels = [</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s4">&quot;poly&quot;</span><span class="s0">, </span><span class="s4">&quot;rbf&quot;</span><span class="s0">, </span><span class="s4">&quot;sigmoid&quot;</span><span class="s1">]</span>
    <span class="s0">for </span><span class="s1">dataset </span><span class="s0">in </span><span class="s1">datasets:</span>
        <span class="s0">for </span><span class="s1">kernel </span><span class="s0">in </span><span class="s1">kernels:</span>
            <span class="s1">clf = svm.SVC(</span>
                <span class="s1">gamma=</span><span class="s3">1</span><span class="s0">,</span>
                <span class="s1">kernel=kernel</span><span class="s0">,</span>
                <span class="s1">probability=</span><span class="s0">True,</span>
                <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">,</span>
                <span class="s1">decision_function_shape=</span><span class="s4">&quot;ovo&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">sp_clf = svm.SVC(</span>
                <span class="s1">gamma=</span><span class="s3">1</span><span class="s0">,</span>
                <span class="s1">kernel=kernel</span><span class="s0">,</span>
                <span class="s1">probability=</span><span class="s0">True,</span>
                <span class="s1">random_state=</span><span class="s3">0</span><span class="s0">,</span>
                <span class="s1">decision_function_shape=</span><span class="s4">&quot;ovo&quot;</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">check_svm_model_equal(clf</span><span class="s0">, </span><span class="s1">sp_clf</span><span class="s0">, </span><span class="s1">*dataset)</span>


<span class="s0">def </span><span class="s1">test_unsorted_indices():</span>
    <span class="s2"># test that the result with sorted and unsorted indices in csr is the same</span>
    <span class="s2"># we use a subset of digits as iris, blobs or make_classification didn't</span>
    <span class="s2"># show the problem</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = load_digits(return_X_y=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">X_test = sparse.csr_matrix(X[</span><span class="s3">50</span><span class="s1">:</span><span class="s3">100</span><span class="s1">])</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = X[:</span><span class="s3">50</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y[:</span><span class="s3">50</span><span class="s1">]</span>

    <span class="s1">X_sparse = sparse.csr_matrix(X)</span>
    <span class="s1">coef_dense = (</span>
        <span class="s1">svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">y).coef_</span>
    <span class="s1">)</span>
    <span class="s1">sparse_svc = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(</span>
        <span class="s1">X_sparse</span><span class="s0">, </span><span class="s1">y</span>
    <span class="s1">)</span>
    <span class="s1">coef_sorted = sparse_svc.coef_</span>
    <span class="s2"># make sure dense and sparse SVM give the same result</span>
    <span class="s1">assert_array_almost_equal(coef_dense</span><span class="s0">, </span><span class="s1">coef_sorted.toarray())</span>

    <span class="s2"># reverse each row's indices</span>
    <span class="s0">def </span><span class="s1">scramble_indices(X):</span>
        <span class="s1">new_data = []</span>
        <span class="s1">new_indices = []</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">len(X.indptr)):</span>
            <span class="s1">row_slice = slice(*X.indptr[i - </span><span class="s3">1 </span><span class="s1">: i + </span><span class="s3">1</span><span class="s1">])</span>
            <span class="s1">new_data.extend(X.data[row_slice][::-</span><span class="s3">1</span><span class="s1">])</span>
            <span class="s1">new_indices.extend(X.indices[row_slice][::-</span><span class="s3">1</span><span class="s1">])</span>
        <span class="s0">return </span><span class="s1">sparse.csr_matrix((new_data</span><span class="s0">, </span><span class="s1">new_indices</span><span class="s0">, </span><span class="s1">X.indptr)</span><span class="s0">, </span><span class="s1">shape=X.shape)</span>

    <span class="s1">X_sparse_unsorted = scramble_indices(X_sparse)</span>
    <span class="s1">X_test_unsorted = scramble_indices(X_test)</span>

    <span class="s0">assert not </span><span class="s1">X_sparse_unsorted.has_sorted_indices</span>
    <span class="s0">assert not </span><span class="s1">X_test_unsorted.has_sorted_indices</span>

    <span class="s1">unsorted_svc = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(</span>
        <span class="s1">X_sparse_unsorted</span><span class="s0">, </span><span class="s1">y</span>
    <span class="s1">)</span>
    <span class="s1">coef_unsorted = unsorted_svc.coef_</span>
    <span class="s2"># make sure unsorted indices give same result</span>
    <span class="s1">assert_array_almost_equal(coef_unsorted.toarray()</span><span class="s0">, </span><span class="s1">coef_sorted.toarray())</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">sparse_svc.predict_proba(X_test_unsorted)</span><span class="s0">, </span><span class="s1">sparse_svc.predict_proba(X_test)</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_svc_with_custom_kernel():</span>
    <span class="s0">def </span><span class="s1">kfunc(x</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s0">return </span><span class="s1">safe_sparse_dot(x</span><span class="s0">, </span><span class="s1">y.T)</span>

    <span class="s1">clf_lin = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s1">).fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">clf_mylin = svm.SVC(kernel=kfunc).fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">assert_array_equal(clf_lin.predict(X_sp)</span><span class="s0">, </span><span class="s1">clf_mylin.predict(X_sp))</span>


<span class="s1">@skip_if_32bit</span>
<span class="s0">def </span><span class="s1">test_svc_iris():</span>
    <span class="s2"># Test the sparse SVC with the iris dataset</span>
    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">(</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s4">&quot;poly&quot;</span><span class="s0">, </span><span class="s4">&quot;rbf&quot;</span><span class="s1">):</span>
        <span class="s1">sp_clf = svm.SVC(kernel=k).fit(iris.data</span><span class="s0">, </span><span class="s1">iris.target)</span>
        <span class="s1">clf = svm.SVC(kernel=k).fit(iris.data.toarray()</span><span class="s0">, </span><span class="s1">iris.target)</span>

        <span class="s1">assert_array_almost_equal(</span>
            <span class="s1">clf.support_vectors_</span><span class="s0">, </span><span class="s1">sp_clf.support_vectors_.toarray()</span>
        <span class="s1">)</span>
        <span class="s1">assert_array_almost_equal(clf.dual_coef_</span><span class="s0">, </span><span class="s1">sp_clf.dual_coef_.toarray())</span>
        <span class="s1">assert_array_almost_equal(</span>
            <span class="s1">clf.predict(iris.data.toarray())</span><span class="s0">, </span><span class="s1">sp_clf.predict(iris.data)</span>
        <span class="s1">)</span>
        <span class="s0">if </span><span class="s1">k == </span><span class="s4">&quot;linear&quot;</span><span class="s1">:</span>
            <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">sp_clf.coef_.toarray())</span>


<span class="s0">def </span><span class="s1">test_sparse_decision_function():</span>
    <span class="s2"># Test decision_function</span>

    <span class="s2"># Sanity check, test that decision_function implemented in python</span>
    <span class="s2"># returns the same as the one in libsvm</span>

    <span class="s2"># multi class:</span>
    <span class="s1">svc = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s1">C=</span><span class="s3">0.1</span><span class="s0">, </span><span class="s1">decision_function_shape=</span><span class="s4">&quot;ovo&quot;</span><span class="s1">)</span>
    <span class="s1">clf = svc.fit(iris.data</span><span class="s0">, </span><span class="s1">iris.target)</span>

    <span class="s1">dec = safe_sparse_dot(iris.data</span><span class="s0">, </span><span class="s1">clf.coef_.T) + clf.intercept_</span>

    <span class="s1">assert_array_almost_equal(dec</span><span class="s0">, </span><span class="s1">clf.decision_function(iris.data))</span>

    <span class="s2"># binary:</span>
    <span class="s1">clf.fit(X</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">dec = np.dot(X</span><span class="s0">, </span><span class="s1">clf.coef_.T) + clf.intercept_</span>
    <span class="s1">prediction = clf.predict(X)</span>
    <span class="s1">assert_array_almost_equal(dec.ravel()</span><span class="s0">, </span><span class="s1">clf.decision_function(X))</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">prediction</span><span class="s0">, </span><span class="s1">clf.classes_[(clf.decision_function(X) &gt; </span><span class="s3">0</span><span class="s1">).astype(int).ravel()]</span>
    <span class="s1">)</span>
    <span class="s1">expected = np.array([-</span><span class="s3">1.0</span><span class="s0">, </span><span class="s1">-</span><span class="s3">0.66</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">0.66</span><span class="s0">, </span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">])</span>
    <span class="s1">assert_array_almost_equal(clf.decision_function(X)</span><span class="s0">, </span><span class="s1">expected</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_error():</span>
    <span class="s2"># Test that it gives proper exception on deficient input</span>
    <span class="s1">clf = svm.SVC()</span>

    <span class="s1">Y2 = Y[:-</span><span class="s3">1</span><span class="s1">]  </span><span class="s2"># wrong dimensions for labels</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">clf.fit(X_sp</span><span class="s0">, </span><span class="s1">Y2)</span>

    <span class="s1">clf.fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">assert_array_equal(clf.predict(T)</span><span class="s0">, </span><span class="s1">true_result)</span>


<span class="s0">def </span><span class="s1">test_linearsvc():</span>
    <span class="s2"># Similar to test_SVC</span>
    <span class="s1">clf = svm.LinearSVC(dual=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">sp_clf = svm.LinearSVC(dual=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>

    <span class="s0">assert </span><span class="s1">sp_clf.fit_intercept</span>

    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">sp_clf.coef_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(clf.intercept_</span><span class="s0">, </span><span class="s1">sp_clf.intercept_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">4</span><span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(clf.predict(X)</span><span class="s0">, </span><span class="s1">sp_clf.predict(X_sp))</span>

    <span class="s1">clf.fit(X2</span><span class="s0">, </span><span class="s1">Y2)</span>
    <span class="s1">sp_clf.fit(X2_sp</span><span class="s0">, </span><span class="s1">Y2)</span>

    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">sp_clf.coef_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">4</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(clf.intercept_</span><span class="s0">, </span><span class="s1">sp_clf.intercept_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">4</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_linearsvc_iris():</span>
    <span class="s2"># Test the sparse LinearSVC with the iris dataset</span>

    <span class="s1">sp_clf = svm.LinearSVC(dual=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(iris.data</span><span class="s0">, </span><span class="s1">iris.target)</span>
    <span class="s1">clf = svm.LinearSVC(dual=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">).fit(</span>
        <span class="s1">iris.data.toarray()</span><span class="s0">, </span><span class="s1">iris.target</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">clf.fit_intercept == sp_clf.fit_intercept</span>

    <span class="s1">assert_array_almost_equal(clf.coef_</span><span class="s0">, </span><span class="s1">sp_clf.coef_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(clf.intercept_</span><span class="s0">, </span><span class="s1">sp_clf.intercept_</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(</span>
        <span class="s1">clf.predict(iris.data.toarray())</span><span class="s0">, </span><span class="s1">sp_clf.predict(iris.data)</span>
    <span class="s1">)</span>

    <span class="s2"># check decision_function</span>
    <span class="s1">pred = np.argmax(sp_clf.decision_function(iris.data)</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(pred</span><span class="s0">, </span><span class="s1">clf.predict(iris.data.toarray()))</span>

    <span class="s2"># sparsify the coefficients on both models and check that they still</span>
    <span class="s2"># produce the same results</span>
    <span class="s1">clf.sparsify()</span>
    <span class="s1">assert_array_equal(pred</span><span class="s0">, </span><span class="s1">clf.predict(iris.data))</span>
    <span class="s1">sp_clf.sparsify()</span>
    <span class="s1">assert_array_equal(pred</span><span class="s0">, </span><span class="s1">sp_clf.predict(iris.data))</span>


<span class="s0">def </span><span class="s1">test_weight():</span>
    <span class="s2"># Test class weights</span>
    <span class="s1">X_</span><span class="s0">, </span><span class="s1">y_ = make_classification(</span>
        <span class="s1">n_samples=</span><span class="s3">200</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">weights=[</span><span class="s3">0.833</span><span class="s0">, </span><span class="s3">0.167</span><span class="s1">]</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>

    <span class="s1">X_ = sparse.csr_matrix(X_)</span>
    <span class="s0">for </span><span class="s1">clf </span><span class="s0">in </span><span class="s1">(</span>
        <span class="s1">linear_model.LogisticRegression()</span><span class="s0">,</span>
        <span class="s1">svm.LinearSVC(dual=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">svm.SVC()</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">clf.set_params(class_weight={</span><span class="s3">0</span><span class="s1">: </span><span class="s3">5</span><span class="s1">})</span>
        <span class="s1">clf.fit(X_[:</span><span class="s3">180</span><span class="s1">]</span><span class="s0">, </span><span class="s1">y_[:</span><span class="s3">180</span><span class="s1">])</span>
        <span class="s1">y_pred = clf.predict(X_[</span><span class="s3">180</span><span class="s1">:])</span>
        <span class="s0">assert </span><span class="s1">np.sum(y_pred == y_[</span><span class="s3">180</span><span class="s1">:]) &gt;= </span><span class="s3">11</span>


<span class="s0">def </span><span class="s1">test_sample_weights():</span>
    <span class="s2"># Test weights on individual samples</span>
    <span class="s1">clf = svm.SVC()</span>
    <span class="s1">clf.fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">assert_array_equal(clf.predict([X[</span><span class="s3">2</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">[</span><span class="s3">1.0</span><span class="s1">])</span>

    <span class="s1">sample_weight = [</span><span class="s3">0.1</span><span class="s1">] * </span><span class="s3">3 </span><span class="s1">+ [</span><span class="s3">10</span><span class="s1">] * </span><span class="s3">3</span>
    <span class="s1">clf.fit(X_sp</span><span class="s0">, </span><span class="s1">Y</span><span class="s0">, </span><span class="s1">sample_weight=sample_weight)</span>
    <span class="s1">assert_array_equal(clf.predict([X[</span><span class="s3">2</span><span class="s1">]])</span><span class="s0">, </span><span class="s1">[</span><span class="s3">2.0</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_sparse_liblinear_intercept_handling():</span>
    <span class="s2"># Test that sparse liblinear honours intercept_scaling param</span>
    <span class="s1">test_svm.test_dense_liblinear_intercept_handling(svm.LinearSVC)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;datasets_index&quot;</span><span class="s0">, </span><span class="s1">range(</span><span class="s3">4</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;kernel&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">&quot;linear&quot;</span><span class="s0">, </span><span class="s4">&quot;poly&quot;</span><span class="s0">, </span><span class="s4">&quot;rbf&quot;</span><span class="s0">, </span><span class="s4">&quot;sigmoid&quot;</span><span class="s1">])</span>
<span class="s1">@skip_if_32bit</span>
<span class="s0">def </span><span class="s1">test_sparse_oneclasssvm(datasets_index</span><span class="s0">, </span><span class="s1">kernel):</span>
    <span class="s2"># Check that sparse OneClassSVM gives the same result as dense OneClassSVM</span>
    <span class="s2"># many class dataset:</span>
    <span class="s1">X_blobs</span><span class="s0">, </span><span class="s1">_ = make_blobs(n_samples=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">centers=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">X_blobs = sparse.csr_matrix(X_blobs)</span>
    <span class="s1">datasets = [</span>
        <span class="s1">[X_sp</span><span class="s0">, None, </span><span class="s1">T]</span><span class="s0">,</span>
        <span class="s1">[X2_sp</span><span class="s0">, None, </span><span class="s1">T2]</span><span class="s0">,</span>
        <span class="s1">[X_blobs[:</span><span class="s3">80</span><span class="s1">]</span><span class="s0">, None, </span><span class="s1">X_blobs[</span><span class="s3">80</span><span class="s1">:]]</span><span class="s0">,</span>
        <span class="s1">[iris.data</span><span class="s0">, None, </span><span class="s1">iris.data]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">dataset = datasets[datasets_index]</span>
    <span class="s1">clf = svm.OneClassSVM(gamma=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">kernel=kernel)</span>
    <span class="s1">sp_clf = svm.OneClassSVM(gamma=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">kernel=kernel)</span>
    <span class="s1">check_svm_model_equal(clf</span><span class="s0">, </span><span class="s1">sp_clf</span><span class="s0">, </span><span class="s1">*dataset)</span>


<span class="s0">def </span><span class="s1">test_sparse_realdata():</span>
    <span class="s2"># Test on a subset from the 20newsgroups dataset.</span>
    <span class="s2"># This catches some bugs if input is not correctly converted into</span>
    <span class="s2"># sparse format or weights are not correctly initialized.</span>

    <span class="s1">data = np.array([</span><span class="s3">0.03771744</span><span class="s0">, </span><span class="s3">0.1003567</span><span class="s0">, </span><span class="s3">0.01174647</span><span class="s0">, </span><span class="s3">0.027069</span><span class="s1">])</span>
    <span class="s1">indices = np.array([</span><span class="s3">6</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">35</span><span class="s0">, </span><span class="s3">31</span><span class="s1">])</span>
    <span class="s1">indptr = np.array(</span>
        <span class="s1">[</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">0</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">1</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">2</span><span class="s0">,</span>
            <span class="s3">4</span><span class="s0">,</span>
            <span class="s3">4</span><span class="s0">,</span>
            <span class="s3">4</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">X = sparse.csr_matrix((data</span><span class="s0">, </span><span class="s1">indices</span><span class="s0">, </span><span class="s1">indptr))</span>
    <span class="s1">y = np.array(</span>
        <span class="s1">[</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">0.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">2.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">1.0</span><span class="s0">,</span>
            <span class="s3">3.0</span><span class="s0">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>

    <span class="s1">clf = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s1">).fit(X.toarray()</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">sp_clf = svm.SVC(kernel=</span><span class="s4">&quot;linear&quot;</span><span class="s1">).fit(sparse.coo_matrix(X)</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">assert_array_equal(clf.support_vectors_</span><span class="s0">, </span><span class="s1">sp_clf.support_vectors_.toarray())</span>
    <span class="s1">assert_array_equal(clf.dual_coef_</span><span class="s0">, </span><span class="s1">sp_clf.dual_coef_.toarray())</span>


<span class="s0">def </span><span class="s1">test_sparse_svc_clone_with_callable_kernel():</span>
    <span class="s2"># Test that the &quot;dense_fit&quot; is called even though we use sparse input</span>
    <span class="s2"># meaning that everything works fine.</span>
    <span class="s1">a = svm.SVC(C=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">kernel=</span><span class="s0">lambda </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y: x * y.T</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">b = base.clone(a)</span>

    <span class="s1">b.fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>
    <span class="s1">pred = b.predict(X_sp)</span>
    <span class="s1">b.predict_proba(X_sp)</span>

    <span class="s1">dense_svm = svm.SVC(</span>
        <span class="s1">C=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">kernel=</span><span class="s0">lambda </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y: np.dot(x</span><span class="s0">, </span><span class="s1">y.T)</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span>
    <span class="s1">)</span>
    <span class="s1">pred_dense = dense_svm.fit(X</span><span class="s0">, </span><span class="s1">Y).predict(X)</span>
    <span class="s1">assert_array_equal(pred_dense</span><span class="s0">, </span><span class="s1">pred)</span>
    <span class="s2"># b.decision_function(X_sp)  # XXX : should be supported</span>


<span class="s0">def </span><span class="s1">test_timeout():</span>
    <span class="s1">sp = svm.SVC(</span>
        <span class="s1">C=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">kernel=</span><span class="s0">lambda </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y: x * y.T</span><span class="s0">, </span><span class="s1">probability=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">max_iter=</span><span class="s3">1</span>
    <span class="s1">)</span>
    <span class="s1">warning_msg = (</span>
        <span class="s4">r&quot;Solver terminated early \(max_iter=1\).  Consider pre-processing &quot;</span>
        <span class="s4">r&quot;your data with StandardScaler or MinMaxScaler.&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.warns(ConvergenceWarning</span><span class="s0">, </span><span class="s1">match=warning_msg):</span>
        <span class="s1">sp.fit(X_sp</span><span class="s0">, </span><span class="s1">Y)</span>


<span class="s0">def </span><span class="s1">test_consistent_proba():</span>
    <span class="s1">a = svm.SVC(probability=</span><span class="s0">True, </span><span class="s1">max_iter=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
        <span class="s1">proba_1 = a.fit(X</span><span class="s0">, </span><span class="s1">Y).predict_proba(X)</span>
    <span class="s1">a = svm.SVC(probability=</span><span class="s0">True, </span><span class="s1">max_iter=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s0">with </span><span class="s1">ignore_warnings(category=ConvergenceWarning):</span>
        <span class="s1">proba_2 = a.fit(X</span><span class="s0">, </span><span class="s1">Y).predict_proba(X)</span>
    <span class="s1">assert_array_almost_equal(proba_1</span><span class="s0">, </span><span class="s1">proba_2)</span>
</pre>
</body>
</html>
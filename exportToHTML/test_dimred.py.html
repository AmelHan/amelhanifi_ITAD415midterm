<html>
<head>
<title>test_dimred.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_dimred.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">statsmodels.regression.dimred </span><span class="s0">import </span><span class="s1">(</span>
     <span class="s1">SlicedInverseReg</span><span class="s0">, </span><span class="s1">SAVE</span><span class="s0">, </span><span class="s1">PHD</span><span class="s0">, </span><span class="s1">CORE)</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(assert_equal</span><span class="s0">, </span><span class="s1">assert_allclose)</span>
<span class="s0">from </span><span class="s1">statsmodels.tools.numdiff </span><span class="s0">import </span><span class="s1">approx_fprime</span>


<span class="s0">def </span><span class="s1">test_poisson():</span>

    <span class="s1">np.random.seed(</span><span class="s2">43242</span><span class="s1">)</span>

    <span class="s3"># Generate a non-orthogonal design matrix</span>
    <span class="s1">xmat = np.random.normal(size=(</span><span class="s2">500</span><span class="s0">, </span><span class="s2">5</span><span class="s1">))</span>
    <span class="s1">xmat[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] = </span><span class="s2">0.5</span><span class="s1">*xmat[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] + np.sqrt(</span><span class="s2">1 </span><span class="s1">- </span><span class="s2">0.5</span><span class="s1">**</span><span class="s2">2</span><span class="s1">) * xmat[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">xmat[:</span><span class="s0">, </span><span class="s2">3</span><span class="s1">] = </span><span class="s2">0.5</span><span class="s1">*xmat[:</span><span class="s0">, </span><span class="s2">2</span><span class="s1">] + np.sqrt(</span><span class="s2">1 </span><span class="s1">- </span><span class="s2">0.5</span><span class="s1">**</span><span class="s2">2</span><span class="s1">) * xmat[:</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]</span>

    <span class="s1">b = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span>
    <span class="s1">lpr = np.dot(xmat</span><span class="s0">, </span><span class="s1">b)</span>
    <span class="s1">ev = np.exp(lpr)</span>
    <span class="s1">y = np.random.poisson(ev)</span>

    <span class="s0">for </span><span class="s1">method </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">6</span><span class="s1">):</span>

        <span class="s0">if </span><span class="s1">method == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">model = SlicedInverseReg(y</span><span class="s0">, </span><span class="s1">xmat)</span>
            <span class="s1">rslt = model.fit()</span>
        <span class="s0">elif </span><span class="s1">method == </span><span class="s2">1</span><span class="s1">:</span>
            <span class="s1">model = SAVE(y</span><span class="s0">, </span><span class="s1">xmat)</span>
            <span class="s1">rslt = model.fit(slice_n=</span><span class="s2">100</span><span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">method == </span><span class="s2">2</span><span class="s1">:</span>
            <span class="s1">model = SAVE(y</span><span class="s0">, </span><span class="s1">xmat</span><span class="s0">, </span><span class="s1">bc=</span><span class="s0">True</span><span class="s1">)</span>
            <span class="s1">rslt = model.fit(slice_n=</span><span class="s2">100</span><span class="s1">)</span>
        <span class="s0">elif </span><span class="s1">method == </span><span class="s2">3</span><span class="s1">:</span>
            <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">,</span>
                               <span class="s4">&quot;x0&quot;</span><span class="s1">: xmat[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">,</span>
                               <span class="s4">&quot;x1&quot;</span><span class="s1">: xmat[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span><span class="s0">,</span>
                               <span class="s4">&quot;x2&quot;</span><span class="s1">: xmat[:</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span><span class="s0">,</span>
                               <span class="s4">&quot;x3&quot;</span><span class="s1">: xmat[:</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]</span><span class="s0">,</span>
                               <span class="s4">&quot;x4&quot;</span><span class="s1">: xmat[:</span><span class="s0">, </span><span class="s2">4</span><span class="s1">]})</span>
            <span class="s1">model = SlicedInverseReg.from_formula(</span>
                        <span class="s4">&quot;y ~ 0 + x0 + x1 + x2 + x3 + x4&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
            <span class="s1">rslt = model.fit()</span>
        <span class="s0">elif </span><span class="s1">method == </span><span class="s2">4</span><span class="s1">:</span>
            <span class="s1">model = PHD(y</span><span class="s0">, </span><span class="s1">xmat)</span>
            <span class="s1">rslt = model.fit()</span>
        <span class="s0">elif </span><span class="s1">method == </span><span class="s2">5</span><span class="s1">:</span>
            <span class="s1">model = PHD(y</span><span class="s0">, </span><span class="s1">xmat)</span>
            <span class="s1">rslt = model.fit(resid=</span><span class="s0">True</span><span class="s1">)</span>

        <span class="s3"># Check for concentration in one direction (this is</span>
        <span class="s3"># a single index model)</span>
        <span class="s1">assert_equal(np.abs(rslt.eigs[</span><span class="s2">0</span><span class="s1">] / rslt.eigs[</span><span class="s2">1</span><span class="s1">]) &gt; </span><span class="s2">5</span><span class="s0">, True</span><span class="s1">)</span>

        <span class="s3"># Check that the estimated direction aligns with the true</span>
        <span class="s3"># direction</span>
        <span class="s1">params = np.asarray(rslt.params)</span>
        <span class="s1">q = np.dot(params[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">b)</span>
        <span class="s1">q /= np.sqrt(np.sum(params[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]**</span><span class="s2">2</span><span class="s1">))</span>
        <span class="s1">q /= np.sqrt(np.sum(b**</span><span class="s2">2</span><span class="s1">))</span>
        <span class="s1">assert_equal(np.abs(q) &gt; </span><span class="s2">0.95</span><span class="s0">, True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sir_regularized_numdiff():</span>
    <span class="s3"># Use numeric gradients to check the analytic gradient</span>
    <span class="s3"># for the regularized SIRobjective function.</span>

    <span class="s1">np.random.seed(</span><span class="s2">93482</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s2">1000</span>
    <span class="s1">p = </span><span class="s2">10</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s1">y1 = np.dot(xmat</span><span class="s0">, </span><span class="s1">np.linspace(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s1">y2 = xmat.sum(</span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">y = y2 / (</span><span class="s2">1 </span><span class="s1">+ y1**</span><span class="s2">2</span><span class="s1">) + np.random.normal(size=n)</span>
    <span class="s1">model = SlicedInverseReg(y</span><span class="s0">, </span><span class="s1">xmat)</span>
    <span class="s1">_ = model.fit()</span>

    <span class="s3"># Second difference penalty matrix.</span>
    <span class="s1">fmat = np.zeros((p-</span><span class="s2">2</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(p-</span><span class="s2">2</span><span class="s1">):</span>
        <span class="s1">fmat[i</span><span class="s0">, </span><span class="s1">i:i+</span><span class="s2">3</span><span class="s1">] = [</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>

    <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;SIR.fit_regularized did not&quot;</span><span class="s1">):</span>
        <span class="s1">_ = model.fit_regularized(</span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s1">*fmat)</span>

    <span class="s3"># Compare the gradients to the numerical derivatives</span>
    <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">5</span><span class="s1">):</span>
        <span class="s1">pa = np.random.normal(size=(p</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
        <span class="s1">pa</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">_ = np.linalg.svd(pa</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">gn = approx_fprime(pa.ravel()</span><span class="s0">, </span><span class="s1">model._regularized_objective</span><span class="s0">, </span><span class="s2">1e-7</span><span class="s1">)</span>
        <span class="s1">gr = model._regularized_grad(pa.ravel())</span>
        <span class="s1">assert_allclose(gn</span><span class="s0">, </span><span class="s1">gr</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sir_regularized_1d():</span>
    <span class="s3"># Compare regularized SIR to traditional SIR, in a setting where the</span>
    <span class="s3"># regularization is compatible with the true parameters (i.e. there</span>
    <span class="s3"># is no regularization bias).</span>

    <span class="s1">np.random.seed(</span><span class="s2">93482</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s2">1000</span>
    <span class="s1">p = </span><span class="s2">10</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s1">y = np.dot(xmat[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]) + np.random.normal(size=n)</span>
    <span class="s1">model = SlicedInverseReg(y</span><span class="s0">, </span><span class="s1">xmat)</span>
    <span class="s1">rslt = model.fit()</span>

    <span class="s3"># The penalty drives p[0] ~ p[1] and p[2] ~ p[3]]</span>
    <span class="s1">fmat = np.zeros((</span><span class="s2">2</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s1">fmat[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s1">] = [</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">fmat[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span><span class="s2">4</span><span class="s1">] = [</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span>

    <span class="s1">rslt2 = model.fit_regularized(</span><span class="s2">1</span><span class="s0">, </span><span class="s2">3</span><span class="s1">*fmat)</span>

    <span class="s1">pa0 = np.zeros(p)</span>
    <span class="s1">pa0[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">4</span><span class="s1">] = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">pa1 = rslt.params[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">pa2 = rslt2.params[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s1">]</span>

    <span class="s3"># Compare two 1d subspaces</span>
    <span class="s0">def </span><span class="s1">sim(x</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s1">x = x / np.sqrt(np.sum(x * x))</span>
        <span class="s1">y = y / np.sqrt(np.sum(y * y))</span>
        <span class="s0">return </span><span class="s2">1 </span><span class="s1">- np.abs(np.dot(x</span><span class="s0">, </span><span class="s1">y))</span>

    <span class="s3"># Regularized SIRshould be closer to the truth than traditional SIR</span>
    <span class="s1">assert_equal(sim(pa0</span><span class="s0">, </span><span class="s1">pa1) &gt; sim(pa0</span><span class="s0">, </span><span class="s1">pa2)</span><span class="s0">, True</span><span class="s1">)</span>

    <span class="s3"># Regularized SIR should be close to the truth</span>
    <span class="s1">assert_equal(sim(pa0</span><span class="s0">, </span><span class="s1">pa2) &lt; </span><span class="s2">1e-3</span><span class="s0">, True</span><span class="s1">)</span>

    <span class="s3"># Regularized SIR should have a smaller penalty value than traditional SIR</span>
    <span class="s1">assert_equal(np.sum(np.dot(fmat</span><span class="s0">, </span><span class="s1">pa1)**</span><span class="s2">2</span><span class="s1">) &gt; np.sum(np.dot(fmat</span><span class="s0">, </span><span class="s1">pa2)**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">,</span>
                 <span class="s0">True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sir_regularized_2d():</span>
    <span class="s3"># Compare regularized SIR to traditional SIR when there is no penalty.</span>
    <span class="s3"># The two procedures should agree exactly.</span>

    <span class="s1">np.random.seed(</span><span class="s2">93482</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s2">1000</span>
    <span class="s1">p = </span><span class="s2">10</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s0">, </span><span class="s1">p))</span>
    <span class="s1">y1 = np.dot(xmat[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">4</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">])</span>
    <span class="s1">y2 = np.dot(xmat[:</span><span class="s0">, </span><span class="s2">4</span><span class="s1">:</span><span class="s2">8</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">])</span>
    <span class="s1">y = y1 + np.arctan(y2) + np.random.normal(size=n)</span>
    <span class="s1">model = SlicedInverseReg(y</span><span class="s0">, </span><span class="s1">xmat)</span>
    <span class="s1">rslt1 = model.fit()</span>

    <span class="s1">fmat = np.zeros((</span><span class="s2">1</span><span class="s0">, </span><span class="s1">p))</span>

    <span class="s0">for </span><span class="s1">d </span><span class="s0">in </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s0">, </span><span class="s2">4</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">d &lt; </span><span class="s2">3</span><span class="s1">:</span>
            <span class="s1">rslt2 = model.fit_regularized(d</span><span class="s0">, </span><span class="s1">fmat)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">with </span><span class="s1">pytest.warns(UserWarning</span><span class="s0">, </span><span class="s1">match=</span><span class="s4">&quot;SIR.fit_regularized did&quot;</span><span class="s1">):</span>
                <span class="s1">rslt2 = model.fit_regularized(d</span><span class="s0">, </span><span class="s1">fmat)</span>
        <span class="s1">pa1 = rslt1.params[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:d]</span>
        <span class="s1">pa1</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">_ = np.linalg.svd(pa1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">pa2 = rslt2.params</span>
        <span class="s1">_</span><span class="s0">, </span><span class="s1">s</span><span class="s0">, </span><span class="s1">_ = np.linalg.svd(np.dot(pa1.T</span><span class="s0">, </span><span class="s1">pa2))</span>
        <span class="s1">assert_allclose(np.sum(s)</span><span class="s0">, </span><span class="s1">d</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-1</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_covreduce():</span>

    <span class="s1">np.random.seed(</span><span class="s2">34324</span><span class="s1">)</span>

    <span class="s1">p = </span><span class="s2">4</span>
    <span class="s1">endog = []</span>
    <span class="s1">exog = []</span>
    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">3</span><span class="s1">):</span>
        <span class="s1">c = np.eye(p)</span>
        <span class="s1">x = np.random.normal(size=(</span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
        <span class="s3"># The differences between the covariance matrices</span>
        <span class="s3"># are all in the first 2 rows/columns.</span>
        <span class="s1">c[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s1">] = np.dot(x.T</span><span class="s0">, </span><span class="s1">x)</span>

        <span class="s1">cr = np.linalg.cholesky(c)</span>
        <span class="s1">m = </span><span class="s2">1000</span><span class="s1">*k + </span><span class="s2">50</span><span class="s1">*k</span>
        <span class="s1">x = np.random.normal(size=(m</span><span class="s0">, </span><span class="s1">p))</span>
        <span class="s1">x = np.dot(x</span><span class="s0">, </span><span class="s1">cr.T)</span>
        <span class="s1">exog.append(x)</span>
        <span class="s1">endog.append(k * np.ones(m))</span>

    <span class="s1">endog = np.concatenate(endog)</span>
    <span class="s1">exog = np.concatenate(exog</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">0</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">dim </span><span class="s0">in </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s1">:</span>

        <span class="s1">cr = CORE(endog</span><span class="s0">, </span><span class="s1">exog</span><span class="s0">, </span><span class="s1">dim)</span>

        <span class="s1">pt = np.random.normal(size=(p</span><span class="s0">, </span><span class="s1">dim))</span>
        <span class="s1">pt</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">_ = np.linalg.svd(pt</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">gn = approx_fprime(pt.ravel()</span><span class="s0">, </span><span class="s1">cr.loglike</span><span class="s0">, </span><span class="s2">1e-7</span><span class="s1">)</span>
        <span class="s1">g = cr.score(pt.ravel())</span>

        <span class="s1">assert_allclose(g</span><span class="s0">, </span><span class="s1">gn</span><span class="s0">, </span><span class="s2">1e-5</span><span class="s0">, </span><span class="s2">1e-5</span><span class="s1">)</span>

        <span class="s1">rslt = cr.fit()</span>
        <span class="s1">proj = rslt.params</span>
        <span class="s1">assert_equal(proj.shape[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">p)</span>
        <span class="s1">assert_equal(proj.shape[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dim)</span>
        <span class="s1">assert_allclose(np.dot(proj.T</span><span class="s0">, </span><span class="s1">proj)</span><span class="s0">, </span><span class="s1">np.eye(dim)</span><span class="s0">, </span><span class="s2">1e-8</span><span class="s0">, </span><span class="s2">1e-8</span><span class="s1">)</span>

        <span class="s0">if </span><span class="s1">dim == </span><span class="s2">2</span><span class="s1">:</span>
            <span class="s3"># Here we know the approximate truth</span>
            <span class="s1">projt = np.zeros((p</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
            <span class="s1">projt[</span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s0">, </span><span class="s2">0</span><span class="s1">:</span><span class="s2">2</span><span class="s1">] = np.eye(</span><span class="s2">2</span><span class="s1">)</span>
            <span class="s1">assert_allclose(np.trace(np.dot(proj.T</span><span class="s0">, </span><span class="s1">projt))</span><span class="s0">, </span><span class="s2">2</span><span class="s0">,</span>
                            <span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-3</span><span class="s1">)</span>
</pre>
</body>
</html>
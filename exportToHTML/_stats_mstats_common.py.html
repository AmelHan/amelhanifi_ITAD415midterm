<html>
<head>
<title>_stats_mstats_common.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #808080;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_stats_mstats_common.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">scipy.stats._stats_py</span>
<span class="s0">from </span><span class="s1">. </span><span class="s0">import </span><span class="s1">distributions</span>
<span class="s0">from </span><span class="s1">.._lib._bunch </span><span class="s0">import </span><span class="s1">_make_tuple_bunch</span>
<span class="s0">from </span><span class="s1">._stats_pythran </span><span class="s0">import </span><span class="s1">siegelslopes </span><span class="s0">as </span><span class="s1">siegelslopes_pythran</span>

<span class="s1">__all__ = [</span><span class="s2">'_find_repeats'</span><span class="s0">, </span><span class="s2">'linregress'</span><span class="s0">, </span><span class="s2">'theilslopes'</span><span class="s0">, </span><span class="s2">'siegelslopes'</span><span class="s1">]</span>

<span class="s3"># This is not a namedtuple for backwards compatibility. See PR #12983</span>
<span class="s1">LinregressResult = _make_tuple_bunch(</span><span class="s2">'LinregressResult'</span><span class="s0">,</span>
                                     <span class="s1">[</span><span class="s2">'slope'</span><span class="s0">, </span><span class="s2">'intercept'</span><span class="s0">, </span><span class="s2">'rvalue'</span><span class="s0">,</span>
                                      <span class="s2">'pvalue'</span><span class="s0">, </span><span class="s2">'stderr'</span><span class="s1">]</span><span class="s0">,</span>
                                     <span class="s1">extra_field_names=[</span><span class="s2">'intercept_stderr'</span><span class="s1">])</span>
<span class="s1">TheilslopesResult = _make_tuple_bunch(</span><span class="s2">'TheilslopesResult'</span><span class="s0">,</span>
                                      <span class="s1">[</span><span class="s2">'slope'</span><span class="s0">, </span><span class="s2">'intercept'</span><span class="s0">,</span>
                                       <span class="s2">'low_slope'</span><span class="s0">, </span><span class="s2">'high_slope'</span><span class="s1">])</span>
<span class="s1">SiegelslopesResult = _make_tuple_bunch(</span><span class="s2">'SiegelslopesResult'</span><span class="s0">,</span>
                                       <span class="s1">[</span><span class="s2">'slope'</span><span class="s0">, </span><span class="s2">'intercept'</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">linregress(x</span><span class="s0">, </span><span class="s1">y=</span><span class="s0">None, </span><span class="s1">alternative=</span><span class="s2">'two-sided'</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot; 
    Calculate a linear least-squares regression for two sets of measurements. 
 
    Parameters 
    ---------- 
    x, y : array_like 
        Two sets of measurements.  Both arrays should have the same length.  If 
        only `x` is given (and ``y=None``), then it must be a two-dimensional 
        array where one dimension has length 2.  The two sets of measurements 
        are then found by splitting the array along the length-2 dimension. In 
        the case where ``y=None`` and `x` is a 2x2 array, ``linregress(x)`` is 
        equivalent to ``linregress(x[0], x[1])``. 
    alternative : {'two-sided', 'less', 'greater'}, optional 
        Defines the alternative hypothesis. Default is 'two-sided'. 
        The following options are available: 
 
        * 'two-sided': the slope of the regression line is nonzero 
        * 'less': the slope of the regression line is less than zero 
        * 'greater':  the slope of the regression line is greater than zero 
 
        .. versionadded:: 1.7.0 
 
    Returns 
    ------- 
    result : ``LinregressResult`` instance 
        The return value is an object with the following attributes: 
 
        slope : float 
            Slope of the regression line. 
        intercept : float 
            Intercept of the regression line. 
        rvalue : float 
            The Pearson correlation coefficient. The square of ``rvalue`` 
            is equal to the coefficient of determination. 
        pvalue : float 
            The p-value for a hypothesis test whose null hypothesis is 
            that the slope is zero, using Wald Test with t-distribution of 
            the test statistic. See `alternative` above for alternative 
            hypotheses. 
        stderr : float 
            Standard error of the estimated slope (gradient), under the 
            assumption of residual normality. 
        intercept_stderr : float 
            Standard error of the estimated intercept, under the assumption 
            of residual normality. 
 
    See Also 
    -------- 
    scipy.optimize.curve_fit : 
        Use non-linear least squares to fit a function to data. 
    scipy.optimize.leastsq : 
        Minimize the sum of squares of a set of equations. 
 
    Notes 
    ----- 
    Missing values are considered pair-wise: if a value is missing in `x`, 
    the corresponding value in `y` is masked. 
 
    For compatibility with older versions of SciPy, the return value acts 
    like a ``namedtuple`` of length 5, with fields ``slope``, ``intercept``, 
    ``rvalue``, ``pvalue`` and ``stderr``, so one can continue to write:: 
 
        slope, intercept, r, p, se = linregress(x, y) 
 
    With that style, however, the standard error of the intercept is not 
    available.  To have access to all the computed values, including the 
    standard error of the intercept, use the return value as an object 
    with attributes, e.g.:: 
 
        result = linregress(x, y) 
        print(result.intercept, result.intercept_stderr) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; rng = np.random.default_rng() 
 
    Generate some data: 
 
    &gt;&gt;&gt; x = rng.random(10) 
    &gt;&gt;&gt; y = 1.6*x + rng.random(10) 
 
    Perform the linear regression: 
 
    &gt;&gt;&gt; res = stats.linregress(x, y) 
 
    Coefficient of determination (R-squared): 
 
    &gt;&gt;&gt; print(f&quot;R-squared: {res.rvalue**2:.6f}&quot;) 
    R-squared: 0.717533 
 
    Plot the data along with the fitted line: 
 
    &gt;&gt;&gt; plt.plot(x, y, 'o', label='original data') 
    &gt;&gt;&gt; plt.plot(x, res.intercept + res.slope*x, 'r', label='fitted line') 
    &gt;&gt;&gt; plt.legend() 
    &gt;&gt;&gt; plt.show() 
 
    Calculate 95% confidence interval on slope and intercept: 
 
    &gt;&gt;&gt; # Two-sided inverse Students t-distribution 
    &gt;&gt;&gt; # p - probability, df - degrees of freedom 
    &gt;&gt;&gt; from scipy.stats import t 
    &gt;&gt;&gt; tinv = lambda p, df: abs(t.ppf(p/2, df)) 
 
    &gt;&gt;&gt; ts = tinv(0.05, len(x)-2) 
    &gt;&gt;&gt; print(f&quot;slope (95%): {res.slope:.6f} +/- {ts*res.stderr:.6f}&quot;) 
    slope (95%): 1.453392 +/- 0.743465 
    &gt;&gt;&gt; print(f&quot;intercept (95%): {res.intercept:.6f}&quot; 
    ...       f&quot; +/- {ts*res.intercept_stderr:.6f}&quot;) 
    intercept (95%): 0.616950 +/- 0.544475 
 
    &quot;&quot;&quot;</span>
    <span class="s1">TINY = </span><span class="s5">1.0e-20</span>
    <span class="s0">if </span><span class="s1">y </span><span class="s0">is None</span><span class="s1">:  </span><span class="s3"># x is a (2, N) or (N, 2) shaped array_like</span>
        <span class="s1">x = np.asarray(x)</span>
        <span class="s0">if </span><span class="s1">x.shape[</span><span class="s5">0</span><span class="s1">] == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">x</span><span class="s0">, </span><span class="s1">y = x</span>
        <span class="s0">elif </span><span class="s1">x.shape[</span><span class="s5">1</span><span class="s1">] == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">x</span><span class="s0">, </span><span class="s1">y = x.T</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;If only `x` is given as input, it has to &quot;</span>
                             <span class="s2">&quot;be of shape (2, N) or (N, 2); provided shape &quot;</span>
                             <span class="s2">f&quot;was </span><span class="s0">{</span><span class="s1">x.shape</span><span class="s0">}</span><span class="s2">.&quot;</span><span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">x = np.asarray(x)</span>
        <span class="s1">y = np.asarray(y)</span>

    <span class="s0">if </span><span class="s1">x.size == </span><span class="s5">0 </span><span class="s0">or </span><span class="s1">y.size == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Inputs must not be empty.&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">np.amax(x) == np.amin(x) </span><span class="s0">and </span><span class="s1">len(x) &gt; </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Cannot calculate a linear regression &quot;</span>
                         <span class="s2">&quot;if all x values are identical&quot;</span><span class="s1">)</span>

    <span class="s1">n = len(x)</span>
    <span class="s1">xmean = np.mean(x</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s1">ymean = np.mean(y</span><span class="s0">, None</span><span class="s1">)</span>

    <span class="s3"># Average sums of square differences from the mean</span>
    <span class="s3">#   ssxm = mean( (x-mean(x))^2 )</span>
    <span class="s3">#   ssxym = mean( (x-mean(x)) * (y-mean(y)) )</span>
    <span class="s1">ssxm</span><span class="s0">, </span><span class="s1">ssxym</span><span class="s0">, </span><span class="s1">_</span><span class="s0">, </span><span class="s1">ssym = np.cov(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">bias=</span><span class="s5">1</span><span class="s1">).flat</span>

    <span class="s3"># R-value</span>
    <span class="s3">#   r = ssxym / sqrt( ssxm * ssym )</span>
    <span class="s0">if </span><span class="s1">ssxm == </span><span class="s5">0.0 </span><span class="s0">or </span><span class="s1">ssym == </span><span class="s5">0.0</span><span class="s1">:</span>
        <span class="s3"># If the denominator was going to be 0</span>
        <span class="s1">r = </span><span class="s5">0.0</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">r = ssxym / np.sqrt(ssxm * ssym)</span>
        <span class="s3"># Test for numerical error propagation (make sure -1 &lt; r &lt; 1)</span>
        <span class="s0">if </span><span class="s1">r &gt; </span><span class="s5">1.0</span><span class="s1">:</span>
            <span class="s1">r = </span><span class="s5">1.0</span>
        <span class="s0">elif </span><span class="s1">r &lt; -</span><span class="s5">1.0</span><span class="s1">:</span>
            <span class="s1">r = -</span><span class="s5">1.0</span>

    <span class="s1">slope = ssxym / ssxm</span>
    <span class="s1">intercept = ymean - slope*xmean</span>
    <span class="s0">if </span><span class="s1">n == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s3"># handle case when only two points are passed in</span>
        <span class="s0">if </span><span class="s1">y[</span><span class="s5">0</span><span class="s1">] == y[</span><span class="s5">1</span><span class="s1">]:</span>
            <span class="s1">prob = </span><span class="s5">1.0</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">prob = </span><span class="s5">0.0</span>
        <span class="s1">slope_stderr = </span><span class="s5">0.0</span>
        <span class="s1">intercept_stderr = </span><span class="s5">0.0</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">df = n - </span><span class="s5">2  </span><span class="s3"># Number of degrees of freedom</span>
        <span class="s3"># n-2 degrees of freedom because 2 has been used up</span>
        <span class="s3"># to estimate the mean and standard deviation</span>
        <span class="s1">t = r * np.sqrt(df / ((</span><span class="s5">1.0 </span><span class="s1">- r + TINY)*(</span><span class="s5">1.0 </span><span class="s1">+ r + TINY)))</span>
        <span class="s1">t</span><span class="s0">, </span><span class="s1">prob = scipy.stats._stats_py._ttest_finish(df</span><span class="s0">, </span><span class="s1">t</span><span class="s0">, </span><span class="s1">alternative)</span>

        <span class="s1">slope_stderr = np.sqrt((</span><span class="s5">1 </span><span class="s1">- r**</span><span class="s5">2</span><span class="s1">) * ssym / ssxm / df)</span>

        <span class="s3"># Also calculate the standard error of the intercept</span>
        <span class="s3"># The following relationship is used:</span>
        <span class="s3">#   ssxm = mean( (x-mean(x))^2 )</span>
        <span class="s3">#        = ssx - sx*sx</span>
        <span class="s3">#        = mean( x^2 ) - mean(x)^2</span>
        <span class="s1">intercept_stderr = slope_stderr * np.sqrt(ssxm + xmean**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s0">return </span><span class="s1">LinregressResult(slope=slope</span><span class="s0">, </span><span class="s1">intercept=intercept</span><span class="s0">, </span><span class="s1">rvalue=r</span><span class="s0">,</span>
                            <span class="s1">pvalue=prob</span><span class="s0">, </span><span class="s1">stderr=slope_stderr</span><span class="s0">,</span>
                            <span class="s1">intercept_stderr=intercept_stderr)</span>


<span class="s0">def </span><span class="s1">theilslopes(y</span><span class="s0">, </span><span class="s1">x=</span><span class="s0">None, </span><span class="s1">alpha=</span><span class="s5">0.95</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">'separate'</span><span class="s1">):</span>
    <span class="s4">r&quot;&quot;&quot; 
    Computes the Theil-Sen estimator for a set of points (x, y). 
 
    `theilslopes` implements a method for robust linear regression.  It 
    computes the slope as the median of all slopes between paired values. 
 
    Parameters 
    ---------- 
    y : array_like 
        Dependent variable. 
    x : array_like or None, optional 
        Independent variable. If None, use ``arange(len(y))`` instead. 
    alpha : float, optional 
        Confidence degree between 0 and 1. Default is 95% confidence. 
        Note that `alpha` is symmetric around 0.5, i.e. both 0.1 and 0.9 are 
        interpreted as &quot;find the 90% confidence interval&quot;. 
    method : {'joint', 'separate'}, optional 
        Method to be used for computing estimate for intercept. 
        Following methods are supported, 
 
            * 'joint': Uses np.median(y - slope * x) as intercept. 
            * 'separate': Uses np.median(y) - slope * np.median(x) 
                          as intercept. 
 
        The default is 'separate'. 
 
        .. versionadded:: 1.8.0 
 
    Returns 
    ------- 
    result : ``TheilslopesResult`` instance 
        The return value is an object with the following attributes: 
 
        slope : float 
            Theil slope. 
        intercept : float 
            Intercept of the Theil line. 
        low_slope : float 
            Lower bound of the confidence interval on `slope`. 
        high_slope : float 
            Upper bound of the confidence interval on `slope`. 
 
    See Also 
    -------- 
    siegelslopes : a similar technique using repeated medians 
 
    Notes 
    ----- 
    The implementation of `theilslopes` follows [1]_. The intercept is 
    not defined in [1]_, and here it is defined as ``median(y) - 
    slope*median(x)``, which is given in [3]_. Other definitions of 
    the intercept exist in the literature such as  ``median(y - slope*x)`` 
    in [4]_. The approach to compute the intercept can be determined by the 
    parameter ``method``. A confidence interval for the intercept is not 
    given as this question is not addressed in [1]_. 
 
    For compatibility with older versions of SciPy, the return value acts 
    like a ``namedtuple`` of length 4, with fields ``slope``, ``intercept``, 
    ``low_slope``, and ``high_slope``, so one can continue to write:: 
 
        slope, intercept, low_slope, high_slope = theilslopes(y, x) 
 
    References 
    ---------- 
    .. [1] P.K. Sen, &quot;Estimates of the regression coefficient based on 
           Kendall's tau&quot;, J. Am. Stat. Assoc., Vol. 63, pp. 1379-1389, 1968. 
    .. [2] H. Theil, &quot;A rank-invariant method of linear and polynomial 
           regression analysis I, II and III&quot;,  Nederl. Akad. Wetensch., Proc. 
           53:, pp. 386-392, pp. 521-525, pp. 1397-1412, 1950. 
    .. [3] W.L. Conover, &quot;Practical nonparametric statistics&quot;, 2nd ed., 
           John Wiley and Sons, New York, pp. 493. 
    .. [4] https://en.wikipedia.org/wiki/Theil%E2%80%93Sen_estimator 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
 
    &gt;&gt;&gt; x = np.linspace(-5, 5, num=150) 
    &gt;&gt;&gt; y = x + np.random.normal(size=x.size) 
    &gt;&gt;&gt; y[11:15] += 10  # add outliers 
    &gt;&gt;&gt; y[-5:] -= 7 
 
    Compute the slope, intercept and 90% confidence interval.  For comparison, 
    also compute the least-squares fit with `linregress`: 
 
    &gt;&gt;&gt; res = stats.theilslopes(y, x, 0.90, method='separate') 
    &gt;&gt;&gt; lsq_res = stats.linregress(x, y) 
 
    Plot the results. The Theil-Sen regression line is shown in red, with the 
    dashed red lines illustrating the confidence interval of the slope (note 
    that the dashed red lines are not the confidence interval of the regression 
    as the confidence interval of the intercept is not included). The green 
    line shows the least-squares fit for comparison. 
 
    &gt;&gt;&gt; fig = plt.figure() 
    &gt;&gt;&gt; ax = fig.add_subplot(111) 
    &gt;&gt;&gt; ax.plot(x, y, 'b.') 
    &gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, 'r-') 
    &gt;&gt;&gt; ax.plot(x, res[1] + res[2] * x, 'r--') 
    &gt;&gt;&gt; ax.plot(x, res[1] + res[3] * x, 'r--') 
    &gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-') 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">method </span><span class="s0">not in </span><span class="s1">[</span><span class="s2">'joint'</span><span class="s0">, </span><span class="s2">'separate'</span><span class="s1">]:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;method must be either 'joint' or 'separate'.&quot;</span>
                         <span class="s2">&quot;'{}' is invalid.&quot;</span><span class="s1">.format(method))</span>
    <span class="s3"># We copy both x and y so we can use _find_repeats.</span>
    <span class="s1">y = np.array(y).flatten()</span>
    <span class="s0">if </span><span class="s1">x </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">x = np.arange(len(y)</span><span class="s0">, </span><span class="s1">dtype=float)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">x = np.array(x</span><span class="s0">, </span><span class="s1">dtype=float).flatten()</span>
        <span class="s0">if </span><span class="s1">len(x) != len(y):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Incompatible lengths ! (%s&lt;&gt;%s)&quot; </span><span class="s1">%</span>
                             <span class="s1">(len(y)</span><span class="s0">, </span><span class="s1">len(x)))</span>

    <span class="s3"># Compute sorted slopes only when deltax &gt; 0</span>
    <span class="s1">deltax = x[:</span><span class="s0">, </span><span class="s1">np.newaxis] - x</span>
    <span class="s1">deltay = y[:</span><span class="s0">, </span><span class="s1">np.newaxis] - y</span>
    <span class="s1">slopes = deltay[deltax &gt; </span><span class="s5">0</span><span class="s1">] / deltax[deltax &gt; </span><span class="s5">0</span><span class="s1">]</span>
    <span class="s0">if not </span><span class="s1">slopes.size:</span>
        <span class="s1">msg = </span><span class="s2">&quot;All `x` coordinates are identical.&quot;</span>
        <span class="s1">warnings.warn(msg</span><span class="s0">, </span><span class="s1">RuntimeWarning</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">slopes.sort()</span>
    <span class="s1">medslope = np.median(slopes)</span>
    <span class="s0">if </span><span class="s1">method == </span><span class="s2">'joint'</span><span class="s1">:</span>
        <span class="s1">medinter = np.median(y - medslope * x)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">medinter = np.median(y) - medslope * np.median(x)</span>
    <span class="s3"># Now compute confidence intervals</span>
    <span class="s0">if </span><span class="s1">alpha &gt; </span><span class="s5">0.5</span><span class="s1">:</span>
        <span class="s1">alpha = </span><span class="s5">1. </span><span class="s1">- alpha</span>

    <span class="s1">z = distributions.norm.ppf(alpha / </span><span class="s5">2.</span><span class="s1">)</span>
    <span class="s3"># This implements (2.6) from Sen (1968)</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">nxreps = _find_repeats(x)</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">nyreps = _find_repeats(y)</span>
    <span class="s1">nt = len(slopes)       </span><span class="s3"># N in Sen (1968)</span>
    <span class="s1">ny = len(y)            </span><span class="s3"># n in Sen (1968)</span>
    <span class="s3"># Equation 2.6 in Sen (1968):</span>
    <span class="s1">sigsq = </span><span class="s5">1</span><span class="s1">/</span><span class="s5">18. </span><span class="s1">* (ny * (ny-</span><span class="s5">1</span><span class="s1">) * (</span><span class="s5">2</span><span class="s1">*ny+</span><span class="s5">5</span><span class="s1">) -</span>
                     <span class="s1">sum(k * (k-</span><span class="s5">1</span><span class="s1">) * (</span><span class="s5">2</span><span class="s1">*k + </span><span class="s5">5</span><span class="s1">) </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">nxreps) -</span>
                     <span class="s1">sum(k * (k-</span><span class="s5">1</span><span class="s1">) * (</span><span class="s5">2</span><span class="s1">*k + </span><span class="s5">5</span><span class="s1">) </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">nyreps))</span>
    <span class="s3"># Find the confidence interval indices in `slopes`</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">sigma = np.sqrt(sigsq)</span>
        <span class="s1">Ru = min(int(np.round((nt - z*sigma)/</span><span class="s5">2.</span><span class="s1">))</span><span class="s0">, </span><span class="s1">len(slopes)-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">Rl = max(int(np.round((nt + z*sigma)/</span><span class="s5">2.</span><span class="s1">)) - </span><span class="s5">1</span><span class="s0">, </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">delta = slopes[[Rl</span><span class="s0">, </span><span class="s1">Ru]]</span>
    <span class="s0">except </span><span class="s1">(ValueError</span><span class="s0">, </span><span class="s1">IndexError):</span>
        <span class="s1">delta = (np.nan</span><span class="s0">, </span><span class="s1">np.nan)</span>

    <span class="s0">return </span><span class="s1">TheilslopesResult(slope=medslope</span><span class="s0">, </span><span class="s1">intercept=medinter</span><span class="s0">,</span>
                             <span class="s1">low_slope=delta[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">high_slope=delta[</span><span class="s5">1</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">_find_repeats(arr):</span>
    <span class="s3"># This function assumes it may clobber its input.</span>
    <span class="s0">if </span><span class="s1">len(arr) == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">np.array(</span><span class="s5">0</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">, </span><span class="s1">np.array(</span><span class="s5">0</span><span class="s0">, </span><span class="s1">np.intp)</span>

    <span class="s3"># XXX This cast was previously needed for the Fortran implementation,</span>
    <span class="s3"># should we ditch it?</span>
    <span class="s1">arr = np.asarray(arr</span><span class="s0">, </span><span class="s1">np.float64).ravel()</span>
    <span class="s1">arr.sort()</span>

    <span class="s3"># Taken from NumPy 1.9's np.unique.</span>
    <span class="s1">change = np.concatenate(([</span><span class="s0">True</span><span class="s1">]</span><span class="s0">, </span><span class="s1">arr[</span><span class="s5">1</span><span class="s1">:] != arr[:-</span><span class="s5">1</span><span class="s1">]))</span>
    <span class="s1">unique = arr[change]</span>
    <span class="s1">change_idx = np.concatenate(np.nonzero(change) + ([arr.size]</span><span class="s0">,</span><span class="s1">))</span>
    <span class="s1">freq = np.diff(change_idx)</span>
    <span class="s1">atleast2 = freq &gt; </span><span class="s5">1</span>
    <span class="s0">return </span><span class="s1">unique[atleast2]</span><span class="s0">, </span><span class="s1">freq[atleast2]</span>


<span class="s0">def </span><span class="s1">siegelslopes(y</span><span class="s0">, </span><span class="s1">x=</span><span class="s0">None, </span><span class="s1">method=</span><span class="s2">&quot;hierarchical&quot;</span><span class="s1">):</span>
    <span class="s4">r&quot;&quot;&quot; 
    Computes the Siegel estimator for a set of points (x, y). 
 
    `siegelslopes` implements a method for robust linear regression 
    using repeated medians (see [1]_) to fit a line to the points (x, y). 
    The method is robust to outliers with an asymptotic breakdown point 
    of 50%. 
 
    Parameters 
    ---------- 
    y : array_like 
        Dependent variable. 
    x : array_like or None, optional 
        Independent variable. If None, use ``arange(len(y))`` instead. 
    method : {'hierarchical', 'separate'} 
        If 'hierarchical', estimate the intercept using the estimated 
        slope ``slope`` (default option). 
        If 'separate', estimate the intercept independent of the estimated 
        slope. See Notes for details. 
 
    Returns 
    ------- 
    result : ``SiegelslopesResult`` instance 
        The return value is an object with the following attributes: 
 
        slope : float 
            Estimate of the slope of the regression line. 
        intercept : float 
            Estimate of the intercept of the regression line. 
 
    See Also 
    -------- 
    theilslopes : a similar technique without repeated medians 
 
    Notes 
    ----- 
    With ``n = len(y)``, compute ``m_j`` as the median of 
    the slopes from the point ``(x[j], y[j])`` to all other `n-1` points. 
    ``slope`` is then the median of all slopes ``m_j``. 
    Two ways are given to estimate the intercept in [1]_ which can be chosen 
    via the parameter ``method``. 
    The hierarchical approach uses the estimated slope ``slope`` 
    and computes ``intercept`` as the median of ``y - slope*x``. 
    The other approach estimates the intercept separately as follows: for 
    each point ``(x[j], y[j])``, compute the intercepts of all the `n-1` 
    lines through the remaining points and take the median ``i_j``. 
    ``intercept`` is the median of the ``i_j``. 
 
    The implementation computes `n` times the median of a vector of size `n` 
    which can be slow for large vectors. There are more efficient algorithms 
    (see [2]_) which are not implemented here. 
 
    For compatibility with older versions of SciPy, the return value acts 
    like a ``namedtuple`` of length 2, with fields ``slope`` and 
    ``intercept``, so one can continue to write:: 
 
        slope, intercept = siegelslopes(y, x) 
 
    References 
    ---------- 
    .. [1] A. Siegel, &quot;Robust Regression Using Repeated Medians&quot;, 
           Biometrika, Vol. 69, pp. 242-244, 1982. 
 
    .. [2] A. Stein and M. Werman, &quot;Finding the repeated median regression 
           line&quot;, Proceedings of the Third Annual ACM-SIAM Symposium on 
           Discrete Algorithms, pp. 409-413, 1992. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
 
    &gt;&gt;&gt; x = np.linspace(-5, 5, num=150) 
    &gt;&gt;&gt; y = x + np.random.normal(size=x.size) 
    &gt;&gt;&gt; y[11:15] += 10  # add outliers 
    &gt;&gt;&gt; y[-5:] -= 7 
 
    Compute the slope and intercept.  For comparison, also compute the 
    least-squares fit with `linregress`: 
 
    &gt;&gt;&gt; res = stats.siegelslopes(y, x) 
    &gt;&gt;&gt; lsq_res = stats.linregress(x, y) 
 
    Plot the results. The Siegel regression line is shown in red. The green 
    line shows the least-squares fit for comparison. 
 
    &gt;&gt;&gt; fig = plt.figure() 
    &gt;&gt;&gt; ax = fig.add_subplot(111) 
    &gt;&gt;&gt; ax.plot(x, y, 'b.') 
    &gt;&gt;&gt; ax.plot(x, res[1] + res[0] * x, 'r-') 
    &gt;&gt;&gt; ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-') 
    &gt;&gt;&gt; plt.show() 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">method </span><span class="s0">not in </span><span class="s1">[</span><span class="s2">'hierarchical'</span><span class="s0">, </span><span class="s2">'separate'</span><span class="s1">]:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;method can only be 'hierarchical' or 'separate'&quot;</span><span class="s1">)</span>
    <span class="s1">y = np.asarray(y).ravel()</span>
    <span class="s0">if </span><span class="s1">x </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">x = np.arange(len(y)</span><span class="s0">, </span><span class="s1">dtype=float)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">x = np.asarray(x</span><span class="s0">, </span><span class="s1">dtype=float).ravel()</span>
        <span class="s0">if </span><span class="s1">len(x) != len(y):</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Incompatible lengths ! (%s&lt;&gt;%s)&quot; </span><span class="s1">%</span>
                             <span class="s1">(len(y)</span><span class="s0">, </span><span class="s1">len(x)))</span>
    <span class="s1">dtype = np.result_type(x</span><span class="s0">, </span><span class="s1">y</span><span class="s0">, </span><span class="s1">np.float32)  </span><span class="s3"># use at least float32</span>
    <span class="s1">y</span><span class="s0">, </span><span class="s1">x = y.astype(dtype)</span><span class="s0">, </span><span class="s1">x.astype(dtype)</span>
    <span class="s1">medslope</span><span class="s0">, </span><span class="s1">medinter = siegelslopes_pythran(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">method)</span>
    <span class="s0">return </span><span class="s1">SiegelslopesResult(slope=medslope</span><span class="s0">, </span><span class="s1">intercept=medinter)</span>
</pre>
</body>
</html>
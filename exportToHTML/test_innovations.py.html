<html>
<head>
<title>test_innovations.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_innovations.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>

<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_</span><span class="s0">, </span><span class="s1">assert_allclose</span><span class="s0">, </span><span class="s1">assert_warns</span><span class="s0">, </span><span class="s1">assert_raises)</span>

<span class="s0">from </span><span class="s1">statsmodels.tsa.innovations.arma_innovations </span><span class="s0">import </span><span class="s1">arma_innovations</span>
<span class="s0">from </span><span class="s1">statsmodels.tsa.statespace </span><span class="s0">import </span><span class="s1">sarimax</span>
<span class="s0">from </span><span class="s1">statsmodels.tsa.arima.datasets.brockwell_davis_2002 </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">dowj</span><span class="s0">, </span><span class="s1">lake</span><span class="s0">, </span><span class="s1">oshorts)</span>
<span class="s0">from </span><span class="s1">statsmodels.tsa.arima.estimators.burg </span><span class="s0">import </span><span class="s1">burg</span>
<span class="s0">from </span><span class="s1">statsmodels.tsa.arima.estimators.hannan_rissanen </span><span class="s0">import </span><span class="s1">hannan_rissanen</span>
<span class="s0">from </span><span class="s1">statsmodels.tsa.arima.estimators.innovations </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">innovations</span><span class="s0">, </span><span class="s1">innovations_mle)</span>


<span class="s1">@pytest.mark.low_precision(</span><span class="s2">'Test against Example 5.1.5 in Brockwell and Davis'</span>
                           <span class="s2">' (2016)'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_brockwell_davis_example_515():</span>
    <span class="s3"># Difference and demean the series</span>
    <span class="s1">endog = dowj.diff().iloc[</span><span class="s4">1</span><span class="s1">:]</span>

    <span class="s3"># Innvations algorithm (MA)</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations(endog</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">17</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># First BD show the MA(2) coefficients resulting from the m=17 computations</span>
    <span class="s1">assert_allclose(p[</span><span class="s4">17</span><span class="s1">].ma_params[:</span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">.4269</span><span class="s0">, </span><span class="s4">.2704</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>
    <span class="s1">assert_allclose(p[</span><span class="s4">17</span><span class="s1">].sigma2</span><span class="s0">, </span><span class="s4">0.1122</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>

    <span class="s3"># Then they separately show the full MA(17) coefficients</span>
    <span class="s1">desired = [</span><span class="s4">.4269</span><span class="s0">, </span><span class="s4">.2704</span><span class="s0">, </span><span class="s4">.1183</span><span class="s0">, </span><span class="s4">.1589</span><span class="s0">, </span><span class="s4">.1355</span><span class="s0">, </span><span class="s4">.1568</span><span class="s0">, </span><span class="s4">.1284</span><span class="s0">, </span><span class="s1">-</span><span class="s4">.0060</span><span class="s0">, </span><span class="s4">.0148</span><span class="s0">,</span>
               <span class="s1">-</span><span class="s4">.0017</span><span class="s0">, </span><span class="s4">.1974</span><span class="s0">, </span><span class="s1">-</span><span class="s4">.0463</span><span class="s0">, </span><span class="s4">.2023</span><span class="s0">, </span><span class="s4">.1285</span><span class="s0">, </span><span class="s1">-</span><span class="s4">.0213</span><span class="s0">, </span><span class="s1">-</span><span class="s4">.2575</span><span class="s0">, </span><span class="s4">.0760</span><span class="s1">]</span>
    <span class="s1">assert_allclose(p[</span><span class="s4">17</span><span class="s1">].ma_params</span><span class="s0">, </span><span class="s1">desired</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">check_innovations_ma_itsmr(lake):</span>
    <span class="s3"># Test against R itsmr::ia; see results/results_innovations.R</span>
    <span class="s1">ia</span><span class="s0">, </span><span class="s1">_ = innovations(lake</span><span class="s0">, </span><span class="s4">10</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s1">desired = [</span>
        <span class="s4">1.0816255264</span><span class="s0">, </span><span class="s4">0.7781248438</span><span class="s0">, </span><span class="s4">0.5367164430</span><span class="s0">, </span><span class="s4">0.3291559246</span><span class="s0">, </span><span class="s4">0.3160039850</span><span class="s0">,</span>
        <span class="s4">0.2513754550</span><span class="s0">, </span><span class="s4">0.2051536531</span><span class="s0">, </span><span class="s4">0.1441070313</span><span class="s0">, </span><span class="s4">0.3431868340</span><span class="s0">, </span><span class="s4">0.1827400798</span><span class="s1">]</span>
    <span class="s1">assert_allclose(ia[</span><span class="s4">10</span><span class="s1">].ma_params</span><span class="s0">, </span><span class="s1">desired)</span>

    <span class="s3"># itsmr::ia returns the innovations algorithm estimate of the variance</span>
    <span class="s1">u</span><span class="s0">, </span><span class="s1">v = arma_innovations(np.array(lake) - np.mean(lake)</span><span class="s0">,</span>
                            <span class="s1">ma_params=ia[</span><span class="s4">10</span><span class="s1">].ma_params</span><span class="s0">, </span><span class="s1">sigma2=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">desired_sigma2 = </span><span class="s4">0.4523684344</span>
    <span class="s1">assert_allclose(np.sum(u**</span><span class="s4">2 </span><span class="s1">/ v) / len(u)</span><span class="s0">, </span><span class="s1">desired_sigma2)</span>


<span class="s0">def </span><span class="s1">test_innovations_ma_itsmr():</span>
    <span class="s3"># Note: apparently itsmr automatically demeans (there is no option to</span>
    <span class="s3"># control this)</span>
    <span class="s1">endog = lake.copy()</span>

    <span class="s1">check_innovations_ma_itsmr(endog)           </span><span class="s3"># Pandas series</span>
    <span class="s1">check_innovations_ma_itsmr(endog.values)    </span><span class="s3"># Numpy array</span>
    <span class="s1">check_innovations_ma_itsmr(endog.tolist())  </span><span class="s3"># Python list</span>


<span class="s0">def </span><span class="s1">test_innovations_ma_invalid():</span>
    <span class="s1">endog = np.arange(</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">ma_order=-</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">1.5</span><span class="s1">)</span>

    <span class="s1">endog = np.arange(</span><span class="s4">10</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">ma_order=[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">])</span>


<span class="s1">@pytest.mark.low_precision(</span><span class="s2">'Test against Example 5.2.4 in Brockwell and Davis'</span>
                           <span class="s2">' (2016)'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_brockwell_davis_example_524():</span>
    <span class="s3"># Difference and demean the series</span>
    <span class="s1">endog = dowj.diff().iloc[</span><span class="s4">1</span><span class="s1">:]</span>

    <span class="s3"># Use Burg method to get initial coefficients for MLE</span>
    <span class="s1">initial</span><span class="s0">, </span><span class="s1">_ = burg(endog</span><span class="s0">, </span><span class="s1">ar_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># Fit MLE via innovations algorithm</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True,</span>
                           <span class="s1">start_params=initial.params)</span>

    <span class="s1">assert_allclose(p.ar_params</span><span class="s0">, </span><span class="s4">0.4471</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s1">@pytest.mark.low_precision(</span><span class="s2">'Test against Example 5.2.4 in Brockwell and Davis'</span>
                           <span class="s2">' (2016)'</span><span class="s1">)</span>
<span class="s1">@pytest.mark.xfail(reason=</span><span class="s2">'Suspicious result reported in Brockwell and Davis'</span>
                          <span class="s2">' (2016).'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_brockwell_davis_example_524_variance():</span>
    <span class="s3"># See `test_brockwell_davis_example_524` for the main test</span>
    <span class="s3"># TODO: the test for sigma2 fails, but the value reported by BD (0.02117)</span>
    <span class="s3"># is suspicious. For example, the Burg results have an AR coefficient of</span>
    <span class="s3"># 0.4371 and sigma2 = 0.1423. It seems unlikely that the small difference</span>
    <span class="s3"># in AR coefficient would result in an order of magniture reduction in</span>
    <span class="s3"># sigma2 (see test_burg::test_brockwell_davis_example_513). Should run</span>
    <span class="s3"># this in the ITSM program to check its output.</span>
    <span class="s1">endog = dowj.diff().iloc[</span><span class="s4">1</span><span class="s1">:]</span>

    <span class="s3"># Use Burg method to get initial coefficients for MLE</span>
    <span class="s1">initial</span><span class="s0">, </span><span class="s1">_ = burg(endog</span><span class="s0">, </span><span class="s1">ar_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># Fit MLE via innovations algorithm</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True,</span>
                           <span class="s1">start_params=initial.params)</span>

    <span class="s1">assert_allclose(p.sigma2</span><span class="s0">, </span><span class="s4">0.02117</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s1">@pytest.mark.low_precision(</span><span class="s2">'Test against Example 5.2.5 in Brockwell and Davis'</span>
                           <span class="s2">' (2016)'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_brockwell_davis_example_525():</span>
    <span class="s3"># Difference and demean the series</span>
    <span class="s1">endog = lake.copy()</span>

    <span class="s3"># Use HR method to get initial coefficients for MLE</span>
    <span class="s1">initial</span><span class="s0">, </span><span class="s1">_ = hannan_rissanen(endog</span><span class="s0">, </span><span class="s1">ar_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># Fit MLE via innovations algorithm</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True,</span>
                           <span class="s1">start_params=initial.params)</span>

    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.7446</span><span class="s0">, </span><span class="s4">0.3213</span><span class="s0">, </span><span class="s4">0.4750</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>

    <span class="s3"># Fit MLE via innovations algorithm, with default starting parameters</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0.7446</span><span class="s0">, </span><span class="s4">0.3213</span><span class="s0">, </span><span class="s4">0.4750</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-4</span><span class="s1">)</span>


<span class="s1">@pytest.mark.low_precision(</span><span class="s2">'Test against Example 5.4.1 in Brockwell and Davis'</span>
                           <span class="s2">' (2016)'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_brockwell_davis_example_541():</span>
    <span class="s3"># Difference and demean the series</span>
    <span class="s1">endog = oshorts.copy()</span>

    <span class="s3"># Use innovations MA method to get initial coefficients for MLE</span>
    <span class="s1">initial</span><span class="s0">, </span><span class="s1">_ = innovations(endog</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># Fit MLE via innovations algorithm</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">True,</span>
                           <span class="s1">start_params=initial[</span><span class="s4">1</span><span class="s1">].params)</span>

    <span class="s1">assert_allclose(p.ma_params</span><span class="s0">, </span><span class="s1">-</span><span class="s4">0.818</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-3</span><span class="s1">)</span>

    <span class="s3"># TODO: the test for sigma2 fails; we get 2040.85 whereas BD reports</span>
    <span class="s3"># 2040.75. Unclear if this is optimizers finding different maxima, or a</span>
    <span class="s3"># reporting error by BD (i.e. typo where the 8 got reported as a 7). Should</span>
    <span class="s3"># check this out with ITSM program. NB: state space also finds 2040.85 as</span>
    <span class="s3"># the MLE value.</span>
    <span class="s3"># assert_allclose(p.sigma2, 2040.75, atol=1e-2)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_statespace():</span>
    <span class="s3"># Test innovations output against state-space output.</span>
    <span class="s1">endog = lake.copy()</span>
    <span class="s1">endog = endog - endog.mean()</span>

    <span class="s1">start_params = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">np.var(endog)]</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">mleres = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False,</span>
                                <span class="s1">start_params=start_params)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">))</span>

    <span class="s3"># Test that the maximized log-likelihood found via applications of the</span>
    <span class="s3"># innovations algorithm matches the log-likelihood found by the Kalman</span>
    <span class="s3"># filter at the same parameters</span>
    <span class="s1">res = mod.filter(p.params)</span>
    <span class="s1">assert_allclose(-mleres.minimize_results.fun</span><span class="s0">, </span><span class="s1">res.llf)</span>

    <span class="s3"># Test MLE fitting</span>
    <span class="s3"># To avoid small numerical differences with MLE fitting, start at the</span>
    <span class="s3"># parameters found from innovations_mle</span>
    <span class="s1">res2 = mod.fit(start_params=p.params</span><span class="s0">, </span><span class="s1">disp=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test that the state space approach confirms the MLE values found by</span>
    <span class="s3"># innovations_mle</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">res2.params)</span>

    <span class="s3"># Test that starting parameter estimation succeeds and isn't terrible</span>
    <span class="s3"># (i.e. leads to the same MLE)</span>
    <span class="s1">p2</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s3"># (does not need to be high-precision test since it's okay if different</span>
    <span class="s3"># starting parameters give slightly different MLE)</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">p2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_statespace_seasonal():</span>
    <span class="s3"># Test innovations output against state-space output.</span>
    <span class="s1">endog = lake.copy()</span>
    <span class="s1">endog = endog - endog.mean()</span>

    <span class="s1">start_params = [</span><span class="s4">0</span><span class="s0">, </span><span class="s1">np.var(endog)]</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">mleres = innovations_mle(endog</span><span class="s0">, </span><span class="s1">seasonal_order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">)</span><span class="s0">,</span>
                                <span class="s1">demean=</span><span class="s0">False, </span><span class="s1">start_params=start_params)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">seasonal_order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">))</span>

    <span class="s3"># Test that the maximized log-likelihood found via applications of the</span>
    <span class="s3"># innovations algorithm matches the log-likelihood found by the Kalman</span>
    <span class="s3"># filter at the same parameters</span>
    <span class="s1">res = mod.filter(p.params)</span>
    <span class="s1">assert_allclose(-mleres.minimize_results.fun</span><span class="s0">, </span><span class="s1">res.llf)</span>

    <span class="s3"># Test MLE fitting</span>
    <span class="s3"># To avoid small numerical differences with MLE fitting, start at the</span>
    <span class="s3"># parameters found from innovations_mle</span>
    <span class="s1">res2 = mod.fit(start_params=p.params</span><span class="s0">, </span><span class="s1">disp=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test that the state space approach confirms the MLE values found by</span>
    <span class="s3"># innovations_mle</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">res2.params)</span>

    <span class="s3"># Test that starting parameter estimation succeeds and isn't terrible</span>
    <span class="s3"># (i.e. leads to the same MLE)</span>
    <span class="s1">p2</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">seasonal_order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">4</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s3"># (does not need to be high-precision test since it's okay if different</span>
    <span class="s3"># starting parameters give slightly different MLE)</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">p2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_statespace_nonconsecutive():</span>
    <span class="s3"># Test innovations output against state-space output.</span>
    <span class="s1">endog = lake.copy()</span>
    <span class="s1">endog = endog - endog.mean()</span>

    <span class="s1">start_params = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">np.var(endog)]</span>
    <span class="s1">p</span><span class="s0">, </span><span class="s1">mleres = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span><span class="s0">,</span>
                                <span class="s1">demean=</span><span class="s0">False, </span><span class="s1">start_params=start_params)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s0">, </span><span class="s1">order=([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]))</span>

    <span class="s3"># Test that the maximized log-likelihood found via applications of the</span>
    <span class="s3"># innovations algorithm matches the log-likelihood found by the Kalman</span>
    <span class="s3"># filter at the same parameters</span>
    <span class="s1">res = mod.filter(p.params)</span>
    <span class="s1">assert_allclose(-mleres.minimize_results.fun</span><span class="s0">, </span><span class="s1">res.llf)</span>

    <span class="s3"># Test MLE fitting</span>
    <span class="s3"># To avoid small numerical differences with MLE fitting, start at the</span>
    <span class="s3"># parameters found from innovations_mle</span>
    <span class="s1">res2 = mod.fit(start_params=p.params</span><span class="s0">, </span><span class="s1">disp=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test that the state space approach confirms the MLE values found by</span>
    <span class="s3"># innovations_mle</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">res2.params)</span>

    <span class="s3"># Test that starting parameter estimation succeeds and isn't terrible</span>
    <span class="s3"># (i.e. leads to the same MLE)</span>
    <span class="s1">p2</span><span class="s0">, </span><span class="s1">_ = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s3"># (does not need to be high-precision test since it's okay if different</span>
    <span class="s3"># starting parameters give slightly different MLE)</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">p2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_integrated():</span>
    <span class="s1">endog = np.r_[</span><span class="s4">0</span><span class="s0">, </span><span class="s1">np.cumsum(lake.copy())]</span>

    <span class="s1">start_params = [</span><span class="s4">0</span><span class="s0">, </span><span class="s1">np.var(lake.copy())]</span>
    <span class="s0">with </span><span class="s1">assert_warns(UserWarning):</span>
        <span class="s1">p</span><span class="s0">, </span><span class="s1">mleres = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">,</span>
                                    <span class="s1">demean=</span><span class="s0">False, </span><span class="s1">start_params=start_params)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">,</span>
                          <span class="s1">simple_differencing=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s3"># Test that the maximized log-likelihood found via applications of the</span>
    <span class="s3"># innovations algorithm matches the log-likelihood found by the Kalman</span>
    <span class="s3"># filter at the same parameters</span>
    <span class="s1">res = mod.filter(p.params)</span>
    <span class="s1">assert_allclose(-mleres.minimize_results.fun</span><span class="s0">, </span><span class="s1">res.llf)</span>

    <span class="s3"># Test MLE fitting</span>
    <span class="s3"># To avoid small numerical differences with MLE fitting, start at the</span>
    <span class="s3"># parameters found from innovations_mle</span>
    <span class="s1">res2 = mod.fit(start_params=p.params</span><span class="s0">, </span><span class="s1">disp=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Test that the state space approach confirms the MLE values found by</span>
    <span class="s3"># innovations_mle</span>
    <span class="s3"># Note: atol is required only due to precision issues on Windows</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">res2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s1">)</span>

    <span class="s3"># Test that the result is equivalent to order=(1, 0, 0) on the differenced</span>
    <span class="s3"># data</span>
    <span class="s1">p2</span><span class="s0">, </span><span class="s1">_ = innovations_mle(lake.copy()</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False,</span>
                            <span class="s1">start_params=start_params)</span>
    <span class="s3"># (does not need to be high-precision test since it's okay if different</span>
    <span class="s3"># starting parameters give slightly different MLE)</span>
    <span class="s1">assert_allclose(p.params</span><span class="s0">, </span><span class="s1">p2.params</span><span class="s0">, </span><span class="s1">atol=</span><span class="s4">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_misc():</span>
    <span class="s1">endog = np.arange(</span><span class="s4">20</span><span class="s1">)**</span><span class="s4">2 </span><span class="s1">* </span><span class="s4">1.0</span>

    <span class="s3"># Check that when Hannan-Rissanen estimates non-stationary starting</span>
    <span class="s3"># parameters, innovations_mle sets it to zero</span>
    <span class="s1">hr</span><span class="s0">, </span><span class="s1">_ = hannan_rissanen(endog</span><span class="s0">, </span><span class="s1">ar_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">assert_(hr.ar_params[</span><span class="s4">0</span><span class="s1">] &gt; </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">res = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">))</span>
    <span class="s1">assert_allclose(res.start_params[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>

    <span class="s3"># Check that when Hannan-Rissanen estimates non-invertible starting</span>
    <span class="s3"># parameters, innovations_mle sets it to zero</span>
    <span class="s1">hr</span><span class="s0">, </span><span class="s1">_ = hannan_rissanen(endog</span><span class="s0">, </span><span class="s1">ma_order=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">demean=</span><span class="s0">False</span><span class="s1">)</span>
    <span class="s1">assert_(hr.ma_params[</span><span class="s4">0</span><span class="s1">] &gt; </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">res = innovations_mle(endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">assert_allclose(res.start_params[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_innovations_mle_invalid():</span>
    <span class="s1">endog = np.arange(</span><span class="s4">2</span><span class="s1">) * </span><span class="s4">1.0</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations_mle</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">))</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations_mle</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations_mle</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1.5</span><span class="s1">))</span>

    <span class="s1">endog = lake.copy()</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations_mle</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">,</span>
                  <span class="s1">start_params=[</span><span class="s4">1.</span><span class="s0">, </span><span class="s4">1.</span><span class="s1">])</span>
    <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">innovations_mle</span><span class="s0">, </span><span class="s1">endog</span><span class="s0">, </span><span class="s1">order=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
                  <span class="s1">start_params=[</span><span class="s4">1.</span><span class="s0">, </span><span class="s4">1.</span><span class="s1">])</span>
</pre>
</body>
</html>
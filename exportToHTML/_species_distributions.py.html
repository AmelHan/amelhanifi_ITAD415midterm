<html>
<head>
<title>_species_distributions.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
.s6 { color: #a5c261;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_species_distributions.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
============================= 
Species distribution dataset 
============================= 
 
This dataset represents the geographic distribution of species. 
The dataset is provided by Phillips et. al. (2006). 
 
The two species are: 
 
 - `&quot;Bradypus variegatus&quot; 
   &lt;http://www.iucnredlist.org/details/3038/0&gt;`_ , 
   the Brown-throated Sloth. 
 
 - `&quot;Microryzomys minutus&quot; 
   &lt;http://www.iucnredlist.org/details/13408/0&gt;`_ , 
   also known as the Forest Small Rice Rat, a rodent that lives in Peru, 
   Colombia, Ecuador, Peru, and Venezuela. 
 
References 
---------- 
 
`&quot;Maximum entropy modeling of species geographic distributions&quot; 
&lt;http://rob.schapire.net/papers/ecolmod.pdf&gt;`_ S. J. Phillips, 
R. P. Anderson, R. E. Schapire - Ecological Modelling, 190:231-259, 2006. 
 
Notes 
----- 
 
For an example of using this dataset, see 
:ref:`examples/applications/plot_species_distribution_modeling.py 
&lt;sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py&gt;`. 
&quot;&quot;&quot;</span>

<span class="s2"># Authors: Peter Prettenhofer &lt;peter.prettenhofer@gmail.com&gt;</span>
<span class="s2">#          Jake Vanderplas &lt;vanderplas@astro.washington.edu&gt;</span>
<span class="s2">#</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">logging</span>
<span class="s3">from </span><span class="s1">io </span><span class="s3">import </span><span class="s1">BytesIO</span>
<span class="s3">from </span><span class="s1">os </span><span class="s3">import </span><span class="s1">PathLike</span><span class="s3">, </span><span class="s1">makedirs</span><span class="s3">, </span><span class="s1">remove</span>
<span class="s3">from </span><span class="s1">os.path </span><span class="s3">import </span><span class="s1">exists</span>

<span class="s3">import </span><span class="s1">joblib</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">from </span><span class="s1">..utils </span><span class="s3">import </span><span class="s1">Bunch</span>
<span class="s3">from </span><span class="s1">..utils._param_validation </span><span class="s3">import </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s1">. </span><span class="s3">import </span><span class="s1">get_data_home</span>
<span class="s3">from </span><span class="s1">._base </span><span class="s3">import </span><span class="s1">RemoteFileMetadata</span><span class="s3">, </span><span class="s1">_fetch_remote</span><span class="s3">, </span><span class="s1">_pkl_filepath</span>

<span class="s2"># The original data can be found at:</span>
<span class="s2"># https://biodiversityinformatics.amnh.org/open_source/maxent/samples.zip</span>
<span class="s1">SAMPLES = RemoteFileMetadata(</span>
    <span class="s1">filename=</span><span class="s4">&quot;samples.zip&quot;</span><span class="s3">,</span>
    <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976075&quot;</span><span class="s3">,</span>
    <span class="s1">checksum=</span><span class="s4">&quot;abb07ad284ac50d9e6d20f1c4211e0fd3c098f7f85955e89d321ee8efe37ac28&quot;</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s2"># The original data can be found at:</span>
<span class="s2"># https://biodiversityinformatics.amnh.org/open_source/maxent/coverages.zip</span>
<span class="s1">COVERAGES = RemoteFileMetadata(</span>
    <span class="s1">filename=</span><span class="s4">&quot;coverages.zip&quot;</span><span class="s3">,</span>
    <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976078&quot;</span><span class="s3">,</span>
    <span class="s1">checksum=</span><span class="s4">&quot;4d862674d72e79d6cee77e63b98651ec7926043ba7d39dcb31329cf3f6073807&quot;</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s1">DATA_ARCHIVE_NAME = </span><span class="s4">&quot;species_coverage.pkz&quot;</span>


<span class="s1">logger = logging.getLogger(__name__)</span>


<span class="s3">def </span><span class="s1">_load_coverage(F</span><span class="s3">, </span><span class="s1">header_length=</span><span class="s5">6</span><span class="s3">, </span><span class="s1">dtype=np.int16):</span>
    <span class="s0">&quot;&quot;&quot;Load a coverage file from an open file object. 
 
    This will return a numpy array of the given dtype 
    &quot;&quot;&quot;</span>
    <span class="s1">header = [F.readline() </span><span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range(header_length)]</span>
    <span class="s1">make_tuple = </span><span class="s3">lambda </span><span class="s1">t: (t.split()[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">float(t.split()[</span><span class="s5">1</span><span class="s1">]))</span>
    <span class="s1">header = dict([make_tuple(line) </span><span class="s3">for </span><span class="s1">line </span><span class="s3">in </span><span class="s1">header])</span>

    <span class="s1">M = np.loadtxt(F</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">nodata = int(header[</span><span class="s6">b&quot;NODATA_value&quot;</span><span class="s1">])</span>
    <span class="s3">if </span><span class="s1">nodata != -</span><span class="s5">9999</span><span class="s1">:</span>
        <span class="s1">M[nodata] = -</span><span class="s5">9999</span>
    <span class="s3">return </span><span class="s1">M</span>


<span class="s3">def </span><span class="s1">_load_csv(F):</span>
    <span class="s0">&quot;&quot;&quot;Load csv file. 
 
    Parameters 
    ---------- 
    F : file object 
        CSV file open in byte mode. 
 
    Returns 
    ------- 
    rec : np.ndarray 
        record array representing the data 
    &quot;&quot;&quot;</span>
    <span class="s1">names = F.readline().decode(</span><span class="s4">&quot;ascii&quot;</span><span class="s1">).strip().split(</span><span class="s4">&quot;,&quot;</span><span class="s1">)</span>

    <span class="s1">rec = np.loadtxt(F</span><span class="s3">, </span><span class="s1">skiprows=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">delimiter=</span><span class="s4">&quot;,&quot;</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s4">&quot;a22,f4,f4&quot;</span><span class="s1">)</span>
    <span class="s1">rec.dtype.names = names</span>
    <span class="s3">return </span><span class="s1">rec</span>


<span class="s3">def </span><span class="s1">construct_grids(batch):</span>
    <span class="s0">&quot;&quot;&quot;Construct the map grid from the batch object 
 
    Parameters 
    ---------- 
    batch : Batch object 
        The object returned by :func:`fetch_species_distributions` 
 
    Returns 
    ------- 
    (xgrid, ygrid) : 1-D arrays 
        The grid corresponding to the values in batch.coverages 
    &quot;&quot;&quot;</span>
    <span class="s2"># x,y coordinates for corner cells</span>
    <span class="s1">xmin = batch.x_left_lower_corner + batch.grid_size</span>
    <span class="s1">xmax = xmin + (batch.Nx * batch.grid_size)</span>
    <span class="s1">ymin = batch.y_left_lower_corner + batch.grid_size</span>
    <span class="s1">ymax = ymin + (batch.Ny * batch.grid_size)</span>

    <span class="s2"># x coordinates of the grid cells</span>
    <span class="s1">xgrid = np.arange(xmin</span><span class="s3">, </span><span class="s1">xmax</span><span class="s3">, </span><span class="s1">batch.grid_size)</span>
    <span class="s2"># y coordinates of the grid cells</span>
    <span class="s1">ygrid = np.arange(ymin</span><span class="s3">, </span><span class="s1">ymax</span><span class="s3">, </span><span class="s1">batch.grid_size)</span>

    <span class="s3">return </span><span class="s1">(xgrid</span><span class="s3">, </span><span class="s1">ygrid)</span>


<span class="s1">@validate_params(</span>
    <span class="s1">{</span><span class="s4">&quot;data_home&quot;</span><span class="s1">: [str</span><span class="s3">, </span><span class="s1">PathLike</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">, </span><span class="s4">&quot;download_if_missing&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]}</span><span class="s3">,</span>
    <span class="s1">prefer_skip_nested_validation=</span><span class="s3">True,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">fetch_species_distributions(*</span><span class="s3">, </span><span class="s1">data_home=</span><span class="s3">None, </span><span class="s1">download_if_missing=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Loader for species distribution dataset from Phillips et. al. (2006). 
 
    Read more in the :ref:`User Guide &lt;datasets&gt;`. 
 
    Parameters 
    ---------- 
    data_home : str or path-like, default=None 
        Specify another download and cache folder for the datasets. By default 
        all scikit-learn data is stored in '~/scikit_learn_data' subfolders. 
 
    download_if_missing : bool, default=True 
        If False, raise an OSError if the data is not locally available 
        instead of trying to download the data from the source site. 
 
    Returns 
    ------- 
    data : :class:`~sklearn.utils.Bunch` 
        Dictionary-like object, with the following attributes. 
 
        coverages : array, shape = [14, 1592, 1212] 
            These represent the 14 features measured 
            at each point of the map grid. 
            The latitude/longitude values for the grid are discussed below. 
            Missing data is represented by the value -9999. 
        train : record array, shape = (1624,) 
            The training points for the data.  Each point has three fields: 
 
            - train['species'] is the species name 
            - train['dd long'] is the longitude, in degrees 
            - train['dd lat'] is the latitude, in degrees 
        test : record array, shape = (620,) 
            The test points for the data.  Same format as the training data. 
        Nx, Ny : integers 
            The number of longitudes (x) and latitudes (y) in the grid 
        x_left_lower_corner, y_left_lower_corner : floats 
            The (x,y) position of the lower-left corner, in degrees 
        grid_size : float 
            The spacing between points of the grid, in degrees 
 
    Notes 
    ----- 
 
    This dataset represents the geographic distribution of species. 
    The dataset is provided by Phillips et. al. (2006). 
 
    The two species are: 
 
    - `&quot;Bradypus variegatus&quot; 
      &lt;http://www.iucnredlist.org/details/3038/0&gt;`_ , 
      the Brown-throated Sloth. 
 
    - `&quot;Microryzomys minutus&quot; 
      &lt;http://www.iucnredlist.org/details/13408/0&gt;`_ , 
      also known as the Forest Small Rice Rat, a rodent that lives in Peru, 
      Colombia, Ecuador, Peru, and Venezuela. 
 
    - For an example of using this dataset with scikit-learn, see 
      :ref:`examples/applications/plot_species_distribution_modeling.py 
      &lt;sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py&gt;`. 
 
    References 
    ---------- 
 
    * `&quot;Maximum entropy modeling of species geographic distributions&quot; 
      &lt;http://rob.schapire.net/papers/ecolmod.pdf&gt;`_ 
      S. J. Phillips, R. P. Anderson, R. E. Schapire - Ecological Modelling, 
      190:231-259, 2006. 
    &quot;&quot;&quot;</span>
    <span class="s1">data_home = get_data_home(data_home)</span>
    <span class="s3">if not </span><span class="s1">exists(data_home):</span>
        <span class="s1">makedirs(data_home)</span>

    <span class="s2"># Define parameters for the data files.  These should not be changed</span>
    <span class="s2"># unless the data model changes.  They will be saved in the npz file</span>
    <span class="s2"># with the downloaded data.</span>
    <span class="s1">extra_params = dict(</span>
        <span class="s1">x_left_lower_corner=-</span><span class="s5">94.8</span><span class="s3">,</span>
        <span class="s1">Nx=</span><span class="s5">1212</span><span class="s3">,</span>
        <span class="s1">y_left_lower_corner=-</span><span class="s5">56.05</span><span class="s3">,</span>
        <span class="s1">Ny=</span><span class="s5">1592</span><span class="s3">,</span>
        <span class="s1">grid_size=</span><span class="s5">0.05</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">dtype = np.int16</span>

    <span class="s1">archive_path = _pkl_filepath(data_home</span><span class="s3">, </span><span class="s1">DATA_ARCHIVE_NAME)</span>

    <span class="s3">if not </span><span class="s1">exists(archive_path):</span>
        <span class="s3">if not </span><span class="s1">download_if_missing:</span>
            <span class="s3">raise </span><span class="s1">OSError(</span><span class="s4">&quot;Data not found and `download_if_missing` is False&quot;</span><span class="s1">)</span>
        <span class="s1">logger.info(</span><span class="s4">&quot;Downloading species data from %s to %s&quot; </span><span class="s1">% (SAMPLES.url</span><span class="s3">, </span><span class="s1">data_home))</span>
        <span class="s1">samples_path = _fetch_remote(SAMPLES</span><span class="s3">, </span><span class="s1">dirname=data_home)</span>
        <span class="s3">with </span><span class="s1">np.load(samples_path) </span><span class="s3">as </span><span class="s1">X:  </span><span class="s2"># samples.zip is a valid npz</span>
            <span class="s3">for </span><span class="s1">f </span><span class="s3">in </span><span class="s1">X.files:</span>
                <span class="s1">fhandle = BytesIO(X[f])</span>
                <span class="s3">if </span><span class="s4">&quot;train&quot; </span><span class="s3">in </span><span class="s1">f:</span>
                    <span class="s1">train = _load_csv(fhandle)</span>
                <span class="s3">if </span><span class="s4">&quot;test&quot; </span><span class="s3">in </span><span class="s1">f:</span>
                    <span class="s1">test = _load_csv(fhandle)</span>
        <span class="s1">remove(samples_path)</span>

        <span class="s1">logger.info(</span>
            <span class="s4">&quot;Downloading coverage data from %s to %s&quot; </span><span class="s1">% (COVERAGES.url</span><span class="s3">, </span><span class="s1">data_home)</span>
        <span class="s1">)</span>
        <span class="s1">coverages_path = _fetch_remote(COVERAGES</span><span class="s3">, </span><span class="s1">dirname=data_home)</span>
        <span class="s3">with </span><span class="s1">np.load(coverages_path) </span><span class="s3">as </span><span class="s1">X:  </span><span class="s2"># coverages.zip is a valid npz</span>
            <span class="s1">coverages = []</span>
            <span class="s3">for </span><span class="s1">f </span><span class="s3">in </span><span class="s1">X.files:</span>
                <span class="s1">fhandle = BytesIO(X[f])</span>
                <span class="s1">logger.debug(</span><span class="s4">&quot; - converting {}&quot;</span><span class="s1">.format(f))</span>
                <span class="s1">coverages.append(_load_coverage(fhandle))</span>
            <span class="s1">coverages = np.asarray(coverages</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>
        <span class="s1">remove(coverages_path)</span>

        <span class="s1">bunch = Bunch(coverages=coverages</span><span class="s3">, </span><span class="s1">test=test</span><span class="s3">, </span><span class="s1">train=train</span><span class="s3">, </span><span class="s1">**extra_params)</span>
        <span class="s1">joblib.dump(bunch</span><span class="s3">, </span><span class="s1">archive_path</span><span class="s3">, </span><span class="s1">compress=</span><span class="s5">9</span><span class="s1">)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">bunch = joblib.load(archive_path)</span>

    <span class="s3">return </span><span class="s1">bunch</span>
</pre>
</body>
</html>
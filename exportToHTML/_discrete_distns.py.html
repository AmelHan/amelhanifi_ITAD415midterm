<html>
<head>
<title>_discrete_distns.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_discrete_distns.py</font>
</center></td></tr></table>
<pre><span class="s0">#</span>
<span class="s0"># Author:  Travis Oliphant  2002-2011 with contributions from</span>
<span class="s0">#          SciPy Developers 2004-2011</span>
<span class="s0">#</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>

<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">special</span>
<span class="s2">from </span><span class="s1">scipy.special </span><span class="s2">import </span><span class="s1">entr</span><span class="s2">, </span><span class="s1">logsumexp</span><span class="s2">, </span><span class="s1">betaln</span><span class="s2">, </span><span class="s1">gammaln </span><span class="s2">as </span><span class="s1">gamln</span><span class="s2">, </span><span class="s1">zeta</span>
<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">_lazywhere</span><span class="s2">, </span><span class="s1">rng_integers</span>
<span class="s2">from </span><span class="s1">scipy.interpolate </span><span class="s2">import </span><span class="s1">interp1d</span>

<span class="s2">from </span><span class="s1">numpy </span><span class="s2">import </span><span class="s1">floor</span><span class="s2">, </span><span class="s1">ceil</span><span class="s2">, </span><span class="s1">log</span><span class="s2">, </span><span class="s1">exp</span><span class="s2">, </span><span class="s1">sqrt</span><span class="s2">, </span><span class="s1">log1p</span><span class="s2">, </span><span class="s1">expm1</span><span class="s2">, </span><span class="s1">tanh</span><span class="s2">, </span><span class="s1">cosh</span><span class="s2">, </span><span class="s1">sinh</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">._distn_infrastructure </span><span class="s2">import </span><span class="s1">(rv_discrete</span><span class="s2">, </span><span class="s1">get_distribution_names</span><span class="s2">,</span>
                                    <span class="s1">_check_shape</span><span class="s2">, </span><span class="s1">_ShapeInfo)</span>
<span class="s2">import </span><span class="s1">scipy.stats._boost </span><span class="s2">as </span><span class="s1">_boost</span>
<span class="s2">from </span><span class="s1">._biasedurn </span><span class="s2">import </span><span class="s1">(_PyFishersNCHypergeometric</span><span class="s2">,</span>
                         <span class="s1">_PyWalleniusNCHypergeometric</span><span class="s2">,</span>
                         <span class="s1">_PyStochasticLib3)</span>


<span class="s2">def </span><span class="s1">_isintegral(x):</span>
    <span class="s2">return </span><span class="s1">x == np.round(x)</span>


<span class="s2">class </span><span class="s1">binom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A binomial discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `binom` is: 
 
    .. math:: 
 
       f(k) = \binom{n}{k} p^k (1-p)^{n-k} 
 
    for :math:`k \in \{0, 1, \dots, n\}`, :math:`0 \leq p \leq 1` 
 
    `binom` takes :math:`n` and :math:`p` as shape parameters, 
    where :math:`p` is the probability of a single success 
    and :math:`1-p` is the probability of a single failure. 
 
    %(after_notes)s 
 
    %(example)s 
 
    See Also 
    -------- 
    hypergeom, nbinom, nhypergeom 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.binomial(n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(n &gt;= </span><span class="s5">0</span><span class="s1">) &amp; _isintegral(n) &amp; (p &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (p &lt;= </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">n</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s1">combiln = (gamln(n+</span><span class="s5">1</span><span class="s1">) - (gamln(k+</span><span class="s5">1</span><span class="s1">) + gamln(n-k+</span><span class="s5">1</span><span class="s1">)))</span>
        <span class="s2">return </span><span class="s1">combiln + special.xlogy(k</span><span class="s2">, </span><span class="s1">p) + special.xlog1py(n-k</span><span class="s2">, </span><span class="s1">-p)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s0"># binom.pmf(k) = choose(n, k) * p**k * (1-p)**(n-k)</span>
        <span class="s2">return </span><span class="s1">_boost._binom_pdf(x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">_boost._binom_cdf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">_boost._binom_sf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">_boost._binom_isf(x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">_boost._binom_ppf(q</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">mu = _boost._binom_mean(n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s1">var = _boost._binom_variance(n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g1 = _boost._binom_skewness(n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g2 = _boost._binom_kurtosis_excess(n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = np.r_[</span><span class="s5">0</span><span class="s1">:n + </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">vals = self._pmf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">return </span><span class="s1">np.sum(entr(vals)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>


<span class="s1">binom = binom_gen(name=</span><span class="s4">'binom'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">bernoulli_gen(binom_gen):</span>
    <span class="s3">r&quot;&quot;&quot;A Bernoulli discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `bernoulli` is: 
 
    .. math:: 
 
       f(k) = \begin{cases}1-p  &amp;\text{if } k = 0\\ 
                           p    &amp;\text{if } k = 1\end{cases} 
 
    for :math:`k` in :math:`\{0, 1\}`, :math:`0 \leq p \leq 1` 
 
    `bernoulli` takes :math:`p` as shape parameter, 
    where :math:`p` is the probability of a single success 
    and :math:`1-p` is the probability of a single failure. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">binom_gen._rvs(self</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(p &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (p &lt;= </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s0"># Overrides binom_gen._get_support!x</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">self.b</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._logpmf(x</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s0"># bernoulli.pmf(k) = 1-p  if k = 0</span>
        <span class="s0">#                  = p    if k = 1</span>
        <span class="s2">return </span><span class="s1">binom._pmf(x</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._cdf(x</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._sf(x</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._isf(x</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._ppf(q</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">binom._stats(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">entr(p) + entr(</span><span class="s5">1</span><span class="s1">-p)</span>


<span class="s1">bernoulli = bernoulli_gen(b=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'bernoulli'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">betabinom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A beta-binomial discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The beta-binomial distribution is a binomial distribution with a 
    probability of success `p` that follows a beta distribution. 
 
    The probability mass function for `betabinom` is: 
 
    .. math:: 
 
       f(k) = \binom{n}{k} \frac{B(k + a, n - k + b)}{B(a, b)} 
 
    for :math:`k \in \{0, 1, \dots, n\}`, :math:`n \geq 0`, :math:`a &gt; 0`, 
    :math:`b &gt; 0`, where :math:`B(a, b)` is the beta function. 
 
    `betabinom` takes :math:`n`, :math:`a`, and :math:`b` as shape parameters. 
 
    References 
    ---------- 
    .. [1] https://en.wikipedia.org/wiki/Beta-binomial_distribution 
 
    %(after_notes)s 
 
    .. versionadded:: 1.4.0 
 
    See Also 
    -------- 
    beta, binom 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;b&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">p = random_state.beta(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">size)</span>
        <span class="s2">return </span><span class="s1">random_state.binomial(n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s1">n</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">(n &gt;= </span><span class="s5">0</span><span class="s1">) &amp; _isintegral(n) &amp; (a &gt; </span><span class="s5">0</span><span class="s1">) &amp; (b &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s1">combiln = -log(n + </span><span class="s5">1</span><span class="s1">) - betaln(n - k + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">k + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">combiln + betaln(k + a</span><span class="s2">, </span><span class="s1">n - k + b) - betaln(a</span><span class="s2">, </span><span class="s1">b)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b):</span>
        <span class="s2">return </span><span class="s1">exp(self._logpmf(x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">moments=</span><span class="s4">'mv'</span><span class="s1">):</span>
        <span class="s1">e_p = a / (a + b)</span>
        <span class="s1">e_q = </span><span class="s5">1 </span><span class="s1">- e_p</span>
        <span class="s1">mu = n * e_p</span>
        <span class="s1">var = n * (a + b + n) * e_p * e_q / (a + b + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None</span>
        <span class="s2">if </span><span class="s4">'s' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g1 = </span><span class="s5">1.0 </span><span class="s1">/ sqrt(var)</span>
            <span class="s1">g1 *= (a + b + </span><span class="s5">2 </span><span class="s1">* n) * (b - a)</span>
            <span class="s1">g1 /= (a + b + </span><span class="s5">2</span><span class="s1">) * (a + b)</span>
        <span class="s2">if </span><span class="s4">'k' </span><span class="s2">in </span><span class="s1">moments:</span>
            <span class="s1">g2 = (a + b).astype(e_p.dtype)</span>
            <span class="s1">g2 *= (a + b - </span><span class="s5">1 </span><span class="s1">+ </span><span class="s5">6 </span><span class="s1">* n)</span>
            <span class="s1">g2 += </span><span class="s5">3 </span><span class="s1">* a * b * (n - </span><span class="s5">2</span><span class="s1">)</span>
            <span class="s1">g2 += </span><span class="s5">6 </span><span class="s1">* n ** </span><span class="s5">2</span>
            <span class="s1">g2 -= </span><span class="s5">3 </span><span class="s1">* e_p * b * n * (</span><span class="s5">6 </span><span class="s1">- n)</span>
            <span class="s1">g2 -= </span><span class="s5">18 </span><span class="s1">* e_p * e_q * n ** </span><span class="s5">2</span>
            <span class="s1">g2 *= (a + b) ** </span><span class="s5">2 </span><span class="s1">* (</span><span class="s5">1 </span><span class="s1">+ a + b)</span>
            <span class="s1">g2 /= (n * a * b * (a + b + </span><span class="s5">2</span><span class="s1">) * (a + b + </span><span class="s5">3</span><span class="s1">) * (a + b + n))</span>
            <span class="s1">g2 -= </span><span class="s5">3</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">betabinom = betabinom_gen(name=</span><span class="s4">'betabinom'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">nbinom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A negative binomial discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    Negative binomial distribution describes a sequence of i.i.d. Bernoulli 
    trials, repeated until a predefined, non-random number of successes occurs. 
 
    The probability mass function of the number of failures for `nbinom` is: 
 
    .. math:: 
 
       f(k) = \binom{k+n-1}{n-1} p^n (1-p)^k 
 
    for :math:`k \ge 0`, :math:`0 &lt; p \leq 1` 
 
    `nbinom` takes :math:`n` and :math:`p` as shape parameters where :math:`n` 
    is the number of successes, :math:`p` is the probability of a single 
    success, and :math:`1-p` is the probability of a single failure. 
 
    Another common parameterization of the negative binomial distribution is 
    in terms of the mean number of failures :math:`\mu` to achieve :math:`n` 
    successes. The mean :math:`\mu` is related to the probability of success 
    as 
 
    .. math:: 
 
       p = \frac{n}{n + \mu} 
 
    The number of successes :math:`n` may also be specified in terms of a 
    &quot;dispersion&quot;, &quot;heterogeneity&quot;, or &quot;aggregation&quot; parameter :math:`\alpha`, 
    which relates the mean :math:`\mu` to the variance :math:`\sigma^2`, 
    e.g. :math:`\sigma^2 = \mu + \alpha \mu^2`. Regardless of the convention 
    used for :math:`\alpha`, 
 
    .. math:: 
 
       p &amp;= \frac{\mu}{\sigma^2} \\ 
       n &amp;= \frac{\mu^2}{\sigma^2 - \mu} 
 
    %(after_notes)s 
 
    %(example)s 
 
    See Also 
    -------- 
    hypergeom, binom, nhypergeom 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.negative_binomial(n</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(n &gt; </span><span class="s5">0</span><span class="s1">) &amp; (p &gt; </span><span class="s5">0</span><span class="s1">) &amp; (p &lt;= </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s0"># nbinom.pmf(k) = choose(k+n-1, n-1) * p**n * (1-p)**k</span>
        <span class="s2">return </span><span class="s1">_boost._nbinom_pdf(x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">coeff = gamln(n+x) - gamln(x+</span><span class="s5">1</span><span class="s1">) - gamln(n)</span>
        <span class="s2">return </span><span class="s1">coeff + n*log(p) + special.xlog1py(x</span><span class="s2">, </span><span class="s1">-p)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">_boost._nbinom_cdf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s1">cdf = self._cdf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s1">cond = cdf &gt; </span><span class="s5">0.5</span>

        <span class="s2">def </span><span class="s1">f1(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
            <span class="s2">return </span><span class="s1">np.log1p(-special.betainc(k + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">- p))</span>

        <span class="s0"># do calc in place</span>
        <span class="s1">logcdf = cdf</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s4">'ignore'</span><span class="s1">):</span>
            <span class="s1">logcdf[cond] = f1(k[cond]</span><span class="s2">, </span><span class="s1">n[cond]</span><span class="s2">, </span><span class="s1">p[cond])</span>
            <span class="s1">logcdf[~cond] = np.log(cdf[~cond])</span>
        <span class="s2">return </span><span class="s1">logcdf</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">_boost._nbinom_sf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_isf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._nbinom_isf(x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s2">return </span><span class="s1">_boost._nbinom_ppf(q</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(</span>
            <span class="s1">_boost._nbinom_mean(n</span><span class="s2">, </span><span class="s1">p)</span><span class="s2">,</span>
            <span class="s1">_boost._nbinom_variance(n</span><span class="s2">, </span><span class="s1">p)</span><span class="s2">,</span>
            <span class="s1">_boost._nbinom_skewness(n</span><span class="s2">, </span><span class="s1">p)</span><span class="s2">,</span>
            <span class="s1">_boost._nbinom_kurtosis_excess(n</span><span class="s2">, </span><span class="s1">p)</span><span class="s2">,</span>
        <span class="s1">)</span>


<span class="s1">nbinom = nbinom_gen(name=</span><span class="s4">'nbinom'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">geom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A geometric discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `geom` is: 
 
    .. math:: 
 
        f(k) = (1-p)^{k-1} p 
 
    for :math:`k \ge 1`, :math:`0 &lt; p \leq 1` 
 
    `geom` takes :math:`p` as shape parameter, 
    where :math:`p` is the probability of a single success 
    and :math:`1-p` is the probability of a single failure. 
 
    %(after_notes)s 
 
    See Also 
    -------- 
    planck 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.geometric(p</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(p &lt;= </span><span class="s5">1</span><span class="s1">) &amp; (p &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">np.power(</span><span class="s5">1</span><span class="s1">-p</span><span class="s2">, </span><span class="s1">k-</span><span class="s5">1</span><span class="s1">) * p</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">special.xlog1py(k - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">-p) + log(p)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">-expm1(log1p(-p)*k)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">np.exp(self._logsf(x</span><span class="s2">, </span><span class="s1">p))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">k*log1p(-p)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">vals = ceil(log1p(-q) / log1p(-p))</span>
        <span class="s1">temp = self._cdf(vals-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">p)</span>
        <span class="s2">return </span><span class="s1">np.where((temp &gt;= q) &amp; (vals &gt; </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">vals-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">mu = </span><span class="s5">1.0</span><span class="s1">/p</span>
        <span class="s1">qr = </span><span class="s5">1.0</span><span class="s1">-p</span>
        <span class="s1">var = qr / p / p</span>
        <span class="s1">g1 = (</span><span class="s5">2.0</span><span class="s1">-p) / sqrt(qr)</span>
        <span class="s1">g2 = np.polyval([</span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">6</span><span class="s2">, </span><span class="s5">6</span><span class="s1">]</span><span class="s2">, </span><span class="s1">p)/(</span><span class="s5">1.0</span><span class="s1">-p)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">-np.log(p) - np.log1p(-p) * (</span><span class="s5">1.0</span><span class="s1">-p) / p</span>


<span class="s1">geom = geom_gen(a=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'geom'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">&quot;A geometric&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">hypergeom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A hypergeometric discrete random variable. 
 
    The hypergeometric distribution models drawing objects from a bin. 
    `M` is the total number of objects, `n` is total number of Type I objects. 
    The random variate represents the number of Type I objects in `N` drawn 
    without replacement from the total population. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The symbols used to denote the shape parameters (`M`, `n`, and `N`) are not 
    universally accepted.  See the Examples for a clarification of the 
    definitions used here. 
 
    The probability mass function is defined as, 
 
    .. math:: p(k, M, n, N) = \frac{\binom{n}{k} \binom{M - n}{N - k}} 
                                   {\binom{M}{N}} 
 
    for :math:`k \in [\max(0, N - M + n), \min(n, N)]`, where the binomial 
    coefficients are defined as, 
 
    .. math:: \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}. 
 
    %(after_notes)s 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import hypergeom 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
 
    Suppose we have a collection of 20 animals, of which 7 are dogs.  Then if 
    we want to know the probability of finding a given number of dogs if we 
    choose at random 12 of the 20 animals, we can initialize a frozen 
    distribution and plot the probability mass function: 
 
    &gt;&gt;&gt; [M, n, N] = [20, 7, 12] 
    &gt;&gt;&gt; rv = hypergeom(M, n, N) 
    &gt;&gt;&gt; x = np.arange(0, n+1) 
    &gt;&gt;&gt; pmf_dogs = rv.pmf(x) 
 
    &gt;&gt;&gt; fig = plt.figure() 
    &gt;&gt;&gt; ax = fig.add_subplot(111) 
    &gt;&gt;&gt; ax.plot(x, pmf_dogs, 'bo') 
    &gt;&gt;&gt; ax.vlines(x, 0, pmf_dogs, lw=2) 
    &gt;&gt;&gt; ax.set_xlabel('# of dogs in our group of chosen animals') 
    &gt;&gt;&gt; ax.set_ylabel('hypergeom PMF') 
    &gt;&gt;&gt; plt.show() 
 
    Instead of using a frozen distribution we can also use `hypergeom` 
    methods directly.  To for example obtain the cumulative distribution 
    function, use: 
 
    &gt;&gt;&gt; prb = hypergeom.cdf(x, M, n, N) 
 
    And to generate random numbers: 
 
    &gt;&gt;&gt; R = hypergeom.rvs(M, n, N, size=10) 
 
    See Also 
    -------- 
    nhypergeom, binom, nbinom 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;M&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;N&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.hypergeometric(n</span><span class="s2">, </span><span class="s1">M-n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">np.maximum(N-(M-n)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.minimum(n</span><span class="s2">, </span><span class="s1">N)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">cond = (M &gt; </span><span class="s5">0</span><span class="s1">) &amp; (n &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (N &gt;= </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cond &amp;= (n &lt;= M) &amp; (N &lt;= M)</span>
        <span class="s1">cond &amp;= _isintegral(M) &amp; _isintegral(n) &amp; _isintegral(N)</span>
        <span class="s2">return </span><span class="s1">cond</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">tot</span><span class="s2">, </span><span class="s1">good = M</span><span class="s2">, </span><span class="s1">n</span>
        <span class="s1">bad = tot - good</span>
        <span class="s1">result = (betaln(good+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) + betaln(bad+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) + betaln(tot-N+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">N+</span><span class="s5">1</span><span class="s1">) -</span>
                  <span class="s1">betaln(k+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">good-k+</span><span class="s5">1</span><span class="s1">) - betaln(N-k+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">bad-N+k+</span><span class="s5">1</span><span class="s1">) -</span>
                  <span class="s1">betaln(tot+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">_boost._hypergeom_pdf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">_boost._hypergeom_cdf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N = </span><span class="s5">1. </span><span class="s1">* M</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">* n</span><span class="s2">, </span><span class="s5">1. </span><span class="s1">* N</span>
        <span class="s1">m = M - n</span>

        <span class="s0"># Boost kurtosis_excess doesn't return the same as the value</span>
        <span class="s0"># computed here.</span>
        <span class="s1">g2 = M * (M + </span><span class="s5">1</span><span class="s1">) - </span><span class="s5">6. </span><span class="s1">* N * (M - N) - </span><span class="s5">6. </span><span class="s1">* n * m</span>
        <span class="s1">g2 *= (M - </span><span class="s5">1</span><span class="s1">) * M * M</span>
        <span class="s1">g2 += </span><span class="s5">6. </span><span class="s1">* n * N * (M - N) * m * (</span><span class="s5">5. </span><span class="s1">* M - </span><span class="s5">6</span><span class="s1">)</span>
        <span class="s1">g2 /= n * N * (M - N) * m * (M - </span><span class="s5">2.</span><span class="s1">) * (M - </span><span class="s5">3.</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">(</span>
            <span class="s1">_boost._hypergeom_mean(n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span><span class="s2">,</span>
            <span class="s1">_boost._hypergeom_variance(n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span><span class="s2">,</span>
            <span class="s1">_boost._hypergeom_skewness(n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span><span class="s2">,</span>
            <span class="s1">g2</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">k = np.r_[N - (M - n):min(n</span><span class="s2">, </span><span class="s1">N) + </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">vals = self.pmf(k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N)</span>
        <span class="s2">return </span><span class="s1">np.sum(entr(vals)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">_boost._hypergeom_sf(k</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">M)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">res = []</span>
        <span class="s2">for </span><span class="s1">quant</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw </span><span class="s2">in </span><span class="s1">zip(*np.broadcast_arrays(k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N)):</span>
            <span class="s2">if </span><span class="s1">(quant + </span><span class="s5">0.5</span><span class="s1">) * (tot + </span><span class="s5">0.5</span><span class="s1">) &lt; (good - </span><span class="s5">0.5</span><span class="s1">) * (draw - </span><span class="s5">0.5</span><span class="s1">):</span>
                <span class="s0"># Less terms to sum if we calculate log(1-cdf)</span>
                <span class="s1">res.append(log1p(-exp(self.logcdf(quant</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw))))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># Integration over probability mass function using logsumexp</span>
                <span class="s1">k2 = np.arange(quant + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">draw + </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">res.append(logsumexp(self._logpmf(k2</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw)))</span>
        <span class="s2">return </span><span class="s1">np.asarray(res)</span>

    <span class="s2">def </span><span class="s1">_logcdf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">res = []</span>
        <span class="s2">for </span><span class="s1">quant</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw </span><span class="s2">in </span><span class="s1">zip(*np.broadcast_arrays(k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N)):</span>
            <span class="s2">if </span><span class="s1">(quant + </span><span class="s5">0.5</span><span class="s1">) * (tot + </span><span class="s5">0.5</span><span class="s1">) &gt; (good - </span><span class="s5">0.5</span><span class="s1">) * (draw - </span><span class="s5">0.5</span><span class="s1">):</span>
                <span class="s0"># Less terms to sum if we calculate log(1-sf)</span>
                <span class="s1">res.append(log1p(-exp(self.logsf(quant</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw))))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0"># Integration over probability mass function using logsumexp</span>
                <span class="s1">k2 = np.arange(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">quant + </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">res.append(logsumexp(self._logpmf(k2</span><span class="s2">, </span><span class="s1">tot</span><span class="s2">, </span><span class="s1">good</span><span class="s2">, </span><span class="s1">draw)))</span>
        <span class="s2">return </span><span class="s1">np.asarray(res)</span>


<span class="s1">hypergeom = hypergeom_gen(name=</span><span class="s4">'hypergeom'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">nhypergeom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A negative hypergeometric discrete random variable. 
 
    Consider a box containing :math:`M` balls:, :math:`n` red and 
    :math:`M-n` blue. We randomly sample balls from the box, one 
    at a time and *without* replacement, until we have picked :math:`r` 
    blue balls. `nhypergeom` is the distribution of the number of 
    red balls :math:`k` we have picked. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The symbols used to denote the shape parameters (`M`, `n`, and `r`) are not 
    universally accepted. See the Examples for a clarification of the 
    definitions used here. 
 
    The probability mass function is defined as, 
 
    .. math:: f(k; M, n, r) = \frac{{{k+r-1}\choose{k}}{{M-r-k}\choose{n-k}}} 
                                   {{M \choose n}} 
 
    for :math:`k \in [0, n]`, :math:`n \in [0, M]`, :math:`r \in [0, M-n]`, 
    and the binomial coefficient is: 
 
    .. math:: \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}. 
 
    It is equivalent to observing :math:`k` successes in :math:`k+r-1` 
    samples with :math:`k+r`'th sample being a failure. The former 
    can be modelled as a hypergeometric distribution. The probability 
    of the latter is simply the number of failures remaining 
    :math:`M-n-(r-1)` divided by the size of the remaining population 
    :math:`M-(k+r-1)`. This relationship can be shown as: 
 
    .. math:: NHG(k;M,n,r) = HG(k;M,n,k+r-1)\frac{(M-n-(r-1))}{(M-(k+r-1))} 
 
    where :math:`NHG` is probability mass function (PMF) of the 
    negative hypergeometric distribution and :math:`HG` is the 
    PMF of the hypergeometric distribution. 
 
    %(after_notes)s 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import nhypergeom 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
 
    Suppose we have a collection of 20 animals, of which 7 are dogs. 
    Then if we want to know the probability of finding a given number 
    of dogs (successes) in a sample with exactly 12 animals that 
    aren't dogs (failures), we can initialize a frozen distribution 
    and plot the probability mass function: 
 
    &gt;&gt;&gt; M, n, r = [20, 7, 12] 
    &gt;&gt;&gt; rv = nhypergeom(M, n, r) 
    &gt;&gt;&gt; x = np.arange(0, n+2) 
    &gt;&gt;&gt; pmf_dogs = rv.pmf(x) 
 
    &gt;&gt;&gt; fig = plt.figure() 
    &gt;&gt;&gt; ax = fig.add_subplot(111) 
    &gt;&gt;&gt; ax.plot(x, pmf_dogs, 'bo') 
    &gt;&gt;&gt; ax.vlines(x, 0, pmf_dogs, lw=2) 
    &gt;&gt;&gt; ax.set_xlabel('# of dogs in our group with given 12 failures') 
    &gt;&gt;&gt; ax.set_ylabel('nhypergeom PMF') 
    &gt;&gt;&gt; plt.show() 
 
    Instead of using a frozen distribution we can also use `nhypergeom` 
    methods directly.  To for example obtain the probability mass 
    function, use: 
 
    &gt;&gt;&gt; prb = nhypergeom.pmf(x, M, n, r) 
 
    And to generate random numbers: 
 
    &gt;&gt;&gt; R = nhypergeom.rvs(M, n, r, size=10) 
 
    To verify the relationship between `hypergeom` and `nhypergeom`, use: 
 
    &gt;&gt;&gt; from scipy.stats import hypergeom, nhypergeom 
    &gt;&gt;&gt; M, n, r = 45, 13, 8 
    &gt;&gt;&gt; k = 6 
    &gt;&gt;&gt; nhypergeom.pmf(k, M, n, r) 
    0.06180776620271643 
    &gt;&gt;&gt; hypergeom.pmf(k, M, n, k+r-1) * (M - n - (r-1)) / (M - (k+r-1)) 
    0.06180776620271644 
 
    See Also 
    -------- 
    hypergeom, binom, nbinom 
 
    References 
    ---------- 
    .. [1] Negative Hypergeometric Distribution on Wikipedia 
           https://en.wikipedia.org/wiki/Negative_hypergeometric_distribution 
 
    .. [2] Negative Hypergeometric Distribution from 
           http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Negativehypergeometric.pdf 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;M&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;r&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s2">return </span><span class="s5">0</span><span class="s2">, </span><span class="s1">n</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s1">cond = (n &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (n &lt;= M) &amp; (r &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (r &lt;= M-n)</span>
        <span class="s1">cond &amp;= _isintegral(M) &amp; _isintegral(n) &amp; _isintegral(r)</span>
        <span class="s2">return </span><span class="s1">cond</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s1">@_vectorize_rvs_over_shapes</span>
        <span class="s2">def </span><span class="s1">_rvs1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state):</span>
            <span class="s0"># invert cdf by calculating all values in support, scalar M, n, r</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = self.support(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r)</span>
            <span class="s1">ks = np.arange(a</span><span class="s2">, </span><span class="s1">b+</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">cdf = self.cdf(ks</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r)</span>
            <span class="s1">ppf = interp1d(cdf</span><span class="s2">, </span><span class="s1">ks</span><span class="s2">, </span><span class="s1">kind=</span><span class="s4">'next'</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s4">'extrapolate'</span><span class="s1">)</span>
            <span class="s1">rvs = ppf(random_state.uniform(size=size)).astype(int)</span>
            <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">rvs.item()</span>
            <span class="s2">return </span><span class="s1">rvs</span>

        <span class="s2">return </span><span class="s1">_rvs1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s1">cond = ((r == </span><span class="s5">0</span><span class="s1">) &amp; (k == </span><span class="s5">0</span><span class="s1">))</span>
        <span class="s1">result = _lazywhere(~cond</span><span class="s2">, </span><span class="s1">(k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r)</span><span class="s2">,</span>
                            <span class="s2">lambda </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r:</span>
                                <span class="s1">(-betaln(k+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">r) + betaln(k+r</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) -</span>
                                 <span class="s1">betaln(n-k+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">M-r-n+</span><span class="s5">1</span><span class="s1">) + betaln(M-r-k+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) +</span>
                                 <span class="s1">betaln(n+</span><span class="s5">1</span><span class="s2">, </span><span class="s1">M-n+</span><span class="s5">1</span><span class="s1">) - betaln(M+</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span><span class="s2">,</span>
                            <span class="s1">fillvalue=</span><span class="s5">0.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s0"># same as the following but numerically more precise</span>
        <span class="s0"># return comb(k+r-1, k) * comb(M-r-k, n-k) / comb(M, n)</span>
        <span class="s2">return </span><span class="s1">exp(self._logpmf(k</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r):</span>
        <span class="s0"># Promote the datatype to at least float</span>
        <span class="s0"># mu = rn / (M-n+1)</span>
        <span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r = </span><span class="s5">1.</span><span class="s1">*M</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">*n</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">*r</span>
        <span class="s1">mu = r*n / (M-n+</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s1">var = r*(M+</span><span class="s5">1</span><span class="s1">)*n / ((M-n+</span><span class="s5">1</span><span class="s1">)*(M-n+</span><span class="s5">2</span><span class="s1">)) * (</span><span class="s5">1 </span><span class="s1">- r / (M-n+</span><span class="s5">1</span><span class="s1">))</span>

        <span class="s0"># The skew and kurtosis are mathematically</span>
        <span class="s0"># intractable so return `None`. See [2]_.</span>
        <span class="s1">g1</span><span class="s2">, </span><span class="s1">g2 = </span><span class="s2">None, None</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">nhypergeom = nhypergeom_gen(name=</span><span class="s4">'nhypergeom'</span><span class="s1">)</span>


<span class="s0"># FIXME: Fails _cdfvec</span>
<span class="s2">class </span><span class="s1">logser_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Logarithmic (Log-Series, Series) discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `logser` is: 
 
    .. math:: 
 
        f(k) = - \frac{p^k}{k \log(1-p)} 
 
    for :math:`k \ge 1`, :math:`0 &lt; p &lt; 1` 
 
    `logser` takes :math:`p` as shape parameter, 
    where :math:`p` is the probability of a single success 
    and :math:`1-p` is the probability of a single failure. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;p&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, True</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># looks wrong for p&gt;0.5, too few k=1</span>
        <span class="s0"># trying to use generic is worse, no k=1 at all</span>
        <span class="s2">return </span><span class="s1">random_state.logseries(p</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s2">return </span><span class="s1">(p &gt; </span><span class="s5">0</span><span class="s1">) &amp; (p &lt; </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s0"># logser.pmf(k) = - p**k / (k*log(1-p))</span>
        <span class="s2">return </span><span class="s1">-np.power(p</span><span class="s2">, </span><span class="s1">k) * </span><span class="s5">1.0 </span><span class="s1">/ k / special.log1p(-p)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">p):</span>
        <span class="s1">r = special.log1p(-p)</span>
        <span class="s1">mu = p / (p - </span><span class="s5">1.0</span><span class="s1">) / r</span>
        <span class="s1">mu2p = -p / r / (p - </span><span class="s5">1.0</span><span class="s1">)**</span><span class="s5">2</span>
        <span class="s1">var = mu2p - mu*mu</span>
        <span class="s1">mu3p = -p / r * (</span><span class="s5">1.0</span><span class="s1">+p) / (</span><span class="s5">1.0 </span><span class="s1">- p)**</span><span class="s5">3</span>
        <span class="s1">mu3 = mu3p - </span><span class="s5">3</span><span class="s1">*mu*mu2p + </span><span class="s5">2</span><span class="s1">*mu**</span><span class="s5">3</span>
        <span class="s1">g1 = mu3 / np.power(var</span><span class="s2">, </span><span class="s5">1.5</span><span class="s1">)</span>

        <span class="s1">mu4p = -p / r * (</span>
            <span class="s5">1.0 </span><span class="s1">/ (p-</span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">6</span><span class="s1">*p / (p - </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">3 </span><span class="s1">+ </span><span class="s5">6</span><span class="s1">*p*p / (p-</span><span class="s5">1</span><span class="s1">)**</span><span class="s5">4</span><span class="s1">)</span>
        <span class="s1">mu4 = mu4p - </span><span class="s5">4</span><span class="s1">*mu3p*mu + </span><span class="s5">6</span><span class="s1">*mu2p*mu*mu - </span><span class="s5">3</span><span class="s1">*mu**</span><span class="s5">4</span>
        <span class="s1">g2 = mu4 / var**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">3.0</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">logser = logser_gen(a=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'logser'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A logarithmic'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">poisson_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Poisson discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `poisson` is: 
 
    .. math:: 
 
        f(k) = \exp(-\mu) \frac{\mu^k}{k!} 
 
    for :math:`k \ge 0`. 
 
    `poisson` takes :math:`\mu \geq 0` as shape parameter. 
    When :math:`\mu = 0`, the ``pmf`` method 
    returns ``1.0`` at quantile :math:`k = 0`. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;mu&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))]</span>

    <span class="s0"># Override rv_discrete._argcheck to allow mu=0.</span>
    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s2">return </span><span class="s1">mu &gt;= </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.poisson(mu</span><span class="s2">, </span><span class="s1">size)</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">Pk = special.xlogy(k</span><span class="s2">, </span><span class="s1">mu) - gamln(k + </span><span class="s5">1</span><span class="s1">) - mu</span>
        <span class="s2">return </span><span class="s1">Pk</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s0"># poisson.pmf(k) = exp(-mu) * mu**k / k!</span>
        <span class="s2">return </span><span class="s1">exp(self._logpmf(k</span><span class="s2">, </span><span class="s1">mu))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">special.pdtr(k</span><span class="s2">, </span><span class="s1">mu)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">special.pdtrc(k</span><span class="s2">, </span><span class="s1">mu)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">vals = ceil(special.pdtrik(q</span><span class="s2">, </span><span class="s1">mu))</span>
        <span class="s1">vals1 = np.maximum(vals - </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">temp = special.pdtr(vals1</span><span class="s2">, </span><span class="s1">mu)</span>
        <span class="s2">return </span><span class="s1">np.where(temp &gt;= q</span><span class="s2">, </span><span class="s1">vals1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">mu):</span>
        <span class="s1">var = mu</span>
        <span class="s1">tmp = np.asarray(mu)</span>
        <span class="s1">mu_nonzero = tmp &gt; </span><span class="s5">0</span>
        <span class="s1">g1 = _lazywhere(mu_nonzero</span><span class="s2">, </span><span class="s1">(tmp</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, lambda </span><span class="s1">x: sqrt(</span><span class="s5">1.0</span><span class="s1">/x)</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">g2 = _lazywhere(mu_nonzero</span><span class="s2">, </span><span class="s1">(tmp</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, lambda </span><span class="s1">x: </span><span class="s5">1.0</span><span class="s1">/x</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">poisson = poisson_gen(name=</span><span class="s4">&quot;poisson&quot;</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A Poisson'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">planck_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Planck discrete exponential random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `planck` is: 
 
    .. math:: 
 
        f(k) = (1-\exp(-\lambda)) \exp(-\lambda k) 
 
    for :math:`k \ge 0` and :math:`\lambda &gt; 0`. 
 
    `planck` takes :math:`\lambda` as shape parameter. The Planck distribution 
    can be written as a geometric distribution (`geom`) with 
    :math:`p = 1 - \exp(-\lambda)` shifted by ``loc = -1``. 
 
    %(after_notes)s 
 
    See Also 
    -------- 
    geom 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;lambda&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s2">return </span><span class="s1">lambda_ &gt; </span><span class="s5">0</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s2">return </span><span class="s1">-expm1(-lambda_)*exp(-lambda_*k)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">-expm1(-lambda_*(k+</span><span class="s5">1</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s2">return </span><span class="s1">exp(self._logsf(x</span><span class="s2">, </span><span class="s1">lambda_))</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">-lambda_*(k+</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s1">vals = ceil(-</span><span class="s5">1.0</span><span class="s1">/lambda_ * log1p(-q)-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">vals1 = (vals-</span><span class="s5">1</span><span class="s1">).clip(*(self._get_support(lambda_)))</span>
        <span class="s1">temp = self._cdf(vals1</span><span class="s2">, </span><span class="s1">lambda_)</span>
        <span class="s2">return </span><span class="s1">np.where(temp &gt;= q</span><span class="s2">, </span><span class="s1">vals1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># use relation to geometric distribution for sampling</span>
        <span class="s1">p = -expm1(-lambda_)</span>
        <span class="s2">return </span><span class="s1">random_state.geometric(p</span><span class="s2">, </span><span class="s1">size=size) - </span><span class="s5">1.0</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s1">mu = </span><span class="s5">1</span><span class="s1">/expm1(lambda_)</span>
        <span class="s1">var = exp(-lambda_)/(expm1(-lambda_))**</span><span class="s5">2</span>
        <span class="s1">g1 = </span><span class="s5">2</span><span class="s1">*cosh(lambda_/</span><span class="s5">2.0</span><span class="s1">)</span>
        <span class="s1">g2 = </span><span class="s5">4</span><span class="s1">+</span><span class="s5">2</span><span class="s1">*cosh(lambda_)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">lambda_):</span>
        <span class="s1">C = -expm1(-lambda_)</span>
        <span class="s2">return </span><span class="s1">lambda_*exp(-lambda_)/C - log(C)</span>


<span class="s1">planck = planck_gen(a=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'planck'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A discrete exponential '</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">boltzmann_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Boltzmann (Truncated Discrete Exponential) random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `boltzmann` is: 
 
    .. math:: 
 
        f(k) = (1-\exp(-\lambda)) \exp(-\lambda k) / (1-\exp(-\lambda N)) 
 
    for :math:`k = 0,..., N-1`. 
 
    `boltzmann` takes :math:`\lambda &gt; 0` and :math:`N &gt; 0` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;lambda_&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;N&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">(lambda_ &gt; </span><span class="s5">0</span><span class="s1">) &amp; (N &gt; </span><span class="s5">0</span><span class="s1">) &amp; _isintegral(N)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s2">return </span><span class="s1">self.a</span><span class="s2">, </span><span class="s1">N - </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s0"># boltzmann.pmf(k) =</span>
        <span class="s0">#               (1-exp(-lambda_)*exp(-lambda_*k)/(1-exp(-lambda_*N))</span>
        <span class="s1">fact = (</span><span class="s5">1</span><span class="s1">-exp(-lambda_))/(</span><span class="s5">1</span><span class="s1">-exp(-lambda_*N))</span>
        <span class="s2">return </span><span class="s1">fact*exp(-lambda_*k)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">(</span><span class="s5">1</span><span class="s1">-exp(-lambda_*(k+</span><span class="s5">1</span><span class="s1">)))/(</span><span class="s5">1</span><span class="s1">-exp(-lambda_*N))</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">qnew = q*(</span><span class="s5">1</span><span class="s1">-exp(-lambda_*N))</span>
        <span class="s1">vals = ceil(-</span><span class="s5">1.0</span><span class="s1">/lambda_ * log(</span><span class="s5">1</span><span class="s1">-qnew)-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">vals1 = (vals-</span><span class="s5">1</span><span class="s1">).clip(</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">np.inf)</span>
        <span class="s1">temp = self._cdf(vals1</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N)</span>
        <span class="s2">return </span><span class="s1">np.where(temp &gt;= q</span><span class="s2">, </span><span class="s1">vals1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">lambda_</span><span class="s2">, </span><span class="s1">N):</span>
        <span class="s1">z = exp(-lambda_)</span>
        <span class="s1">zN = exp(-lambda_*N)</span>
        <span class="s1">mu = z/(</span><span class="s5">1.0</span><span class="s1">-z)-N*zN/(</span><span class="s5">1</span><span class="s1">-zN)</span>
        <span class="s1">var = z/(</span><span class="s5">1.0</span><span class="s1">-z)**</span><span class="s5">2 </span><span class="s1">- N*N*zN/(</span><span class="s5">1</span><span class="s1">-zN)**</span><span class="s5">2</span>
        <span class="s1">trm = (</span><span class="s5">1</span><span class="s1">-zN)/(</span><span class="s5">1</span><span class="s1">-z)</span>
        <span class="s1">trm2 = (z*trm**</span><span class="s5">2 </span><span class="s1">- N*N*zN)</span>
        <span class="s1">g1 = z*(</span><span class="s5">1</span><span class="s1">+z)*trm**</span><span class="s5">3 </span><span class="s1">- N**</span><span class="s5">3</span><span class="s1">*zN*(</span><span class="s5">1</span><span class="s1">+zN)</span>
        <span class="s1">g1 = g1 / trm2**(</span><span class="s5">1.5</span><span class="s1">)</span>
        <span class="s1">g2 = z*(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">4</span><span class="s1">*z+z*z)*trm**</span><span class="s5">4 </span><span class="s1">- N**</span><span class="s5">4 </span><span class="s1">* zN*(</span><span class="s5">1</span><span class="s1">+</span><span class="s5">4</span><span class="s1">*zN+zN*zN)</span>
        <span class="s1">g2 = g2 / trm2 / trm2</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">boltzmann = boltzmann_gen(name=</span><span class="s4">'boltzmann'</span><span class="s2">, </span><span class="s1">a=</span><span class="s5">0</span><span class="s2">,</span>
                          <span class="s1">longname=</span><span class="s4">'A truncated discrete exponential '</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">randint_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A uniform discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `randint` is: 
 
    .. math:: 
 
        f(k) = \frac{1}{\texttt{high} - \texttt{low}} 
 
    for :math:`k \in \{\texttt{low}, \dots, \texttt{high} - 1\}`. 
 
    `randint` takes :math:`\texttt{low}` and :math:`\texttt{high}` as shape 
    parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;low&quot;</span><span class="s2">, True, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;high&quot;</span><span class="s2">, True, </span><span class="s1">(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s2">return </span><span class="s1">(high &gt; low) &amp; _isintegral(low) &amp; _isintegral(high)</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s2">return </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high-</span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s0"># randint.pmf(k) = 1./(high - low)</span>
        <span class="s1">p = np.ones_like(k) / (high - low)</span>
        <span class="s2">return </span><span class="s1">np.where((k &gt;= low) &amp; (k &lt; high)</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s5">0.</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s1">k = floor(x)</span>
        <span class="s2">return </span><span class="s1">(k - low + </span><span class="s5">1.</span><span class="s1">) / (high - low)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s1">vals = ceil(q * (high - low) + low) - </span><span class="s5">1</span>
        <span class="s1">vals1 = (vals - </span><span class="s5">1</span><span class="s1">).clip(low</span><span class="s2">, </span><span class="s1">high)</span>
        <span class="s1">temp = self._cdf(vals1</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high)</span>
        <span class="s2">return </span><span class="s1">np.where(temp &gt;= q</span><span class="s2">, </span><span class="s1">vals1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s1">m2</span><span class="s2">, </span><span class="s1">m1 = np.asarray(high)</span><span class="s2">, </span><span class="s1">np.asarray(low)</span>
        <span class="s1">mu = (m2 + m1 - </span><span class="s5">1.0</span><span class="s1">) / </span><span class="s5">2</span>
        <span class="s1">d = m2 - m1</span>
        <span class="s1">var = (d*d - </span><span class="s5">1</span><span class="s1">) / </span><span class="s5">12.0</span>
        <span class="s1">g1 = </span><span class="s5">0.0</span>
        <span class="s1">g2 = -</span><span class="s5">6.0</span><span class="s1">/</span><span class="s5">5.0 </span><span class="s1">* (d*d + </span><span class="s5">1.0</span><span class="s1">) / (d*d - </span><span class="s5">1.0</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot;An array of *size* random integers &gt;= ``low`` and &lt; ``high``.&quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">np.asarray(low).size == </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">np.asarray(high).size == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s0"># no need to vectorize in that case</span>
            <span class="s2">return </span><span class="s1">rng_integers(random_state</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high</span><span class="s2">, </span><span class="s1">size=size)</span>

        <span class="s2">if </span><span class="s1">size </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s0"># NumPy's RandomState.randint() doesn't broadcast its arguments.</span>
            <span class="s0"># Use `broadcast_to()` to extend the shapes of low and high</span>
            <span class="s0"># up to size.  Then we can use the numpy.vectorize'd</span>
            <span class="s0"># randint without needing to pass it a `size` argument.</span>
            <span class="s1">low = np.broadcast_to(low</span><span class="s2">, </span><span class="s1">size)</span>
            <span class="s1">high = np.broadcast_to(high</span><span class="s2">, </span><span class="s1">size)</span>
        <span class="s1">randint = np.vectorize(partial(rng_integers</span><span class="s2">, </span><span class="s1">random_state)</span><span class="s2">,</span>
                               <span class="s1">otypes=[np.int_])</span>
        <span class="s2">return </span><span class="s1">randint(low</span><span class="s2">, </span><span class="s1">high)</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">high):</span>
        <span class="s2">return </span><span class="s1">log(high - low)</span>


<span class="s1">randint = randint_gen(name=</span><span class="s4">'randint'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A discrete uniform '</span>
                      <span class="s4">'(random integer)'</span><span class="s1">)</span>


<span class="s0"># FIXME: problems sampling.</span>
<span class="s2">class </span><span class="s1">zipf_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Zipf (Zeta) discrete random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    zipfian 
 
    Notes 
    ----- 
    The probability mass function for `zipf` is: 
 
    .. math:: 
 
        f(k, a) = \frac{1}{\zeta(a) k^a} 
 
    for :math:`k \ge 1`, :math:`a &gt; 1`. 
 
    `zipf` takes :math:`a &gt; 1` as shape parameter. :math:`\zeta` is the 
    Riemann zeta function (`scipy.special.zeta`) 
 
    The Zipf distribution is also known as the zeta distribution, which is 
    a special case of the Zipfian distribution (`zipfian`). 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Zeta Distribution&quot;, Wikipedia, 
           https://en.wikipedia.org/wiki/Zeta_distribution 
 
    %(example)s 
 
    Confirm that `zipf` is the large `n` limit of `zipfian`. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import zipfian 
    &gt;&gt;&gt; k = np.arange(11) 
    &gt;&gt;&gt; np.allclose(zipf.pmf(k, a), zipfian.pmf(k, a, n=10000000)) 
    True 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">random_state.zipf(a</span><span class="s2">, </span><span class="s1">size=size)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">a &gt; </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># zipf.pmf(k, a) = 1/(zeta(a) * k**a)</span>
        <span class="s1">Pk = </span><span class="s5">1.0 </span><span class="s1">/ special.zeta(a</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) / k**a</span>
        <span class="s2">return </span><span class="s1">Pk</span>

    <span class="s2">def </span><span class="s1">_munp(self</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">_lazywhere(</span>
            <span class="s1">a &gt; n + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">(a</span><span class="s2">, </span><span class="s1">n)</span><span class="s2">,</span>
            <span class="s2">lambda </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n: special.zeta(a - n</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) / special.zeta(a</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">np.inf)</span>


<span class="s1">zipf = zipf_gen(a=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'zipf'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A Zipf'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_gen_harmonic_gt1(n</span><span class="s2">, </span><span class="s1">a):</span>
    <span class="s3">&quot;&quot;&quot;Generalized harmonic number, a &gt; 1&quot;&quot;&quot;</span>
    <span class="s0"># See https://en.wikipedia.org/wiki/Harmonic_number; search for &quot;hurwitz&quot;</span>
    <span class="s2">return </span><span class="s1">zeta(a</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) - zeta(a</span><span class="s2">, </span><span class="s1">n+</span><span class="s5">1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_gen_harmonic_leq1(n</span><span class="s2">, </span><span class="s1">a):</span>
    <span class="s3">&quot;&quot;&quot;Generalized harmonic number, a &lt;= 1&quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">np.size(n):</span>
        <span class="s2">return </span><span class="s1">n</span>
    <span class="s1">n_max = np.max(n)  </span><span class="s0"># loop starts at maximum of all n</span>
    <span class="s1">out = np.zeros_like(a</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s0"># add terms of harmonic series; starting from smallest to avoid roundoff</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">np.arange(n_max</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dtype=float):</span>
        <span class="s1">mask = i &lt;= n  </span><span class="s0"># don't add terms after nth</span>
        <span class="s1">out[mask] += </span><span class="s5">1</span><span class="s1">/i**a[mask]</span>
    <span class="s2">return </span><span class="s1">out</span>


<span class="s2">def </span><span class="s1">_gen_harmonic(n</span><span class="s2">, </span><span class="s1">a):</span>
    <span class="s3">&quot;&quot;&quot;Generalized harmonic number&quot;&quot;&quot;</span>
    <span class="s1">n</span><span class="s2">, </span><span class="s1">a = np.broadcast_arrays(n</span><span class="s2">, </span><span class="s1">a)</span>
    <span class="s2">return </span><span class="s1">_lazywhere(a &gt; </span><span class="s5">1</span><span class="s2">, </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">a)</span><span class="s2">,</span>
                      <span class="s1">f=_gen_harmonic_gt1</span><span class="s2">, </span><span class="s1">f2=_gen_harmonic_leq1)</span>


<span class="s2">class </span><span class="s1">zipfian_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Zipfian discrete random variable. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    zipf 
 
    Notes 
    ----- 
    The probability mass function for `zipfian` is: 
 
    .. math:: 
 
        f(k, a, n) = \frac{1}{H_{n,a} k^a} 
 
    for :math:`k \in \{1, 2, \dots, n-1, n\}`, :math:`a \ge 0`, 
    :math:`n \in \{1, 2, 3, \dots\}`. 
 
    `zipfian` takes :math:`a` and :math:`n` as shape parameters. 
    :math:`H_{n,a}` is the :math:`n`:sup:`th` generalized harmonic 
    number of order :math:`a`. 
 
    The Zipfian distribution reduces to the Zipf (zeta) distribution as 
    :math:`n \rightarrow \infty`. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] &quot;Zipf's Law&quot;, Wikipedia, https://en.wikipedia.org/wiki/Zipf's_law 
    .. [2] Larry Leemis, &quot;Zipf Distribution&quot;, Univariate Distribution 
           Relationships. http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Zipf.pdf 
 
    %(example)s 
 
    Confirm that `zipfian` reduces to `zipf` for large `n`, `a &gt; 1`. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import zipf 
    &gt;&gt;&gt; k = np.arange(11) 
    &gt;&gt;&gt; np.allclose(zipfian.pmf(k, a=3.5, n=10000000), zipf.pmf(k, a=3.5)) 
    True 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s0"># we need np.asarray here because moment (maybe others) don't convert</span>
        <span class="s2">return </span><span class="s1">(a &gt;= </span><span class="s5">0</span><span class="s1">) &amp; (n &gt; </span><span class="s5">0</span><span class="s1">) &amp; (n == np.asarray(n</span><span class="s2">, </span><span class="s1">dtype=int))</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s5">1</span><span class="s2">, </span><span class="s1">n</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">/ _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a) / k**a</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s2">return </span><span class="s1">_gen_harmonic(k</span><span class="s2">, </span><span class="s1">a) / _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s1">k = k + </span><span class="s5">1  </span><span class="s0"># # to match SciPy convention</span>
        <span class="s0"># see http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Zipf.pdf</span>
        <span class="s2">return </span><span class="s1">((k**a*(_gen_harmonic(n</span><span class="s2">, </span><span class="s1">a) - _gen_harmonic(k</span><span class="s2">, </span><span class="s1">a)) + </span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">/ (k**a*_gen_harmonic(n</span><span class="s2">, </span><span class="s1">a)))</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">n):</span>
        <span class="s0"># see # see http://www.math.wm.edu/~leemis/chart/UDR/PDFs/Zipf.pdf</span>
        <span class="s1">Hna = _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a)</span>
        <span class="s1">Hna1 = _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">Hna2 = _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a-</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">Hna3 = _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a-</span><span class="s5">3</span><span class="s1">)</span>
        <span class="s1">Hna4 = _gen_harmonic(n</span><span class="s2">, </span><span class="s1">a-</span><span class="s5">4</span><span class="s1">)</span>
        <span class="s1">mu1 = Hna1/Hna</span>
        <span class="s1">mu2n = (Hna2*Hna - Hna1**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">mu2d = Hna**</span><span class="s5">2</span>
        <span class="s1">mu2 = mu2n / mu2d</span>
        <span class="s1">g1 = (Hna3/Hna - </span><span class="s5">3</span><span class="s1">*Hna1*Hna2/Hna**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">2</span><span class="s1">*Hna1**</span><span class="s5">3</span><span class="s1">/Hna**</span><span class="s5">3</span><span class="s1">)/mu2**(</span><span class="s5">3</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">g2 = (Hna**</span><span class="s5">3</span><span class="s1">*Hna4 - </span><span class="s5">4</span><span class="s1">*Hna**</span><span class="s5">2</span><span class="s1">*Hna1*Hna3 + </span><span class="s5">6</span><span class="s1">*Hna*Hna1**</span><span class="s5">2</span><span class="s1">*Hna2</span>
              <span class="s1">- </span><span class="s5">3</span><span class="s1">*Hna1**</span><span class="s5">4</span><span class="s1">) / mu2n**</span><span class="s5">2</span>
        <span class="s1">g2 -= </span><span class="s5">3</span>
        <span class="s2">return </span><span class="s1">mu1</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">zipfian = zipfian_gen(a=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">'zipfian'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A Zipfian'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">dlaplace_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A  Laplacian discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    The probability mass function for `dlaplace` is: 
 
    .. math:: 
 
        f(k) = \tanh(a/2) \exp(-a |k|) 
 
    for integers :math:`k` and :math:`a &gt; 0`. 
 
    `dlaplace` takes :math:`a` as shape parameter. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;a&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">k</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s0"># dlaplace.pmf(k) = tanh(a/2) * exp(-a*abs(k))</span>
        <span class="s2">return </span><span class="s1">tanh(a/</span><span class="s5">2.0</span><span class="s1">) * exp(-a * abs(k))</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">k = floor(x)</span>

        <span class="s2">def </span><span class="s1">f(k</span><span class="s2">, </span><span class="s1">a):</span>
            <span class="s2">return </span><span class="s5">1.0 </span><span class="s1">- exp(-a * k) / (exp(a) + </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">f2(k</span><span class="s2">, </span><span class="s1">a):</span>
            <span class="s2">return </span><span class="s1">exp(a * (k + </span><span class="s5">1</span><span class="s1">)) / (exp(a) + </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">_lazywhere(k &gt;= </span><span class="s5">0</span><span class="s2">, </span><span class="s1">(k</span><span class="s2">, </span><span class="s1">a)</span><span class="s2">, </span><span class="s1">f=f</span><span class="s2">, </span><span class="s1">f2=f2)</span>

    <span class="s2">def </span><span class="s1">_ppf(self</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">const = </span><span class="s5">1 </span><span class="s1">+ exp(a)</span>
        <span class="s1">vals = ceil(np.where(q &lt; </span><span class="s5">1.0 </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">+ exp(-a))</span><span class="s2">,</span>
                             <span class="s1">log(q*const) / a - </span><span class="s5">1</span><span class="s2">,</span>
                             <span class="s1">-log((</span><span class="s5">1</span><span class="s1">-q) * const) / a))</span>
        <span class="s1">vals1 = vals - </span><span class="s5">1</span>
        <span class="s2">return </span><span class="s1">np.where(self._cdf(vals1</span><span class="s2">, </span><span class="s1">a) &gt;= q</span><span class="s2">, </span><span class="s1">vals1</span><span class="s2">, </span><span class="s1">vals)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s1">ea = exp(a)</span>
        <span class="s1">mu2 = </span><span class="s5">2.</span><span class="s1">*ea/(ea-</span><span class="s5">1.</span><span class="s1">)**</span><span class="s5">2</span>
        <span class="s1">mu4 = </span><span class="s5">2.</span><span class="s1">*ea*(ea**</span><span class="s5">2</span><span class="s1">+</span><span class="s5">10.</span><span class="s1">*ea+</span><span class="s5">1.</span><span class="s1">) / (ea-</span><span class="s5">1.</span><span class="s1">)**</span><span class="s5">4</span>
        <span class="s2">return </span><span class="s5">0.</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s5">0.</span><span class="s2">, </span><span class="s1">mu4/mu2**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">3.</span>

    <span class="s2">def </span><span class="s1">_entropy(self</span><span class="s2">, </span><span class="s1">a):</span>
        <span class="s2">return </span><span class="s1">a / sinh(a) - log(tanh(a/</span><span class="s5">2.0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># The discrete Laplace is equivalent to the two-sided geometric</span>
        <span class="s0"># distribution with PMF:</span>
        <span class="s0">#   f(k) = (1 - alpha)/(1 + alpha) * alpha^abs(k)</span>
        <span class="s0">#   Reference:</span>
        <span class="s0">#     https://www.sciencedirect.com/science/</span>
        <span class="s0">#     article/abs/pii/S0378375804003519</span>
        <span class="s0"># Furthermore, the two-sided geometric distribution is</span>
        <span class="s0"># equivalent to the difference between two iid geometric</span>
        <span class="s0"># distributions.</span>
        <span class="s0">#   Reference (page 179):</span>
        <span class="s0">#     https://pdfs.semanticscholar.org/61b3/</span>
        <span class="s0">#     b99f466815808fd0d03f5d2791eea8b541a1.pdf</span>
        <span class="s0"># Thus, we can leverage the following:</span>
        <span class="s0">#   1) alpha = e^-a</span>
        <span class="s0">#   2) probability_of_success = 1 - alpha (Bernoulli trial)</span>
        <span class="s1">probOfSuccess = -np.expm1(-np.asarray(a))</span>
        <span class="s1">x = random_state.geometric(probOfSuccess</span><span class="s2">, </span><span class="s1">size=size)</span>
        <span class="s1">y = random_state.geometric(probOfSuccess</span><span class="s2">, </span><span class="s1">size=size)</span>
        <span class="s2">return </span><span class="s1">x - y</span>


<span class="s1">dlaplace = dlaplace_gen(a=-np.inf</span><span class="s2">,</span>
                        <span class="s1">name=</span><span class="s4">'dlaplace'</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A discrete Laplacian'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">skellam_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A  Skellam discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
    Probability distribution of the difference of two correlated or 
    uncorrelated Poisson random variables. 
 
    Let :math:`k_1` and :math:`k_2` be two Poisson-distributed r.v. with 
    expected values :math:`\lambda_1` and :math:`\lambda_2`. Then, 
    :math:`k_1 - k_2` follows a Skellam distribution with parameters 
    :math:`\mu_1 = \lambda_1 - \rho \sqrt{\lambda_1 \lambda_2}` and 
    :math:`\mu_2 = \lambda_2 - \rho \sqrt{\lambda_1 \lambda_2}`, where 
    :math:`\rho` is the correlation coefficient between :math:`k_1` and 
    :math:`k_2`. If the two Poisson-distributed r.v. are independent then 
    :math:`\rho = 0`. 
 
    Parameters :math:`\mu_1` and :math:`\mu_2` must be strictly positive. 
 
    For details see: https://en.wikipedia.org/wiki/Skellam_distribution 
 
    `skellam` takes :math:`\mu_1` and :math:`\mu_2` as shape parameters. 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;mu1&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;mu2&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">mu1</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">n = size</span>
        <span class="s2">return </span><span class="s1">(random_state.poisson(mu1</span><span class="s2">, </span><span class="s1">n) -</span>
                <span class="s1">random_state.poisson(mu2</span><span class="s2">, </span><span class="s1">n))</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu1</span><span class="s2">, </span><span class="s1">mu2):</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s1">px = np.where(x &lt; </span><span class="s5">0</span><span class="s2">,</span>
                          <span class="s1">_boost._ncx2_pdf(</span><span class="s5">2</span><span class="s1">*mu2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">-x)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*mu1)*</span><span class="s5">2</span><span class="s2">,</span>
                          <span class="s1">_boost._ncx2_pdf(</span><span class="s5">2</span><span class="s1">*mu1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*(</span><span class="s5">1</span><span class="s1">+x)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*mu2)*</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s0"># ncx2.pdf() returns nan's for extremely low probabilities</span>
        <span class="s2">return </span><span class="s1">px</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">mu1</span><span class="s2">, </span><span class="s1">mu2):</span>
        <span class="s1">x = floor(x)</span>
        <span class="s2">with </span><span class="s1">np.errstate(over=</span><span class="s4">'ignore'</span><span class="s1">):  </span><span class="s0"># see gh-17432</span>
            <span class="s1">px = np.where(x &lt; </span><span class="s5">0</span><span class="s2">,</span>
                          <span class="s1">_boost._ncx2_cdf(</span><span class="s5">2</span><span class="s1">*mu2</span><span class="s2">, </span><span class="s1">-</span><span class="s5">2</span><span class="s1">*x</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*mu1)</span><span class="s2">,</span>
                          <span class="s5">1 </span><span class="s1">- _boost._ncx2_cdf(</span><span class="s5">2</span><span class="s1">*mu1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*(x+</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s5">2</span><span class="s1">*mu2))</span>
        <span class="s2">return </span><span class="s1">px</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">mu1</span><span class="s2">, </span><span class="s1">mu2):</span>
        <span class="s1">mean = mu1 - mu2</span>
        <span class="s1">var = mu1 + mu2</span>
        <span class="s1">g1 = mean / sqrt((var)**</span><span class="s5">3</span><span class="s1">)</span>
        <span class="s1">g2 = </span><span class="s5">1 </span><span class="s1">/ var</span>
        <span class="s2">return </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">var</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">skellam = skellam_gen(a=-np.inf</span><span class="s2">, </span><span class="s1">name=</span><span class="s4">&quot;skellam&quot;</span><span class="s2">, </span><span class="s1">longname=</span><span class="s4">'A Skellam'</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">yulesimon_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A Yule-Simon discrete random variable. 
 
    %(before_notes)s 
 
    Notes 
    ----- 
 
    The probability mass function for the `yulesimon` is: 
 
    .. math:: 
 
        f(k) =  \alpha B(k, \alpha+1) 
 
    for :math:`k=1,2,3,...`, where :math:`\alpha&gt;0`. 
    Here :math:`B` refers to the `scipy.special.beta` function. 
 
    The sampling of random variates is based on pg 553, Section 6.3 of [1]_. 
    Our notation maps to the referenced logic via :math:`\alpha=a-1`. 
 
    For details see the wikipedia entry [2]_. 
 
    References 
    ---------- 
    .. [1] Devroye, Luc. &quot;Non-uniform Random Variate Generation&quot;, 
         (1986) Springer, New York. 
 
    .. [2] https://en.wikipedia.org/wiki/Yule-Simon_distribution 
 
    %(after_notes)s 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;alpha&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">E1 = random_state.standard_exponential(size)</span>
        <span class="s1">E2 = random_state.standard_exponential(size)</span>
        <span class="s1">ans = ceil(-E1 / log1p(-exp(-E2 / alpha)))</span>
        <span class="s2">return </span><span class="s1">ans</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s1">alpha * special.beta(x</span><span class="s2">, </span><span class="s1">alpha + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s1">(alpha &gt; </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logpmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s1">log(alpha) + special.betaln(x</span><span class="s2">, </span><span class="s1">alpha + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cdf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">- x * special.beta(x</span><span class="s2">, </span><span class="s1">alpha + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_sf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s1">x * special.beta(x</span><span class="s2">, </span><span class="s1">alpha + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_logsf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s2">return </span><span class="s1">log(x) + special.betaln(x</span><span class="s2">, </span><span class="s1">alpha + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">alpha):</span>
        <span class="s1">mu = np.where(alpha &lt;= </span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">alpha / (alpha - </span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">mu2 = np.where(alpha &gt; </span><span class="s5">2</span><span class="s2">,</span>
                       <span class="s1">alpha**</span><span class="s5">2 </span><span class="s1">/ ((alpha - </span><span class="s5">2.0</span><span class="s1">) * (alpha - </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2</span><span class="s1">)</span><span class="s2">,</span>
                       <span class="s1">np.inf)</span>
        <span class="s1">mu2 = np.where(alpha &lt;= </span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">mu2)</span>
        <span class="s1">g1 = np.where(alpha &gt; </span><span class="s5">3</span><span class="s2">,</span>
                      <span class="s1">sqrt(alpha - </span><span class="s5">2</span><span class="s1">) * (alpha + </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2 </span><span class="s1">/ (alpha * (alpha - </span><span class="s5">3</span><span class="s1">))</span><span class="s2">,</span>
                      <span class="s1">np.inf)</span>
        <span class="s1">g1 = np.where(alpha &lt;= </span><span class="s5">2</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">g1)</span>
        <span class="s1">g2 = np.where(alpha &gt; </span><span class="s5">4</span><span class="s2">,</span>
                      <span class="s1">alpha + </span><span class="s5">3 </span><span class="s1">+ ((alpha**</span><span class="s5">3 </span><span class="s1">- </span><span class="s5">49 </span><span class="s1">* alpha - </span><span class="s5">22</span><span class="s1">) /</span>
                                   <span class="s1">(alpha * (alpha - </span><span class="s5">4</span><span class="s1">) * (alpha - </span><span class="s5">3</span><span class="s1">)))</span><span class="s2">,</span>
                      <span class="s1">np.inf)</span>
        <span class="s1">g2 = np.where(alpha &lt;= </span><span class="s5">2</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">g2)</span>
        <span class="s2">return </span><span class="s1">mu</span><span class="s2">, </span><span class="s1">mu2</span><span class="s2">, </span><span class="s1">g1</span><span class="s2">, </span><span class="s1">g2</span>


<span class="s1">yulesimon = yulesimon_gen(name=</span><span class="s4">'yulesimon'</span><span class="s2">, </span><span class="s1">a=</span><span class="s5">1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_vectorize_rvs_over_shapes(_rvs1):</span>
    <span class="s3">&quot;&quot;&quot;Decorator that vectorizes _rvs method to work on ndarray shapes&quot;&quot;&quot;</span>
    <span class="s0"># _rvs1 must be a _function_ that accepts _scalar_ args as positional</span>
    <span class="s0"># arguments, `size` and `random_state` as keyword arguments.</span>
    <span class="s0"># _rvs1 must return a random variate array with shape `size`. If `size` is</span>
    <span class="s0"># None, _rvs1 must return a scalar.</span>
    <span class="s0"># When applied to _rvs1, this decorator broadcasts ndarray args</span>
    <span class="s0"># and loops over them, calling _rvs1 for each set of scalar args.</span>
    <span class="s0"># For usage example, see _nchypergeom_gen</span>
    <span class="s2">def </span><span class="s1">_rvs(*args</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state):</span>
        <span class="s1">_rvs1_size</span><span class="s2">, </span><span class="s1">_rvs1_indices = _check_shape(args[</span><span class="s5">0</span><span class="s1">].shape</span><span class="s2">, </span><span class="s1">size)</span>

        <span class="s1">size = np.array(size)</span>
        <span class="s1">_rvs1_size = np.array(_rvs1_size)</span>
        <span class="s1">_rvs1_indices = np.array(_rvs1_indices)</span>

        <span class="s2">if </span><span class="s1">np.all(_rvs1_indices):  </span><span class="s0"># all args are scalars</span>
            <span class="s2">return </span><span class="s1">_rvs1(*args</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state)</span>

        <span class="s1">out = np.empty(size)</span>

        <span class="s0"># out.shape can mix dimensions associated with arg_shape and _rvs1_size</span>
        <span class="s0"># Sort them to arg_shape + _rvs1_size for easy indexing of dimensions</span>
        <span class="s0"># corresponding with the different sets of scalar args</span>
        <span class="s1">j0 = np.arange(out.ndim)</span>
        <span class="s1">j1 = np.hstack((j0[~_rvs1_indices]</span><span class="s2">, </span><span class="s1">j0[_rvs1_indices]))</span>
        <span class="s1">out = np.moveaxis(out</span><span class="s2">, </span><span class="s1">j1</span><span class="s2">, </span><span class="s1">j0)</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">np.ndindex(*size[~_rvs1_indices]):</span>
            <span class="s0"># arg can be squeezed because singleton dimensions will be</span>
            <span class="s0"># associated with _rvs1_size, not arg_shape per _check_shape</span>
            <span class="s1">out[i] = _rvs1(*[np.squeeze(arg)[i] </span><span class="s2">for </span><span class="s1">arg </span><span class="s2">in </span><span class="s1">args]</span><span class="s2">,</span>
                           <span class="s1">_rvs1_size</span><span class="s2">, </span><span class="s1">random_state)</span>

        <span class="s2">return </span><span class="s1">np.moveaxis(out</span><span class="s2">, </span><span class="s1">j0</span><span class="s2">, </span><span class="s1">j1)  </span><span class="s0"># move axes back before returning</span>
    <span class="s2">return </span><span class="s1">_rvs</span>


<span class="s2">class </span><span class="s1">_nchypergeom_gen(rv_discrete):</span>
    <span class="s3">r&quot;&quot;&quot;A noncentral hypergeometric discrete random variable. 
 
    For subclassing by nchypergeom_fisher_gen and nchypergeom_wallenius_gen. 
 
    &quot;&quot;&quot;</span>

    <span class="s1">rvs_name = </span><span class="s2">None</span>
    <span class="s1">dist = </span><span class="s2">None</span>

    <span class="s2">def </span><span class="s1">_shape_info(self):</span>
        <span class="s2">return </span><span class="s1">[_ShapeInfo(</span><span class="s4">&quot;M&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;n&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;N&quot;</span><span class="s2">, True, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">True, False</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">_ShapeInfo(</span><span class="s4">&quot;odds&quot;</span><span class="s2">, False, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">, </span><span class="s1">(</span><span class="s2">False, False</span><span class="s1">))]</span>

    <span class="s2">def </span><span class="s1">_get_support(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds):</span>
        <span class="s1">N</span><span class="s2">, </span><span class="s1">m1</span><span class="s2">, </span><span class="s1">n = M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N  </span><span class="s0"># follow Wikipedia notation</span>
        <span class="s1">m2 = N - m1</span>
        <span class="s1">x_min = np.maximum(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n - m2)</span>
        <span class="s1">x_max = np.minimum(n</span><span class="s2">, </span><span class="s1">m1)</span>
        <span class="s2">return </span><span class="s1">x_min</span><span class="s2">, </span><span class="s1">x_max</span>

    <span class="s2">def </span><span class="s1">_argcheck(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds):</span>
        <span class="s1">M</span><span class="s2">, </span><span class="s1">n = np.asarray(M)</span><span class="s2">, </span><span class="s1">np.asarray(n)</span><span class="s2">,</span>
        <span class="s1">N</span><span class="s2">, </span><span class="s1">odds = np.asarray(N)</span><span class="s2">, </span><span class="s1">np.asarray(odds)</span>
        <span class="s1">cond1 = (M.astype(int) == M) &amp; (M &gt;= </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cond2 = (n.astype(int) == n) &amp; (n &gt;= </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cond3 = (N.astype(int) == N) &amp; (N &gt;= </span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">cond4 = odds &gt; </span><span class="s5">0</span>
        <span class="s1">cond5 = N &lt;= M</span>
        <span class="s1">cond6 = n &lt;= M</span>
        <span class="s2">return </span><span class="s1">cond1 &amp; cond2 &amp; cond3 &amp; cond4 &amp; cond5 &amp; cond6</span>

    <span class="s2">def </span><span class="s1">_rvs(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s1">size=</span><span class="s2">None, </span><span class="s1">random_state=</span><span class="s2">None</span><span class="s1">):</span>

        <span class="s1">@_vectorize_rvs_over_shapes</span>
        <span class="s2">def </span><span class="s1">_rvs1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">random_state):</span>
            <span class="s1">length = np.prod(size)</span>
            <span class="s1">urn = _PyStochasticLib3()</span>
            <span class="s1">rv_gen = getattr(urn</span><span class="s2">, </span><span class="s1">self.rvs_name)</span>
            <span class="s1">rvs = rv_gen(N</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s1">length</span><span class="s2">, </span><span class="s1">random_state)</span>
            <span class="s1">rvs = rvs.reshape(size)</span>
            <span class="s2">return </span><span class="s1">rvs</span>

        <span class="s2">return </span><span class="s1">_rvs1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">random_state=random_state)</span>

    <span class="s2">def </span><span class="s1">_pmf(self</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds):</span>

        <span class="s1">x</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds = np.broadcast_arrays(x</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds)</span>
        <span class="s2">if </span><span class="s1">x.size == </span><span class="s5">0</span><span class="s1">:  </span><span class="s0"># np.vectorize doesn't work with zero size input</span>
            <span class="s2">return </span><span class="s1">np.empty_like(x)</span>

        <span class="s1">@np.vectorize</span>
        <span class="s2">def </span><span class="s1">_pmf1(x</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds):</span>
            <span class="s1">urn = self.dist(N</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s5">1e-12</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">urn.probability(x)</span>

        <span class="s2">return </span><span class="s1">_pmf1(x</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds)</span>

    <span class="s2">def </span><span class="s1">_stats(self</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s1">moments):</span>

        <span class="s1">@np.vectorize</span>
        <span class="s2">def </span><span class="s1">_moments1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds):</span>
            <span class="s1">urn = self.dist(N</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">M</span><span class="s2">, </span><span class="s1">odds</span><span class="s2">, </span><span class="s5">1e-12</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">urn.moments()</span>

        <span class="s1">m</span><span class="s2">, </span><span class="s1">v = (_moments1(M</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">N</span><span class="s2">, </span><span class="s1">odds) </span><span class="s2">if </span><span class="s1">(</span><span class="s4">&quot;m&quot; </span><span class="s2">in </span><span class="s1">moments </span><span class="s2">or </span><span class="s4">&quot;v&quot; </span><span class="s2">in </span><span class="s1">moments)</span>
                <span class="s2">else </span><span class="s1">(</span><span class="s2">None, None</span><span class="s1">))</span>
        <span class="s1">s</span><span class="s2">, </span><span class="s1">k = </span><span class="s2">None, None</span>
        <span class="s2">return </span><span class="s1">m</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">k</span>


<span class="s2">class </span><span class="s1">nchypergeom_fisher_gen(_nchypergeom_gen):</span>
    <span class="s3">r&quot;&quot;&quot;A Fisher's noncentral hypergeometric discrete random variable. 
 
    Fisher's noncentral hypergeometric distribution models drawing objects of 
    two types from a bin. `M` is the total number of objects, `n` is the 
    number of Type I objects, and `odds` is the odds ratio: the odds of 
    selecting a Type I object rather than a Type II object when there is only 
    one object of each type. 
    The random variate represents the number of Type I objects drawn if we 
    take a handful of objects from the bin at once and find out afterwards 
    that we took `N` objects. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    nchypergeom_wallenius, hypergeom, nhypergeom 
 
    Notes 
    ----- 
    Let mathematical symbols :math:`N`, :math:`n`, and :math:`M` correspond 
    with parameters `N`, `n`, and `M` (respectively) as defined above. 
 
    The probability mass function is defined as 
 
    .. math:: 
 
        p(x; M, n, N, \omega) = 
        \frac{\binom{n}{x}\binom{M - n}{N-x}\omega^x}{P_0}, 
 
    for 
    :math:`x \in [x_l, x_u]`, 
    :math:`M \in {\mathbb N}`, 
    :math:`n \in [0, M]`, 
    :math:`N \in [0, M]`, 
    :math:`\omega &gt; 0`, 
    where 
    :math:`x_l = \max(0, N - (M - n))`, 
    :math:`x_u = \min(N, n)`, 
 
    .. math:: 
 
        P_0 = \sum_{y=x_l}^{x_u} \binom{n}{y}\binom{M - n}{N-y}\omega^y, 
 
    and the binomial coefficients are defined as 
 
    .. math:: \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}. 
 
    `nchypergeom_fisher` uses the BiasedUrn package by Agner Fog with 
    permission for it to be distributed under SciPy's license. 
 
    The symbols used to denote the shape parameters (`N`, `n`, and `M`) are not 
    universally accepted; they are chosen for consistency with `hypergeom`. 
 
    Note that Fisher's noncentral hypergeometric distribution is distinct 
    from Wallenius' noncentral hypergeometric distribution, which models 
    drawing a pre-determined `N` objects from a bin one by one. 
    When the odds ratio is unity, however, both distributions reduce to the 
    ordinary hypergeometric distribution. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Agner Fog, &quot;Biased Urn Theory&quot;. 
           https://cran.r-project.org/web/packages/BiasedUrn/vignettes/UrnTheory.pdf 
 
    .. [2] &quot;Fisher's noncentral hypergeometric distribution&quot;, Wikipedia, 
           https://en.wikipedia.org/wiki/Fisher's_noncentral_hypergeometric_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s1">rvs_name = </span><span class="s4">&quot;rvs_fisher&quot;</span>
    <span class="s1">dist = _PyFishersNCHypergeometric</span>


<span class="s1">nchypergeom_fisher = nchypergeom_fisher_gen(</span>
    <span class="s1">name=</span><span class="s4">'nchypergeom_fisher'</span><span class="s2">,</span>
    <span class="s1">longname=</span><span class="s4">&quot;A Fisher's noncentral hypergeometric&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">nchypergeom_wallenius_gen(_nchypergeom_gen):</span>
    <span class="s3">r&quot;&quot;&quot;A Wallenius' noncentral hypergeometric discrete random variable. 
 
    Wallenius' noncentral hypergeometric distribution models drawing objects of 
    two types from a bin. `M` is the total number of objects, `n` is the 
    number of Type I objects, and `odds` is the odds ratio: the odds of 
    selecting a Type I object rather than a Type II object when there is only 
    one object of each type. 
    The random variate represents the number of Type I objects drawn if we 
    draw a pre-determined `N` objects from a bin one by one. 
 
    %(before_notes)s 
 
    See Also 
    -------- 
    nchypergeom_fisher, hypergeom, nhypergeom 
 
    Notes 
    ----- 
    Let mathematical symbols :math:`N`, :math:`n`, and :math:`M` correspond 
    with parameters `N`, `n`, and `M` (respectively) as defined above. 
 
    The probability mass function is defined as 
 
    .. math:: 
 
        p(x; N, n, M) = \binom{n}{x} \binom{M - n}{N-x} 
        \int_0^1 \left(1-t^{\omega/D}\right)^x\left(1-t^{1/D}\right)^{N-x} dt 
 
    for 
    :math:`x \in [x_l, x_u]`, 
    :math:`M \in {\mathbb N}`, 
    :math:`n \in [0, M]`, 
    :math:`N \in [0, M]`, 
    :math:`\omega &gt; 0`, 
    where 
    :math:`x_l = \max(0, N - (M - n))`, 
    :math:`x_u = \min(N, n)`, 
 
    .. math:: 
 
        D = \omega(n - x) + ((M - n)-(N-x)), 
 
    and the binomial coefficients are defined as 
 
    .. math:: \binom{n}{k} \equiv \frac{n!}{k! (n - k)!}. 
 
    `nchypergeom_wallenius` uses the BiasedUrn package by Agner Fog with 
    permission for it to be distributed under SciPy's license. 
 
    The symbols used to denote the shape parameters (`N`, `n`, and `M`) are not 
    universally accepted; they are chosen for consistency with `hypergeom`. 
 
    Note that Wallenius' noncentral hypergeometric distribution is distinct 
    from Fisher's noncentral hypergeometric distribution, which models 
    take a handful of objects from the bin at once, finding out afterwards 
    that `N` objects were taken. 
    When the odds ratio is unity, however, both distributions reduce to the 
    ordinary hypergeometric distribution. 
 
    %(after_notes)s 
 
    References 
    ---------- 
    .. [1] Agner Fog, &quot;Biased Urn Theory&quot;. 
           https://cran.r-project.org/web/packages/BiasedUrn/vignettes/UrnTheory.pdf 
 
    .. [2] &quot;Wallenius' noncentral hypergeometric distribution&quot;, Wikipedia, 
           https://en.wikipedia.org/wiki/Wallenius'_noncentral_hypergeometric_distribution 
 
    %(example)s 
 
    &quot;&quot;&quot;</span>

    <span class="s1">rvs_name = </span><span class="s4">&quot;rvs_wallenius&quot;</span>
    <span class="s1">dist = _PyWalleniusNCHypergeometric</span>


<span class="s1">nchypergeom_wallenius = nchypergeom_wallenius_gen(</span>
    <span class="s1">name=</span><span class="s4">'nchypergeom_wallenius'</span><span class="s2">,</span>
    <span class="s1">longname=</span><span class="s4">&quot;A Wallenius' noncentral hypergeometric&quot;</span><span class="s1">)</span>


<span class="s0"># Collect names of classes and objects in this module.</span>
<span class="s1">pairs = list(globals().copy().items())</span>
<span class="s1">_distn_names</span><span class="s2">, </span><span class="s1">_distn_gen_names = get_distribution_names(pairs</span><span class="s2">, </span><span class="s1">rv_discrete)</span>

<span class="s1">__all__ = _distn_names + _distn_gen_names</span>
</pre>
</body>
</html>
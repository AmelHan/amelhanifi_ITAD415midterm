<html>
<head>
<title>_differentialevolution.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_differentialevolution.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
differential_evolution: The differential evolution global optimization algorithm 
Added by Andrew Nelson 2014 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">OptimizeResult</span><span class="s2">, </span><span class="s1">minimize</span>
<span class="s2">from </span><span class="s1">scipy.optimize._optimize </span><span class="s2">import </span><span class="s1">_status_message</span>
<span class="s2">from </span><span class="s1">scipy._lib._util </span><span class="s2">import </span><span class="s1">check_random_state</span><span class="s2">, </span><span class="s1">MapWrapper</span><span class="s2">, </span><span class="s1">_FunctionWrapper</span>

<span class="s2">from </span><span class="s1">scipy.optimize._constraints </span><span class="s2">import </span><span class="s1">(Bounds</span><span class="s2">, </span><span class="s1">new_bounds_to_old</span><span class="s2">,</span>
                                         <span class="s1">NonlinearConstraint</span><span class="s2">, </span><span class="s1">LinearConstraint)</span>
<span class="s2">from </span><span class="s1">scipy.sparse </span><span class="s2">import </span><span class="s1">issparse</span>

<span class="s1">__all__ = [</span><span class="s3">'differential_evolution'</span><span class="s1">]</span>


<span class="s1">_MACHEPS = np.finfo(np.float64).eps</span>


<span class="s2">def </span><span class="s1">differential_evolution(func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">strategy=</span><span class="s3">'best1bin'</span><span class="s2">,</span>
                           <span class="s1">maxiter=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">popsize=</span><span class="s4">15</span><span class="s2">, </span><span class="s1">tol=</span><span class="s4">0.01</span><span class="s2">,</span>
                           <span class="s1">mutation=(</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">recombination=</span><span class="s4">0.7</span><span class="s2">, </span><span class="s1">seed=</span><span class="s2">None,</span>
                           <span class="s1">callback=</span><span class="s2">None, </span><span class="s1">disp=</span><span class="s2">False, </span><span class="s1">polish=</span><span class="s2">True,</span>
                           <span class="s1">init=</span><span class="s3">'latinhypercube'</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">updating=</span><span class="s3">'immediate'</span><span class="s2">,</span>
                           <span class="s1">workers=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">constraints=()</span><span class="s2">, </span><span class="s1">x0=</span><span class="s2">None, </span><span class="s1">*</span><span class="s2">,</span>
                           <span class="s1">integrality=</span><span class="s2">None, </span><span class="s1">vectorized=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Finds the global minimum of a multivariate function. 
 
    The differential evolution method [1]_ is stochastic in nature. It does 
    not use gradient methods to find the minimum, and can search large areas 
    of candidate space, but often requires larger numbers of function 
    evaluations than conventional gradient-based techniques. 
 
    The algorithm is due to Storn and Price [2]_. 
 
    Parameters 
    ---------- 
    func : callable 
        The objective function to be minimized. Must be in the form 
        ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array 
        and ``args`` is a tuple of any additional fixed parameters needed to 
        completely specify the function. The number of parameters, N, is equal 
        to ``len(x)``. 
    bounds : sequence or `Bounds` 
        Bounds for variables. There are two ways to specify the bounds: 
 
            1. Instance of `Bounds` class. 
            2. ``(min, max)`` pairs for each element in ``x``, defining the 
               finite lower and upper bounds for the optimizing argument of 
               `func`. 
 
        The total number of bounds is used to determine the number of 
        parameters, N. If there are parameters whose bounds are equal the total 
        number of free parameters is ``N - N_equal``. 
 
    args : tuple, optional 
        Any additional fixed parameters needed to 
        completely specify the objective function. 
    strategy : str, optional 
        The differential evolution strategy to use. Should be one of: 
 
            - 'best1bin' 
            - 'best1exp' 
            - 'rand1exp' 
            - 'randtobest1exp' 
            - 'currenttobest1exp' 
            - 'best2exp' 
            - 'rand2exp' 
            - 'randtobest1bin' 
            - 'currenttobest1bin' 
            - 'best2bin' 
            - 'rand2bin' 
            - 'rand1bin' 
 
        The default is 'best1bin'. 
    maxiter : int, optional 
        The maximum number of generations over which the entire population is 
        evolved. The maximum number of function evaluations (with no polishing) 
        is: ``(maxiter + 1) * popsize * (N - N_equal)`` 
    popsize : int, optional 
        A multiplier for setting the total population size. The population has 
        ``popsize * (N - N_equal)`` individuals. This keyword is overridden if 
        an initial population is supplied via the `init` keyword. When using 
        ``init='sobol'`` the population size is calculated as the next power 
        of 2 after ``popsize * (N - N_equal)``. 
    tol : float, optional 
        Relative tolerance for convergence, the solving stops when 
        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``, 
        where and `atol` and `tol` are the absolute and relative tolerance 
        respectively. 
    mutation : float or tuple(float, float), optional 
        The mutation constant. In the literature this is also known as 
        differential weight, being denoted by F. 
        If specified as a float it should be in the range [0, 2]. 
        If specified as a tuple ``(min, max)`` dithering is employed. Dithering 
        randomly changes the mutation constant on a generation by generation 
        basis. The mutation constant for that generation is taken from 
        ``U[min, max)``. Dithering can help speed convergence significantly. 
        Increasing the mutation constant increases the search radius, but will 
        slow down convergence. 
    recombination : float, optional 
        The recombination constant, should be in the range [0, 1]. In the 
        literature this is also known as the crossover probability, being 
        denoted by CR. Increasing this value allows a larger number of mutants 
        to progress into the next generation, but at the risk of population 
        stability. 
    seed : {None, int, `numpy.random.Generator`, `numpy.random.RandomState`}, optional 
        If `seed` is None (or `np.random`), the `numpy.random.RandomState` 
        singleton is used. 
        If `seed` is an int, a new ``RandomState`` instance is used, 
        seeded with `seed`. 
        If `seed` is already a ``Generator`` or ``RandomState`` instance then 
        that instance is used. 
        Specify `seed` for repeatable minimizations. 
    disp : bool, optional 
        Prints the evaluated `func` at every iteration. 
    callback : callable, `callback(xk, convergence=val)`, optional 
        A function to follow the progress of the minimization. ``xk`` is 
        the best solution found so far. ``val`` represents the fractional 
        value of the population convergence.  When ``val`` is greater than one 
        the function halts. If callback returns `True`, then the minimization 
        is halted (any polishing is still carried out). 
    polish : bool, optional 
        If True (default), then `scipy.optimize.minimize` with the `L-BFGS-B` 
        method is used to polish the best population member at the end, which 
        can improve the minimization slightly. If a constrained problem is 
        being studied then the `trust-constr` method is used instead. For large 
        problems with many constraints, polishing can take a long time due to 
        the Jacobian computations. 
    init : str or array-like, optional 
        Specify which type of population initialization is performed. Should be 
        one of: 
 
            - 'latinhypercube' 
            - 'sobol' 
            - 'halton' 
            - 'random' 
            - array specifying the initial population. The array should have 
              shape ``(S, N)``, where S is the total population size and N is 
              the number of parameters. 
              `init` is clipped to `bounds` before use. 
 
        The default is 'latinhypercube'. Latin Hypercube sampling tries to 
        maximize coverage of the available parameter space. 
 
        'sobol' and 'halton' are superior alternatives and maximize even more 
        the parameter space. 'sobol' will enforce an initial population 
        size which is calculated as the next power of 2 after 
        ``popsize * (N - N_equal)``. 'halton' has no requirements but is a bit 
        less efficient. See `scipy.stats.qmc` for more details. 
 
        'random' initializes the population randomly - this has the drawback 
        that clustering can occur, preventing the whole of parameter space 
        being covered. Use of an array to specify a population could be used, 
        for example, to create a tight bunch of initial guesses in an location 
        where the solution is known to exist, thereby reducing time for 
        convergence. 
    atol : float, optional 
        Absolute tolerance for convergence, the solving stops when 
        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``, 
        where and `atol` and `tol` are the absolute and relative tolerance 
        respectively. 
    updating : {'immediate', 'deferred'}, optional 
        If ``'immediate'``, the best solution vector is continuously updated 
        within a single generation [4]_. This can lead to faster convergence as 
        trial vectors can take advantage of continuous improvements in the best 
        solution. 
        With ``'deferred'``, the best solution vector is updated once per 
        generation. Only ``'deferred'`` is compatible with parallelization or 
        vectorization, and the `workers` and `vectorized` keywords can 
        over-ride this option. 
 
        .. versionadded:: 1.2.0 
 
    workers : int or map-like callable, optional 
        If `workers` is an int the population is subdivided into `workers` 
        sections and evaluated in parallel 
        (uses `multiprocessing.Pool &lt;multiprocessing&gt;`). 
        Supply -1 to use all available CPU cores. 
        Alternatively supply a map-like callable, such as 
        `multiprocessing.Pool.map` for evaluating the population in parallel. 
        This evaluation is carried out as ``workers(func, iterable)``. 
        This option will override the `updating` keyword to 
        ``updating='deferred'`` if ``workers != 1``. 
        This option overrides the `vectorized` keyword if ``workers != 1``. 
        Requires that `func` be pickleable. 
 
        .. versionadded:: 1.2.0 
 
    constraints : {NonLinearConstraint, LinearConstraint, Bounds} 
        Constraints on the solver, over and above those applied by the `bounds` 
        kwd. Uses the approach by Lampinen [5]_. 
 
        .. versionadded:: 1.4.0 
 
    x0 : None or array-like, optional 
        Provides an initial guess to the minimization. Once the population has 
        been initialized this vector replaces the first (best) member. This 
        replacement is done even if `init` is given an initial population. 
        ``x0.shape == (N,)``. 
 
        .. versionadded:: 1.7.0 
 
    integrality : 1-D array, optional 
        For each decision variable, a boolean value indicating whether the 
        decision variable is constrained to integer values. The array is 
        broadcast to ``(N,)``. 
        If any decision variables are constrained to be integral, they will not 
        be changed during polishing. 
        Only integer values lying between the lower and upper bounds are used. 
        If there are no integer values lying between the bounds then a 
        `ValueError` is raised. 
 
        .. versionadded:: 1.9.0 
 
    vectorized : bool, optional 
        If ``vectorized is True``, `func` is sent an `x` array with 
        ``x.shape == (N, S)``, and is expected to return an array of shape 
        ``(S,)``, where `S` is the number of solution vectors to be calculated. 
        If constraints are applied, each of the functions used to construct 
        a `Constraint` object should accept an `x` array with 
        ``x.shape == (N, S)``, and return an array of shape ``(M, S)``, where 
        `M` is the number of constraint components. 
        This option is an alternative to the parallelization offered by 
        `workers`, and may help in optimization speed by reducing interpreter 
        overhead from multiple function calls. This keyword is ignored if 
        ``workers != 1``. 
        This option will override the `updating` keyword to 
        ``updating='deferred'``. 
        See the notes section for further discussion on when to use 
        ``'vectorized'``, and when to use ``'workers'``. 
 
        .. versionadded:: 1.9.0 
 
    Returns 
    ------- 
    res : OptimizeResult 
        The optimization result represented as a `OptimizeResult` object. 
        Important attributes are: ``x`` the solution array, ``success`` a 
        Boolean flag indicating if the optimizer exited successfully and 
        ``message`` which describes the cause of the termination. See 
        `OptimizeResult` for a description of other attributes. If `polish` 
        was employed, and a lower minimum was obtained by the polishing, then 
        OptimizeResult also contains the ``jac`` attribute. 
        If the eventual solution does not satisfy the applied constraints 
        ``success`` will be `False`. 
 
    Notes 
    ----- 
    Differential evolution is a stochastic population based method that is 
    useful for global optimization problems. At each pass through the 
    population the algorithm mutates each candidate solution by mixing with 
    other candidate solutions to create a trial candidate. There are several 
    strategies [3]_ for creating trial candidates, which suit some problems 
    more than others. The 'best1bin' strategy is a good starting point for 
    many systems. In this strategy two members of the population are randomly 
    chosen. Their difference is used to mutate the best member (the 'best' in 
    'best1bin'), :math:`b_0`, so far: 
 
    .. math:: 
 
        b' = b_0 + mutation * (population[rand0] - population[rand1]) 
 
    A trial vector is then constructed. Starting with a randomly chosen ith 
    parameter the trial is sequentially filled (in modulo) with parameters 
    from ``b'`` or the original candidate. The choice of whether to use ``b'`` 
    or the original candidate is made with a binomial distribution (the 'bin' 
    in 'best1bin') - a random number in [0, 1) is generated. If this number is 
    less than the `recombination` constant then the parameter is loaded from 
    ``b'``, otherwise it is loaded from the original candidate. The final 
    parameter is always loaded from ``b'``. Once the trial candidate is built 
    its fitness is assessed. If the trial is better than the original candidate 
    then it takes its place. If it is also better than the best overall 
    candidate it also replaces that. 
    To improve your chances of finding a global minimum use higher `popsize` 
    values, with higher `mutation` and (dithering), but lower `recombination` 
    values. This has the effect of widening the search radius, but slowing 
    convergence. 
    By default the best solution vector is updated continuously within a single 
    iteration (``updating='immediate'``). This is a modification [4]_ of the 
    original differential evolution algorithm which can lead to faster 
    convergence as trial vectors can immediately benefit from improved 
    solutions. To use the original Storn and Price behaviour, updating the best 
    solution once per iteration, set ``updating='deferred'``. 
    The ``'deferred'`` approach is compatible with both parallelization and 
    vectorization (``'workers'`` and ``'vectorized'`` keywords). These may 
    improve minimization speed by using computer resources more efficiently. 
    The ``'workers'`` distribute calculations over multiple processors. By 
    default the Python `multiprocessing` module is used, but other approaches 
    are also possible, such as the Message Passing Interface (MPI) used on 
    clusters [6]_ [7]_. The overhead from these approaches (creating new 
    Processes, etc) may be significant, meaning that computational speed 
    doesn't necessarily scale with the number of processors used. 
    Parallelization is best suited to computationally expensive objective 
    functions. If the objective function is less expensive, then 
    ``'vectorized'`` may aid by only calling the objective function once per 
    iteration, rather than multiple times for all the population members; the 
    interpreter overhead is reduced. 
 
    .. versionadded:: 0.15.0 
 
    References 
    ---------- 
    .. [1] Differential evolution, Wikipedia, 
           http://en.wikipedia.org/wiki/Differential_evolution 
    .. [2] Storn, R and Price, K, Differential Evolution - a Simple and 
           Efficient Heuristic for Global Optimization over Continuous Spaces, 
           Journal of Global Optimization, 1997, 11, 341 - 359. 
    .. [3] http://www1.icsi.berkeley.edu/~storn/code.html 
    .. [4] Wormington, M., Panaccione, C., Matney, K. M., Bowen, D. K., - 
           Characterization of structures from X-ray scattering data using 
           genetic algorithms, Phil. Trans. R. Soc. Lond. A, 1999, 357, 
           2827-2848 
    .. [5] Lampinen, J., A constraint handling approach for the differential 
           evolution algorithm. Proceedings of the 2002 Congress on 
           Evolutionary Computation. CEC'02 (Cat. No. 02TH8600). Vol. 2. IEEE, 
           2002. 
    .. [6] https://mpi4py.readthedocs.io/en/stable/ 
    .. [7] https://schwimmbad.readthedocs.io/en/latest/ 
 
    Examples 
    -------- 
    Let us consider the problem of minimizing the Rosenbrock function. This 
    function is implemented in `rosen` in `scipy.optimize`. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.optimize import rosen, differential_evolution 
    &gt;&gt;&gt; bounds = [(0,2), (0, 2), (0, 2), (0, 2), (0, 2)] 
    &gt;&gt;&gt; result = differential_evolution(rosen, bounds) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19) 
 
    Now repeat, but with parallelization. 
 
    &gt;&gt;&gt; result = differential_evolution(rosen, bounds, updating='deferred', 
    ...                                 workers=2) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([1., 1., 1., 1., 1.]), 1.9216496320061384e-19) 
 
    Let's do a constrained minimization. 
 
    &gt;&gt;&gt; from scipy.optimize import LinearConstraint, Bounds 
 
    We add the constraint that the sum of ``x[0]`` and ``x[1]`` must be less 
    than or equal to 1.9.  This is a linear constraint, which may be written 
    ``A @ x &lt;= 1.9``, where ``A = array([[1, 1]])``.  This can be encoded as 
    a `LinearConstraint` instance: 
 
    &gt;&gt;&gt; lc = LinearConstraint([[1, 1]], -np.inf, 1.9) 
 
    Specify limits using a `Bounds` object. 
 
    &gt;&gt;&gt; bounds = Bounds([0., 0.], [2., 2.]) 
    &gt;&gt;&gt; result = differential_evolution(rosen, bounds, constraints=lc, 
    ...                                 seed=1) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([0.96632622, 0.93367155]), 0.0011352416852625719) 
 
    Next find the minimum of the Ackley function 
    (https://en.wikipedia.org/wiki/Test_functions_for_optimization). 
 
    &gt;&gt;&gt; def ackley(x): 
    ...     arg1 = -0.2 * np.sqrt(0.5 * (x[0] ** 2 + x[1] ** 2)) 
    ...     arg2 = 0.5 * (np.cos(2. * np.pi * x[0]) + np.cos(2. * np.pi * x[1])) 
    ...     return -20. * np.exp(arg1) - np.exp(arg2) + 20. + np.e 
    &gt;&gt;&gt; bounds = [(-5, 5), (-5, 5)] 
    &gt;&gt;&gt; result = differential_evolution(ackley, bounds, seed=1) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([0., 0.]), 4.440892098500626e-16) 
 
    The Ackley function is written in a vectorized manner, so the 
    ``'vectorized'`` keyword can be employed. Note the reduced number of 
    function evaluations. 
 
    &gt;&gt;&gt; result = differential_evolution( 
    ...     ackley, bounds, vectorized=True, updating='deferred', seed=1 
    ... ) 
    &gt;&gt;&gt; result.x, result.fun 
    (array([0., 0.]), 4.440892098500626e-16) 
 
    &quot;&quot;&quot;</span>

    <span class="s5"># using a context manager means that any created Pool objects are</span>
    <span class="s5"># cleared up.</span>
    <span class="s2">with </span><span class="s1">DifferentialEvolutionSolver(func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=args</span><span class="s2">,</span>
                                     <span class="s1">strategy=strategy</span><span class="s2">,</span>
                                     <span class="s1">maxiter=maxiter</span><span class="s2">,</span>
                                     <span class="s1">popsize=popsize</span><span class="s2">, </span><span class="s1">tol=tol</span><span class="s2">,</span>
                                     <span class="s1">mutation=mutation</span><span class="s2">,</span>
                                     <span class="s1">recombination=recombination</span><span class="s2">,</span>
                                     <span class="s1">seed=seed</span><span class="s2">, </span><span class="s1">polish=polish</span><span class="s2">,</span>
                                     <span class="s1">callback=callback</span><span class="s2">,</span>
                                     <span class="s1">disp=disp</span><span class="s2">, </span><span class="s1">init=init</span><span class="s2">, </span><span class="s1">atol=atol</span><span class="s2">,</span>
                                     <span class="s1">updating=updating</span><span class="s2">,</span>
                                     <span class="s1">workers=workers</span><span class="s2">,</span>
                                     <span class="s1">constraints=constraints</span><span class="s2">,</span>
                                     <span class="s1">x0=x0</span><span class="s2">,</span>
                                     <span class="s1">integrality=integrality</span><span class="s2">,</span>
                                     <span class="s1">vectorized=vectorized) </span><span class="s2">as </span><span class="s1">solver:</span>
        <span class="s1">ret = solver.solve()</span>

    <span class="s2">return </span><span class="s1">ret</span>


<span class="s2">class </span><span class="s1">DifferentialEvolutionSolver:</span>

    <span class="s0">&quot;&quot;&quot;This class implements the differential evolution solver 
 
    Parameters 
    ---------- 
    func : callable 
        The objective function to be minimized. Must be in the form 
        ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array 
        and ``args`` is a tuple of any additional fixed parameters needed to 
        completely specify the function. The number of parameters, N, is equal 
        to ``len(x)``. 
    bounds : sequence or `Bounds` 
        Bounds for variables. There are two ways to specify the bounds: 
 
            1. Instance of `Bounds` class. 
            2. ``(min, max)`` pairs for each element in ``x``, defining the 
               finite lower and upper bounds for the optimizing argument of 
               `func`. 
 
        The total number of bounds is used to determine the number of 
        parameters, N. If there are parameters whose bounds are equal the total 
        number of free parameters is ``N - N_equal``. 
    args : tuple, optional 
        Any additional fixed parameters needed to 
        completely specify the objective function. 
    strategy : str, optional 
        The differential evolution strategy to use. Should be one of: 
 
            - 'best1bin' 
            - 'best1exp' 
            - 'rand1exp' 
            - 'randtobest1exp' 
            - 'currenttobest1exp' 
            - 'best2exp' 
            - 'rand2exp' 
            - 'randtobest1bin' 
            - 'currenttobest1bin' 
            - 'best2bin' 
            - 'rand2bin' 
            - 'rand1bin' 
 
        The default is 'best1bin' 
 
    maxiter : int, optional 
        The maximum number of generations over which the entire population is 
        evolved. The maximum number of function evaluations (with no polishing) 
        is: ``(maxiter + 1) * popsize * (N - N_equal)`` 
    popsize : int, optional 
        A multiplier for setting the total population size. The population has 
        ``popsize * (N - N_equal)`` individuals. This keyword is overridden if 
        an initial population is supplied via the `init` keyword. When using 
        ``init='sobol'`` the population size is calculated as the next power 
        of 2 after ``popsize * (N - N_equal)``. 
    tol : float, optional 
        Relative tolerance for convergence, the solving stops when 
        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``, 
        where and `atol` and `tol` are the absolute and relative tolerance 
        respectively. 
    mutation : float or tuple(float, float), optional 
        The mutation constant. In the literature this is also known as 
        differential weight, being denoted by F. 
        If specified as a float it should be in the range [0, 2]. 
        If specified as a tuple ``(min, max)`` dithering is employed. Dithering 
        randomly changes the mutation constant on a generation by generation 
        basis. The mutation constant for that generation is taken from 
        U[min, max). Dithering can help speed convergence significantly. 
        Increasing the mutation constant increases the search radius, but will 
        slow down convergence. 
    recombination : float, optional 
        The recombination constant, should be in the range [0, 1]. In the 
        literature this is also known as the crossover probability, being 
        denoted by CR. Increasing this value allows a larger number of mutants 
        to progress into the next generation, but at the risk of population 
        stability. 
    seed : {None, int, `numpy.random.Generator`, `numpy.random.RandomState`}, optional 
        If `seed` is None (or `np.random`), the `numpy.random.RandomState` 
        singleton is used. 
        If `seed` is an int, a new ``RandomState`` instance is used, 
        seeded with `seed`. 
        If `seed` is already a ``Generator`` or ``RandomState`` instance then 
        that instance is used. 
        Specify `seed` for repeatable minimizations. 
    disp : bool, optional 
        Prints the evaluated `func` at every iteration. 
    callback : callable, `callback(xk, convergence=val)`, optional 
        A function to follow the progress of the minimization. ``xk`` is 
        the current value of ``x0``. ``val`` represents the fractional 
        value of the population convergence. When ``val`` is greater than one 
        the function halts. If callback returns `True`, then the minimization 
        is halted (any polishing is still carried out). 
    polish : bool, optional 
        If True (default), then `scipy.optimize.minimize` with the `L-BFGS-B` 
        method is used to polish the best population member at the end, which 
        can improve the minimization slightly. If a constrained problem is 
        being studied then the `trust-constr` method is used instead. For large 
        problems with many constraints, polishing can take a long time due to 
        the Jacobian computations. 
    maxfun : int, optional 
        Set the maximum number of function evaluations. However, it probably 
        makes more sense to set `maxiter` instead. 
    init : str or array-like, optional 
        Specify which type of population initialization is performed. Should be 
        one of: 
 
            - 'latinhypercube' 
            - 'sobol' 
            - 'halton' 
            - 'random' 
            - array specifying the initial population. The array should have 
              shape ``(S, N)``, where S is the total population size and 
              N is the number of parameters. 
              `init` is clipped to `bounds` before use. 
 
        The default is 'latinhypercube'. Latin Hypercube sampling tries to 
        maximize coverage of the available parameter space. 
 
        'sobol' and 'halton' are superior alternatives and maximize even more 
        the parameter space. 'sobol' will enforce an initial population 
        size which is calculated as the next power of 2 after 
        ``popsize * (N - N_equal)``. 'halton' has no requirements but is a bit 
        less efficient. See `scipy.stats.qmc` for more details. 
 
        'random' initializes the population randomly - this has the drawback 
        that clustering can occur, preventing the whole of parameter space 
        being covered. Use of an array to specify a population could be used, 
        for example, to create a tight bunch of initial guesses in an location 
        where the solution is known to exist, thereby reducing time for 
        convergence. 
    atol : float, optional 
        Absolute tolerance for convergence, the solving stops when 
        ``np.std(pop) &lt;= atol + tol * np.abs(np.mean(population_energies))``, 
        where and `atol` and `tol` are the absolute and relative tolerance 
        respectively. 
    updating : {'immediate', 'deferred'}, optional 
        If ``'immediate'``, the best solution vector is continuously updated 
        within a single generation [4]_. This can lead to faster convergence as 
        trial vectors can take advantage of continuous improvements in the best 
        solution. 
        With ``'deferred'``, the best solution vector is updated once per 
        generation. Only ``'deferred'`` is compatible with parallelization or 
        vectorization, and the `workers` and `vectorized` keywords can 
        over-ride this option. 
    workers : int or map-like callable, optional 
        If `workers` is an int the population is subdivided into `workers` 
        sections and evaluated in parallel 
        (uses `multiprocessing.Pool &lt;multiprocessing&gt;`). 
        Supply `-1` to use all cores available to the Process. 
        Alternatively supply a map-like callable, such as 
        `multiprocessing.Pool.map` for evaluating the population in parallel. 
        This evaluation is carried out as ``workers(func, iterable)``. 
        This option will override the `updating` keyword to 
        `updating='deferred'` if `workers != 1`. 
        Requires that `func` be pickleable. 
    constraints : {NonLinearConstraint, LinearConstraint, Bounds} 
        Constraints on the solver, over and above those applied by the `bounds` 
        kwd. Uses the approach by Lampinen. 
    x0 : None or array-like, optional 
        Provides an initial guess to the minimization. Once the population has 
        been initialized this vector replaces the first (best) member. This 
        replacement is done even if `init` is given an initial population. 
        ``x0.shape == (N,)``. 
    integrality : 1-D array, optional 
        For each decision variable, a boolean value indicating whether the 
        decision variable is constrained to integer values. The array is 
        broadcast to ``(N,)``. 
        If any decision variables are constrained to be integral, they will not 
        be changed during polishing. 
        Only integer values lying between the lower and upper bounds are used. 
        If there are no integer values lying between the bounds then a 
        `ValueError` is raised. 
    vectorized : bool, optional 
        If ``vectorized is True``, `func` is sent an `x` array with 
        ``x.shape == (N, S)``, and is expected to return an array of shape 
        ``(S,)``, where `S` is the number of solution vectors to be calculated. 
        If constraints are applied, each of the functions used to construct 
        a `Constraint` object should accept an `x` array with 
        ``x.shape == (N, S)``, and return an array of shape ``(M, S)``, where 
        `M` is the number of constraint components. 
        This option is an alternative to the parallelization offered by 
        `workers`, and may help in optimization speed. This keyword is 
        ignored if ``workers != 1``. 
        This option will override the `updating` keyword to 
        ``updating='deferred'``. 
    &quot;&quot;&quot;</span>

    <span class="s5"># Dispatch of mutation strategy method (binomial or exponential).</span>
    <span class="s1">_binomial = {</span><span class="s3">'best1bin'</span><span class="s1">: </span><span class="s3">'_best1'</span><span class="s2">,</span>
                 <span class="s3">'randtobest1bin'</span><span class="s1">: </span><span class="s3">'_randtobest1'</span><span class="s2">,</span>
                 <span class="s3">'currenttobest1bin'</span><span class="s1">: </span><span class="s3">'_currenttobest1'</span><span class="s2">,</span>
                 <span class="s3">'best2bin'</span><span class="s1">: </span><span class="s3">'_best2'</span><span class="s2">,</span>
                 <span class="s3">'rand2bin'</span><span class="s1">: </span><span class="s3">'_rand2'</span><span class="s2">,</span>
                 <span class="s3">'rand1bin'</span><span class="s1">: </span><span class="s3">'_rand1'</span><span class="s1">}</span>
    <span class="s1">_exponential = {</span><span class="s3">'best1exp'</span><span class="s1">: </span><span class="s3">'_best1'</span><span class="s2">,</span>
                    <span class="s3">'rand1exp'</span><span class="s1">: </span><span class="s3">'_rand1'</span><span class="s2">,</span>
                    <span class="s3">'randtobest1exp'</span><span class="s1">: </span><span class="s3">'_randtobest1'</span><span class="s2">,</span>
                    <span class="s3">'currenttobest1exp'</span><span class="s1">: </span><span class="s3">'_currenttobest1'</span><span class="s2">,</span>
                    <span class="s3">'best2exp'</span><span class="s1">: </span><span class="s3">'_best2'</span><span class="s2">,</span>
                    <span class="s3">'rand2exp'</span><span class="s1">: </span><span class="s3">'_rand2'</span><span class="s1">}</span>

    <span class="s1">__init_error_msg = (</span><span class="s3">&quot;The population initialization method must be one of &quot;</span>
                        <span class="s3">&quot;'latinhypercube' or 'random', or an array of shape &quot;</span>
                        <span class="s3">&quot;(S, N) where N is the number of parameters and S&gt;5&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">bounds</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">,</span>
                 <span class="s1">strategy=</span><span class="s3">'best1bin'</span><span class="s2">, </span><span class="s1">maxiter=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">popsize=</span><span class="s4">15</span><span class="s2">,</span>
                 <span class="s1">tol=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">mutation=(</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">recombination=</span><span class="s4">0.7</span><span class="s2">, </span><span class="s1">seed=</span><span class="s2">None,</span>
                 <span class="s1">maxfun=np.inf</span><span class="s2">, </span><span class="s1">callback=</span><span class="s2">None, </span><span class="s1">disp=</span><span class="s2">False, </span><span class="s1">polish=</span><span class="s2">True,</span>
                 <span class="s1">init=</span><span class="s3">'latinhypercube'</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">updating=</span><span class="s3">'immediate'</span><span class="s2">,</span>
                 <span class="s1">workers=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">constraints=()</span><span class="s2">, </span><span class="s1">x0=</span><span class="s2">None, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">integrality=</span><span class="s2">None,</span>
                 <span class="s1">vectorized=</span><span class="s2">False</span><span class="s1">):</span>

        <span class="s2">if </span><span class="s1">strategy </span><span class="s2">in </span><span class="s1">self._binomial:</span>
            <span class="s1">self.mutation_func = getattr(self</span><span class="s2">, </span><span class="s1">self._binomial[strategy])</span>
        <span class="s2">elif </span><span class="s1">strategy </span><span class="s2">in </span><span class="s1">self._exponential:</span>
            <span class="s1">self.mutation_func = getattr(self</span><span class="s2">, </span><span class="s1">self._exponential[strategy])</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Please select a valid mutation strategy&quot;</span><span class="s1">)</span>
        <span class="s1">self.strategy = strategy</span>

        <span class="s1">self.callback = callback</span>
        <span class="s1">self.polish = polish</span>

        <span class="s5"># set the updating / parallelisation options</span>
        <span class="s2">if </span><span class="s1">updating </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'immediate'</span><span class="s2">, </span><span class="s3">'deferred'</span><span class="s1">]:</span>
            <span class="s1">self._updating = updating</span>

        <span class="s1">self.vectorized = vectorized</span>

        <span class="s5"># want to use parallelisation, but updating is immediate</span>
        <span class="s2">if </span><span class="s1">workers != </span><span class="s4">1 </span><span class="s2">and </span><span class="s1">updating == </span><span class="s3">'immediate'</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;differential_evolution: the 'workers' keyword has&quot;</span>
                          <span class="s3">&quot; overridden updating='immediate' to&quot;</span>
                          <span class="s3">&quot; updating='deferred'&quot;</span><span class="s2">, </span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">stacklevel=</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">self._updating = </span><span class="s3">'deferred'</span>

        <span class="s2">if </span><span class="s1">vectorized </span><span class="s2">and </span><span class="s1">workers != </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;differential_evolution: the 'workers' keyword&quot;</span>
                          <span class="s3">&quot; overrides the 'vectorized' keyword&quot;</span><span class="s2">, </span><span class="s1">stacklevel=</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">self.vectorized = vectorized = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">vectorized </span><span class="s2">and </span><span class="s1">updating == </span><span class="s3">'immediate'</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span><span class="s3">&quot;differential_evolution: the 'vectorized' keyword&quot;</span>
                          <span class="s3">&quot; has overridden updating='immediate' to updating&quot;</span>
                          <span class="s3">&quot;='deferred'&quot;</span><span class="s2">, </span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">stacklevel=</span><span class="s4">2</span><span class="s1">)</span>
            <span class="s1">self._updating = </span><span class="s3">'deferred'</span>

        <span class="s5"># an object with a map method.</span>
        <span class="s2">if </span><span class="s1">vectorized:</span>
            <span class="s2">def </span><span class="s1">maplike_for_vectorized_func(func</span><span class="s2">, </span><span class="s1">x):</span>
                <span class="s5"># send an array (N, S) to the user func,</span>
                <span class="s5"># expect to receive (S,). Transposition is required because</span>
                <span class="s5"># internally the population is held as (S, N)</span>
                <span class="s2">return </span><span class="s1">np.atleast_1d(func(x.T))</span>
            <span class="s1">workers = maplike_for_vectorized_func</span>

        <span class="s1">self._mapwrapper = MapWrapper(workers)</span>

        <span class="s5"># relative and absolute tolerances for convergence</span>
        <span class="s1">self.tol</span><span class="s2">, </span><span class="s1">self.atol = tol</span><span class="s2">, </span><span class="s1">atol</span>

        <span class="s5"># Mutation constant should be in [0, 2). If specified as a sequence</span>
        <span class="s5"># then dithering is performed.</span>
        <span class="s1">self.scale = mutation</span>
        <span class="s2">if </span><span class="s1">(</span><span class="s2">not </span><span class="s1">np.all(np.isfinite(mutation)) </span><span class="s2">or</span>
                <span class="s1">np.any(np.array(mutation) &gt;= </span><span class="s4">2</span><span class="s1">) </span><span class="s2">or</span>
                <span class="s1">np.any(np.array(mutation) &lt; </span><span class="s4">0</span><span class="s1">)):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'The mutation constant must be a float in '</span>
                             <span class="s3">'U[0, 2), or specified as a tuple(min, max)'</span>
                             <span class="s3">' where min &lt; max and min, max are in U[0, 2).'</span><span class="s1">)</span>

        <span class="s1">self.dither = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">hasattr(mutation</span><span class="s2">, </span><span class="s3">'__iter__'</span><span class="s1">) </span><span class="s2">and </span><span class="s1">len(mutation) &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">self.dither = [mutation[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">mutation[</span><span class="s4">1</span><span class="s1">]]</span>
            <span class="s1">self.dither.sort()</span>

        <span class="s1">self.cross_over_probability = recombination</span>

        <span class="s5"># we create a wrapped function to allow the use of map (and Pool.map</span>
        <span class="s5"># in the future)</span>
        <span class="s1">self.func = _FunctionWrapper(func</span><span class="s2">, </span><span class="s1">args)</span>
        <span class="s1">self.args = args</span>

        <span class="s5"># convert tuple of lower and upper bounds to limits</span>
        <span class="s5"># [(low_0, high_0), ..., (low_n, high_n]</span>
        <span class="s5">#     -&gt; [[low_0, ..., low_n], [high_0, ..., high_n]]</span>
        <span class="s2">if </span><span class="s1">isinstance(bounds</span><span class="s2">, </span><span class="s1">Bounds):</span>
            <span class="s1">self.limits = np.array(new_bounds_to_old(bounds.lb</span><span class="s2">,</span>
                                                     <span class="s1">bounds.ub</span><span class="s2">,</span>
                                                     <span class="s1">len(bounds.lb))</span><span class="s2">,</span>
                                   <span class="s1">dtype=float).T</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.limits = np.array(bounds</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s3">'float'</span><span class="s1">).T</span>

        <span class="s2">if </span><span class="s1">(np.size(self.limits</span><span class="s2">, </span><span class="s4">0</span><span class="s1">) != </span><span class="s4">2 </span><span class="s2">or not</span>
                <span class="s1">np.all(np.isfinite(self.limits))):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'bounds should be a sequence containing '</span>
                             <span class="s3">'real valued (min, max) pairs for each value'</span>
                             <span class="s3">' in x'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">maxiter </span><span class="s2">is None</span><span class="s1">:  </span><span class="s5"># the default used to be None</span>
            <span class="s1">maxiter = </span><span class="s4">1000</span>
        <span class="s1">self.maxiter = maxiter</span>
        <span class="s2">if </span><span class="s1">maxfun </span><span class="s2">is None</span><span class="s1">:  </span><span class="s5"># the default used to be None</span>
            <span class="s1">maxfun = np.inf</span>
        <span class="s1">self.maxfun = maxfun</span>

        <span class="s5"># population is scaled to between [0, 1].</span>
        <span class="s5"># We have to scale between parameter &lt;-&gt; population</span>
        <span class="s5"># save these arguments for _scale_parameter and</span>
        <span class="s5"># _unscale_parameter. This is an optimization</span>
        <span class="s1">self.__scale_arg1 = </span><span class="s4">0.5 </span><span class="s1">* (self.limits[</span><span class="s4">0</span><span class="s1">] + self.limits[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">self.__scale_arg2 = np.fabs(self.limits[</span><span class="s4">0</span><span class="s1">] - self.limits[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s2">with </span><span class="s1">np.errstate(divide=</span><span class="s3">'ignore'</span><span class="s1">):</span>
            <span class="s5"># if lb == ub then the following line will be 1/0, which is why</span>
            <span class="s5"># we ignore the divide by zero warning. The result from 1/0 is</span>
            <span class="s5"># inf, so replace those values by 0.</span>
            <span class="s1">self.__recip_scale_arg2 = </span><span class="s4">1 </span><span class="s1">/ self.__scale_arg2</span>
            <span class="s1">self.__recip_scale_arg2[~np.isfinite(self.__recip_scale_arg2)] = </span><span class="s4">0</span>

        <span class="s1">self.parameter_count = np.size(self.limits</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s1">self.random_number_generator = check_random_state(seed)</span>

        <span class="s5"># Which parameters are going to be integers?</span>
        <span class="s2">if </span><span class="s1">np.any(integrality):</span>
            <span class="s5"># # user has provided a truth value for integer constraints</span>
            <span class="s1">integrality = np.broadcast_to(</span>
                <span class="s1">integrality</span><span class="s2">,</span>
                <span class="s1">self.parameter_count</span>
            <span class="s1">)</span>
            <span class="s1">integrality = np.asarray(integrality</span><span class="s2">, </span><span class="s1">bool)</span>
            <span class="s5"># For integrality parameters change the limits to only allow</span>
            <span class="s5"># integer values lying between the limits.</span>
            <span class="s1">lb</span><span class="s2">, </span><span class="s1">ub = np.copy(self.limits)</span>

            <span class="s1">lb = np.ceil(lb)</span>
            <span class="s1">ub = np.floor(ub)</span>
            <span class="s2">if not </span><span class="s1">(lb[integrality] &lt;= ub[integrality]).all():</span>
                <span class="s5"># there's a parameter that doesn't have an integer value</span>
                <span class="s5"># lying between the limits</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;One of the integrality constraints does not&quot;</span>
                                 <span class="s3">&quot; have any possible integer values between&quot;</span>
                                 <span class="s3">&quot; the lower/upper bounds.&quot;</span><span class="s1">)</span>
            <span class="s1">nlb = np.nextafter(lb[integrality] - </span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">np.inf)</span>
            <span class="s1">nub = np.nextafter(ub[integrality] + </span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">-np.inf)</span>

            <span class="s1">self.integrality = integrality</span>
            <span class="s1">self.limits[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">self.integrality] = nlb</span>
            <span class="s1">self.limits[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self.integrality] = nub</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.integrality = </span><span class="s2">False</span>

        <span class="s5"># check for equal bounds</span>
        <span class="s1">eb = self.limits[</span><span class="s4">0</span><span class="s1">] == self.limits[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">eb_count = np.count_nonzero(eb)</span>

        <span class="s5"># default population initialization is a latin hypercube design, but</span>
        <span class="s5"># there are other population initializations possible.</span>
        <span class="s5"># the minimum is 5 because 'best2bin' requires a population that's at</span>
        <span class="s5"># least 5 long</span>
        <span class="s5"># 202301 - reduced population size to account for parameters with</span>
        <span class="s5"># equal bounds. If there are no varying parameters set N to at least 1</span>
        <span class="s1">self.num_population_members = max(</span>
            <span class="s4">5</span><span class="s2">,</span>
            <span class="s1">popsize * max(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self.parameter_count - eb_count)</span>
        <span class="s1">)</span>
        <span class="s1">self.population_shape = (self.num_population_members</span><span class="s2">,</span>
                                 <span class="s1">self.parameter_count)</span>

        <span class="s1">self._nfev = </span><span class="s4">0</span>
        <span class="s5"># check first str otherwise will fail to compare str with array</span>
        <span class="s2">if </span><span class="s1">isinstance(init</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s2">if </span><span class="s1">init == </span><span class="s3">'latinhypercube'</span><span class="s1">:</span>
                <span class="s1">self.init_population_lhs()</span>
            <span class="s2">elif </span><span class="s1">init == </span><span class="s3">'sobol'</span><span class="s1">:</span>
                <span class="s5"># must be Ns = 2**m for Sobol'</span>
                <span class="s1">n_s = int(</span><span class="s4">2 </span><span class="s1">** np.ceil(np.log2(self.num_population_members)))</span>
                <span class="s1">self.num_population_members = n_s</span>
                <span class="s1">self.population_shape = (self.num_population_members</span><span class="s2">,</span>
                                         <span class="s1">self.parameter_count)</span>
                <span class="s1">self.init_population_qmc(qmc_engine=</span><span class="s3">'sobol'</span><span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">init == </span><span class="s3">'halton'</span><span class="s1">:</span>
                <span class="s1">self.init_population_qmc(qmc_engine=</span><span class="s3">'halton'</span><span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">init == </span><span class="s3">'random'</span><span class="s1">:</span>
                <span class="s1">self.init_population_random()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(self.__init_error_msg)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.init_population_array(init)</span>

        <span class="s2">if </span><span class="s1">x0 </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s5"># scale to within unit interval and</span>
            <span class="s5"># ensure parameters are within bounds.</span>
            <span class="s1">x0_scaled = self._unscale_parameters(np.asarray(x0))</span>
            <span class="s2">if </span><span class="s1">((x0_scaled &gt; </span><span class="s4">1.0</span><span class="s1">) | (x0_scaled &lt; </span><span class="s4">0.0</span><span class="s1">)).any():</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;Some entries in x0 lay outside the specified bounds&quot;</span>
                <span class="s1">)</span>
            <span class="s1">self.population[</span><span class="s4">0</span><span class="s1">] = x0_scaled</span>

        <span class="s5"># infrastructure for constraints</span>
        <span class="s1">self.constraints = constraints</span>
        <span class="s1">self._wrapped_constraints = []</span>

        <span class="s2">if </span><span class="s1">hasattr(constraints</span><span class="s2">, </span><span class="s3">'__len__'</span><span class="s1">):</span>
            <span class="s5"># sequence of constraints, this will also deal with default</span>
            <span class="s5"># keyword parameter</span>
            <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">constraints:</span>
                <span class="s1">self._wrapped_constraints.append(</span>
                    <span class="s1">_ConstraintWrapper(c</span><span class="s2">, </span><span class="s1">self.x)</span>
                <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._wrapped_constraints = [</span>
                <span class="s1">_ConstraintWrapper(constraints</span><span class="s2">, </span><span class="s1">self.x)</span>
            <span class="s1">]</span>
        <span class="s1">self.total_constraints = np.sum(</span>
            <span class="s1">[c.num_constr </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">self._wrapped_constraints]</span>
        <span class="s1">)</span>
        <span class="s1">self.constraint_violation = np.zeros((self.num_population_members</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>
        <span class="s1">self.feasible = np.ones(self.num_population_members</span><span class="s2">, </span><span class="s1">bool)</span>

        <span class="s1">self.disp = disp</span>

    <span class="s2">def </span><span class="s1">init_population_lhs(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Initializes the population with Latin Hypercube Sampling. 
        Latin Hypercube Sampling ensures that each parameter is uniformly 
        sampled over its range. 
        &quot;&quot;&quot;</span>
        <span class="s1">rng = self.random_number_generator</span>

        <span class="s5"># Each parameter range needs to be sampled uniformly. The scaled</span>
        <span class="s5"># parameter range ([0, 1)) needs to be split into</span>
        <span class="s5"># `self.num_population_members` segments, each of which has the following</span>
        <span class="s5"># size:</span>
        <span class="s1">segsize = </span><span class="s4">1.0 </span><span class="s1">/ self.num_population_members</span>

        <span class="s5"># Within each segment we sample from a uniform random distribution.</span>
        <span class="s5"># We need to do this sampling for each parameter.</span>
        <span class="s1">samples = (segsize * rng.uniform(size=self.population_shape)</span>

        <span class="s5"># Offset each segment to cover the entire parameter range [0, 1)</span>
                   <span class="s1">+ np.linspace(</span><span class="s4">0.</span><span class="s2">, </span><span class="s4">1.</span><span class="s2">, </span><span class="s1">self.num_population_members</span><span class="s2">,</span>
                                 <span class="s1">endpoint=</span><span class="s2">False</span><span class="s1">)[:</span><span class="s2">, </span><span class="s1">np.newaxis])</span>

        <span class="s5"># Create an array for population of candidate solutions.</span>
        <span class="s1">self.population = np.zeros_like(samples)</span>

        <span class="s5"># Initialize population of candidate solutions by permutation of the</span>
        <span class="s5"># random samples.</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(self.parameter_count):</span>
            <span class="s1">order = rng.permutation(range(self.num_population_members))</span>
            <span class="s1">self.population[:</span><span class="s2">, </span><span class="s1">j] = samples[order</span><span class="s2">, </span><span class="s1">j]</span>

        <span class="s5"># reset population energies</span>
        <span class="s1">self.population_energies = np.full(self.num_population_members</span><span class="s2">,</span>
                                           <span class="s1">np.inf)</span>

        <span class="s5"># reset number of function evaluations counter</span>
        <span class="s1">self._nfev = </span><span class="s4">0</span>

    <span class="s2">def </span><span class="s1">init_population_qmc(self</span><span class="s2">, </span><span class="s1">qmc_engine):</span>
        <span class="s0">&quot;&quot;&quot;Initializes the population with a QMC method. 
 
        QMC methods ensures that each parameter is uniformly 
        sampled over its range. 
 
        Parameters 
        ---------- 
        qmc_engine : str 
            The QMC method to use for initialization. Can be one of 
            ``latinhypercube``, ``sobol`` or ``halton``. 
 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">scipy.stats </span><span class="s2">import </span><span class="s1">qmc</span>

        <span class="s1">rng = self.random_number_generator</span>

        <span class="s5"># Create an array for population of candidate solutions.</span>
        <span class="s2">if </span><span class="s1">qmc_engine == </span><span class="s3">'latinhypercube'</span><span class="s1">:</span>
            <span class="s1">sampler = qmc.LatinHypercube(d=self.parameter_count</span><span class="s2">, </span><span class="s1">seed=rng)</span>
        <span class="s2">elif </span><span class="s1">qmc_engine == </span><span class="s3">'sobol'</span><span class="s1">:</span>
            <span class="s1">sampler = qmc.Sobol(d=self.parameter_count</span><span class="s2">, </span><span class="s1">seed=rng)</span>
        <span class="s2">elif </span><span class="s1">qmc_engine == </span><span class="s3">'halton'</span><span class="s1">:</span>
            <span class="s1">sampler = qmc.Halton(d=self.parameter_count</span><span class="s2">, </span><span class="s1">seed=rng)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(self.__init_error_msg)</span>

        <span class="s1">self.population = sampler.random(n=self.num_population_members)</span>

        <span class="s5"># reset population energies</span>
        <span class="s1">self.population_energies = np.full(self.num_population_members</span><span class="s2">,</span>
                                           <span class="s1">np.inf)</span>

        <span class="s5"># reset number of function evaluations counter</span>
        <span class="s1">self._nfev = </span><span class="s4">0</span>

    <span class="s2">def </span><span class="s1">init_population_random(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Initializes the population at random. This type of initialization 
        can possess clustering, Latin Hypercube sampling is generally better. 
        &quot;&quot;&quot;</span>
        <span class="s1">rng = self.random_number_generator</span>
        <span class="s1">self.population = rng.uniform(size=self.population_shape)</span>

        <span class="s5"># reset population energies</span>
        <span class="s1">self.population_energies = np.full(self.num_population_members</span><span class="s2">,</span>
                                           <span class="s1">np.inf)</span>

        <span class="s5"># reset number of function evaluations counter</span>
        <span class="s1">self._nfev = </span><span class="s4">0</span>

    <span class="s2">def </span><span class="s1">init_population_array(self</span><span class="s2">, </span><span class="s1">init):</span>
        <span class="s0">&quot;&quot;&quot; 
        Initializes the population with a user specified population. 
 
        Parameters 
        ---------- 
        init : np.ndarray 
            Array specifying subset of the initial population. The array should 
            have shape (S, N), where N is the number of parameters. 
            The population is clipped to the lower and upper bounds. 
        &quot;&quot;&quot;</span>
        <span class="s5"># make sure you're using a float array</span>
        <span class="s1">popn = np.asfarray(init)</span>

        <span class="s2">if </span><span class="s1">(np.size(popn</span><span class="s2">, </span><span class="s4">0</span><span class="s1">) &lt; </span><span class="s4">5 </span><span class="s2">or</span>
                <span class="s1">popn.shape[</span><span class="s4">1</span><span class="s1">] != self.parameter_count </span><span class="s2">or</span>
                <span class="s1">len(popn.shape) != </span><span class="s4">2</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;The population supplied needs to have shape&quot;</span>
                             <span class="s3">&quot; (S, len(x)), where S &gt; 4.&quot;</span><span class="s1">)</span>

        <span class="s5"># scale values and clip to bounds, assigning to population</span>
        <span class="s1">self.population = np.clip(self._unscale_parameters(popn)</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s1">self.num_population_members = np.size(self.population</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

        <span class="s1">self.population_shape = (self.num_population_members</span><span class="s2">,</span>
                                 <span class="s1">self.parameter_count)</span>

        <span class="s5"># reset population energies</span>
        <span class="s1">self.population_energies = np.full(self.num_population_members</span><span class="s2">,</span>
                                           <span class="s1">np.inf)</span>

        <span class="s5"># reset number of function evaluations counter</span>
        <span class="s1">self._nfev = </span><span class="s4">0</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">x(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        The best solution from the solver 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._scale_parameters(self.population[</span><span class="s4">0</span><span class="s1">])</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">convergence(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        The standard deviation of the population energies divided by their 
        mean. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">np.any(np.isinf(self.population_energies)):</span>
            <span class="s2">return </span><span class="s1">np.inf</span>
        <span class="s2">return </span><span class="s1">(np.std(self.population_energies) /</span>
                <span class="s1">(np.abs(np.mean(self.population_energies)) + _MACHEPS))</span>

    <span class="s2">def </span><span class="s1">converged(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return True if the solver has converged. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">np.any(np.isinf(self.population_energies)):</span>
            <span class="s2">return False</span>

        <span class="s2">return </span><span class="s1">(np.std(self.population_energies) &lt;=</span>
                <span class="s1">self.atol +</span>
                <span class="s1">self.tol * np.abs(np.mean(self.population_energies)))</span>

    <span class="s2">def </span><span class="s1">solve(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Runs the DifferentialEvolutionSolver. 
 
        Returns 
        ------- 
        res : OptimizeResult 
            The optimization result represented as a ``OptimizeResult`` object. 
            Important attributes are: ``x`` the solution array, ``success`` a 
            Boolean flag indicating if the optimizer exited successfully and 
            ``message`` which describes the cause of the termination. See 
            `OptimizeResult` for a description of other attributes.  If `polish` 
            was employed, and a lower minimum was obtained by the polishing, 
            then OptimizeResult also contains the ``jac`` attribute. 
        &quot;&quot;&quot;</span>
        <span class="s1">nit</span><span class="s2">, </span><span class="s1">warning_flag = </span><span class="s4">0</span><span class="s2">, False</span>
        <span class="s1">status_message = _status_message[</span><span class="s3">'success'</span><span class="s1">]</span>

        <span class="s5"># The population may have just been initialized (all entries are</span>
        <span class="s5"># np.inf). If it has you have to calculate the initial energies.</span>
        <span class="s5"># Although this is also done in the evolve generator it's possible</span>
        <span class="s5"># that someone can set maxiter=0, at which point we still want the</span>
        <span class="s5"># initial energies to be calculated (the following loop isn't run).</span>
        <span class="s2">if </span><span class="s1">np.all(np.isinf(self.population_energies)):</span>
            <span class="s1">self.feasible</span><span class="s2">, </span><span class="s1">self.constraint_violation = (</span>
                <span class="s1">self._calculate_population_feasibilities(self.population))</span>

            <span class="s5"># only work out population energies for feasible solutions</span>
            <span class="s1">self.population_energies[self.feasible] = (</span>
                <span class="s1">self._calculate_population_energies(</span>
                    <span class="s1">self.population[self.feasible]))</span>

            <span class="s1">self._promote_lowest_energy()</span>

        <span class="s5"># do the optimization.</span>
        <span class="s2">for </span><span class="s1">nit </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self.maxiter + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s5"># evolve the population by a generation</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">next(self)</span>
            <span class="s2">except </span><span class="s1">StopIteration:</span>
                <span class="s1">warning_flag = </span><span class="s2">True</span>
                <span class="s2">if </span><span class="s1">self._nfev &gt; self.maxfun:</span>
                    <span class="s1">status_message = _status_message[</span><span class="s3">'maxfev'</span><span class="s1">]</span>
                <span class="s2">elif </span><span class="s1">self._nfev == self.maxfun:</span>
                    <span class="s1">status_message = (</span><span class="s3">'Maximum number of function evaluations'</span>
                                      <span class="s3">' has been reached.'</span><span class="s1">)</span>
                <span class="s2">break</span>

            <span class="s2">if </span><span class="s1">self.disp:</span>
                <span class="s1">print(</span><span class="s3">&quot;differential_evolution step %d: f(x)= %g&quot;</span>
                      <span class="s1">% (nit</span><span class="s2">,</span>
                         <span class="s1">self.population_energies[</span><span class="s4">0</span><span class="s1">]))</span>

            <span class="s2">if </span><span class="s1">self.callback:</span>
                <span class="s1">c = self.tol / (self.convergence + _MACHEPS)</span>
                <span class="s1">warning_flag = bool(self.callback(self.x</span><span class="s2">, </span><span class="s1">convergence=c))</span>
                <span class="s2">if </span><span class="s1">warning_flag:</span>
                    <span class="s1">status_message = (</span><span class="s3">'callback function requested stop early'</span>
                                      <span class="s3">' by returning True'</span><span class="s1">)</span>

            <span class="s5"># should the solver terminate?</span>
            <span class="s2">if </span><span class="s1">warning_flag </span><span class="s2">or </span><span class="s1">self.converged():</span>
                <span class="s2">break</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">status_message = _status_message[</span><span class="s3">'maxiter'</span><span class="s1">]</span>
            <span class="s1">warning_flag = </span><span class="s2">True</span>

        <span class="s1">DE_result = OptimizeResult(</span>
            <span class="s1">x=self.x</span><span class="s2">,</span>
            <span class="s1">fun=self.population_energies[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">nfev=self._nfev</span><span class="s2">,</span>
            <span class="s1">nit=nit</span><span class="s2">,</span>
            <span class="s1">message=status_message</span><span class="s2">,</span>
            <span class="s1">success=(warning_flag </span><span class="s2">is not True</span><span class="s1">))</span>

        <span class="s2">if </span><span class="s1">self.polish </span><span class="s2">and not </span><span class="s1">np.all(self.integrality):</span>
            <span class="s5"># can't polish if all the parameters are integers</span>
            <span class="s2">if </span><span class="s1">np.any(self.integrality):</span>
                <span class="s5"># set the lower/upper bounds equal so that any integrality</span>
                <span class="s5"># constraints work.</span>
                <span class="s1">limits</span><span class="s2">, </span><span class="s1">integrality = self.limits</span><span class="s2">, </span><span class="s1">self.integrality</span>
                <span class="s1">limits[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">integrality] = DE_result.x[integrality]</span>
                <span class="s1">limits[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">integrality] = DE_result.x[integrality]</span>

            <span class="s1">polish_method = </span><span class="s3">'L-BFGS-B'</span>

            <span class="s2">if </span><span class="s1">self._wrapped_constraints:</span>
                <span class="s1">polish_method = </span><span class="s3">'trust-constr'</span>

                <span class="s1">constr_violation = self._constraint_violation_fn(DE_result.x)</span>
                <span class="s2">if </span><span class="s1">np.any(constr_violation &gt; </span><span class="s4">0.</span><span class="s1">):</span>
                    <span class="s1">warnings.warn(</span><span class="s3">&quot;differential evolution didn't find a&quot;</span>
                                  <span class="s3">&quot; solution satisfying the constraints,&quot;</span>
                                  <span class="s3">&quot; attempting to polish from the least&quot;</span>
                                  <span class="s3">&quot; infeasible solution&quot;</span><span class="s2">, </span><span class="s1">UserWarning)</span>
            <span class="s2">if </span><span class="s1">self.disp:</span>
                <span class="s1">print(</span><span class="s3">f&quot;Polishing solution with '</span><span class="s2">{</span><span class="s1">polish_method</span><span class="s2">}</span><span class="s3">'&quot;</span><span class="s1">)</span>
            <span class="s1">result = minimize(self.func</span><span class="s2">,</span>
                              <span class="s1">np.copy(DE_result.x)</span><span class="s2">,</span>
                              <span class="s1">method=polish_method</span><span class="s2">,</span>
                              <span class="s1">bounds=self.limits.T</span><span class="s2">,</span>
                              <span class="s1">constraints=self.constraints)</span>

            <span class="s1">self._nfev += result.nfev</span>
            <span class="s1">DE_result.nfev = self._nfev</span>

            <span class="s5"># Polishing solution is only accepted if there is an improvement in</span>
            <span class="s5"># cost function, the polishing was successful and the solution lies</span>
            <span class="s5"># within the bounds.</span>
            <span class="s2">if </span><span class="s1">(result.fun &lt; DE_result.fun </span><span class="s2">and</span>
                    <span class="s1">result.success </span><span class="s2">and</span>
                    <span class="s1">np.all(result.x &lt;= self.limits[</span><span class="s4">1</span><span class="s1">]) </span><span class="s2">and</span>
                    <span class="s1">np.all(self.limits[</span><span class="s4">0</span><span class="s1">] &lt;= result.x)):</span>
                <span class="s1">DE_result.fun = result.fun</span>
                <span class="s1">DE_result.x = result.x</span>
                <span class="s1">DE_result.jac = result.jac</span>
                <span class="s5"># to keep internal state consistent</span>
                <span class="s1">self.population_energies[</span><span class="s4">0</span><span class="s1">] = result.fun</span>
                <span class="s1">self.population[</span><span class="s4">0</span><span class="s1">] = self._unscale_parameters(result.x)</span>

        <span class="s2">if </span><span class="s1">self._wrapped_constraints:</span>
            <span class="s1">DE_result.constr = [c.violation(DE_result.x) </span><span class="s2">for</span>
                                <span class="s1">c </span><span class="s2">in </span><span class="s1">self._wrapped_constraints]</span>
            <span class="s1">DE_result.constr_violation = np.max(</span>
                <span class="s1">np.concatenate(DE_result.constr))</span>
            <span class="s1">DE_result.maxcv = DE_result.constr_violation</span>
            <span class="s2">if </span><span class="s1">DE_result.maxcv &gt; </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s5"># if the result is infeasible then success must be False</span>
                <span class="s1">DE_result.success = </span><span class="s2">False</span>
                <span class="s1">DE_result.message = (</span><span class="s3">&quot;The solution does not satisfy the &quot;</span>
                                     <span class="s3">f&quot;constraints, MAXCV = </span><span class="s2">{</span><span class="s1">DE_result.maxcv</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">DE_result</span>

    <span class="s2">def </span><span class="s1">_calculate_population_energies(self</span><span class="s2">, </span><span class="s1">population):</span>
        <span class="s0">&quot;&quot;&quot; 
        Calculate the energies of a population. 
 
        Parameters 
        ---------- 
        population : ndarray 
            An array of parameter vectors normalised to [0, 1] using lower 
            and upper limits. Has shape ``(np.size(population, 0), N)``. 
 
        Returns 
        ------- 
        energies : ndarray 
            An array of energies corresponding to each population member. If 
            maxfun will be exceeded during this call, then the number of 
            function evaluations will be reduced and energies will be 
            right-padded with np.inf. Has shape ``(np.size(population, 0),)`` 
        &quot;&quot;&quot;</span>
        <span class="s1">num_members = np.size(population</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s5"># S is the number of function evals left to stay under the</span>
        <span class="s5"># maxfun budget</span>
        <span class="s1">S = min(num_members</span><span class="s2">, </span><span class="s1">self.maxfun - self._nfev)</span>

        <span class="s1">energies = np.full(num_members</span><span class="s2">, </span><span class="s1">np.inf)</span>

        <span class="s1">parameters_pop = self._scale_parameters(population)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">calc_energies = list(</span>
                <span class="s1">self._mapwrapper(self.func</span><span class="s2">, </span><span class="s1">parameters_pop[</span><span class="s4">0</span><span class="s1">:S])</span>
            <span class="s1">)</span>
            <span class="s1">calc_energies = np.squeeze(calc_energies)</span>
        <span class="s2">except </span><span class="s1">(TypeError</span><span class="s2">, </span><span class="s1">ValueError) </span><span class="s2">as </span><span class="s1">e:</span>
            <span class="s5"># wrong number of arguments for _mapwrapper</span>
            <span class="s5"># or wrong length returned from the mapper</span>
            <span class="s2">raise </span><span class="s1">RuntimeError(</span>
                <span class="s3">&quot;The map-like callable must be of the form f(func, iterable), &quot;</span>
                <span class="s3">&quot;returning a sequence of numbers the same length as 'iterable'&quot;</span>
            <span class="s1">) </span><span class="s2">from </span><span class="s1">e</span>

        <span class="s2">if </span><span class="s1">calc_energies.size != S:</span>
            <span class="s2">if </span><span class="s1">self.vectorized:</span>
                <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;The vectorized function must return an&quot;</span>
                                   <span class="s3">&quot; array of shape (S,) when given an array&quot;</span>
                                   <span class="s3">&quot; of shape (len(x), S)&quot;</span><span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;func(x, *args) must return a scalar value&quot;</span><span class="s1">)</span>

        <span class="s1">energies[</span><span class="s4">0</span><span class="s1">:S] = calc_energies</span>

        <span class="s2">if </span><span class="s1">self.vectorized:</span>
            <span class="s1">self._nfev += </span><span class="s4">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._nfev += S</span>

        <span class="s2">return </span><span class="s1">energies</span>

    <span class="s2">def </span><span class="s1">_promote_lowest_energy(self):</span>
        <span class="s5"># swaps 'best solution' into first population entry</span>

        <span class="s1">idx = np.arange(self.num_population_members)</span>
        <span class="s1">feasible_solutions = idx[self.feasible]</span>
        <span class="s2">if </span><span class="s1">feasible_solutions.size:</span>
            <span class="s5"># find the best feasible solution</span>
            <span class="s1">idx_t = np.argmin(self.population_energies[feasible_solutions])</span>
            <span class="s1">l = feasible_solutions[idx_t]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s5"># no solution was feasible, use 'best' infeasible solution, which</span>
            <span class="s5"># will violate constraints the least</span>
            <span class="s1">l = np.argmin(np.sum(self.constraint_violation</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">))</span>

        <span class="s1">self.population_energies[[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">l]] = self.population_energies[[l</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]]</span>
        <span class="s1">self.population[[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">l]</span><span class="s2">, </span><span class="s1">:] = self.population[[l</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">:]</span>
        <span class="s1">self.feasible[[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">l]] = self.feasible[[l</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]]</span>
        <span class="s1">self.constraint_violation[[</span><span class="s4">0</span><span class="s2">, </span><span class="s1">l]</span><span class="s2">, </span><span class="s1">:] = (</span>
        <span class="s1">self.constraint_violation[[l</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">:])</span>

    <span class="s2">def </span><span class="s1">_constraint_violation_fn(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0">&quot;&quot;&quot; 
        Calculates total constraint violation for all the constraints, for a 
        set of solutions. 
 
        Parameters 
        ---------- 
        x : ndarray 
            Solution vector(s). Has shape (S, N), or (N,), where S is the 
            number of solutions to investigate and N is the number of 
            parameters. 
 
        Returns 
        ------- 
        cv : ndarray 
            Total violation of constraints. Has shape ``(S, M)``, where M is 
            the total number of constraint components (which is not necessarily 
            equal to len(self._wrapped_constraints)). 
        &quot;&quot;&quot;</span>
        <span class="s5"># how many solution vectors you're calculating constraint violations</span>
        <span class="s5"># for</span>
        <span class="s1">S = np.size(x) // self.parameter_count</span>
        <span class="s1">_out = np.zeros((S</span><span class="s2">, </span><span class="s1">self.total_constraints))</span>
        <span class="s1">offset = </span><span class="s4">0</span>
        <span class="s2">for </span><span class="s1">con </span><span class="s2">in </span><span class="s1">self._wrapped_constraints:</span>
            <span class="s5"># the input/output of the (vectorized) constraint function is</span>
            <span class="s5"># {(N, S), (N,)} --&gt; (M, S)</span>
            <span class="s5"># The input to _constraint_violation_fn is (S, N) or (N,), so</span>
            <span class="s5"># transpose to pass it to the constraint. The output is transposed</span>
            <span class="s5"># from (M, S) to (S, M) for further use.</span>
            <span class="s1">c = con.violation(x.T).T</span>

            <span class="s5"># The shape of c should be (M,), (1, M), or (S, M). Check for</span>
            <span class="s5"># those shapes, as an incorrect shape indicates that the</span>
            <span class="s5"># user constraint function didn't return the right thing, and</span>
            <span class="s5"># the reshape operation will fail. Intercept the wrong shape</span>
            <span class="s5"># to give a reasonable error message. I'm not sure what failure</span>
            <span class="s5"># modes an inventive user will come up with.</span>
            <span class="s2">if </span><span class="s1">c.shape[-</span><span class="s4">1</span><span class="s1">] != con.num_constr </span><span class="s2">or </span><span class="s1">(S &gt; </span><span class="s4">1 </span><span class="s2">and </span><span class="s1">c.shape[</span><span class="s4">0</span><span class="s1">] != S):</span>
                <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;An array returned from a Constraint has&quot;</span>
                                   <span class="s3">&quot; the wrong shape. If `vectorized is False`&quot;</span>
                                   <span class="s3">&quot; the Constraint should return an array of&quot;</span>
                                   <span class="s3">&quot; shape (M,). If `vectorized is True` then&quot;</span>
                                   <span class="s3">&quot; the Constraint must return an array of&quot;</span>
                                   <span class="s3">&quot; shape (M, S), where S is the number of&quot;</span>
                                   <span class="s3">&quot; solution vectors and M is the number of&quot;</span>
                                   <span class="s3">&quot; constraint components in a given&quot;</span>
                                   <span class="s3">&quot; Constraint object.&quot;</span><span class="s1">)</span>

            <span class="s5"># the violation function may return a 1D array, but is it a</span>
            <span class="s5"># sequence of constraints for one solution (S=1, M&gt;=1), or the</span>
            <span class="s5"># value of a single constraint for a sequence of solutions</span>
            <span class="s5"># (S&gt;=1, M=1)</span>
            <span class="s1">c = np.reshape(c</span><span class="s2">, </span><span class="s1">(S</span><span class="s2">, </span><span class="s1">con.num_constr))</span>
            <span class="s1">_out[:</span><span class="s2">, </span><span class="s1">offset:offset + con.num_constr] = c</span>
            <span class="s1">offset += con.num_constr</span>

        <span class="s2">return </span><span class="s1">_out</span>

    <span class="s2">def </span><span class="s1">_calculate_population_feasibilities(self</span><span class="s2">, </span><span class="s1">population):</span>
        <span class="s0">&quot;&quot;&quot; 
        Calculate the feasibilities of a population. 
 
        Parameters 
        ---------- 
        population : ndarray 
            An array of parameter vectors normalised to [0, 1] using lower 
            and upper limits. Has shape ``(np.size(population, 0), N)``. 
 
        Returns 
        ------- 
        feasible, constraint_violation : ndarray, ndarray 
            Boolean array of feasibility for each population member, and an 
            array of the constraint violation for each population member. 
            constraint_violation has shape ``(np.size(population, 0), M)``, 
            where M is the number of constraints. 
        &quot;&quot;&quot;</span>
        <span class="s1">num_members = np.size(population</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">self._wrapped_constraints:</span>
            <span class="s5"># shortcut for no constraints</span>
            <span class="s2">return </span><span class="s1">np.ones(num_members</span><span class="s2">, </span><span class="s1">bool)</span><span class="s2">, </span><span class="s1">np.zeros((num_members</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>

        <span class="s5"># (S, N)</span>
        <span class="s1">parameters_pop = self._scale_parameters(population)</span>

        <span class="s2">if </span><span class="s1">self.vectorized:</span>
            <span class="s5"># (S, M)</span>
            <span class="s1">constraint_violation = np.array(</span>
                <span class="s1">self._constraint_violation_fn(parameters_pop)</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s5"># (S, 1, M)</span>
            <span class="s1">constraint_violation = np.array([self._constraint_violation_fn(x)</span>
                                             <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">parameters_pop])</span>
            <span class="s5"># if you use the list comprehension in the line above it will</span>
            <span class="s5"># create an array of shape (S, 1, M), because each iteration</span>
            <span class="s5"># generates an array of (1, M). In comparison the vectorized</span>
            <span class="s5"># version returns (S, M). It's therefore necessary to remove axis 1</span>
            <span class="s1">constraint_violation = constraint_violation[:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span>

        <span class="s1">feasible = ~(np.sum(constraint_violation</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">) &gt; </span><span class="s4">0</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">feasible</span><span class="s2">, </span><span class="s1">constraint_violation</span>

    <span class="s2">def </span><span class="s1">__iter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__enter__(self):</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__exit__(self</span><span class="s2">, </span><span class="s1">*args):</span>
        <span class="s2">return </span><span class="s1">self._mapwrapper.__exit__(*args)</span>

    <span class="s2">def </span><span class="s1">_accept_trial(self</span><span class="s2">, </span><span class="s1">energy_trial</span><span class="s2">, </span><span class="s1">feasible_trial</span><span class="s2">, </span><span class="s1">cv_trial</span><span class="s2">,</span>
                      <span class="s1">energy_orig</span><span class="s2">, </span><span class="s1">feasible_orig</span><span class="s2">, </span><span class="s1">cv_orig):</span>
        <span class="s0">&quot;&quot;&quot; 
        Trial is accepted if: 
        * it satisfies all constraints and provides a lower or equal objective 
          function value, while both the compared solutions are feasible 
        - or - 
        * it is feasible while the original solution is infeasible, 
        - or - 
        * it is infeasible, but provides a lower or equal constraint violation 
          for all constraint functions. 
 
        This test corresponds to section III of Lampinen [1]_. 
 
        Parameters 
        ---------- 
        energy_trial : float 
            Energy of the trial solution 
        feasible_trial : float 
            Feasibility of trial solution 
        cv_trial : array-like 
            Excess constraint violation for the trial solution 
        energy_orig : float 
            Energy of the original solution 
        feasible_orig : float 
            Feasibility of original solution 
        cv_orig : array-like 
            Excess constraint violation for the original solution 
 
        Returns 
        ------- 
        accepted : bool 
 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">feasible_orig </span><span class="s2">and </span><span class="s1">feasible_trial:</span>
            <span class="s2">return </span><span class="s1">energy_trial &lt;= energy_orig</span>
        <span class="s2">elif </span><span class="s1">feasible_trial </span><span class="s2">and not </span><span class="s1">feasible_orig:</span>
            <span class="s2">return True</span>
        <span class="s2">elif not </span><span class="s1">feasible_trial </span><span class="s2">and </span><span class="s1">(cv_trial &lt;= cv_orig).all():</span>
            <span class="s5"># cv_trial &lt; cv_orig would imply that both trial and orig are not</span>
            <span class="s5"># feasible</span>
            <span class="s2">return True</span>

        <span class="s2">return False</span>

    <span class="s2">def </span><span class="s1">__next__(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evolve the population by a single generation 
 
        Returns 
        ------- 
        x : ndarray 
            The best solution from the solver. 
        fun : float 
            Value of objective function obtained from the best solution. 
        &quot;&quot;&quot;</span>
        <span class="s5"># the population may have just been initialized (all entries are</span>
        <span class="s5"># np.inf). If it has you have to calculate the initial energies</span>
        <span class="s2">if </span><span class="s1">np.all(np.isinf(self.population_energies)):</span>
            <span class="s1">self.feasible</span><span class="s2">, </span><span class="s1">self.constraint_violation = (</span>
                <span class="s1">self._calculate_population_feasibilities(self.population))</span>

            <span class="s5"># only need to work out population energies for those that are</span>
            <span class="s5"># feasible</span>
            <span class="s1">self.population_energies[self.feasible] = (</span>
                <span class="s1">self._calculate_population_energies(</span>
                    <span class="s1">self.population[self.feasible]))</span>

            <span class="s1">self._promote_lowest_energy()</span>

        <span class="s2">if </span><span class="s1">self.dither </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.scale = self.random_number_generator.uniform(self.dither[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
                                                              <span class="s1">self.dither[</span><span class="s4">1</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">self._updating == </span><span class="s3">'immediate'</span><span class="s1">:</span>
            <span class="s5"># update best solution immediately</span>
            <span class="s2">for </span><span class="s1">candidate </span><span class="s2">in </span><span class="s1">range(self.num_population_members):</span>
                <span class="s2">if </span><span class="s1">self._nfev &gt; self.maxfun:</span>
                    <span class="s2">raise </span><span class="s1">StopIteration</span>

                <span class="s5"># create a trial solution</span>
                <span class="s1">trial = self._mutate(candidate)</span>

                <span class="s5"># ensuring that it's in the range [0, 1)</span>
                <span class="s1">self._ensure_constraint(trial)</span>

                <span class="s5"># scale from [0, 1) to the actual parameter value</span>
                <span class="s1">parameters = self._scale_parameters(trial)</span>

                <span class="s5"># determine the energy of the objective function</span>
                <span class="s2">if </span><span class="s1">self._wrapped_constraints:</span>
                    <span class="s1">cv = self._constraint_violation_fn(parameters)</span>
                    <span class="s1">feasible = </span><span class="s2">False</span>
                    <span class="s1">energy = np.inf</span>
                    <span class="s2">if not </span><span class="s1">np.sum(cv) &gt; </span><span class="s4">0</span><span class="s1">:</span>
                        <span class="s5"># solution is feasible</span>
                        <span class="s1">feasible = </span><span class="s2">True</span>
                        <span class="s1">energy = self.func(parameters)</span>
                        <span class="s1">self._nfev += </span><span class="s4">1</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">feasible = </span><span class="s2">True</span>
                    <span class="s1">cv = np.atleast_2d([</span><span class="s4">0.</span><span class="s1">])</span>
                    <span class="s1">energy = self.func(parameters)</span>
                    <span class="s1">self._nfev += </span><span class="s4">1</span>

                <span class="s5"># compare trial and population member</span>
                <span class="s2">if </span><span class="s1">self._accept_trial(energy</span><span class="s2">, </span><span class="s1">feasible</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">,</span>
                                      <span class="s1">self.population_energies[candidate]</span><span class="s2">,</span>
                                      <span class="s1">self.feasible[candidate]</span><span class="s2">,</span>
                                      <span class="s1">self.constraint_violation[candidate]):</span>
                    <span class="s1">self.population[candidate] = trial</span>
                    <span class="s1">self.population_energies[candidate] = np.squeeze(energy)</span>
                    <span class="s1">self.feasible[candidate] = feasible</span>
                    <span class="s1">self.constraint_violation[candidate] = cv</span>

                    <span class="s5"># if the trial candidate is also better than the best</span>
                    <span class="s5"># solution then promote it.</span>
                    <span class="s2">if </span><span class="s1">self._accept_trial(energy</span><span class="s2">, </span><span class="s1">feasible</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">,</span>
                                          <span class="s1">self.population_energies[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
                                          <span class="s1">self.feasible[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
                                          <span class="s1">self.constraint_violation[</span><span class="s4">0</span><span class="s1">]):</span>
                        <span class="s1">self._promote_lowest_energy()</span>

        <span class="s2">elif </span><span class="s1">self._updating == </span><span class="s3">'deferred'</span><span class="s1">:</span>
            <span class="s5"># update best solution once per generation</span>
            <span class="s2">if </span><span class="s1">self._nfev &gt;= self.maxfun:</span>
                <span class="s2">raise </span><span class="s1">StopIteration</span>

            <span class="s5"># 'deferred' approach, vectorised form.</span>
            <span class="s5"># create trial solutions</span>
            <span class="s1">trial_pop = np.array(</span>
                <span class="s1">[self._mutate(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_population_members)])</span>

            <span class="s5"># enforce bounds</span>
            <span class="s1">self._ensure_constraint(trial_pop)</span>

            <span class="s5"># determine the energies of the objective function, but only for</span>
            <span class="s5"># feasible trials</span>
            <span class="s1">feasible</span><span class="s2">, </span><span class="s1">cv = self._calculate_population_feasibilities(trial_pop)</span>
            <span class="s1">trial_energies = np.full(self.num_population_members</span><span class="s2">, </span><span class="s1">np.inf)</span>

            <span class="s5"># only calculate for feasible entries</span>
            <span class="s1">trial_energies[feasible] = self._calculate_population_energies(</span>
                <span class="s1">trial_pop[feasible])</span>

            <span class="s5"># which solutions are 'improved'?</span>
            <span class="s1">loc = [self._accept_trial(*val) </span><span class="s2">for </span><span class="s1">val </span><span class="s2">in</span>
                   <span class="s1">zip(trial_energies</span><span class="s2">, </span><span class="s1">feasible</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">, </span><span class="s1">self.population_energies</span><span class="s2">,</span>
                       <span class="s1">self.feasible</span><span class="s2">, </span><span class="s1">self.constraint_violation)]</span>
            <span class="s1">loc = np.array(loc)</span>
            <span class="s1">self.population = np.where(loc[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span><span class="s2">,</span>
                                       <span class="s1">trial_pop</span><span class="s2">,</span>
                                       <span class="s1">self.population)</span>
            <span class="s1">self.population_energies = np.where(loc</span><span class="s2">,</span>
                                                <span class="s1">trial_energies</span><span class="s2">,</span>
                                                <span class="s1">self.population_energies)</span>
            <span class="s1">self.feasible = np.where(loc</span><span class="s2">,</span>
                                     <span class="s1">feasible</span><span class="s2">,</span>
                                     <span class="s1">self.feasible)</span>
            <span class="s1">self.constraint_violation = np.where(loc[:</span><span class="s2">, </span><span class="s1">np.newaxis]</span><span class="s2">,</span>
                                                 <span class="s1">cv</span><span class="s2">,</span>
                                                 <span class="s1">self.constraint_violation)</span>

            <span class="s5"># make sure the best solution is updated if updating='deferred'.</span>
            <span class="s5"># put the lowest energy into the best solution position.</span>
            <span class="s1">self._promote_lowest_energy()</span>

        <span class="s2">return </span><span class="s1">self.x</span><span class="s2">, </span><span class="s1">self.population_energies[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">_scale_parameters(self</span><span class="s2">, </span><span class="s1">trial):</span>
        <span class="s0">&quot;&quot;&quot;Scale from a number between 0 and 1 to parameters.&quot;&quot;&quot;</span>
        <span class="s5"># trial either has shape (N, ) or (L, N), where L is the number of</span>
        <span class="s5"># solutions being scaled</span>
        <span class="s1">scaled = self.__scale_arg1 + (trial - </span><span class="s4">0.5</span><span class="s1">) * self.__scale_arg2</span>
        <span class="s2">if </span><span class="s1">np.any(self.integrality):</span>
            <span class="s1">i = np.broadcast_to(self.integrality</span><span class="s2">, </span><span class="s1">scaled.shape)</span>
            <span class="s1">scaled[i] = np.round(scaled[i])</span>
        <span class="s2">return </span><span class="s1">scaled</span>

    <span class="s2">def </span><span class="s1">_unscale_parameters(self</span><span class="s2">, </span><span class="s1">parameters):</span>
        <span class="s0">&quot;&quot;&quot;Scale from parameters to a number between 0 and 1.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">(parameters - self.__scale_arg1) * self.__recip_scale_arg2 + </span><span class="s4">0.5</span>

    <span class="s2">def </span><span class="s1">_ensure_constraint(self</span><span class="s2">, </span><span class="s1">trial):</span>
        <span class="s0">&quot;&quot;&quot;Make sure the parameters lie between the limits.&quot;&quot;&quot;</span>
        <span class="s1">mask = np.where((trial &gt; </span><span class="s4">1</span><span class="s1">) | (trial &lt; </span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">trial[mask] = self.random_number_generator.uniform(size=mask[</span><span class="s4">0</span><span class="s1">].shape)</span>

    <span class="s2">def </span><span class="s1">_mutate(self</span><span class="s2">, </span><span class="s1">candidate):</span>
        <span class="s0">&quot;&quot;&quot;Create a trial vector based on a mutation strategy.&quot;&quot;&quot;</span>
        <span class="s1">trial = np.copy(self.population[candidate])</span>

        <span class="s1">rng = self.random_number_generator</span>

        <span class="s1">fill_point = rng.choice(self.parameter_count)</span>

        <span class="s2">if </span><span class="s1">self.strategy </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'currenttobest1exp'</span><span class="s2">, </span><span class="s3">'currenttobest1bin'</span><span class="s1">]:</span>
            <span class="s1">bprime = self.mutation_func(candidate</span><span class="s2">,</span>
                                        <span class="s1">self._select_samples(candidate</span><span class="s2">, </span><span class="s4">5</span><span class="s1">))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">bprime = self.mutation_func(self._select_samples(candidate</span><span class="s2">, </span><span class="s4">5</span><span class="s1">))</span>

        <span class="s2">if </span><span class="s1">self.strategy </span><span class="s2">in </span><span class="s1">self._binomial:</span>
            <span class="s1">crossovers = rng.uniform(size=self.parameter_count)</span>
            <span class="s1">crossovers = crossovers &lt; self.cross_over_probability</span>
            <span class="s5"># the last one is always from the bprime vector for binomial</span>
            <span class="s5"># If you fill in modulo with a loop you have to set the last one to</span>
            <span class="s5"># true. If you don't use a loop then you can have any random entry</span>
            <span class="s5"># be True.</span>
            <span class="s1">crossovers[fill_point] = </span><span class="s2">True</span>
            <span class="s1">trial = np.where(crossovers</span><span class="s2">, </span><span class="s1">bprime</span><span class="s2">, </span><span class="s1">trial)</span>
            <span class="s2">return </span><span class="s1">trial</span>

        <span class="s2">elif </span><span class="s1">self.strategy </span><span class="s2">in </span><span class="s1">self._exponential:</span>
            <span class="s1">i = </span><span class="s4">0</span>
            <span class="s1">crossovers = rng.uniform(size=self.parameter_count)</span>
            <span class="s1">crossovers = crossovers &lt; self.cross_over_probability</span>
            <span class="s1">crossovers[</span><span class="s4">0</span><span class="s1">] = </span><span class="s2">True</span>
            <span class="s2">while </span><span class="s1">(i &lt; self.parameter_count </span><span class="s2">and </span><span class="s1">crossovers[i]):</span>
                <span class="s1">trial[fill_point] = bprime[fill_point]</span>
                <span class="s1">fill_point = (fill_point + </span><span class="s4">1</span><span class="s1">) % self.parameter_count</span>
                <span class="s1">i += </span><span class="s4">1</span>

            <span class="s2">return </span><span class="s1">trial</span>

    <span class="s2">def </span><span class="s1">_best1(self</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;best1bin, best1exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1 = samples[:</span><span class="s4">2</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">(self.population[</span><span class="s4">0</span><span class="s1">] + self.scale *</span>
                <span class="s1">(self.population[r0] - self.population[r1]))</span>

    <span class="s2">def </span><span class="s1">_rand1(self</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;rand1bin, rand1exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1</span><span class="s2">, </span><span class="s1">r2 = samples[:</span><span class="s4">3</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">(self.population[r0] + self.scale *</span>
                <span class="s1">(self.population[r1] - self.population[r2]))</span>

    <span class="s2">def </span><span class="s1">_randtobest1(self</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;randtobest1bin, randtobest1exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1</span><span class="s2">, </span><span class="s1">r2 = samples[:</span><span class="s4">3</span><span class="s1">]</span>
        <span class="s1">bprime = np.copy(self.population[r0])</span>
        <span class="s1">bprime += self.scale * (self.population[</span><span class="s4">0</span><span class="s1">] - bprime)</span>
        <span class="s1">bprime += self.scale * (self.population[r1] -</span>
                                <span class="s1">self.population[r2])</span>
        <span class="s2">return </span><span class="s1">bprime</span>

    <span class="s2">def </span><span class="s1">_currenttobest1(self</span><span class="s2">, </span><span class="s1">candidate</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;currenttobest1bin, currenttobest1exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1 = samples[:</span><span class="s4">2</span><span class="s1">]</span>
        <span class="s1">bprime = (self.population[candidate] + self.scale *</span>
                  <span class="s1">(self.population[</span><span class="s4">0</span><span class="s1">] - self.population[candidate] +</span>
                   <span class="s1">self.population[r0] - self.population[r1]))</span>
        <span class="s2">return </span><span class="s1">bprime</span>

    <span class="s2">def </span><span class="s1">_best2(self</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;best2bin, best2exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1</span><span class="s2">, </span><span class="s1">r2</span><span class="s2">, </span><span class="s1">r3 = samples[:</span><span class="s4">4</span><span class="s1">]</span>
        <span class="s1">bprime = (self.population[</span><span class="s4">0</span><span class="s1">] + self.scale *</span>
                  <span class="s1">(self.population[r0] + self.population[r1] -</span>
                   <span class="s1">self.population[r2] - self.population[r3]))</span>

        <span class="s2">return </span><span class="s1">bprime</span>

    <span class="s2">def </span><span class="s1">_rand2(self</span><span class="s2">, </span><span class="s1">samples):</span>
        <span class="s0">&quot;&quot;&quot;rand2bin, rand2exp&quot;&quot;&quot;</span>
        <span class="s1">r0</span><span class="s2">, </span><span class="s1">r1</span><span class="s2">, </span><span class="s1">r2</span><span class="s2">, </span><span class="s1">r3</span><span class="s2">, </span><span class="s1">r4 = samples</span>
        <span class="s1">bprime = (self.population[r0] + self.scale *</span>
                  <span class="s1">(self.population[r1] + self.population[r2] -</span>
                   <span class="s1">self.population[r3] - self.population[r4]))</span>

        <span class="s2">return </span><span class="s1">bprime</span>

    <span class="s2">def </span><span class="s1">_select_samples(self</span><span class="s2">, </span><span class="s1">candidate</span><span class="s2">, </span><span class="s1">number_samples):</span>
        <span class="s0">&quot;&quot;&quot; 
        obtain random integers from range(self.num_population_members), 
        without replacement. You can't have the original candidate either. 
        &quot;&quot;&quot;</span>
        <span class="s1">idxs = list(range(self.num_population_members))</span>
        <span class="s1">idxs.remove(candidate)</span>
        <span class="s1">self.random_number_generator.shuffle(idxs)</span>
        <span class="s1">idxs = idxs[:number_samples]</span>
        <span class="s2">return </span><span class="s1">idxs</span>


<span class="s2">class </span><span class="s1">_ConstraintWrapper:</span>
    <span class="s0">&quot;&quot;&quot;Object to wrap/evaluate user defined constraints. 
 
    Very similar in practice to `PreparedConstraint`, except that no evaluation 
    of jac/hess is performed (explicit or implicit). 
 
    If created successfully, it will contain the attributes listed below. 
 
    Parameters 
    ---------- 
    constraint : {`NonlinearConstraint`, `LinearConstraint`, `Bounds`} 
        Constraint to check and prepare. 
    x0 : array_like 
        Initial vector of independent variables, shape (N,) 
 
    Attributes 
    ---------- 
    fun : callable 
        Function defining the constraint wrapped by one of the convenience 
        classes. 
    bounds : 2-tuple 
        Contains lower and upper bounds for the constraints --- lb and ub. 
        These are converted to ndarray and have a size equal to the number of 
        the constraints. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">constraint</span><span class="s2">, </span><span class="s1">x0):</span>
        <span class="s1">self.constraint = constraint</span>

        <span class="s2">if </span><span class="s1">isinstance(constraint</span><span class="s2">, </span><span class="s1">NonlinearConstraint):</span>
            <span class="s2">def </span><span class="s1">fun(x):</span>
                <span class="s1">x = np.asarray(x)</span>
                <span class="s2">return </span><span class="s1">np.atleast_1d(constraint.fun(x))</span>
        <span class="s2">elif </span><span class="s1">isinstance(constraint</span><span class="s2">, </span><span class="s1">LinearConstraint):</span>
            <span class="s2">def </span><span class="s1">fun(x):</span>
                <span class="s2">if </span><span class="s1">issparse(constraint.A):</span>
                    <span class="s1">A = constraint.A</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">A = np.atleast_2d(constraint.A)</span>
                <span class="s2">return </span><span class="s1">A.dot(x)</span>
        <span class="s2">elif </span><span class="s1">isinstance(constraint</span><span class="s2">, </span><span class="s1">Bounds):</span>
            <span class="s2">def </span><span class="s1">fun(x):</span>
                <span class="s2">return </span><span class="s1">np.asarray(x)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;`constraint` of an unknown type is passed.&quot;</span><span class="s1">)</span>

        <span class="s1">self.fun = fun</span>

        <span class="s1">lb = np.asarray(constraint.lb</span><span class="s2">, </span><span class="s1">dtype=float)</span>
        <span class="s1">ub = np.asarray(constraint.ub</span><span class="s2">, </span><span class="s1">dtype=float)</span>

        <span class="s1">x0 = np.asarray(x0)</span>

        <span class="s5"># find out the number of constraints</span>
        <span class="s1">f0 = fun(x0)</span>
        <span class="s1">self.num_constr = m = f0.size</span>
        <span class="s1">self.parameter_count = x0.size</span>

        <span class="s2">if </span><span class="s1">lb.ndim == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">lb = np.resize(lb</span><span class="s2">, </span><span class="s1">m)</span>
        <span class="s2">if </span><span class="s1">ub.ndim == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">ub = np.resize(ub</span><span class="s2">, </span><span class="s1">m)</span>

        <span class="s1">self.bounds = (lb</span><span class="s2">, </span><span class="s1">ub)</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">np.atleast_1d(self.fun(x))</span>

    <span class="s2">def </span><span class="s1">violation(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s0">&quot;&quot;&quot;How much the constraint is exceeded by. 
 
        Parameters 
        ---------- 
        x : array-like 
            Vector of independent variables, (N, S), where N is number of 
            parameters and S is the number of solutions to be investigated. 
 
        Returns 
        ------- 
        excess : array-like 
            How much the constraint is exceeded by, for each of the 
            constraints specified by `_ConstraintWrapper.fun`. 
            Has shape (M, S) where M is the number of constraint components. 
        &quot;&quot;&quot;</span>
        <span class="s5"># expect ev to have shape (num_constr, S) or (num_constr,)</span>
        <span class="s1">ev = self.fun(np.asarray(x))</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">excess_lb = np.maximum(self.bounds[</span><span class="s4">0</span><span class="s1">] - ev.T</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">excess_ub = np.maximum(ev.T - self.bounds[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">e:</span>
            <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;An array returned from a Constraint has&quot;</span>
                               <span class="s3">&quot; the wrong shape. If `vectorized is False`&quot;</span>
                               <span class="s3">&quot; the Constraint should return an array of&quot;</span>
                               <span class="s3">&quot; shape (M,). If `vectorized is True` then&quot;</span>
                               <span class="s3">&quot; the Constraint must return an array of&quot;</span>
                               <span class="s3">&quot; shape (M, S), where S is the number of&quot;</span>
                               <span class="s3">&quot; solution vectors and M is the number of&quot;</span>
                               <span class="s3">&quot; constraint components in a given&quot;</span>
                               <span class="s3">&quot; Constraint object.&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">e</span>

        <span class="s1">v = (excess_lb + excess_ub).T</span>
        <span class="s2">return </span><span class="s1">v</span>
</pre>
</body>
</html>
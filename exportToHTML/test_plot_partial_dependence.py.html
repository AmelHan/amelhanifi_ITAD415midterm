<html>
<head>
<title>test_plot_partial_dependence.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_plot_partial_dependence.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>
<span class="s0">from </span><span class="s1">scipy.stats.mstats </span><span class="s0">import </span><span class="s1">mquantiles</span>

<span class="s0">from </span><span class="s1">sklearn.compose </span><span class="s0">import </span><span class="s1">make_column_transformer</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">load_diabetes</span><span class="s0">,</span>
    <span class="s1">load_iris</span><span class="s0">,</span>
    <span class="s1">make_classification</span><span class="s0">,</span>
    <span class="s1">make_regression</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.ensemble </span><span class="s0">import </span><span class="s1">GradientBoostingClassifier</span><span class="s0">, </span><span class="s1">GradientBoostingRegressor</span>
<span class="s0">from </span><span class="s1">sklearn.inspection </span><span class="s0">import </span><span class="s1">PartialDependenceDisplay</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LinearRegression</span>
<span class="s0">from </span><span class="s1">sklearn.pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn.preprocessing </span><span class="s0">import </span><span class="s1">OneHotEncoder</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">_convert_container</span>

<span class="s2"># TODO: Remove when https://github.com/numpy/numpy/issues/14397 is resolved</span>
<span class="s1">pytestmark = pytest.mark.filterwarnings(</span>
    <span class="s1">(</span>
        <span class="s3">&quot;ignore:In future, it will be an error for 'np.bool_':DeprecationWarning:&quot;</span>
        <span class="s3">&quot;matplotlib.*&quot;</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s1">@pytest.fixture(scope=</span><span class="s3">&quot;module&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">diabetes():</span>
    <span class="s2"># diabetes dataset, subsampled for speed</span>
    <span class="s1">data = load_diabetes()</span>
    <span class="s1">data.data = data.data[:</span><span class="s4">50</span><span class="s1">]</span>
    <span class="s1">data.target = data.target[:</span><span class="s4">50</span><span class="s1">]</span>
    <span class="s0">return </span><span class="s1">data</span>


<span class="s1">@pytest.fixture(scope=</span><span class="s3">&quot;module&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">clf_diabetes(diabetes):</span>
    <span class="s1">clf = GradientBoostingRegressor(n_estimators=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">clf.fit(diabetes.data</span><span class="s0">, </span><span class="s1">diabetes.target)</span>
    <span class="s0">return </span><span class="s1">clf</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;grid_resolution&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">10</span><span class="s0">, </span><span class="s4">20</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence(grid_resolution</span><span class="s0">, </span><span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes):</span>
    <span class="s2"># Test partial dependence plot function.</span>
    <span class="s2"># Use columns 0 &amp; 2 as 1 is not quantitative (sex)</span>
    <span class="s1">feature_names = diabetes.feature_names</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
        <span class="s1">contour_kw={</span><span class="s3">&quot;cmap&quot;</span><span class="s1">: </span><span class="s3">&quot;jet&quot;</span><span class="s1">}</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">fig = pyplot.gcf()</span>
    <span class="s1">axs = fig.get_axes()</span>
    <span class="s0">assert </span><span class="s1">disp.figure_ </span><span class="s0">is </span><span class="s1">fig</span>
    <span class="s0">assert </span><span class="s1">len(axs) == </span><span class="s4">4</span>

    <span class="s0">assert </span><span class="s1">disp.bounding_ax_ </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">disp.axes_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.lines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">] </span><span class="s0">is None</span>

    <span class="s2"># deciles lines: always show on xaxis, only show on yaxis if 2-way PDP</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s4">3</span><span class="s1">):</span>
        <span class="s0">assert </span><span class="s1">disp.deciles_vlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s1">i] </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">] </span><span class="s0">is not None</span>

    <span class="s0">assert </span><span class="s1">disp.features == [(</span><span class="s4">0</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">2</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span>
    <span class="s0">assert </span><span class="s1">np.all(disp.feature_names == feature_names)</span>
    <span class="s0">assert </span><span class="s1">len(disp.deciles) == </span><span class="s4">2</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]:</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">disp.deciles[i]</span><span class="s0">,</span>
            <span class="s1">mquantiles(diabetes.data[:</span><span class="s0">, </span><span class="s1">i]</span><span class="s0">, </span><span class="s1">prob=np.arange(</span><span class="s4">0.1</span><span class="s0">, </span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">0.1</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">)</span>

    <span class="s1">single_feature_positions = [(</span><span class="s4">0</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">))</span><span class="s0">, </span><span class="s1">(</span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">))]</span>
    <span class="s1">expected_ylabels = [</span><span class="s3">&quot;Partial dependence&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s1">]</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">(feat_col</span><span class="s0">, </span><span class="s1">pos) </span><span class="s0">in </span><span class="s1">enumerate(single_feature_positions):</span>
        <span class="s1">ax = disp.axes_[pos]</span>
        <span class="s0">assert </span><span class="s1">ax.get_ylabel() == expected_ylabels[i]</span>
        <span class="s0">assert </span><span class="s1">ax.get_xlabel() == diabetes.feature_names[feat_col]</span>

        <span class="s1">line = disp.lines_[pos]</span>

        <span class="s1">avg_preds = disp.pd_results[i]</span>
        <span class="s0">assert </span><span class="s1">avg_preds.average.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s1">grid_resolution)</span>
        <span class="s1">target_idx = disp.target_idx</span>

        <span class="s1">line_data = line.get_data()</span>
        <span class="s1">assert_allclose(line_data[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds[</span><span class="s3">&quot;grid_values&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">assert_allclose(line_data[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds.average[target_idx].ravel())</span>

    <span class="s2"># two feature position</span>
    <span class="s1">ax = disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">coutour = disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">coutour.get_cmap().name == </span><span class="s3">&quot;jet&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == diabetes.feature_names[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == diabetes.feature_names[</span><span class="s4">2</span><span class="s1">]</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kind, centered, subsample, shape&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">&quot;average&quot;</span><span class="s0">, False, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, False, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">50</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, False, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">51</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, False, </span><span class="s4">20</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">20</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, False, </span><span class="s4">20</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">21</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, False, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">25</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, False, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">26</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;average&quot;</span><span class="s0">, True, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, True, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">50</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, True, None, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">51</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, True, </span><span class="s4">20</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">20</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, True, </span><span class="s4">20</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s0">, </span><span class="s4">21</span><span class="s1">))</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_kind(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">kind</span><span class="s0">,</span>
    <span class="s1">centered</span><span class="s0">,</span>
    <span class="s1">subsample</span><span class="s0">,</span>
    <span class="s1">shape</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">centered=centered</span><span class="s0">,</span>
        <span class="s1">subsample=subsample</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.axes_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.lines_.shape == shape</span>
    <span class="s0">assert </span><span class="s1">disp.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">] </span><span class="s0">is None</span>

    <span class="s0">if </span><span class="s1">centered:</span>
        <span class="s0">assert </span><span class="s1">all([ln._y[</span><span class="s4">0</span><span class="s1">] == </span><span class="s4">0.0 </span><span class="s0">for </span><span class="s1">ln </span><span class="s0">in </span><span class="s1">disp.lines_.ravel() </span><span class="s0">if </span><span class="s1">ln </span><span class="s0">is not None</span><span class="s1">])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">all([ln._y[</span><span class="s4">0</span><span class="s1">] != </span><span class="s4">0.0 </span><span class="s0">for </span><span class="s1">ln </span><span class="s0">in </span><span class="s1">disp.lines_.ravel() </span><span class="s0">if </span><span class="s1">ln </span><span class="s0">is not None</span><span class="s1">])</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;input_type, feature_names_type&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">, </span><span class="s3">&quot;list&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;list&quot;</span><span class="s0">, </span><span class="s3">&quot;list&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;array&quot;</span><span class="s0">, </span><span class="s3">&quot;list&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;list&quot;</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;array&quot;</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">, </span><span class="s3">&quot;series&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;list&quot;</span><span class="s0">, </span><span class="s3">&quot;series&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;array&quot;</span><span class="s0">, </span><span class="s3">&quot;series&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;dataframe&quot;</span><span class="s0">, </span><span class="s3">&quot;index&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;list&quot;</span><span class="s0">, </span><span class="s3">&quot;index&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;array&quot;</span><span class="s0">, </span><span class="s3">&quot;index&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_str_features(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
    <span class="s1">input_type</span><span class="s0">,</span>
    <span class="s1">feature_names_type</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s0">if </span><span class="s1">input_type == </span><span class="s3">&quot;dataframe&quot;</span><span class="s1">:</span>
        <span class="s1">pd = pytest.importorskip(</span><span class="s3">&quot;pandas&quot;</span><span class="s1">)</span>
        <span class="s1">X = pd.DataFrame(diabetes.data</span><span class="s0">, </span><span class="s1">columns=diabetes.feature_names)</span>
    <span class="s0">elif </span><span class="s1">input_type == </span><span class="s3">&quot;list&quot;</span><span class="s1">:</span>
        <span class="s1">X = diabetes.data.tolist()</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">X = diabetes.data</span>

    <span class="s0">if </span><span class="s1">feature_names_type </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">feature_names = </span><span class="s0">None</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">feature_names = _convert_container(diabetes.feature_names</span><span class="s0">, </span><span class="s1">feature_names_type)</span>

    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s2"># check with str features and array feature names and single column</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">[(</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">)</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
        <span class="s1">n_cols=</span><span class="s4">1</span><span class="s0">,</span>
        <span class="s1">line_kw={</span><span class="s3">&quot;alpha&quot;</span><span class="s1">: </span><span class="s4">0.8</span><span class="s1">}</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">fig = pyplot.gcf()</span>
    <span class="s1">axs = fig.get_axes()</span>
    <span class="s0">assert </span><span class="s1">len(axs) == </span><span class="s4">3</span>

    <span class="s0">assert </span><span class="s1">disp.figure_ </span><span class="s0">is </span><span class="s1">fig</span>
    <span class="s0">assert </span><span class="s1">disp.axes_.shape == (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.lines_.shape == (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.contours_.shape == (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_.shape == (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_.shape == (</span><span class="s4">2</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] </span><span class="s0">is not None</span>

    <span class="s2"># line</span>
    <span class="s1">ax = disp.axes_[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;bmi&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;Partial dependence&quot;</span>

    <span class="s1">line = disp.lines_[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">avg_preds = disp.pd_results[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">target_idx = disp.target_idx</span>
    <span class="s0">assert </span><span class="s1">line.get_alpha() == </span><span class="s4">0.8</span>

    <span class="s1">line_data = line.get_data()</span>
    <span class="s1">assert_allclose(line_data[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds[</span><span class="s3">&quot;grid_values&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">assert_allclose(line_data[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds.average[target_idx].ravel())</span>

    <span class="s2"># contour</span>
    <span class="s1">ax = disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;age&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;bmi&quot;</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_custom_axes(pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes):</span>
    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">(ax1</span><span class="s0">, </span><span class="s1">ax2) = pyplot.subplots(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">)]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
        <span class="s1">ax=[ax1</span><span class="s0">, </span><span class="s1">ax2]</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">fig </span><span class="s0">is </span><span class="s1">disp.figure_</span>
    <span class="s0">assert </span><span class="s1">disp.bounding_ax_ </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.axes_.shape == (</span><span class="s4">2</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.axes_[</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is </span><span class="s1">ax1</span>
    <span class="s0">assert </span><span class="s1">disp.axes_[</span><span class="s4">1</span><span class="s1">] </span><span class="s0">is </span><span class="s1">ax2</span>

    <span class="s1">ax = disp.axes_[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;age&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;Partial dependence&quot;</span>

    <span class="s1">line = disp.lines_[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">avg_preds = disp.pd_results[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">target_idx = disp.target_idx</span>

    <span class="s1">line_data = line.get_data()</span>
    <span class="s1">assert_allclose(line_data[</span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds[</span><span class="s3">&quot;grid_values&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">assert_allclose(line_data[</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">avg_preds.average[target_idx].ravel())</span>

    <span class="s2"># contour</span>
    <span class="s1">ax = disp.axes_[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;age&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;bmi&quot;</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kind, lines&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s4">50</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s4">51</span><span class="s1">)]</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_passing_numpy_axes(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span><span class="s0">, </span><span class="s1">kind</span><span class="s0">, </span><span class="s1">lines</span>
<span class="s1">):</span>
    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">feature_names = diabetes.feature_names</span>
    <span class="s1">disp1 = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp1.axes_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp1.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_ylabel() == </span><span class="s3">&quot;Partial dependence&quot;</span>
    <span class="s0">assert </span><span class="s1">disp1.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].get_ylabel() == </span><span class="s3">&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">len(disp1.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_lines()) == lines</span>
    <span class="s0">assert </span><span class="s1">len(disp1.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].get_lines()) == lines</span>

    <span class="s1">lr = LinearRegression()</span>
    <span class="s1">lr.fit(diabetes.data</span><span class="s0">, </span><span class="s1">diabetes.target)</span>

    <span class="s1">disp2 = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">lr</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
        <span class="s1">ax=disp1.axes_</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.all(disp1.axes_ == disp2.axes_)</span>
    <span class="s0">assert </span><span class="s1">len(disp2.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_lines()) == </span><span class="s4">2 </span><span class="s1">* lines</span>
    <span class="s0">assert </span><span class="s1">len(disp2.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].get_lines()) == </span><span class="s4">2 </span><span class="s1">* lines</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;nrows, ncols&quot;</span><span class="s0">, </span><span class="s1">[(</span><span class="s4">2</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">3</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)])</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_incorrent_num_axes(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span><span class="s0">, </span><span class="s1">nrows</span><span class="s0">, </span><span class="s1">ncols</span>
<span class="s1">):</span>
    <span class="s1">grid_resolution = </span><span class="s4">5</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">axes = pyplot.subplots(nrows</span><span class="s0">, </span><span class="s1">ncols)</span>
    <span class="s1">axes_formats = [list(axes.ravel())</span><span class="s0">, </span><span class="s1">tuple(axes.ravel())</span><span class="s0">, </span><span class="s1">axes]</span>

    <span class="s1">msg = </span><span class="s3">&quot;Expected ax to have 2 axes, got {}&quot;</span><span class="s1">.format(nrows * ncols)</span>

    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">ax_format </span><span class="s0">in </span><span class="s1">axes_formats:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">PartialDependenceDisplay.from_estimator(</span>
                <span class="s1">clf_diabetes</span><span class="s0">,</span>
                <span class="s1">diabetes.data</span><span class="s0">,</span>
                <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
                <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
                <span class="s1">ax=ax_format</span><span class="s0">,</span>
            <span class="s1">)</span>

        <span class="s2"># with axes object</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
            <span class="s1">disp.plot(ax=ax_format)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_with_same_axes(pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes):</span>
    <span class="s2"># The first call to plot_partial_dependence will create two new axes to</span>
    <span class="s2"># place in the space of the passed in axes, which results in a total of</span>
    <span class="s2"># three axes in the figure.</span>
    <span class="s2"># Currently the API does not allow for the second call to</span>
    <span class="s2"># plot_partial_dependence to use the same axes again, because it will</span>
    <span class="s2"># create two new axes in the space resulting in five axes. To get the</span>
    <span class="s2"># expected behavior one needs to pass the generated axes into the second</span>
    <span class="s2"># call:</span>
    <span class="s2"># disp1 = plot_partial_dependence(...)</span>
    <span class="s2"># disp2 = plot_partial_dependence(..., ax=disp1.axes_)</span>

    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
        <span class="s1">ax=ax</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">msg = (</span>
        <span class="s3">&quot;The ax was already used in another plot function, please set &quot;</span>
        <span class="s3">&quot;ax=display.axes_ instead&quot;</span>
    <span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">PartialDependenceDisplay.from_estimator(</span>
            <span class="s1">clf_diabetes</span><span class="s0">,</span>
            <span class="s1">diabetes.data</span><span class="s0">,</span>
            <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
            <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
            <span class="s1">ax=ax</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_feature_name_reuse(pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes):</span>
    <span class="s2"># second call to plot does not change the feature names from the first</span>
    <span class="s2"># call</span>

    <span class="s1">feature_names = diabetes.feature_names</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">10</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes.data</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">grid_resolution=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">ax=disp.axes_</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">enumerate(disp.axes_.ravel()):</span>
        <span class="s0">assert </span><span class="s1">ax.get_xlabel() == feature_names[i]</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_multiclass(pyplot):</span>
    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">clf_int = GradientBoostingClassifier(n_estimators=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">iris = load_iris()</span>

    <span class="s2"># Test partial dependence plot function on multi-class input.</span>
    <span class="s1">clf_int.fit(iris.data</span><span class="s0">, </span><span class="s1">iris.target)</span>
    <span class="s1">disp_target_0 = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_int</span><span class="s0">, </span><span class="s1">iris.data</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">target=</span><span class="s4">0</span><span class="s0">, </span><span class="s1">grid_resolution=grid_resolution</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.figure_ </span><span class="s0">is </span><span class="s1">pyplot.gcf()</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.axes_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.lines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.deciles_vlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.deciles_hlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">all(c </span><span class="s0">is None for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">disp_target_0.contours_.flat)</span>
    <span class="s0">assert </span><span class="s1">disp_target_0.target_idx == </span><span class="s4">0</span>

    <span class="s2"># now with symbol labels</span>
    <span class="s1">target = iris.target_names[iris.target]</span>
    <span class="s1">clf_symbol = GradientBoostingClassifier(n_estimators=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">clf_symbol.fit(iris.data</span><span class="s0">, </span><span class="s1">target)</span>
    <span class="s1">disp_symbol = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_symbol</span><span class="s0">, </span><span class="s1">iris.data</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">target=</span><span class="s3">&quot;setosa&quot;</span><span class="s0">, </span><span class="s1">grid_resolution=grid_resolution</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.figure_ </span><span class="s0">is </span><span class="s1">pyplot.gcf()</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.axes_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.lines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.deciles_vlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.deciles_hlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">all(c </span><span class="s0">is None for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">disp_symbol.contours_.flat)</span>
    <span class="s0">assert </span><span class="s1">disp_symbol.target_idx == </span><span class="s4">0</span>

    <span class="s0">for </span><span class="s1">int_result</span><span class="s0">, </span><span class="s1">symbol_result </span><span class="s0">in </span><span class="s1">zip(</span>
        <span class="s1">disp_target_0.pd_results</span><span class="s0">, </span><span class="s1">disp_symbol.pd_results</span>
    <span class="s1">):</span>
        <span class="s1">assert_allclose(int_result.average</span><span class="s0">, </span><span class="s1">symbol_result.average)</span>
        <span class="s1">assert_allclose(int_result[</span><span class="s3">&quot;grid_values&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">symbol_result[</span><span class="s3">&quot;grid_values&quot;</span><span class="s1">])</span>

    <span class="s2"># check that the pd plots are different for another target</span>
    <span class="s1">disp_target_1 = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_int</span><span class="s0">, </span><span class="s1">iris.data</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">target=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">grid_resolution=grid_resolution</span>
    <span class="s1">)</span>
    <span class="s1">target_0_data_y = disp_target_0.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_data()[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s1">target_1_data_y = disp_target_1.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_data()[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">any(target_0_data_y != target_1_data_y)</span>


<span class="s1">multioutput_regression_data = make_regression(n_samples=</span><span class="s4">50</span><span class="s0">, </span><span class="s1">n_targets=</span><span class="s4">2</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;target&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_multioutput(pyplot</span><span class="s0">, </span><span class="s1">target):</span>
    <span class="s2"># Test partial dependence plot function on multi-output input.</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = multioutput_regression_data</span>
    <span class="s1">clf = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">target=target</span><span class="s0">, </span><span class="s1">grid_resolution=grid_resolution</span>
    <span class="s1">)</span>
    <span class="s1">fig = pyplot.gcf()</span>
    <span class="s1">axs = fig.get_axes()</span>
    <span class="s0">assert </span><span class="s1">len(axs) == </span><span class="s4">3</span>
    <span class="s0">assert </span><span class="s1">disp.target_idx == target</span>
    <span class="s0">assert </span><span class="s1">disp.bounding_ax_ </span><span class="s0">is not None</span>

    <span class="s1">positions = [(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)]</span>
    <span class="s1">expected_label = [</span><span class="s3">&quot;Partial dependence&quot;</span><span class="s0">, </span><span class="s3">&quot;&quot;</span><span class="s1">]</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">pos </span><span class="s0">in </span><span class="s1">enumerate(positions):</span>
        <span class="s1">ax = disp.axes_[pos]</span>
        <span class="s0">assert </span><span class="s1">ax.get_ylabel() == expected_label[i]</span>
        <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">f&quot;x</span><span class="s0">{</span><span class="s1">i</span><span class="s0">}</span><span class="s3">&quot;</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_dataframe(pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes):</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s3">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">df = pd.DataFrame(diabetes.data</span><span class="s0">, </span><span class="s1">columns=diabetes.feature_names)</span>

    <span class="s1">grid_resolution = </span><span class="s4">25</span>

    <span class="s1">PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">df</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;bp&quot;</span><span class="s0">, </span><span class="s3">&quot;s1&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=df.columns.tolist()</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">dummy_classification_data = make_classification(random_state=</span><span class="s4">0</span><span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;data, params, err_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">multioutput_regression_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;target&quot;</span><span class="s1">: </span><span class="s0">None, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;target must be specified for multi-output&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">multioutput_regression_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;target&quot;</span><span class="s1">: -</span><span class="s4">1</span><span class="s0">, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">r&quot;target must be in \[0, n_tasks\]&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">multioutput_regression_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;target&quot;</span><span class="s1">: </span><span class="s4">100</span><span class="s0">, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">r&quot;target must be in \[0, n_tasks\]&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s3">&quot;foobar&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;feature_names&quot;</span><span class="s1">: </span><span class="s0">None</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">&quot;Feature 'foobar' not in feature_names&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s3">&quot;foobar&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;feature_names&quot;</span><span class="s1">: [</span><span class="s3">&quot;abcd&quot;</span><span class="s0">, </span><span class="s3">&quot;def&quot;</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;Feature 'foobar' not in feature_names&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">3</span><span class="s1">)]}</span><span class="s0">,</span>
            <span class="s3">&quot;Each entry in features must be either an int, &quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s1">{}]}</span><span class="s0">,</span>
            <span class="s3">&quot;Each entry in features must be either an int, &quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [tuple()]}</span><span class="s0">,</span>
            <span class="s3">&quot;Each entry in features must be either an int, &quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">123</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;feature_names&quot;</span><span class="s1">: [</span><span class="s3">&quot;blahblah&quot;</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;All entries of features must be less than &quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;feature_names&quot;</span><span class="s1">: [</span><span class="s3">&quot;a&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s0">, </span><span class="s3">&quot;a&quot;</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;feature_names should not contain duplicates&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;kind&quot;</span><span class="s1">: [</span><span class="s3">&quot;both&quot;</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;When `kind` is provided as a list of strings, it should contain&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;subsample&quot;</span><span class="s1">: -</span><span class="s4">1</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">&quot;When an integer, subsample=-1 should be positive.&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;subsample&quot;</span><span class="s1">: </span><span class="s4">1.2</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">r&quot;When a floating-point, subsample=1.2 should be in the \(0, 1\) range&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;categorical_features&quot;</span><span class="s1">: [</span><span class="s4">1.0</span><span class="s0">, </span><span class="s4">2.0</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;Expected `categorical_features` to be an array-like of boolean,&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s3">&quot;categorical_features&quot;</span><span class="s1">: [</span><span class="s4">2</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;Two-way partial dependence plots are not supported for pairs&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">dummy_classification_data</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;categorical_features&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;kind&quot;</span><span class="s1">: </span><span class="s3">&quot;individual&quot;</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">&quot;It is not possible to display individual effects&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_error(pyplot</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">params</span><span class="s0">, </span><span class="s1">err_msg):</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = data</span>
    <span class="s1">estimator = LinearRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">PartialDependenceDisplay.from_estimator(estimator</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">**params)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;params, err_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">({</span><span class="s3">&quot;target&quot;</span><span class="s1">: </span><span class="s4">4</span><span class="s0">, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s1">]}</span><span class="s0">, </span><span class="s3">&quot;target not in est.classes_, got 4&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;target&quot;</span><span class="s1">: </span><span class="s0">None, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">0</span><span class="s1">]}</span><span class="s0">, </span><span class="s3">&quot;target must be specified for multi-class&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">{</span><span class="s3">&quot;target&quot;</span><span class="s1">: </span><span class="s4">1</span><span class="s0">, </span><span class="s3">&quot;features&quot;</span><span class="s1">: [</span><span class="s4">4.5</span><span class="s1">]}</span><span class="s0">,</span>
            <span class="s3">&quot;Each entry in features must be either an int,&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_multiclass_error(pyplot</span><span class="s0">, </span><span class="s1">params</span><span class="s0">, </span><span class="s1">err_msg):</span>
    <span class="s1">iris = load_iris()</span>
    <span class="s1">clf = GradientBoostingClassifier(n_estimators=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">clf.fit(iris.data</span><span class="s0">, </span><span class="s1">iris.target)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">PartialDependenceDisplay.from_estimator(clf</span><span class="s0">, </span><span class="s1">iris.data</span><span class="s0">, </span><span class="s1">**params)</span>


<span class="s0">def </span><span class="s1">test_plot_partial_dependence_does_not_override_ylabel(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span>
<span class="s1">):</span>
    <span class="s2"># Non-regression test to be sure to not override the ylabel if it has been</span>
    <span class="s2"># See https://github.com/scikit-learn/scikit-learn/issues/15772</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">axes = pyplot.subplots(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">axes[</span><span class="s4">0</span><span class="s1">].set_ylabel(</span><span class="s3">&quot;Hello world&quot;</span><span class="s1">)</span>
    <span class="s1">PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes.data</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">ax=axes</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">axes[</span><span class="s4">0</span><span class="s1">].get_ylabel() == </span><span class="s3">&quot;Hello world&quot;</span>
    <span class="s0">assert </span><span class="s1">axes[</span><span class="s4">1</span><span class="s1">].get_ylabel() == </span><span class="s3">&quot;Partial dependence&quot;</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;categorical_features, array_type&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;dataframe&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s0">True, False, True</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_with_categorical(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">categorical_features</span><span class="s0">, </span><span class="s1">array_type</span>
<span class="s1">):</span>
    <span class="s1">X = [[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s3">&quot;A&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">2</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s3">&quot;C&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">3</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s3">&quot;B&quot;</span><span class="s1">]]</span>
    <span class="s1">column_name = [</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_B&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span>
    <span class="s1">X = _convert_container(X</span><span class="s0">, </span><span class="s1">array_type</span><span class="s0">, </span><span class="s1">columns_name=column_name)</span>
    <span class="s1">y = np.array([</span><span class="s4">1.2</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.45</span><span class="s1">]).T</span>

    <span class="s1">preprocessor = make_column_transformer((OneHotEncoder()</span><span class="s0">, </span><span class="s1">categorical_features))</span>
    <span class="s1">model = make_pipeline(preprocessor</span><span class="s0">, </span><span class="s1">LinearRegression())</span>
    <span class="s1">model.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># single feature</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">model</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">features=[</span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">feature_names=column_name</span><span class="s0">,</span>
        <span class="s1">categorical_features=categorical_features</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.figure_ </span><span class="s0">is </span><span class="s1">pyplot.gcf()</span>
    <span class="s0">assert </span><span class="s1">disp.bars_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.bars_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">disp.lines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_legend() </span><span class="s0">is None</span>

    <span class="s2"># interaction between two features</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">model</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">features=[(</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">)]</span><span class="s0">,</span>
        <span class="s1">feature_names=column_name</span><span class="s0">,</span>
        <span class="s1">categorical_features=categorical_features</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp.figure_ </span><span class="s0">is </span><span class="s1">pyplot.gcf()</span>
    <span class="s0">assert </span><span class="s1">disp.bars_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.bars_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.lines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.contours_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_vlines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_.shape == (</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">disp.deciles_hlines_[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">] </span><span class="s0">is None</span>
    <span class="s0">assert </span><span class="s1">disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_legend() </span><span class="s0">is None</span>


<span class="s0">def </span><span class="s1">test_plot_partial_dependence_legend(pyplot):</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s3">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">X = pd.DataFrame(</span>
        <span class="s1">{</span>
            <span class="s3">&quot;col_A&quot;</span><span class="s1">: [</span><span class="s3">&quot;A&quot;</span><span class="s0">, </span><span class="s3">&quot;B&quot;</span><span class="s0">, </span><span class="s3">&quot;C&quot;</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s3">&quot;col_B&quot;</span><span class="s1">: [</span><span class="s4">1</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s3">&quot;col_C&quot;</span><span class="s1">: [</span><span class="s3">&quot;C&quot;</span><span class="s0">, </span><span class="s3">&quot;B&quot;</span><span class="s0">, </span><span class="s3">&quot;A&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">}</span>
    <span class="s1">)</span>
    <span class="s1">y = np.array([</span><span class="s4">1.2</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.45</span><span class="s1">]).T</span>

    <span class="s1">categorical_features = [</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span>
    <span class="s1">preprocessor = make_column_transformer((OneHotEncoder()</span><span class="s0">, </span><span class="s1">categorical_features))</span>
    <span class="s1">model = make_pipeline(preprocessor</span><span class="s0">, </span><span class="s1">LinearRegression())</span>
    <span class="s1">model.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">model</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">features=[</span><span class="s3">&quot;col_B&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">categorical_features=categorical_features</span><span class="s0">,</span>
        <span class="s1">kind=[</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;average&quot;</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">legend_text = disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].get_legend().get_texts()</span>
    <span class="s0">assert </span><span class="s1">len(legend_text) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">legend_text[</span><span class="s4">0</span><span class="s1">].get_text() == </span><span class="s3">&quot;average&quot;</span>
    <span class="s0">assert </span><span class="s1">disp.axes_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].get_legend() </span><span class="s0">is None</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kind, expected_shape&quot;</span><span class="s0">,</span>
    <span class="s1">[(</span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">))</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">20</span><span class="s1">))</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s4">21</span><span class="s1">))]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_subsampling(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span><span class="s0">, </span><span class="s1">kind</span><span class="s0">, </span><span class="s1">expected_shape</span>
<span class="s1">):</span>
    <span class="s2"># check that the subsampling is properly working</span>
    <span class="s2"># non-regression test for:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/pull/18359</span>
    <span class="s1">matplotlib = pytest.importorskip(</span><span class="s3">&quot;matplotlib&quot;</span><span class="s1">)</span>
    <span class="s1">grid_resolution = </span><span class="s4">25</span>
    <span class="s1">feature_names = diabetes.feature_names</span>

    <span class="s1">disp1 = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">&quot;age&quot;</span><span class="s0">, </span><span class="s3">&quot;bmi&quot;</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">grid_resolution=grid_resolution</span><span class="s0">,</span>
        <span class="s1">feature_names=feature_names</span><span class="s0">,</span>
        <span class="s1">subsample=</span><span class="s4">20</span><span class="s0">,</span>
        <span class="s1">random_state=</span><span class="s4">0</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">disp1.lines_.shape == expected_shape</span>
    <span class="s0">assert </span><span class="s1">all(</span>
        <span class="s1">[isinstance(line</span><span class="s0">, </span><span class="s1">matplotlib.lines.Line2D) </span><span class="s0">for </span><span class="s1">line </span><span class="s0">in </span><span class="s1">disp1.lines_.ravel()]</span>
    <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kind, line_kw, label&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s1">{}</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;label&quot;</span><span class="s1">: </span><span class="s3">&quot;xxx&quot;</span><span class="s1">}</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s1">{}</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;label&quot;</span><span class="s1">: </span><span class="s3">&quot;xxx&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s3">&quot;xxx&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s1">{}</span><span class="s0">, </span><span class="s3">&quot;average&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;label&quot;</span><span class="s1">: </span><span class="s3">&quot;xxx&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s3">&quot;xxx&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_partial_dependence_overwrite_labels(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
    <span class="s1">kind</span><span class="s0">,</span>
    <span class="s1">line_kw</span><span class="s0">,</span>
    <span class="s1">label</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Test that make sure that we can overwrite the label of the PDP plot&quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">25</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">line_kw=line_kw</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">disp.axes_.ravel():</span>
        <span class="s0">if </span><span class="s1">label </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">ax.get_legend() </span><span class="s0">is None</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">legend_text = ax.get_legend().get_texts()</span>
            <span class="s0">assert </span><span class="s1">len(legend_text) == </span><span class="s4">1</span>
            <span class="s0">assert </span><span class="s1">legend_text[</span><span class="s4">0</span><span class="s1">].get_text() == label</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;categorical_features, array_type&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;dataframe&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s0">True, False, True</span><span class="s1">]</span><span class="s0">, </span><span class="s3">&quot;array&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_grid_resolution_with_categorical(pyplot</span><span class="s0">, </span><span class="s1">categorical_features</span><span class="s0">, </span><span class="s1">array_type):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise a ValueError when the grid_resolution is too small 
    respect to the number of categories in the categorical features targeted. 
    &quot;&quot;&quot;</span>
    <span class="s1">X = [[</span><span class="s3">&quot;A&quot;</span><span class="s0">, </span><span class="s4">1</span><span class="s0">, </span><span class="s3">&quot;A&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;B&quot;</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s3">&quot;C&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;C&quot;</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s3">&quot;B&quot;</span><span class="s1">]]</span>
    <span class="s1">column_name = [</span><span class="s3">&quot;col_A&quot;</span><span class="s0">, </span><span class="s3">&quot;col_B&quot;</span><span class="s0">, </span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span>
    <span class="s1">X = _convert_container(X</span><span class="s0">, </span><span class="s1">array_type</span><span class="s0">, </span><span class="s1">columns_name=column_name)</span>
    <span class="s1">y = np.array([</span><span class="s4">1.2</span><span class="s0">, </span><span class="s4">0.5</span><span class="s0">, </span><span class="s4">0.45</span><span class="s1">]).T</span>

    <span class="s1">preprocessor = make_column_transformer((OneHotEncoder()</span><span class="s0">, </span><span class="s1">categorical_features))</span>
    <span class="s1">model = make_pipeline(preprocessor</span><span class="s0">, </span><span class="s1">LinearRegression())</span>
    <span class="s1">model.fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">err_msg = (</span>
        <span class="s3">&quot;resolution of the computed grid is less than the minimum number of categories&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">PartialDependenceDisplay.from_estimator(</span>
            <span class="s1">model</span><span class="s0">,</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">features=[</span><span class="s3">&quot;col_C&quot;</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s1">feature_names=column_name</span><span class="s0">,</span>
            <span class="s1">categorical_features=categorical_features</span><span class="s0">,</span>
            <span class="s1">grid_resolution=</span><span class="s4">2</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;kind&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">])</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;centered&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_partial_dependence_plot_limits_one_way(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span><span class="s0">, </span><span class="s1">kind</span><span class="s0">, </span><span class="s1">centered</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that the PD limit on the plots are properly set on one-way plots.&quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">features=(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">25</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">range_pd = np.array([-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s0">for </span><span class="s1">pd </span><span class="s0">in </span><span class="s1">disp.pd_results:</span>
        <span class="s0">if </span><span class="s3">&quot;average&quot; </span><span class="s0">in </span><span class="s1">pd:</span>
            <span class="s1">pd[</span><span class="s3">&quot;average&quot;</span><span class="s1">][...] = range_pd[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">pd[</span><span class="s3">&quot;average&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] = range_pd[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s3">&quot;individual&quot; </span><span class="s0">in </span><span class="s1">pd:</span>
            <span class="s1">pd[</span><span class="s3">&quot;individual&quot;</span><span class="s1">][...] = range_pd[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">pd[</span><span class="s3">&quot;individual&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] = range_pd[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">disp.plot(centered=centered)</span>
    <span class="s2"># check that we anchor to zero x-axis when centering</span>
    <span class="s1">y_lim = range_pd - range_pd[</span><span class="s4">0</span><span class="s1">] </span><span class="s0">if </span><span class="s1">centered </span><span class="s0">else </span><span class="s1">range_pd</span>
    <span class="s1">padding = </span><span class="s4">0.05 </span><span class="s1">* (y_lim[</span><span class="s4">1</span><span class="s1">] - y_lim[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">y_lim[</span><span class="s4">0</span><span class="s1">] -= padding</span>
    <span class="s1">y_lim[</span><span class="s4">1</span><span class="s1">] += padding</span>
    <span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">disp.axes_.ravel():</span>
        <span class="s1">assert_allclose(ax.get_ylim()</span><span class="s0">, </span><span class="s1">y_lim)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;centered&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_partial_dependence_plot_limits_two_way(</span>
    <span class="s1">pyplot</span><span class="s0">, </span><span class="s1">clf_diabetes</span><span class="s0">, </span><span class="s1">diabetes</span><span class="s0">, </span><span class="s1">centered</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that the PD limit on the plots are properly set on two-way plots.&quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">features=[(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)]</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s3">&quot;average&quot;</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">25</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">range_pd = np.array([-</span><span class="s4">1</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s0">for </span><span class="s1">pd </span><span class="s0">in </span><span class="s1">disp.pd_results:</span>
        <span class="s1">pd[</span><span class="s3">&quot;average&quot;</span><span class="s1">][...] = range_pd[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">pd[</span><span class="s3">&quot;average&quot;</span><span class="s1">][</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">] = range_pd[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">disp.plot(centered=centered)</span>
    <span class="s1">contours = disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">levels = range_pd - range_pd[</span><span class="s4">0</span><span class="s1">] </span><span class="s0">if </span><span class="s1">centered </span><span class="s0">else </span><span class="s1">range_pd</span>

    <span class="s1">padding = </span><span class="s4">0.05 </span><span class="s1">* (levels[</span><span class="s4">1</span><span class="s1">] - levels[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s1">levels[</span><span class="s4">0</span><span class="s1">] -= padding</span>
    <span class="s1">levels[</span><span class="s4">1</span><span class="s1">] += padding</span>
    <span class="s1">expect_levels = np.linspace(*levels</span><span class="s0">, </span><span class="s1">num=</span><span class="s4">8</span><span class="s1">)</span>
    <span class="s1">assert_allclose(contours.levels</span><span class="s0">, </span><span class="s1">expect_levels)</span>


<span class="s0">def </span><span class="s1">test_partial_dependence_kind_list(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that we can provide a list of strings to kind parameter.&quot;&quot;&quot;</span>
    <span class="s1">matplotlib = pytest.importorskip(</span><span class="s3">&quot;matplotlib&quot;</span><span class="s1">)</span>

    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">features=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">20</span><span class="s0">,</span>
        <span class="s1">kind=[</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;average&quot;</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">idx </span><span class="s0">in </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]:</span>
        <span class="s0">assert </span><span class="s1">all(</span>
            <span class="s1">[</span>
                <span class="s1">isinstance(line</span><span class="s0">, </span><span class="s1">matplotlib.lines.Line2D)</span>
                <span class="s0">for </span><span class="s1">line </span><span class="s0">in </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s1">idx].ravel()</span>
            <span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s1">idx] </span><span class="s0">is None</span>

    <span class="s0">assert </span><span class="s1">disp.contours_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">] </span><span class="s0">is not None</span>
    <span class="s0">assert </span><span class="s1">all([line </span><span class="s0">is None for </span><span class="s1">line </span><span class="s0">in </span><span class="s1">disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">].ravel()])</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;features, kind&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s3">&quot;individual&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s3">&quot;individual&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s3">&quot;individual&quot;</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s0">, </span><span class="s1">(</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">)]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">])</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_partial_dependence_kind_error(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
    <span class="s1">features</span><span class="s0">,</span>
    <span class="s1">kind</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise an informative error when 2-way PD is requested 
    together with 1-way PD/ICE&quot;&quot;&quot;</span>
    <span class="s1">warn_msg = (</span>
        <span class="s3">&quot;ICE plot cannot be rendered for 2-way feature interactions. 2-way &quot;</span>
        <span class="s3">&quot;feature interactions mandates PD plots using the 'average' kind&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=warn_msg):</span>
        <span class="s1">PartialDependenceDisplay.from_estimator(</span>
            <span class="s1">clf_diabetes</span><span class="s0">,</span>
            <span class="s1">diabetes.data</span><span class="s0">,</span>
            <span class="s1">features=features</span><span class="s0">,</span>
            <span class="s1">grid_resolution=</span><span class="s4">20</span><span class="s0">,</span>
            <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s3">&quot;ignore:A Bunch will be returned&quot;</span><span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;line_kw, pd_line_kw, ice_lines_kw, expected_colors&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">({</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;g&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;b&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;g&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">(</span><span class="s0">None, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;g&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;b&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;g&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}</span><span class="s0">, None, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;b&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;r&quot;</span><span class="s0">, </span><span class="s3">&quot;b&quot;</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;g&quot;</span><span class="s1">}</span><span class="s0">, None, </span><span class="s1">(</span><span class="s3">&quot;g&quot;</span><span class="s0">, </span><span class="s3">&quot;r&quot;</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}</span><span class="s0">, None, None, </span><span class="s1">(</span><span class="s3">&quot;r&quot;</span><span class="s0">, </span><span class="s3">&quot;r&quot;</span><span class="s1">))</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;color&quot;</span><span class="s1">: </span><span class="s3">&quot;r&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;linestyle&quot;</span><span class="s1">: </span><span class="s3">&quot;--&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">{</span><span class="s3">&quot;linestyle&quot;</span><span class="s1">: </span><span class="s3">&quot;-.&quot;</span><span class="s1">}</span><span class="s0">, </span><span class="s1">(</span><span class="s3">&quot;r&quot;</span><span class="s0">, </span><span class="s3">&quot;r&quot;</span><span class="s1">))</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_plot_partial_dependence_lines_kw(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
    <span class="s1">line_kw</span><span class="s0">,</span>
    <span class="s1">pd_line_kw</span><span class="s0">,</span>
    <span class="s1">ice_lines_kw</span><span class="s0">,</span>
    <span class="s1">expected_colors</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that passing `pd_line_kw` and `ice_lines_kw` will act on the 
    specific lines in the plot. 
    &quot;&quot;&quot;</span>

    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">20</span><span class="s0">,</span>
        <span class="s1">feature_names=diabetes.feature_names</span><span class="s0">,</span>
        <span class="s1">n_cols=</span><span class="s4">2</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s3">&quot;both&quot;</span><span class="s0">,</span>
        <span class="s1">line_kw=line_kw</span><span class="s0">,</span>
        <span class="s1">pd_line_kw=pd_line_kw</span><span class="s0">,</span>
        <span class="s1">ice_lines_kw=ice_lines_kw</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">line = disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">line.get_color() == expected_colors[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">if </span><span class="s1">pd_line_kw </span><span class="s0">is not None and </span><span class="s3">&quot;linestyle&quot; </span><span class="s0">in </span><span class="s1">pd_line_kw:</span>
        <span class="s0">assert </span><span class="s1">line.get_linestyle() == pd_line_kw[</span><span class="s3">&quot;linestyle&quot;</span><span class="s1">]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">line.get_linestyle() == </span><span class="s3">&quot;--&quot;</span>

    <span class="s1">line = disp.lines_[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">assert </span><span class="s1">line.get_color() == expected_colors[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">if </span><span class="s1">ice_lines_kw </span><span class="s0">is not None and </span><span class="s3">&quot;linestyle&quot; </span><span class="s0">in </span><span class="s1">ice_lines_kw:</span>
        <span class="s0">assert </span><span class="s1">line.get_linestyle() == ice_lines_kw[</span><span class="s3">&quot;linestyle&quot;</span><span class="s1">]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">assert </span><span class="s1">line.get_linestyle() == </span><span class="s3">&quot;-&quot;</span>


<span class="s0">def </span><span class="s1">test_partial_dependence_display_wrong_len_kind(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise an error when `kind` is a list with a wrong length. 
 
    This case can only be triggered using the `PartialDependenceDisplay.from_estimator` 
    method. 
    &quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">features=[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">20</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s3">&quot;average&quot;</span><span class="s0">,  </span><span class="s2"># len(kind) != len(features)</span>
    <span class="s1">)</span>

    <span class="s2"># alter `kind` to be a list with a length different from length of `features`</span>
    <span class="s1">disp.kind = [</span><span class="s3">&quot;average&quot;</span><span class="s1">]</span>
    <span class="s1">err_msg = (</span>
        <span class="s3">r&quot;When `kind` is provided as a list of strings, it should contain as many&quot;</span>
        <span class="s3">r&quot; elements as `features`. `kind` contains 1 element\(s\) and `features`&quot;</span>
        <span class="s3">r&quot; contains 2 element\(s\).&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=err_msg):</span>
        <span class="s1">disp.plot()</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kind&quot;</span><span class="s0">,</span>
    <span class="s1">[</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s0">, </span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;average&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;individual&quot;</span><span class="s0">, </span><span class="s3">&quot;both&quot;</span><span class="s1">]]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_partial_dependence_display_kind_centered_interaction(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">kind</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that we properly center ICE and PD when passing kind as a string and as a 
    list.&quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=kind</span><span class="s0">,</span>
        <span class="s1">centered=</span><span class="s0">True,</span>
        <span class="s1">subsample=</span><span class="s4">5</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">all([ln._y[</span><span class="s4">0</span><span class="s1">] == </span><span class="s4">0.0 </span><span class="s0">for </span><span class="s1">ln </span><span class="s0">in </span><span class="s1">disp.lines_.ravel() </span><span class="s0">if </span><span class="s1">ln </span><span class="s0">is not None</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">test_partial_dependence_display_with_constant_sample_weight(</span>
    <span class="s1">pyplot</span><span class="s0">,</span>
    <span class="s1">clf_diabetes</span><span class="s0">,</span>
    <span class="s1">diabetes</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot;Check that the utilization of a constant sample weight maintains the 
    standard behavior. 
    &quot;&quot;&quot;</span>
    <span class="s1">disp = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s3">&quot;average&quot;</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s3">&quot;brute&quot;</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">sample_weight = np.ones_like(diabetes.target)</span>
    <span class="s1">disp_sw = PartialDependenceDisplay.from_estimator(</span>
        <span class="s1">clf_diabetes</span><span class="s0">,</span>
        <span class="s1">diabetes.data</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">sample_weight=sample_weight</span><span class="s0">,</span>
        <span class="s1">kind=</span><span class="s3">&quot;average&quot;</span><span class="s0">,</span>
        <span class="s1">method=</span><span class="s3">&quot;brute&quot;</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.array_equal(</span>
        <span class="s1">disp.pd_results[</span><span class="s4">0</span><span class="s1">][</span><span class="s3">&quot;average&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">disp_sw.pd_results[</span><span class="s4">0</span><span class="s1">][</span><span class="s3">&quot;average&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_regression.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_regression.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Test functions for models.regression 
&quot;&quot;&quot;</span>
<span class="s2"># TODO: Test for LM</span>
<span class="s3">from </span><span class="s1">statsmodels.compat.python </span><span class="s3">import </span><span class="s1">lrange</span>

<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">numpy.testing </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">assert_</span><span class="s3">,</span>
    <span class="s1">assert_allclose</span><span class="s3">,</span>
    <span class="s1">assert_almost_equal</span><span class="s3">,</span>
    <span class="s1">assert_equal</span><span class="s3">,</span>
    <span class="s1">assert_raises</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>
<span class="s3">import </span><span class="s1">pytest</span>
<span class="s3">from </span><span class="s1">scipy.linalg </span><span class="s3">import </span><span class="s1">toeplitz</span>
<span class="s3">from </span><span class="s1">scipy.stats </span><span class="s3">import </span><span class="s1">t </span><span class="s3">as </span><span class="s1">student_t</span>

<span class="s3">from </span><span class="s1">statsmodels.datasets </span><span class="s3">import </span><span class="s1">longley</span>
<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">GLS</span><span class="s3">,</span>
    <span class="s1">OLS</span><span class="s3">,</span>
    <span class="s1">WLS</span><span class="s3">,</span>
    <span class="s1">burg</span><span class="s3">,</span>
    <span class="s1">yule_walker</span><span class="s3">,</span>
<span class="s1">)</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.tools </span><span class="s3">import </span><span class="s1">add_constant</span>

<span class="s1">DECIMAL_4 = </span><span class="s4">4</span>
<span class="s1">DECIMAL_3 = </span><span class="s4">3</span>
<span class="s1">DECIMAL_2 = </span><span class="s4">2</span>
<span class="s1">DECIMAL_1 = </span><span class="s4">1</span>
<span class="s1">DECIMAL_7 = </span><span class="s4">7</span>
<span class="s1">DECIMAL_0 = </span><span class="s4">0</span>

<span class="s3">try</span><span class="s1">:</span>
    <span class="s3">import </span><span class="s1">cvxopt  </span><span class="s2"># noqa:F401</span>

    <span class="s1">has_cvxopt = </span><span class="s3">True</span>
<span class="s3">except </span><span class="s1">ImportError:</span>
    <span class="s1">has_cvxopt = </span><span class="s3">False</span>


<span class="s3">class </span><span class="s1">CheckRegressionResults:</span>
    <span class="s0">&quot;&quot;&quot; 
    res2 contains results from Rmodelwrap or were obtained from a statistical 
    packages such as R, Stata, or SAS and were written to model_results 
    &quot;&quot;&quot;</span>

    <span class="s1">decimal_params = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.params</span><span class="s3">, </span><span class="s1">self.res2.params</span><span class="s3">, </span><span class="s1">self.decimal_params</span>
        <span class="s1">)</span>

    <span class="s1">decimal_standarderrors = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_standarderrors(self):</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">self.res1.bse</span><span class="s3">, </span><span class="s1">self.res2.bse</span><span class="s3">, </span><span class="s1">self.decimal_standarderrors</span>
        <span class="s1">)</span>

    <span class="s1">decimal_confidenceintervals = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_confidenceintervals(self):</span>
        <span class="s2"># NOTE: stata rounds residuals (at least) to sig digits so approx_equal</span>
        <span class="s1">conf1 = self.res1.conf_int()</span>
        <span class="s1">conf2 = self.res2.conf_int()</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(len(conf1)):</span>
            <span class="s1">assert_allclose(</span>
                <span class="s1">conf1[i][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">conf2[i][</span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">rtol=</span><span class="s4">10 </span><span class="s1">** -self.decimal_confidenceintervals</span><span class="s3">,</span>
            <span class="s1">)</span>
            <span class="s1">assert_allclose(</span>
                <span class="s1">conf1[i][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">conf2[i][</span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">rtol=</span><span class="s4">10 </span><span class="s1">** -self.decimal_confidenceintervals</span><span class="s3">,</span>
            <span class="s1">)</span>

    <span class="s1">decimal_conf_int_subset = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_conf_int_subset(self):</span>
        <span class="s3">if </span><span class="s1">len(self.res1.params) &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">with </span><span class="s1">pytest.warns(FutureWarning</span><span class="s3">, </span><span class="s1">match=</span><span class="s5">&quot;cols is&quot;</span><span class="s1">):</span>
                <span class="s1">ci1 = self.res1.conf_int(cols=(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">))</span>
            <span class="s1">ci2 = self.res1.conf_int()[</span><span class="s4">1</span><span class="s1">:</span><span class="s4">3</span><span class="s1">]</span>
            <span class="s1">assert_almost_equal(ci1</span><span class="s3">, </span><span class="s1">ci2</span><span class="s3">, </span><span class="s1">self.decimal_conf_int_subset)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">pass</span>

    <span class="s1">decimal_scale = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_scale(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.scale</span><span class="s3">, </span><span class="s1">self.res2.scale</span><span class="s3">, </span><span class="s1">self.decimal_scale</span>
        <span class="s1">)</span>

    <span class="s1">decimal_rsquared = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_rsquared(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.rsquared</span><span class="s3">, </span><span class="s1">self.res2.rsquared</span><span class="s3">, </span><span class="s1">self.decimal_rsquared</span>
        <span class="s1">)</span>

    <span class="s1">decimal_rsquared_adj = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_rsquared_adj(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.rsquared_adj</span><span class="s3">,</span>
            <span class="s1">self.res2.rsquared_adj</span><span class="s3">,</span>
            <span class="s1">self.decimal_rsquared_adj</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_degrees(self):</span>
        <span class="s1">assert_equal(self.res1.model.df_model</span><span class="s3">, </span><span class="s1">self.res2.df_model)</span>
        <span class="s1">assert_equal(self.res1.model.df_resid</span><span class="s3">, </span><span class="s1">self.res2.df_resid)</span>

    <span class="s1">decimal_ess = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_ess(self):</span>
        <span class="s2"># Explained Sum of Squares</span>
        <span class="s1">assert_almost_equal(self.res1.ess</span><span class="s3">, </span><span class="s1">self.res2.ess</span><span class="s3">, </span><span class="s1">self.decimal_ess)</span>

    <span class="s1">decimal_ssr = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_sumof_squaredresids(self):</span>
        <span class="s1">assert_almost_equal(self.res1.ssr</span><span class="s3">, </span><span class="s1">self.res2.ssr</span><span class="s3">, </span><span class="s1">self.decimal_ssr)</span>

    <span class="s1">decimal_mse_resid = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_mse_resid(self):</span>
        <span class="s2"># Mean squared error of residuals</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.mse_model</span><span class="s3">, </span><span class="s1">self.res2.mse_model</span><span class="s3">, </span><span class="s1">self.decimal_mse_resid</span>
        <span class="s1">)</span>

    <span class="s1">decimal_mse_model = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_mse_model(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.mse_resid</span><span class="s3">, </span><span class="s1">self.res2.mse_resid</span><span class="s3">, </span><span class="s1">self.decimal_mse_model</span>
        <span class="s1">)</span>

    <span class="s1">decimal_mse_total = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_mse_total(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.mse_total</span><span class="s3">,</span>
            <span class="s1">self.res2.mse_total</span><span class="s3">,</span>
            <span class="s1">self.decimal_mse_total</span><span class="s3">,</span>
            <span class="s1">err_msg=</span><span class="s5">&quot;Test class %s&quot; </span><span class="s1">% self</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s1">decimal_fvalue = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_fvalue(self):</span>
        <span class="s2"># did not change this, not sure it should complain -inf not equal -inf</span>
        <span class="s2"># if not (np.isinf(self.res1.fvalue) and np.isinf(self.res2.fvalue)):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.fvalue</span><span class="s3">, </span><span class="s1">self.res2.fvalue</span><span class="s3">, </span><span class="s1">self.decimal_fvalue</span>
        <span class="s1">)</span>

    <span class="s1">decimal_loglike = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(self.res1.llf</span><span class="s3">, </span><span class="s1">self.res2.llf</span><span class="s3">, </span><span class="s1">self.decimal_loglike)</span>

    <span class="s1">decimal_aic = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_aic(self):</span>
        <span class="s1">assert_almost_equal(self.res1.aic</span><span class="s3">, </span><span class="s1">self.res2.aic</span><span class="s3">, </span><span class="s1">self.decimal_aic)</span>
        <span class="s2"># the following just checks the definition</span>
        <span class="s1">aicc1 = self.res1.info_criteria(</span><span class="s5">&quot;aicc&quot;</span><span class="s1">)</span>
        <span class="s1">k = self.res1.df_model + self.res1.model.k_constant</span>
        <span class="s1">nobs = self.res1.model.nobs</span>
        <span class="s1">aicc2 = self.res1.aic + </span><span class="s4">2 </span><span class="s1">* (k**</span><span class="s4">2 </span><span class="s1">+ k) / (nobs - k - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(aicc1</span><span class="s3">, </span><span class="s1">aicc2</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
        <span class="s1">hqic1 = self.res1.info_criteria(</span><span class="s5">&quot;hqic&quot;</span><span class="s1">)</span>
        <span class="s1">hqic2 = (self.res1.aic - </span><span class="s4">2 </span><span class="s1">* k) + </span><span class="s4">2 </span><span class="s1">* np.log(np.log(nobs)) * k</span>
        <span class="s1">assert_allclose(hqic1</span><span class="s3">, </span><span class="s1">hqic2</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>

    <span class="s1">decimal_bic = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_bic(self):</span>
        <span class="s1">assert_almost_equal(self.res1.bic</span><span class="s3">, </span><span class="s1">self.res2.bic</span><span class="s3">, </span><span class="s1">self.decimal_bic)</span>

    <span class="s1">decimal_pvalues = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_pvalues(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.pvalues</span><span class="s3">, </span><span class="s1">self.res2.pvalues</span><span class="s3">, </span><span class="s1">self.decimal_pvalues</span>
        <span class="s1">)</span>

    <span class="s1">decimal_wresid = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_wresid(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.wresid</span><span class="s3">, </span><span class="s1">self.res2.wresid</span><span class="s3">, </span><span class="s1">self.decimal_wresid</span>
        <span class="s1">)</span>

    <span class="s1">decimal_resids = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_resids(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.resid</span><span class="s3">, </span><span class="s1">self.res2.resid</span><span class="s3">, </span><span class="s1">self.decimal_resids</span>
        <span class="s1">)</span>

    <span class="s1">decimal_norm_resids = DECIMAL_4</span>

    <span class="s3">def </span><span class="s1">test_norm_resids(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.resid_pearson</span><span class="s3">,</span>
            <span class="s1">self.res2.resid_pearson</span><span class="s3">,</span>
            <span class="s1">self.decimal_norm_resids</span><span class="s3">,</span>
        <span class="s1">)</span>


<span class="s2"># TODO: test fittedvalues and what else?</span>


<span class="s3">class </span><span class="s1">TestOLS(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">.results.results_regression </span><span class="s3">import </span><span class="s1">Longley</span>

        <span class="s1">data = longley.load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res1 = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">res2 = Longley()</span>
        <span class="s1">res2.wresid = res1.wresid  </span><span class="s2"># workaround hack</span>
        <span class="s1">cls.res1 = res1</span>
        <span class="s1">cls.res2 = res2</span>

        <span class="s1">res_qr = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit(method=</span><span class="s5">&quot;qr&quot;</span><span class="s1">)</span>

        <span class="s1">model_qr = OLS(endog</span><span class="s3">, </span><span class="s1">exog)</span>
        <span class="s1">Q</span><span class="s3">, </span><span class="s1">R = np.linalg.qr(exog)</span>
        <span class="s1">model_qr.exog_Q</span><span class="s3">, </span><span class="s1">model_qr.exog_R = Q</span><span class="s3">, </span><span class="s1">R</span>
        <span class="s1">model_qr.normalized_cov_params = np.linalg.inv(np.dot(R.T</span><span class="s3">, </span><span class="s1">R))</span>
        <span class="s1">model_qr.rank = np.linalg.matrix_rank(R)</span>
        <span class="s1">res_qr2 = model_qr.fit(method=</span><span class="s5">&quot;qr&quot;</span><span class="s1">)</span>

        <span class="s1">cls.res_qr = res_qr</span>
        <span class="s1">cls.res_qr_manual = res_qr2</span>

    <span class="s3">def </span><span class="s1">test_eigenvalues(self):</span>
        <span class="s1">eigenval_perc_diff = (</span>
            <span class="s1">self.res_qr.eigenvals - self.res_qr_manual.eigenvals</span>
        <span class="s1">)</span>
        <span class="s1">eigenval_perc_diff /= self.res_qr.eigenvals</span>
        <span class="s1">zeros = np.zeros_like(eigenval_perc_diff)</span>
        <span class="s1">assert_almost_equal(eigenval_perc_diff</span><span class="s3">, </span><span class="s1">zeros</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s2"># Robust error tests.  Compare values computed with SAS</span>
    <span class="s3">def </span><span class="s1">test_HC0_errors(self):</span>
        <span class="s2"># They are split up because the copied results do not have any</span>
        <span class="s2"># DECIMAL_4 places for the last place.</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.HC0_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC0_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>
        <span class="s1">assert_allclose(np.round(self.res1.HC0_se[-</span><span class="s4">1</span><span class="s1">])</span><span class="s3">, </span><span class="s1">self.res2.HC0_se[-</span><span class="s4">1</span><span class="s1">])</span>

    <span class="s3">def </span><span class="s1">test_HC1_errors(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.HC1_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC1_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>
        <span class="s2"># Note: tolerance is tight; rtol=3e-7 fails while 4e-7 passes</span>
        <span class="s1">assert_allclose(self.res1.HC1_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC1_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">4e-7</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_HC2_errors(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.HC2_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC2_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>
        <span class="s2"># Note: tolerance is tight; rtol=4e-7 fails while 5e-7 passes</span>
        <span class="s1">assert_allclose(self.res1.HC2_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC2_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">5e-7</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_HC3_errors(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.HC3_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC3_se[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>
        <span class="s2"># Note: tolerance is tight; rtol=1e-7 fails while 1.5e-7 passes</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">self.res1.HC3_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">self.res2.HC3_se[-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1.5e-7</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_qr_params(self):</span>
        <span class="s1">assert_almost_equal(self.res1.params</span><span class="s3">, </span><span class="s1">self.res_qr.params</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_qr_normalized_cov_params(self):</span>
        <span class="s2"># todo: need assert_close</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">np.ones_like(self.res1.normalized_cov_params)</span><span class="s3">,</span>
            <span class="s1">self.res1.normalized_cov_params</span>
            <span class="s1">/ self.res_qr.normalized_cov_params</span><span class="s3">,</span>
            <span class="s4">5</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_missing(self):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">data.endog[[</span><span class="s4">3</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">14</span><span class="s1">]] = np.nan</span>
        <span class="s1">mod = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span>
        <span class="s1">assert_equal(mod.endog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">13</span><span class="s1">)</span>
        <span class="s1">assert_equal(mod.exog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">13</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_rsquared_adj_overfit(self):</span>
        <span class="s2"># Test that if df_resid = 0, rsquared_adj = 0.</span>
        <span class="s2"># This is a regression test for user issue:</span>
        <span class="s2"># https://github.com/statsmodels/statsmodels/issues/868</span>
        <span class="s3">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s3">True</span><span class="s1">):</span>
            <span class="s1">x = np.random.randn(</span><span class="s4">5</span><span class="s1">)</span>
            <span class="s1">y = np.random.randn(</span><span class="s4">5</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>
            <span class="s1">results = OLS(x</span><span class="s3">, </span><span class="s1">y).fit()</span>
            <span class="s1">rsquared_adj = results.rsquared_adj</span>
            <span class="s1">assert_equal(rsquared_adj</span><span class="s3">, </span><span class="s1">np.nan)</span>

    <span class="s3">def </span><span class="s1">test_qr_alternatives(self):</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">self.res_qr.params</span><span class="s3">, </span><span class="s1">self.res_qr_manual.params</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">5e-12</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_norm_resid(self):</span>
        <span class="s1">resid = self.res1.wresid</span>
        <span class="s1">norm_resid = resid / np.sqrt(np.sum(resid ** </span><span class="s4">2.0</span><span class="s1">) / self.res1.df_resid)</span>
        <span class="s1">model_norm_resid = self.res1.resid_pearson</span>
        <span class="s1">assert_almost_equal(model_norm_resid</span><span class="s3">, </span><span class="s1">norm_resid</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_summary_slim(self):</span>
        <span class="s2"># check that slim summary is smaller, does not verify content</span>
        <span class="s3">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">msg = </span><span class="s5">&quot;kurtosistest only valid for n&gt;=20&quot;</span>
            <span class="s1">warnings.filterwarnings(</span><span class="s5">&quot;ignore&quot;</span><span class="s3">, </span><span class="s1">message=msg</span><span class="s3">,</span>
                                    <span class="s1">category=UserWarning)</span>

            <span class="s1">summ = self.res1.summary(slim=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s3">assert </span><span class="s1">len(summ.tables) == </span><span class="s4">2</span>
        <span class="s3">assert </span><span class="s1">len(str(summ)) &lt; </span><span class="s4">6700</span>

    <span class="s3">def </span><span class="s1">test_norm_resid_zero_variance(self):</span>
        <span class="s3">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s3">True</span><span class="s1">):</span>
            <span class="s1">y = self.res1.model.endog</span>
            <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">y).fit()</span>
            <span class="s1">assert_allclose(res.scale</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-20</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res.wresid</span><span class="s3">, </span><span class="s1">res.resid_pearson</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">5e-11</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestRTO(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">.results.results_regression </span><span class="s3">import </span><span class="s1">LongleyRTO</span>

        <span class="s1">data = longley.load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">res1 = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">res2 = LongleyRTO()</span>
        <span class="s1">res2.wresid = res1.wresid  </span><span class="s2"># workaround hack</span>
        <span class="s1">cls.res1 = res1</span>
        <span class="s1">cls.res2 = res2</span>

        <span class="s1">res_qr = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit(method=</span><span class="s5">&quot;qr&quot;</span><span class="s1">)</span>
        <span class="s1">cls.res_qr = res_qr</span>


<span class="s3">class </span><span class="s1">TestFtest:</span>
    <span class="s0">&quot;&quot;&quot; 
    Tests f_test vs. RegressionResults 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">cls.res1 = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog).fit()</span>
        <span class="s1">R = np.identity(</span><span class="s4">7</span><span class="s1">)[:-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">:]</span>
        <span class="s1">cls.Ftest = cls.res1.f_test(R)</span>

    <span class="s3">def </span><span class="s1">test_F(self):</span>
        <span class="s1">assert_almost_equal(self.Ftest.fvalue</span><span class="s3">, </span><span class="s1">self.res1.fvalue</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_p(self):</span>
        <span class="s1">assert_almost_equal(self.Ftest.pvalue</span><span class="s3">, </span><span class="s1">self.res1.f_pvalue</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_Df_denom(self):</span>
        <span class="s1">assert_equal(self.Ftest.df_denom</span><span class="s3">, </span><span class="s1">self.res1.model.df_resid)</span>

    <span class="s3">def </span><span class="s1">test_Df_num(self):</span>
        <span class="s1">assert_equal(self.Ftest.df_num</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestFTest2:</span>
    <span class="s0">&quot;&quot;&quot; 
    A joint test that the coefficient on 
    GNP = the coefficient on UNEMP  and that the coefficient on 
    POP = the coefficient on YEAR for the Longley dataset. 
 
    Ftest1 is from statsmodels.  Results are from Rpy using R's car library. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">columns = [</span><span class="s5">f&quot;x</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">&quot; </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">data.exog.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)]</span>
        <span class="s1">data.exog.columns = columns</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res1 = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog).fit()</span>
        <span class="s1">R2 = [[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]]</span>
        <span class="s1">cls.Ftest1 = res1.f_test(R2)</span>
        <span class="s1">hyp = </span><span class="s5">&quot;x2 = x3, x5 = x6&quot;</span>
        <span class="s1">cls.NewFtest1 = res1.f_test(hyp)</span>

    <span class="s3">def </span><span class="s1">test_new_ftest(self):</span>
        <span class="s1">assert_equal(self.NewFtest1.fvalue</span><span class="s3">, </span><span class="s1">self.Ftest1.fvalue)</span>

    <span class="s3">def </span><span class="s1">test_fvalue(self):</span>
        <span class="s1">assert_almost_equal(self.Ftest1.fvalue</span><span class="s3">, </span><span class="s4">9.7404618732968196</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_pvalue(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.Ftest1.pvalue</span><span class="s3">, </span><span class="s4">0.0056052885317493459</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_denom(self):</span>
        <span class="s1">assert_equal(self.Ftest1.df_denom</span><span class="s3">, </span><span class="s4">9</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_num(self):</span>
        <span class="s1">assert_equal(self.Ftest1.df_num</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestFtestQ:</span>
    <span class="s0">&quot;&quot;&quot; 
    A joint hypothesis test that Rb = q.  Coefficient tests are essentially 
    made up.  Test values taken from Stata. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res1 = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog).fit()</span>
        <span class="s1">R = np.array(</span>
            <span class="s1">[</span>
                <span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
                <span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">,</span>
            <span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s1">q = np.array([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">cls.Ftest1 = res1.f_test((R</span><span class="s3">, </span><span class="s1">q))</span>

    <span class="s3">def </span><span class="s1">test_fvalue(self):</span>
        <span class="s1">assert_almost_equal(self.Ftest1.fvalue</span><span class="s3">, </span><span class="s4">70.115557</span><span class="s3">, </span><span class="s4">5</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_pvalue(self):</span>
        <span class="s1">assert_almost_equal(self.Ftest1.pvalue</span><span class="s3">, </span><span class="s4">6.229e-07</span><span class="s3">, </span><span class="s4">10</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_denom(self):</span>
        <span class="s1">assert_equal(self.Ftest1.df_denom</span><span class="s3">, </span><span class="s4">9</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_num(self):</span>
        <span class="s1">assert_equal(self.Ftest1.df_num</span><span class="s3">, </span><span class="s4">5</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestTtest:</span>
    <span class="s0">&quot;&quot;&quot; 
    Test individual t-tests.  Ie., are the coefficients significantly 
    different than zero. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">columns = [</span><span class="s5">f&quot;x</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s5">&quot; </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s1">data.exog.shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)]</span>
        <span class="s1">data.exog.columns = columns</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">cls.res1 = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog).fit()</span>
        <span class="s1">R = np.identity(</span><span class="s4">7</span><span class="s1">)</span>
        <span class="s1">cls.Ttest = cls.res1.t_test(R)</span>
        <span class="s1">hyp = </span><span class="s5">&quot;x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, x6 = 0, const = 0&quot;</span>
        <span class="s1">cls.NewTTest = cls.res1.t_test(hyp)</span>

    <span class="s3">def </span><span class="s1">test_new_tvalue(self):</span>
        <span class="s1">assert_equal(self.NewTTest.tvalue</span><span class="s3">, </span><span class="s1">self.Ttest.tvalue)</span>

    <span class="s3">def </span><span class="s1">test_tvalue(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest.tvalue</span><span class="s3">, </span><span class="s1">self.res1.tvalues</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_sd(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest.sd</span><span class="s3">, </span><span class="s1">self.res1.bse</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_pvalue(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.Ttest.pvalue</span><span class="s3">,</span>
            <span class="s1">student_t.sf(np.abs(self.res1.tvalues)</span><span class="s3">, </span><span class="s1">self.res1.model.df_resid)</span>
            <span class="s1">* </span><span class="s4">2</span><span class="s3">,</span>
            <span class="s1">DECIMAL_4</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_denom(self):</span>
        <span class="s1">assert_equal(self.Ttest.df_denom</span><span class="s3">, </span><span class="s1">self.res1.model.df_resid)</span>

    <span class="s3">def </span><span class="s1">test_effect(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest.effect</span><span class="s3">, </span><span class="s1">self.res1.params)</span>


<span class="s3">class </span><span class="s1">TestTtest2:</span>
    <span class="s0">&quot;&quot;&quot; 
    Tests the hypothesis that the coefficients on POP and YEAR 
    are equal. 
 
    Results from RPy using 'car' package. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">R = np.zeros(</span><span class="s4">7</span><span class="s1">)</span>
        <span class="s1">R[</span><span class="s4">4</span><span class="s1">:</span><span class="s4">6</span><span class="s1">] = [</span><span class="s4">1</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">res1 = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog).fit()</span>
        <span class="s1">cls.Ttest1 = res1.t_test(R)</span>

    <span class="s3">def </span><span class="s1">test_tvalue(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest1.tvalue</span><span class="s3">, </span><span class="s1">-</span><span class="s4">4.0167754636397284</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_sd(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest1.sd</span><span class="s3">, </span><span class="s4">455.39079425195314</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_pvalue(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.Ttest1.pvalue</span><span class="s3">, </span><span class="s4">2 </span><span class="s1">* </span><span class="s4">0.0015163772380932246</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_df_denom(self):</span>
        <span class="s1">assert_equal(self.Ttest1.df_denom</span><span class="s3">, </span><span class="s4">9</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_effect(self):</span>
        <span class="s1">assert_almost_equal(self.Ttest1.effect</span><span class="s3">, </span><span class="s1">-</span><span class="s4">1829.2025687186533</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s3">class </span><span class="s1">TestGLS:</span>
    <span class="s0">&quot;&quot;&quot; 
    These test results were obtained by replication with R. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">.results.results_regression </span><span class="s3">import </span><span class="s1">LongleyGls</span>

        <span class="s1">data = longley.load()</span>
        <span class="s1">exog = add_constant(</span>
            <span class="s1">np.column_stack((data.exog.iloc[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">data.exog.iloc[:</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]))</span><span class="s3">,</span>
            <span class="s1">prepend=</span><span class="s3">False,</span>
        <span class="s1">)</span>
        <span class="s1">tmp_results = OLS(data.endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">rho = np.corrcoef(tmp_results.resid[</span><span class="s4">1</span><span class="s1">:]</span><span class="s3">, </span><span class="s1">tmp_results.resid[:-</span><span class="s4">1</span><span class="s1">])[</span><span class="s4">0</span><span class="s1">][</span>
            <span class="s4">1</span>
        <span class="s1">]  </span><span class="s2"># by assumption</span>
        <span class="s1">order = toeplitz(np.arange(</span><span class="s4">16</span><span class="s1">))</span>
        <span class="s1">sigma = rho ** order</span>
        <span class="s1">GLS_results = GLS(data.endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">sigma=sigma).fit()</span>
        <span class="s1">cls.res1 = GLS_results</span>
        <span class="s1">cls.res2 = LongleyGls()</span>
        <span class="s2"># attach for test_missing</span>
        <span class="s1">cls.sigma = sigma</span>
        <span class="s1">cls.exog = exog</span>
        <span class="s1">cls.endog = data.endog</span>

    <span class="s3">def </span><span class="s1">test_aic(self):</span>
        <span class="s2"># Note: tolerance is tight; rtol=3e-3 fails while 4e-3 passes</span>
        <span class="s1">assert_allclose(self.res1.aic + </span><span class="s4">2</span><span class="s3">, </span><span class="s1">self.res2.aic</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">4e-3</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_bic(self):</span>
        <span class="s2"># Note: tolerance is tight; rtol=1e-2 fails while 1.5e-2 passes</span>
        <span class="s1">assert_allclose(self.res1.bic</span><span class="s3">, </span><span class="s1">self.res2.bic</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1.5e-2</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_loglike(self):</span>
        <span class="s1">assert_almost_equal(self.res1.llf</span><span class="s3">, </span><span class="s1">self.res2.llf</span><span class="s3">, </span><span class="s1">DECIMAL_0)</span>

    <span class="s3">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(self.res1.params</span><span class="s3">, </span><span class="s1">self.res2.params</span><span class="s3">, </span><span class="s1">DECIMAL_1)</span>

    <span class="s3">def </span><span class="s1">test_resid(self):</span>
        <span class="s1">assert_almost_equal(self.res1.resid</span><span class="s3">, </span><span class="s1">self.res2.resid</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_scale(self):</span>
        <span class="s1">assert_almost_equal(self.res1.scale</span><span class="s3">, </span><span class="s1">self.res2.scale</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_tvalues(self):</span>
        <span class="s1">assert_almost_equal(self.res1.tvalues</span><span class="s3">, </span><span class="s1">self.res2.tvalues</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_standarderrors(self):</span>
        <span class="s1">assert_almost_equal(self.res1.bse</span><span class="s3">, </span><span class="s1">self.res2.bse</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_fittedvalues(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.res1.fittedvalues</span><span class="s3">, </span><span class="s1">self.res2.fittedvalues</span><span class="s3">, </span><span class="s1">DECIMAL_4</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_pvalues(self):</span>
        <span class="s1">assert_almost_equal(self.res1.pvalues</span><span class="s3">, </span><span class="s1">self.res2.pvalues</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>

    <span class="s3">def </span><span class="s1">test_missing(self):</span>
        <span class="s1">endog = self.endog.copy()  </span><span class="s2"># copy or changes endog for other methods</span>
        <span class="s1">endog[[</span><span class="s4">4</span><span class="s3">, </span><span class="s4">7</span><span class="s3">, </span><span class="s4">14</span><span class="s1">]] = np.nan</span>
        <span class="s1">mod = GLS(endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">sigma=self.sigma</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">&quot;drop&quot;</span><span class="s1">)</span>
        <span class="s1">assert_equal(mod.endog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">13</span><span class="s1">)</span>
        <span class="s1">assert_equal(mod.exog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">13</span><span class="s1">)</span>
        <span class="s1">assert_equal(mod.sigma.shape</span><span class="s3">, </span><span class="s1">(</span><span class="s4">13</span><span class="s3">, </span><span class="s4">13</span><span class="s1">))</span>


<span class="s3">class </span><span class="s1">TestGLS_alt_sigma(CheckRegressionResults):</span>
    <span class="s0">&quot;&quot;&quot; 
    Test that GLS with no argument is equivalent to OLS. 
    &quot;&quot;&quot;</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">ols_res = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">gls_res = GLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">gls_res_scalar = GLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">cls.endog = endog</span>
        <span class="s1">cls.exog = exog</span>
        <span class="s1">cls.res1 = gls_res</span>
        <span class="s1">cls.res2 = ols_res</span>
        <span class="s1">cls.res3 = gls_res_scalar</span>

    <span class="s2">#        self.res2.conf_int = self.res2.conf_int()</span>

    <span class="s3">def </span><span class="s1">test_wrong_size_sigma_1d(self):</span>
        <span class="s1">n = len(self.endog)</span>
        <span class="s1">assert_raises(</span>
            <span class="s1">ValueError</span><span class="s3">, </span><span class="s1">GLS</span><span class="s3">, </span><span class="s1">self.endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">sigma=np.ones(n - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_wrong_size_sigma_2d(self):</span>
        <span class="s1">n = len(self.endog)</span>
        <span class="s1">assert_raises(</span>
            <span class="s1">ValueError</span><span class="s3">,</span>
            <span class="s1">GLS</span><span class="s3">,</span>
            <span class="s1">self.endog</span><span class="s3">,</span>
            <span class="s1">self.exog</span><span class="s3">,</span>
            <span class="s1">sigma=np.ones((n - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n - </span><span class="s4">1</span><span class="s1">))</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s1">@pytest.mark.skip(</span><span class="s5">&quot;Test does not raise but should&quot;</span><span class="s1">)</span>
    <span class="s3">def </span><span class="s1">test_singular_sigma(self):</span>
        <span class="s1">n = len(self.endog)</span>
        <span class="s1">sigma = np.ones((n</span><span class="s3">, </span><span class="s1">n)) + np.diag(np.ones(n))</span>
        <span class="s1">sigma[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] = sigma[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">2</span>
        <span class="s3">assert </span><span class="s1">np.linalg.matrix_rank(sigma) == n - </span><span class="s4">1</span>
        <span class="s3">with </span><span class="s1">pytest.raises(np.linalg.LinAlgError):</span>
            <span class="s1">GLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">sigma=sigma)</span>


<span class="s2"># FIXME: do not leave commented-out, use or move/remove</span>
<span class="s2">#    def check_confidenceintervals(self, conf1, conf2):</span>
<span class="s2">#        assert_almost_equal(conf1, conf2, DECIMAL_4)</span>


<span class="s3">class </span><span class="s1">TestLM:</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s2"># TODO: Test HAC method</span>
        <span class="s1">rs = np.random.RandomState(</span><span class="s4">1234</span><span class="s1">)</span>
        <span class="s1">x = rs.randn(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">3</span><span class="s1">)</span>
        <span class="s1">b = np.ones((</span><span class="s4">3</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
        <span class="s1">e = rs.randn(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">y = np.dot(x</span><span class="s3">, </span><span class="s1">b) + e</span>
        <span class="s2"># Cases?</span>
        <span class="s2"># Homoskedastic</span>
        <span class="s2"># HC0</span>
        <span class="s1">cls.res1_full = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
        <span class="s1">cls.res1_restricted = OLS(y</span><span class="s3">, </span><span class="s1">x[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]).fit()</span>

        <span class="s1">cls.res2_full = cls.res1_full.get_robustcov_results(</span><span class="s5">&quot;HC0&quot;</span><span class="s1">)</span>
        <span class="s1">cls.res2_restricted = cls.res1_restricted.get_robustcov_results(</span><span class="s5">&quot;HC0&quot;</span><span class="s1">)</span>

        <span class="s1">cls.x = x</span>
        <span class="s1">cls.Y = y</span>

    <span class="s3">def </span><span class="s1">test_LM_homoskedastic(self):</span>
        <span class="s1">resid = self.res1_restricted.wresid</span>
        <span class="s1">n = resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">x = self.x</span>
        <span class="s1">S = np.dot(resid</span><span class="s3">, </span><span class="s1">resid) / n * np.dot(x.T</span><span class="s3">, </span><span class="s1">x) / n</span>
        <span class="s1">Sinv = np.linalg.inv(S)</span>
        <span class="s1">s = np.mean(x * resid[:</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">LMstat = n * np.dot(np.dot(s</span><span class="s3">, </span><span class="s1">Sinv)</span><span class="s3">, </span><span class="s1">s.T)</span>
        <span class="s1">LMstat_OLS = self.res1_full.compare_lm_test(self.res1_restricted)</span>
        <span class="s1">LMstat2 = LMstat_OLS[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(LMstat</span><span class="s3">, </span><span class="s1">LMstat2</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_LM_heteroskedastic_nodemean(self):</span>
        <span class="s1">resid = self.res1_restricted.wresid</span>
        <span class="s1">n = resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">x = self.x</span>
        <span class="s1">scores = x * resid[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">S = np.dot(scores.T</span><span class="s3">, </span><span class="s1">scores) / n</span>
        <span class="s1">Sinv = np.linalg.inv(S)</span>
        <span class="s1">s = np.mean(scores</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">LMstat = n * np.dot(np.dot(s</span><span class="s3">, </span><span class="s1">Sinv)</span><span class="s3">, </span><span class="s1">s.T)</span>
        <span class="s1">LMstat_OLS = self.res2_full.compare_lm_test(</span>
            <span class="s1">self.res2_restricted</span><span class="s3">, </span><span class="s1">demean=</span><span class="s3">False</span>
        <span class="s1">)</span>
        <span class="s1">LMstat2 = LMstat_OLS[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(LMstat</span><span class="s3">, </span><span class="s1">LMstat2</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_LM_heteroskedastic_demean(self):</span>
        <span class="s1">resid = self.res1_restricted.wresid</span>
        <span class="s1">n = resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">x = self.x</span>
        <span class="s1">scores = x * resid[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">scores_demean = scores - scores.mean(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">S = np.dot(scores_demean.T</span><span class="s3">, </span><span class="s1">scores_demean) / n</span>
        <span class="s1">Sinv = np.linalg.inv(S)</span>
        <span class="s1">s = np.mean(scores</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">LMstat = n * np.dot(np.dot(s</span><span class="s3">, </span><span class="s1">Sinv)</span><span class="s3">, </span><span class="s1">s.T)</span>
        <span class="s1">LMstat_OLS = self.res2_full.compare_lm_test(self.res2_restricted)</span>
        <span class="s1">LMstat2 = LMstat_OLS[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(LMstat</span><span class="s3">, </span><span class="s1">LMstat2</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_LM_heteroskedastic_LRversion(self):</span>
        <span class="s1">resid = self.res1_restricted.wresid</span>
        <span class="s1">resid_full = self.res1_full.wresid</span>
        <span class="s1">n = resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">x = self.x</span>
        <span class="s1">scores = x * resid[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">s = np.mean(scores</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">scores = x * resid_full[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">S = np.dot(scores.T</span><span class="s3">, </span><span class="s1">scores) / n</span>
        <span class="s1">Sinv = np.linalg.inv(S)</span>
        <span class="s1">LMstat = n * np.dot(np.dot(s</span><span class="s3">, </span><span class="s1">Sinv)</span><span class="s3">, </span><span class="s1">s.T)</span>
        <span class="s1">LMstat_OLS = self.res2_full.compare_lm_test(</span>
            <span class="s1">self.res2_restricted</span><span class="s3">, </span><span class="s1">use_lr=</span><span class="s3">True</span>
        <span class="s1">)</span>
        <span class="s1">LMstat2 = LMstat_OLS[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">assert_almost_equal(LMstat</span><span class="s3">, </span><span class="s1">LMstat2</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_LM_nonnested(self):</span>
        <span class="s1">assert_raises(</span>
            <span class="s1">ValueError</span><span class="s3">, </span><span class="s1">self.res2_restricted.compare_lm_test</span><span class="s3">, </span><span class="s1">self.res2_full</span>
        <span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestOLS_GLS_WLS_equivalence:</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">y = data.endog</span>
        <span class="s1">x = data.exog</span>
        <span class="s1">n = y.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">w = np.ones(n)</span>
        <span class="s1">cls.results = []</span>
        <span class="s1">cls.results.append(OLS(y</span><span class="s3">, </span><span class="s1">x).fit())</span>
        <span class="s1">cls.results.append(WLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">w).fit())</span>
        <span class="s2"># scaling weights does not change main results (except scale)</span>
        <span class="s1">cls.results.append(GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s4">100 </span><span class="s1">* w).fit())</span>
        <span class="s1">cls.results.append(GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">np.diag(</span><span class="s4">0.1 </span><span class="s1">* w)).fit())</span>

    <span class="s3">def </span><span class="s1">test_ll(self):</span>
        <span class="s1">llf = np.array([r.llf </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">llf_1 = np.ones_like(llf) * self.results[</span><span class="s4">0</span><span class="s1">].llf</span>
        <span class="s1">assert_almost_equal(llf</span><span class="s3">, </span><span class="s1">llf_1</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

        <span class="s1">ic = np.array([r.aic </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">ic_1 = np.ones_like(ic) * self.results[</span><span class="s4">0</span><span class="s1">].aic</span>
        <span class="s1">assert_almost_equal(ic</span><span class="s3">, </span><span class="s1">ic_1</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

        <span class="s1">ic = np.array([r.bic </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">ic_1 = np.ones_like(ic) * self.results[</span><span class="s4">0</span><span class="s1">].bic</span>
        <span class="s1">assert_almost_equal(ic</span><span class="s3">, </span><span class="s1">ic_1</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_params(self):</span>
        <span class="s1">params = np.array([r.params </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">params_1 = np.array([self.results[</span><span class="s4">0</span><span class="s1">].params] * len(self.results))</span>
        <span class="s1">assert_allclose(params</span><span class="s3">, </span><span class="s1">params_1)</span>

    <span class="s3">def </span><span class="s1">test_ss(self):</span>
        <span class="s1">bse = np.array([r.bse </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">bse_1 = np.array([self.results[</span><span class="s4">0</span><span class="s1">].bse] * len(self.results))</span>
        <span class="s1">assert_allclose(bse</span><span class="s3">, </span><span class="s1">bse_1)</span>

    <span class="s3">def </span><span class="s1">test_rsquared(self):</span>
        <span class="s1">rsquared = np.array([r.rsquared </span><span class="s3">for </span><span class="s1">r </span><span class="s3">in </span><span class="s1">self.results])</span>
        <span class="s1">rsquared_1 = np.array([self.results[</span><span class="s4">0</span><span class="s1">].rsquared] * len(self.results))</span>
        <span class="s1">assert_almost_equal(rsquared</span><span class="s3">, </span><span class="s1">rsquared_1</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>


<span class="s3">class </span><span class="s1">TestGLS_WLS_equivalence(TestOLS_GLS_WLS_equivalence):</span>
    <span class="s2"># reuse test methods</span>

    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">y = data.endog</span>
        <span class="s1">x = data.exog</span>
        <span class="s1">n = y.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">np.random.seed(</span><span class="s4">5</span><span class="s1">)</span>
        <span class="s1">w = np.random.uniform(</span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s1">n)</span>
        <span class="s1">w_inv = </span><span class="s4">1.0 </span><span class="s1">/ w</span>
        <span class="s1">cls.results = []</span>
        <span class="s1">cls.results.append(WLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">w).fit())</span>
        <span class="s2"># scaling weights does not change main results (except scale)</span>
        <span class="s1">cls.results.append(WLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s4">0.01 </span><span class="s1">* w).fit())</span>
        <span class="s1">cls.results.append(GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s4">100 </span><span class="s1">* w_inv).fit())</span>
        <span class="s1">cls.results.append(GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">np.diag(</span><span class="s4">0.1 </span><span class="s1">* w_inv)).fit())</span>


<span class="s3">class </span><span class="s1">TestNonFit:</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">data.exog = add_constant(data.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">cls.endog = data.endog</span>
        <span class="s1">cls.exog = data.exog</span>
        <span class="s1">cls.ols_model = OLS(data.endog</span><span class="s3">, </span><span class="s1">data.exog)</span>

    <span class="s3">def </span><span class="s1">test_df_resid(self):</span>
        <span class="s1">df_resid = self.endog.shape[</span><span class="s4">0</span><span class="s1">] - self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">assert_equal(self.ols_model.df_resid</span><span class="s3">, </span><span class="s4">9</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestWLS_CornerCases:</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">cls.exog = np.ones((</span><span class="s4">1</span><span class="s3">,</span><span class="s1">))</span>
        <span class="s1">cls.endog = np.ones((</span><span class="s4">1</span><span class="s3">,</span><span class="s1">))</span>
        <span class="s1">weights = </span><span class="s4">1</span>
        <span class="s1">cls.wls_res = WLS(cls.endog</span><span class="s3">, </span><span class="s1">cls.exog</span><span class="s3">, </span><span class="s1">weights=weights).fit()</span>

    <span class="s3">def </span><span class="s1">test_wrong_size_weights(self):</span>
        <span class="s1">weights = np.ones((</span><span class="s4">10</span><span class="s3">, </span><span class="s4">10</span><span class="s1">))</span>
        <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">WLS</span><span class="s3">, </span><span class="s1">self.endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">weights=weights)</span>


<span class="s3">class </span><span class="s1">TestWLSExogWeights(CheckRegressionResults):</span>
    <span class="s2"># Test WLS with Greene's credit card data</span>
    <span class="s2"># reg avgexp age income incomesq ownrent [aw=1/incomesq]</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">statsmodels.datasets.ccard </span><span class="s3">import </span><span class="s1">load</span>

        <span class="s3">from </span><span class="s1">.results.results_regression </span><span class="s3">import </span><span class="s1">CCardWLS</span>

        <span class="s1">dta = load()</span>
        <span class="s1">endog = np.asarray(dta.endog)</span>
        <span class="s1">exog = np.asarray(dta.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">nobs = </span><span class="s4">72.0</span>

        <span class="s1">weights = </span><span class="s4">1 </span><span class="s1">/ exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>
        <span class="s2"># for comparison with stata analytic weights</span>
        <span class="s1">scaled_weights = (weights * nobs) / weights.sum()</span>

        <span class="s1">cls.res1 = WLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">weights=scaled_weights).fit()</span>
        <span class="s1">cls.res2 = CCardWLS()</span>
        <span class="s1">cls.res2.wresid = scaled_weights ** </span><span class="s4">0.5 </span><span class="s1">* cls.res2.resid</span>

        <span class="s2"># correction because we use different definition for loglike/llf</span>
        <span class="s1">corr_ic = </span><span class="s4">2 </span><span class="s1">* (cls.res1.llf - cls.res2.llf)</span>
        <span class="s1">cls.res2.aic -= corr_ic</span>
        <span class="s1">cls.res2.bic -= corr_ic</span>
        <span class="s1">cls.res2.llf += </span><span class="s4">0.5 </span><span class="s1">* np.sum(np.log(cls.res1.model.weights))</span>


<span class="s3">def </span><span class="s1">test_wls_example():</span>
    <span class="s2"># example from the docstring, there was a note about a bug, should</span>
    <span class="s2"># be fixed now</span>
    <span class="s1">Y = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s1">]</span>
    <span class="s1">x = lrange(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">8</span><span class="s1">)</span>
    <span class="s1">x = add_constant(x</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
    <span class="s1">wls_model = WLS(Y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">weights=lrange(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">8</span><span class="s1">)).fit()</span>
    <span class="s2"># taken from R lm.summary</span>
    <span class="s1">assert_almost_equal(wls_model.fvalue</span><span class="s3">, </span><span class="s4">0.127337843215</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>
    <span class="s1">assert_almost_equal(wls_model.scale</span><span class="s3">, </span><span class="s4">2.44608530786 </span><span class="s1">** </span><span class="s4">2</span><span class="s3">, </span><span class="s4">6</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_wls_tss():</span>
    <span class="s1">y = np.array([</span><span class="s4">22</span><span class="s3">, </span><span class="s4">22</span><span class="s3">, </span><span class="s4">22</span><span class="s3">, </span><span class="s4">23</span><span class="s3">, </span><span class="s4">23</span><span class="s3">, </span><span class="s4">23</span><span class="s1">])</span>
    <span class="s1">x = [[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]]</span>

    <span class="s1">ols_mod = OLS(y</span><span class="s3">, </span><span class="s1">add_constant(x</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)).fit()</span>

    <span class="s1">yw = np.array([</span><span class="s4">22</span><span class="s3">, </span><span class="s4">22</span><span class="s3">, </span><span class="s4">23.0</span><span class="s1">])</span>
    <span class="s1">Xw = [[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]]</span>
    <span class="s1">w = np.array([</span><span class="s4">2</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">3.0</span><span class="s1">])</span>

    <span class="s1">wls_mod = WLS(yw</span><span class="s3">, </span><span class="s1">add_constant(Xw</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span><span class="s3">, </span><span class="s1">weights=w).fit()</span>
    <span class="s1">assert_equal(ols_mod.centered_tss</span><span class="s3">, </span><span class="s1">wls_mod.centered_tss)</span>


<span class="s3">class </span><span class="s1">TestWLSScalarVsArray(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">statsmodels.datasets.longley </span><span class="s3">import </span><span class="s1">load</span>

        <span class="s1">dta = load()</span>
        <span class="s1">endog = np.asarray(dta.endog)</span>
        <span class="s1">exog = np.asarray(dta.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s1">wls_scalar = WLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">weights=</span><span class="s4">1.0 </span><span class="s1">/ </span><span class="s4">3</span><span class="s1">).fit()</span>
        <span class="s1">weights = [</span><span class="s4">1 </span><span class="s1">/ </span><span class="s4">3.0</span><span class="s1">] * len(endog)</span>
        <span class="s1">wls_array = WLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">weights=weights).fit()</span>
        <span class="s1">cls.res1 = wls_scalar</span>
        <span class="s1">cls.res2 = wls_array</span>


<span class="s3">class </span><span class="s1">TestWLS_GLS(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">statsmodels.datasets.ccard </span><span class="s3">import </span><span class="s1">load</span>

        <span class="s1">data = load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">sigma = exog[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>
        <span class="s1">cls.res1 = WLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">weights=</span><span class="s4">1 </span><span class="s1">/ sigma).fit()</span>
        <span class="s1">cls.res2 = GLS(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">sigma=sigma).fit()</span>

    <span class="s3">def </span><span class="s1">check_confidenceintervals(self</span><span class="s3">, </span><span class="s1">conf1</span><span class="s3">, </span><span class="s1">conf2):  </span><span class="s2"># FIXME: never called</span>
        <span class="s1">assert_almost_equal(conf1</span><span class="s3">, </span><span class="s1">conf2()</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s3">def </span><span class="s1">test_wls_missing():</span>
    <span class="s3">from </span><span class="s1">statsmodels.datasets.ccard </span><span class="s3">import </span><span class="s1">load</span>

    <span class="s1">data = load()</span>
    <span class="s1">endog = data.endog</span>
    <span class="s1">endog[[</span><span class="s4">10</span><span class="s3">, </span><span class="s4">25</span><span class="s1">]] = np.nan</span>
    <span class="s1">mod = WLS(</span>
        <span class="s1">data.endog</span><span class="s3">, </span><span class="s1">data.exog</span><span class="s3">, </span><span class="s1">weights=</span><span class="s4">1 </span><span class="s1">/ data.exog.iloc[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span><span class="s3">, </span><span class="s1">missing=</span><span class="s5">&quot;drop&quot;</span>
    <span class="s1">)</span>
    <span class="s1">assert_equal(mod.endog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">70</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.exog.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">70</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.weights.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s4">70</span><span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestWLS_OLS(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">cls.res1 = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">cls.res2 = WLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>

    <span class="s3">def </span><span class="s1">check_confidenceintervals(self</span><span class="s3">, </span><span class="s1">conf1</span><span class="s3">, </span><span class="s1">conf2):  </span><span class="s2"># FIXME: never called</span>
        <span class="s1">assert_almost_equal(conf1</span><span class="s3">, </span><span class="s1">conf2()</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s3">class </span><span class="s1">TestGLS_OLS(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">data = longley.load()</span>
        <span class="s1">endog = np.asarray(data.endog)</span>
        <span class="s1">exog = np.asarray(data.exog)</span>
        <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
        <span class="s1">cls.res1 = GLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
        <span class="s1">cls.res2 = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>

    <span class="s3">def </span><span class="s1">check_confidenceintervals(self</span><span class="s3">, </span><span class="s1">conf1</span><span class="s3">, </span><span class="s1">conf2):  </span><span class="s2"># FIXME: never called</span>
        <span class="s1">assert_almost_equal(conf1</span><span class="s3">, </span><span class="s1">conf2()</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s2"># FIXME: do not leave this commented-out sitting here</span>
<span class="s2"># TODO: test AR</span>
<span class="s2"># why the two-stage in AR?</span>
<span class="s2"># class TestAR:</span>
<span class="s2">#     from statsmodels.datasets.sunspots import load</span>
<span class="s2">#     data = load()</span>
<span class="s2">#     model = AR(data.endog, rho=4).fit()</span>
<span class="s2">#     R_res = RModel(data.endog, aic=&quot;FALSE&quot;, order_max=4)#</span>

<span class="s2">#     def test_params(self):</span>
<span class="s2">#         assert_almost_equal(self.model.rho,</span>
<span class="s2">#         pass</span>

<span class="s2">#     def test_order(self):</span>
<span class="s2"># In R this can be defined or chosen by minimizing the AIC if aic=True</span>
<span class="s2">#        pass</span>


<span class="s3">class </span><span class="s1">TestYuleWalker:</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s3">from </span><span class="s1">statsmodels.datasets.sunspots </span><span class="s3">import </span><span class="s1">load</span>

        <span class="s1">data = load()</span>
        <span class="s1">cls.rho</span><span class="s3">, </span><span class="s1">cls.sigma = yule_walker(data.endog</span><span class="s3">, </span><span class="s1">order=</span><span class="s4">4</span><span class="s3">, </span><span class="s1">method=</span><span class="s5">&quot;mle&quot;</span><span class="s1">)</span>
        <span class="s1">cls.R_params = [</span>
            <span class="s4">1.2831003105694765</span><span class="s3">,</span>
            <span class="s1">-</span><span class="s4">0.45240924374091945</span><span class="s3">,</span>
            <span class="s1">-</span><span class="s4">0.20770298557575195</span><span class="s3">,</span>
            <span class="s4">0.047943648089542337</span><span class="s3">,</span>
        <span class="s1">]</span>

    <span class="s3">def </span><span class="s1">test_params(self):</span>
        <span class="s1">assert_almost_equal(self.rho</span><span class="s3">, </span><span class="s1">self.R_params</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s3">class </span><span class="s1">TestDataDimensions(CheckRegressionResults):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">np.random.seed(</span><span class="s4">54321</span><span class="s1">)</span>
        <span class="s1">cls.endog_n_ = np.random.uniform(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">20</span><span class="s3">, </span><span class="s1">size=</span><span class="s4">30</span><span class="s1">)</span>
        <span class="s1">cls.endog_n_one = cls.endog_n_[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">cls.exog_n_ = np.random.uniform(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">20</span><span class="s3">, </span><span class="s1">size=</span><span class="s4">30</span><span class="s1">)</span>
        <span class="s1">cls.exog_n_one = cls.exog_n_[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">cls.degen_exog = cls.exog_n_one[:-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">cls.mod1 = OLS(cls.endog_n_one</span><span class="s3">, </span><span class="s1">cls.exog_n_one)</span>
        <span class="s1">cls.mod1.df_model += </span><span class="s4">1</span>
        <span class="s1">cls.res1 = cls.mod1.fit()</span>
        <span class="s2"># Note that these are created for every subclass..</span>
        <span class="s2"># A little extra overhead probably</span>
        <span class="s1">cls.mod2 = OLS(cls.endog_n_one</span><span class="s3">, </span><span class="s1">cls.exog_n_one)</span>
        <span class="s1">cls.mod2.df_model += </span><span class="s4">1</span>
        <span class="s1">cls.res2 = cls.mod2.fit()</span>

    <span class="s3">def </span><span class="s1">check_confidenceintervals(self</span><span class="s3">, </span><span class="s1">conf1</span><span class="s3">, </span><span class="s1">conf2):  </span><span class="s2"># FIXME: never called</span>
        <span class="s1">assert_almost_equal(conf1</span><span class="s3">, </span><span class="s1">conf2()</span><span class="s3">, </span><span class="s1">DECIMAL_4)</span>


<span class="s3">class </span><span class="s1">TestGLS_large_data(TestDataDimensions):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestGLS_large_data</span><span class="s3">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">nobs = </span><span class="s4">1000</span>
        <span class="s1">y = np.random.randn(nobs</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">x = np.random.randn(nobs</span><span class="s3">, </span><span class="s4">20</span><span class="s1">)</span>
        <span class="s1">sigma = np.ones_like(y)</span>
        <span class="s1">cls.gls_res = GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">sigma=sigma).fit()</span>
        <span class="s1">cls.gls_res_scalar = GLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s4">1</span><span class="s1">).fit()</span>
        <span class="s1">cls.gls_res_none = GLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
        <span class="s1">cls.ols_res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>

    <span class="s3">def </span><span class="s1">test_large_equal_params(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.ols_res.params</span><span class="s3">, </span><span class="s1">self.gls_res.params</span><span class="s3">, </span><span class="s1">DECIMAL_7</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_large_equal_loglike(self):</span>
        <span class="s1">assert_almost_equal(self.ols_res.llf</span><span class="s3">, </span><span class="s1">self.gls_res.llf</span><span class="s3">, </span><span class="s1">DECIMAL_7)</span>

    <span class="s3">def </span><span class="s1">test_large_equal_params_none(self):</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">self.gls_res.params</span><span class="s3">, </span><span class="s1">self.gls_res_none.params</span><span class="s3">, </span><span class="s1">DECIMAL_7</span>
        <span class="s1">)</span>


<span class="s3">class </span><span class="s1">TestNxNx(TestDataDimensions):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestNxNx</span><span class="s3">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">cls.mod2 = OLS(cls.endog_n_</span><span class="s3">, </span><span class="s1">cls.exog_n_)</span>
        <span class="s1">cls.mod2.df_model += </span><span class="s4">1</span>
        <span class="s1">cls.res2 = cls.mod2.fit()</span>


<span class="s3">class </span><span class="s1">TestNxOneNx(TestDataDimensions):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestNxOneNx</span><span class="s3">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">cls.mod2 = OLS(cls.endog_n_one</span><span class="s3">, </span><span class="s1">cls.exog_n_)</span>
        <span class="s1">cls.mod2.df_model += </span><span class="s4">1</span>
        <span class="s1">cls.res2 = cls.mod2.fit()</span>


<span class="s3">class </span><span class="s1">TestNxNxOne(TestDataDimensions):</span>
    <span class="s1">@classmethod</span>
    <span class="s3">def </span><span class="s1">setup_class(cls):</span>
        <span class="s1">super(TestNxNxOne</span><span class="s3">, </span><span class="s1">cls).setup_class()</span>
        <span class="s1">cls.mod2 = OLS(cls.endog_n_</span><span class="s3">, </span><span class="s1">cls.exog_n_one)</span>
        <span class="s1">cls.mod2.df_model += </span><span class="s4">1</span>
        <span class="s1">cls.res2 = cls.mod2.fit()</span>


<span class="s3">def </span><span class="s1">test_bad_size():</span>
    <span class="s1">np.random.seed(</span><span class="s4">54321</span><span class="s1">)</span>
    <span class="s1">data = np.random.uniform(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">20</span><span class="s3">, </span><span class="s4">31</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s3">, </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">data[</span><span class="s4">1</span><span class="s1">:])</span>


<span class="s3">def </span><span class="s1">test_const_indicator():</span>
    <span class="s1">rs = np.random.RandomState(</span><span class="s4">12345</span><span class="s1">)</span>
    <span class="s1">x = rs.randint(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s1">size=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">x = pd.get_dummies(pd.Series(x</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s5">&quot;category&quot;</span><span class="s1">)</span><span class="s3">, </span><span class="s1">drop_first=</span><span class="s3">False,</span>
                       <span class="s1">dtype=float)</span>
    <span class="s1">y = np.dot(x</span><span class="s3">, </span><span class="s1">[</span><span class="s4">1.0</span><span class="s3">, </span><span class="s4">2.0</span><span class="s3">, </span><span class="s4">3.0</span><span class="s1">]) + rs.normal(size=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">resc = OLS(y</span><span class="s3">, </span><span class="s1">add_constant(x.iloc[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:]</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">True</span><span class="s1">)).fit()</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">hasconst=</span><span class="s3">True</span><span class="s1">).fit()</span>
    <span class="s1">assert_almost_equal(resc.rsquared</span><span class="s3">, </span><span class="s1">res.rsquared</span><span class="s3">, </span><span class="s4">12</span><span class="s1">)</span>
    <span class="s3">assert </span><span class="s1">res.model.data.k_constant == </span><span class="s4">1</span>
    <span class="s3">assert </span><span class="s1">resc.model.data.k_constant == </span><span class="s4">1</span>


<span class="s3">def </span><span class="s1">test_fvalue_const_only():</span>
    <span class="s1">rs = np.random.RandomState(</span><span class="s4">12345</span><span class="s1">)</span>
    <span class="s1">x = rs.randint(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s1">size=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">x = pd.get_dummies(pd.Series(x</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s5">&quot;category&quot;</span><span class="s1">)</span><span class="s3">, </span><span class="s1">drop_first=</span><span class="s3">False,</span>
                       <span class="s1">dtype=float)</span>
    <span class="s1">x[x.columns[</span><span class="s4">0</span><span class="s1">]] = </span><span class="s4">1</span>
    <span class="s1">y = np.dot(x</span><span class="s3">, </span><span class="s1">[</span><span class="s4">1.0</span><span class="s3">, </span><span class="s4">2.0</span><span class="s3">, </span><span class="s4">3.0</span><span class="s1">]) + rs.normal(size=</span><span class="s4">30</span><span class="s1">)</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">hasconst=</span><span class="s3">True</span><span class="s1">).fit(cov_type=</span><span class="s5">&quot;HC1&quot;</span><span class="s1">)</span>
    <span class="s3">assert not </span><span class="s1">np.isnan(res.fvalue)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res.fvalue</span><span class="s3">, </span><span class="s1">float)</span>
    <span class="s3">assert </span><span class="s1">isinstance(res.f_pvalue</span><span class="s3">, </span><span class="s1">float)</span>


<span class="s3">def </span><span class="s1">test_conf_int_single_regressor():</span>
    <span class="s2"># GH#706 single-regressor model (i.e. no intercept) with 1D exog</span>
    <span class="s2"># should get passed to DataFrame for conf_int</span>
    <span class="s1">y = pd.Series(np.random.randn(</span><span class="s4">10</span><span class="s1">))</span>
    <span class="s1">x = pd.Series(np.ones(</span><span class="s4">10</span><span class="s1">))</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
    <span class="s1">conf_int = res.conf_int()</span>
    <span class="s1">np.testing.assert_equal(conf_int.shape</span><span class="s3">, </span><span class="s1">(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s1">))</span>
    <span class="s1">np.testing.assert_(isinstance(conf_int</span><span class="s3">, </span><span class="s1">pd.DataFrame))</span>


<span class="s3">def </span><span class="s1">test_summary_as_latex():</span>
    <span class="s2"># GH#734</span>
    <span class="s3">import </span><span class="s1">re</span>

    <span class="s1">dta = longley.load_pandas()</span>
    <span class="s1">x = dta.exog</span>
    <span class="s1">x[</span><span class="s5">&quot;constant&quot;</span><span class="s1">] = </span><span class="s4">1</span>
    <span class="s1">y = dta.endog</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
    <span class="s3">with </span><span class="s1">pytest.warns(UserWarning):</span>
        <span class="s1">table = res.summary().as_latex()</span>
    <span class="s2"># replace the date and time</span>
    <span class="s1">table = re.sub(</span>
        <span class="s5">&quot;(?&lt;=</span><span class="s3">\n\\\\</span><span class="s5">textbf</span><span class="s3">\\</span><span class="s5">{Date:</span><span class="s3">\\</span><span class="s5">}             &amp;).+?&amp;&quot;</span><span class="s3">,</span>
        <span class="s5">&quot; Sun, 07 Apr 2013 &amp;&quot;</span><span class="s3">,</span>
        <span class="s1">table</span><span class="s3">,</span>
    <span class="s1">)</span>
    <span class="s1">table = re.sub(</span>
        <span class="s5">&quot;(?&lt;=</span><span class="s3">\n\\\\</span><span class="s5">textbf</span><span class="s3">\\</span><span class="s5">{Time:</span><span class="s3">\\</span><span class="s5">}             &amp;).+?&amp;&quot;</span><span class="s3">,</span>
        <span class="s5">&quot;     13:46:07     &amp;&quot;</span><span class="s3">,</span>
        <span class="s1">table</span><span class="s3">,</span>
    <span class="s1">)</span>

    <span class="s1">expected = </span><span class="s5">&quot;&quot;&quot;</span><span class="s3">\\</span><span class="s5">begin{center} 
</span><span class="s3">\\</span><span class="s5">begin{tabular}{lclc} 
</span><span class="s3">\\</span><span class="s5">toprule 
</span><span class="s3">\\</span><span class="s5">textbf{Dep. Variable:}    &amp;      TOTEMP      &amp; </span><span class="s3">\\</span><span class="s5">textbf{  R-squared:         } &amp;     0.995   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Model:}            &amp;       OLS        &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Adj. R-squared:    } &amp;     0.992   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Method:}           &amp;  Least Squares   &amp; </span><span class="s3">\\</span><span class="s5">textbf{  F-statistic:       } &amp;     330.3   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Date:}             &amp; Sun, 07 Apr 2013 &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Prob (F-statistic):} &amp;  4.98e-10   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Time:}             &amp;     13:46:07     &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Log-Likelihood:    } &amp;   -109.62   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{No. Observations:} &amp;          16      &amp; </span><span class="s3">\\</span><span class="s5">textbf{  AIC:               } &amp;     233.2   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Df Residuals:}     &amp;           9      &amp; </span><span class="s3">\\</span><span class="s5">textbf{  BIC:               } &amp;     238.6   </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Df Model:}         &amp;           6      &amp; </span><span class="s3">\\</span><span class="s5">textbf{                     } &amp;             </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Covariance Type:}  &amp;    nonrobust     &amp; </span><span class="s3">\\</span><span class="s5">textbf{                     } &amp;             </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">bottomrule 
</span><span class="s3">\\</span><span class="s5">end{tabular} 
</span><span class="s3">\\</span><span class="s5">begin{tabular}{lcccccc} 
                  &amp; </span><span class="s3">\\</span><span class="s5">textbf{coef} &amp; </span><span class="s3">\\</span><span class="s5">textbf{std err} &amp; </span><span class="s3">\\</span><span class="s5">textbf{t} &amp; </span><span class="s3">\\</span><span class="s5">textbf{P$&gt; |$t$|$} &amp; </span><span class="s3">\\</span><span class="s5">textbf{[0.025} &amp; </span><span class="s3">\\</span><span class="s5">textbf{0.975]}  </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">midrule 
</span><span class="s3">\\</span><span class="s5">textbf{GNPDEFL}  &amp;      15.0619  &amp;       84.915     &amp;     0.177  &amp;         0.863        &amp;     -177.029    &amp;      207.153     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{GNP}      &amp;      -0.0358  &amp;        0.033     &amp;    -1.070  &amp;         0.313        &amp;       -0.112    &amp;        0.040     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{UNEMP}    &amp;      -2.0202  &amp;        0.488     &amp;    -4.136  &amp;         0.003        &amp;       -3.125    &amp;       -0.915     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{ARMED}    &amp;      -1.0332  &amp;        0.214     &amp;    -4.822  &amp;         0.001        &amp;       -1.518    &amp;       -0.549     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{POP}      &amp;      -0.0511  &amp;        0.226     &amp;    -0.226  &amp;         0.826        &amp;       -0.563    &amp;        0.460     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{YEAR}     &amp;    1829.1515  &amp;      455.478     &amp;     4.016  &amp;         0.003        &amp;      798.788    &amp;     2859.515     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{constant} &amp;   -3.482e+06  &amp;      8.9e+05     &amp;    -3.911  &amp;         0.004        &amp;     -5.5e+06    &amp;    -1.47e+06     </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">bottomrule 
</span><span class="s3">\\</span><span class="s5">end{tabular} 
</span><span class="s3">\\</span><span class="s5">begin{tabular}{lclc} 
</span><span class="s3">\\</span><span class="s5">textbf{Omnibus:}       &amp;  0.749 &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Durbin-Watson:     } &amp;    2.559  </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Prob(Omnibus):} &amp;  0.688 &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Jarque-Bera (JB):  } &amp;    0.684  </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Skew:}          &amp;  0.420 &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Prob(JB):          } &amp;    0.710  </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">textbf{Kurtosis:}      &amp;  2.434 &amp; </span><span class="s3">\\</span><span class="s5">textbf{  Cond. No.          } &amp; 4.86e+09  </span><span class="s3">\\\\</span>
<span class="s3">\\</span><span class="s5">bottomrule 
</span><span class="s3">\\</span><span class="s5">end{tabular} 
%</span><span class="s3">\\</span><span class="s5">caption{OLS Regression Results} 
</span><span class="s3">\\</span><span class="s5">end{center} 
 
Notes: </span><span class="s3">\\</span><span class="s5">newline 
 [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. </span><span class="s3">\\</span><span class="s5">newline 
 [2] The condition number is large, 4.86e+09. This might indicate that there are </span><span class="s3">\\</span><span class="s5">newline 
 strong multicollinearity or other numerical problems.&quot;&quot;&quot;</span>
    <span class="s1">assert_equal(table</span><span class="s3">, </span><span class="s1">expected)</span>


<span class="s3">class </span><span class="s1">TestRegularizedFit:</span>

    <span class="s2"># Make sure there are no problems when no variables are selected.</span>
    <span class="s3">def </span><span class="s1">test_empty_model(self):</span>

        <span class="s1">np.random.seed(</span><span class="s4">742</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s4">100</span>
        <span class="s1">endog = np.random.normal(size=n)</span>
        <span class="s1">exog = np.random.normal(size=(n</span><span class="s3">, </span><span class="s4">3</span><span class="s1">))</span>

        <span class="s3">for </span><span class="s1">cls </span><span class="s3">in </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">WLS</span><span class="s3">, </span><span class="s1">GLS:</span>
            <span class="s1">model = cls(endog</span><span class="s3">, </span><span class="s1">exog)</span>
            <span class="s1">result = model.fit_regularized(alpha=</span><span class="s4">1000</span><span class="s1">)</span>
            <span class="s1">assert_equal(result.params</span><span class="s3">, </span><span class="s4">0.0</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_regularized(self):</span>

        <span class="s3">import </span><span class="s1">os</span>

        <span class="s3">from </span><span class="s1">.results </span><span class="s3">import </span><span class="s1">glmnet_r_results</span>

        <span class="s1">cur_dir = os.path.dirname(os.path.abspath(__file__))</span>
        <span class="s1">data = np.loadtxt(</span>
            <span class="s1">os.path.join(cur_dir</span><span class="s3">, </span><span class="s5">&quot;results&quot;</span><span class="s3">, </span><span class="s5">&quot;lasso_data.csv&quot;</span><span class="s1">)</span><span class="s3">, </span><span class="s1">delimiter=</span><span class="s5">&quot;,&quot;</span>
        <span class="s1">)</span>

        <span class="s1">tests = [x </span><span class="s3">for </span><span class="s1">x </span><span class="s3">in </span><span class="s1">dir(glmnet_r_results) </span><span class="s3">if </span><span class="s1">x.startswith(</span><span class="s5">&quot;rslt_&quot;</span><span class="s1">)]</span>

        <span class="s3">for </span><span class="s1">test </span><span class="s3">in </span><span class="s1">tests:</span>

            <span class="s1">vec = getattr(glmnet_r_results</span><span class="s3">, </span><span class="s1">test)</span>

            <span class="s1">n = vec[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">p = vec[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">L1_wt = float(vec[</span><span class="s4">2</span><span class="s1">])</span>
            <span class="s1">lam = float(vec[</span><span class="s4">3</span><span class="s1">])</span>
            <span class="s1">params = vec[</span><span class="s4">4</span><span class="s1">:].astype(np.float64)</span>

            <span class="s1">endog = data[</span><span class="s4">0 </span><span class="s1">: int(n)</span><span class="s3">, </span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">exog = data[</span><span class="s4">0 </span><span class="s1">: int(n)</span><span class="s3">, </span><span class="s4">1 </span><span class="s1">: (int(p) + </span><span class="s4">1</span><span class="s1">)]</span>

            <span class="s1">endog = endog - endog.mean()</span>
            <span class="s1">endog /= endog.std(ddof=</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">exog = exog - exog.mean(</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">exog /= exog.std(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">ddof=</span><span class="s4">1</span><span class="s1">)</span>

            <span class="s3">for </span><span class="s1">cls </span><span class="s3">in </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">WLS</span><span class="s3">, </span><span class="s1">GLS:</span>
                <span class="s1">mod = cls(endog</span><span class="s3">, </span><span class="s1">exog)</span>
                <span class="s1">rslt = mod.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=lam)</span>
                <span class="s1">assert_almost_equal(rslt.params</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>

                <span class="s2"># Smoke test for profile likelihood</span>
                <span class="s1">mod.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=lam</span><span class="s3">, </span><span class="s1">profile_scale=</span><span class="s3">True</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_regularized_weights(self):</span>

        <span class="s1">np.random.seed(</span><span class="s4">1432</span><span class="s1">)</span>
        <span class="s1">exog1 = np.random.normal(size=(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">3</span><span class="s1">))</span>
        <span class="s1">endog1 = exog1[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] + exog1[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] + np.random.normal(size=</span><span class="s4">100</span><span class="s1">)</span>
        <span class="s1">exog2 = np.random.normal(size=(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">3</span><span class="s1">))</span>
        <span class="s1">endog2 = exog2[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] + exog2[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] + np.random.normal(size=</span><span class="s4">100</span><span class="s1">)</span>

        <span class="s1">exog_a = np.vstack((exog1</span><span class="s3">, </span><span class="s1">exog1</span><span class="s3">, </span><span class="s1">exog2))</span>
        <span class="s1">endog_a = np.concatenate((endog1</span><span class="s3">, </span><span class="s1">endog1</span><span class="s3">, </span><span class="s1">endog2))</span>

        <span class="s2"># Should be equivalent to exog_a, endog_a.</span>
        <span class="s1">exog_b = np.vstack((exog1</span><span class="s3">, </span><span class="s1">exog2))</span>
        <span class="s1">endog_b = np.concatenate((endog1</span><span class="s3">, </span><span class="s1">endog2))</span>
        <span class="s1">wgts = np.ones(</span><span class="s4">200</span><span class="s1">)</span>
        <span class="s1">wgts[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">100</span><span class="s1">] = </span><span class="s4">2</span>
        <span class="s1">sigma = np.diag(</span><span class="s4">1 </span><span class="s1">/ wgts)</span>

        <span class="s3">for </span><span class="s1">L1_wt </span><span class="s3">in </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">for </span><span class="s1">alpha </span><span class="s3">in </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">mod1 = OLS(endog_a</span><span class="s3">, </span><span class="s1">exog_a)</span>
                <span class="s1">rslt1 = mod1.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">mod2 = WLS(endog_b</span><span class="s3">, </span><span class="s1">exog_b</span><span class="s3">, </span><span class="s1">weights=wgts)</span>
                <span class="s1">rslt2 = mod2.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">mod3 = GLS(endog_b</span><span class="s3">, </span><span class="s1">exog_b</span><span class="s3">, </span><span class="s1">sigma=sigma)</span>
                <span class="s1">rslt3 = mod3.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">assert_almost_equal(rslt1.params</span><span class="s3">, </span><span class="s1">rslt2.params</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
                <span class="s1">assert_almost_equal(rslt1.params</span><span class="s3">, </span><span class="s1">rslt3.params</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">test_regularized_weights_list(self):</span>

        <span class="s1">np.random.seed(</span><span class="s4">132</span><span class="s1">)</span>
        <span class="s1">exog1 = np.random.normal(size=(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">3</span><span class="s1">))</span>
        <span class="s1">endog1 = exog1[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] + exog1[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] + np.random.normal(size=</span><span class="s4">100</span><span class="s1">)</span>
        <span class="s1">exog2 = np.random.normal(size=(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">3</span><span class="s1">))</span>
        <span class="s1">endog2 = exog2[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] + exog2[:</span><span class="s3">, </span><span class="s4">1</span><span class="s1">] + np.random.normal(size=</span><span class="s4">100</span><span class="s1">)</span>

        <span class="s1">exog_a = np.vstack((exog1</span><span class="s3">, </span><span class="s1">exog1</span><span class="s3">, </span><span class="s1">exog2))</span>
        <span class="s1">endog_a = np.concatenate((endog1</span><span class="s3">, </span><span class="s1">endog1</span><span class="s3">, </span><span class="s1">endog2))</span>

        <span class="s2"># Should be equivalent to exog_a, endog_a.</span>
        <span class="s1">exog_b = np.vstack((exog1</span><span class="s3">, </span><span class="s1">exog2))</span>
        <span class="s1">endog_b = np.concatenate((endog1</span><span class="s3">, </span><span class="s1">endog2))</span>
        <span class="s1">wgts = np.ones(</span><span class="s4">200</span><span class="s1">)</span>
        <span class="s1">wgts[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">100</span><span class="s1">] = </span><span class="s4">2</span>
        <span class="s1">sigma = np.diag(</span><span class="s4">1 </span><span class="s1">/ wgts)</span>

        <span class="s3">for </span><span class="s1">L1_wt </span><span class="s3">in </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">for </span><span class="s1">alpha_element </span><span class="s3">in </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">alpha = [</span>
                    <span class="s1">alpha_element</span><span class="s3">,</span>
                <span class="s1">] * </span><span class="s4">3</span>

                <span class="s1">mod1 = OLS(endog_a</span><span class="s3">, </span><span class="s1">exog_a)</span>
                <span class="s1">rslt1 = mod1.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">mod2 = WLS(endog_b</span><span class="s3">, </span><span class="s1">exog_b</span><span class="s3">, </span><span class="s1">weights=wgts)</span>
                <span class="s1">rslt2 = mod2.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">mod3 = GLS(endog_b</span><span class="s3">, </span><span class="s1">exog_b</span><span class="s3">, </span><span class="s1">sigma=sigma)</span>
                <span class="s1">rslt3 = mod3.fit_regularized(L1_wt=L1_wt</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>

                <span class="s1">assert_almost_equal(rslt1.params</span><span class="s3">, </span><span class="s1">rslt2.params</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>
                <span class="s1">assert_almost_equal(rslt1.params</span><span class="s3">, </span><span class="s1">rslt3.params</span><span class="s3">, </span><span class="s1">decimal=</span><span class="s4">3</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_formula_missing_cat():</span>
    <span class="s2"># gh-805</span>

    <span class="s3">from </span><span class="s1">patsy </span><span class="s3">import </span><span class="s1">PatsyError</span>

    <span class="s3">import </span><span class="s1">statsmodels.api </span><span class="s3">as </span><span class="s1">sm</span>
    <span class="s3">from </span><span class="s1">statsmodels.formula.api </span><span class="s3">import </span><span class="s1">ols</span>

    <span class="s1">dta = sm.datasets.grunfeld.load_pandas().data</span>
    <span class="s1">dta.loc[dta.index[</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s5">&quot;firm&quot;</span><span class="s1">] = np.nan</span>

    <span class="s1">mod = ols(</span>
        <span class="s1">formula=</span><span class="s5">&quot;value ~ invest + capital + firm + year&quot;</span><span class="s3">, </span><span class="s1">data=dta.dropna()</span>
    <span class="s1">)</span>
    <span class="s1">res = mod.fit()</span>

    <span class="s1">mod2 = ols(formula=</span><span class="s5">&quot;value ~ invest + capital + firm + year&quot;</span><span class="s3">, </span><span class="s1">data=dta)</span>
    <span class="s1">res2 = mod2.fit()</span>

    <span class="s1">assert_almost_equal(res.params.values</span><span class="s3">, </span><span class="s1">res2.params.values)</span>

    <span class="s1">assert_raises(</span>
        <span class="s1">PatsyError</span><span class="s3">,</span>
        <span class="s1">ols</span><span class="s3">,</span>
        <span class="s5">&quot;value ~ invest + capital + firm + year&quot;</span><span class="s3">,</span>
        <span class="s1">data=dta</span><span class="s3">,</span>
        <span class="s1">missing=</span><span class="s5">&quot;raise&quot;</span><span class="s3">,</span>
    <span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_missing_formula_predict():</span>
    <span class="s2"># see 2171</span>
    <span class="s1">nsample = </span><span class="s4">30</span>

    <span class="s1">data = np.linspace(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">10</span><span class="s3">, </span><span class="s1">nsample)</span>
    <span class="s1">null = np.array([np.nan])</span>
    <span class="s1">data = pd.DataFrame({</span><span class="s5">&quot;x&quot;</span><span class="s1">: np.concatenate((data</span><span class="s3">, </span><span class="s1">null))})</span>
    <span class="s1">beta = np.array([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.1</span><span class="s1">])</span>
    <span class="s1">e = np.random.normal(size=nsample + </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">data[</span><span class="s5">&quot;y&quot;</span><span class="s1">] = beta[</span><span class="s4">0</span><span class="s1">] + beta[</span><span class="s4">1</span><span class="s1">] * data[</span><span class="s5">&quot;x&quot;</span><span class="s1">] + e</span>
    <span class="s1">model = OLS.from_formula(</span><span class="s5">&quot;y ~ x&quot;</span><span class="s3">, </span><span class="s1">data=data)</span>
    <span class="s1">fit = model.fit()</span>
    <span class="s1">fit.predict(exog=data[:-</span><span class="s4">1</span><span class="s1">])</span>


<span class="s3">def </span><span class="s1">test_fvalue_implicit_constant():</span>
    <span class="s2"># if constant is implicit, return nan see #2444</span>
    <span class="s1">nobs = </span><span class="s4">100</span>
    <span class="s1">np.random.seed(</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">x = np.random.randn(nobs</span><span class="s3">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">x = ((x &gt; </span><span class="s4">0</span><span class="s1">) == [</span><span class="s3">True, False</span><span class="s1">]).astype(int)</span>
    <span class="s1">y = x.sum(</span><span class="s4">1</span><span class="s1">) + np.random.randn(nobs)</span>

    <span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">WLS</span>

    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit(cov_type=</span><span class="s5">&quot;HC1&quot;</span><span class="s1">)</span>
    <span class="s1">assert_(np.isnan(res.fvalue))</span>
    <span class="s1">assert_(np.isnan(res.f_pvalue))</span>
    <span class="s1">res.summary()</span>

    <span class="s1">res = WLS(y</span><span class="s3">, </span><span class="s1">x).fit(cov_type=</span><span class="s5">&quot;HC1&quot;</span><span class="s1">)</span>
    <span class="s1">assert_(np.isnan(res.fvalue))</span>
    <span class="s1">assert_(np.isnan(res.f_pvalue))</span>
    <span class="s1">res.summary()</span>


<span class="s3">def </span><span class="s1">test_fvalue_only_constant():</span>
    <span class="s2"># if only constant in model, return nan see #3642</span>
    <span class="s1">nobs = </span><span class="s4">20</span>
    <span class="s1">np.random.seed(</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">x = np.ones(nobs)</span>
    <span class="s1">y = np.random.randn(nobs)</span>

    <span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">WLS</span>

    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit(cov_type=</span><span class="s5">&quot;hac&quot;</span><span class="s3">, </span><span class="s1">cov_kwds={</span><span class="s5">&quot;maxlags&quot;</span><span class="s1">: </span><span class="s4">3</span><span class="s1">})</span>
    <span class="s1">assert_(np.isnan(res.fvalue))</span>
    <span class="s1">assert_(np.isnan(res.f_pvalue))</span>
    <span class="s1">res.summary()</span>

    <span class="s1">res = WLS(y</span><span class="s3">, </span><span class="s1">x).fit(cov_type=</span><span class="s5">&quot;HC1&quot;</span><span class="s1">)</span>
    <span class="s1">assert_(np.isnan(res.fvalue))</span>
    <span class="s1">assert_(np.isnan(res.f_pvalue))</span>
    <span class="s1">res.summary()</span>


<span class="s3">def </span><span class="s1">test_ridge():</span>
    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">5</span>
    <span class="s1">np.random.seed(</span><span class="s4">3132</span><span class="s1">)</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span>
    <span class="s1">yvec = xmat.sum(</span><span class="s4">1</span><span class="s1">) + np.random.normal(size=n)</span>

    <span class="s1">v = np.ones(p)</span>
    <span class="s1">v[</span><span class="s4">0</span><span class="s1">] = </span><span class="s4">0</span>

    <span class="s3">for </span><span class="s1">a </span><span class="s3">in </span><span class="s1">(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">10</span><span class="s1">):</span>
        <span class="s3">for </span><span class="s1">alpha </span><span class="s3">in </span><span class="s1">(a</span><span class="s3">, </span><span class="s1">a * np.ones(p)</span><span class="s3">, </span><span class="s1">a * v):</span>
            <span class="s1">model1 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat)</span>
            <span class="s1">result1 = model1._fit_ridge(alpha=alpha)</span>
            <span class="s1">model2 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat)</span>
            <span class="s1">result2 = model2.fit_regularized(alpha=alpha</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">assert_allclose(result1.params</span><span class="s3">, </span><span class="s1">result2.params)</span>
            <span class="s1">model3 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat)</span>
            <span class="s1">result3 = model3.fit_regularized(alpha=alpha</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">1e-10</span><span class="s1">)</span>
            <span class="s1">assert_allclose(result1.params</span><span class="s3">, </span><span class="s1">result3.params)</span>

    <span class="s1">fv1 = result1.fittedvalues</span>
    <span class="s1">fv2 = np.dot(xmat</span><span class="s3">, </span><span class="s1">result1.params)</span>
    <span class="s1">assert_allclose(fv1</span><span class="s3">, </span><span class="s1">fv2)</span>


<span class="s3">def </span><span class="s1">test_regularized_refit():</span>
    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">5</span>
    <span class="s1">np.random.seed(</span><span class="s4">3132</span><span class="s1">)</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span>
    <span class="s2"># covariates 0 and 2 matter</span>
    <span class="s1">yvec = xmat[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">] + xmat[:</span><span class="s3">, </span><span class="s4">2</span><span class="s1">] + np.random.normal(size=n)</span>
    <span class="s1">model1 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat)</span>
    <span class="s1">result1 = model1.fit_regularized(alpha=</span><span class="s4">2.0</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">refit=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s1">model2 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat[:</span><span class="s3">, </span><span class="s1">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]])</span>
    <span class="s1">result2 = model2.fit()</span>
    <span class="s1">ii = [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">assert_allclose(result1.params[ii]</span><span class="s3">, </span><span class="s1">result2.params)</span>
    <span class="s1">assert_allclose(result1.bse[ii]</span><span class="s3">, </span><span class="s1">result2.bse)</span>


<span class="s3">def </span><span class="s1">test_regularized_predict():</span>
    <span class="s2"># this also compares WLS with GLS</span>
    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">5</span>
    <span class="s1">np.random.seed(</span><span class="s4">3132</span><span class="s1">)</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span>
    <span class="s1">yvec = xmat.sum(</span><span class="s4">1</span><span class="s1">) + np.random.normal(size=n)</span>
    <span class="s1">wgt = np.random.uniform(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s1">n)</span>
    <span class="s1">model_wls = WLS(yvec</span><span class="s3">, </span><span class="s1">xmat</span><span class="s3">, </span><span class="s1">weights=wgt)</span>
    <span class="s2"># TODO: params is not the same in GLS if sigma=1 / wgt, i.e 1-dim, #7755</span>
    <span class="s1">model_gls1 = GLS(yvec</span><span class="s3">, </span><span class="s1">xmat</span><span class="s3">, </span><span class="s1">sigma=np.diag(</span><span class="s4">1 </span><span class="s1">/ wgt))</span>
    <span class="s1">model_gls2 = GLS(yvec</span><span class="s3">, </span><span class="s1">xmat</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s4">1 </span><span class="s1">/ wgt)</span>
    <span class="s1">res = []</span>
    <span class="s3">for </span><span class="s1">model1 </span><span class="s3">in </span><span class="s1">[model_wls</span><span class="s3">, </span><span class="s1">model_gls1</span><span class="s3">, </span><span class="s1">model_gls2]:</span>
        <span class="s1">result1 = model1.fit_regularized(alpha=</span><span class="s4">20.0</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">refit=</span><span class="s3">True</span><span class="s1">)</span>
        <span class="s1">res.append(result1)</span>
        <span class="s1">params = result1.params</span>
        <span class="s1">fittedvalues = np.dot(xmat</span><span class="s3">, </span><span class="s1">params)</span>
        <span class="s1">pr = model1.predict(result1.params)</span>
        <span class="s1">assert_allclose(fittedvalues</span><span class="s3">, </span><span class="s1">pr)</span>
        <span class="s1">assert_allclose(result1.fittedvalues</span><span class="s3">, </span><span class="s1">pr)</span>

        <span class="s1">pr = result1.predict()</span>
        <span class="s1">assert_allclose(fittedvalues</span><span class="s3">, </span><span class="s1">pr)</span>

    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].model.wendog</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">1</span><span class="s1">].model.wendog</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].model.wexog</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">1</span><span class="s1">].model.wexog</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].fittedvalues</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">1</span><span class="s1">].fittedvalues</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].params</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">1</span><span class="s1">].params</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>

    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].model.wendog</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">2</span><span class="s1">].model.wendog</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].model.wexog</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">2</span><span class="s1">].model.wexog</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].fittedvalues</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">2</span><span class="s1">].fittedvalues</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res[</span><span class="s4">0</span><span class="s1">].params</span><span class="s3">, </span><span class="s1">res[</span><span class="s4">2</span><span class="s1">].params</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-10</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_regularized_options():</span>
    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">5</span>
    <span class="s1">np.random.seed(</span><span class="s4">3132</span><span class="s1">)</span>
    <span class="s1">xmat = np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span>
    <span class="s1">yvec = xmat.sum(</span><span class="s4">1</span><span class="s1">) + np.random.normal(size=n)</span>
    <span class="s1">model1 = OLS(yvec - </span><span class="s4">1</span><span class="s3">, </span><span class="s1">xmat)</span>
    <span class="s1">result1 = model1.fit_regularized(alpha=</span><span class="s4">1.0</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">0.5</span><span class="s1">)</span>
    <span class="s1">model2 = OLS(yvec</span><span class="s3">, </span><span class="s1">xmat</span><span class="s3">, </span><span class="s1">offset=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">result2 = model2.fit_regularized(</span>
        <span class="s1">alpha=</span><span class="s4">1.0</span><span class="s3">, </span><span class="s1">L1_wt=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">start_params=np.zeros(</span><span class="s4">5</span><span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s1">assert_allclose(result1.params</span><span class="s3">, </span><span class="s1">result2.params)</span>


<span class="s3">def </span><span class="s1">test_burg():</span>
    <span class="s1">rnd = np.random.RandomState(</span><span class="s4">12345</span><span class="s1">)</span>
    <span class="s1">e = rnd.randn(</span><span class="s4">10001</span><span class="s1">)</span>
    <span class="s1">y = e[</span><span class="s4">1</span><span class="s1">:] + </span><span class="s4">0.5 </span><span class="s1">* e[:-</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s2"># R, ar.burg</span>
    <span class="s1">expected = [</span>
        <span class="s1">[</span><span class="s4">0.3909931</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s1">[</span><span class="s4">0.4602607</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.1771582</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s1">[</span><span class="s4">0.47473245</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.21475602</span><span class="s3">, </span><span class="s4">0.08168813</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s1">[</span><span class="s4">0.4787017</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.2251910</span><span class="s3">, </span><span class="s4">0.1047554</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.0485900</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s1">[</span><span class="s4">0.47975462</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.22746106</span><span class="s3">, </span><span class="s4">0.10963527</span><span class="s3">, </span><span class="s1">-</span><span class="s4">0.05896347</span><span class="s3">, </span><span class="s4">0.02167001</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">]</span>

    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s3">, </span><span class="s4">6</span><span class="s1">):</span>
        <span class="s1">ar</span><span class="s3">, </span><span class="s1">_ = burg(y</span><span class="s3">, </span><span class="s1">i)</span>
        <span class="s1">assert_allclose(ar</span><span class="s3">, </span><span class="s1">expected[i - </span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-6</span><span class="s1">)</span>
        <span class="s1">as_nodemean</span><span class="s3">, </span><span class="s1">_ = burg(</span><span class="s4">1 </span><span class="s1">+ y</span><span class="s3">, </span><span class="s1">i</span><span class="s3">, False</span><span class="s1">)</span>
        <span class="s3">assert </span><span class="s1">np.all(ar != as_nodemean)</span>


<span class="s3">def </span><span class="s1">test_burg_errors():</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">burg(np.ones((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)))</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">burg(np.random.randn(</span><span class="s4">100</span><span class="s1">)</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s3">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">burg(np.random.randn(</span><span class="s4">100</span><span class="s1">)</span><span class="s3">, </span><span class="s5">&quot;apple&quot;</span><span class="s1">)</span>


<span class="s1">@pytest.mark.skipif(</span><span class="s3">not </span><span class="s1">has_cvxopt</span><span class="s3">, </span><span class="s1">reason=</span><span class="s5">&quot;sqrt_lasso requires cvxopt&quot;</span><span class="s1">)</span>
<span class="s3">def </span><span class="s1">test_sqrt_lasso():</span>

    <span class="s1">np.random.seed(</span><span class="s4">234923</span><span class="s1">)</span>

    <span class="s2"># Based on the example in the Belloni paper</span>
    <span class="s1">n = </span><span class="s4">100</span>
    <span class="s1">p = </span><span class="s4">500</span>
    <span class="s1">ii = np.arange(p)</span>
    <span class="s1">cx = </span><span class="s4">0.5 </span><span class="s1">** np.abs(np.subtract.outer(ii</span><span class="s3">, </span><span class="s1">ii))</span>
    <span class="s1">cxr = np.linalg.cholesky(cx)</span>

    <span class="s1">x = np.dot(np.random.normal(size=(n</span><span class="s3">, </span><span class="s1">p))</span><span class="s3">, </span><span class="s1">cxr.T)</span>
    <span class="s1">b = np.zeros(p)</span>
    <span class="s1">b[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">5</span><span class="s1">] = [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s1">]</span>

    <span class="s3">from </span><span class="s1">scipy.stats.distributions </span><span class="s3">import </span><span class="s1">norm</span>

    <span class="s1">alpha = </span><span class="s4">1.1 </span><span class="s1">* np.sqrt(n) * norm.ppf(</span><span class="s4">1 </span><span class="s1">- </span><span class="s4">0.05 </span><span class="s1">/ (</span><span class="s4">2 </span><span class="s1">* p))</span>

    <span class="s2"># Use very low noise level for a unit test</span>
    <span class="s1">y = np.dot(x</span><span class="s3">, </span><span class="s1">b) + </span><span class="s4">0.25 </span><span class="s1">* np.random.normal(size=n)</span>

    <span class="s2"># At low noise levels, the sqrt lasso should be around a</span>
    <span class="s2"># factor of 3 from the oracle without refit, and should</span>
    <span class="s2"># almost equal the oracle with refit.</span>
    <span class="s1">expected_oracle = {</span><span class="s3">False</span><span class="s1">: </span><span class="s4">3</span><span class="s3">, True</span><span class="s1">: </span><span class="s4">1</span><span class="s1">}</span>

    <span class="s2"># Used for regression testing</span>
    <span class="s1">expected_params = {</span>
        <span class="s3">False</span><span class="s1">: np.r_[</span>
            <span class="s4">0.87397122</span><span class="s3">, </span><span class="s4">0.96051874</span><span class="s3">, </span><span class="s4">0.9905915</span><span class="s3">, </span><span class="s4">0.93868953</span><span class="s3">, </span><span class="s4">0.90771773</span>
        <span class="s1">]</span><span class="s3">,</span>
        <span class="s3">True</span><span class="s1">: np.r_[</span><span class="s4">0.95114241</span><span class="s3">, </span><span class="s4">1.0302987</span><span class="s3">, </span><span class="s4">1.01723074</span><span class="s3">, </span><span class="s4">0.97587343</span><span class="s3">, </span><span class="s4">0.99846403</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">}</span>

    <span class="s3">for </span><span class="s1">refit </span><span class="s3">in False, True</span><span class="s1">:</span>

        <span class="s1">rslt = OLS(y</span><span class="s3">, </span><span class="s1">x).fit_regularized(</span>
            <span class="s1">method=</span><span class="s5">&quot;sqrt_lasso&quot;</span><span class="s3">, </span><span class="s1">alpha=alpha</span><span class="s3">, </span><span class="s1">refit=refit</span>
        <span class="s1">)</span>
        <span class="s1">err = rslt.params - b</span>
        <span class="s1">numer = np.sqrt(np.dot(err</span><span class="s3">, </span><span class="s1">np.dot(cx</span><span class="s3">, </span><span class="s1">err)))</span>

        <span class="s1">oracle = OLS(y</span><span class="s3">, </span><span class="s1">x[:</span><span class="s3">, </span><span class="s4">0</span><span class="s1">:</span><span class="s4">5</span><span class="s1">]).fit()</span>
        <span class="s1">oracle_err = np.zeros(p)</span>
        <span class="s1">oracle_err[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">5</span><span class="s1">] = oracle.params - b[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">5</span><span class="s1">]</span>
        <span class="s1">denom = np.sqrt(np.dot(oracle_err</span><span class="s3">, </span><span class="s1">np.dot(cx</span><span class="s3">, </span><span class="s1">oracle_err)))</span>

        <span class="s2"># Check performance relative to oracle, should be around</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">numer / denom</span><span class="s3">, </span><span class="s1">expected_oracle[refit]</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">0.1</span>
        <span class="s1">)</span>

        <span class="s2"># Regression test the parameters</span>
        <span class="s1">assert_allclose(</span>
            <span class="s1">rslt.params[</span><span class="s4">0</span><span class="s1">:</span><span class="s4">5</span><span class="s1">]</span><span class="s3">, </span><span class="s1">expected_params[refit]</span><span class="s3">, </span><span class="s1">rtol=</span><span class="s4">1e-5</span><span class="s3">, </span><span class="s1">atol=</span><span class="s4">1e-5</span>
        <span class="s1">)</span>


<span class="s3">def </span><span class="s1">test_bool_regressor(reset_randomstate):</span>
    <span class="s1">exog = np.random.randint(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s1">size=(</span><span class="s4">100</span><span class="s3">, </span><span class="s4">2</span><span class="s1">)).astype(bool)</span>
    <span class="s1">endog = np.random.standard_normal(</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">bool_res = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit()</span>
    <span class="s1">res = OLS(endog</span><span class="s3">, </span><span class="s1">exog.astype(np.double)).fit()</span>
    <span class="s1">assert_allclose(bool_res.params</span><span class="s3">, </span><span class="s1">res.params)</span>


<span class="s3">def </span><span class="s1">test_ols_constant(reset_randomstate):</span>
    <span class="s1">y = np.random.standard_normal((</span><span class="s4">200</span><span class="s1">))</span>
    <span class="s1">x = np.ones((</span><span class="s4">200</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
    <span class="s3">with </span><span class="s1">warnings.catch_warnings(record=</span><span class="s3">True</span><span class="s1">) </span><span class="s3">as </span><span class="s1">recording:</span>
        <span class="s3">assert </span><span class="s1">np.isnan(res.fvalue)</span>
        <span class="s3">assert </span><span class="s1">np.isnan(res.f_pvalue)</span>
    <span class="s3">assert </span><span class="s1">len(recording) == </span><span class="s4">0</span>


<span class="s3">def </span><span class="s1">test_summary_no_constant():</span>
    <span class="s1">rs = np.random.RandomState(</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">x = rs.standard_normal((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">2</span><span class="s1">))</span>
    <span class="s1">y = rs.standard_normal(</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">summary = OLS(y</span><span class="s3">, </span><span class="s1">x).fit().summary()</span>
    <span class="s3">assert </span><span class="s5">&quot;R is computed &quot; </span><span class="s3">in </span><span class="s1">summary.as_text()</span>


<span class="s3">def </span><span class="s1">test_condition_number(reset_randomstate):</span>
    <span class="s1">y = np.random.standard_normal(</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">x = np.random.standard_normal((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">x = x + np.random.standard_normal((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
    <span class="s1">assert_allclose(res.condition_number</span><span class="s3">, </span><span class="s1">np.sqrt(np.linalg.cond(x.T @ x)))</span>
    <span class="s1">assert_allclose(res.condition_number</span><span class="s3">, </span><span class="s1">np.linalg.cond(x))</span>


<span class="s3">def </span><span class="s1">test_slim_summary(reset_randomstate):</span>
    <span class="s1">y = np.random.standard_normal(</span><span class="s4">100</span><span class="s1">)</span>
    <span class="s1">x = np.random.standard_normal((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">x = x + np.random.standard_normal((</span><span class="s4">100</span><span class="s3">, </span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">res = OLS(y</span><span class="s3">, </span><span class="s1">x).fit()</span>
    <span class="s3">import </span><span class="s1">copy</span>
    <span class="s1">summ = copy.deepcopy(res.summary())</span>
    <span class="s1">slim_summ = copy.deepcopy(res.summary(slim=</span><span class="s3">True</span><span class="s1">))</span>
    <span class="s3">assert </span><span class="s1">len(summ.tables) == </span><span class="s4">3</span>
    <span class="s3">assert </span><span class="s1">len(slim_summ.tables) == </span><span class="s4">2</span>
    <span class="s3">assert </span><span class="s1">summ.tables[</span><span class="s4">0</span><span class="s1">].as_text() != slim_summ.tables[</span><span class="s4">0</span><span class="s1">].as_text()</span>
    <span class="s3">assert </span><span class="s1">slim_summ.tables[</span><span class="s4">1</span><span class="s1">].as_text() == summ.tables[</span><span class="s4">1</span><span class="s1">].as_text()</span>
</pre>
</body>
</html>
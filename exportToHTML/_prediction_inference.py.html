<html>
<head>
<title>_prediction_inference.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_prediction_inference.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Fri Dec 19 11:29:18 2014 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span>
<span class="s3">import </span><span class="s1">pandas </span><span class="s3">as </span><span class="s1">pd</span>


<span class="s0"># this is similar to ContrastResults after t_test, partially copied, adjusted</span>
<span class="s3">class </span><span class="s1">PredictionResultsBase:</span>
    <span class="s2">&quot;&quot;&quot;Based class for get_prediction results 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">predicted</span><span class="s3">, </span><span class="s1">var_pred</span><span class="s3">, </span><span class="s1">func=</span><span class="s3">None, </span><span class="s1">deriv=</span><span class="s3">None,</span>
                 <span class="s1">df=</span><span class="s3">None, </span><span class="s1">dist=</span><span class="s3">None, </span><span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">**kwds):</span>
        <span class="s1">self.predicted = predicted</span>
        <span class="s1">self.var_pred = var_pred</span>
        <span class="s1">self.func = func</span>
        <span class="s1">self.deriv = deriv</span>
        <span class="s1">self.df = df</span>
        <span class="s1">self.row_labels = row_labels</span>
        <span class="s1">self.__dict__.update(kwds)</span>

        <span class="s3">if </span><span class="s1">dist </span><span class="s3">is None or </span><span class="s1">dist == </span><span class="s4">'norm'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.norm</span>
            <span class="s1">self.dist_args = ()</span>
        <span class="s3">elif </span><span class="s1">dist == </span><span class="s4">'t'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.t</span>
            <span class="s1">self.dist_args = (self.df</span><span class="s3">,</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self.dist = dist</span>
            <span class="s1">self.dist_args = ()</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">se(self):</span>
        <span class="s3">return </span><span class="s1">np.sqrt(self.var_pred)</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">tvalues(self):</span>
        <span class="s3">return </span><span class="s1">self.predicted / self.se</span>

    <span class="s3">def </span><span class="s1">t_test(self</span><span class="s3">, </span><span class="s1">value=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s4">'two-sided'</span><span class="s1">):</span>
        <span class="s2">'''z- or t-test for hypothesis that mean is equal to value 
 
        Parameters 
        ---------- 
        value : array_like 
            value under the null hypothesis 
        alternative : str 
            'two-sided', 'larger', 'smaller' 
 
        Returns 
        ------- 
        stat : ndarray 
            test statistic 
        pvalue : ndarray 
            p-value of the hypothesis test, the distribution is given by 
            the attribute of the instance, specified in `__init__`. Default 
            if not specified is the normal distribution. 
 
        '''</span>
        <span class="s0"># assumes symmetric distribution</span>
        <span class="s1">stat = (self.predicted - value) / self.se</span>

        <span class="s3">if </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'two-sided'</span><span class="s3">, </span><span class="s4">'2-sided'</span><span class="s3">, </span><span class="s4">'2s'</span><span class="s1">]:</span>
            <span class="s1">pvalue = self.dist.sf(np.abs(stat)</span><span class="s3">, </span><span class="s1">*self.dist_args)*</span><span class="s5">2</span>
        <span class="s3">elif </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'larger'</span><span class="s3">, </span><span class="s4">'l'</span><span class="s1">]:</span>
            <span class="s1">pvalue = self.dist.sf(stat</span><span class="s3">, </span><span class="s1">*self.dist_args)</span>
        <span class="s3">elif </span><span class="s1">alternative </span><span class="s3">in </span><span class="s1">[</span><span class="s4">'smaller'</span><span class="s3">, </span><span class="s4">'s'</span><span class="s1">]:</span>
            <span class="s1">pvalue = self.dist.cdf(stat</span><span class="s3">, </span><span class="s1">*self.dist_args)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'invalid alternative'</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">stat</span><span class="s3">, </span><span class="s1">pvalue</span>

    <span class="s3">def </span><span class="s1">_conf_int_generic(self</span><span class="s3">, </span><span class="s1">center</span><span class="s3">, </span><span class="s1">se</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">dist_args=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;internal function to avoid code duplication 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">dist_args </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">dist_args = ()</span>

        <span class="s1">q = self.dist.ppf(</span><span class="s5">1 </span><span class="s1">- alpha / </span><span class="s5">2.</span><span class="s3">, </span><span class="s1">*dist_args)</span>
        <span class="s1">lower = center - q * se</span>
        <span class="s1">upper = center + q * se</span>
        <span class="s1">ci = np.column_stack((lower</span><span class="s3">, </span><span class="s1">upper))</span>
        <span class="s0"># if we want to stack at a new last axis, for lower.ndim &gt; 1</span>
        <span class="s0"># np.concatenate((lower[..., None], upper[..., None]), axis=-1)</span>
        <span class="s3">return </span><span class="s1">ci</span>

    <span class="s3">def </span><span class="s1">conf_int(self</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s2">&quot;&quot;&quot;Confidence interval for the predicted value. 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            The significance level for the confidence interval. 
            ie., The default `alpha` = .05 returns a 95% confidence interval. 
 
        kwds : extra keyword arguments 
            Ignored in base class, only for compatibility, consistent signature 
            with subclasses 
 
        Returns 
        ------- 
        ci : ndarray, (k_constraints, 2) 
            The array has the lower and the upper limit of the confidence 
            interval in the columns. 
        &quot;&quot;&quot;</span>

        <span class="s1">ci = self._conf_int_generic(self.predicted</span><span class="s3">, </span><span class="s1">self.se</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">,</span>
                                    <span class="s1">dist_args=self.dist_args)</span>
        <span class="s3">return </span><span class="s1">ci</span>

    <span class="s3">def </span><span class="s1">summary_frame(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Summary frame 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            The significance level for the confidence interval. 
            ie., The default `alpha` = .05 returns a 95% confidence interval. 
 
        Returns 
        ------- 
        pandas DataFrame with columns 'predicted', 'se', 'ci_lower', 'ci_upper' 
        &quot;&quot;&quot;</span>
        <span class="s1">ci = self.conf_int(alpha=alpha)</span>
        <span class="s1">to_include = {}</span>
        <span class="s1">to_include[</span><span class="s4">'predicted'</span><span class="s1">] = self.predicted</span>
        <span class="s1">to_include[</span><span class="s4">'se'</span><span class="s1">] = self.se</span>
        <span class="s1">to_include[</span><span class="s4">'ci_lower'</span><span class="s1">] = ci[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">to_include[</span><span class="s4">'ci_upper'</span><span class="s1">] = ci[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">self.table = to_include</span>
        <span class="s0"># pandas dict does not handle 2d_array</span>
        <span class="s0"># data = np.column_stack(list(to_include.values()))</span>
        <span class="s0"># names = ....</span>
        <span class="s1">res = pd.DataFrame(to_include</span><span class="s3">, </span><span class="s1">index=self.row_labels</span><span class="s3">,</span>
                           <span class="s1">columns=to_include.keys())</span>
        <span class="s3">return </span><span class="s1">res</span>


<span class="s3">class </span><span class="s1">PredictionResultsMonotonic(PredictionResultsBase):</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">predicted</span><span class="s3">, </span><span class="s1">var_pred</span><span class="s3">, </span><span class="s1">linpred=</span><span class="s3">None, </span><span class="s1">linpred_se=</span><span class="s3">None,</span>
                 <span class="s1">func=</span><span class="s3">None, </span><span class="s1">deriv=</span><span class="s3">None, </span><span class="s1">df=</span><span class="s3">None, </span><span class="s1">dist=</span><span class="s3">None, </span><span class="s1">row_labels=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0"># TODO: is var_resid used? drop from arguments?</span>
        <span class="s1">self.predicted = predicted</span>
        <span class="s1">self.var_pred = var_pred</span>
        <span class="s1">self.linpred = linpred</span>
        <span class="s1">self.linpred_se = linpred_se</span>
        <span class="s1">self.func = func</span>
        <span class="s1">self.deriv = deriv</span>
        <span class="s1">self.df = df</span>
        <span class="s1">self.row_labels = row_labels</span>

        <span class="s3">if </span><span class="s1">dist </span><span class="s3">is None or </span><span class="s1">dist == </span><span class="s4">'norm'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.norm</span>
            <span class="s1">self.dist_args = ()</span>
        <span class="s3">elif </span><span class="s1">dist == </span><span class="s4">'t'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.t</span>
            <span class="s1">self.dist_args = (self.df</span><span class="s3">,</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self.dist = dist</span>
            <span class="s1">self.dist_args = ()</span>

    <span class="s3">def </span><span class="s1">_conf_int_generic(self</span><span class="s3">, </span><span class="s1">center</span><span class="s3">, </span><span class="s1">se</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">dist_args=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;internal function to avoid code duplication 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">dist_args </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">dist_args = ()</span>

        <span class="s1">q = self.dist.ppf(</span><span class="s5">1 </span><span class="s1">- alpha / </span><span class="s5">2.</span><span class="s3">, </span><span class="s1">*dist_args)</span>
        <span class="s1">lower = center - q * se</span>
        <span class="s1">upper = center + q * se</span>
        <span class="s1">ci = np.column_stack((lower</span><span class="s3">, </span><span class="s1">upper))</span>
        <span class="s0"># if we want to stack at a new last axis, for lower.ndim &gt; 1</span>
        <span class="s0"># np.concatenate((lower[..., None], upper[..., None]), axis=-1)</span>
        <span class="s3">return </span><span class="s1">ci</span>

    <span class="s3">def </span><span class="s1">conf_int(self</span><span class="s3">, </span><span class="s1">method=</span><span class="s4">'endpoint'</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s2">&quot;&quot;&quot;Confidence interval for the predicted value. 
 
        This is currently only available for t and z tests. 
 
        Parameters 
        ---------- 
        method : {&quot;endpoint&quot;, &quot;delta&quot;} 
            Method for confidence interval, &quot;m 
            If method is &quot;endpoint&quot;, then the confidence interval of the 
            linear predictor is transformed by the prediction function. 
            If method is &quot;delta&quot;, then the delta-method is used. The confidence 
            interval in this case might reach outside the range of the 
            prediction, for example probabilities larger than one or smaller 
            than zero. 
        alpha : float, optional 
            The significance level for the confidence interval. 
            ie., The default `alpha` = .05 returns a 95% confidence interval. 
        kwds : extra keyword arguments 
            currently ignored, only for compatibility, consistent signature 
 
        Returns 
        ------- 
        ci : ndarray, (k_constraints, 2) 
            The array has the lower and the upper limit of the confidence 
            interval in the columns. 
        &quot;&quot;&quot;</span>
        <span class="s1">tmp = np.linspace(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">6</span><span class="s1">)</span>
        <span class="s0"># TODO: drop check?</span>
        <span class="s1">is_linear = (self.func(tmp) == tmp).all()</span>
        <span class="s3">if </span><span class="s1">method == </span><span class="s4">'endpoint' </span><span class="s3">and not </span><span class="s1">is_linear:</span>
            <span class="s1">ci_linear = self._conf_int_generic(self.linpred</span><span class="s3">, </span><span class="s1">self.linpred_se</span><span class="s3">,</span>
                                               <span class="s1">alpha</span><span class="s3">,</span>
                                               <span class="s1">dist_args=self.dist_args)</span>
            <span class="s1">ci = self.func(ci_linear)</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s4">'delta' </span><span class="s3">or </span><span class="s1">is_linear:</span>
            <span class="s1">ci = self._conf_int_generic(self.predicted</span><span class="s3">, </span><span class="s1">self.se</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">,</span>
                                        <span class="s1">dist_args=self.dist_args)</span>

        <span class="s3">return </span><span class="s1">ci</span>


<span class="s3">class </span><span class="s1">PredictionResultsDelta(PredictionResultsBase):</span>
    <span class="s2">&quot;&quot;&quot;Prediction results based on delta method 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">results_delta</span><span class="s3">, </span><span class="s1">**kwds):</span>

        <span class="s1">predicted = results_delta.predicted()</span>
        <span class="s1">var_pred = results_delta.var()</span>

        <span class="s1">super().__init__(predicted</span><span class="s3">, </span><span class="s1">var_pred</span><span class="s3">, </span><span class="s1">**kwds)</span>


<span class="s3">class </span><span class="s1">PredictionResultsMean(PredictionResultsBase):</span>
    <span class="s2">&quot;&quot;&quot;Prediction results for GLM. 
 
    This results class is used for backwards compatibility for 
    `get_prediction` with GLM. The new PredictionResults classes dropped the 
    `_mean` post fix in the attribute names. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">predicted_mean</span><span class="s3">, </span><span class="s1">var_pred_mean</span><span class="s3">, </span><span class="s1">var_resid=</span><span class="s3">None,</span>
                 <span class="s1">df=</span><span class="s3">None, </span><span class="s1">dist=</span><span class="s3">None, </span><span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">linpred=</span><span class="s3">None, </span><span class="s1">link=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s0"># TODO: is var_resid used? drop from arguments?</span>
        <span class="s1">self.predicted = predicted_mean</span>
        <span class="s1">self.var_pred = var_pred_mean</span>
        <span class="s1">self.df = df</span>
        <span class="s1">self.var_resid = var_resid</span>
        <span class="s1">self.row_labels = row_labels</span>
        <span class="s1">self.linpred = linpred</span>
        <span class="s1">self.link = link</span>

        <span class="s3">if </span><span class="s1">dist </span><span class="s3">is None or </span><span class="s1">dist == </span><span class="s4">'norm'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.norm</span>
            <span class="s1">self.dist_args = ()</span>
        <span class="s3">elif </span><span class="s1">dist == </span><span class="s4">'t'</span><span class="s1">:</span>
            <span class="s1">self.dist = stats.t</span>
            <span class="s1">self.dist_args = (self.df</span><span class="s3">,</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self.dist = dist</span>
            <span class="s1">self.dist_args = ()</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">predicted_mean(self):</span>
        <span class="s0"># alias for backwards compatibility</span>
        <span class="s3">return </span><span class="s1">self.predicted</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">var_pred_mean(self):</span>
        <span class="s0"># alias for backwards compatibility</span>
        <span class="s3">return </span><span class="s1">self.var_pred</span>

    <span class="s1">@property</span>
    <span class="s3">def </span><span class="s1">se_mean(self):</span>
        <span class="s0"># alias for backwards compatibility</span>
        <span class="s3">return </span><span class="s1">self.se</span>

    <span class="s3">def </span><span class="s1">conf_int(self</span><span class="s3">, </span><span class="s1">method=</span><span class="s4">'endpoint'</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s3">, </span><span class="s1">**kwds):</span>
        <span class="s2">&quot;&quot;&quot;Confidence interval for the predicted value. 
 
        This is currently only available for t and z tests. 
 
        Parameters 
        ---------- 
        method : {&quot;endpoint&quot;, &quot;delta&quot;} 
            Method for confidence interval, &quot;m 
            If method is &quot;endpoint&quot;, then the confidence interval of the 
            linear predictor is transformed by the prediction function. 
            If method is &quot;delta&quot;, then the delta-method is used. The confidence 
            interval in this case might reach outside the range of the 
            prediction, for example probabilities larger than one or smaller 
            than zero. 
        alpha : float, optional 
            The significance level for the confidence interval. 
            ie., The default `alpha` = .05 returns a 95% confidence interval. 
        kwds : extra keyword arguments 
            currently ignored, only for compatibility, consistent signature 
 
        Returns 
        ------- 
        ci : ndarray, (k_constraints, 2) 
            The array has the lower and the upper limit of the confidence 
            interval in the columns. 
        &quot;&quot;&quot;</span>
        <span class="s1">tmp = np.linspace(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">6</span><span class="s1">)</span>
        <span class="s1">is_linear = (self.link.inverse(tmp) == tmp).all()</span>
        <span class="s3">if </span><span class="s1">method == </span><span class="s4">'endpoint' </span><span class="s3">and not </span><span class="s1">is_linear:</span>
            <span class="s1">ci_linear = self.linpred.conf_int(alpha=alpha</span><span class="s3">, </span><span class="s1">obs=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">ci = self.link.inverse(ci_linear)</span>
        <span class="s3">elif </span><span class="s1">method == </span><span class="s4">'delta' </span><span class="s3">or </span><span class="s1">is_linear:</span>
            <span class="s1">se = self.se_mean</span>
            <span class="s1">q = self.dist.ppf(</span><span class="s5">1 </span><span class="s1">- alpha / </span><span class="s5">2.</span><span class="s3">, </span><span class="s1">*self.dist_args)</span>
            <span class="s1">lower = self.predicted_mean - q * se</span>
            <span class="s1">upper = self.predicted_mean + q * se</span>
            <span class="s1">ci = np.column_stack((lower</span><span class="s3">, </span><span class="s1">upper))</span>
            <span class="s0"># if we want to stack at a new last axis, for lower.ndim &gt; 1</span>
            <span class="s0"># np.concatenate((lower[..., None], upper[..., None]), axis=-1)</span>

        <span class="s3">return </span><span class="s1">ci</span>

    <span class="s3">def </span><span class="s1">summary_frame(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;Summary frame 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            The significance level for the confidence interval. 
            ie., The default `alpha` = .05 returns a 95% confidence interval. 
 
        Returns 
        ------- 
        pandas DataFrame with columns 
        'mean', 'mean_se', 'mean_ci_lower', 'mean_ci_upper'. 
        &quot;&quot;&quot;</span>
        <span class="s0"># TODO: finish and cleanup</span>
        <span class="s1">ci_mean = self.conf_int(alpha=alpha)</span>
        <span class="s1">to_include = {}</span>
        <span class="s1">to_include[</span><span class="s4">'mean'</span><span class="s1">] = self.predicted_mean</span>
        <span class="s1">to_include[</span><span class="s4">'mean_se'</span><span class="s1">] = self.se_mean</span>
        <span class="s1">to_include[</span><span class="s4">'mean_ci_lower'</span><span class="s1">] = ci_mean[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">to_include[</span><span class="s4">'mean_ci_upper'</span><span class="s1">] = ci_mean[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">self.table = to_include</span>
        <span class="s0"># pandas dict does not handle 2d_array</span>
        <span class="s0"># data = np.column_stack(list(to_include.values()))</span>
        <span class="s0"># names = ....</span>
        <span class="s1">res = pd.DataFrame(to_include</span><span class="s3">, </span><span class="s1">index=self.row_labels</span><span class="s3">,</span>
                           <span class="s1">columns=to_include.keys())</span>
        <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">_get_exog_predict(self</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">True, </span><span class="s1">row_labels=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Prepare or transform exog for prediction 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
 
    Returns 
    ------- 
    exog : ndarray 
        Prediction exog 
    row_labels : list of str 
        Labels or pandas index for rows of prediction 
    &quot;&quot;&quot;</span>

    <span class="s0"># prepare exog and row_labels, based on base Results.predict</span>
    <span class="s3">if </span><span class="s1">transform </span><span class="s3">and </span><span class="s1">hasattr(self.model</span><span class="s3">, </span><span class="s4">'formula'</span><span class="s1">) </span><span class="s3">and </span><span class="s1">exog </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s3">from </span><span class="s1">patsy </span><span class="s3">import </span><span class="s1">dmatrix</span>
        <span class="s3">if </span><span class="s1">isinstance(exog</span><span class="s3">, </span><span class="s1">pd.Series):</span>
            <span class="s1">exog = pd.DataFrame(exog)</span>
        <span class="s1">exog = dmatrix(self.model.data.design_info</span><span class="s3">, </span><span class="s1">exog)</span>

    <span class="s3">if </span><span class="s1">exog </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">row_labels </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">row_labels = getattr(exog</span><span class="s3">, </span><span class="s4">'index'</span><span class="s3">, None</span><span class="s1">)</span>
            <span class="s3">if </span><span class="s1">callable(row_labels):</span>
                <span class="s1">row_labels = </span><span class="s3">None</span>

        <span class="s1">exog = np.asarray(exog)</span>
        <span class="s3">if </span><span class="s1">exog.ndim == </span><span class="s5">1 </span><span class="s3">and </span><span class="s1">(self.model.exog.ndim == </span><span class="s5">1 </span><span class="s3">or</span>
                               <span class="s1">self.model.exog.shape[</span><span class="s5">1</span><span class="s1">] == </span><span class="s5">1</span><span class="s1">):</span>
            <span class="s1">exog = exog[:</span><span class="s3">, None</span><span class="s1">]</span>
        <span class="s1">exog = np.atleast_2d(exog)  </span><span class="s0"># needed in count model shape[1]</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">exog = self.model.exog</span>

        <span class="s3">if </span><span class="s1">row_labels </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">row_labels = getattr(self.model.data</span><span class="s3">, </span><span class="s4">'row_labels'</span><span class="s3">, None</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">row_labels</span>


<span class="s3">def </span><span class="s1">get_prediction_glm(self</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">True,</span>
                       <span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">linpred=</span><span class="s3">None, </span><span class="s1">link=</span><span class="s3">None,</span>
                       <span class="s1">pred_kwds=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute prediction results for GLM compatible models. 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
    linpred : linear prediction instance 
        Instance of linear prediction results used for confidence intervals 
        based on endpoint transformation. 
    link : instance of link function 
        If no link function is provided, then the `model.family.link` is used. 
    pred_kwds : dict 
        Some models can take additional keyword arguments, such as offset or 
        additional exog in multi-part models. See the predict method of the 
        model for the details. 
 
    Returns 
    ------- 
    prediction_results : generalized_linear_model.PredictionResults 
        The prediction results instance contains prediction and prediction 
        variance and can on demand calculate confidence intervals and summary 
        tables for the prediction of the mean and of new observations. 
    &quot;&quot;&quot;</span>

    <span class="s0"># prepare exog and row_labels, based on base Results.predict</span>
    <span class="s1">exog</span><span class="s3">, </span><span class="s1">row_labels = _get_exog_predict(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">exog=exog</span><span class="s3">,</span>
        <span class="s1">transform=transform</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">if </span><span class="s1">pred_kwds </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">pred_kwds = {}</span>

    <span class="s1">predicted_mean = self.model.predict(self.params</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">**pred_kwds)</span>

    <span class="s1">covb = self.cov_params()</span>

    <span class="s1">link_deriv = self.model.family.link.inverse_deriv(linpred.predicted_mean)</span>
    <span class="s1">var_pred_mean = link_deriv**</span><span class="s5">2 </span><span class="s1">* (exog * np.dot(covb</span><span class="s3">, </span><span class="s1">exog.T).T).sum(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">var_resid = self.scale  </span><span class="s0"># self.mse_resid / weights</span>

    <span class="s0"># TODO: check that we have correct scale, Refactor scale #???</span>
    <span class="s0"># special case for now:</span>
    <span class="s3">if </span><span class="s1">self.cov_type == </span><span class="s4">'fixed scale'</span><span class="s1">:</span>
        <span class="s1">var_resid = self.cov_kwds[</span><span class="s4">'scale'</span><span class="s1">]</span>

    <span class="s1">dist = [</span><span class="s4">'norm'</span><span class="s3">, </span><span class="s4">'t'</span><span class="s1">][self.use_t]</span>
    <span class="s3">return </span><span class="s1">PredictionResultsMean(</span>
        <span class="s1">predicted_mean</span><span class="s3">, </span><span class="s1">var_pred_mean</span><span class="s3">, </span><span class="s1">var_resid</span><span class="s3">,</span>
        <span class="s1">df=self.df_resid</span><span class="s3">, </span><span class="s1">dist=dist</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">, </span><span class="s1">linpred=linpred</span><span class="s3">, </span><span class="s1">link=link)</span>


<span class="s3">def </span><span class="s1">get_prediction_linear(self</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">True,</span>
                          <span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">pred_kwds=</span><span class="s3">None, </span><span class="s1">index=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute prediction results for linear prediction. 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
    pred_kwargs : 
        Some models can take additional keyword arguments, such as offset or 
        additional exog in multi-part models. 
        See the predict method of the model for the details. 
    index : slice or array-index 
        Is used to select rows and columns of cov_params, if the prediction 
        function only depends on a subset of parameters. 
 
    Returns 
    ------- 
    prediction_results : PredictionResults 
        The prediction results instance contains prediction and prediction 
        variance and can on demand calculate confidence intervals and summary 
        tables for the prediction. 
    &quot;&quot;&quot;</span>

    <span class="s0"># prepare exog and row_labels, based on base Results.predict</span>
    <span class="s1">exog</span><span class="s3">, </span><span class="s1">row_labels = _get_exog_predict(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">exog=exog</span><span class="s3">,</span>
        <span class="s1">transform=transform</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">if </span><span class="s1">pred_kwds </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">pred_kwds = {}</span>

    <span class="s1">k1 = exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s3">if </span><span class="s1">len(self.params &gt; k1):</span>
        <span class="s0"># TODO: we allow endpoint transformation only for the first link</span>
        <span class="s1">index = np.arange(k1)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">index = </span><span class="s3">None</span>
    <span class="s0"># get linear prediction and standard errors</span>
    <span class="s1">covb = self.cov_params(column=index)</span>
    <span class="s1">var_pred = (exog * np.dot(covb</span><span class="s3">, </span><span class="s1">exog.T).T).sum(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">pred_kwds_linear = pred_kwds.copy()</span>
    <span class="s1">pred_kwds_linear[</span><span class="s4">&quot;which&quot;</span><span class="s1">] = </span><span class="s4">&quot;linear&quot;</span>
    <span class="s1">predicted = self.model.predict(self.params</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">**pred_kwds_linear)</span>

    <span class="s1">dist = [</span><span class="s4">'norm'</span><span class="s3">, </span><span class="s4">'t'</span><span class="s1">][self.use_t]</span>
    <span class="s1">res = PredictionResultsBase(predicted</span><span class="s3">, </span><span class="s1">var_pred</span><span class="s3">,</span>
                                <span class="s1">df=self.df_resid</span><span class="s3">, </span><span class="s1">dist=dist</span><span class="s3">,</span>
                                <span class="s1">row_labels=row_labels</span>
                                <span class="s1">)</span>
    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">get_prediction_monotonic(self</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">True,</span>
                             <span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">link=</span><span class="s3">None,</span>
                             <span class="s1">pred_kwds=</span><span class="s3">None, </span><span class="s1">index=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute prediction results when endpoint transformation is valid. 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
    link : instance of link function 
        If no link function is provided, then the ``mmodel.family.link` is 
        used. 
    pred_kwargs : 
        Some models can take additional keyword arguments, such as offset or 
        additional exog in multi-part models. 
        See the predict method of the model for the details. 
    index : slice or array-index 
        Is used to select rows and columns of cov_params, if the prediction 
        function only depends on a subset of parameters. 
 
    Returns 
    ------- 
    prediction_results : PredictionResults 
        The prediction results instance contains prediction and prediction 
        variance and can on demand calculate confidence intervals and summary 
        tables for the prediction. 
    &quot;&quot;&quot;</span>

    <span class="s0"># prepare exog and row_labels, based on base Results.predict</span>
    <span class="s1">exog</span><span class="s3">, </span><span class="s1">row_labels = _get_exog_predict(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">exog=exog</span><span class="s3">,</span>
        <span class="s1">transform=transform</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">if </span><span class="s1">pred_kwds </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">pred_kwds = {}</span>

    <span class="s3">if </span><span class="s1">link </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">link = self.model.family.link</span>

    <span class="s1">func_deriv = link.inverse_deriv</span>

    <span class="s0"># get linear prediction and standard errors</span>
    <span class="s1">covb = self.cov_params(column=index)</span>
    <span class="s1">linpred_var = (exog * np.dot(covb</span><span class="s3">, </span><span class="s1">exog.T).T).sum(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">pred_kwds_linear = pred_kwds.copy()</span>
    <span class="s1">pred_kwds_linear[</span><span class="s4">&quot;which&quot;</span><span class="s1">] = </span><span class="s4">&quot;linear&quot;</span>
    <span class="s1">linpred = self.model.predict(self.params</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">**pred_kwds_linear)</span>

    <span class="s1">predicted = self.model.predict(self.params</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">**pred_kwds)</span>
    <span class="s1">link_deriv = func_deriv(linpred)</span>
    <span class="s1">var_pred = link_deriv**</span><span class="s5">2 </span><span class="s1">* linpred_var</span>

    <span class="s1">dist = [</span><span class="s4">'norm'</span><span class="s3">, </span><span class="s4">'t'</span><span class="s1">][self.use_t]</span>
    <span class="s1">res = PredictionResultsMonotonic(predicted</span><span class="s3">, </span><span class="s1">var_pred</span><span class="s3">,</span>
                                     <span class="s1">df=self.df_resid</span><span class="s3">, </span><span class="s1">dist=dist</span><span class="s3">,</span>
                                     <span class="s1">row_labels=row_labels</span><span class="s3">, </span><span class="s1">linpred=linpred</span><span class="s3">,</span>
                                     <span class="s1">linpred_se=np.sqrt(linpred_var)</span><span class="s3">,</span>
                                     <span class="s1">func=link.inverse</span><span class="s3">, </span><span class="s1">deriv=func_deriv)</span>
    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">get_prediction_delta(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">exog=</span><span class="s3">None,</span>
        <span class="s1">which=</span><span class="s4">&quot;mean&quot;</span><span class="s3">,</span>
        <span class="s1">average=</span><span class="s3">False,</span>
        <span class="s1">agg_weights=</span><span class="s3">None,</span>
        <span class="s1">transform=</span><span class="s3">True,</span>
        <span class="s1">row_labels=</span><span class="s3">None,</span>
        <span class="s1">pred_kwds=</span><span class="s3">None</span>
        <span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    compute prediction results 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    which : str 
        The statistic that is prediction. Which statistics are available 
        depends on the model.predict method. 
    average : bool 
        If average is True, then the mean prediction is computed, that is, 
        predictions are computed for individual exog and then them mean over 
        observation is used. 
        If average is False, then the results are the predictions for all 
        observations, i.e. same length as ``exog``. 
    agg_weights : ndarray, optional 
        Aggregation weights, only used if average is True. 
        The weights are not normalized. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
    pred_kwargs : 
        Some models can take additional keyword arguments, such as offset or 
        additional exog in multi-part models. 
        See the predict method of the model for the details. 
 
    Returns 
    ------- 
    prediction_results : generalized_linear_model.PredictionResults 
        The prediction results instance contains prediction and prediction 
        variance and can on demand calculate confidence intervals and summary 
        tables for the prediction of the mean and of new observations. 
    &quot;&quot;&quot;</span>

    <span class="s0"># prepare exog and row_labels, based on base Results.predict</span>
    <span class="s1">exog</span><span class="s3">, </span><span class="s1">row_labels = _get_exog_predict(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">exog=exog</span><span class="s3">,</span>
        <span class="s1">transform=transform</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
        <span class="s1">)</span>
    <span class="s3">if </span><span class="s1">agg_weights </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">agg_weights = np.array(</span><span class="s5">1.</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">f_pred(p):</span>
        <span class="s2">&quot;&quot;&quot;Prediction function as function of params 
        &quot;&quot;&quot;</span>
        <span class="s1">pred = self.model.predict(p</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">which=which</span><span class="s3">, </span><span class="s1">**pred_kwds)</span>
        <span class="s3">if </span><span class="s1">average:</span>
            <span class="s0"># using `.T` which should work if aggweights is 1-dim</span>
            <span class="s1">pred = (pred.T * agg_weights.T).mean(-</span><span class="s5">1</span><span class="s1">).T</span>
        <span class="s3">return </span><span class="s1">pred</span>

    <span class="s1">nlpm = self._get_wald_nonlinear(f_pred)</span>
    <span class="s0"># TODO: currently returns NonlinearDeltaCov</span>
    <span class="s1">res = PredictionResultsDelta(nlpm)</span>
    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">get_prediction(self</span><span class="s3">, </span><span class="s1">exog=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">True, </span><span class="s1">which=</span><span class="s4">&quot;mean&quot;</span><span class="s3">,</span>
                   <span class="s1">row_labels=</span><span class="s3">None, </span><span class="s1">average=</span><span class="s3">False, </span><span class="s1">agg_weights=</span><span class="s3">None,</span>
                   <span class="s1">pred_kwds=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Compute prediction results when endpoint transformation is valid. 
 
    Parameters 
    ---------- 
    exog : array_like, optional 
        The values for which you want to predict. 
    transform : bool, optional 
        If the model was fit via a formula, do you want to pass 
        exog through the formula. Default is True. E.g., if you fit 
        a model y ~ log(x1) + log(x2), and transform is True, then 
        you can pass a data structure that contains x1 and x2 in 
        their original form. Otherwise, you'd need to log the data 
        first. 
    which : str 
        Which statistic is to be predicted. Default is &quot;mean&quot;. 
        The available statistics and options depend on the model. 
        see the model.predict docstring 
    linear : bool 
        Linear has been replaced by the `which` keyword and will be 
        deprecated. 
        If linear is True, then `which` is ignored and the linear 
        prediction is returned. 
    row_labels : list of str or None 
        If row_lables are provided, then they will replace the generated 
        labels. 
    average : bool 
        If average is True, then the mean prediction is computed, that is, 
        predictions are computed for individual exog and then the average 
        over observation is used. 
        If average is False, then the results are the predictions for all 
        observations, i.e. same length as ``exog``. 
    agg_weights : ndarray, optional 
        Aggregation weights, only used if average is True. 
        The weights are not normalized. 
    **kwargs : 
        Some models can take additional keyword arguments, such as offset, 
        exposure or additional exog in multi-part models like zero inflated 
        models. 
        See the predict method of the model for the details. 
 
    Returns 
    ------- 
    prediction_results : PredictionResults 
        The prediction results instance contains prediction and prediction 
        variance and can on demand calculate confidence intervals and 
        summary dataframe for the prediction. 
 
    Notes 
    ----- 
    Status: new in 0.14, experimental 
    &quot;&quot;&quot;</span>
    <span class="s1">use_endpoint = getattr(self.model</span><span class="s3">, </span><span class="s4">&quot;_use_endpoint&quot;</span><span class="s3">, True</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">which == </span><span class="s4">&quot;linear&quot;</span><span class="s1">:</span>
        <span class="s1">res = get_prediction_linear(</span>
            <span class="s1">self</span><span class="s3">,</span>
            <span class="s1">exog=exog</span><span class="s3">,</span>
            <span class="s1">transform=transform</span><span class="s3">,</span>
            <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
            <span class="s1">pred_kwds=pred_kwds</span><span class="s3">,</span>
            <span class="s1">)</span>

    <span class="s3">elif </span><span class="s1">(which == </span><span class="s4">&quot;mean&quot;</span><span class="s1">)</span><span class="s3">and </span><span class="s1">(use_endpoint </span><span class="s3">is True</span><span class="s1">) </span><span class="s3">and </span><span class="s1">(average </span><span class="s3">is False</span><span class="s1">):</span>
        <span class="s0"># endpoint transformation</span>
        <span class="s1">k1 = self.model.exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s3">if </span><span class="s1">len(self.params &gt; k1):</span>
            <span class="s0"># TODO: we allow endpoint transformation only for the first link</span>
            <span class="s1">index = np.arange(k1)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">index = </span><span class="s3">None</span>

        <span class="s1">pred_kwds[</span><span class="s4">&quot;which&quot;</span><span class="s1">] = which</span>
        <span class="s0"># TODO: add link or ilink to all link based models (except zi</span>
        <span class="s1">link = getattr(self.model</span><span class="s3">, </span><span class="s4">&quot;link&quot;</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">link </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s0"># GLM</span>
            <span class="s3">if </span><span class="s1">hasattr(self.model</span><span class="s3">, </span><span class="s4">&quot;family&quot;</span><span class="s1">):</span>
                <span class="s1">link = getattr(self.model.family</span><span class="s3">, </span><span class="s4">&quot;link&quot;</span><span class="s3">, None</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">link </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s0"># defaulting to log link for count models</span>
            <span class="s3">import </span><span class="s1">warnings</span>
            <span class="s1">warnings.warn(</span><span class="s4">&quot;using default log-link in get_prediction&quot;</span><span class="s1">)</span>
            <span class="s3">from </span><span class="s1">statsmodels.genmod.families </span><span class="s3">import </span><span class="s1">links</span>
            <span class="s1">link = links.Log()</span>
        <span class="s1">res = get_prediction_monotonic(</span>
            <span class="s1">self</span><span class="s3">,</span>
            <span class="s1">exog=exog</span><span class="s3">,</span>
            <span class="s1">transform=transform</span><span class="s3">,</span>
            <span class="s1">row_labels=row_labels</span><span class="s3">,</span>
            <span class="s1">link=link</span><span class="s3">,</span>
            <span class="s1">pred_kwds=pred_kwds</span><span class="s3">,</span>
            <span class="s1">index=index</span><span class="s3">,</span>
            <span class="s1">)</span>

    <span class="s3">else</span><span class="s1">:</span>
        <span class="s0"># which is not mean or linear, or we need averaging</span>
        <span class="s1">res = get_prediction_delta(</span>
            <span class="s1">self</span><span class="s3">,</span>
            <span class="s1">exog=exog</span><span class="s3">,</span>
            <span class="s1">which=which</span><span class="s3">,</span>
            <span class="s1">average=average</span><span class="s3">,</span>
            <span class="s1">agg_weights=agg_weights</span><span class="s3">,</span>
            <span class="s1">pred_kwds=pred_kwds</span><span class="s3">,</span>
            <span class="s1">)</span>

    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">params_transform_univariate(params</span><span class="s3">, </span><span class="s1">cov_params</span><span class="s3">, </span><span class="s1">link=</span><span class="s3">None, </span><span class="s1">transform=</span><span class="s3">None,</span>
                                <span class="s1">row_labels=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    results for univariate, nonlinear, monotonicaly transformed parameters 
 
    This provides transformed values, standard errors and confidence interval 
    for transformations of parameters, for example in calculating rates with 
    `exp(params)` in the case of Poisson or other models with exponential 
    mean function. 
    &quot;&quot;&quot;</span>

    <span class="s3">from </span><span class="s1">statsmodels.genmod.families </span><span class="s3">import </span><span class="s1">links</span>
    <span class="s3">if </span><span class="s1">link </span><span class="s3">is None and </span><span class="s1">transform </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">link = links.Log()</span>

    <span class="s3">if </span><span class="s1">row_labels </span><span class="s3">is None and </span><span class="s1">hasattr(params</span><span class="s3">, </span><span class="s4">'index'</span><span class="s1">):</span>
        <span class="s1">row_labels = params.index</span>

    <span class="s1">params = np.asarray(params)</span>

    <span class="s1">predicted_mean = link.inverse(params)</span>
    <span class="s1">link_deriv = link.inverse_deriv(params)</span>
    <span class="s1">var_pred_mean = link_deriv**</span><span class="s5">2 </span><span class="s1">* np.diag(cov_params)</span>
    <span class="s0"># TODO: do we want covariance also, or just var/se</span>

    <span class="s1">dist = stats.norm</span>

    <span class="s0"># TODO: need ci for linear prediction, method of `lin_pred</span>
    <span class="s1">linpred = PredictionResultsMean(</span>
        <span class="s1">params</span><span class="s3">, </span><span class="s1">np.diag(cov_params)</span><span class="s3">, </span><span class="s1">dist=dist</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">, </span><span class="s1">link=links.Identity())</span>

    <span class="s1">res = PredictionResultsMean(</span>
        <span class="s1">predicted_mean</span><span class="s3">, </span><span class="s1">var_pred_mean</span><span class="s3">, </span><span class="s1">dist=dist</span><span class="s3">,</span>
        <span class="s1">row_labels=row_labels</span><span class="s3">, </span><span class="s1">linpred=linpred</span><span class="s3">, </span><span class="s1">link=link)</span>

    <span class="s3">return </span><span class="s1">res</span>
</pre>
</body>
</html>
<html>
<head>
<title>_lfw.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_lfw.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Labeled Faces in the Wild (LFW) dataset 
 
This dataset is a collection of JPEG pictures of famous people collected 
over the internet, all details are available on the official website: 
 
    http://vis-www.cs.umass.edu/lfw/ 
&quot;&quot;&quot;</span>
<span class="s2"># Copyright (c) 2011 Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">logging</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s3">, </span><span class="s1">Real</span>
<span class="s3">from </span><span class="s1">os </span><span class="s3">import </span><span class="s1">PathLike</span><span class="s3">, </span><span class="s1">listdir</span><span class="s3">, </span><span class="s1">makedirs</span><span class="s3">, </span><span class="s1">remove</span>
<span class="s3">from </span><span class="s1">os.path </span><span class="s3">import </span><span class="s1">exists</span><span class="s3">, </span><span class="s1">isdir</span><span class="s3">, </span><span class="s1">join</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">joblib </span><span class="s3">import </span><span class="s1">Memory</span>

<span class="s3">from </span><span class="s1">..utils </span><span class="s3">import </span><span class="s1">Bunch</span>
<span class="s3">from </span><span class="s1">..utils._param_validation </span><span class="s3">import </span><span class="s1">Hidden</span><span class="s3">, </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span><span class="s3">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s1">._base </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">RemoteFileMetadata</span><span class="s3">,</span>
    <span class="s1">_fetch_remote</span><span class="s3">,</span>
    <span class="s1">get_data_home</span><span class="s3">,</span>
    <span class="s1">load_descr</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s1">logger = logging.getLogger(__name__)</span>

<span class="s2"># The original data can be found in:</span>
<span class="s2"># http://vis-www.cs.umass.edu/lfw/lfw.tgz</span>
<span class="s1">ARCHIVE = RemoteFileMetadata(</span>
    <span class="s1">filename=</span><span class="s4">&quot;lfw.tgz&quot;</span><span class="s3">,</span>
    <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976018&quot;</span><span class="s3">,</span>
    <span class="s1">checksum=</span><span class="s4">&quot;055f7d9c632d7370e6fb4afc7468d40f970c34a80d4c6f50ffec63f5a8d536c0&quot;</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s2"># The original funneled data can be found in:</span>
<span class="s2"># http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz</span>
<span class="s1">FUNNELED_ARCHIVE = RemoteFileMetadata(</span>
    <span class="s1">filename=</span><span class="s4">&quot;lfw-funneled.tgz&quot;</span><span class="s3">,</span>
    <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976015&quot;</span><span class="s3">,</span>
    <span class="s1">checksum=</span><span class="s4">&quot;b47c8422c8cded889dc5a13418c4bc2abbda121092b3533a83306f90d900100a&quot;</span><span class="s3">,</span>
<span class="s1">)</span>

<span class="s2"># The original target data can be found in:</span>
<span class="s2"># http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt',</span>
<span class="s2"># http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt',</span>
<span class="s2"># http://vis-www.cs.umass.edu/lfw/pairs.txt',</span>
<span class="s1">TARGETS = (</span>
    <span class="s1">RemoteFileMetadata(</span>
        <span class="s1">filename=</span><span class="s4">&quot;pairsDevTrain.txt&quot;</span><span class="s3">,</span>
        <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976012&quot;</span><span class="s3">,</span>
        <span class="s1">checksum=</span><span class="s4">&quot;1d454dada7dfeca0e7eab6f65dc4e97a6312d44cf142207be28d688be92aabfa&quot;</span><span class="s3">,</span>
    <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">RemoteFileMetadata(</span>
        <span class="s1">filename=</span><span class="s4">&quot;pairsDevTest.txt&quot;</span><span class="s3">,</span>
        <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976009&quot;</span><span class="s3">,</span>
        <span class="s1">checksum=</span><span class="s4">&quot;7cb06600ea8b2814ac26e946201cdb304296262aad67d046a16a7ec85d0ff87c&quot;</span><span class="s3">,</span>
    <span class="s1">)</span><span class="s3">,</span>
    <span class="s1">RemoteFileMetadata(</span>
        <span class="s1">filename=</span><span class="s4">&quot;pairs.txt&quot;</span><span class="s3">,</span>
        <span class="s1">url=</span><span class="s4">&quot;https://ndownloader.figshare.com/files/5976006&quot;</span><span class="s3">,</span>
        <span class="s1">checksum=</span><span class="s4">&quot;ea42330c62c92989f9d7c03237ed5d591365e89b3e649747777b70e692dc1592&quot;</span><span class="s3">,</span>
    <span class="s1">)</span><span class="s3">,</span>
<span class="s1">)</span>


<span class="s2">#</span>
<span class="s2"># Common private utilities for data fetching from the original LFW website</span>
<span class="s2"># local disk caching, and image decoding.</span>
<span class="s2">#</span>


<span class="s3">def </span><span class="s1">_check_fetch_lfw(data_home=</span><span class="s3">None, </span><span class="s1">funneled=</span><span class="s3">True, </span><span class="s1">download_if_missing=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Helper function to download any missing LFW data&quot;&quot;&quot;</span>

    <span class="s1">data_home = get_data_home(data_home=data_home)</span>
    <span class="s1">lfw_home = join(data_home</span><span class="s3">, </span><span class="s4">&quot;lfw_home&quot;</span><span class="s1">)</span>

    <span class="s3">if not </span><span class="s1">exists(lfw_home):</span>
        <span class="s1">makedirs(lfw_home)</span>

    <span class="s3">for </span><span class="s1">target </span><span class="s3">in </span><span class="s1">TARGETS:</span>
        <span class="s1">target_filepath = join(lfw_home</span><span class="s3">, </span><span class="s1">target.filename)</span>
        <span class="s3">if not </span><span class="s1">exists(target_filepath):</span>
            <span class="s3">if </span><span class="s1">download_if_missing:</span>
                <span class="s1">logger.info(</span><span class="s4">&quot;Downloading LFW metadata: %s&quot;</span><span class="s3">, </span><span class="s1">target.url)</span>
                <span class="s1">_fetch_remote(target</span><span class="s3">, </span><span class="s1">dirname=lfw_home)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">OSError(</span><span class="s4">&quot;%s is missing&quot; </span><span class="s1">% target_filepath)</span>

    <span class="s3">if </span><span class="s1">funneled:</span>
        <span class="s1">data_folder_path = join(lfw_home</span><span class="s3">, </span><span class="s4">&quot;lfw_funneled&quot;</span><span class="s1">)</span>
        <span class="s1">archive = FUNNELED_ARCHIVE</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">data_folder_path = join(lfw_home</span><span class="s3">, </span><span class="s4">&quot;lfw&quot;</span><span class="s1">)</span>
        <span class="s1">archive = ARCHIVE</span>

    <span class="s3">if not </span><span class="s1">exists(data_folder_path):</span>
        <span class="s1">archive_path = join(lfw_home</span><span class="s3">, </span><span class="s1">archive.filename)</span>
        <span class="s3">if not </span><span class="s1">exists(archive_path):</span>
            <span class="s3">if </span><span class="s1">download_if_missing:</span>
                <span class="s1">logger.info(</span><span class="s4">&quot;Downloading LFW data (~200MB): %s&quot;</span><span class="s3">, </span><span class="s1">archive.url)</span>
                <span class="s1">_fetch_remote(archive</span><span class="s3">, </span><span class="s1">dirname=lfw_home)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">OSError(</span><span class="s4">&quot;%s is missing&quot; </span><span class="s1">% archive_path)</span>

        <span class="s3">import </span><span class="s1">tarfile</span>

        <span class="s1">logger.debug(</span><span class="s4">&quot;Decompressing the data archive to %s&quot;</span><span class="s3">, </span><span class="s1">data_folder_path)</span>
        <span class="s1">tarfile.open(archive_path</span><span class="s3">, </span><span class="s4">&quot;r:gz&quot;</span><span class="s1">).extractall(path=lfw_home)</span>
        <span class="s1">remove(archive_path)</span>

    <span class="s3">return </span><span class="s1">lfw_home</span><span class="s3">, </span><span class="s1">data_folder_path</span>


<span class="s3">def </span><span class="s1">_load_imgs(file_paths</span><span class="s3">, </span><span class="s1">slice_</span><span class="s3">, </span><span class="s1">color</span><span class="s3">, </span><span class="s1">resize):</span>
    <span class="s0">&quot;&quot;&quot;Internally used to load images&quot;&quot;&quot;</span>
    <span class="s3">try</span><span class="s1">:</span>
        <span class="s3">from </span><span class="s1">PIL </span><span class="s3">import </span><span class="s1">Image</span>
    <span class="s3">except </span><span class="s1">ImportError:</span>
        <span class="s3">raise </span><span class="s1">ImportError(</span>
            <span class="s4">&quot;The Python Imaging Library (PIL) is required to load data &quot;</span>
            <span class="s4">&quot;from jpeg files. Please refer to &quot;</span>
            <span class="s4">&quot;https://pillow.readthedocs.io/en/stable/installation.html &quot;</span>
            <span class="s4">&quot;for installing PIL.&quot;</span>
        <span class="s1">)</span>

    <span class="s2"># compute the portion of the images to load to respect the slice_ parameter</span>
    <span class="s2"># given by the caller</span>
    <span class="s1">default_slice = (slice(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">250</span><span class="s1">)</span><span class="s3">, </span><span class="s1">slice(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">250</span><span class="s1">))</span>
    <span class="s3">if </span><span class="s1">slice_ </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">slice_ = default_slice</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">slice_ = tuple(s </span><span class="s3">or </span><span class="s1">ds </span><span class="s3">for </span><span class="s1">s</span><span class="s3">, </span><span class="s1">ds </span><span class="s3">in </span><span class="s1">zip(slice_</span><span class="s3">, </span><span class="s1">default_slice))</span>

    <span class="s1">h_slice</span><span class="s3">, </span><span class="s1">w_slice = slice_</span>
    <span class="s1">h = (h_slice.stop - h_slice.start) // (h_slice.step </span><span class="s3">or </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">w = (w_slice.stop - w_slice.start) // (w_slice.step </span><span class="s3">or </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">resize </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">resize = float(resize)</span>
        <span class="s1">h = int(resize * h)</span>
        <span class="s1">w = int(resize * w)</span>

    <span class="s2"># allocate some contiguous memory to host the decoded image slices</span>
    <span class="s1">n_faces = len(file_paths)</span>
    <span class="s3">if not </span><span class="s1">color:</span>
        <span class="s1">faces = np.zeros((n_faces</span><span class="s3">, </span><span class="s1">h</span><span class="s3">, </span><span class="s1">w)</span><span class="s3">, </span><span class="s1">dtype=np.float32)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">faces = np.zeros((n_faces</span><span class="s3">, </span><span class="s1">h</span><span class="s3">, </span><span class="s1">w</span><span class="s3">, </span><span class="s5">3</span><span class="s1">)</span><span class="s3">, </span><span class="s1">dtype=np.float32)</span>

    <span class="s2"># iterate over the collected file path to load the jpeg files as numpy</span>
    <span class="s2"># arrays</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">file_path </span><span class="s3">in </span><span class="s1">enumerate(file_paths):</span>
        <span class="s3">if </span><span class="s1">i % </span><span class="s5">1000 </span><span class="s1">== </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">logger.debug(</span><span class="s4">&quot;Loading face #%05d / %05d&quot;</span><span class="s3">, </span><span class="s1">i + </span><span class="s5">1</span><span class="s3">, </span><span class="s1">n_faces)</span>

        <span class="s2"># Checks if jpeg reading worked. Refer to issue #3594 for more</span>
        <span class="s2"># details.</span>
        <span class="s1">pil_img = Image.open(file_path)</span>
        <span class="s1">pil_img = pil_img.crop(</span>
            <span class="s1">(w_slice.start</span><span class="s3">, </span><span class="s1">h_slice.start</span><span class="s3">, </span><span class="s1">w_slice.stop</span><span class="s3">, </span><span class="s1">h_slice.stop)</span>
        <span class="s1">)</span>
        <span class="s3">if </span><span class="s1">resize </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">pil_img = pil_img.resize((w</span><span class="s3">, </span><span class="s1">h))</span>
        <span class="s1">face = np.asarray(pil_img</span><span class="s3">, </span><span class="s1">dtype=np.float32)</span>

        <span class="s3">if </span><span class="s1">face.ndim == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">RuntimeError(</span>
                <span class="s4">&quot;Failed to read the image file %s, &quot;</span>
                <span class="s4">&quot;Please make sure that libjpeg is installed&quot; </span><span class="s1">% file_path</span>
            <span class="s1">)</span>

        <span class="s1">face /= </span><span class="s5">255.0  </span><span class="s2"># scale uint8 coded colors to the [0.0, 1.0] floats</span>
        <span class="s3">if not </span><span class="s1">color:</span>
            <span class="s2"># average the color channels to compute a gray levels</span>
            <span class="s2"># representation</span>
            <span class="s1">face = face.mean(axis=</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s1">faces[i</span><span class="s3">, </span><span class="s1">...] = face</span>

    <span class="s3">return </span><span class="s1">faces</span>


<span class="s2">#</span>
<span class="s2"># Task #1:  Face Identification on picture with names</span>
<span class="s2">#</span>


<span class="s3">def </span><span class="s1">_fetch_lfw_people(</span>
    <span class="s1">data_folder_path</span><span class="s3">, </span><span class="s1">slice_=</span><span class="s3">None, </span><span class="s1">color=</span><span class="s3">False, </span><span class="s1">resize=</span><span class="s3">None, </span><span class="s1">min_faces_per_person=</span><span class="s5">0</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Perform the actual data loading for the lfw people dataset 
 
    This operation is meant to be cached by a joblib wrapper. 
    &quot;&quot;&quot;</span>
    <span class="s2"># scan the data folder content to retain people with more that</span>
    <span class="s2"># `min_faces_per_person` face pictures</span>
    <span class="s1">person_names</span><span class="s3">, </span><span class="s1">file_paths = []</span><span class="s3">, </span><span class="s1">[]</span>
    <span class="s3">for </span><span class="s1">person_name </span><span class="s3">in </span><span class="s1">sorted(listdir(data_folder_path)):</span>
        <span class="s1">folder_path = join(data_folder_path</span><span class="s3">, </span><span class="s1">person_name)</span>
        <span class="s3">if not </span><span class="s1">isdir(folder_path):</span>
            <span class="s3">continue</span>
        <span class="s1">paths = [join(folder_path</span><span class="s3">, </span><span class="s1">f) </span><span class="s3">for </span><span class="s1">f </span><span class="s3">in </span><span class="s1">sorted(listdir(folder_path))]</span>
        <span class="s1">n_pictures = len(paths)</span>
        <span class="s3">if </span><span class="s1">n_pictures &gt;= min_faces_per_person:</span>
            <span class="s1">person_name = person_name.replace(</span><span class="s4">&quot;_&quot;</span><span class="s3">, </span><span class="s4">&quot; &quot;</span><span class="s1">)</span>
            <span class="s1">person_names.extend([person_name] * n_pictures)</span>
            <span class="s1">file_paths.extend(paths)</span>

    <span class="s1">n_faces = len(file_paths)</span>
    <span class="s3">if </span><span class="s1">n_faces == </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s4">&quot;min_faces_per_person=%d is too restrictive&quot; </span><span class="s1">% min_faces_per_person</span>
        <span class="s1">)</span>

    <span class="s1">target_names = np.unique(person_names)</span>
    <span class="s1">target = np.searchsorted(target_names</span><span class="s3">, </span><span class="s1">person_names)</span>

    <span class="s1">faces = _load_imgs(file_paths</span><span class="s3">, </span><span class="s1">slice_</span><span class="s3">, </span><span class="s1">color</span><span class="s3">, </span><span class="s1">resize)</span>

    <span class="s2"># shuffle the faces with a deterministic RNG scheme to avoid having</span>
    <span class="s2"># all faces of the same person in a row, as it would break some</span>
    <span class="s2"># cross validation and learning algorithms such as SGD and online</span>
    <span class="s2"># k-means that make an IID assumption</span>

    <span class="s1">indices = np.arange(n_faces)</span>
    <span class="s1">np.random.RandomState(</span><span class="s5">42</span><span class="s1">).shuffle(indices)</span>
    <span class="s1">faces</span><span class="s3">, </span><span class="s1">target = faces[indices]</span><span class="s3">, </span><span class="s1">target[indices]</span>
    <span class="s3">return </span><span class="s1">faces</span><span class="s3">, </span><span class="s1">target</span><span class="s3">, </span><span class="s1">target_names</span>


<span class="s1">@validate_params(</span>
    <span class="s1">{</span>
        <span class="s4">&quot;data_home&quot;</span><span class="s1">: [str</span><span class="s3">, </span><span class="s1">PathLike</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;funneled&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;resize&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s4">&quot;neither&quot;</span><span class="s1">)</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;min_faces_per_person&quot;</span><span class="s1">: [Interval(Integral</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s4">&quot;left&quot;</span><span class="s1">)</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;color&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;slice_&quot;</span><span class="s1">: [tuple</span><span class="s3">, </span><span class="s1">Hidden(</span><span class="s3">None</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s4">&quot;download_if_missing&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;return_X_y&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">}</span><span class="s3">,</span>
    <span class="s1">prefer_skip_nested_validation=</span><span class="s3">True,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">fetch_lfw_people(</span>
    <span class="s1">*</span><span class="s3">,</span>
    <span class="s1">data_home=</span><span class="s3">None,</span>
    <span class="s1">funneled=</span><span class="s3">True,</span>
    <span class="s1">resize=</span><span class="s5">0.5</span><span class="s3">,</span>
    <span class="s1">min_faces_per_person=</span><span class="s5">0</span><span class="s3">,</span>
    <span class="s1">color=</span><span class="s3">False,</span>
    <span class="s1">slice_=(slice(</span><span class="s5">70</span><span class="s3">, </span><span class="s5">195</span><span class="s1">)</span><span class="s3">, </span><span class="s1">slice(</span><span class="s5">78</span><span class="s3">, </span><span class="s5">172</span><span class="s1">))</span><span class="s3">,</span>
    <span class="s1">download_if_missing=</span><span class="s3">True,</span>
    <span class="s1">return_X_y=</span><span class="s3">False,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Load the Labeled Faces in the Wild (LFW) people dataset \ 
(classification). 
 
    Download it if necessary. 
 
    =================   ======================= 
    Classes                                5749 
    Samples total                         13233 
    Dimensionality                         5828 
    Features            real, between 0 and 255 
    =================   ======================= 
 
    Read more in the :ref:`User Guide &lt;labeled_faces_in_the_wild_dataset&gt;`. 
 
    Parameters 
    ---------- 
    data_home : str or path-like, default=None 
        Specify another download and cache folder for the datasets. By default 
        all scikit-learn data is stored in '~/scikit_learn_data' subfolders. 
 
    funneled : bool, default=True 
        Download and use the funneled variant of the dataset. 
 
    resize : float or None, default=0.5 
        Ratio used to resize the each face picture. If `None`, no resizing is 
        performed. 
 
    min_faces_per_person : int, default=None 
        The extracted dataset will only retain pictures of people that have at 
        least `min_faces_per_person` different pictures. 
 
    color : bool, default=False 
        Keep the 3 RGB channels instead of averaging them to a single 
        gray level channel. If color is True the shape of the data has 
        one more dimension than the shape with color = False. 
 
    slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172)) 
        Provide a custom 2D slice (height, width) to extract the 
        'interesting' part of the jpeg files and avoid use statistical 
        correlation from the background. 
 
    download_if_missing : bool, default=True 
        If False, raise an OSError if the data is not locally available 
        instead of trying to download the data from the source site. 
 
    return_X_y : bool, default=False 
        If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch 
        object. See below for more information about the `dataset.data` and 
        `dataset.target` object. 
 
        .. versionadded:: 0.20 
 
    Returns 
    ------- 
    dataset : :class:`~sklearn.utils.Bunch` 
        Dictionary-like object, with the following attributes. 
 
        data : numpy array of shape (13233, 2914) 
            Each row corresponds to a ravelled face image 
            of original size 62 x 47 pixels. 
            Changing the ``slice_`` or resize parameters will change the 
            shape of the output. 
        images : numpy array of shape (13233, 62, 47) 
            Each row is a face image corresponding to one of the 5749 people in 
            the dataset. Changing the ``slice_`` 
            or resize parameters will change the shape of the output. 
        target : numpy array of shape (13233,) 
            Labels associated to each face image. 
            Those labels range from 0-5748 and correspond to the person IDs. 
        target_names : numpy array of shape (5749,) 
            Names of all persons in the dataset. 
            Position in array corresponds to the person ID in the target array. 
        DESCR : str 
            Description of the Labeled Faces in the Wild (LFW) dataset. 
 
    (data, target) : tuple if ``return_X_y`` is True 
        A tuple of two ndarray. The first containing a 2D array of 
        shape (n_samples, n_features) with each row representing one 
        sample and each column representing the features. The second 
        ndarray of shape (n_samples,) containing the target samples. 
 
        .. versionadded:: 0.20 
    &quot;&quot;&quot;</span>
    <span class="s1">lfw_home</span><span class="s3">, </span><span class="s1">data_folder_path = _check_fetch_lfw(</span>
        <span class="s1">data_home=data_home</span><span class="s3">, </span><span class="s1">funneled=funneled</span><span class="s3">, </span><span class="s1">download_if_missing=download_if_missing</span>
    <span class="s1">)</span>
    <span class="s1">logger.debug(</span><span class="s4">&quot;Loading LFW people faces from %s&quot;</span><span class="s3">, </span><span class="s1">lfw_home)</span>

    <span class="s2"># wrap the loader in a memoizing function that will return memmaped data</span>
    <span class="s2"># arrays for optimal memory usage</span>
    <span class="s1">m = Memory(location=lfw_home</span><span class="s3">, </span><span class="s1">compress=</span><span class="s5">6</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">load_func = m.cache(_fetch_lfw_people)</span>

    <span class="s2"># load and memoize the pairs as np arrays</span>
    <span class="s1">faces</span><span class="s3">, </span><span class="s1">target</span><span class="s3">, </span><span class="s1">target_names = load_func(</span>
        <span class="s1">data_folder_path</span><span class="s3">,</span>
        <span class="s1">resize=resize</span><span class="s3">,</span>
        <span class="s1">min_faces_per_person=min_faces_per_person</span><span class="s3">,</span>
        <span class="s1">color=color</span><span class="s3">,</span>
        <span class="s1">slice_=slice_</span><span class="s3">,</span>
    <span class="s1">)</span>

    <span class="s1">X = faces.reshape(len(faces)</span><span class="s3">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">fdescr = load_descr(</span><span class="s4">&quot;lfw.rst&quot;</span><span class="s1">)</span>

    <span class="s3">if </span><span class="s1">return_X_y:</span>
        <span class="s3">return </span><span class="s1">X</span><span class="s3">, </span><span class="s1">target</span>

    <span class="s2"># pack the results as a Bunch instance</span>
    <span class="s3">return </span><span class="s1">Bunch(</span>
        <span class="s1">data=X</span><span class="s3">, </span><span class="s1">images=faces</span><span class="s3">, </span><span class="s1">target=target</span><span class="s3">, </span><span class="s1">target_names=target_names</span><span class="s3">, </span><span class="s1">DESCR=fdescr</span>
    <span class="s1">)</span>


<span class="s2">#</span>
<span class="s2"># Task #2:  Face Verification on pairs of face pictures</span>
<span class="s2">#</span>


<span class="s3">def </span><span class="s1">_fetch_lfw_pairs(</span>
    <span class="s1">index_file_path</span><span class="s3">, </span><span class="s1">data_folder_path</span><span class="s3">, </span><span class="s1">slice_=</span><span class="s3">None, </span><span class="s1">color=</span><span class="s3">False, </span><span class="s1">resize=</span><span class="s3">None</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Perform the actual data loading for the LFW pairs dataset 
 
    This operation is meant to be cached by a joblib wrapper. 
    &quot;&quot;&quot;</span>
    <span class="s2"># parse the index file to find the number of pairs to be able to allocate</span>
    <span class="s2"># the right amount of memory before starting to decode the jpeg files</span>
    <span class="s3">with </span><span class="s1">open(index_file_path</span><span class="s3">, </span><span class="s4">&quot;rb&quot;</span><span class="s1">) </span><span class="s3">as </span><span class="s1">index_file:</span>
        <span class="s1">split_lines = [ln.decode().strip().split(</span><span class="s4">&quot;</span><span class="s3">\t</span><span class="s4">&quot;</span><span class="s1">) </span><span class="s3">for </span><span class="s1">ln </span><span class="s3">in </span><span class="s1">index_file]</span>
    <span class="s1">pair_specs = [sl </span><span class="s3">for </span><span class="s1">sl </span><span class="s3">in </span><span class="s1">split_lines </span><span class="s3">if </span><span class="s1">len(sl) &gt; </span><span class="s5">2</span><span class="s1">]</span>
    <span class="s1">n_pairs = len(pair_specs)</span>

    <span class="s2"># iterating over the metadata lines for each pair to find the filename to</span>
    <span class="s2"># decode and load in memory</span>
    <span class="s1">target = np.zeros(n_pairs</span><span class="s3">, </span><span class="s1">dtype=int)</span>
    <span class="s1">file_paths = list()</span>
    <span class="s3">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">components </span><span class="s3">in </span><span class="s1">enumerate(pair_specs):</span>
        <span class="s3">if </span><span class="s1">len(components) == </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s1">target[i] = </span><span class="s5">1</span>
            <span class="s1">pair = (</span>
                <span class="s1">(components[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">int(components[</span><span class="s5">1</span><span class="s1">]) - </span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
                <span class="s1">(components[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">int(components[</span><span class="s5">2</span><span class="s1">]) - </span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">)</span>
        <span class="s3">elif </span><span class="s1">len(components) == </span><span class="s5">4</span><span class="s1">:</span>
            <span class="s1">target[i] = </span><span class="s5">0</span>
            <span class="s1">pair = (</span>
                <span class="s1">(components[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">int(components[</span><span class="s5">1</span><span class="s1">]) - </span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
                <span class="s1">(components[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">, </span><span class="s1">int(components[</span><span class="s5">3</span><span class="s1">]) - </span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
            <span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;invalid line %d: %r&quot; </span><span class="s1">% (i + </span><span class="s5">1</span><span class="s3">, </span><span class="s1">components))</span>
        <span class="s3">for </span><span class="s1">j</span><span class="s3">, </span><span class="s1">(name</span><span class="s3">, </span><span class="s1">idx) </span><span class="s3">in </span><span class="s1">enumerate(pair):</span>
            <span class="s3">try</span><span class="s1">:</span>
                <span class="s1">person_folder = join(data_folder_path</span><span class="s3">, </span><span class="s1">name)</span>
            <span class="s3">except </span><span class="s1">TypeError:</span>
                <span class="s1">person_folder = join(data_folder_path</span><span class="s3">, </span><span class="s1">str(name</span><span class="s3">, </span><span class="s4">&quot;UTF-8&quot;</span><span class="s1">))</span>
            <span class="s1">filenames = list(sorted(listdir(person_folder)))</span>
            <span class="s1">file_path = join(person_folder</span><span class="s3">, </span><span class="s1">filenames[idx])</span>
            <span class="s1">file_paths.append(file_path)</span>

    <span class="s1">pairs = _load_imgs(file_paths</span><span class="s3">, </span><span class="s1">slice_</span><span class="s3">, </span><span class="s1">color</span><span class="s3">, </span><span class="s1">resize)</span>
    <span class="s1">shape = list(pairs.shape)</span>
    <span class="s1">n_faces = shape.pop(</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">shape.insert(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">shape.insert(</span><span class="s5">0</span><span class="s3">, </span><span class="s1">n_faces // </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">pairs.shape = shape</span>

    <span class="s3">return </span><span class="s1">pairs</span><span class="s3">, </span><span class="s1">target</span><span class="s3">, </span><span class="s1">np.array([</span><span class="s4">&quot;Different persons&quot;</span><span class="s3">, </span><span class="s4">&quot;Same person&quot;</span><span class="s1">])</span>


<span class="s1">@validate_params(</span>
    <span class="s1">{</span>
        <span class="s4">&quot;subset&quot;</span><span class="s1">: [StrOptions({</span><span class="s4">&quot;train&quot;</span><span class="s3">, </span><span class="s4">&quot;test&quot;</span><span class="s3">, </span><span class="s4">&quot;10_folds&quot;</span><span class="s1">})]</span><span class="s3">,</span>
        <span class="s4">&quot;data_home&quot;</span><span class="s1">: [str</span><span class="s3">, </span><span class="s1">PathLike</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;funneled&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;resize&quot;</span><span class="s1">: [Interval(Real</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, None, </span><span class="s1">closed=</span><span class="s4">&quot;neither&quot;</span><span class="s1">)</span><span class="s3">, None</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;color&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
        <span class="s4">&quot;slice_&quot;</span><span class="s1">: [tuple</span><span class="s3">, </span><span class="s1">Hidden(</span><span class="s3">None</span><span class="s1">)]</span><span class="s3">,</span>
        <span class="s4">&quot;download_if_missing&quot;</span><span class="s1">: [</span><span class="s4">&quot;boolean&quot;</span><span class="s1">]</span><span class="s3">,</span>
    <span class="s1">}</span><span class="s3">,</span>
    <span class="s1">prefer_skip_nested_validation=</span><span class="s3">True,</span>
<span class="s1">)</span>
<span class="s3">def </span><span class="s1">fetch_lfw_pairs(</span>
    <span class="s1">*</span><span class="s3">,</span>
    <span class="s1">subset=</span><span class="s4">&quot;train&quot;</span><span class="s3">,</span>
    <span class="s1">data_home=</span><span class="s3">None,</span>
    <span class="s1">funneled=</span><span class="s3">True,</span>
    <span class="s1">resize=</span><span class="s5">0.5</span><span class="s3">,</span>
    <span class="s1">color=</span><span class="s3">False,</span>
    <span class="s1">slice_=(slice(</span><span class="s5">70</span><span class="s3">, </span><span class="s5">195</span><span class="s1">)</span><span class="s3">, </span><span class="s1">slice(</span><span class="s5">78</span><span class="s3">, </span><span class="s5">172</span><span class="s1">))</span><span class="s3">,</span>
    <span class="s1">download_if_missing=</span><span class="s3">True,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Load the Labeled Faces in the Wild (LFW) pairs dataset (classification). 
 
    Download it if necessary. 
 
    =================   ======================= 
    Classes                                   2 
    Samples total                         13233 
    Dimensionality                         5828 
    Features            real, between 0 and 255 
    =================   ======================= 
 
    In the official `README.txt`_ this task is described as the 
    &quot;Restricted&quot; task.  As I am not sure as to implement the 
    &quot;Unrestricted&quot; variant correctly, I left it as unsupported for now. 
 
      .. _`README.txt`: http://vis-www.cs.umass.edu/lfw/README.txt 
 
    The original images are 250 x 250 pixels, but the default slice and resize 
    arguments reduce them to 62 x 47. 
 
    Read more in the :ref:`User Guide &lt;labeled_faces_in_the_wild_dataset&gt;`. 
 
    Parameters 
    ---------- 
    subset : {'train', 'test', '10_folds'}, default='train' 
        Select the dataset to load: 'train' for the development training 
        set, 'test' for the development test set, and '10_folds' for the 
        official evaluation set that is meant to be used with a 10-folds 
        cross validation. 
 
    data_home : str or path-like, default=None 
        Specify another download and cache folder for the datasets. By 
        default all scikit-learn data is stored in '~/scikit_learn_data' 
        subfolders. 
 
    funneled : bool, default=True 
        Download and use the funneled variant of the dataset. 
 
    resize : float, default=0.5 
        Ratio used to resize the each face picture. 
 
    color : bool, default=False 
        Keep the 3 RGB channels instead of averaging them to a single 
        gray level channel. If color is True the shape of the data has 
        one more dimension than the shape with color = False. 
 
    slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172)) 
        Provide a custom 2D slice (height, width) to extract the 
        'interesting' part of the jpeg files and avoid use statistical 
        correlation from the background. 
 
    download_if_missing : bool, default=True 
        If False, raise an OSError if the data is not locally available 
        instead of trying to download the data from the source site. 
 
    Returns 
    ------- 
    data : :class:`~sklearn.utils.Bunch` 
        Dictionary-like object, with the following attributes. 
 
        data : ndarray of shape (2200, 5828). Shape depends on ``subset``. 
            Each row corresponds to 2 ravel'd face images 
            of original size 62 x 47 pixels. 
            Changing the ``slice_``, ``resize`` or ``subset`` parameters 
            will change the shape of the output. 
        pairs : ndarray of shape (2200, 2, 62, 47). Shape depends on ``subset`` 
            Each row has 2 face images corresponding 
            to same or different person from the dataset 
            containing 5749 people. Changing the ``slice_``, 
            ``resize`` or ``subset`` parameters will change the shape of the 
            output. 
        target : numpy array of shape (2200,). Shape depends on ``subset``. 
            Labels associated to each pair of images. 
            The two label values being different persons or the same person. 
        target_names : numpy array of shape (2,) 
            Explains the target values of the target array. 
            0 corresponds to &quot;Different person&quot;, 1 corresponds to &quot;same person&quot;. 
        DESCR : str 
            Description of the Labeled Faces in the Wild (LFW) dataset. 
    &quot;&quot;&quot;</span>
    <span class="s1">lfw_home</span><span class="s3">, </span><span class="s1">data_folder_path = _check_fetch_lfw(</span>
        <span class="s1">data_home=data_home</span><span class="s3">, </span><span class="s1">funneled=funneled</span><span class="s3">, </span><span class="s1">download_if_missing=download_if_missing</span>
    <span class="s1">)</span>
    <span class="s1">logger.debug(</span><span class="s4">&quot;Loading %s LFW pairs from %s&quot;</span><span class="s3">, </span><span class="s1">subset</span><span class="s3">, </span><span class="s1">lfw_home)</span>

    <span class="s2"># wrap the loader in a memoizing function that will return memmaped data</span>
    <span class="s2"># arrays for optimal memory usage</span>
    <span class="s1">m = Memory(location=lfw_home</span><span class="s3">, </span><span class="s1">compress=</span><span class="s5">6</span><span class="s3">, </span><span class="s1">verbose=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">load_func = m.cache(_fetch_lfw_pairs)</span>

    <span class="s2"># select the right metadata file according to the requested subset</span>
    <span class="s1">label_filenames = {</span>
        <span class="s4">&quot;train&quot;</span><span class="s1">: </span><span class="s4">&quot;pairsDevTrain.txt&quot;</span><span class="s3">,</span>
        <span class="s4">&quot;test&quot;</span><span class="s1">: </span><span class="s4">&quot;pairsDevTest.txt&quot;</span><span class="s3">,</span>
        <span class="s4">&quot;10_folds&quot;</span><span class="s1">: </span><span class="s4">&quot;pairs.txt&quot;</span><span class="s3">,</span>
    <span class="s1">}</span>
    <span class="s3">if </span><span class="s1">subset </span><span class="s3">not in </span><span class="s1">label_filenames:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span>
            <span class="s4">&quot;subset='%s' is invalid: should be one of %r&quot;</span>
            <span class="s1">% (subset</span><span class="s3">, </span><span class="s1">list(sorted(label_filenames.keys())))</span>
        <span class="s1">)</span>
    <span class="s1">index_file_path = join(lfw_home</span><span class="s3">, </span><span class="s1">label_filenames[subset])</span>

    <span class="s2"># load and memoize the pairs as np arrays</span>
    <span class="s1">pairs</span><span class="s3">, </span><span class="s1">target</span><span class="s3">, </span><span class="s1">target_names = load_func(</span>
        <span class="s1">index_file_path</span><span class="s3">, </span><span class="s1">data_folder_path</span><span class="s3">, </span><span class="s1">resize=resize</span><span class="s3">, </span><span class="s1">color=color</span><span class="s3">, </span><span class="s1">slice_=slice_</span>
    <span class="s1">)</span>

    <span class="s1">fdescr = load_descr(</span><span class="s4">&quot;lfw.rst&quot;</span><span class="s1">)</span>

    <span class="s2"># pack the results as a Bunch instance</span>
    <span class="s3">return </span><span class="s1">Bunch(</span>
        <span class="s1">data=pairs.reshape(len(pairs)</span><span class="s3">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span><span class="s3">,</span>
        <span class="s1">pairs=pairs</span><span class="s3">,</span>
        <span class="s1">target=target</span><span class="s3">,</span>
        <span class="s1">target_names=target_names</span><span class="s3">,</span>
        <span class="s1">DESCR=fdescr</span><span class="s3">,</span>
    <span class="s1">)</span>
</pre>
</body>
</html>
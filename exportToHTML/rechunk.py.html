<html>
<head>
<title>rechunk.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
rechunk.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
The rechunk module defines: 
    intersect_chunks: a function for 
        converting chunks to new dimensions 
    rechunk: a function to convert the blocks 
        of an existing dask array to new chunks or blockshape 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">import </span><span class="s1">heapq</span>
<span class="s2">import </span><span class="s1">math</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">reduce</span>
<span class="s2">from </span><span class="s1">itertools </span><span class="s2">import </span><span class="s1">chain</span><span class="s2">, </span><span class="s1">count</span><span class="s2">, </span><span class="s1">product</span>
<span class="s2">from </span><span class="s1">operator </span><span class="s2">import </span><span class="s1">add</span><span class="s2">, </span><span class="s1">itemgetter</span><span class="s2">, </span><span class="s1">mul</span>
<span class="s2">from </span><span class="s1">warnings </span><span class="s2">import </span><span class="s1">warn</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">tlz </span><span class="s2">as </span><span class="s1">toolz</span>
<span class="s2">from </span><span class="s1">tlz </span><span class="s2">import </span><span class="s1">accumulate</span>

<span class="s2">from </span><span class="s1">dask </span><span class="s2">import </span><span class="s1">config</span>
<span class="s2">from </span><span class="s1">dask.array.chunk </span><span class="s2">import </span><span class="s1">getitem</span>
<span class="s2">from </span><span class="s1">dask.array.core </span><span class="s2">import </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">concatenate3</span><span class="s2">, </span><span class="s1">normalize_chunks</span>
<span class="s2">from </span><span class="s1">dask.array.utils </span><span class="s2">import </span><span class="s1">validate_axis</span>
<span class="s2">from </span><span class="s1">dask.array.wrap </span><span class="s2">import </span><span class="s1">empty</span>
<span class="s2">from </span><span class="s1">dask.base </span><span class="s2">import </span><span class="s1">tokenize</span>
<span class="s2">from </span><span class="s1">dask.highlevelgraph </span><span class="s2">import </span><span class="s1">HighLevelGraph</span>
<span class="s2">from </span><span class="s1">dask.utils </span><span class="s2">import </span><span class="s1">parse_bytes</span>


<span class="s2">def </span><span class="s1">cumdims_label(chunks</span><span class="s2">, </span><span class="s1">const):</span>
    <span class="s0">&quot;&quot;&quot;Internal utility for cumulative sum with label. 
 
    &gt;&gt;&gt; cumdims_label(((5, 3, 3), (2, 2, 1)), 'n')  # doctest: +NORMALIZE_WHITESPACE 
    [(('n', 0), ('n', 5), ('n', 8), ('n', 11)), 
     (('n', 0), ('n', 2), ('n', 4), ('n', 5))] 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">[</span>
        <span class="s1">tuple(zip((const</span><span class="s2">,</span><span class="s1">) * (</span><span class="s3">1 </span><span class="s1">+ len(bds))</span><span class="s2">, </span><span class="s1">accumulate(add</span><span class="s2">, </span><span class="s1">(</span><span class="s3">0</span><span class="s2">,</span><span class="s1">) + bds)))</span>
        <span class="s2">for </span><span class="s1">bds </span><span class="s2">in </span><span class="s1">chunks</span>
    <span class="s1">]</span>


<span class="s2">def </span><span class="s1">_breakpoints(cumold</span><span class="s2">, </span><span class="s1">cumnew):</span>
    <span class="s0">&quot;&quot;&quot; 
 
    &gt;&gt;&gt; new = cumdims_label(((2, 3), (2, 2, 1)), 'n') 
    &gt;&gt;&gt; old = cumdims_label(((2, 2, 1), (5,)), 'o') 
 
    &gt;&gt;&gt; _breakpoints(new[0], old[0]) 
    (('n', 0), ('o', 0), ('n', 2), ('o', 2), ('o', 4), ('n', 5), ('o', 5)) 
    &gt;&gt;&gt; _breakpoints(new[1], old[1]) 
    (('n', 0), ('o', 0), ('n', 2), ('n', 4), ('n', 5), ('o', 5)) 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">tuple(sorted(cumold + cumnew</span><span class="s2">, </span><span class="s1">key=itemgetter(</span><span class="s3">1</span><span class="s1">)))</span>


<span class="s2">def </span><span class="s1">_intersect_1d(breaks):</span>
    <span class="s0">&quot;&quot;&quot; 
    Internal utility to intersect chunks for 1d after preprocessing. 
 
    &gt;&gt;&gt; new = cumdims_label(((2, 3), (2, 2, 1)), 'n') 
    &gt;&gt;&gt; old = cumdims_label(((2, 2, 1), (5,)), 'o') 
 
    &gt;&gt;&gt; _intersect_1d(_breakpoints(old[0], new[0]))  # doctest: +NORMALIZE_WHITESPACE 
    [[(0, slice(0, 2, None))], 
     [(1, slice(0, 2, None)), (2, slice(0, 1, None))]] 
    &gt;&gt;&gt; _intersect_1d(_breakpoints(old[1], new[1]))  # doctest: +NORMALIZE_WHITESPACE 
    [[(0, slice(0, 2, None))], 
     [(0, slice(2, 4, None))], 
     [(0, slice(4, 5, None))]] 
 
    Parameters 
    ---------- 
 
    breaks: list of tuples 
        Each tuple is ('o', 8) or ('n', 8) 
        These are pairs of 'o' old or new 'n' 
        indicator with a corresponding cumulative sum, 
        or breakpoint (a position along the chunking axis). 
        The list of pairs is already ordered by breakpoint. 
        Note that an 'o' pair always occurs BEFORE 
        an 'n' pair if both share the same breakpoint. 
    Uses 'o' and 'n' to make new tuples of slices for 
    the new block crosswalk to old blocks. 
    &quot;&quot;&quot;</span>
    <span class="s4"># EXPLANATION:</span>
    <span class="s4"># We know each new chunk is obtained from the old chunks, but</span>
    <span class="s4"># from which ones and how? This function provides the answer.</span>
    <span class="s4"># On return, each new chunk is represented as a list of slices</span>
    <span class="s4"># of the old chunks. Therefore,  paired with each slice is the</span>
    <span class="s4"># index of the old chunk to which that slice refers.</span>
    <span class="s4"># NOTE: if any nonzero-size new chunks extend beyond the total</span>
    <span class="s4">#    span of the old chunks, then those new chunks are assumed</span>
    <span class="s4">#    to be obtained from an imaginary old chunk that extends</span>
    <span class="s4">#    from the end of that total span to infinity. The chunk-</span>
    <span class="s4">#    index of this imaginary chunk follows in consecutive order</span>
    <span class="s4">#    from the chunk-indices of the actual old chunks.</span>

    <span class="s4"># First, let us determine the index of the last old_chunk:</span>
    <span class="s1">o_pairs = [pair </span><span class="s2">for </span><span class="s1">pair </span><span class="s2">in </span><span class="s1">breaks </span><span class="s2">if </span><span class="s1">pair[</span><span class="s3">0</span><span class="s1">] == </span><span class="s5">&quot;o&quot;</span><span class="s1">]</span>
    <span class="s1">last_old_chunk_idx = len(o_pairs) - </span><span class="s3">2</span>
    <span class="s1">last_o_br = o_pairs[-</span><span class="s3">1</span><span class="s1">][</span><span class="s3">1</span><span class="s1">]  </span><span class="s4"># end of range spanning all old chunks</span>

    <span class="s1">start = </span><span class="s3">0  </span><span class="s4"># start of a slice of an old chunk</span>
    <span class="s1">last_end = </span><span class="s3">0</span>
    <span class="s1">old_idx = </span><span class="s3">0  </span><span class="s4"># index of old chunk</span>
    <span class="s1">last_o_end = </span><span class="s3">0</span>
    <span class="s1">ret = []  </span><span class="s4"># will hold the list of new chunks</span>
    <span class="s1">ret_next = []  </span><span class="s4"># will hold the list of slices comprising one new chunk</span>
    <span class="s2">for </span><span class="s1">idx </span><span class="s2">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">len(breaks)):  </span><span class="s4"># Note start from the 2nd pair</span>
        <span class="s4"># the interval between any two consecutive breakpoints is a potential</span>
        <span class="s4"># new chunk:</span>
        <span class="s1">label</span><span class="s2">, </span><span class="s1">br = breaks[idx]</span>
        <span class="s1">last_label</span><span class="s2">, </span><span class="s1">last_br = breaks[idx - </span><span class="s3">1</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">last_label == </span><span class="s5">&quot;n&quot;</span><span class="s1">:</span>
            <span class="s4"># This always denotes the end of a new chunk or the start</span>
            <span class="s4"># of the next new chunk or both</span>
            <span class="s1">start = last_end</span>
            <span class="s2">if </span><span class="s1">ret_next:</span>
                <span class="s1">ret.append(ret_next)</span>
                <span class="s1">ret_next = []</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">start = </span><span class="s3">0</span>
        <span class="s1">end = br - last_br + start  </span><span class="s4"># end of a slice of an old chunk</span>
        <span class="s1">last_end = end</span>
        <span class="s2">if </span><span class="s1">br == last_br:</span>
            <span class="s4"># Here we have a zero-size interval between the previous and</span>
            <span class="s4"># current breakpoints. This should not result in a slice unless</span>
            <span class="s4"># this interval's end-points (`last_label` and `label`) are both</span>
            <span class="s4"># equal to 'n'</span>
            <span class="s2">if </span><span class="s1">label == </span><span class="s5">&quot;o&quot;</span><span class="s1">:</span>
                <span class="s1">old_idx += </span><span class="s3">1</span>
                <span class="s1">last_o_end = end</span>
            <span class="s2">if </span><span class="s1">label == </span><span class="s5">&quot;n&quot; </span><span class="s2">and </span><span class="s1">last_label == </span><span class="s5">&quot;n&quot;</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">br == last_o_br:</span>
                    <span class="s4"># zero-size new chunks located at the edge of the range</span>
                    <span class="s4"># spanning all the old chunks are assumed to come from the</span>
                    <span class="s4"># end of the last old chunk:</span>
                    <span class="s1">slc = slice(last_o_end</span><span class="s2">, </span><span class="s1">last_o_end)</span>
                    <span class="s1">ret_next.append((last_old_chunk_idx</span><span class="s2">, </span><span class="s1">slc))</span>
                    <span class="s2">continue</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">continue</span>
        <span class="s1">ret_next.append((old_idx</span><span class="s2">, </span><span class="s1">slice(start</span><span class="s2">, </span><span class="s1">end)))</span>
        <span class="s2">if </span><span class="s1">label == </span><span class="s5">&quot;o&quot;</span><span class="s1">:</span>
            <span class="s1">old_idx += </span><span class="s3">1</span>
            <span class="s1">start = </span><span class="s3">0</span>
            <span class="s1">last_o_end = end</span>

    <span class="s2">if </span><span class="s1">ret_next:</span>
        <span class="s1">ret.append(ret_next)</span>

    <span class="s2">return </span><span class="s1">ret</span>


<span class="s2">def </span><span class="s1">old_to_new(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks):</span>
    <span class="s0">&quot;&quot;&quot;Helper to build old_chunks to new_chunks. 
 
    Handles missing values, as long as the dimension with the missing chunk values 
    is unchanged. 
 
    Notes 
    ----- 
    This function expects that the arguments have been pre-processed by 
    :func:`dask.array.core.normalize_chunks`. In particular any ``nan`` values should 
    have been replaced (and are so by :func:`dask.array.core.normalize_chunks`) 
    by the canonical ``np.nan``. It also expects that the arguments have been validated 
    with `_validate_rechunk` and rechunking is thus possible. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; old = ((10, 10, 10, 10, 10), ) 
    &gt;&gt;&gt; new = ((25, 5, 20), ) 
    &gt;&gt;&gt; old_to_new(old, new)  # doctest: +NORMALIZE_WHITESPACE 
    [[[(0, slice(0, 10, None)), (1, slice(0, 10, None)), (2, slice(0, 5, None))], 
      [(2, slice(5, 10, None))], 
      [(3, slice(0, 10, None)), (4, slice(0, 10, None))]]] 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">is_unknown(dim):</span>
        <span class="s2">return </span><span class="s1">any(math.isnan(chunk) </span><span class="s2">for </span><span class="s1">chunk </span><span class="s2">in </span><span class="s1">dim)</span>

    <span class="s1">dims_unknown = [is_unknown(dim) </span><span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">old_chunks]</span>

    <span class="s1">known_indices = []</span>
    <span class="s1">unknown_indices = []</span>
    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">unknown </span><span class="s2">in </span><span class="s1">enumerate(dims_unknown):</span>
        <span class="s2">if </span><span class="s1">unknown:</span>
            <span class="s1">unknown_indices.append(i)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">known_indices.append(i)</span>

    <span class="s1">old_known = [old_chunks[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">known_indices]</span>
    <span class="s1">new_known = [new_chunks[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">known_indices]</span>

    <span class="s1">cmos = cumdims_label(old_known</span><span class="s2">, </span><span class="s5">&quot;o&quot;</span><span class="s1">)</span>
    <span class="s1">cmns = cumdims_label(new_known</span><span class="s2">, </span><span class="s5">&quot;n&quot;</span><span class="s1">)</span>

    <span class="s1">sliced = [</span><span class="s2">None</span><span class="s1">] * len(old_chunks)</span>
    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">cmo</span><span class="s2">, </span><span class="s1">cmn </span><span class="s2">in </span><span class="s1">zip(known_indices</span><span class="s2">, </span><span class="s1">cmos</span><span class="s2">, </span><span class="s1">cmns):</span>
        <span class="s1">sliced[i] = _intersect_1d(_breakpoints(cmo</span><span class="s2">, </span><span class="s1">cmn))</span>

    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">unknown_indices:</span>
        <span class="s1">dim = old_chunks[i]</span>
        <span class="s4"># Unknown dimensions are always unchanged, so old -&gt; new is everything</span>
        <span class="s1">extra = [</span>
            <span class="s1">[(j</span><span class="s2">, </span><span class="s1">slice(</span><span class="s3">0</span><span class="s2">, </span><span class="s1">size </span><span class="s2">if not </span><span class="s1">math.isnan(size) </span><span class="s2">else None</span><span class="s1">))]</span>
            <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">size </span><span class="s2">in </span><span class="s1">enumerate(dim)</span>
        <span class="s1">]</span>
        <span class="s1">sliced[i] = extra</span>
    <span class="s2">assert </span><span class="s1">all(x </span><span class="s2">is not None for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">sliced)</span>
    <span class="s2">return </span><span class="s1">sliced</span>


<span class="s2">def </span><span class="s1">intersect_chunks(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks):</span>
    <span class="s0">&quot;&quot;&quot; 
    Make dask.array slices as intersection of old and new chunks. 
 
    &gt;&gt;&gt; intersections = intersect_chunks(((4, 4), (2,)), 
    ...                                  ((8,), (1, 1))) 
    &gt;&gt;&gt; list(intersections)  # doctest: +NORMALIZE_WHITESPACE 
    [(((0, slice(0, 4, None)), (0, slice(0, 1, None))), 
      ((1, slice(0, 4, None)), (0, slice(0, 1, None)))), 
     (((0, slice(0, 4, None)), (0, slice(1, 2, None))), 
      ((1, slice(0, 4, None)), (0, slice(1, 2, None))))] 
 
    Parameters 
    ---------- 
 
    old_chunks : iterable of tuples 
        block sizes along each dimension (convert from old_chunks) 
    new_chunks: iterable of tuples 
        block sizes along each dimension (converts to new_chunks) 
    &quot;&quot;&quot;</span>
    <span class="s1">cross1 = product(*old_to_new(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks))</span>
    <span class="s1">cross = chain(tuple(product(*cr)) </span><span class="s2">for </span><span class="s1">cr </span><span class="s2">in </span><span class="s1">cross1)</span>
    <span class="s2">return </span><span class="s1">cross</span>


<span class="s2">def </span><span class="s1">_validate_rechunk(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks):</span>
    <span class="s0">&quot;&quot;&quot;Validates that rechunking an array from ``old_chunks`` to ``new_chunks`` 
    is possible, raises an error if otherwise. 
 
    Notes 
    ----- 
    This function expects ``old_chunks`` and ``new_chunks`` to have matching 
    dimensionality and will not raise an informative error if they don't. 
    &quot;&quot;&quot;</span>
    <span class="s2">assert </span><span class="s1">len(old_chunks) == len(new_chunks)</span>

    <span class="s1">old_shapes = tuple(map(sum</span><span class="s2">, </span><span class="s1">old_chunks))</span>
    <span class="s1">new_shapes = tuple(map(sum</span><span class="s2">, </span><span class="s1">new_chunks))</span>

    <span class="s2">for </span><span class="s1">old_shape</span><span class="s2">, </span><span class="s1">old_dim</span><span class="s2">, </span><span class="s1">new_shape</span><span class="s2">, </span><span class="s1">new_dim </span><span class="s2">in </span><span class="s1">zip(</span>
        <span class="s1">old_shapes</span><span class="s2">, </span><span class="s1">old_chunks</span><span class="s2">, </span><span class="s1">new_shapes</span><span class="s2">, </span><span class="s1">new_chunks</span>
    <span class="s1">):</span>
        <span class="s2">if </span><span class="s1">old_shape != new_shape:</span>
            <span class="s2">if not </span><span class="s1">(</span>
                <span class="s1">math.isnan(old_shape) </span><span class="s2">and </span><span class="s1">math.isnan(new_shape)</span>
            <span class="s1">) </span><span class="s2">or not </span><span class="s1">np.array_equal(old_dim</span><span class="s2">, </span><span class="s1">new_dim</span><span class="s2">, </span><span class="s1">equal_nan=</span><span class="s2">True</span><span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s5">&quot;Chunks must be unchanging along dimensions with missing values.</span><span class="s2">\n\n</span><span class="s5">&quot;</span>
                    <span class="s5">&quot;A possible solution:</span><span class="s2">\n  </span><span class="s5">x.compute_chunk_sizes()&quot;</span>
                <span class="s1">)</span>


<span class="s2">def </span><span class="s1">rechunk(</span>
    <span class="s1">x</span><span class="s2">,</span>
    <span class="s1">chunks=</span><span class="s5">&quot;auto&quot;</span><span class="s2">,</span>
    <span class="s1">threshold=</span><span class="s2">None,</span>
    <span class="s1">block_size_limit=</span><span class="s2">None,</span>
    <span class="s1">balance=</span><span class="s2">False,</span>
    <span class="s1">method=</span><span class="s2">None,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Convert blocks in dask array x for new chunks. 
 
    Parameters 
    ---------- 
    x: dask array 
        Array to be rechunked. 
    chunks:  int, tuple, dict or str, optional 
        The new block dimensions to create. -1 indicates the full size of the 
        corresponding dimension. Default is &quot;auto&quot; which automatically 
        determines chunk sizes. 
    threshold: int, optional 
        The graph growth factor under which we don't bother introducing an 
        intermediate step. 
    block_size_limit: int, optional 
        The maximum block size (in bytes) we want to produce 
        Defaults to the configuration value ``array.chunk-size`` 
    balance : bool, default False 
        If True, try to make each chunk to be the same size. 
 
        This means ``balance=True`` will remove any small leftover chunks, so 
        using ``x.rechunk(chunks=len(x) // N, balance=True)`` 
        will almost certainly result in ``N`` chunks. 
    method: {'tasks', 'p2p'}, optional. 
        Rechunking method to use. 
 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import dask.array as da 
    &gt;&gt;&gt; x = da.ones((1000, 1000), chunks=(100, 100)) 
 
    Specify uniform chunk sizes with a tuple 
 
    &gt;&gt;&gt; y = x.rechunk((1000, 10)) 
 
    Or chunk only specific dimensions with a dictionary 
 
    &gt;&gt;&gt; y = x.rechunk({0: 1000}) 
 
    Use the value ``-1`` to specify that you want a single chunk along a 
    dimension or the value ``&quot;auto&quot;`` to specify that dask can freely rechunk a 
    dimension to attain blocks of a uniform block size 
 
    &gt;&gt;&gt; y = x.rechunk({0: -1, 1: 'auto'}, block_size_limit=1e8) 
 
    If a chunk size does not divide the dimension then rechunk will leave any 
    unevenness to the last chunk. 
 
    &gt;&gt;&gt; x.rechunk(chunks=(400, -1)).chunks 
    ((400, 400, 200), (1000,)) 
 
    However if you want more balanced chunks, and don't mind Dask choosing a 
    different chunksize for you then you can use the ``balance=True`` option. 
 
    &gt;&gt;&gt; x.rechunk(chunks=(400, -1), balance=True).chunks 
    ((500, 500), (1000,)) 
    &quot;&quot;&quot;</span>
    <span class="s4"># don't rechunk if array is empty</span>
    <span class="s2">if </span><span class="s1">x.ndim &gt; </span><span class="s3">0 </span><span class="s2">and </span><span class="s1">all(s == </span><span class="s3">0 </span><span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">x.shape):</span>
        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">if </span><span class="s1">isinstance(chunks</span><span class="s2">, </span><span class="s1">dict):</span>
        <span class="s1">chunks = {validate_axis(c</span><span class="s2">, </span><span class="s1">x.ndim): v </span><span class="s2">for </span><span class="s1">c</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">chunks.items()}</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(x.ndim):</span>
            <span class="s2">if </span><span class="s1">i </span><span class="s2">not in </span><span class="s1">chunks:</span>
                <span class="s1">chunks[i] = x.chunks[i]</span>
            <span class="s2">elif </span><span class="s1">chunks[i] </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">chunks[i] = x.chunks[i]</span>
    <span class="s2">if </span><span class="s1">isinstance(chunks</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
        <span class="s1">chunks = tuple(lc </span><span class="s2">if </span><span class="s1">lc </span><span class="s2">is not None else </span><span class="s1">rc </span><span class="s2">for </span><span class="s1">lc</span><span class="s2">, </span><span class="s1">rc </span><span class="s2">in </span><span class="s1">zip(chunks</span><span class="s2">, </span><span class="s1">x.chunks))</span>
    <span class="s1">chunks = normalize_chunks(</span>
        <span class="s1">chunks</span><span class="s2">, </span><span class="s1">x.shape</span><span class="s2">, </span><span class="s1">limit=block_size_limit</span><span class="s2">, </span><span class="s1">dtype=x.dtype</span><span class="s2">, </span><span class="s1">previous_chunks=x.chunks</span>
    <span class="s1">)</span>

    <span class="s4"># Now chunks are tuple of tuples</span>
    <span class="s1">ndim = x.ndim</span>
    <span class="s2">if not </span><span class="s1">len(chunks) == ndim:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Provided chunks are not consistent with shape&quot;</span><span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">balance </span><span class="s2">and </span><span class="s1">(chunks == x.chunks):</span>
        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">if </span><span class="s1">balance:</span>
        <span class="s1">chunks = tuple(_balance_chunksizes(chunk) </span><span class="s2">for </span><span class="s1">chunk </span><span class="s2">in </span><span class="s1">chunks)</span>

    <span class="s1">_validate_rechunk(x.chunks</span><span class="s2">, </span><span class="s1">chunks)</span>

    <span class="s1">method = method </span><span class="s2">or </span><span class="s1">config.get(</span><span class="s5">&quot;array.rechunk.method&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">method == </span><span class="s5">&quot;tasks&quot;</span><span class="s1">:</span>
        <span class="s1">steps = plan_rechunk(</span>
            <span class="s1">x.chunks</span><span class="s2">, </span><span class="s1">chunks</span><span class="s2">, </span><span class="s1">x.dtype.itemsize</span><span class="s2">, </span><span class="s1">threshold</span><span class="s2">, </span><span class="s1">block_size_limit</span>
        <span class="s1">)</span>
        <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">steps:</span>
            <span class="s1">x = _compute_rechunk(x</span><span class="s2">, </span><span class="s1">c)</span>

        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">elif </span><span class="s1">method == </span><span class="s5">&quot;p2p&quot;</span><span class="s1">:</span>
        <span class="s2">from </span><span class="s1">distributed.shuffle </span><span class="s2">import </span><span class="s1">rechunk_p2p</span>

        <span class="s2">return </span><span class="s1">rechunk_p2p(x</span><span class="s2">, </span><span class="s1">chunks)</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s5">f&quot;Unknown rechunking method '</span><span class="s2">{</span><span class="s1">method</span><span class="s2">}</span><span class="s5">'&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_number_of_blocks(chunks):</span>
    <span class="s2">return </span><span class="s1">reduce(mul</span><span class="s2">, </span><span class="s1">map(len</span><span class="s2">, </span><span class="s1">chunks))</span>


<span class="s2">def </span><span class="s1">_largest_block_size(chunks):</span>
    <span class="s2">return </span><span class="s1">reduce(mul</span><span class="s2">, </span><span class="s1">map(max</span><span class="s2">, </span><span class="s1">chunks))</span>


<span class="s2">def </span><span class="s1">estimate_graph_size(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks):</span>
    <span class="s0">&quot;&quot;&quot;Estimate the graph size during a rechunk computation.&quot;&quot;&quot;</span>
    <span class="s4"># Estimate the number of intermediate blocks that will be produced</span>
    <span class="s4"># (we don't use intersect_chunks() which is much more expensive)</span>
    <span class="s1">crossed_size = reduce(</span>
        <span class="s1">mul</span><span class="s2">,</span>
        <span class="s1">(</span>
            <span class="s1">(len(oc) + len(nc) - </span><span class="s3">1 </span><span class="s2">if </span><span class="s1">oc != nc </span><span class="s2">else </span><span class="s1">len(oc))</span>
            <span class="s2">for </span><span class="s1">oc</span><span class="s2">, </span><span class="s1">nc </span><span class="s2">in </span><span class="s1">zip(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks)</span>
        <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">crossed_size</span>


<span class="s2">def </span><span class="s1">divide_to_width(desired_chunks</span><span class="s2">, </span><span class="s1">max_width):</span>
    <span class="s0">&quot;&quot;&quot;Minimally divide the given chunks so as to make the largest chunk 
    width less or equal than *max_width*. 
    &quot;&quot;&quot;</span>
    <span class="s1">chunks = []</span>
    <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">desired_chunks:</span>
        <span class="s1">nb_divides = int(np.ceil(c / max_width))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(nb_divides):</span>
            <span class="s1">n = c // (nb_divides - i)</span>
            <span class="s1">chunks.append(n)</span>
            <span class="s1">c -= n</span>
        <span class="s2">assert </span><span class="s1">c == </span><span class="s3">0</span>
    <span class="s2">return </span><span class="s1">tuple(chunks)</span>


<span class="s2">def </span><span class="s1">merge_to_number(desired_chunks</span><span class="s2">, </span><span class="s1">max_number):</span>
    <span class="s0">&quot;&quot;&quot;Minimally merge the given chunks so as to drop the number of 
    chunks below *max_number*, while minimizing the largest width. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">len(desired_chunks) &lt;= max_number:</span>
        <span class="s2">return </span><span class="s1">desired_chunks</span>

    <span class="s1">distinct = set(desired_chunks)</span>
    <span class="s2">if </span><span class="s1">len(distinct) == </span><span class="s3">1</span><span class="s1">:</span>
        <span class="s4"># Fast path for homogeneous target, also ensuring a regular result</span>
        <span class="s1">w = distinct.pop()</span>
        <span class="s1">n = len(desired_chunks)</span>
        <span class="s1">total = n * w</span>

        <span class="s1">desired_width = total // max_number</span>
        <span class="s1">width = w * (desired_width // w)</span>
        <span class="s1">adjust = (total - max_number * width) // w</span>

        <span class="s2">return </span><span class="s1">(width + w</span><span class="s2">,</span><span class="s1">) * adjust + (width</span><span class="s2">,</span><span class="s1">) * (max_number - adjust)</span>

    <span class="s1">desired_width = sum(desired_chunks) // max_number</span>
    <span class="s1">nmerges = len(desired_chunks) - max_number</span>

    <span class="s1">heap = [</span>
        <span class="s1">(desired_chunks[i] + desired_chunks[i + </span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">i + </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(desired_chunks) - </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">]</span>
    <span class="s1">heapq.heapify(heap)</span>

    <span class="s1">chunks = list(desired_chunks)</span>

    <span class="s2">while </span><span class="s1">nmerges &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s4"># Find smallest interval to merge</span>
        <span class="s1">width</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">j = heapq.heappop(heap)</span>
        <span class="s4"># If interval was made invalid by another merge, recompute</span>
        <span class="s4"># it, re-insert it and retry.</span>
        <span class="s2">if </span><span class="s1">chunks[j] == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">j += </span><span class="s3">1</span>
            <span class="s2">while </span><span class="s1">chunks[j] == </span><span class="s3">0</span><span class="s1">:</span>
                <span class="s1">j += </span><span class="s3">1</span>
            <span class="s1">heapq.heappush(heap</span><span class="s2">, </span><span class="s1">(chunks[i] + chunks[j]</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">j))</span>
            <span class="s2">continue</span>
        <span class="s2">elif </span><span class="s1">chunks[i] + chunks[j] != width:</span>
            <span class="s1">heapq.heappush(heap</span><span class="s2">, </span><span class="s1">(chunks[i] + chunks[j]</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">j))</span>
            <span class="s2">continue</span>
        <span class="s4"># Merge</span>
        <span class="s2">assert </span><span class="s1">chunks[i] != </span><span class="s3">0</span>
        <span class="s1">chunks[i] = </span><span class="s3">0  </span><span class="s4"># mark deleted</span>
        <span class="s1">chunks[j] = width</span>
        <span class="s1">nmerges -= </span><span class="s3">1</span>

    <span class="s2">return </span><span class="s1">tuple(filter(</span><span class="s2">None, </span><span class="s1">chunks))</span>


<span class="s2">def </span><span class="s1">find_merge_rechunk(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks</span><span class="s2">, </span><span class="s1">block_size_limit):</span>
    <span class="s0">&quot;&quot;&quot; 
    Find an intermediate rechunk that would merge some adjacent blocks 
    together in order to get us nearer the *new_chunks* target, without 
    violating the *block_size_limit* (in number of elements). 
    &quot;&quot;&quot;</span>
    <span class="s1">ndim = len(old_chunks)</span>

    <span class="s1">old_largest_width = [max(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">old_chunks]</span>
    <span class="s1">new_largest_width = [max(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">new_chunks]</span>

    <span class="s1">graph_size_effect = {</span>
        <span class="s1">dim: len(nc) / len(oc)</span>
        <span class="s2">for </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">(oc</span><span class="s2">, </span><span class="s1">nc) </span><span class="s2">in </span><span class="s1">enumerate(zip(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks))</span>
    <span class="s1">}</span>

    <span class="s1">block_size_effect = {</span>
        <span class="s1">dim: new_largest_width[dim] / (old_largest_width[dim] </span><span class="s2">or </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">range(ndim)</span>
    <span class="s1">}</span>

    <span class="s4"># Our goal is to reduce the number of nodes in the rechunk graph</span>
    <span class="s4"># by merging some adjacent chunks, so consider dimensions where we can</span>
    <span class="s4"># reduce the # of chunks</span>
    <span class="s1">merge_candidates = [dim </span><span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">range(ndim) </span><span class="s2">if </span><span class="s1">graph_size_effect[dim] &lt;= </span><span class="s3">1.0</span><span class="s1">]</span>

    <span class="s4"># Merging along each dimension reduces the graph size by a certain factor</span>
    <span class="s4"># and increases memory largest block size by a certain factor.</span>
    <span class="s4"># We want to optimize the graph size while staying below the given</span>
    <span class="s4"># block_size_limit.  This is in effect a knapsack problem, except with</span>
    <span class="s4"># multiplicative values and weights.  Just use a greedy algorithm</span>
    <span class="s4"># by trying dimensions in decreasing value / weight order.</span>
    <span class="s2">def </span><span class="s1">key(k):</span>
        <span class="s1">gse = graph_size_effect[k]</span>
        <span class="s1">bse = block_size_effect[k]</span>
        <span class="s2">if </span><span class="s1">bse == </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">bse = </span><span class="s3">1 </span><span class="s1">+ </span><span class="s3">1e-9</span>
        <span class="s2">return </span><span class="s1">(np.log(gse) / np.log(bse)) </span><span class="s2">if </span><span class="s1">bse &gt; </span><span class="s3">0 </span><span class="s2">else </span><span class="s3">0</span>

    <span class="s1">sorted_candidates = sorted(merge_candidates</span><span class="s2">, </span><span class="s1">key=key)</span>

    <span class="s1">largest_block_size = reduce(mul</span><span class="s2">, </span><span class="s1">old_largest_width)</span>

    <span class="s1">chunks = list(old_chunks)</span>
    <span class="s1">memory_limit_hit = </span><span class="s2">False</span>

    <span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">sorted_candidates:</span>
        <span class="s4"># Examine this dimension for possible graph reduction</span>
        <span class="s1">new_largest_block_size = (</span>
            <span class="s1">largest_block_size * new_largest_width[dim] // (old_largest_width[dim] </span><span class="s2">or </span><span class="s3">1</span><span class="s1">)</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">new_largest_block_size &lt;= block_size_limit:</span>
            <span class="s4"># Full replacement by new chunks is possible</span>
            <span class="s1">chunks[dim] = new_chunks[dim]</span>
            <span class="s1">largest_block_size = new_largest_block_size</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># Try a partial rechunk, dividing the new chunks into</span>
            <span class="s4"># smaller pieces</span>
            <span class="s1">largest_width = old_largest_width[dim]</span>
            <span class="s1">chunk_limit = int(block_size_limit * largest_width / largest_block_size)</span>
            <span class="s1">c = divide_to_width(new_chunks[dim]</span><span class="s2">, </span><span class="s1">chunk_limit)</span>
            <span class="s2">if </span><span class="s1">len(c) &lt;= len(old_chunks[dim]):</span>
                <span class="s4"># We manage to reduce the number of blocks, so do it</span>
                <span class="s1">chunks[dim] = c</span>
                <span class="s1">largest_block_size = largest_block_size * max(c) // largest_width</span>

            <span class="s1">memory_limit_hit = </span><span class="s2">True</span>

    <span class="s2">assert </span><span class="s1">largest_block_size == _largest_block_size(chunks)</span>
    <span class="s2">assert </span><span class="s1">largest_block_size &lt;= block_size_limit</span>
    <span class="s2">return </span><span class="s1">tuple(chunks)</span><span class="s2">, </span><span class="s1">memory_limit_hit</span>


<span class="s2">def </span><span class="s1">find_split_rechunk(old_chunks</span><span class="s2">, </span><span class="s1">new_chunks</span><span class="s2">, </span><span class="s1">graph_size_limit):</span>
    <span class="s0">&quot;&quot;&quot; 
    Find an intermediate rechunk that would split some chunks to 
    get us nearer *new_chunks*, without violating the *graph_size_limit*. 
    &quot;&quot;&quot;</span>
    <span class="s1">ndim = len(old_chunks)</span>

    <span class="s1">chunks = list(old_chunks)</span>

    <span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">range(ndim):</span>
        <span class="s1">graph_size = estimate_graph_size(chunks</span><span class="s2">, </span><span class="s1">new_chunks)</span>
        <span class="s2">if </span><span class="s1">graph_size &gt; graph_size_limit:</span>
            <span class="s2">break</span>
        <span class="s2">if </span><span class="s1">len(old_chunks[dim]) &gt; len(new_chunks[dim]):</span>
            <span class="s4"># It's not interesting to split</span>
            <span class="s2">continue</span>
        <span class="s4"># Merge the new chunks so as to stay within the graph size budget</span>
        <span class="s1">max_number = int(len(old_chunks[dim]) * graph_size_limit / graph_size)</span>
        <span class="s1">c = merge_to_number(new_chunks[dim]</span><span class="s2">, </span><span class="s1">max_number)</span>
        <span class="s2">assert </span><span class="s1">len(c) &lt;= max_number</span>
        <span class="s4"># Consider the merge successful if its result has a greater length</span>
        <span class="s4"># and smaller max width than the old chunks</span>
        <span class="s2">if </span><span class="s1">len(c) &gt;= len(old_chunks[dim]) </span><span class="s2">and </span><span class="s1">max(c) &lt;= max(old_chunks[dim]):</span>
            <span class="s1">chunks[dim] = c</span>

    <span class="s2">return </span><span class="s1">tuple(chunks)</span>


<span class="s2">def </span><span class="s1">plan_rechunk(</span>
    <span class="s1">old_chunks</span><span class="s2">, </span><span class="s1">new_chunks</span><span class="s2">, </span><span class="s1">itemsize</span><span class="s2">, </span><span class="s1">threshold=</span><span class="s2">None, </span><span class="s1">block_size_limit=</span><span class="s2">None</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Plan an iterative rechunking from *old_chunks* to *new_chunks*. 
    The plan aims to minimize the rechunk graph size. 
 
    Parameters 
    ---------- 
    itemsize: int 
        The item size of the array 
    threshold: int 
        The graph growth factor under which we don't bother 
        introducing an intermediate step 
    block_size_limit: int 
        The maximum block size (in bytes) we want to produce during an 
        intermediate step 
 
    Notes 
    ----- 
    No intermediate steps will be planned if any dimension of ``old_chunks`` 
    is unknown. 
    &quot;&quot;&quot;</span>
    <span class="s1">threshold = threshold </span><span class="s2">or </span><span class="s1">config.get(</span><span class="s5">&quot;array.rechunk.threshold&quot;</span><span class="s1">)</span>
    <span class="s1">block_size_limit = block_size_limit </span><span class="s2">or </span><span class="s1">config.get(</span><span class="s5">&quot;array.chunk-size&quot;</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">isinstance(block_size_limit</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s1">block_size_limit = parse_bytes(block_size_limit)</span>

    <span class="s1">has_nans = (any(math.isnan(y) </span><span class="s2">for </span><span class="s1">y </span><span class="s2">in </span><span class="s1">x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">old_chunks)</span>

    <span class="s2">if </span><span class="s1">len(new_chunks) &lt;= </span><span class="s3">1 </span><span class="s2">or not </span><span class="s1">all(new_chunks) </span><span class="s2">or </span><span class="s1">any(has_nans):</span>
        <span class="s4"># Trivial array / unknown dim =&gt; no need / ability for an intermediate</span>
        <span class="s2">return </span><span class="s1">[new_chunks]</span>

    <span class="s4"># Make it a number of elements</span>
    <span class="s1">block_size_limit /= itemsize</span>

    <span class="s4"># Fix block_size_limit if too small for either old_chunks or new_chunks</span>
    <span class="s1">largest_old_block = _largest_block_size(old_chunks)</span>
    <span class="s1">largest_new_block = _largest_block_size(new_chunks)</span>
    <span class="s1">block_size_limit = max([block_size_limit</span><span class="s2">, </span><span class="s1">largest_old_block</span><span class="s2">, </span><span class="s1">largest_new_block])</span>

    <span class="s4"># The graph size above which to optimize</span>
    <span class="s1">graph_size_threshold = threshold * (</span>
        <span class="s1">_number_of_blocks(old_chunks) + _number_of_blocks(new_chunks)</span>
    <span class="s1">)</span>

    <span class="s1">current_chunks = old_chunks</span>
    <span class="s1">first_pass = </span><span class="s2">True</span>
    <span class="s1">steps = []</span>

    <span class="s2">while True</span><span class="s1">:</span>
        <span class="s1">graph_size = estimate_graph_size(current_chunks</span><span class="s2">, </span><span class="s1">new_chunks)</span>
        <span class="s2">if </span><span class="s1">graph_size &lt; graph_size_threshold:</span>
            <span class="s2">break</span>

        <span class="s2">if </span><span class="s1">first_pass:</span>
            <span class="s1">chunks = current_chunks</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s4"># We hit the block_size_limit in a previous merge pass =&gt;</span>
            <span class="s4"># accept a significant increase in graph size in exchange for</span>
            <span class="s4"># 1) getting nearer the goal 2) reducing the largest block size</span>
            <span class="s4"># to make place for the following merge.</span>
            <span class="s4"># To see this pass in action, make the block_size_limit very small.</span>
            <span class="s1">chunks = find_split_rechunk(</span>
                <span class="s1">current_chunks</span><span class="s2">, </span><span class="s1">new_chunks</span><span class="s2">, </span><span class="s1">graph_size * threshold</span>
            <span class="s1">)</span>
        <span class="s1">chunks</span><span class="s2">, </span><span class="s1">memory_limit_hit = find_merge_rechunk(</span>
            <span class="s1">chunks</span><span class="s2">, </span><span class="s1">new_chunks</span><span class="s2">, </span><span class="s1">block_size_limit</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">(chunks == current_chunks </span><span class="s2">and not </span><span class="s1">first_pass) </span><span class="s2">or </span><span class="s1">chunks == new_chunks:</span>
            <span class="s2">break</span>
        <span class="s2">if </span><span class="s1">chunks != current_chunks:</span>
            <span class="s1">steps.append(chunks)</span>
        <span class="s1">current_chunks = chunks</span>
        <span class="s2">if not </span><span class="s1">memory_limit_hit:</span>
            <span class="s2">break</span>
        <span class="s1">first_pass = </span><span class="s2">False</span>

    <span class="s2">return </span><span class="s1">steps + [new_chunks]</span>


<span class="s2">def </span><span class="s1">_compute_rechunk(x</span><span class="s2">, </span><span class="s1">chunks):</span>
    <span class="s0">&quot;&quot;&quot;Compute the rechunk of *x* to the given *chunks*.&quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">x.size == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s4"># Special case for empty array, as the algorithm below does not behave correctly</span>
        <span class="s2">return </span><span class="s1">empty(x.shape</span><span class="s2">, </span><span class="s1">chunks=chunks</span><span class="s2">, </span><span class="s1">dtype=x.dtype)</span>

    <span class="s1">ndim = x.ndim</span>
    <span class="s1">crossed = intersect_chunks(x.chunks</span><span class="s2">, </span><span class="s1">chunks)</span>
    <span class="s1">x2 = dict()</span>
    <span class="s1">intermediates = dict()</span>
    <span class="s1">token = tokenize(x</span><span class="s2">, </span><span class="s1">chunks)</span>
    <span class="s1">merge_name = </span><span class="s5">&quot;rechunk-merge-&quot; </span><span class="s1">+ token</span>
    <span class="s1">split_name = </span><span class="s5">&quot;rechunk-split-&quot; </span><span class="s1">+ token</span>
    <span class="s1">split_name_suffixes = count()</span>

    <span class="s4"># Pre-allocate old block references, to allow re-use and reduce the</span>
    <span class="s4"># graph's memory footprint a bit.</span>
    <span class="s1">old_blocks = np.empty([len(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">x.chunks]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s5">&quot;O&quot;</span><span class="s1">)</span>
    <span class="s2">for </span><span class="s1">index </span><span class="s2">in </span><span class="s1">np.ndindex(old_blocks.shape):</span>
        <span class="s1">old_blocks[index] = (x.name</span><span class="s2">,</span><span class="s1">) + index</span>

    <span class="s4"># Iterate over all new blocks</span>
    <span class="s1">new_index = product(*(range(len(c)) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">chunks))</span>

    <span class="s2">for </span><span class="s1">new_idx</span><span class="s2">, </span><span class="s1">cross1 </span><span class="s2">in </span><span class="s1">zip(new_index</span><span class="s2">, </span><span class="s1">crossed):</span>
        <span class="s1">key = (merge_name</span><span class="s2">,</span><span class="s1">) + new_idx</span>
        <span class="s1">old_block_indices = [[cr[i][</span><span class="s3">0</span><span class="s1">] </span><span class="s2">for </span><span class="s1">cr </span><span class="s2">in </span><span class="s1">cross1] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(ndim)]</span>
        <span class="s1">subdims1 = [len(set(old_block_indices[i])) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(ndim)]</span>

        <span class="s1">rec_cat_arg = np.empty(subdims1</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s5">&quot;O&quot;</span><span class="s1">)</span>
        <span class="s1">rec_cat_arg_flat = rec_cat_arg.flat</span>

        <span class="s4"># Iterate over the old blocks required to build the new block</span>
        <span class="s2">for </span><span class="s1">rec_cat_index</span><span class="s2">, </span><span class="s1">ind_slices </span><span class="s2">in </span><span class="s1">enumerate(cross1):</span>
            <span class="s1">old_block_index</span><span class="s2">, </span><span class="s1">slices = zip(*ind_slices)</span>
            <span class="s1">name = (split_name</span><span class="s2">, </span><span class="s1">next(split_name_suffixes))</span>
            <span class="s1">old_index = old_blocks[old_block_index][</span><span class="s3">1</span><span class="s1">:]</span>
            <span class="s2">if </span><span class="s1">all(</span>
                <span class="s1">slc.start == </span><span class="s3">0 </span><span class="s2">and </span><span class="s1">slc.stop == x.chunks[i][ind]</span>
                <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">(slc</span><span class="s2">, </span><span class="s1">ind) </span><span class="s2">in </span><span class="s1">enumerate(zip(slices</span><span class="s2">, </span><span class="s1">old_index))</span>
            <span class="s1">):</span>
                <span class="s1">rec_cat_arg_flat[rec_cat_index] = old_blocks[old_block_index]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">intermediates[name] = (getitem</span><span class="s2">, </span><span class="s1">old_blocks[old_block_index]</span><span class="s2">, </span><span class="s1">slices)</span>
                <span class="s1">rec_cat_arg_flat[rec_cat_index] = name</span>

        <span class="s2">assert </span><span class="s1">rec_cat_index == rec_cat_arg.size - </span><span class="s3">1</span>

        <span class="s4"># New block is formed by concatenation of sliced old blocks</span>
        <span class="s2">if </span><span class="s1">all(d == </span><span class="s3">1 </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">rec_cat_arg.shape):</span>
            <span class="s1">x2[key] = rec_cat_arg.flat[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">x2[key] = (concatenate3</span><span class="s2">, </span><span class="s1">rec_cat_arg.tolist())</span>

    <span class="s2">del </span><span class="s1">old_blocks</span><span class="s2">, </span><span class="s1">new_index</span>

    <span class="s1">layer = toolz.merge(x2</span><span class="s2">, </span><span class="s1">intermediates)</span>
    <span class="s1">graph = HighLevelGraph.from_collections(merge_name</span><span class="s2">, </span><span class="s1">layer</span><span class="s2">, </span><span class="s1">dependencies=[x])</span>
    <span class="s2">return </span><span class="s1">Array(graph</span><span class="s2">, </span><span class="s1">merge_name</span><span class="s2">, </span><span class="s1">chunks</span><span class="s2">, </span><span class="s1">meta=x)</span>


<span class="s2">class </span><span class="s1">_PrettyBlocks:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">blocks):</span>
        <span class="s1">self.blocks = blocks</span>

    <span class="s2">def </span><span class="s1">__str__(self):</span>
        <span class="s1">runs = []</span>
        <span class="s1">run = []</span>
        <span class="s1">repeats = </span><span class="s3">0</span>
        <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">self.blocks:</span>
            <span class="s2">if </span><span class="s1">run </span><span class="s2">and </span><span class="s1">run[-</span><span class="s3">1</span><span class="s1">] == c:</span>
                <span class="s2">if </span><span class="s1">repeats == </span><span class="s3">0 </span><span class="s2">and </span><span class="s1">len(run) &gt; </span><span class="s3">1</span><span class="s1">:</span>
                    <span class="s1">runs.append((</span><span class="s2">None, </span><span class="s1">run[:-</span><span class="s3">1</span><span class="s1">]))</span>
                    <span class="s1">run = run[-</span><span class="s3">1</span><span class="s1">:]</span>
                <span class="s1">repeats += </span><span class="s3">1</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">repeats &gt; </span><span class="s3">0</span><span class="s1">:</span>
                    <span class="s2">assert </span><span class="s1">len(run) == </span><span class="s3">1</span>
                    <span class="s1">runs.append((repeats + </span><span class="s3">1</span><span class="s2">, </span><span class="s1">run[-</span><span class="s3">1</span><span class="s1">]))</span>
                    <span class="s1">run = []</span>
                    <span class="s1">repeats = </span><span class="s3">0</span>
                <span class="s1">run.append(c)</span>
        <span class="s2">if </span><span class="s1">run:</span>
            <span class="s2">if </span><span class="s1">repeats == </span><span class="s3">0</span><span class="s1">:</span>
                <span class="s1">runs.append((</span><span class="s2">None, </span><span class="s1">run))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">assert </span><span class="s1">len(run) == </span><span class="s3">1</span>
                <span class="s1">runs.append((repeats + </span><span class="s3">1</span><span class="s2">, </span><span class="s1">run[-</span><span class="s3">1</span><span class="s1">]))</span>

        <span class="s1">parts = []</span>
        <span class="s2">for </span><span class="s1">repeats</span><span class="s2">, </span><span class="s1">run </span><span class="s2">in </span><span class="s1">runs:</span>
            <span class="s2">if </span><span class="s1">repeats </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">parts.append(str(run))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">parts.append(</span><span class="s5">&quot;%d*[%s]&quot; </span><span class="s1">% (repeats</span><span class="s2">, </span><span class="s1">run))</span>
        <span class="s2">return </span><span class="s5">&quot; | &quot;</span><span class="s1">.join(parts)</span>

    <span class="s1">__repr__ = __str__</span>


<span class="s2">def </span><span class="s1">format_blocks(blocks):</span>
    <span class="s0">&quot;&quot;&quot; 
    Pretty-format *blocks*. 
 
    &gt;&gt;&gt; format_blocks((10, 10, 10)) 
    3*[10] 
    &gt;&gt;&gt; format_blocks((2, 3, 4)) 
    [2, 3, 4] 
    &gt;&gt;&gt; format_blocks((10, 10, 5, 6, 2, 2, 2, 7)) 
    2*[10] | [5, 6] | 3*[2] | [7] 
    &quot;&quot;&quot;</span>
    <span class="s2">assert </span><span class="s1">isinstance(blocks</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">and </span><span class="s1">all(</span>
        <span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">int) </span><span class="s2">or </span><span class="s1">math.isnan(x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">blocks</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">_PrettyBlocks(blocks)</span>


<span class="s2">def </span><span class="s1">format_chunks(chunks):</span>
    <span class="s0">&quot;&quot;&quot; 
    &gt;&gt;&gt; format_chunks((10 * (3,), 3 * (10,))) 
    (10*[3], 3*[10]) 
    &quot;&quot;&quot;</span>
    <span class="s2">assert </span><span class="s1">isinstance(chunks</span><span class="s2">, </span><span class="s1">tuple)</span>
    <span class="s2">return </span><span class="s1">tuple(format_blocks(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">chunks)</span>


<span class="s2">def </span><span class="s1">format_plan(plan):</span>
    <span class="s0">&quot;&quot;&quot; 
    &gt;&gt;&gt; format_plan([((10, 10, 10), (15, 15)), ((30,), (10, 10, 10))]) 
    [(3*[10], 2*[15]), ([30], 3*[10])] 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">[format_chunks(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">plan]</span>


<span class="s2">def </span><span class="s1">_get_chunks(n</span><span class="s2">, </span><span class="s1">chunksize):</span>
    <span class="s1">leftover = n % chunksize</span>
    <span class="s1">n_chunks = n // chunksize</span>

    <span class="s1">chunks = [chunksize] * n_chunks</span>
    <span class="s2">if </span><span class="s1">leftover:</span>
        <span class="s1">chunks.append(leftover)</span>
    <span class="s2">return </span><span class="s1">tuple(chunks)</span>


<span class="s2">def </span><span class="s1">_balance_chunksizes(chunks: tuple[int</span><span class="s2">, </span><span class="s1">...]) -&gt; tuple[int</span><span class="s2">, </span><span class="s1">...]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Balance the chunk sizes 
 
    Parameters 
    ---------- 
    chunks : tuple[int, ...] 
        Chunk sizes for Dask array. 
 
    Returns 
    ------- 
    new_chunks : tuple[int, ...] 
        New chunks for Dask array with balanced sizes. 
    &quot;&quot;&quot;</span>
    <span class="s1">median_len = np.median(chunks).astype(int)</span>
    <span class="s1">n_chunks = len(chunks)</span>
    <span class="s1">eps = median_len // </span><span class="s3">2</span>
    <span class="s2">if </span><span class="s1">min(chunks) &lt;= </span><span class="s3">0.5 </span><span class="s1">* max(chunks):</span>
        <span class="s1">n_chunks -= </span><span class="s3">1</span>

    <span class="s1">new_chunks = [</span>
        <span class="s1">_get_chunks(sum(chunks)</span><span class="s2">, </span><span class="s1">chunk_len)</span>
        <span class="s2">for </span><span class="s1">chunk_len </span><span class="s2">in </span><span class="s1">range(median_len - eps</span><span class="s2">, </span><span class="s1">median_len + eps + </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">]</span>
    <span class="s1">possible_chunks = [c </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">new_chunks </span><span class="s2">if </span><span class="s1">len(c) == n_chunks]</span>
    <span class="s2">if not </span><span class="s1">len(possible_chunks):</span>
        <span class="s1">warn(</span>
            <span class="s5">&quot;chunk size balancing not possible with given chunks. &quot;</span>
            <span class="s5">&quot;Try increasing the chunk size.&quot;</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">chunks</span>

    <span class="s1">diffs = [max(c) - min(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">possible_chunks]</span>
    <span class="s1">best_chunk_size = np.argmin(diffs)</span>
    <span class="s2">return </span><span class="s1">possible_chunks[best_chunk_size]</span>
</pre>
</body>
</html>
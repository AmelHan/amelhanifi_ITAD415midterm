<html>
<head>
<title>generic.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
generic.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Define the SeriesGroupBy and DataFrameGroupBy 
classes that hold the groupby interfaces (and some implementations). 
 
These are user facing as the result of the ``df.groupby(...)`` operations, 
which here returns a DataFrameGroupBy object. 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">abc</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">from </span><span class="s1">textwrap </span><span class="s2">import </span><span class="s1">dedent</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">TYPE_CHECKING</span><span class="s2">,</span>
    <span class="s1">Any</span><span class="s2">,</span>
    <span class="s1">Callable</span><span class="s2">,</span>
    <span class="s1">Literal</span><span class="s2">,</span>
    <span class="s1">NamedTuple</span><span class="s2">,</span>
    <span class="s1">TypeVar</span><span class="s2">,</span>
    <span class="s1">Union</span><span class="s2">,</span>
    <span class="s1">cast</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">pandas._libs </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Interval</span><span class="s2">,</span>
    <span class="s1">lib</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.errors </span><span class="s2">import </span><span class="s1">SpecificationError</span>
<span class="s2">from </span><span class="s1">pandas.util._decorators </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Appender</span><span class="s2">,</span>
    <span class="s1">Substitution</span><span class="s2">,</span>
    <span class="s1">doc</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.util._exceptions </span><span class="s2">import </span><span class="s1">find_stack_level</span>

<span class="s2">from </span><span class="s1">pandas.core.dtypes.common </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ensure_int64</span><span class="s2">,</span>
    <span class="s1">is_bool</span><span class="s2">,</span>
    <span class="s1">is_dict_like</span><span class="s2">,</span>
    <span class="s1">is_integer_dtype</span><span class="s2">,</span>
    <span class="s1">is_list_like</span><span class="s2">,</span>
    <span class="s1">is_numeric_dtype</span><span class="s2">,</span>
    <span class="s1">is_scalar</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.dtypes </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">CategoricalDtype</span><span class="s2">,</span>
    <span class="s1">IntervalDtype</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.inference </span><span class="s2">import </span><span class="s1">is_hashable</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.missing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">isna</span><span class="s2">,</span>
    <span class="s1">notna</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.core </span><span class="s2">import </span><span class="s1">algorithms</span>
<span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">GroupByApply</span><span class="s2">,</span>
    <span class="s1">maybe_mangle_lambdas</span><span class="s2">,</span>
    <span class="s1">reconstruct_func</span><span class="s2">,</span>
    <span class="s1">validate_func_kwargs</span><span class="s2">,</span>
    <span class="s1">warn_alias_replacement</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">pandas.core.common </span><span class="s2">as </span><span class="s1">com</span>
<span class="s2">from </span><span class="s1">pandas.core.frame </span><span class="s2">import </span><span class="s1">DataFrame</span>
<span class="s2">from </span><span class="s1">pandas.core.groupby </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">base</span><span class="s2">,</span>
    <span class="s1">ops</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.groupby.groupby </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">GroupBy</span><span class="s2">,</span>
    <span class="s1">GroupByPlot</span><span class="s2">,</span>
    <span class="s1">_agg_template_frame</span><span class="s2">,</span>
    <span class="s1">_agg_template_series</span><span class="s2">,</span>
    <span class="s1">_apply_docs</span><span class="s2">,</span>
    <span class="s1">_transform_template</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.indexes.api </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Index</span><span class="s2">,</span>
    <span class="s1">MultiIndex</span><span class="s2">,</span>
    <span class="s1">all_indexes_same</span><span class="s2">,</span>
    <span class="s1">default_index</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.series </span><span class="s2">import </span><span class="s1">Series</span>
<span class="s2">from </span><span class="s1">pandas.core.util.numba_ </span><span class="s2">import </span><span class="s1">maybe_use_numba</span>

<span class="s2">from </span><span class="s1">pandas.plotting </span><span class="s2">import </span><span class="s1">boxplot_frame_groupby</span>

<span class="s2">if </span><span class="s1">TYPE_CHECKING:</span>
    <span class="s2">from </span><span class="s1">collections.abc </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">Hashable</span><span class="s2">,</span>
        <span class="s1">Mapping</span><span class="s2">,</span>
        <span class="s1">Sequence</span><span class="s2">,</span>
    <span class="s1">)</span>

    <span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">ArrayLike</span><span class="s2">,</span>
        <span class="s1">Axis</span><span class="s2">,</span>
        <span class="s1">AxisInt</span><span class="s2">,</span>
        <span class="s1">CorrelationMethod</span><span class="s2">,</span>
        <span class="s1">FillnaOptions</span><span class="s2">,</span>
        <span class="s1">IndexLabel</span><span class="s2">,</span>
        <span class="s1">Manager</span><span class="s2">,</span>
        <span class="s1">Manager2D</span><span class="s2">,</span>
        <span class="s1">SingleManager</span><span class="s2">,</span>
        <span class="s1">TakeIndexer</span><span class="s2">,</span>
    <span class="s1">)</span>

    <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">Categorical</span>
    <span class="s2">from </span><span class="s1">pandas.core.generic </span><span class="s2">import </span><span class="s1">NDFrame</span>

<span class="s3"># TODO(typing) the return value on this callable should be any *scalar*.</span>
<span class="s1">AggScalar = Union[str</span><span class="s2">, </span><span class="s1">Callable[...</span><span class="s2">, </span><span class="s1">Any]]</span>
<span class="s3"># TODO: validate types on ScalarResult and move to _typing</span>
<span class="s3"># Blocked from using by https://github.com/python/mypy/issues/1484</span>
<span class="s3"># See note at _mangle_lambda_list</span>
<span class="s1">ScalarResult = TypeVar(</span><span class="s4">&quot;ScalarResult&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">NamedAgg(NamedTuple):</span>
    <span class="s0">&quot;&quot;&quot; 
    Helper for column specific aggregation with control over output column names. 
 
    Subclass of typing.NamedTuple. 
 
    Parameters 
    ---------- 
    column : Hashable 
        Column label in the DataFrame to apply aggfunc. 
    aggfunc : function or str 
        Function to apply to the provided column. If string, the name of a built-in 
        pandas function. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; df = pd.DataFrame({&quot;key&quot;: [1, 1, 2], &quot;a&quot;: [-1, 0, 1], 1: [10, 11, 12]}) 
    &gt;&gt;&gt; agg_a = pd.NamedAgg(column=&quot;a&quot;, aggfunc=&quot;min&quot;) 
    &gt;&gt;&gt; agg_1 = pd.NamedAgg(column=1, aggfunc=lambda x: np.mean(x)) 
    &gt;&gt;&gt; df.groupby(&quot;key&quot;).agg(result_a=agg_a, result_1=agg_1) 
         result_a  result_1 
    key 
    1          -1      10.5 
    2           1      12.0 
    &quot;&quot;&quot;</span>

    <span class="s1">column: Hashable</span>
    <span class="s1">aggfunc: AggScalar</span>


<span class="s2">class </span><span class="s1">SeriesGroupBy(GroupBy[Series]):</span>
    <span class="s2">def </span><span class="s1">_wrap_agged_manager(self</span><span class="s2">, </span><span class="s1">mgr: Manager) -&gt; Series:</span>
        <span class="s1">out = self.obj._constructor_from_mgr(mgr</span><span class="s2">, </span><span class="s1">axes=mgr.axes)</span>
        <span class="s1">out._name = self.obj.name</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_get_data_to_aggregate(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">False, </span><span class="s1">name: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span>
    <span class="s1">) -&gt; SingleManager:</span>
        <span class="s1">ser = self._selected_obj</span>
        <span class="s1">single = ser._mgr</span>
        <span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">and not </span><span class="s1">is_numeric_dtype(ser.dtype):</span>
            <span class="s3"># GH#41291 match Series behavior</span>
            <span class="s1">kwd_name = </span><span class="s4">&quot;numeric_only&quot;</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span>
                <span class="s4">f&quot;Cannot use </span><span class="s2">{</span><span class="s1">kwd_name</span><span class="s2">}</span><span class="s4">=True with &quot;</span>
                <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">type(self).__name__</span><span class="s2">}</span><span class="s4">.</span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s4">and non-numeric dtypes.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">single</span>

    <span class="s1">_agg_examples_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    Examples 
    -------- 
    &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4]) 
 
    &gt;&gt;&gt; s 
    0    1 
    1    2 
    2    3 
    3    4 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).min() 
    1    1 
    2    3 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg('min') 
    1    1 
    2    3 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg(['min', 'max']) 
       min  max 
    1    1    2 
    2    3    4 
 
    The output column names can be controlled by passing 
    the desired column names and aggregations as keyword arguments. 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg( 
    ...     minimum='min', 
    ...     maximum='max', 
    ... ) 
       minimum  maximum 
    1        1        2 
    2        3        4 
 
    .. versionchanged:: 1.3.0 
 
        The resulting dtype will reflect the return value of the aggregating function. 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min()) 
    1    1.0 
    2    3.0 
    dtype: float64 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@Appender(</span>
        <span class="s1">_apply_docs[</span><span class="s4">&quot;template&quot;</span><span class="s1">].format(</span>
            <span class="s1">input=</span><span class="s4">&quot;series&quot;</span><span class="s2">, </span><span class="s1">examples=_apply_docs[</span><span class="s4">&quot;series_examples&quot;</span><span class="s1">]</span>
        <span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">apply(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; Series:</span>
        <span class="s2">return </span><span class="s1">super().apply(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s1">@doc(_agg_template_series</span><span class="s2">, </span><span class="s1">examples=_agg_examples_doc</span><span class="s2">, </span><span class="s1">klass=</span><span class="s4">&quot;Series&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">aggregate(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s1">relabeling = func </span><span class="s2">is None</span>
        <span class="s1">columns = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">relabeling:</span>
            <span class="s1">columns</span><span class="s2">, </span><span class="s1">func = validate_func_kwargs(kwargs)</span>
            <span class="s1">kwargs = {}</span>

        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s2">if </span><span class="s1">maybe_use_numba(engine) </span><span class="s2">and </span><span class="s1">engine </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s3"># Not all agg functions support numba, only propagate numba kwargs</span>
                <span class="s3"># if user asks for numba, and engine is not None</span>
                <span class="s3"># (if engine is None, the called function will handle the case where</span>
                <span class="s3"># numba is requested via the global option)</span>
                <span class="s1">kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">] = engine</span>
            <span class="s2">if </span><span class="s1">engine_kwargs </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">kwargs[</span><span class="s4">&quot;engine_kwargs&quot;</span><span class="s1">] = engine_kwargs</span>
            <span class="s2">return </span><span class="s1">getattr(self</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">elif </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">abc.Iterable):</span>
            <span class="s3"># Catch instances of lists / tuples</span>
            <span class="s3"># but not the class list / tuple itself.</span>
            <span class="s1">func = maybe_mangle_lambdas(func)</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">] = engine</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;engine_kwargs&quot;</span><span class="s1">] = engine_kwargs</span>
            <span class="s1">ret = self._aggregate_multiple_funcs(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s2">if </span><span class="s1">relabeling:</span>
                <span class="s3"># columns is not narrowed by mypy from relabeling flag</span>
                <span class="s2">assert </span><span class="s1">columns </span><span class="s2">is not None  </span><span class="s3"># for mypy</span>
                <span class="s1">ret.columns = columns</span>
            <span class="s2">if not </span><span class="s1">self.as_index:</span>
                <span class="s1">ret = ret.reset_index()</span>
            <span class="s2">return </span><span class="s1">ret</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cyfunc = com.get_cython_func(func)</span>
            <span class="s2">if </span><span class="s1">cyfunc </span><span class="s2">and not </span><span class="s1">args </span><span class="s2">and not </span><span class="s1">kwargs:</span>
                <span class="s1">warn_alias_replacement(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">cyfunc)</span>
                <span class="s2">return </span><span class="s1">getattr(self</span><span class="s2">, </span><span class="s1">cyfunc)()</span>

            <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
                <span class="s2">return </span><span class="s1">self._aggregate_with_numba(</span>
                    <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
                <span class="s1">)</span>

            <span class="s2">if </span><span class="s1">self.ngroups == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s3"># e.g. test_evaluate_with_empty_groups without any groups to</span>
                <span class="s3">#  iterate over, we have no output on which to do dtype</span>
                <span class="s3">#  inference. We default to using the existing dtype.</span>
                <span class="s3">#  xref GH#51445</span>
                <span class="s1">obj = self._obj_with_exclusions</span>
                <span class="s2">return </span><span class="s1">self.obj._constructor(</span>
                    <span class="s1">[]</span><span class="s2">,</span>
                    <span class="s1">name=self.obj.name</span><span class="s2">,</span>
                    <span class="s1">index=self.grouper.result_index</span><span class="s2">,</span>
                    <span class="s1">dtype=obj.dtype</span><span class="s2">,</span>
                <span class="s1">)</span>

            <span class="s2">if </span><span class="s1">self.grouper.nkeys &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s2">except </span><span class="s1">KeyError:</span>
                <span class="s3"># KeyError raised in test_groupby.test_basic is bc the func does</span>
                <span class="s3">#  a dictionary lookup on group.name, but group name is not</span>
                <span class="s3">#  pinned in _python_agg_general, only in _aggregate_named</span>
                <span class="s1">result = self._aggregate_named(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

                <span class="s1">warnings.warn(</span>
                    <span class="s4">&quot;Pinning the groupby key to each group in &quot;</span>
                    <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">type(self).__name__</span><span class="s2">}</span><span class="s4">.agg is deprecated, and cases that &quot;</span>
                    <span class="s4">&quot;relied on it will raise in a future version. &quot;</span>
                    <span class="s4">&quot;If your operation requires utilizing the groupby keys, &quot;</span>
                    <span class="s4">&quot;iterate over the groupby object instead.&quot;</span><span class="s2">,</span>
                    <span class="s1">FutureWarning</span><span class="s2">,</span>
                    <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
                <span class="s1">)</span>

                <span class="s3"># result is a dict whose keys are the elements of result_index</span>
                <span class="s1">result = Series(result</span><span class="s2">, </span><span class="s1">index=self.grouper.result_index)</span>
                <span class="s1">result = self._wrap_aggregated_output(result)</span>
                <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">agg = aggregate</span>

    <span class="s2">def </span><span class="s1">_python_agg_general(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">orig_func = func</span>
        <span class="s1">func = com.is_builtin_func(func)</span>
        <span class="s2">if </span><span class="s1">orig_func != func:</span>
            <span class="s1">alias = com._builtin_table_alias[func]</span>
            <span class="s1">warn_alias_replacement(self</span><span class="s2">, </span><span class="s1">orig_func</span><span class="s2">, </span><span class="s1">alias)</span>
        <span class="s1">f = </span><span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">result = self.grouper.agg_series(obj</span><span class="s2">, </span><span class="s1">f)</span>
        <span class="s1">res = obj._constructor(result</span><span class="s2">, </span><span class="s1">name=obj.name)</span>
        <span class="s2">return </span><span class="s1">self._wrap_aggregated_output(res)</span>

    <span class="s2">def </span><span class="s1">_aggregate_multiple_funcs(self</span><span class="s2">, </span><span class="s1">arg</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s2">if </span><span class="s1">isinstance(arg</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s2">if </span><span class="s1">self.as_index:</span>
                <span class="s3"># GH 15931</span>
                <span class="s2">raise </span><span class="s1">SpecificationError(</span><span class="s4">&quot;nested renamer is not supported&quot;</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># GH#50684 - This accidentally worked in 1.x</span>
                <span class="s1">msg = (</span>
                    <span class="s4">&quot;Passing a dictionary to SeriesGroupBy.agg is deprecated &quot;</span>
                    <span class="s4">&quot;and will raise in a future version of pandas. Pass a list &quot;</span>
                    <span class="s4">&quot;of aggregations instead.&quot;</span>
                <span class="s1">)</span>
                <span class="s1">warnings.warn(</span>
                    <span class="s1">message=msg</span><span class="s2">,</span>
                    <span class="s1">category=FutureWarning</span><span class="s2">,</span>
                    <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
                <span class="s1">)</span>
                <span class="s1">arg = list(arg.items())</span>
        <span class="s2">elif </span><span class="s1">any(isinstance(x</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">arg):</span>
            <span class="s1">arg = [(x</span><span class="s2">, </span><span class="s1">x) </span><span class="s2">if not </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)) </span><span class="s2">else </span><span class="s1">x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">arg]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># list of functions / function names</span>
            <span class="s1">columns = (com.get_callable_name(f) </span><span class="s2">or </span><span class="s1">f </span><span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">arg)</span>
            <span class="s1">arg = zip(columns</span><span class="s2">, </span><span class="s1">arg)</span>

        <span class="s1">results: dict[base.OutputKey</span><span class="s2">, </span><span class="s1">DataFrame | Series] = {}</span>
        <span class="s2">with </span><span class="s1">com.temp_setattr(self</span><span class="s2">, </span><span class="s4">&quot;as_index&quot;</span><span class="s2">, True</span><span class="s1">):</span>
            <span class="s3"># Combine results using the index, need to adjust index after</span>
            <span class="s3"># if as_index=False (GH#50724)</span>
            <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">(name</span><span class="s2">, </span><span class="s1">func) </span><span class="s2">in </span><span class="s1">enumerate(arg):</span>
                <span class="s1">key = base.OutputKey(label=name</span><span class="s2">, </span><span class="s1">position=idx)</span>
                <span class="s1">results[key] = self.aggregate(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">if </span><span class="s1">any(isinstance(x</span><span class="s2">, </span><span class="s1">DataFrame) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">results.values()):</span>
            <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">concat</span>

            <span class="s1">res_df = concat(</span>
                <span class="s1">results.values()</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">keys=[key.label </span><span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">results]</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">res_df</span>

        <span class="s1">indexed_output = {key.position: val </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">results.items()}</span>
        <span class="s1">output = self.obj._constructor_expanddim(indexed_output</span><span class="s2">, </span><span class="s1">index=</span><span class="s2">None</span><span class="s1">)</span>
        <span class="s1">output.columns = Index(key.label </span><span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">results)</span>

        <span class="s2">return </span><span class="s1">output</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">data: Series</span><span class="s2">,</span>
        <span class="s1">values: list[Any]</span><span class="s2">,</span>
        <span class="s1">not_indexed_same: bool = </span><span class="s2">False,</span>
        <span class="s1">is_transform: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrap the output of SeriesGroupBy.apply into the expected result. 
 
        Parameters 
        ---------- 
        data : Series 
            Input data for groupby operation. 
        values : List[Any] 
            Applied output for each group. 
        not_indexed_same : bool, default False 
            Whether the applied outputs are not indexed the same as the group axes. 
 
        Returns 
        ------- 
        DataFrame or Series 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">len(values) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># GH #6265</span>
            <span class="s2">if </span><span class="s1">is_transform:</span>
                <span class="s3"># GH#47787 see test_group_on_empty_multiindex</span>
                <span class="s1">res_index = data.index</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">res_index = self.grouper.result_index</span>

            <span class="s2">return </span><span class="s1">self.obj._constructor(</span>
                <span class="s1">[]</span><span class="s2">,</span>
                <span class="s1">name=self.obj.name</span><span class="s2">,</span>
                <span class="s1">index=res_index</span><span class="s2">,</span>
                <span class="s1">dtype=data.dtype</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">values </span><span class="s2">is not None</span>

        <span class="s2">if </span><span class="s1">isinstance(values[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s3"># GH #823 #24880</span>
            <span class="s1">index = self.grouper.result_index</span>
            <span class="s1">res_df = self.obj._constructor_expanddim(values</span><span class="s2">, </span><span class="s1">index=index)</span>
            <span class="s1">res_df = self._reindex_output(res_df)</span>
            <span class="s3"># if self.observed is False,</span>
            <span class="s3"># keep all-NaN rows created while re-indexing</span>
            <span class="s1">res_ser = res_df.stack(future_stack=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">res_ser.name = self.obj.name</span>
            <span class="s2">return </span><span class="s1">res_ser</span>
        <span class="s2">elif </span><span class="s1">isinstance(values[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">DataFrame)):</span>
            <span class="s1">result = self._concat_objects(</span>
                <span class="s1">values</span><span class="s2">,</span>
                <span class="s1">not_indexed_same=not_indexed_same</span><span class="s2">,</span>
                <span class="s1">is_transform=is_transform</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">isinstance(result</span><span class="s2">, </span><span class="s1">Series):</span>
                <span class="s1">result.name = self.obj.name</span>
            <span class="s2">if not </span><span class="s1">self.as_index </span><span class="s2">and </span><span class="s1">not_indexed_same:</span>
                <span class="s1">result = self._insert_inaxis_grouper(result)</span>
                <span class="s1">result.index = default_index(len(result))</span>
            <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># GH #6265 #24880</span>
            <span class="s1">result = self.obj._constructor(</span>
                <span class="s1">data=values</span><span class="s2">, </span><span class="s1">index=self.grouper.result_index</span><span class="s2">, </span><span class="s1">name=self.obj.name</span>
            <span class="s1">)</span>
            <span class="s2">if not </span><span class="s1">self.as_index:</span>
                <span class="s1">result = self._insert_inaxis_grouper(result)</span>
                <span class="s1">result.index = default_index(len(result))</span>
            <span class="s2">return </span><span class="s1">self._reindex_output(result)</span>

    <span class="s2">def </span><span class="s1">_aggregate_named(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s3"># Note: this is very similar to _aggregate_series_pure_python,</span>
        <span class="s3">#  but that does not pin group.name</span>
        <span class="s1">result = {}</span>
        <span class="s1">initialized = </span><span class="s2">False</span>

        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self.grouper.get_iterator(</span>
            <span class="s1">self._selected_obj</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
        <span class="s1">):</span>
            <span class="s3"># needed for pandas/tests/groupby/test_groupby.py::test_basic_aggregations</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>

            <span class="s1">output = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">output = ops.extract_result(output)</span>
            <span class="s2">if not </span><span class="s1">initialized:</span>
                <span class="s3"># We only do this validation on the first iteration</span>
                <span class="s1">ops.check_result_array(output</span><span class="s2">, </span><span class="s1">group.dtype)</span>
                <span class="s1">initialized = </span><span class="s2">True</span>
            <span class="s1">result[name] = output</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">__examples_series_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    &gt;&gt;&gt; ser = pd.Series( 
    ...    [390.0, 350.0, 30.0, 20.0], 
    ...    index=[&quot;Falcon&quot;, &quot;Falcon&quot;, &quot;Parrot&quot;, &quot;Parrot&quot;], 
    ...    name=&quot;Max Speed&quot;) 
    &gt;&gt;&gt; grouped = ser.groupby([1, 1, 2, 2]) 
    &gt;&gt;&gt; grouped.transform(lambda x: (x - x.mean()) / x.std()) 
        Falcon    0.707107 
        Falcon   -0.707107 
        Parrot    0.707107 
        Parrot   -0.707107 
        Name: Max Speed, dtype: float64 
 
    Broadcast result of the transformation 
 
    &gt;&gt;&gt; grouped.transform(lambda x: x.max() - x.min()) 
    Falcon    40.0 
    Falcon    40.0 
    Parrot    10.0 
    Parrot    10.0 
    Name: Max Speed, dtype: float64 
 
    &gt;&gt;&gt; grouped.transform(&quot;mean&quot;) 
    Falcon    370.0 
    Falcon    370.0 
    Parrot     25.0 
    Parrot     25.0 
    Name: Max Speed, dtype: float64 
 
    .. versionchanged:: 1.3.0 
 
    The resulting dtype will reflect the return value of the passed ``func``, 
    for example: 
 
    &gt;&gt;&gt; grouped.transform(lambda x: x.astype(int).max()) 
    Falcon    390 
    Falcon    390 
    Parrot     30 
    Parrot     30 
    Name: Max Speed, dtype: int64 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@Substitution(klass=</span><span class="s4">&quot;Series&quot;</span><span class="s2">, </span><span class="s1">example=__examples_series_doc)</span>
    <span class="s1">@Appender(_transform_template)</span>
    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">self._transform(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=engine</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cython_transform(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">how: str</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">False, </span><span class="s1">axis: AxisInt = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">):</span>
        <span class="s2">assert </span><span class="s1">axis == </span><span class="s5">0  </span><span class="s3"># handled by caller</span>

        <span class="s1">obj = self._selected_obj</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">result = self.grouper._cython_operation(</span>
                <span class="s4">&quot;transform&quot;</span><span class="s2">, </span><span class="s1">obj._values</span><span class="s2">, </span><span class="s1">how</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
        <span class="s2">except </span><span class="s1">NotImplementedError </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s3"># e.g. test_groupby_raises_string</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">how</span><span class="s2">} </span><span class="s4">is not supported for </span><span class="s2">{</span><span class="s1">obj.dtype</span><span class="s2">} </span><span class="s4">dtype&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

        <span class="s2">return </span><span class="s1">obj._constructor(result</span><span class="s2">, </span><span class="s1">index=self.obj.index</span><span class="s2">, </span><span class="s1">name=obj.name)</span>

    <span class="s2">def </span><span class="s1">_transform_general(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">func: Callable</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">engine_kwargs</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform with a callable `func`. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
            <span class="s2">return </span><span class="s1">self._transform_with_numba(</span>
                <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">callable(func)</span>
        <span class="s1">klass = type(self.obj)</span>

        <span class="s1">results = []</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self.grouper.get_iterator(</span>
            <span class="s1">self._selected_obj</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
        <span class="s1">):</span>
            <span class="s3"># this setattr is needed for test_transform_lambda_with_datetimetz</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s1">res = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s1">results.append(klass(res</span><span class="s2">, </span><span class="s1">index=group.index))</span>

        <span class="s3"># check for empty &quot;results&quot; to avoid concat ValueError</span>
        <span class="s2">if </span><span class="s1">results:</span>
            <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

            <span class="s1">concatenated = concat(results)</span>
            <span class="s1">result = self._set_result_index_ordered(concatenated)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self.obj._constructor(dtype=np.float64)</span>

        <span class="s1">result.name = self.obj.name</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">filter(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Filter elements from groups that don't satisfy a criterion. 
 
        Elements from groups are filtered if they do not satisfy the 
        boolean criterion specified by func. 
 
        Parameters 
        ---------- 
        func : function 
            Criterion to apply to each group. Should return True or False. 
        dropna : bool 
            Drop groups that do not pass the filter. True by default; if False, 
            groups that evaluate False are filled with NaNs. 
 
        Returns 
        ------- 
        Series 
 
        Notes 
        ----- 
        Functions that mutate the passed object can produce unexpected 
        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation` 
        for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 
        ...                           'foo', 'bar'], 
        ...                    'B' : [1, 2, 3, 4, 5, 6], 
        ...                    'C' : [2.0, 5., 8., 1., 2., 9.]}) 
        &gt;&gt;&gt; grouped = df.groupby('A') 
        &gt;&gt;&gt; df.groupby('A').B.filter(lambda x: x.mean() &gt; 3.) 
        1    2 
        3    4 
        5    6 
        Name: B, dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">wrapper = </span><span class="s2">lambda </span><span class="s1">x: getattr(x</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">wrapper = </span><span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s3"># Interpret np.nan as False.</span>
        <span class="s2">def </span><span class="s1">true_and_notna(x) -&gt; bool:</span>
            <span class="s1">b = wrapper(x)</span>
            <span class="s2">return </span><span class="s1">notna(b) </span><span class="s2">and </span><span class="s1">b</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">indices = [</span>
                <span class="s1">self._get_index(name)</span>
                <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self.grouper.get_iterator(</span>
                    <span class="s1">self._selected_obj</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
                <span class="s1">)</span>
                <span class="s2">if </span><span class="s1">true_and_notna(group)</span>
            <span class="s1">]</span>
        <span class="s2">except </span><span class="s1">(ValueError</span><span class="s2">, </span><span class="s1">TypeError) </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;the filter must return a boolean result&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

        <span class="s1">filtered = self._apply_filter(indices</span><span class="s2">, </span><span class="s1">dropna)</span>
        <span class="s2">return </span><span class="s1">filtered</span>

    <span class="s2">def </span><span class="s1">nunique(self</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Series | DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return number of unique elements in the group. 
 
        Returns 
        ------- 
        Series 
            Number of unique values within each group. 
 
        Examples 
        -------- 
        For SeriesGroupby: 
 
        &gt;&gt;&gt; lst = ['a', 'a', 'b', 'b'] 
        &gt;&gt;&gt; ser = pd.Series([1, 2, 3, 3], index=lst) 
        &gt;&gt;&gt; ser 
        a    1 
        a    2 
        b    3 
        b    3 
        dtype: int64 
        &gt;&gt;&gt; ser.groupby(level=0).nunique() 
        a    2 
        b    1 
        dtype: int64 
 
        For Resampler: 
 
        &gt;&gt;&gt; ser = pd.Series([1, 2, 3, 3], index=pd.DatetimeIndex( 
        ...                 ['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15'])) 
        &gt;&gt;&gt; ser 
        2023-01-01    1 
        2023-01-15    2 
        2023-02-01    3 
        2023-02-15    3 
        dtype: int64 
        &gt;&gt;&gt; ser.resample('MS').nunique() 
        2023-01-01    2 
        2023-02-01    1 
        Freq: MS, dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s1">ids</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = self.grouper.group_info</span>

        <span class="s1">val = self.obj._values</span>

        <span class="s1">codes</span><span class="s2">, </span><span class="s1">_ = algorithms.factorize(val</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">sorter = np.lexsort((codes</span><span class="s2">, </span><span class="s1">ids))</span>
        <span class="s1">codes = codes[sorter]</span>
        <span class="s1">ids = ids[sorter]</span>

        <span class="s3"># group boundaries are where group ids change</span>
        <span class="s3"># unique observations are where sorted values change</span>
        <span class="s1">idx = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">+ np.nonzero(ids[</span><span class="s5">1</span><span class="s1">:] != ids[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">]]</span>
        <span class="s1">inc = np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">codes[</span><span class="s5">1</span><span class="s1">:] != codes[:-</span><span class="s5">1</span><span class="s1">]]</span>

        <span class="s3"># 1st item of each group is a new unique observation</span>
        <span class="s1">mask = codes == -</span><span class="s5">1</span>
        <span class="s2">if </span><span class="s1">dropna:</span>
            <span class="s1">inc[idx] = </span><span class="s5">1</span>
            <span class="s1">inc[mask] = </span><span class="s5">0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">inc[mask &amp; np.r_[</span><span class="s2">False, </span><span class="s1">mask[:-</span><span class="s5">1</span><span class="s1">]]] = </span><span class="s5">0</span>
            <span class="s1">inc[idx] = </span><span class="s5">1</span>

        <span class="s1">out = np.add.reduceat(inc</span><span class="s2">, </span><span class="s1">idx).astype(</span><span class="s4">&quot;int64&quot;</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(ids):</span>
            <span class="s3"># NaN/NaT group exists if the head of ids is -1,</span>
            <span class="s3"># so remove it from res and exclude its index from idx</span>
            <span class="s2">if </span><span class="s1">ids[</span><span class="s5">0</span><span class="s1">] == -</span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">res = out[</span><span class="s5">1</span><span class="s1">:]</span>
                <span class="s1">idx = idx[np.flatnonzero(idx)]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">res = out</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res = out[</span><span class="s5">1</span><span class="s1">:]</span>
        <span class="s1">ri = self.grouper.result_index</span>

        <span class="s3"># we might have duplications among the bins</span>
        <span class="s2">if </span><span class="s1">len(res) != len(ri):</span>
            <span class="s1">res</span><span class="s2">, </span><span class="s1">out = np.zeros(len(ri)</span><span class="s2">, </span><span class="s1">dtype=out.dtype)</span><span class="s2">, </span><span class="s1">res</span>
            <span class="s2">if </span><span class="s1">len(ids) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s3"># GH#21334s</span>
                <span class="s1">res[ids[idx]] = out</span>

        <span class="s1">result: Series | DataFrame = self.obj._constructor(</span>
            <span class="s1">res</span><span class="s2">, </span><span class="s1">index=ri</span><span class="s2">, </span><span class="s1">name=self.obj.name</span>
        <span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">result = self._insert_inaxis_grouper(result)</span>
            <span class="s1">result.index = default_index(len(result))</span>
        <span class="s2">return </span><span class="s1">self._reindex_output(result</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s1">@doc(Series.describe)</span>
    <span class="s2">def </span><span class="s1">describe(self</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">super().describe(**kwargs)</span>

    <span class="s2">def </span><span class="s1">value_counts(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">ascending: bool = </span><span class="s2">False,</span>
        <span class="s1">bins=</span><span class="s2">None,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; Series | DataFrame:</span>
        <span class="s1">name = </span><span class="s4">&quot;proportion&quot; </span><span class="s2">if </span><span class="s1">normalize </span><span class="s2">else </span><span class="s4">&quot;count&quot;</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">result = self._value_counts(</span>
                <span class="s1">normalize=normalize</span><span class="s2">, </span><span class="s1">sort=sort</span><span class="s2">, </span><span class="s1">ascending=ascending</span><span class="s2">, </span><span class="s1">dropna=dropna</span>
            <span class="s1">)</span>
            <span class="s1">result.name = name</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">from </span><span class="s1">pandas.core.reshape.merge </span><span class="s2">import </span><span class="s1">get_join_indexers</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.tile </span><span class="s2">import </span><span class="s1">cut</span>

        <span class="s1">ids</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = self.grouper.group_info</span>
        <span class="s1">val = self.obj._values</span>

        <span class="s1">index_names = self.grouper.names + [self.obj.name]</span>

        <span class="s2">if </span><span class="s1">isinstance(val.dtype</span><span class="s2">, </span><span class="s1">CategoricalDtype) </span><span class="s2">or </span><span class="s1">(</span>
            <span class="s1">bins </span><span class="s2">is not None and not </span><span class="s1">np.iterable(bins)</span>
        <span class="s1">):</span>
            <span class="s3"># scalar bins cannot be done at top level</span>
            <span class="s3"># in a backward compatible way</span>
            <span class="s3"># GH38672 relates to categorical dtype</span>
            <span class="s1">ser = self.apply(</span>
                <span class="s1">Series.value_counts</span><span class="s2">,</span>
                <span class="s1">normalize=normalize</span><span class="s2">,</span>
                <span class="s1">sort=sort</span><span class="s2">,</span>
                <span class="s1">ascending=ascending</span><span class="s2">,</span>
                <span class="s1">bins=bins</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">ser.name = name</span>
            <span class="s1">ser.index.names = index_names</span>
            <span class="s2">return </span><span class="s1">ser</span>

        <span class="s3"># groupby removes null keys from groupings</span>
        <span class="s1">mask = ids != -</span><span class="s5">1</span>
        <span class="s1">ids</span><span class="s2">, </span><span class="s1">val = ids[mask]</span><span class="s2">, </span><span class="s1">val[mask]</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lab</span><span class="s2">, </span><span class="s1">lev = algorithms.factorize(val</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">llab = </span><span class="s2">lambda </span><span class="s1">lab</span><span class="s2">, </span><span class="s1">inc: lab[inc]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># lab is a Categorical with categories an IntervalIndex</span>
            <span class="s1">cat_ser = cut(Series(val</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span><span class="s2">, </span><span class="s1">bins</span><span class="s2">, </span><span class="s1">include_lowest=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">cat_obj = cast(</span><span class="s4">&quot;Categorical&quot;</span><span class="s2">, </span><span class="s1">cat_ser._values)</span>
            <span class="s1">lev = cat_obj.categories</span>
            <span class="s1">lab = lev.take(</span>
                <span class="s1">cat_obj.codes</span><span class="s2">,</span>
                <span class="s1">allow_fill=</span><span class="s2">True,</span>
                <span class="s1">fill_value=lev._na_value</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">llab = </span><span class="s2">lambda </span><span class="s1">lab</span><span class="s2">, </span><span class="s1">inc: lab[inc]._multiindex.codes[-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">isinstance(lab.dtype</span><span class="s2">, </span><span class="s1">IntervalDtype):</span>
            <span class="s3"># TODO: should we do this inside II?</span>
            <span class="s1">lab_interval = cast(Interval</span><span class="s2">, </span><span class="s1">lab)</span>

            <span class="s1">sorter = np.lexsort((lab_interval.left</span><span class="s2">, </span><span class="s1">lab_interval.right</span><span class="s2">, </span><span class="s1">ids))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sorter = np.lexsort((lab</span><span class="s2">, </span><span class="s1">ids))</span>

        <span class="s1">ids</span><span class="s2">, </span><span class="s1">lab = ids[sorter]</span><span class="s2">, </span><span class="s1">lab[sorter]</span>

        <span class="s3"># group boundaries are where group ids change</span>
        <span class="s1">idchanges = </span><span class="s5">1 </span><span class="s1">+ np.nonzero(ids[</span><span class="s5">1</span><span class="s1">:] != ids[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">idx = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">idchanges]</span>
        <span class="s2">if not </span><span class="s1">len(ids):</span>
            <span class="s1">idx = idchanges</span>

        <span class="s3"># new values are where sorted labels change</span>
        <span class="s1">lchanges = llab(lab</span><span class="s2">, </span><span class="s1">slice(</span><span class="s5">1</span><span class="s2">, None</span><span class="s1">)) != llab(lab</span><span class="s2">, </span><span class="s1">slice(</span><span class="s2">None, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">inc = np.r_[</span><span class="s2">True, </span><span class="s1">lchanges]</span>
        <span class="s2">if not </span><span class="s1">len(val):</span>
            <span class="s1">inc = lchanges</span>
        <span class="s1">inc[idx] = </span><span class="s2">True  </span><span class="s3"># group boundaries are also new values</span>
        <span class="s1">out = np.diff(np.nonzero(np.r_[inc</span><span class="s2">, True</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">])  </span><span class="s3"># value counts</span>

        <span class="s3"># num. of times each group should be repeated</span>
        <span class="s1">rep = partial(np.repeat</span><span class="s2">, </span><span class="s1">repeats=np.add.reduceat(inc</span><span class="s2">, </span><span class="s1">idx))</span>

        <span class="s3"># multi-index components</span>
        <span class="s1">codes = self.grouper.reconstructed_codes</span>
        <span class="s1">codes = [rep(level_codes) </span><span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes] + [llab(lab</span><span class="s2">, </span><span class="s1">inc)]</span>
        <span class="s1">levels = [ping.group_index </span><span class="s2">for </span><span class="s1">ping </span><span class="s2">in </span><span class="s1">self.grouper.groupings] + [lev]</span>

        <span class="s2">if </span><span class="s1">dropna:</span>
            <span class="s1">mask = codes[-</span><span class="s5">1</span><span class="s1">] != -</span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">mask.all():</span>
                <span class="s1">dropna = </span><span class="s2">False</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">out</span><span class="s2">, </span><span class="s1">codes = out[mask]</span><span class="s2">, </span><span class="s1">[level_codes[mask] </span><span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes]</span>

        <span class="s2">if </span><span class="s1">normalize:</span>
            <span class="s1">out = out.astype(</span><span class="s4">&quot;float&quot;</span><span class="s1">)</span>
            <span class="s1">d = np.diff(np.r_[idx</span><span class="s2">, </span><span class="s1">len(ids)])</span>
            <span class="s2">if </span><span class="s1">dropna:</span>
                <span class="s1">m = ids[lab == -</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">np.add.at(d</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">acc = rep(d)[mask]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">acc = rep(d)</span>
            <span class="s1">out /= acc</span>

        <span class="s2">if </span><span class="s1">sort </span><span class="s2">and </span><span class="s1">bins </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cat = ids[inc][mask] </span><span class="s2">if </span><span class="s1">dropna </span><span class="s2">else </span><span class="s1">ids[inc]</span>
            <span class="s1">sorter = np.lexsort((out </span><span class="s2">if </span><span class="s1">ascending </span><span class="s2">else </span><span class="s1">-out</span><span class="s2">, </span><span class="s1">cat))</span>
            <span class="s1">out</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">] = out[sorter]</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">][sorter]</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># for compat. with libgroupby.value_counts need to ensure every</span>
            <span class="s3"># bin is present at every index level, null filled with zeros</span>
            <span class="s1">diff = np.zeros(len(out)</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;bool&quot;</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes[:-</span><span class="s5">1</span><span class="s1">]:</span>
                <span class="s1">diff |= np.r_[</span><span class="s2">True, </span><span class="s1">level_codes[</span><span class="s5">1</span><span class="s1">:] != level_codes[:-</span><span class="s5">1</span><span class="s1">]]</span>

            <span class="s1">ncat</span><span class="s2">, </span><span class="s1">nbin = diff.sum()</span><span class="s2">, </span><span class="s1">len(levels[-</span><span class="s5">1</span><span class="s1">])</span>

            <span class="s1">left = [np.repeat(np.arange(ncat)</span><span class="s2">, </span><span class="s1">nbin)</span><span class="s2">, </span><span class="s1">np.tile(np.arange(nbin)</span><span class="s2">, </span><span class="s1">ncat)]</span>

            <span class="s1">right = [diff.cumsum() - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">]]</span>

            <span class="s3"># error: Argument 1 to &quot;get_join_indexers&quot; has incompatible type</span>
            <span class="s3"># &quot;List[ndarray[Any, Any]]&quot;; expected &quot;List[Union[Union[ExtensionArray,</span>
            <span class="s3"># ndarray[Any, Any]], Index, Series]]</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">idx = get_join_indexers(</span>
                <span class="s1">left</span><span class="s2">, </span><span class="s1">right</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">False, </span><span class="s1">how=</span><span class="s4">&quot;left&quot;  </span><span class="s3"># type: ignore[arg-type]</span>
            <span class="s1">)</span>
            <span class="s1">out = np.where(idx != -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">out[idx]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">sort:</span>
                <span class="s1">sorter = np.lexsort((out </span><span class="s2">if </span><span class="s1">ascending </span><span class="s2">else </span><span class="s1">-out</span><span class="s2">, </span><span class="s1">left[</span><span class="s5">0</span><span class="s1">]))</span>
                <span class="s1">out</span><span class="s2">, </span><span class="s1">left[-</span><span class="s5">1</span><span class="s1">] = out[sorter]</span><span class="s2">, </span><span class="s1">left[-</span><span class="s5">1</span><span class="s1">][sorter]</span>

            <span class="s3"># build the multi-index w/ full levels</span>
            <span class="s2">def </span><span class="s1">build_codes(lev_codes: np.ndarray) -&gt; np.ndarray:</span>
                <span class="s2">return </span><span class="s1">np.repeat(lev_codes[diff]</span><span class="s2">, </span><span class="s1">nbin)</span>

            <span class="s1">codes = [build_codes(lev_codes) </span><span class="s2">for </span><span class="s1">lev_codes </span><span class="s2">in </span><span class="s1">codes[:-</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s1">codes.append(left[-</span><span class="s5">1</span><span class="s1">])</span>

        <span class="s1">mi = MultiIndex(</span>
            <span class="s1">levels=levels</span><span class="s2">, </span><span class="s1">codes=codes</span><span class="s2">, </span><span class="s1">names=index_names</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">False</span>
        <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">is_integer_dtype(out.dtype):</span>
            <span class="s1">out = ensure_int64(out)</span>
        <span class="s1">result = self.obj._constructor(out</span><span class="s2">, </span><span class="s1">index=mi</span><span class="s2">, </span><span class="s1">name=name)</span>
        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">result = result.reset_index()</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value: object | ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">downcast: dict | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
    <span class="s1">) -&gt; Series | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Fill NA/NaN values using the specified method within groups. 
 
        Parameters 
        ---------- 
        value : scalar, dict, Series, or DataFrame 
            Value to use to fill holes (e.g. 0), alternately a 
            dict/Series/DataFrame of values specifying which value to use for 
            each index (for a Series) or column (for a DataFrame).  Values not 
            in the dict/Series/DataFrame will not be filled. This value cannot 
            be a list. Users wanting to use the ``value`` argument and not ``method`` 
            should prefer :meth:`.Series.fillna` as this 
            will produce the same result and be more performant. 
        method : {{'bfill', 'ffill', None}}, default None 
            Method to use for filling holes. ``'ffill'`` will propagate 
            the last valid observation forward within a group. 
            ``'bfill'`` will use next valid observation to fill the gap. 
 
            .. deprecated:: 2.1.0 
                Use obj.ffill or obj.bfill instead. 
 
        axis : {0 or 'index', 1 or 'columns'} 
            Unused, only for compatibility with :meth:`DataFrameGroupBy.fillna`. 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        inplace : bool, default False 
            Broken. Do not set to True. 
        limit : int, default None 
            If method is specified, this is the maximum number of consecutive 
            NaN values to forward/backward fill within a group. In other words, 
            if there is a gap with more than this number of consecutive NaNs, 
            it will only be partially filled. If method is not specified, this is the 
            maximum number of entries along the entire axis where NaNs will be 
            filled. Must be greater than 0 if not None. 
        downcast : dict, default is None 
            A dict of item-&gt;dtype of what to downcast if possible, 
            or the string 'infer' which will try to downcast to an appropriate 
            equal type (e.g. float64 to int64 if possible). 
 
            .. deprecated:: 2.1.0 
 
        Returns 
        ------- 
        Series 
            Object with missing values filled within groups. 
 
        See Also 
        -------- 
        ffill : Forward fill values within a group. 
        bfill : Backward fill values within a group. 
 
        Examples 
        -------- 
        For SeriesGroupBy: 
 
        &gt;&gt;&gt; lst = ['cat', 'cat', 'cat', 'mouse', 'mouse'] 
        &gt;&gt;&gt; ser = pd.Series([1, None, None, 2, None], index=lst) 
        &gt;&gt;&gt; ser 
        cat    1.0 
        cat    NaN 
        cat    NaN 
        mouse  2.0 
        mouse  NaN 
        dtype: float64 
        &gt;&gt;&gt; ser.groupby(level=0).fillna(0, limit=1) 
        cat    1.0 
        cat    0.0 
        cat    NaN 
        mouse  2.0 
        mouse  0.0 
        dtype: float64 
        &quot;&quot;&quot;</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;fillna&quot;</span><span class="s2">,</span>
            <span class="s1">value=value</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">limit=limit</span><span class="s2">,</span>
            <span class="s1">downcast=downcast</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">take(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">indices: TakeIndexer</span><span class="s2">,</span>
        <span class="s1">axis: Axis | lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the elements in the given *positional* indices in each group. 
 
        This means that we are not indexing according to actual values in 
        the index attribute of the object. We are indexing according to the 
        actual position of the element in the object. 
 
        If a requested index does not exist for some group, this method will raise. 
        To get similar behavior that ignores indices that don't exist, see 
        :meth:`.SeriesGroupBy.nth`. 
 
        Parameters 
        ---------- 
        indices : array-like 
            An array of ints indicating which positions to take in each group. 
        axis : {0 or 'index', 1 or 'columns', None}, default 0 
            The axis on which to select elements. ``0`` means that we are 
            selecting rows, ``1`` means that we are selecting columns. 
            For `SeriesGroupBy` this parameter is unused and defaults to 0. 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        **kwargs 
            For compatibility with :meth:`numpy.take`. Has no effect on the 
            output. 
 
        Returns 
        ------- 
        Series 
            A Series containing the elements taken from each group. 
 
        See Also 
        -------- 
        Series.take : Take elements from a Series along an axis. 
        Series.loc : Select a subset of a DataFrame by labels. 
        Series.iloc : Select a subset of a DataFrame by positions. 
        numpy.take : Take elements from an array along an axis. 
        SeriesGroupBy.nth : Similar to take, won't raise if indices don't exist. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('falcon', 'bird', 389.0), 
        ...                    ('parrot', 'bird', 24.0), 
        ...                    ('lion', 'mammal', 80.5), 
        ...                    ('monkey', 'mammal', np.nan), 
        ...                    ('rabbit', 'mammal', 15.0)], 
        ...                   columns=['name', 'class', 'max_speed'], 
        ...                   index=[4, 3, 2, 1, 0]) 
        &gt;&gt;&gt; df 
             name   class  max_speed 
        4  falcon    bird      389.0 
        3  parrot    bird       24.0 
        2    lion  mammal       80.5 
        1  monkey  mammal        NaN 
        0  rabbit  mammal       15.0 
        &gt;&gt;&gt; gb = df[&quot;name&quot;].groupby([1, 1, 2, 2, 2]) 
 
        Take elements at positions 0 and 1 along the axis 0 in each group (default). 
 
        &gt;&gt;&gt; gb.take([0, 1]) 
        1  4    falcon 
           3    parrot 
        2  2      lion 
           1    monkey 
        Name: name, dtype: object 
 
        We may take elements using negative integers for positive indices, 
        starting from the end of the object, just like with Python lists. 
 
        &gt;&gt;&gt; gb.take([-1, -2]) 
        1  3    parrot 
           4    falcon 
        2  0    rabbit 
           1    monkey 
        Name: name, dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">result = self._op_via_apply(</span><span class="s4">&quot;take&quot;</span><span class="s2">, </span><span class="s1">indices=indices</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">skew(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis | lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">skipna: bool = </span><span class="s2">True,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return unbiased skew within groups. 
 
        Normalized by N-1. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns', None}, default 0 
            Axis for the function to be applied on. 
            This parameter is only for compatibility with DataFrame and is unused. 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        skipna : bool, default True 
            Exclude NA/null values when computing the result. 
 
        numeric_only : bool, default False 
            Include only float, int, boolean columns. Not implemented for Series. 
 
        **kwargs 
            Additional keyword arguments to be passed to the function. 
 
        Returns 
        ------- 
        Series 
 
        See Also 
        -------- 
        Series.skew : Return unbiased skew over requested axis. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; ser = pd.Series([390., 350., 357., np.nan, 22., 20., 30.], 
        ...                 index=['Falcon', 'Falcon', 'Falcon', 'Falcon', 
        ...                        'Parrot', 'Parrot', 'Parrot'], 
        ...                 name=&quot;Max Speed&quot;) 
        &gt;&gt;&gt; ser 
        Falcon    390.0 
        Falcon    350.0 
        Falcon    357.0 
        Falcon      NaN 
        Parrot     22.0 
        Parrot     20.0 
        Parrot     30.0 
        Name: Max Speed, dtype: float64 
        &gt;&gt;&gt; ser.groupby(level=0).skew() 
        Falcon    1.525174 
        Parrot    1.457863 
        Name: Max Speed, dtype: float64 
        &gt;&gt;&gt; ser.groupby(level=0).skew(skipna=False) 
        Falcon         NaN 
        Parrot    1.457863 
        Name: Max Speed, dtype: float64 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">axis </span><span class="s2">is </span><span class="s1">lib.no_default:</span>
            <span class="s1">axis = </span><span class="s5">0</span>

        <span class="s2">if </span><span class="s1">axis != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">result = self._op_via_apply(</span>
                <span class="s4">&quot;skew&quot;</span><span class="s2">,</span>
                <span class="s1">axis=axis</span><span class="s2">,</span>
                <span class="s1">skipna=skipna</span><span class="s2">,</span>
                <span class="s1">numeric_only=numeric_only</span><span class="s2">,</span>
                <span class="s1">**kwargs</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">def </span><span class="s1">alt(obj):</span>
            <span class="s3"># This should not be reached since the cython path should raise</span>
            <span class="s3">#  TypeError and not NotImplementedError.</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;'skew' is not supported for dtype=</span><span class="s2">{</span><span class="s1">obj.dtype</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._cython_agg_general(</span>
            <span class="s4">&quot;skew&quot;</span><span class="s2">, </span><span class="s1">alt=alt</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s1">@doc(Series.plot.__doc__)</span>
    <span class="s2">def </span><span class="s1">plot(self):</span>
        <span class="s1">result = GroupByPlot(self)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(Series.nlargest.__doc__)</span>
    <span class="s2">def </span><span class="s1">nlargest(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">5</span><span class="s2">, </span><span class="s1">keep: Literal[</span><span class="s4">&quot;first&quot;</span><span class="s2">, </span><span class="s4">&quot;last&quot;</span><span class="s2">, </span><span class="s4">&quot;all&quot;</span><span class="s1">] = </span><span class="s4">&quot;first&quot;</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">f = partial(Series.nlargest</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep)</span>
        <span class="s1">data = self._selected_obj</span>
        <span class="s3"># Don't change behavior if result index happens to be the same, i.e.</span>
        <span class="s3"># already ordered and n &gt;= all group sizes.</span>
        <span class="s1">result = self._python_apply_general(f</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(Series.nsmallest.__doc__)</span>
    <span class="s2">def </span><span class="s1">nsmallest(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">5</span><span class="s2">, </span><span class="s1">keep: Literal[</span><span class="s4">&quot;first&quot;</span><span class="s2">, </span><span class="s4">&quot;last&quot;</span><span class="s2">, </span><span class="s4">&quot;all&quot;</span><span class="s1">] = </span><span class="s4">&quot;first&quot;</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">f = partial(Series.nsmallest</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep)</span>
        <span class="s1">data = self._selected_obj</span>
        <span class="s3"># Don't change behavior if result index happens to be the same, i.e.</span>
        <span class="s3"># already ordered and n &gt;= all group sizes.</span>
        <span class="s1">result = self._python_apply_general(f</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(Series.idxmin.__doc__)</span>
    <span class="s2">def </span><span class="s1">idxmin(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">axis: Axis | lib.NoDefault = lib.no_default</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">result = self._op_via_apply(</span><span class="s4">&quot;idxmin&quot;</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna)</span>
        <span class="s2">return </span><span class="s1">result.astype(self.obj.index.dtype) </span><span class="s2">if </span><span class="s1">result.empty </span><span class="s2">else </span><span class="s1">result</span>

    <span class="s1">@doc(Series.idxmax.__doc__)</span>
    <span class="s2">def </span><span class="s1">idxmax(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">axis: Axis | lib.NoDefault = lib.no_default</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">result = self._op_via_apply(</span><span class="s4">&quot;idxmax&quot;</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna)</span>
        <span class="s2">return </span><span class="s1">result.astype(self.obj.index.dtype) </span><span class="s2">if </span><span class="s1">result.empty </span><span class="s2">else </span><span class="s1">result</span>

    <span class="s1">@doc(Series.corr.__doc__)</span>
    <span class="s2">def </span><span class="s1">corr(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other: Series</span><span class="s2">,</span>
        <span class="s1">method: CorrelationMethod = </span><span class="s4">&quot;pearson&quot;</span><span class="s2">,</span>
        <span class="s1">min_periods: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;corr&quot;</span><span class="s2">, </span><span class="s1">other=other</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">min_periods=min_periods</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(Series.cov.__doc__)</span>
    <span class="s2">def </span><span class="s1">cov(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">other: Series</span><span class="s2">, </span><span class="s1">min_periods: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s5">1</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;cov&quot;</span><span class="s2">, </span><span class="s1">other=other</span><span class="s2">, </span><span class="s1">min_periods=min_periods</span><span class="s2">, </span><span class="s1">ddof=ddof</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">is_monotonic_increasing(self) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return whether each group's values are monotonically increasing. 
 
        Returns 
        ------- 
        Series 
 
        Examples 
        -------- 
        &gt;&gt;&gt; s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot']) 
        &gt;&gt;&gt; s.groupby(level=0).is_monotonic_increasing 
        Falcon    False 
        Parrot     True 
        dtype: bool 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.apply(</span><span class="s2">lambda </span><span class="s1">ser: ser.is_monotonic_increasing)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">is_monotonic_decreasing(self) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return whether each group's values are monotonically decreasing. 
 
        Returns 
        ------- 
        Series 
 
        Examples 
        -------- 
        &gt;&gt;&gt; s = pd.Series([2, 1, 3, 4], index=['Falcon', 'Falcon', 'Parrot', 'Parrot']) 
        &gt;&gt;&gt; s.groupby(level=0).is_monotonic_decreasing 
        Falcon     True 
        Parrot    False 
        dtype: bool 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.apply(</span><span class="s2">lambda </span><span class="s1">ser: ser.is_monotonic_decreasing)</span>

    <span class="s1">@doc(Series.hist.__doc__)</span>
    <span class="s2">def </span><span class="s1">hist(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">by=</span><span class="s2">None,</span>
        <span class="s1">ax=</span><span class="s2">None,</span>
        <span class="s1">grid: bool = </span><span class="s2">True,</span>
        <span class="s1">xlabelsize: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">xrot: float | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ylabelsize: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">yrot: float | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">figsize: tuple[int</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">bins: int | Sequence[int] = </span><span class="s5">10</span><span class="s2">,</span>
        <span class="s1">backend: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">legend: bool = </span><span class="s2">False,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;hist&quot;</span><span class="s2">,</span>
            <span class="s1">by=by</span><span class="s2">,</span>
            <span class="s1">ax=ax</span><span class="s2">,</span>
            <span class="s1">grid=grid</span><span class="s2">,</span>
            <span class="s1">xlabelsize=xlabelsize</span><span class="s2">,</span>
            <span class="s1">xrot=xrot</span><span class="s2">,</span>
            <span class="s1">ylabelsize=ylabelsize</span><span class="s2">,</span>
            <span class="s1">yrot=yrot</span><span class="s2">,</span>
            <span class="s1">figsize=figsize</span><span class="s2">,</span>
            <span class="s1">bins=bins</span><span class="s2">,</span>
            <span class="s1">backend=backend</span><span class="s2">,</span>
            <span class="s1">legend=legend</span><span class="s2">,</span>
            <span class="s1">**kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@property</span>
    <span class="s1">@doc(Series.dtype.__doc__)</span>
    <span class="s2">def </span><span class="s1">dtype(self) -&gt; Series:</span>
        <span class="s2">return </span><span class="s1">self.apply(</span><span class="s2">lambda </span><span class="s1">ser: ser.dtype)</span>

    <span class="s2">def </span><span class="s1">unique(self) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return unique values for each group. 
 
        It returns unique values for each of the grouped values. Returned in 
        order of appearance. Hash table-based unique, therefore does NOT sort. 
 
        Returns 
        ------- 
        Series 
            Unique values for each of the grouped values. 
 
        See Also 
        -------- 
        Series.unique : Return unique values of Series object. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('Chihuahua', 'dog', 6.1), 
        ...                    ('Beagle', 'dog', 15.2), 
        ...                    ('Chihuahua', 'dog', 6.9), 
        ...                    ('Persian', 'cat', 9.2), 
        ...                    ('Chihuahua', 'dog', 7), 
        ...                    ('Persian', 'cat', 8.8)], 
        ...                   columns=['breed', 'animal', 'height_in']) 
        &gt;&gt;&gt; df 
               breed     animal   height_in 
        0  Chihuahua        dog         6.1 
        1     Beagle        dog        15.2 
        2  Chihuahua        dog         6.9 
        3    Persian        cat         9.2 
        4  Chihuahua        dog         7.0 
        5    Persian        cat         8.8 
        &gt;&gt;&gt; ser = df.groupby('animal')['breed'].unique() 
        &gt;&gt;&gt; ser 
        animal 
        cat              [Persian] 
        dog    [Chihuahua, Beagle] 
        Name: breed, dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">result = self._op_via_apply(</span><span class="s4">&quot;unique&quot;</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">class </span><span class="s1">DataFrameGroupBy(GroupBy[DataFrame]):</span>
    <span class="s1">_agg_examples_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    Examples 
    -------- 
    &gt;&gt;&gt; df = pd.DataFrame( 
    ...     { 
    ...         &quot;A&quot;: [1, 1, 2, 2], 
    ...         &quot;B&quot;: [1, 2, 3, 4], 
    ...         &quot;C&quot;: [0.362838, 0.227877, 1.267767, -0.562860], 
    ...     } 
    ... ) 
 
    &gt;&gt;&gt; df 
       A  B         C 
    0  1  1  0.362838 
    1  1  2  0.227877 
    2  2  3  1.267767 
    3  2  4 -0.562860 
 
    The aggregation is for each column. 
 
    &gt;&gt;&gt; df.groupby('A').agg('min') 
       B         C 
    A 
    1  1  0.227877 
    2  3 -0.562860 
 
    Multiple aggregations 
 
    &gt;&gt;&gt; df.groupby('A').agg(['min', 'max']) 
        B             C 
      min max       min       max 
    A 
    1   1   2  0.227877  0.362838 
    2   3   4 -0.562860  1.267767 
 
    Select a column for aggregation 
 
    &gt;&gt;&gt; df.groupby('A').B.agg(['min', 'max']) 
       min  max 
    A 
    1    1    2 
    2    3    4 
 
    User-defined function for aggregation 
 
    &gt;&gt;&gt; df.groupby('A').agg(lambda x: sum(x) + 2) 
        B          C 
    A 
    1   5   2.590715 
    2   9   2.704907 
 
    Different aggregations per column 
 
    &gt;&gt;&gt; df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'}) 
        B             C 
      min max       sum 
    A 
    1   1   2  0.590715 
    2   3   4  0.704907 
 
    To control the output names with different aggregations per column, 
    pandas supports &quot;named aggregation&quot; 
 
    &gt;&gt;&gt; df.groupby(&quot;A&quot;).agg( 
    ...     b_min=pd.NamedAgg(column=&quot;B&quot;, aggfunc=&quot;min&quot;), 
    ...     c_sum=pd.NamedAgg(column=&quot;C&quot;, aggfunc=&quot;sum&quot;)) 
       b_min     c_sum 
    A 
    1      1  0.590715 
    2      3  0.704907 
 
    - The keywords are the *output* column names 
    - The values are tuples whose first element is the column to select 
      and the second element is the aggregation to apply to that column. 
      Pandas provides the ``pandas.NamedAgg`` namedtuple with the fields 
      ``['column', 'aggfunc']`` to make it clearer what the arguments are. 
      As usual, the aggregation can be a callable or a string alias. 
 
    See :ref:`groupby.aggregate.named` for more. 
 
    .. versionchanged:: 1.3.0 
 
        The resulting dtype will reflect the return value of the aggregating function. 
 
    &gt;&gt;&gt; df.groupby(&quot;A&quot;)[[&quot;B&quot;]].agg(lambda x: x.astype(float).min()) 
          B 
    A 
    1   1.0 
    2   3.0 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@doc(_agg_template_frame</span><span class="s2">, </span><span class="s1">examples=_agg_examples_doc</span><span class="s2">, </span><span class="s1">klass=</span><span class="s4">&quot;DataFrame&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">aggregate(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s1">relabeling</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">order = reconstruct_func(func</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">func = maybe_mangle_lambdas(func)</span>

        <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
            <span class="s3"># Not all agg functions support numba, only propagate numba kwargs</span>
            <span class="s3"># if user asks for numba</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">] = engine</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;engine_kwargs&quot;</span><span class="s1">] = engine_kwargs</span>

        <span class="s1">op = GroupByApply(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">args=args</span><span class="s2">, </span><span class="s1">kwargs=kwargs)</span>
        <span class="s1">result = op.agg()</span>
        <span class="s2">if not </span><span class="s1">is_dict_like(func) </span><span class="s2">and </span><span class="s1">result </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># GH #52849</span>
            <span class="s2">if not </span><span class="s1">self.as_index </span><span class="s2">and </span><span class="s1">is_list_like(func):</span>
                <span class="s2">return </span><span class="s1">result.reset_index()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">elif </span><span class="s1">relabeling:</span>
            <span class="s3"># this should be the only (non-raising) case with relabeling</span>
            <span class="s3"># used reordered index of columns</span>
            <span class="s1">result = cast(DataFrame</span><span class="s2">, </span><span class="s1">result)</span>
            <span class="s1">result = result.iloc[:</span><span class="s2">, </span><span class="s1">order]</span>
            <span class="s1">result = cast(DataFrame</span><span class="s2">, </span><span class="s1">result)</span>
            <span class="s3"># error: Incompatible types in assignment (expression has type</span>
            <span class="s3"># &quot;Optional[List[str]]&quot;, variable has type</span>
            <span class="s3"># &quot;Union[Union[Union[ExtensionArray, ndarray[Any, Any]],</span>
            <span class="s3"># Index, Series], Sequence[Any]]&quot;)</span>
            <span class="s1">result.columns = columns  </span><span class="s3"># type: ignore[assignment]</span>

        <span class="s2">if </span><span class="s1">result </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># Remove the kwargs we inserted</span>
            <span class="s3"># (already stored in engine, engine_kwargs arguments)</span>
            <span class="s2">if </span><span class="s4">&quot;engine&quot; </span><span class="s2">in </span><span class="s1">kwargs:</span>
                <span class="s2">del </span><span class="s1">kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">]</span>
                <span class="s2">del </span><span class="s1">kwargs[</span><span class="s4">&quot;engine_kwargs&quot;</span><span class="s1">]</span>
            <span class="s3"># at this point func is not a str, list-like, dict-like,</span>
            <span class="s3"># or a known callable(e.g. sum)</span>
            <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
                <span class="s2">return </span><span class="s1">self._aggregate_with_numba(</span>
                    <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
                <span class="s1">)</span>
            <span class="s3"># grouper specific aggregations</span>
            <span class="s2">if </span><span class="s1">self.grouper.nkeys &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s3"># test_groupby_as_index_series_scalar gets here with 'not self.as_index'</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s2">elif </span><span class="s1">args </span><span class="s2">or </span><span class="s1">kwargs:</span>
                <span class="s3"># test_pass_args_kwargs gets here (with and without as_index)</span>
                <span class="s3"># can't return early</span>
                <span class="s1">result = self._aggregate_frame(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">elif </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s3"># _aggregate_multiple_funcs does not allow self.axis == 1</span>
                <span class="s3"># Note: axis == 1 precludes 'not self.as_index', see __init__</span>
                <span class="s1">result = self._aggregate_frame(func)</span>
                <span class="s2">return </span><span class="s1">result</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># try to treat as if we are passing a list</span>
                <span class="s1">gba = GroupByApply(self</span><span class="s2">, </span><span class="s1">[func]</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">kwargs={})</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">result = gba.agg()</span>

                <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
                    <span class="s2">if </span><span class="s4">&quot;No objects to concatenate&quot; </span><span class="s2">not in </span><span class="s1">str(err):</span>
                        <span class="s2">raise</span>
                    <span class="s3"># _aggregate_frame can fail with e.g. func=Series.mode,</span>
                    <span class="s3"># where it expects 1D values but would be getting 2D values</span>
                    <span class="s3"># In other tests, using aggregate_frame instead of GroupByApply</span>
                    <span class="s3">#  would give correct values but incorrect dtypes</span>
                    <span class="s3">#  object vs float64 in test_cython_agg_empty_buckets</span>
                    <span class="s3">#  float64 vs int64 in test_category_order_apply</span>
                    <span class="s1">result = self._aggregate_frame(func)</span>

                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s3"># GH#32040, GH#35246</span>
                    <span class="s3"># e.g. test_groupby_as_index_select_column_sum_empty_df</span>
                    <span class="s1">result = cast(DataFrame</span><span class="s2">, </span><span class="s1">result)</span>
                    <span class="s1">result.columns = self._obj_with_exclusions.columns.copy()</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">result = self._insert_inaxis_grouper(result)</span>
            <span class="s1">result.index = default_index(len(result))</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">agg = aggregate</span>

    <span class="s2">def </span><span class="s1">_python_agg_general(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">orig_func = func</span>
        <span class="s1">func = com.is_builtin_func(func)</span>
        <span class="s2">if </span><span class="s1">orig_func != func:</span>
            <span class="s1">alias = com._builtin_table_alias[func]</span>
            <span class="s1">warn_alias_replacement(self</span><span class="s2">, </span><span class="s1">orig_func</span><span class="s2">, </span><span class="s1">alias)</span>
        <span class="s1">f = </span><span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">if </span><span class="s1">self.ngroups == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># e.g. test_evaluate_with_empty_groups different path gets different</span>
            <span class="s3">#  result dtype in empty case.</span>
            <span class="s2">return </span><span class="s1">self._python_apply_general(f</span><span class="s2">, </span><span class="s1">self._selected_obj</span><span class="s2">, </span><span class="s1">is_agg=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">obj = obj.T</span>

        <span class="s2">if not </span><span class="s1">len(obj.columns):</span>
            <span class="s3"># e.g. test_margins_no_values_no_cols</span>
            <span class="s2">return </span><span class="s1">self._python_apply_general(f</span><span class="s2">, </span><span class="s1">self._selected_obj)</span>

        <span class="s1">output: dict[int</span><span class="s2">, </span><span class="s1">ArrayLike] = {}</span>
        <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">(name</span><span class="s2">, </span><span class="s1">ser) </span><span class="s2">in </span><span class="s1">enumerate(obj.items()):</span>
            <span class="s1">result = self.grouper.agg_series(ser</span><span class="s2">, </span><span class="s1">f)</span>
            <span class="s1">output[idx] = result</span>

        <span class="s1">res = self.obj._constructor(output)</span>
        <span class="s1">res.columns = obj.columns.copy(deep=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._wrap_aggregated_output(res)</span>

    <span class="s2">def </span><span class="s1">_aggregate_frame(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s2">if </span><span class="s1">self.grouper.nkeys != </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">AssertionError(</span><span class="s4">&quot;Number of keys must be 1&quot;</span><span class="s1">)</span>

        <span class="s1">obj = self._obj_with_exclusions</span>

        <span class="s1">result: dict[Hashable</span><span class="s2">, </span><span class="s1">NDFrame | np.ndarray] = {}</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">grp_df </span><span class="s2">in </span><span class="s1">self.grouper.get_iterator(obj</span><span class="s2">, </span><span class="s1">self.axis):</span>
            <span class="s1">fres = func(grp_df</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">result[name] = fres</span>

        <span class="s1">result_index = self.grouper.result_index</span>
        <span class="s1">other_ax = obj.axes[</span><span class="s5">1 </span><span class="s1">- self.axis]</span>
        <span class="s1">out = self.obj._constructor(result</span><span class="s2">, </span><span class="s1">index=other_ax</span><span class="s2">, </span><span class="s1">columns=result_index)</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">out = out.T</span>

        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">data: DataFrame</span><span class="s2">,</span>
        <span class="s1">values: list</span><span class="s2">,</span>
        <span class="s1">not_indexed_same: bool = </span><span class="s2">False,</span>
        <span class="s1">is_transform: bool = </span><span class="s2">False,</span>
    <span class="s1">):</span>
        <span class="s2">if </span><span class="s1">len(values) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">is_transform:</span>
                <span class="s3"># GH#47787 see test_group_on_empty_multiindex</span>
                <span class="s1">res_index = data.index</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">res_index = self.grouper.result_index</span>

            <span class="s1">result = self.obj._constructor(index=res_index</span><span class="s2">, </span><span class="s1">columns=data.columns)</span>
            <span class="s1">result = result.astype(data.dtypes</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s3"># GH12824</span>
        <span class="s3"># using values[0] here breaks test_groupby_apply_none_first</span>
        <span class="s1">first_not_none = next(com.not_none(*values)</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">first_not_none </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># GH9684 - All values are None, return an empty frame.</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor()</span>
        <span class="s2">elif </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">return </span><span class="s1">self._concat_objects(</span>
                <span class="s1">values</span><span class="s2">,</span>
                <span class="s1">not_indexed_same=not_indexed_same</span><span class="s2">,</span>
                <span class="s1">is_transform=is_transform</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s1">key_index = self.grouper.result_index </span><span class="s2">if </span><span class="s1">self.as_index </span><span class="s2">else None</span>

        <span class="s2">if </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">Index)):</span>
            <span class="s3"># GH#1738: values is list of arrays of unequal lengths</span>
            <span class="s3">#  fall through to the outer else clause</span>
            <span class="s3"># TODO: sure this is right?  we used to do this</span>
            <span class="s3">#  after raising AttributeError above</span>
            <span class="s3"># GH 18930</span>
            <span class="s2">if not </span><span class="s1">is_hashable(self._selection):</span>
                <span class="s3"># error: Need type annotation for &quot;name&quot;</span>
                <span class="s1">name = tuple(self._selection)  </span><span class="s3"># type: ignore[var-annotated, arg-type]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># error: Incompatible types in assignment</span>
                <span class="s3"># (expression has type &quot;Hashable&quot;, variable</span>
                <span class="s3"># has type &quot;Tuple[Any, ...]&quot;)</span>
                <span class="s1">name = self._selection  </span><span class="s3"># type: ignore[assignment]</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor_sliced(values</span><span class="s2">, </span><span class="s1">index=key_index</span><span class="s2">, </span><span class="s1">name=name)</span>
        <span class="s2">elif not </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s3"># values are not series or array-like but scalars</span>
            <span class="s3"># self._selection not passed through to Series as the</span>
            <span class="s3"># result should not take the name of original selection</span>
            <span class="s3"># of columns</span>
            <span class="s2">if </span><span class="s1">self.as_index:</span>
                <span class="s2">return </span><span class="s1">self.obj._constructor_sliced(values</span><span class="s2">, </span><span class="s1">index=key_index)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">result = self.obj._constructor(values</span><span class="s2">, </span><span class="s1">columns=[self._selection])</span>
                <span class="s1">result = self._insert_inaxis_grouper(result)</span>
                <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># values are Series</span>
            <span class="s2">return </span><span class="s1">self._wrap_applied_output_series(</span>
                <span class="s1">values</span><span class="s2">,</span>
                <span class="s1">not_indexed_same</span><span class="s2">,</span>
                <span class="s1">first_not_none</span><span class="s2">,</span>
                <span class="s1">key_index</span><span class="s2">,</span>
                <span class="s1">is_transform</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output_series(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">values: list[Series]</span><span class="s2">,</span>
        <span class="s1">not_indexed_same: bool</span><span class="s2">,</span>
        <span class="s1">first_not_none</span><span class="s2">,</span>
        <span class="s1">key_index: Index | </span><span class="s2">None,</span>
        <span class="s1">is_transform: bool</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s1">kwargs = first_not_none._construct_axes_dict()</span>
        <span class="s1">backup = Series(**kwargs)</span>
        <span class="s1">values = [x </span><span class="s2">if </span><span class="s1">(x </span><span class="s2">is not None</span><span class="s1">) </span><span class="s2">else </span><span class="s1">backup </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">values]</span>

        <span class="s1">all_indexed_same = all_indexes_same(x.index </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">values)</span>

        <span class="s2">if not </span><span class="s1">all_indexed_same:</span>
            <span class="s3"># GH 8467</span>
            <span class="s2">return </span><span class="s1">self._concat_objects(</span>
                <span class="s1">values</span><span class="s2">,</span>
                <span class="s1">not_indexed_same=</span><span class="s2">True,</span>
                <span class="s1">is_transform=is_transform</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s3"># Combine values</span>
        <span class="s3"># vstack+constructor is faster than concat and handles MI-columns</span>
        <span class="s1">stacked_values = np.vstack([np.asarray(v) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">values])</span>

        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">index = key_index</span>
            <span class="s1">columns = first_not_none.index.copy()</span>
            <span class="s2">if </span><span class="s1">columns.name </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s3"># GH6124 - propagate name of Series when it's consistent</span>
                <span class="s1">names = {v.name </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">values}</span>
                <span class="s2">if </span><span class="s1">len(names) == </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s1">columns.name = next(iter(names))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">index = first_not_none.index</span>
            <span class="s1">columns = key_index</span>
            <span class="s1">stacked_values = stacked_values.T</span>

        <span class="s2">if </span><span class="s1">stacked_values.dtype == object:</span>
            <span class="s3"># We'll have the DataFrame constructor do inference</span>
            <span class="s1">stacked_values = stacked_values.tolist()</span>
        <span class="s1">result = self.obj._constructor(stacked_values</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=columns)</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">result = self._insert_inaxis_grouper(result)</span>

        <span class="s2">return </span><span class="s1">self._reindex_output(result)</span>

    <span class="s2">def </span><span class="s1">_cython_transform(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">how: str</span><span class="s2">,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
        <span class="s1">axis: AxisInt = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">assert </span><span class="s1">axis == </span><span class="s5">0  </span><span class="s3"># handled by caller</span>

        <span class="s3"># With self.axis == 0, we have multi-block tests</span>
        <span class="s3">#  e.g. test_rank_min_int, test_cython_transform_frame</span>
        <span class="s3">#  test_transform_numeric_ret</span>
        <span class="s3"># With self.axis == 1, _get_data_to_aggregate does a transpose</span>
        <span class="s3">#  so we always have a single block.</span>
        <span class="s1">mgr: Manager2D = self._get_data_to_aggregate(</span>
            <span class="s1">numeric_only=numeric_only</span><span class="s2">, </span><span class="s1">name=how</span>
        <span class="s1">)</span>

        <span class="s2">def </span><span class="s1">arr_func(bvalues: ArrayLike) -&gt; ArrayLike:</span>
            <span class="s2">return </span><span class="s1">self.grouper._cython_operation(</span>
                <span class="s4">&quot;transform&quot;</span><span class="s2">, </span><span class="s1">bvalues</span><span class="s2">, </span><span class="s1">how</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>

        <span class="s3"># We could use `mgr.apply` here and not have to set_axis, but</span>
        <span class="s3">#  we would have to do shape gymnastics for ArrayManager compat</span>
        <span class="s1">res_mgr = mgr.grouped_reduce(arr_func)</span>
        <span class="s1">res_mgr.set_axis(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">mgr.axes[</span><span class="s5">1</span><span class="s1">])</span>

        <span class="s1">res_df = self.obj._constructor_from_mgr(res_mgr</span><span class="s2">, </span><span class="s1">axes=res_mgr.axes)</span>
        <span class="s1">res_df = self._maybe_transpose_result(res_df)</span>
        <span class="s2">return </span><span class="s1">res_df</span>

    <span class="s2">def </span><span class="s1">_transform_general(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">engine_kwargs</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
            <span class="s2">return </span><span class="s1">self._transform_with_numba(</span>
                <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s1">applied = []</span>
        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">gen = self.grouper.get_iterator(obj</span><span class="s2">, </span><span class="s1">axis=self.axis)</span>
        <span class="s1">fast_path</span><span class="s2">, </span><span class="s1">slow_path = self._define_paths(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s3"># Determine whether to use slow or fast path by evaluating on the first group.</span>
        <span class="s3"># Need to handle the case of an empty generator and process the result so that</span>
        <span class="s3"># it does not need to be computed again.</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">group = next(gen)</span>
        <span class="s2">except </span><span class="s1">StopIteration:</span>
            <span class="s2">pass</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># 2023-02-27 No tests broken by disabling this pinning</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s1">res = self._choose_path(fast_path</span><span class="s2">, </span><span class="s1">slow_path</span><span class="s2">, </span><span class="s1">group)</span>
            <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
                <span class="s3"># e.g. test_transform_with_non_scalar_group</span>
                <span class="s1">msg = </span><span class="s4">&quot;transform must return a scalar value for each group&quot;</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from </span><span class="s1">err</span>
            <span class="s2">if </span><span class="s1">group.size &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">res = _wrap_transform_general_frame(self.obj</span><span class="s2">, </span><span class="s1">group</span><span class="s2">, </span><span class="s1">res)</span>
                <span class="s1">applied.append(res)</span>

        <span class="s3"># Compute and process with the remaining groups</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">gen:</span>
            <span class="s2">if </span><span class="s1">group.size == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">continue</span>
            <span class="s3"># 2023-02-27 No tests broken by disabling this pinning</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s1">res = path(group)</span>

            <span class="s1">res = _wrap_transform_general_frame(self.obj</span><span class="s2">, </span><span class="s1">group</span><span class="s2">, </span><span class="s1">res)</span>
            <span class="s1">applied.append(res)</span>

        <span class="s1">concat_index = obj.columns </span><span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">obj.index</span>
        <span class="s1">other_axis = </span><span class="s5">1 </span><span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0  </span><span class="s3"># switches between 0 &amp; 1</span>
        <span class="s1">concatenated = concat(applied</span><span class="s2">, </span><span class="s1">axis=self.axis</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">concatenated = concatenated.reindex(concat_index</span><span class="s2">, </span><span class="s1">axis=other_axis</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._set_result_index_ordered(concatenated)</span>

    <span class="s1">__examples_dataframe_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    &gt;&gt;&gt; df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 
    ...                           'foo', 'bar'], 
    ...                    'B' : ['one', 'one', 'two', 'three', 
    ...                           'two', 'two'], 
    ...                    'C' : [1, 5, 5, 2, 5, 5], 
    ...                    'D' : [2.0, 5., 8., 1., 2., 9.]}) 
    &gt;&gt;&gt; grouped = df.groupby('A')[['C', 'D']] 
    &gt;&gt;&gt; grouped.transform(lambda x: (x - x.mean()) / x.std()) 
            C         D 
    0 -1.154701 -0.577350 
    1  0.577350  0.000000 
    2  0.577350  1.154701 
    3 -1.154701 -1.000000 
    4  0.577350 -0.577350 
    5  0.577350  1.000000 
 
    Broadcast result of the transformation 
 
    &gt;&gt;&gt; grouped.transform(lambda x: x.max() - x.min()) 
        C    D 
    0  4.0  6.0 
    1  3.0  8.0 
    2  4.0  6.0 
    3  3.0  8.0 
    4  4.0  6.0 
    5  3.0  8.0 
 
    &gt;&gt;&gt; grouped.transform(&quot;mean&quot;) 
        C    D 
    0  3.666667  4.0 
    1  4.000000  5.0 
    2  3.666667  4.0 
    3  4.000000  5.0 
    4  3.666667  4.0 
    5  4.000000  5.0 
 
    .. versionchanged:: 1.3.0 
 
    The resulting dtype will reflect the return value of the passed ``func``, 
    for example: 
 
    &gt;&gt;&gt; grouped.transform(lambda x: x.astype(int).max()) 
    C  D 
    0  5  8 
    1  5  9 
    2  5  8 
    3  5  9 
    4  5  8 
    5  5  9 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@Substitution(klass=</span><span class="s4">&quot;DataFrame&quot;</span><span class="s2">, </span><span class="s1">example=__examples_dataframe_doc)</span>
    <span class="s1">@Appender(_transform_template)</span>
    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">self._transform(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=engine</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_define_paths(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">fast_path = </span><span class="s2">lambda </span><span class="s1">group: getattr(group</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">slow_path = </span><span class="s2">lambda </span><span class="s1">group: group.apply(</span>
                <span class="s2">lambda </span><span class="s1">x: getattr(x</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fast_path = </span><span class="s2">lambda </span><span class="s1">group: func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">slow_path = </span><span class="s2">lambda </span><span class="s1">group: group.apply(</span>
                <span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">fast_path</span><span class="s2">, </span><span class="s1">slow_path</span>

    <span class="s2">def </span><span class="s1">_choose_path(self</span><span class="s2">, </span><span class="s1">fast_path: Callable</span><span class="s2">, </span><span class="s1">slow_path: Callable</span><span class="s2">, </span><span class="s1">group: DataFrame):</span>
        <span class="s1">path = slow_path</span>
        <span class="s1">res = slow_path(group)</span>

        <span class="s2">if </span><span class="s1">self.ngroups == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># no need to evaluate multiple paths when only</span>
            <span class="s3"># a single group exists</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s3"># if we make it here, test if we can use the fast path</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">res_fast = fast_path(group)</span>
        <span class="s2">except </span><span class="s1">AssertionError:</span>
            <span class="s2">raise  </span><span class="s3"># pragma: no cover</span>
        <span class="s2">except </span><span class="s1">Exception:</span>
            <span class="s3"># GH#29631 For user-defined function, we can't predict what may be</span>
            <span class="s3">#  raised; see test_transform.test_transform_fastpath_raises</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s3"># verify fast path returns either:</span>
        <span class="s3"># a DataFrame with columns equal to group.columns</span>
        <span class="s3"># OR a Series with index equal to group.columns</span>
        <span class="s2">if </span><span class="s1">isinstance(res_fast</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">if not </span><span class="s1">res_fast.columns.equals(group.columns):</span>
                <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>
        <span class="s2">elif </span><span class="s1">isinstance(res_fast</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">if not </span><span class="s1">res_fast.index.equals(group.columns):</span>
                <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s2">if </span><span class="s1">res_fast.equals(res):</span>
            <span class="s1">path = fast_path</span>

        <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

    <span class="s2">def </span><span class="s1">filter(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Filter elements from groups that don't satisfy a criterion. 
 
        Elements from groups are filtered if they do not satisfy the 
        boolean criterion specified by func. 
 
        Parameters 
        ---------- 
        func : function 
            Criterion to apply to each group. Should return True or False. 
        dropna : bool 
            Drop groups that do not pass the filter. True by default; if False, 
            groups that evaluate False are filled with NaNs. 
 
        Returns 
        ------- 
        DataFrame 
 
        Notes 
        ----- 
        Each subframe is endowed the attribute 'name' in case you need to know 
        which group you are working on. 
 
        Functions that mutate the passed object can produce unexpected 
        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation` 
        for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 
        ...                           'foo', 'bar'], 
        ...                    'B' : [1, 2, 3, 4, 5, 6], 
        ...                    'C' : [2.0, 5., 8., 1., 2., 9.]}) 
        &gt;&gt;&gt; grouped = df.groupby('A') 
        &gt;&gt;&gt; grouped.filter(lambda x: x['B'].mean() &gt; 3.) 
             A  B    C 
        1  bar  2  5.0 
        3  bar  4  1.0 
        5  bar  6  9.0 
        &quot;&quot;&quot;</span>
        <span class="s1">indices = []</span>

        <span class="s1">obj = self._selected_obj</span>
        <span class="s1">gen = self.grouper.get_iterator(obj</span><span class="s2">, </span><span class="s1">axis=self.axis)</span>

        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">gen:</span>
            <span class="s3"># 2023-02-27 no tests are broken this pinning, but it is documented in the</span>
            <span class="s3">#  docstring above.</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>

            <span class="s1">res = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">res = res.squeeze()</span>
            <span class="s2">except </span><span class="s1">AttributeError:  </span><span class="s3"># allow e.g., scalars and frames to pass</span>
                <span class="s2">pass</span>

            <span class="s3"># interpret the result of the filter</span>
            <span class="s2">if </span><span class="s1">is_bool(res) </span><span class="s2">or </span><span class="s1">(is_scalar(res) </span><span class="s2">and </span><span class="s1">isna(res)):</span>
                <span class="s2">if </span><span class="s1">notna(res) </span><span class="s2">and </span><span class="s1">res:</span>
                    <span class="s1">indices.append(self._get_index(name))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># non scalars aren't allowed</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s4">f&quot;filter function returned a </span><span class="s2">{</span><span class="s1">type(res).__name__</span><span class="s2">}</span><span class="s4">, &quot;</span>
                    <span class="s4">&quot;but expected a scalar bool&quot;</span>
                <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._apply_filter(indices</span><span class="s2">, </span><span class="s1">dropna)</span>

    <span class="s2">def </span><span class="s1">__getitem__(self</span><span class="s2">, </span><span class="s1">key) -&gt; DataFrameGroupBy | SeriesGroupBy:</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># GH 37725</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Cannot subset columns when using axis=1&quot;</span><span class="s1">)</span>
        <span class="s3"># per GH 23566</span>
        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">and </span><span class="s1">len(key) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># if len == 1, then it becomes a SeriesGroupBy and this is actually</span>
            <span class="s3"># valid syntax, so don't raise</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;Cannot subset columns with a tuple with more than one element. &quot;</span>
                <span class="s4">&quot;Use a list instead.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">super().__getitem__(key)</span>

    <span class="s2">def </span><span class="s1">_gotitem(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">ndim: int</span><span class="s2">, </span><span class="s1">subset=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        sub-classes to define 
        return a sliced object 
 
        Parameters 
        ---------- 
        key : string / list of selections 
        ndim : {1, 2} 
            requested ndim of result 
        subset : object, default None 
            subset to act on 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">ndim == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">subset = self.obj</span>
            <span class="s2">return </span><span class="s1">DataFrameGroupBy(</span>
                <span class="s1">subset</span><span class="s2">,</span>
                <span class="s1">self.keys</span><span class="s2">,</span>
                <span class="s1">axis=self.axis</span><span class="s2">,</span>
                <span class="s1">level=self.level</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">exclusions=self.exclusions</span><span class="s2">,</span>
                <span class="s1">selection=key</span><span class="s2">,</span>
                <span class="s1">as_index=self.as_index</span><span class="s2">,</span>
                <span class="s1">sort=self.sort</span><span class="s2">,</span>
                <span class="s1">group_keys=self.group_keys</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
                <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">subset = self.obj[key]</span>
            <span class="s2">return </span><span class="s1">SeriesGroupBy(</span>
                <span class="s1">subset</span><span class="s2">,</span>
                <span class="s1">self.keys</span><span class="s2">,</span>
                <span class="s1">level=self.level</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">exclusions=self.exclusions</span><span class="s2">,</span>
                <span class="s1">selection=key</span><span class="s2">,</span>
                <span class="s1">as_index=self.as_index</span><span class="s2">,</span>
                <span class="s1">sort=self.sort</span><span class="s2">,</span>
                <span class="s1">group_keys=self.group_keys</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
                <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s2">raise </span><span class="s1">AssertionError(</span><span class="s4">&quot;invalid ndim for _gotitem&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_data_to_aggregate(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">False, </span><span class="s1">name: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span>
    <span class="s1">) -&gt; Manager2D:</span>
        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">mgr = obj.T._mgr</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">mgr = obj._mgr</span>

        <span class="s2">if </span><span class="s1">numeric_only:</span>
            <span class="s1">mgr = mgr.get_numeric_data(copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">mgr</span>

    <span class="s2">def </span><span class="s1">_wrap_agged_manager(self</span><span class="s2">, </span><span class="s1">mgr: Manager2D) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">self.obj._constructor_from_mgr(mgr</span><span class="s2">, </span><span class="s1">axes=mgr.axes)</span>

    <span class="s2">def </span><span class="s1">_apply_to_column_groupbys(self</span><span class="s2">, </span><span class="s1">func) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">columns = obj.columns</span>
        <span class="s1">sgbs = [</span>
            <span class="s1">SeriesGroupBy(</span>
                <span class="s1">obj.iloc[:</span><span class="s2">, </span><span class="s1">i]</span><span class="s2">,</span>
                <span class="s1">selection=colname</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">exclusions=self.exclusions</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">colname </span><span class="s2">in </span><span class="s1">enumerate(obj.columns)</span>
        <span class="s1">]</span>
        <span class="s1">results = [func(sgb) </span><span class="s2">for </span><span class="s1">sgb </span><span class="s2">in </span><span class="s1">sgbs]</span>

        <span class="s2">if not </span><span class="s1">len(results):</span>
            <span class="s3"># concat would raise</span>
            <span class="s1">res_df = DataFrame([]</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">index=self.grouper.result_index)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res_df = concat(results</span><span class="s2">, </span><span class="s1">keys=columns</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">res_df.index = default_index(len(res_df))</span>
            <span class="s1">res_df = self._insert_inaxis_grouper(res_df)</span>
        <span class="s2">return </span><span class="s1">res_df</span>

    <span class="s2">def </span><span class="s1">nunique(self</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return DataFrame with counts of unique elements in each position. 
 
        Parameters 
        ---------- 
        dropna : bool, default True 
            Don't include NaN in the counts. 
 
        Returns 
        ------- 
        nunique: DataFrame 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam', 
        ...                           'ham', 'ham'], 
        ...                    'value1': [1, 5, 5, 2, 5, 5], 
        ...                    'value2': list('abbaxy')}) 
        &gt;&gt;&gt; df 
             id  value1 value2 
        0  spam       1      a 
        1   egg       5      b 
        2   egg       5      b 
        3  spam       2      a 
        4   ham       5      x 
        5   ham       5      y 
 
        &gt;&gt;&gt; df.groupby('id').nunique() 
              value1  value2 
        id 
        egg        1       1 
        ham        1       2 
        spam       2       1 
 
        Check for rows with the same id but conflicting values: 
 
        &gt;&gt;&gt; df.groupby('id').filter(lambda g: (g.nunique() &gt; 1).any()) 
             id  value1 value2 
        0  spam       1      a 
        3  spam       2      a 
        4   ham       5      x 
        5   ham       5      y 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.axis != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># see test_groupby_crash_on_nunique</span>
            <span class="s2">return </span><span class="s1">self._python_apply_general(</span>
                <span class="s2">lambda </span><span class="s1">sgb: sgb.nunique(dropna)</span><span class="s2">, </span><span class="s1">self._obj_with_exclusions</span><span class="s2">, </span><span class="s1">is_agg=</span><span class="s2">True</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._apply_to_column_groupbys(</span><span class="s2">lambda </span><span class="s1">sgb: sgb.nunique(dropna))</span>

    <span class="s2">def </span><span class="s1">idxmax(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">skipna: bool = </span><span class="s2">True,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return index of first occurrence of maximum over requested axis. 
 
        NA/null values are excluded. 
 
        Parameters 
        ---------- 
        axis : {{0 or 'index', 1 or 'columns'}}, default None 
            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise. 
            If axis is not provided, grouper's axis is used. 
 
            .. versionchanged:: 2.0.0 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        skipna : bool, default True 
            Exclude NA/null values. If an entire row/column is NA, the result 
            will be NA. 
        numeric_only : bool, default False 
            Include only `float`, `int` or `boolean` data. 
 
            .. versionadded:: 1.5.0 
 
        Returns 
        ------- 
        Series 
            Indexes of maxima along the specified axis. 
 
        Raises 
        ------ 
        ValueError 
            * If the row/column is empty 
 
        See Also 
        -------- 
        Series.idxmax : Return index of the maximum element. 
 
        Notes 
        ----- 
        This method is the DataFrame version of ``ndarray.argmax``. 
 
        Examples 
        -------- 
        Consider a dataset containing food consumption in Argentina. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48], 
        ...                    'co2_emissions': [37.2, 19.66, 1712]}, 
        ...                    index=['Pork', 'Wheat Products', 'Beef']) 
 
        &gt;&gt;&gt; df 
                        consumption  co2_emissions 
        Pork                  10.51         37.20 
        Wheat Products       103.11         19.66 
        Beef                  55.48       1712.00 
 
        By default, it returns the index for the maximum value in each column. 
 
        &gt;&gt;&gt; df.idxmax() 
        consumption     Wheat Products 
        co2_emissions             Beef 
        dtype: object 
 
        To return the index for the maximum value in each row, use ``axis=&quot;columns&quot;``. 
 
        &gt;&gt;&gt; df.idxmax(axis=&quot;columns&quot;) 
        Pork              co2_emissions 
        Wheat Products     consumption 
        Beef              co2_emissions 
        dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">axis </span><span class="s2">is not </span><span class="s1">lib.no_default:</span>
            <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">axis = self.axis</span>
            <span class="s1">axis = self.obj._get_axis_number(axis)</span>
            <span class="s1">self._deprecate_axis(axis</span><span class="s2">, </span><span class="s4">&quot;idxmax&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">axis = self.axis</span>

        <span class="s2">def </span><span class="s1">func(df):</span>
            <span class="s2">return </span><span class="s1">df.idxmax(axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only)</span>

        <span class="s1">func.__name__ = </span><span class="s4">&quot;idxmax&quot;</span>
        <span class="s1">result = self._python_apply_general(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">self._obj_with_exclusions</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result.astype(self.obj.index.dtype) </span><span class="s2">if </span><span class="s1">result.empty </span><span class="s2">else </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">idxmin(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">skipna: bool = </span><span class="s2">True,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return index of first occurrence of minimum over requested axis. 
 
        NA/null values are excluded. 
 
        Parameters 
        ---------- 
        axis : {{0 or 'index', 1 or 'columns'}}, default None 
            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise. 
            If axis is not provided, grouper's axis is used. 
 
            .. versionchanged:: 2.0.0 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        skipna : bool, default True 
            Exclude NA/null values. If an entire row/column is NA, the result 
            will be NA. 
        numeric_only : bool, default False 
            Include only `float`, `int` or `boolean` data. 
 
            .. versionadded:: 1.5.0 
 
        Returns 
        ------- 
        Series 
            Indexes of minima along the specified axis. 
 
        Raises 
        ------ 
        ValueError 
            * If the row/column is empty 
 
        See Also 
        -------- 
        Series.idxmin : Return index of the minimum element. 
 
        Notes 
        ----- 
        This method is the DataFrame version of ``ndarray.argmin``. 
 
        Examples 
        -------- 
        Consider a dataset containing food consumption in Argentina. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48], 
        ...                    'co2_emissions': [37.2, 19.66, 1712]}, 
        ...                    index=['Pork', 'Wheat Products', 'Beef']) 
 
        &gt;&gt;&gt; df 
                        consumption  co2_emissions 
        Pork                  10.51         37.20 
        Wheat Products       103.11         19.66 
        Beef                  55.48       1712.00 
 
        By default, it returns the index for the minimum value in each column. 
 
        &gt;&gt;&gt; df.idxmin() 
        consumption                Pork 
        co2_emissions    Wheat Products 
        dtype: object 
 
        To return the index for the minimum value in each row, use ``axis=&quot;columns&quot;``. 
 
        &gt;&gt;&gt; df.idxmin(axis=&quot;columns&quot;) 
        Pork                consumption 
        Wheat Products    co2_emissions 
        Beef                consumption 
        dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">axis </span><span class="s2">is not </span><span class="s1">lib.no_default:</span>
            <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">axis = self.axis</span>
            <span class="s1">axis = self.obj._get_axis_number(axis)</span>
            <span class="s1">self._deprecate_axis(axis</span><span class="s2">, </span><span class="s4">&quot;idxmin&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">axis = self.axis</span>

        <span class="s2">def </span><span class="s1">func(df):</span>
            <span class="s2">return </span><span class="s1">df.idxmin(axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only)</span>

        <span class="s1">func.__name__ = </span><span class="s4">&quot;idxmin&quot;</span>
        <span class="s1">result = self._python_apply_general(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">self._obj_with_exclusions</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result.astype(self.obj.index.dtype) </span><span class="s2">if </span><span class="s1">result.empty </span><span class="s2">else </span><span class="s1">result</span>

    <span class="s1">boxplot = boxplot_frame_groupby</span>

    <span class="s2">def </span><span class="s1">value_counts(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">subset: Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">ascending: bool = </span><span class="s2">False,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a Series or DataFrame containing counts of unique rows. 
 
        .. versionadded:: 1.4.0 
 
        Parameters 
        ---------- 
        subset : list-like, optional 
            Columns to use when counting unique combinations. 
        normalize : bool, default False 
            Return proportions rather than frequencies. 
        sort : bool, default True 
            Sort by frequencies. 
        ascending : bool, default False 
            Sort in ascending order. 
        dropna : bool, default True 
            Don't include counts of rows that contain NA values. 
 
        Returns 
        ------- 
        Series or DataFrame 
            Series if the groupby as_index is True, otherwise DataFrame. 
 
        See Also 
        -------- 
        Series.value_counts: Equivalent method on Series. 
        DataFrame.value_counts: Equivalent method on DataFrame. 
        SeriesGroupBy.value_counts: Equivalent method on SeriesGroupBy. 
 
        Notes 
        ----- 
        - If the groupby as_index is True then the returned Series will have a 
          MultiIndex with one level per input column. 
        - If the groupby as_index is False then the returned DataFrame will have an 
          additional column with the value_counts. The column is labelled 'count' or 
          'proportion', depending on the ``normalize`` parameter. 
 
        By default, rows that contain any NA values are omitted from 
        the result. 
 
        By default, the result will be in descending order so that the 
        first element of each group is the most frequently-occurring row. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({ 
        ...    'gender': ['male', 'male', 'female', 'male', 'female', 'male'], 
        ...    'education': ['low', 'medium', 'high', 'low', 'high', 'low'], 
        ...    'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR'] 
        ... }) 
 
        &gt;&gt;&gt; df 
                gender  education   country 
        0       male    low         US 
        1       male    medium      FR 
        2       female  high        US 
        3       male    low         FR 
        4       female  high        FR 
        5       male    low         FR 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts() 
        gender  education  country 
        female  high       FR         1 
                           US         1 
        male    low        FR         2 
                           US         1 
                medium     FR         1 
        Name: count, dtype: int64 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts(ascending=True) 
        gender  education  country 
        female  high       FR         1 
                           US         1 
        male    low        US         1 
                medium     FR         1 
                low        FR         2 
        Name: count, dtype: int64 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts(normalize=True) 
        gender  education  country 
        female  high       FR         0.50 
                           US         0.50 
        male    low        FR         0.50 
                           US         0.25 
                medium     FR         0.25 
        Name: proportion, dtype: float64 
 
        &gt;&gt;&gt; df.groupby('gender', as_index=False).value_counts() 
           gender education country  count 
        0  female      high      FR      1 
        1  female      high      US      1 
        2    male       low      FR      2 
        3    male       low      US      1 
        4    male    medium      FR      1 
 
        &gt;&gt;&gt; df.groupby('gender', as_index=False).value_counts(normalize=True) 
           gender education country  proportion 
        0  female      high      FR        0.50 
        1  female      high      US        0.50 
        2    male       low      FR        0.50 
        3    male       low      US        0.25 
        4    male    medium      FR        0.25 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._value_counts(subset</span><span class="s2">, </span><span class="s1">normalize</span><span class="s2">, </span><span class="s1">sort</span><span class="s2">, </span><span class="s1">ascending</span><span class="s2">, </span><span class="s1">dropna)</span>

    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value: Hashable | Mapping | Series | DataFrame | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">downcast=lib.no_default</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Fill NA/NaN values using the specified method within groups. 
 
        Parameters 
        ---------- 
        value : scalar, dict, Series, or DataFrame 
            Value to use to fill holes (e.g. 0), alternately a 
            dict/Series/DataFrame of values specifying which value to use for 
            each index (for a Series) or column (for a DataFrame).  Values not 
            in the dict/Series/DataFrame will not be filled. This value cannot 
            be a list. Users wanting to use the ``value`` argument and not ``method`` 
            should prefer :meth:`.DataFrame.fillna` as this 
            will produce the same result and be more performant. 
        method : {{'bfill', 'ffill', None}}, default None 
            Method to use for filling holes. ``'ffill'`` will propagate 
            the last valid observation forward within a group. 
            ``'bfill'`` will use next valid observation to fill the gap. 
        axis : {0 or 'index', 1 or 'columns'} 
            Axis along which to fill missing values. When the :class:`DataFrameGroupBy` 
            ``axis`` argument is ``0``, using ``axis=1`` here will produce 
            the same results as :meth:`.DataFrame.fillna`. When the 
            :class:`DataFrameGroupBy` ``axis`` argument is ``1``, using ``axis=0`` 
            or ``axis=1`` here will produce the same results. 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        inplace : bool, default False 
            Broken. Do not set to True. 
        limit : int, default None 
            If method is specified, this is the maximum number of consecutive 
            NaN values to forward/backward fill within a group. In other words, 
            if there is a gap with more than this number of consecutive NaNs, 
            it will only be partially filled. If method is not specified, this is the 
            maximum number of entries along the entire axis where NaNs will be 
            filled. Must be greater than 0 if not None. 
        downcast : dict, default is None 
            A dict of item-&gt;dtype of what to downcast if possible, 
            or the string 'infer' which will try to downcast to an appropriate 
            equal type (e.g. float64 to int64 if possible). 
 
            .. deprecated:: 2.1.0 
 
        Returns 
        ------- 
        DataFrame 
            Object with missing values filled. 
 
        See Also 
        -------- 
        ffill : Forward fill values within a group. 
        bfill : Backward fill values within a group. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame( 
        ...     { 
        ...         &quot;key&quot;: [0, 0, 1, 1, 1], 
        ...         &quot;A&quot;: [np.nan, 2, np.nan, 3, np.nan], 
        ...         &quot;B&quot;: [2, 3, np.nan, np.nan, np.nan], 
        ...         &quot;C&quot;: [np.nan, np.nan, 2, np.nan, np.nan], 
        ...     } 
        ... ) 
        &gt;&gt;&gt; df 
           key    A    B   C 
        0    0  NaN  2.0 NaN 
        1    0  2.0  3.0 NaN 
        2    1  NaN  NaN 2.0 
        3    1  3.0  NaN NaN 
        4    1  NaN  NaN NaN 
 
        Propagate non-null values forward or backward within each group along columns. 
 
        &gt;&gt;&gt; df.groupby(&quot;key&quot;).fillna(method=&quot;ffill&quot;) 
             A    B   C 
        0  NaN  2.0 NaN 
        1  2.0  3.0 NaN 
        2  NaN  NaN 2.0 
        3  3.0  NaN 2.0 
        4  3.0  NaN 2.0 
 
        &gt;&gt;&gt; df.groupby(&quot;key&quot;).fillna(method=&quot;bfill&quot;) 
             A    B   C 
        0  2.0  2.0 NaN 
        1  2.0  3.0 NaN 
        2  3.0  NaN 2.0 
        3  3.0  NaN NaN 
        4  NaN  NaN NaN 
 
        Propagate non-null values forward or backward within each group along rows. 
 
        &gt;&gt;&gt; df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=&quot;ffill&quot;).T 
           key    A    B    C 
        0  0.0  0.0  2.0  2.0 
        1  0.0  2.0  3.0  3.0 
        2  1.0  1.0  NaN  2.0 
        3  1.0  3.0  NaN  NaN 
        4  1.0  1.0  NaN  NaN 
 
        &gt;&gt;&gt; df.T.groupby(np.array([0, 0, 1, 1])).fillna(method=&quot;bfill&quot;).T 
           key    A    B    C 
        0  0.0  NaN  2.0  NaN 
        1  0.0  2.0  3.0  NaN 
        2  1.0  NaN  2.0  2.0 
        3  1.0  3.0  NaN  NaN 
        4  1.0  NaN  NaN  NaN 
 
        Only replace the first NaN element within a group along rows. 
 
        &gt;&gt;&gt; df.groupby(&quot;key&quot;).fillna(method=&quot;ffill&quot;, limit=1) 
             A    B    C 
        0  NaN  2.0  NaN 
        1  2.0  3.0  NaN 
        2  NaN  NaN  2.0 
        3  3.0  NaN  2.0 
        4  3.0  NaN  NaN 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">method </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">type(self).__name__</span><span class="s2">}</span><span class="s4">.fillna with 'method' is deprecated and &quot;</span>
                <span class="s4">&quot;will raise in a future version. Use obj.ffill() or obj.bfill() &quot;</span>
                <span class="s4">&quot;instead.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;fillna&quot;</span><span class="s2">,</span>
            <span class="s1">value=value</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">limit=limit</span><span class="s2">,</span>
            <span class="s1">downcast=downcast</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">take(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">indices: TakeIndexer</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the elements in the given *positional* indices in each group. 
 
        This means that we are not indexing according to actual values in 
        the index attribute of the object. We are indexing according to the 
        actual position of the element in the object. 
 
        If a requested index does not exist for some group, this method will raise. 
        To get similar behavior that ignores indices that don't exist, see 
        :meth:`.DataFrameGroupBy.nth`. 
 
        Parameters 
        ---------- 
        indices : array-like 
            An array of ints indicating which positions to take. 
        axis : {0 or 'index', 1 or 'columns', None}, default 0 
            The axis on which to select elements. ``0`` means that we are 
            selecting rows, ``1`` means that we are selecting columns. 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        **kwargs 
            For compatibility with :meth:`numpy.take`. Has no effect on the 
            output. 
 
        Returns 
        ------- 
        DataFrame 
            An DataFrame containing the elements taken from each group. 
 
        See Also 
        -------- 
        DataFrame.take : Take elements from a Series along an axis. 
        DataFrame.loc : Select a subset of a DataFrame by labels. 
        DataFrame.iloc : Select a subset of a DataFrame by positions. 
        numpy.take : Take elements from an array along an axis. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('falcon', 'bird', 389.0), 
        ...                    ('parrot', 'bird', 24.0), 
        ...                    ('lion', 'mammal', 80.5), 
        ...                    ('monkey', 'mammal', np.nan), 
        ...                    ('rabbit', 'mammal', 15.0)], 
        ...                   columns=['name', 'class', 'max_speed'], 
        ...                   index=[4, 3, 2, 1, 0]) 
        &gt;&gt;&gt; df 
             name   class  max_speed 
        4  falcon    bird      389.0 
        3  parrot    bird       24.0 
        2    lion  mammal       80.5 
        1  monkey  mammal        NaN 
        0  rabbit  mammal       15.0 
        &gt;&gt;&gt; gb = df.groupby([1, 1, 2, 2, 2]) 
 
        Take elements at positions 0 and 1 along the axis 0 (default). 
 
        Note how the indices selected in the result do not correspond to 
        our input indices 0 and 1. That's because we are selecting the 0th 
        and 1st rows, not rows whose indices equal 0 and 1. 
 
        &gt;&gt;&gt; gb.take([0, 1]) 
               name   class  max_speed 
        1 4  falcon    bird      389.0 
          3  parrot    bird       24.0 
        2 2    lion  mammal       80.5 
          1  monkey  mammal        NaN 
 
        The order of the specified indices influences the order in the result. 
        Here, the order is swapped from the previous example. 
 
        &gt;&gt;&gt; gb.take([1, 0]) 
               name   class  max_speed 
        1 3  parrot    bird       24.0 
          4  falcon    bird      389.0 
        2 1  monkey  mammal        NaN 
          2    lion  mammal       80.5 
 
        Take elements at indices 1 and 2 along the axis 1 (column selection). 
 
        We may take elements using negative integers for positive indices, 
        starting from the end of the object, just like with Python lists. 
 
        &gt;&gt;&gt; gb.take([-1, -2]) 
               name   class  max_speed 
        1 3  parrot    bird       24.0 
          4  falcon    bird      389.0 
        2 0  rabbit  mammal       15.0 
          1  monkey  mammal        NaN 
        &quot;&quot;&quot;</span>
        <span class="s1">result = self._op_via_apply(</span><span class="s4">&quot;take&quot;</span><span class="s2">, </span><span class="s1">indices=indices</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">skew(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">| lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">skipna: bool = </span><span class="s2">True,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return unbiased skew within groups. 
 
        Normalized by N-1. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns', None}, default 0 
            Axis for the function to be applied on. 
 
            Specifying ``axis=None`` will apply the aggregation across both axes. 
 
            .. versionadded:: 2.0.0 
 
            .. deprecated:: 2.1.0 
                For axis=1, operate on the underlying object instead. Otherwise 
                the axis keyword is not necessary. 
 
        skipna : bool, default True 
            Exclude NA/null values when computing the result. 
 
        numeric_only : bool, default False 
            Include only float, int, boolean columns. 
 
        **kwargs 
            Additional keyword arguments to be passed to the function. 
 
        Returns 
        ------- 
        DataFrame 
 
        See Also 
        -------- 
        DataFrame.skew : Return unbiased skew over requested axis. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; arrays = [['falcon', 'parrot', 'cockatoo', 'kiwi', 
        ...            'lion', 'monkey', 'rabbit'], 
        ...           ['bird', 'bird', 'bird', 'bird', 
        ...            'mammal', 'mammal', 'mammal']] 
        &gt;&gt;&gt; index = pd.MultiIndex.from_arrays(arrays, names=('name', 'class')) 
        &gt;&gt;&gt; df = pd.DataFrame({'max_speed': [389.0, 24.0, 70.0, np.nan, 
        ...                                  80.5, 21.5, 15.0]}, 
        ...                   index=index) 
        &gt;&gt;&gt; df 
                        max_speed 
        name     class 
        falcon   bird        389.0 
        parrot   bird         24.0 
        cockatoo bird         70.0 
        kiwi     bird          NaN 
        lion     mammal       80.5 
        monkey   mammal       21.5 
        rabbit   mammal       15.0 
        &gt;&gt;&gt; gb = df.groupby([&quot;class&quot;]) 
        &gt;&gt;&gt; gb.skew() 
                max_speed 
        class 
        bird     1.628296 
        mammal   1.669046 
        &gt;&gt;&gt; gb.skew(skipna=False) 
                max_speed 
        class 
        bird          NaN 
        mammal   1.669046 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">axis </span><span class="s2">is </span><span class="s1">lib.no_default:</span>
            <span class="s1">axis = </span><span class="s5">0</span>

        <span class="s2">if </span><span class="s1">axis != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">result = self._op_via_apply(</span>
                <span class="s4">&quot;skew&quot;</span><span class="s2">,</span>
                <span class="s1">axis=axis</span><span class="s2">,</span>
                <span class="s1">skipna=skipna</span><span class="s2">,</span>
                <span class="s1">numeric_only=numeric_only</span><span class="s2">,</span>
                <span class="s1">**kwargs</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">def </span><span class="s1">alt(obj):</span>
            <span class="s3"># This should not be reached since the cython path should raise</span>
            <span class="s3">#  TypeError and not NotImplementedError.</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;'skew' is not supported for dtype=</span><span class="s2">{</span><span class="s1">obj.dtype</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._cython_agg_general(</span>
            <span class="s4">&quot;skew&quot;</span><span class="s2">, </span><span class="s1">alt=alt</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s1">@doc(DataFrame.plot.__doc__)</span>
    <span class="s2">def </span><span class="s1">plot(self) -&gt; GroupByPlot:</span>
        <span class="s1">result = GroupByPlot(self)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(DataFrame.corr.__doc__)</span>
    <span class="s2">def </span><span class="s1">corr(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">method: str | Callable[[np.ndarray</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">float] = </span><span class="s4">&quot;pearson&quot;</span><span class="s2">,</span>
        <span class="s1">min_periods: int = </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;corr&quot;</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">min_periods=min_periods</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(DataFrame.cov.__doc__)</span>
    <span class="s2">def </span><span class="s1">cov(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">min_periods: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ddof: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;cov&quot;</span><span class="s2">, </span><span class="s1">min_periods=min_periods</span><span class="s2">, </span><span class="s1">ddof=ddof</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(DataFrame.hist.__doc__)</span>
    <span class="s2">def </span><span class="s1">hist(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">column: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">by=</span><span class="s2">None,</span>
        <span class="s1">grid: bool = </span><span class="s2">True,</span>
        <span class="s1">xlabelsize: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">xrot: float | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ylabelsize: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">yrot: float | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ax=</span><span class="s2">None,</span>
        <span class="s1">sharex: bool = </span><span class="s2">False,</span>
        <span class="s1">sharey: bool = </span><span class="s2">False,</span>
        <span class="s1">figsize: tuple[int</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">layout: tuple[int</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">bins: int | Sequence[int] = </span><span class="s5">10</span><span class="s2">,</span>
        <span class="s1">backend: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">legend: bool = </span><span class="s2">False,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;hist&quot;</span><span class="s2">,</span>
            <span class="s1">column=column</span><span class="s2">,</span>
            <span class="s1">by=by</span><span class="s2">,</span>
            <span class="s1">grid=grid</span><span class="s2">,</span>
            <span class="s1">xlabelsize=xlabelsize</span><span class="s2">,</span>
            <span class="s1">xrot=xrot</span><span class="s2">,</span>
            <span class="s1">ylabelsize=ylabelsize</span><span class="s2">,</span>
            <span class="s1">yrot=yrot</span><span class="s2">,</span>
            <span class="s1">ax=ax</span><span class="s2">,</span>
            <span class="s1">sharex=sharex</span><span class="s2">,</span>
            <span class="s1">sharey=sharey</span><span class="s2">,</span>
            <span class="s1">figsize=figsize</span><span class="s2">,</span>
            <span class="s1">layout=layout</span><span class="s2">,</span>
            <span class="s1">bins=bins</span><span class="s2">,</span>
            <span class="s1">backend=backend</span><span class="s2">,</span>
            <span class="s1">legend=legend</span><span class="s2">,</span>
            <span class="s1">**kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@property</span>
    <span class="s1">@doc(DataFrame.dtypes.__doc__)</span>
    <span class="s2">def </span><span class="s1">dtypes(self) -&gt; Series:</span>
        <span class="s3"># GH#51045</span>
        <span class="s1">warnings.warn(</span>
            <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">type(self).__name__</span><span class="s2">}</span><span class="s4">.dtypes is deprecated and will be removed in &quot;</span>
            <span class="s4">&quot;a future version. Check the dtypes on the base object instead&quot;</span><span class="s2">,</span>
            <span class="s1">FutureWarning</span><span class="s2">,</span>
            <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s3"># error: Incompatible return value type (got &quot;DataFrame&quot;, expected &quot;Series&quot;)</span>
        <span class="s2">return </span><span class="s1">self._python_apply_general(  </span><span class="s3"># type: ignore[return-value]</span>
            <span class="s2">lambda </span><span class="s1">df: df.dtypes</span><span class="s2">, </span><span class="s1">self._selected_obj</span>
        <span class="s1">)</span>

    <span class="s1">@doc(DataFrame.corrwith.__doc__)</span>
    <span class="s2">def </span><span class="s1">corrwith(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other: DataFrame | Series</span><span class="s2">,</span>
        <span class="s1">axis: Axis | lib.NoDefault = lib.no_default</span><span class="s2">,</span>
        <span class="s1">drop: bool = </span><span class="s2">False,</span>
        <span class="s1">method: CorrelationMethod = </span><span class="s4">&quot;pearson&quot;</span><span class="s2">,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">result = self._op_via_apply(</span>
            <span class="s4">&quot;corrwith&quot;</span><span class="s2">,</span>
            <span class="s1">other=other</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">drop=drop</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">numeric_only=numeric_only</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">def </span><span class="s1">_wrap_transform_general_frame(</span>
    <span class="s1">obj: DataFrame</span><span class="s2">, </span><span class="s1">group: DataFrame</span><span class="s2">, </span><span class="s1">res: DataFrame | Series</span>
<span class="s1">) -&gt; DataFrame:</span>
    <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">concat</span>

    <span class="s2">if </span><span class="s1">isinstance(res</span><span class="s2">, </span><span class="s1">Series):</span>
        <span class="s3"># we need to broadcast across the</span>
        <span class="s3"># other dimension; this will preserve dtypes</span>
        <span class="s3"># GH14457</span>
        <span class="s2">if </span><span class="s1">res.index.is_(obj.index):</span>
            <span class="s1">res_frame = concat([res] * len(group.columns)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">res_frame.columns = group.columns</span>
            <span class="s1">res_frame.index = group.index</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res_frame = obj._constructor(</span>
                <span class="s1">np.tile(res.values</span><span class="s2">, </span><span class="s1">(len(group.index)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span><span class="s2">,</span>
                <span class="s1">columns=group.columns</span><span class="s2">,</span>
                <span class="s1">index=group.index</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">isinstance(res_frame</span><span class="s2">, </span><span class="s1">DataFrame)</span>
        <span class="s2">return </span><span class="s1">res_frame</span>
    <span class="s2">elif </span><span class="s1">isinstance(res</span><span class="s2">, </span><span class="s1">DataFrame) </span><span class="s2">and not </span><span class="s1">res.index.is_(group.index):</span>
        <span class="s2">return </span><span class="s1">res._align_frame(group)[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">res</span>
</pre>
</body>
</html>
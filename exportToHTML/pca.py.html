<html>
<head>
<title>pca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
pca.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Principal Component Analysis 
 
Author: josef-pktd 
Modified by Kevin Sheppard 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>

<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">(ValueWarning</span><span class="s2">,</span>
                                             <span class="s1">EstimationWarning)</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.validation </span><span class="s2">import </span><span class="s1">(string_like</span><span class="s2">,</span>
                                          <span class="s1">array_like</span><span class="s2">,</span>
                                          <span class="s1">bool_like</span><span class="s2">,</span>
                                          <span class="s1">float_like</span><span class="s2">,</span>
                                          <span class="s1">int_like</span><span class="s2">,</span>
                                          <span class="s1">)</span>


<span class="s2">def </span><span class="s1">_norm(x):</span>
    <span class="s2">return </span><span class="s1">np.sqrt(np.sum(x * x))</span>


<span class="s2">class </span><span class="s1">PCA:</span>
    <span class="s0">&quot;&quot;&quot; 
    Principal Component Analysis 
 
    Parameters 
    ---------- 
    data : array_like 
        Variables in columns, observations in rows. 
    ncomp : int, optional 
        Number of components to return.  If None, returns the as many as the 
        smaller of the number of rows or columns in data. 
    standardize : bool, optional 
        Flag indicating to use standardized data with mean 0 and unit 
        variance.  standardized being True implies demean.  Using standardized 
        data is equivalent to computing principal components from the 
        correlation matrix of data. 
    demean : bool, optional 
        Flag indicating whether to demean data before computing principal 
        components.  demean is ignored if standardize is True. Demeaning data 
        but not standardizing is equivalent to computing principal components 
        from the covariance matrix of data. 
    normalize : bool , optional 
        Indicates whether to normalize the factors to have unit inner product. 
        If False, the loadings will have unit inner product. 
    gls : bool, optional 
        Flag indicating to implement a two-step GLS estimator where 
        in the first step principal components are used to estimate residuals, 
        and then the inverse residual variance is used as a set of weights to 
        estimate the final principal components.  Setting gls to True requires 
        ncomp to be less then the min of the number of rows or columns. 
    weights : ndarray, optional 
        Series weights to use after transforming data according to standardize 
        or demean when computing the principal components. 
    method : str, optional 
        Sets the linear algebra routine used to compute eigenvectors: 
 
        * 'svd' uses a singular value decomposition (default). 
        * 'eig' uses an eigenvalue decomposition of a quadratic form 
        * 'nipals' uses the NIPALS algorithm and can be faster than SVD when 
          ncomp is small and nvars is large. See notes about additional changes 
          when using NIPALS. 
    missing : {str, None} 
        Method for missing data.  Choices are: 
 
        * 'drop-row' - drop rows with missing values. 
        * 'drop-col' - drop columns with missing values. 
        * 'drop-min' - drop either rows or columns, choosing by data retention. 
        * 'fill-em' - use EM algorithm to fill missing value.  ncomp should be 
          set to the number of factors required. 
        * `None` raises if data contains NaN values. 
    tol : float, optional 
        Tolerance to use when checking for convergence when using NIPALS. 
    max_iter : int, optional 
        Maximum iterations when using NIPALS. 
    tol_em : float 
        Tolerance to use when checking for convergence of the EM algorithm. 
    max_em_iter : int 
        Maximum iterations for the EM algorithm. 
    svd_full_matrices : bool, optional 
        If the 'svd' method is selected, this flag is used to set the parameter 
        'full_matrices' in the singular value decomposition method. Is set to 
        False by default. 
 
    Attributes 
    ---------- 
    factors : array or DataFrame 
        nobs by ncomp array of principal components (scores) 
    scores :  array or DataFrame 
        nobs by ncomp array of principal components - identical to factors 
    loadings : array or DataFrame 
        ncomp by nvar array of principal component loadings for constructing 
        the factors 
    coeff : array or DataFrame 
        nvar by ncomp array of principal component loadings for constructing 
        the projections 
    projection : array or DataFrame 
        nobs by var array containing the projection of the data onto the ncomp 
        estimated factors 
    rsquare : array or Series 
        ncomp array where the element in the ith position is the R-square 
        of including the fist i principal components.  Note: values are 
        calculated on the transformed data, not the original data 
    ic : array or DataFrame 
        ncomp by 3 array containing the Bai and Ng (2003) Information 
        criteria.  Each column is a different criteria, and each row 
        represents the number of included factors. 
    eigenvals : array or Series 
        nvar array of eigenvalues 
    eigenvecs : array or DataFrame 
        nvar by nvar array of eigenvectors 
    weights : ndarray 
        nvar array of weights used to compute the principal components, 
        normalized to unit length 
    transformed_data : ndarray 
        Standardized, demeaned and weighted data used to compute 
        principal components and related quantities 
    cols : ndarray 
        Array of indices indicating columns used in the PCA 
    rows : ndarray 
        Array of indices indicating rows used in the PCA 
 
    Notes 
    ----- 
    The default options perform principal component analysis on the 
    demeaned, unit variance version of data.  Setting standardize to False 
    will instead only demean, and setting both standardized and 
    demean to False will not alter the data. 
 
    Once the data have been transformed, the following relationships hold when 
    the number of components (ncomp) is the same as tne minimum of the number 
    of observation or the number of variables. 
 
    .. math: 
 
        X' X = V \\Lambda V' 
 
    .. math: 
 
        F = X V 
 
    .. math: 
 
        X = F V' 
 
    where X is the `data`, F is the array of principal components (`factors` 
    or `scores`), and V is the array of eigenvectors (`loadings`) and V' is 
    the array of factor coefficients (`coeff`). 
 
    When weights are provided, the principal components are computed from the 
    modified data 
 
    .. math: 
 
        \\Omega^{-\\frac{1}{2}} X 
 
    where :math:`\\Omega` is a diagonal matrix composed of the weights. For 
    example, when using the GLS version of PCA, the elements of :math:`\\Omega` 
    will be the inverse of the variances of the residuals from 
 
    .. math: 
 
        X - F V' 
 
    where the number of factors is less than the rank of X 
 
    References 
    ---------- 
    .. [*] J. Bai and S. Ng, &quot;Determining the number of factors in approximate 
       factor models,&quot; Econometrica, vol. 70, number 1, pp. 191-221, 2002 
 
    Examples 
    -------- 
    Basic PCA using the correlation matrix of the data 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from statsmodels.multivariate.pca import PCA 
    &gt;&gt;&gt; x = np.random.randn(100)[:, None] 
    &gt;&gt;&gt; x = x + np.random.randn(100, 100) 
    &gt;&gt;&gt; pc = PCA(x) 
 
    Note that the principal components are computed using a SVD and so the 
    correlation matrix is never constructed, unless method='eig'. 
 
    PCA using the covariance matrix of the data 
 
    &gt;&gt;&gt; pc = PCA(x, standardize=False) 
 
    Limiting the number of factors returned to 1 computed using NIPALS 
 
    &gt;&gt;&gt; pc = PCA(x, ncomp=1, method='nipals') 
    &gt;&gt;&gt; pc.factors.shape 
    (100, 1) 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None, </span><span class="s1">standardize=</span><span class="s2">True, </span><span class="s1">demean=</span><span class="s2">True,</span>
                 <span class="s1">normalize=</span><span class="s2">True, </span><span class="s1">gls=</span><span class="s2">False, </span><span class="s1">weights=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'svd'</span><span class="s2">,</span>
                 <span class="s1">missing=</span><span class="s2">None, </span><span class="s1">tol=</span><span class="s4">5e-8</span><span class="s2">, </span><span class="s1">max_iter=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">tol_em=</span><span class="s4">5e-8</span><span class="s2">,</span>
                 <span class="s1">max_em_iter=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">svd_full_matrices=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s1">self._index = </span><span class="s2">None</span>
        <span class="s1">self._columns = []</span>
        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">pd.DataFrame):</span>
            <span class="s1">self._index = data.index</span>
            <span class="s1">self._columns = data.columns</span>

        <span class="s1">self.data = array_like(data</span><span class="s2">, </span><span class="s3">&quot;data&quot;</span><span class="s2">, </span><span class="s1">ndim=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s5"># Store inputs</span>
        <span class="s1">self._gls = bool_like(gls</span><span class="s2">, </span><span class="s3">&quot;gls&quot;</span><span class="s1">)</span>
        <span class="s1">self._normalize = bool_like(normalize</span><span class="s2">, </span><span class="s3">&quot;normalize&quot;</span><span class="s1">)</span>
        <span class="s1">self._svd_full_matrices = bool_like(svd_full_matrices</span><span class="s2">, </span><span class="s3">&quot;svd_fm&quot;</span><span class="s1">)</span>
        <span class="s1">self._tol = float_like(tol</span><span class="s2">, </span><span class="s3">&quot;tol&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s4">0 </span><span class="s1">&lt; self._tol &lt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'tol must be strictly between 0 and 1'</span><span class="s1">)</span>
        <span class="s1">self._max_iter = int_like(max_iter</span><span class="s2">, </span><span class="s3">&quot;int_like&quot;</span><span class="s1">)</span>
        <span class="s1">self._max_em_iter = int_like(max_em_iter</span><span class="s2">, </span><span class="s3">&quot;max_em_iter&quot;</span><span class="s1">)</span>
        <span class="s1">self._tol_em = float_like(tol_em</span><span class="s2">, </span><span class="s3">&quot;tol_em&quot;</span><span class="s1">)</span>

        <span class="s5"># Prepare data</span>
        <span class="s1">self._standardize = bool_like(standardize</span><span class="s2">, </span><span class="s3">&quot;standardize&quot;</span><span class="s1">)</span>
        <span class="s1">self._demean = bool_like(demean</span><span class="s2">, </span><span class="s3">&quot;demean&quot;</span><span class="s1">)</span>

        <span class="s1">self._nobs</span><span class="s2">, </span><span class="s1">self._nvar = self.data.shape</span>
        <span class="s1">weights = array_like(weights</span><span class="s2">, </span><span class="s3">&quot;weights&quot;</span><span class="s2">, </span><span class="s1">maxdim=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">weights </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">weights = np.ones(self._nvar)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">weights = np.array(weights).flatten()</span>
            <span class="s2">if </span><span class="s1">weights.shape[</span><span class="s4">0</span><span class="s1">] != self._nvar:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'weights should have nvar elements'</span><span class="s1">)</span>
            <span class="s1">weights = weights / np.sqrt((weights ** </span><span class="s4">2.0</span><span class="s1">).mean())</span>
        <span class="s1">self.weights = weights</span>

        <span class="s5"># Check ncomp against maximum</span>
        <span class="s1">min_dim = min(self._nobs</span><span class="s2">, </span><span class="s1">self._nvar)</span>
        <span class="s1">self._ncomp = min_dim </span><span class="s2">if </span><span class="s1">ncomp </span><span class="s2">is None else </span><span class="s1">ncomp</span>
        <span class="s2">if </span><span class="s1">self._ncomp &gt; min_dim:</span>
            <span class="s2">import </span><span class="s1">warnings</span>

            <span class="s1">warn = </span><span class="s3">'The requested number of components is more than can be ' </span><span class="s1">\</span>
                   <span class="s3">'computed from data. The maximum number of components is ' </span><span class="s1">\</span>
                   <span class="s3">'the minimum of the number of observations or variables'</span>
            <span class="s1">warnings.warn(warn</span><span class="s2">, </span><span class="s1">ValueWarning)</span>
            <span class="s1">self._ncomp = min_dim</span>

        <span class="s1">self._method = method</span>
        <span class="s5"># Workaround to avoid instance methods in __dict__</span>
        <span class="s2">if </span><span class="s1">self._method </span><span class="s2">not in </span><span class="s1">(</span><span class="s3">'eig'</span><span class="s2">, </span><span class="s3">'svd'</span><span class="s2">, </span><span class="s3">'nipals'</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'method {0} is not known.'</span><span class="s1">.format(method))</span>
        <span class="s2">if </span><span class="s1">self._method == </span><span class="s3">'svd'</span><span class="s1">:</span>
            <span class="s1">self._svd_full_matrices = </span><span class="s2">True</span>

        <span class="s1">self.rows = np.arange(self._nobs)</span>
        <span class="s1">self.cols = np.arange(self._nvar)</span>
        <span class="s5"># Handle missing</span>
        <span class="s1">self._missing = string_like(missing</span><span class="s2">, </span><span class="s3">&quot;missing&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">self._adjusted_data = self.data</span>
        <span class="s1">self._adjust_missing()</span>

        <span class="s5"># Update size</span>
        <span class="s1">self._nobs</span><span class="s2">, </span><span class="s1">self._nvar = self._adjusted_data.shape</span>
        <span class="s2">if </span><span class="s1">self._ncomp == np.min(self.data.shape):</span>
            <span class="s1">self._ncomp = np.min(self._adjusted_data.shape)</span>
        <span class="s2">elif </span><span class="s1">self._ncomp &gt; np.min(self._adjusted_data.shape):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'When adjusting for missing values, user '</span>
                             <span class="s3">'provided ncomp must be no larger than the '</span>
                             <span class="s3">'smallest dimension of the '</span>
                             <span class="s3">'missing-value-adjusted data size.'</span><span class="s1">)</span>

        <span class="s5"># Attributes and internal values</span>
        <span class="s1">self._tss = </span><span class="s4">0.0</span>
        <span class="s1">self._ess = </span><span class="s2">None</span>
        <span class="s1">self.transformed_data = </span><span class="s2">None</span>
        <span class="s1">self._mu = </span><span class="s2">None</span>
        <span class="s1">self._sigma = </span><span class="s2">None</span>
        <span class="s1">self._ess_indiv = </span><span class="s2">None</span>
        <span class="s1">self._tss_indiv = </span><span class="s2">None</span>
        <span class="s1">self.scores = self.factors = </span><span class="s2">None</span>
        <span class="s1">self.loadings = </span><span class="s2">None</span>
        <span class="s1">self.coeff = </span><span class="s2">None</span>
        <span class="s1">self.eigenvals = </span><span class="s2">None</span>
        <span class="s1">self.eigenvecs = </span><span class="s2">None</span>
        <span class="s1">self.projection = </span><span class="s2">None</span>
        <span class="s1">self.rsquare = </span><span class="s2">None</span>
        <span class="s1">self.ic = </span><span class="s2">None</span>

        <span class="s5"># Prepare data</span>
        <span class="s1">self.transformed_data = self._prepare_data()</span>
        <span class="s5"># Perform the PCA</span>
        <span class="s1">self._pca()</span>
        <span class="s2">if </span><span class="s1">gls:</span>
            <span class="s1">self._compute_gls_weights()</span>
            <span class="s1">self.transformed_data = self._prepare_data()</span>
            <span class="s1">self._pca()</span>

        <span class="s5"># Final calculations</span>
        <span class="s1">self._compute_rsquare_and_ic()</span>
        <span class="s2">if </span><span class="s1">self._index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self._to_pandas()</span>

    <span class="s2">def </span><span class="s1">_adjust_missing(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Implements alternatives for handling missing values 
        &quot;&quot;&quot;</span>

        <span class="s2">def </span><span class="s1">keep_col(x):</span>
            <span class="s1">index = np.logical_not(np.any(np.isnan(x)</span><span class="s2">, </span><span class="s4">0</span><span class="s1">))</span>
            <span class="s2">return </span><span class="s1">x[:</span><span class="s2">, </span><span class="s1">index]</span><span class="s2">, </span><span class="s1">index</span>

        <span class="s2">def </span><span class="s1">keep_row(x):</span>
            <span class="s1">index = np.logical_not(np.any(np.isnan(x)</span><span class="s2">, </span><span class="s4">1</span><span class="s1">))</span>
            <span class="s2">return </span><span class="s1">x[index</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s1">index</span>

        <span class="s2">if </span><span class="s1">self._missing == </span><span class="s3">'drop-col'</span><span class="s1">:</span>
            <span class="s1">self._adjusted_data</span><span class="s2">, </span><span class="s1">index = keep_col(self.data)</span>
            <span class="s1">self.cols = np.where(index)[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">self.weights = self.weights[index]</span>
        <span class="s2">elif </span><span class="s1">self._missing == </span><span class="s3">'drop-row'</span><span class="s1">:</span>
            <span class="s1">self._adjusted_data</span><span class="s2">, </span><span class="s1">index = keep_row(self.data)</span>
            <span class="s1">self.rows = np.where(index)[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">elif </span><span class="s1">self._missing == </span><span class="s3">'drop-min'</span><span class="s1">:</span>
            <span class="s1">drop_col</span><span class="s2">, </span><span class="s1">drop_col_index = keep_col(self.data)</span>
            <span class="s1">drop_col_size = drop_col.size</span>

            <span class="s1">drop_row</span><span class="s2">, </span><span class="s1">drop_row_index = keep_row(self.data)</span>
            <span class="s1">drop_row_size = drop_row.size</span>

            <span class="s2">if </span><span class="s1">drop_row_size &gt; drop_col_size:</span>
                <span class="s1">self._adjusted_data = drop_row</span>
                <span class="s1">self.rows = np.where(drop_row_index)[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self._adjusted_data = drop_col</span>
                <span class="s1">self.weights = self.weights[drop_col_index]</span>
                <span class="s1">self.cols = np.where(drop_col_index)[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">elif </span><span class="s1">self._missing == </span><span class="s3">'fill-em'</span><span class="s1">:</span>
            <span class="s1">self._adjusted_data = self._fill_missing_em()</span>
        <span class="s2">elif </span><span class="s1">self._missing </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">np.isfinite(self._adjusted_data).all():</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;&quot;&quot;</span><span class="s2">\ 
</span><span class="s3">data contains non-finite values (inf, NaN). You should drop these values or 
use one of the methods for adjusting data for missing-values.&quot;&quot;&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'missing method is not known.'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self._index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self._columns = self._columns[self.cols]</span>
            <span class="s1">self._index = self._index[self.rows]</span>

        <span class="s5"># Check adjusted data size</span>
        <span class="s2">if </span><span class="s1">self._adjusted_data.size == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Removal of missing values has eliminated '</span>
                             <span class="s3">'all data.'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_compute_gls_weights(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Computes GLS weights based on percentage of data fit 
        &quot;&quot;&quot;</span>
        <span class="s1">projection = np.asarray(self.project(transform=</span><span class="s2">False</span><span class="s1">))</span>
        <span class="s1">errors = self.transformed_data - projection</span>
        <span class="s2">if </span><span class="s1">self._ncomp == self._nvar:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'gls can only be used when ncomp &lt; nvar '</span>
                             <span class="s3">'so that residuals have non-zero variance'</span><span class="s1">)</span>
        <span class="s1">var = (errors ** </span><span class="s4">2.0</span><span class="s1">).mean(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">weights = </span><span class="s4">1.0 </span><span class="s1">/ var</span>
        <span class="s1">weights = weights / np.sqrt((weights ** </span><span class="s4">2.0</span><span class="s1">).mean())</span>
        <span class="s1">nvar = self._nvar</span>
        <span class="s1">eff_series_perc = (</span><span class="s4">1.0 </span><span class="s1">/ sum((weights / weights.sum()) ** </span><span class="s4">2.0</span><span class="s1">)) / nvar</span>
        <span class="s2">if </span><span class="s1">eff_series_perc &lt; </span><span class="s4">0.1</span><span class="s1">:</span>
            <span class="s1">eff_series = int(np.round(eff_series_perc * nvar))</span>
            <span class="s2">import </span><span class="s1">warnings</span>

            <span class="s1">warn = </span><span class="s3">f&quot;&quot;&quot;</span><span class="s2">\ 
</span><span class="s3">Many series are being down weighted by GLS. Of the </span><span class="s2">{</span><span class="s1">nvar</span><span class="s2">} </span><span class="s3">series, the GLS</span>
<span class="s3">estimates are based on only </span><span class="s2">{</span><span class="s1">eff_series</span><span class="s2">} </span><span class="s3">(effective) series.&quot;&quot;&quot;</span>
            <span class="s1">warnings.warn(warn</span><span class="s2">, </span><span class="s1">EstimationWarning)</span>

        <span class="s1">self.weights = weights</span>

    <span class="s2">def </span><span class="s1">_pca(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Main PCA routine 
        &quot;&quot;&quot;</span>
        <span class="s1">self._compute_eig()</span>
        <span class="s1">self._compute_pca_from_eig()</span>
        <span class="s1">self.projection = self.project()</span>

    <span class="s2">def </span><span class="s1">__repr__(self):</span>
        <span class="s1">string = self.__str__()</span>
        <span class="s1">string = string[:-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">string += </span><span class="s3">', id: ' </span><span class="s1">+ hex(id(self)) + </span><span class="s3">')'</span>
        <span class="s2">return </span><span class="s1">string</span>

    <span class="s2">def </span><span class="s1">__str__(self):</span>
        <span class="s1">string = </span><span class="s3">'Principal Component Analysis('</span>
        <span class="s1">string += </span><span class="s3">'nobs: ' </span><span class="s1">+ str(self._nobs) + </span><span class="s3">', '</span>
        <span class="s1">string += </span><span class="s3">'nvar: ' </span><span class="s1">+ str(self._nvar) + </span><span class="s3">', '</span>
        <span class="s2">if </span><span class="s1">self._standardize:</span>
            <span class="s1">kind = </span><span class="s3">'Standardize (Correlation)'</span>
        <span class="s2">elif </span><span class="s1">self._demean:</span>
            <span class="s1">kind = </span><span class="s3">'Demean (Covariance)'</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">kind = </span><span class="s3">'None'</span>
        <span class="s1">string += </span><span class="s3">'transformation: ' </span><span class="s1">+ kind + </span><span class="s3">', '</span>
        <span class="s2">if </span><span class="s1">self._gls:</span>
            <span class="s1">string += </span><span class="s3">'GLS, '</span>
        <span class="s1">string += </span><span class="s3">'normalization: ' </span><span class="s1">+ str(self._normalize) + </span><span class="s3">', '</span>
        <span class="s1">string += </span><span class="s3">'number of components: ' </span><span class="s1">+ str(self._ncomp) + </span><span class="s3">', '</span>
        <span class="s1">string += </span><span class="s3">'method: ' </span><span class="s1">+ </span><span class="s3">'Eigenvalue' </span><span class="s2">if </span><span class="s1">self._method == </span><span class="s3">'eig' </span><span class="s2">else </span><span class="s3">'SVD'</span>
        <span class="s1">string += </span><span class="s3">')'</span>
        <span class="s2">return </span><span class="s1">string</span>

    <span class="s2">def </span><span class="s1">_prepare_data(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Standardize or demean data. 
        &quot;&quot;&quot;</span>
        <span class="s1">adj_data = self._adjusted_data</span>
        <span class="s2">if </span><span class="s1">np.all(np.isnan(adj_data)):</span>
            <span class="s2">return </span><span class="s1">np.empty(adj_data.shape[</span><span class="s4">1</span><span class="s1">]).fill(np.nan)</span>

        <span class="s1">self._mu = np.nanmean(adj_data</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">self._sigma = np.sqrt(np.nanmean((adj_data - self._mu) ** </span><span class="s4">2.0</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">))</span>
        <span class="s2">if </span><span class="s1">self._standardize:</span>
            <span class="s1">data = (adj_data - self._mu) / self._sigma</span>
        <span class="s2">elif </span><span class="s1">self._demean:</span>
            <span class="s1">data = (adj_data - self._mu)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">data = adj_data</span>
        <span class="s2">return </span><span class="s1">data / np.sqrt(self.weights)</span>

    <span class="s2">def </span><span class="s1">_compute_eig(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrapper for actual eigenvalue method 
 
        This is a workaround to avoid instance methods in __dict__ 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._method == </span><span class="s3">'eig'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._compute_using_eig()</span>
        <span class="s2">elif </span><span class="s1">self._method == </span><span class="s3">'svd'</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._compute_using_svd()</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s5"># self._method == 'nipals'</span>
            <span class="s2">return </span><span class="s1">self._compute_using_nipals()</span>

    <span class="s2">def </span><span class="s1">_compute_using_svd(self):</span>
        <span class="s0">&quot;&quot;&quot;SVD method to compute eigenvalues and eigenvecs&quot;&quot;&quot;</span>
        <span class="s1">x = self.transformed_data</span>
        <span class="s1">u</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">v = np.linalg.svd(x</span><span class="s2">, </span><span class="s1">full_matrices=self._svd_full_matrices)</span>
        <span class="s1">self.eigenvals = s ** </span><span class="s4">2.0</span>
        <span class="s1">self.eigenvecs = v.T</span>

    <span class="s2">def </span><span class="s1">_compute_using_eig(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Eigenvalue decomposition method to compute eigenvalues and eigenvectors 
        &quot;&quot;&quot;</span>
        <span class="s1">x = self.transformed_data</span>
        <span class="s1">self.eigenvals</span><span class="s2">, </span><span class="s1">self.eigenvecs = np.linalg.eigh(x.T.dot(x))</span>

    <span class="s2">def </span><span class="s1">_compute_using_nipals(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        NIPALS implementation to compute small number of eigenvalues 
        and eigenvectors 
        &quot;&quot;&quot;</span>
        <span class="s1">x = self.transformed_data</span>
        <span class="s2">if </span><span class="s1">self._ncomp &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">x = x + </span><span class="s4">0.0  </span><span class="s5"># Copy</span>

        <span class="s1">tol</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">, </span><span class="s1">ncomp = self._tol</span><span class="s2">, </span><span class="s1">self._max_iter</span><span class="s2">, </span><span class="s1">self._ncomp</span>
        <span class="s1">vals = np.zeros(self._ncomp)</span>
        <span class="s1">vecs = np.zeros((self._nvar</span><span class="s2">, </span><span class="s1">self._ncomp))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(ncomp):</span>
            <span class="s1">max_var_ind = np.argmax(x.var(</span><span class="s4">0</span><span class="s1">))</span>
            <span class="s1">factor = x[:</span><span class="s2">, </span><span class="s1">[max_var_ind]]</span>
            <span class="s1">_iter = </span><span class="s4">0</span>
            <span class="s1">diff = </span><span class="s4">1.0</span>
            <span class="s2">while </span><span class="s1">diff &gt; tol </span><span class="s2">and </span><span class="s1">_iter &lt; max_iter:</span>
                <span class="s1">vec = x.T.dot(factor) / (factor.T.dot(factor))</span>
                <span class="s1">vec = vec / np.sqrt(vec.T.dot(vec))</span>
                <span class="s1">factor_last = factor</span>
                <span class="s1">factor = x.dot(vec) / (vec.T.dot(vec))</span>
                <span class="s1">diff = _norm(factor - factor_last) / _norm(factor)</span>
                <span class="s1">_iter += </span><span class="s4">1</span>
            <span class="s1">vals[i] = (factor ** </span><span class="s4">2</span><span class="s1">).sum()</span>
            <span class="s1">vecs[:</span><span class="s2">, </span><span class="s1">[i]] = vec</span>
            <span class="s2">if </span><span class="s1">ncomp &gt; </span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">x -= factor.dot(vec.T)</span>

        <span class="s1">self.eigenvals = vals</span>
        <span class="s1">self.eigenvecs = vecs</span>

    <span class="s2">def </span><span class="s1">_fill_missing_em(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        EM algorithm to fill missing values 
        &quot;&quot;&quot;</span>
        <span class="s1">non_missing = np.logical_not(np.isnan(self.data))</span>

        <span class="s5"># If nothing missing, return without altering the data</span>
        <span class="s2">if </span><span class="s1">np.all(non_missing):</span>
            <span class="s2">return </span><span class="s1">self.data</span>

        <span class="s5"># 1. Standardized data as needed</span>
        <span class="s1">data = self.transformed_data = np.asarray(self._prepare_data())</span>

        <span class="s1">ncomp = self._ncomp</span>

        <span class="s5"># 2. Check for all nans</span>
        <span class="s1">col_non_missing = np.sum(non_missing</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">row_non_missing = np.sum(non_missing</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">np.any(col_non_missing &lt; ncomp) </span><span class="s2">or </span><span class="s1">np.any(row_non_missing &lt; ncomp):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'Implementation requires that all columns and '</span>
                             <span class="s3">'all rows have at least ncomp non-missing values'</span><span class="s1">)</span>
        <span class="s5"># 3. Get mask</span>
        <span class="s1">mask = np.isnan(data)</span>

        <span class="s5"># 4. Compute mean</span>
        <span class="s1">mu = np.nanmean(data</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

        <span class="s5"># 5. Replace missing with mean</span>
        <span class="s1">projection = np.ones((self._nobs</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)) * mu</span>
        <span class="s1">projection_masked = projection[mask]</span>
        <span class="s1">data[mask] = projection_masked</span>

        <span class="s5"># 6. Compute eigenvalues and fit</span>
        <span class="s1">diff = </span><span class="s4">1.0</span>
        <span class="s1">_iter = </span><span class="s4">0</span>
        <span class="s2">while </span><span class="s1">diff &gt; self._tol_em </span><span class="s2">and </span><span class="s1">_iter &lt; self._max_em_iter:</span>
            <span class="s1">last_projection_masked = projection_masked</span>
            <span class="s5"># Set transformed data to compute eigenvalues</span>
            <span class="s1">self.transformed_data = data</span>
            <span class="s5"># Call correct eig function here</span>
            <span class="s1">self._compute_eig()</span>
            <span class="s5"># Call function to compute factors and projection</span>
            <span class="s1">self._compute_pca_from_eig()</span>
            <span class="s1">projection = np.asarray(self.project(transform=</span><span class="s2">False,</span>
                                                 <span class="s1">unweight=</span><span class="s2">False</span><span class="s1">))</span>
            <span class="s1">projection_masked = projection[mask]</span>
            <span class="s1">data[mask] = projection_masked</span>
            <span class="s1">delta = last_projection_masked - projection_masked</span>
            <span class="s1">diff = _norm(delta) / _norm(projection_masked)</span>
            <span class="s1">_iter += </span><span class="s4">1</span>
        <span class="s5"># Must copy to avoid overwriting original data since replacing values</span>
        <span class="s1">data = self._adjusted_data + </span><span class="s4">0.0</span>
        <span class="s1">projection = np.asarray(self.project())</span>
        <span class="s1">data[mask] = projection[mask]</span>

        <span class="s2">return </span><span class="s1">data</span>

    <span class="s2">def </span><span class="s1">_compute_pca_from_eig(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute relevant statistics after eigenvalues have been computed 
        &quot;&quot;&quot;</span>
        <span class="s5"># Ensure sorted largest to smallest</span>
        <span class="s1">vals</span><span class="s2">, </span><span class="s1">vecs = self.eigenvals</span><span class="s2">, </span><span class="s1">self.eigenvecs</span>
        <span class="s1">indices = np.argsort(vals)</span>
        <span class="s1">indices = indices[::-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">vals = vals[indices]</span>
        <span class="s1">vecs = vecs[:</span><span class="s2">, </span><span class="s1">indices]</span>
        <span class="s2">if </span><span class="s1">(vals &lt;= </span><span class="s4">0</span><span class="s1">).any():</span>
            <span class="s5"># Discard and warn</span>
            <span class="s1">num_good = vals.shape[</span><span class="s4">0</span><span class="s1">] - (vals &lt;= </span><span class="s4">0</span><span class="s1">).sum()</span>
            <span class="s2">if </span><span class="s1">num_good &lt; self._ncomp:</span>
                <span class="s2">import </span><span class="s1">warnings</span>

                <span class="s1">warnings.warn(</span><span class="s3">'Only {num:d} eigenvalues are positive.  '</span>
                              <span class="s3">'This is the maximum number of components '</span>
                              <span class="s3">'that can be extracted.'</span><span class="s1">.format(num=num_good)</span><span class="s2">,</span>
                              <span class="s1">EstimationWarning)</span>

                <span class="s1">self._ncomp = num_good</span>
                <span class="s1">vals[num_good:] = np.finfo(np.float64).tiny</span>
        <span class="s5"># Use ncomp for the remaining calculations</span>
        <span class="s1">vals = vals[:self._ncomp]</span>
        <span class="s1">vecs = vecs[:</span><span class="s2">, </span><span class="s1">:self._ncomp]</span>
        <span class="s1">self.eigenvals</span><span class="s2">, </span><span class="s1">self.eigenvecs = vals</span><span class="s2">, </span><span class="s1">vecs</span>
        <span class="s5"># Select correct number of components to return</span>
        <span class="s1">self.scores = self.factors = self.transformed_data.dot(vecs)</span>
        <span class="s1">self.loadings = vecs</span>
        <span class="s1">self.coeff = vecs.T</span>
        <span class="s2">if </span><span class="s1">self._normalize:</span>
            <span class="s1">self.coeff = (self.coeff.T * np.sqrt(vals)).T</span>
            <span class="s1">self.factors /= np.sqrt(vals)</span>
            <span class="s1">self.scores = self.factors</span>

    <span class="s2">def </span><span class="s1">_compute_rsquare_and_ic(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Final statistics to compute 
        &quot;&quot;&quot;</span>
        <span class="s5"># TSS and related calculations</span>
        <span class="s5"># TODO: This needs careful testing, with and without weights,</span>
        <span class="s5">#   gls, standardized and demean</span>
        <span class="s1">weights = self.weights</span>
        <span class="s1">ss_data = self.transformed_data * np.sqrt(weights)</span>
        <span class="s1">self._tss_indiv = np.sum(ss_data ** </span><span class="s4">2</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">self._tss = np.sum(self._tss_indiv)</span>
        <span class="s1">self._ess = np.zeros(self._ncomp + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">self._ess_indiv = np.zeros((self._ncomp + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">self._nvar))</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self._ncomp + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s5"># Projection in the same space as transformed_data</span>
            <span class="s1">projection = self.project(ncomp=i</span><span class="s2">, </span><span class="s1">transform=</span><span class="s2">False, </span><span class="s1">unweight=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">indiv_rss = (projection ** </span><span class="s4">2</span><span class="s1">).sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">rss = indiv_rss.sum()</span>
            <span class="s1">self._ess[i] = self._tss - rss</span>
            <span class="s1">self._ess_indiv[i</span><span class="s2">, </span><span class="s1">:] = self._tss_indiv - indiv_rss</span>
        <span class="s1">self.rsquare = </span><span class="s4">1.0 </span><span class="s1">- self._ess / self._tss</span>
        <span class="s5"># Information Criteria</span>
        <span class="s1">ess = self._ess</span>
        <span class="s1">invalid = ess &lt;= </span><span class="s4">0  </span><span class="s5"># Prevent log issues of 0</span>
        <span class="s2">if </span><span class="s1">invalid.any():</span>
            <span class="s1">last_obs = (np.where(invalid)[</span><span class="s4">0</span><span class="s1">]).min()</span>
            <span class="s1">ess = ess[:last_obs]</span>

        <span class="s1">log_ess = np.log(ess)</span>
        <span class="s1">r = np.arange(ess.shape[</span><span class="s4">0</span><span class="s1">])</span>

        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">nvar = self._nobs</span><span class="s2">, </span><span class="s1">self._nvar</span>
        <span class="s1">sum_to_prod = (nobs + nvar) / (nobs * nvar)</span>
        <span class="s1">min_dim = min(nobs</span><span class="s2">, </span><span class="s1">nvar)</span>
        <span class="s1">penalties = np.array([sum_to_prod * np.log(</span><span class="s4">1.0 </span><span class="s1">/ sum_to_prod)</span><span class="s2">,</span>
                              <span class="s1">sum_to_prod * np.log(min_dim)</span><span class="s2">,</span>
                              <span class="s1">np.log(min_dim) / min_dim])</span>
        <span class="s1">penalties = penalties[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">ic = log_ess + r * penalties</span>
        <span class="s1">self.ic = ic.T</span>

    <span class="s2">def </span><span class="s1">project(self</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None, </span><span class="s1">transform=</span><span class="s2">True, </span><span class="s1">unweight=</span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Project series onto a specific number of factors. 
 
        Parameters 
        ---------- 
        ncomp : int, optional 
            Number of components to use.  If omitted, all components 
            initially computed are used. 
        transform : bool, optional 
            Flag indicating whether to return the projection in the original 
            space of the data (True, default) or in the space of the 
            standardized/demeaned data. 
        unweight : bool, optional 
            Flag indicating whether to undo the effects of the estimation 
            weights. 
 
        Returns 
        ------- 
        array_like 
            The nobs by nvar array of the projection onto ncomp factors. 
 
        Notes 
        ----- 
        &quot;&quot;&quot;</span>
        <span class="s5"># Projection needs to be scaled/shifted based on inputs</span>
        <span class="s1">ncomp = self._ncomp </span><span class="s2">if </span><span class="s1">ncomp </span><span class="s2">is None else </span><span class="s1">ncomp</span>
        <span class="s2">if </span><span class="s1">ncomp &gt; self._ncomp:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'ncomp must be smaller than the number of '</span>
                             <span class="s3">'components computed.'</span><span class="s1">)</span>
        <span class="s1">factors = np.asarray(self.factors)</span>
        <span class="s1">coeff = np.asarray(self.coeff)</span>

        <span class="s1">projection = factors[:</span><span class="s2">, </span><span class="s1">:ncomp].dot(coeff[:ncomp</span><span class="s2">, </span><span class="s1">:])</span>
        <span class="s2">if </span><span class="s1">transform </span><span class="s2">or </span><span class="s1">unweight:</span>
            <span class="s1">projection *= np.sqrt(self.weights)</span>
        <span class="s2">if </span><span class="s1">transform:</span>
            <span class="s5"># Remove the weights, which do not depend on transformation</span>
            <span class="s2">if </span><span class="s1">self._standardize:</span>
                <span class="s1">projection *= self._sigma</span>
            <span class="s2">if </span><span class="s1">self._standardize </span><span class="s2">or </span><span class="s1">self._demean:</span>
                <span class="s1">projection += self._mu</span>
        <span class="s2">if </span><span class="s1">self._index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">projection = pd.DataFrame(projection</span><span class="s2">,</span>
                                      <span class="s1">columns=self._columns</span><span class="s2">,</span>
                                      <span class="s1">index=self._index)</span>
        <span class="s2">return </span><span class="s1">projection</span>

    <span class="s2">def </span><span class="s1">_to_pandas(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns pandas DataFrames for all values 
        &quot;&quot;&quot;</span>
        <span class="s1">index = self._index</span>
        <span class="s5"># Principal Components</span>
        <span class="s1">num_zeros = np.ceil(np.log10(self._ncomp))</span>
        <span class="s1">comp_str = </span><span class="s3">'comp_{0:0' </span><span class="s1">+ str(int(num_zeros)) + </span><span class="s3">'d}'</span>
        <span class="s1">cols = [comp_str.format(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self._ncomp)]</span>
        <span class="s1">df = pd.DataFrame(self.factors</span><span class="s2">, </span><span class="s1">columns=cols</span><span class="s2">, </span><span class="s1">index=index)</span>
        <span class="s1">self.scores = self.factors = df</span>
        <span class="s5"># Projections</span>
        <span class="s1">df = pd.DataFrame(self.projection</span><span class="s2">,</span>
                          <span class="s1">columns=self._columns</span><span class="s2">,</span>
                          <span class="s1">index=index)</span>
        <span class="s1">self.projection = df</span>
        <span class="s5"># Weights</span>
        <span class="s1">df = pd.DataFrame(self.coeff</span><span class="s2">, </span><span class="s1">index=cols</span><span class="s2">,</span>
                          <span class="s1">columns=self._columns)</span>
        <span class="s1">self.coeff = df</span>
        <span class="s5"># Loadings</span>
        <span class="s1">df = pd.DataFrame(self.loadings</span><span class="s2">,</span>
                          <span class="s1">index=self._columns</span><span class="s2">, </span><span class="s1">columns=cols)</span>
        <span class="s1">self.loadings = df</span>
        <span class="s5"># eigenvals</span>
        <span class="s1">self.eigenvals = pd.Series(self.eigenvals)</span>
        <span class="s1">self.eigenvals.name = </span><span class="s3">'eigenvals'</span>
        <span class="s5"># eigenvecs</span>
        <span class="s1">vec_str = comp_str.replace(</span><span class="s3">'comp'</span><span class="s2">, </span><span class="s3">'eigenvec'</span><span class="s1">)</span>
        <span class="s1">cols = [vec_str.format(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.eigenvecs.shape[</span><span class="s4">1</span><span class="s1">])]</span>
        <span class="s1">self.eigenvecs = pd.DataFrame(self.eigenvecs</span><span class="s2">, </span><span class="s1">columns=cols)</span>
        <span class="s5"># R2</span>
        <span class="s1">self.rsquare = pd.Series(self.rsquare)</span>
        <span class="s1">self.rsquare.index.name = </span><span class="s3">'ncomp'</span>
        <span class="s1">self.rsquare.name = </span><span class="s3">'rsquare'</span>
        <span class="s5"># IC</span>
        <span class="s1">self.ic = pd.DataFrame(self.ic</span><span class="s2">, </span><span class="s1">columns=[</span><span class="s3">'IC_p1'</span><span class="s2">, </span><span class="s3">'IC_p2'</span><span class="s2">, </span><span class="s3">'IC_p3'</span><span class="s1">])</span>
        <span class="s1">self.ic.index.name = </span><span class="s3">'ncomp'</span>

    <span class="s2">def </span><span class="s1">plot_scree(self</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None, </span><span class="s1">log_scale=</span><span class="s2">True,</span>
                   <span class="s1">cumulative=</span><span class="s2">False, </span><span class="s1">ax=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Plot of the ordered eigenvalues 
 
        Parameters 
        ---------- 
        ncomp : int, optional 
            Number of components ot include in the plot.  If None, will 
            included the same as the number of components computed 
        log_scale : boot, optional 
            Flag indicating whether ot use a log scale for the y-axis 
        cumulative : bool, optional 
            Flag indicating whether to plot the eigenvalues or cumulative 
            eigenvalues 
        ax : AxesSubplot, optional 
            An axes on which to draw the graph.  If omitted, new a figure 
            is created 
 
        Returns 
        ------- 
        matplotlib.figure.Figure 
            The handle to the figure. 
        &quot;&quot;&quot;</span>
        <span class="s2">import </span><span class="s1">statsmodels.graphics.utils </span><span class="s2">as </span><span class="s1">gutils</span>

        <span class="s1">fig</span><span class="s2">, </span><span class="s1">ax = gutils.create_mpl_ax(ax)</span>

        <span class="s1">ncomp = self._ncomp </span><span class="s2">if </span><span class="s1">ncomp </span><span class="s2">is None else </span><span class="s1">ncomp</span>
        <span class="s1">vals = np.asarray(self.eigenvals)</span>
        <span class="s1">vals = vals[:self._ncomp]</span>
        <span class="s2">if </span><span class="s1">cumulative:</span>
            <span class="s1">vals = np.cumsum(vals)</span>

        <span class="s2">if </span><span class="s1">log_scale:</span>
            <span class="s1">ax.set_yscale(</span><span class="s3">'log'</span><span class="s1">)</span>
        <span class="s1">ax.plot(np.arange(ncomp)</span><span class="s2">, </span><span class="s1">vals[: ncomp]</span><span class="s2">, </span><span class="s3">'bo'</span><span class="s1">)</span>
        <span class="s1">ax.autoscale(tight=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">xlim = np.array(ax.get_xlim())</span>
        <span class="s1">sp = xlim[</span><span class="s4">1</span><span class="s1">] - xlim[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">xlim += </span><span class="s4">0.02 </span><span class="s1">* np.array([-sp</span><span class="s2">, </span><span class="s1">sp])</span>
        <span class="s1">ax.set_xlim(xlim)</span>

        <span class="s1">ylim = np.array(ax.get_ylim())</span>
        <span class="s1">scale = </span><span class="s4">0.02</span>
        <span class="s2">if </span><span class="s1">log_scale:</span>
            <span class="s1">sp = np.log(ylim[</span><span class="s4">1</span><span class="s1">] / ylim[</span><span class="s4">0</span><span class="s1">])</span>
            <span class="s1">ylim = np.exp(np.array([np.log(ylim[</span><span class="s4">0</span><span class="s1">]) - scale * sp</span><span class="s2">,</span>
                                    <span class="s1">np.log(ylim[</span><span class="s4">1</span><span class="s1">]) + scale * sp]))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sp = ylim[</span><span class="s4">1</span><span class="s1">] - ylim[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">ylim += scale * np.array([-sp</span><span class="s2">, </span><span class="s1">sp])</span>
        <span class="s1">ax.set_ylim(ylim)</span>
        <span class="s1">ax.set_title(</span><span class="s3">'Scree Plot'</span><span class="s1">)</span>
        <span class="s1">ax.set_ylabel(</span><span class="s3">'Eigenvalue'</span><span class="s1">)</span>
        <span class="s1">ax.set_xlabel(</span><span class="s3">'Component Number'</span><span class="s1">)</span>
        <span class="s1">fig.tight_layout()</span>

        <span class="s2">return </span><span class="s1">fig</span>

    <span class="s2">def </span><span class="s1">plot_rsquare(self</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None, </span><span class="s1">ax=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Box plots of the individual series R-square against the number of PCs. 
 
        Parameters 
        ---------- 
        ncomp : int, optional 
            Number of components ot include in the plot.  If None, will 
            plot the minimum of 10 or the number of computed components. 
        ax : AxesSubplot, optional 
            An axes on which to draw the graph.  If omitted, new a figure 
            is created. 
 
        Returns 
        ------- 
        matplotlib.figure.Figure 
            The handle to the figure. 
        &quot;&quot;&quot;</span>
        <span class="s2">import </span><span class="s1">statsmodels.graphics.utils </span><span class="s2">as </span><span class="s1">gutils</span>

        <span class="s1">fig</span><span class="s2">, </span><span class="s1">ax = gutils.create_mpl_ax(ax)</span>

        <span class="s1">ncomp = </span><span class="s4">10 </span><span class="s2">if </span><span class="s1">ncomp </span><span class="s2">is None else </span><span class="s1">ncomp</span>
        <span class="s1">ncomp = min(ncomp</span><span class="s2">, </span><span class="s1">self._ncomp)</span>
        <span class="s5"># R2s in rows, series in columns</span>
        <span class="s1">r2s = </span><span class="s4">1.0 </span><span class="s1">- self._ess_indiv / self._tss_indiv</span>
        <span class="s1">r2s = r2s[</span><span class="s4">1</span><span class="s1">:]</span>
        <span class="s1">r2s = r2s[:ncomp]</span>
        <span class="s1">ax.boxplot(r2s.T)</span>
        <span class="s1">ax.set_title(</span><span class="s3">'Individual Input $R^2$'</span><span class="s1">)</span>
        <span class="s1">ax.set_ylabel(</span><span class="s3">'$R^2$'</span><span class="s1">)</span>
        <span class="s1">ax.set_xlabel(</span><span class="s3">'Number of Included Principal Components'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>


<span class="s2">def </span><span class="s1">pca(data</span><span class="s2">, </span><span class="s1">ncomp=</span><span class="s2">None, </span><span class="s1">standardize=</span><span class="s2">True, </span><span class="s1">demean=</span><span class="s2">True, </span><span class="s1">normalize=</span><span class="s2">True,</span>
        <span class="s1">gls=</span><span class="s2">False, </span><span class="s1">weights=</span><span class="s2">None, </span><span class="s1">method=</span><span class="s3">'svd'</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Perform Principal Component Analysis (PCA). 
 
    Parameters 
    ---------- 
    data : ndarray 
        Variables in columns, observations in rows. 
    ncomp : int, optional 
        Number of components to return.  If None, returns the as many as the 
        smaller to the number of rows or columns of data. 
    standardize : bool, optional 
        Flag indicating to use standardized data with mean 0 and unit 
        variance.  standardized being True implies demean. 
    demean : bool, optional 
        Flag indicating whether to demean data before computing principal 
        components.  demean is ignored if standardize is True. 
    normalize : bool , optional 
        Indicates whether th normalize the factors to have unit inner 
        product.  If False, the loadings will have unit inner product. 
    gls : bool, optional 
        Flag indicating to implement a two-step GLS estimator where 
        in the first step principal components are used to estimate residuals, 
        and then the inverse residual variance is used as a set of weights to 
        estimate the final principal components 
    weights : ndarray, optional 
        Series weights to use after transforming data according to standardize 
        or demean when computing the principal components. 
    method : str, optional 
        Determines the linear algebra routine uses.  'eig', the default, 
        uses an eigenvalue decomposition. 'svd' uses a singular value 
        decomposition. 
 
    Returns 
    ------- 
    factors : {ndarray, DataFrame} 
        Array (nobs, ncomp) of principal components (also known as scores). 
    loadings : {ndarray, DataFrame} 
        Array (ncomp, nvar) of principal component loadings for constructing 
        the factors. 
    projection : {ndarray, DataFrame} 
        Array (nobs, nvar) containing the projection of the data onto the ncomp 
        estimated factors. 
    rsquare : {ndarray, Series} 
        Array (ncomp,) where the element in the ith position is the R-square 
        of including the fist i principal components.  The values are 
        calculated on the transformed data, not the original data. 
    ic : {ndarray, DataFrame} 
        Array (ncomp, 3) containing the Bai and Ng (2003) Information 
        criteria.  Each column is a different criteria, and each row 
        represents the number of included factors. 
    eigenvals : {ndarray, Series} 
        Array of eigenvalues (nvar,). 
    eigenvecs : {ndarray, DataFrame} 
        Array of eigenvectors. (nvar, nvar). 
 
    Notes 
    ----- 
    This is a simple function wrapper around the PCA class. See PCA for 
    more information and additional methods. 
    &quot;&quot;&quot;</span>
    <span class="s1">pc = PCA(data</span><span class="s2">, </span><span class="s1">ncomp=ncomp</span><span class="s2">, </span><span class="s1">standardize=standardize</span><span class="s2">, </span><span class="s1">demean=demean</span><span class="s2">,</span>
             <span class="s1">normalize=normalize</span><span class="s2">, </span><span class="s1">gls=gls</span><span class="s2">, </span><span class="s1">weights=weights</span><span class="s2">, </span><span class="s1">method=method)</span>

    <span class="s2">return </span><span class="s1">(pc.factors</span><span class="s2">, </span><span class="s1">pc.loadings</span><span class="s2">, </span><span class="s1">pc.projection</span><span class="s2">, </span><span class="s1">pc.rsquare</span><span class="s2">, </span><span class="s1">pc.ic</span><span class="s2">,</span>
            <span class="s1">pc.eigenvals</span><span class="s2">, </span><span class="s1">pc.eigenvecs)</span>
</pre>
</body>
</html>
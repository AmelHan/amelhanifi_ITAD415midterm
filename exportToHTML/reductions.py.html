<html>
<head>
<title>reductions.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
reductions.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>

<span class="s0">import </span><span class="s1">builtins</span>
<span class="s0">import </span><span class="s1">contextlib</span>
<span class="s0">import </span><span class="s1">math</span>
<span class="s0">import </span><span class="s1">operator</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">collections.abc </span><span class="s0">import </span><span class="s1">Iterable</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>
<span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">product</span><span class="s0">, </span><span class="s1">repeat</span>
<span class="s0">from </span><span class="s1">numbers </span><span class="s0">import </span><span class="s1">Integral</span><span class="s0">, </span><span class="s1">Number</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">tlz </span><span class="s0">import </span><span class="s1">accumulate</span><span class="s0">, </span><span class="s1">compose</span><span class="s0">, </span><span class="s1">drop</span><span class="s0">, </span><span class="s1">get</span><span class="s0">, </span><span class="s1">partition_all</span><span class="s0">, </span><span class="s1">pluck</span>

<span class="s0">from </span><span class="s1">dask </span><span class="s0">import </span><span class="s1">config</span>
<span class="s0">from </span><span class="s1">dask.array </span><span class="s0">import </span><span class="s1">chunk</span>
<span class="s0">from </span><span class="s1">dask.array.blockwise </span><span class="s0">import </span><span class="s1">blockwise</span>
<span class="s0">from </span><span class="s1">dask.array.core </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">Array</span><span class="s0">,</span>
    <span class="s1">_concatenate2</span><span class="s0">,</span>
    <span class="s1">asanyarray</span><span class="s0">,</span>
    <span class="s1">broadcast_to</span><span class="s0">,</span>
    <span class="s1">handle_out</span><span class="s0">,</span>
    <span class="s1">implements</span><span class="s0">,</span>
    <span class="s1">unknown_chunk_message</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">dask.array.creation </span><span class="s0">import </span><span class="s1">arange</span><span class="s0">, </span><span class="s1">diagonal</span>
<span class="s0">from </span><span class="s1">dask.array.dispatch </span><span class="s0">import </span><span class="s1">divide_lookup</span><span class="s0">, </span><span class="s1">nannumel_lookup</span><span class="s0">, </span><span class="s1">numel_lookup</span>
<span class="s0">from </span><span class="s1">dask.array.numpy_compat </span><span class="s0">import </span><span class="s1">ComplexWarning</span>
<span class="s0">from </span><span class="s1">dask.array.utils </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">array_safe</span><span class="s0">,</span>
    <span class="s1">asarray_safe</span><span class="s0">,</span>
    <span class="s1">compute_meta</span><span class="s0">,</span>
    <span class="s1">is_arraylike</span><span class="s0">,</span>
    <span class="s1">meta_from_array</span><span class="s0">,</span>
    <span class="s1">validate_axis</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">dask.array.wrap </span><span class="s0">import </span><span class="s1">ones</span><span class="s0">, </span><span class="s1">zeros</span>
<span class="s0">from </span><span class="s1">dask.base </span><span class="s0">import </span><span class="s1">tokenize</span>
<span class="s0">from </span><span class="s1">dask.blockwise </span><span class="s0">import </span><span class="s1">lol_tuples</span>
<span class="s0">from </span><span class="s1">dask.highlevelgraph </span><span class="s0">import </span><span class="s1">HighLevelGraph</span>
<span class="s0">from </span><span class="s1">dask.utils </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">apply</span><span class="s0">,</span>
    <span class="s1">deepmap</span><span class="s0">,</span>
    <span class="s1">derived_from</span><span class="s0">,</span>
    <span class="s1">funcname</span><span class="s0">,</span>
    <span class="s1">getargspec</span><span class="s0">,</span>
    <span class="s1">is_series_like</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s0">def </span><span class="s1">divide(a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s1">key = </span><span class="s0">lambda </span><span class="s1">x: getattr(x</span><span class="s0">, </span><span class="s2">&quot;__array_priority__&quot;</span><span class="s0">, </span><span class="s1">float(</span><span class="s2">&quot;-inf&quot;</span><span class="s1">))</span>
    <span class="s1">f = divide_lookup.dispatch(type(builtins.max(a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">key=key)))</span>
    <span class="s0">return </span><span class="s1">f(a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>


<span class="s0">def </span><span class="s1">numel(x</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s0">return </span><span class="s1">numel_lookup(x</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s0">def </span><span class="s1">nannumel(x</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s0">return </span><span class="s1">nannumel_lookup(x</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s0">def </span><span class="s1">reduction(</span>
    <span class="s1">x</span><span class="s0">,</span>
    <span class="s1">chunk</span><span class="s0">,</span>
    <span class="s1">aggregate</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s0">None,</span>
    <span class="s1">keepdims=</span><span class="s0">False,</span>
    <span class="s1">dtype=</span><span class="s0">None,</span>
    <span class="s1">split_every=</span><span class="s0">None,</span>
    <span class="s1">combine=</span><span class="s0">None,</span>
    <span class="s1">name=</span><span class="s0">None,</span>
    <span class="s1">out=</span><span class="s0">None,</span>
    <span class="s1">concatenate=</span><span class="s0">True,</span>
    <span class="s1">output_size=</span><span class="s3">1</span><span class="s0">,</span>
    <span class="s1">meta=</span><span class="s0">None,</span>
    <span class="s1">weights=</span><span class="s0">None,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;General version of reductions 
 
    Parameters 
    ---------- 
    x: Array 
        Data being reduced along one or more axes 
    chunk: callable(x_chunk, [weights_chunk=None], axis, keepdims) 
        First function to be executed when resolving the dask graph. 
        This function is applied in parallel to all original chunks of x. 
        See below for function parameters. 
    combine: callable(x_chunk, axis, keepdims), optional 
        Function used for intermediate recursive aggregation (see 
        split_every below). If omitted, it defaults to aggregate. 
        If the reduction can be performed in less than 3 steps, it will not 
        be invoked at all. 
    aggregate: callable(x_chunk, axis, keepdims) 
        Last function to be executed when resolving the dask graph, 
        producing the final output. It is always invoked, even when the reduced 
        Array counts a single chunk along the reduced axes. 
    axis: int or sequence of ints, optional 
        Axis or axes to aggregate upon. If omitted, aggregate along all axes. 
    keepdims: boolean, optional 
        Whether the reduction function should preserve the reduced axes, 
        leaving them at size ``output_size``, or remove them. 
    dtype: np.dtype 
        data type of output. This argument was previously optional, but 
        leaving as ``None`` will now raise an exception. 
    split_every: int &gt;= 2 or dict(axis: int), optional 
        Determines the depth of the recursive aggregation. If set to or more 
        than the number of input chunks, the aggregation will be performed in 
        two steps, one ``chunk`` function per input chunk and a single 
        ``aggregate`` function at the end. If set to less than that, an 
        intermediate ``combine`` function will be used, so that any one 
        ``combine`` or ``aggregate`` function has no more than ``split_every`` 
        inputs. The depth of the aggregation graph will be 
        :math:`log_{split_every}(input chunks along reduced axes)`. Setting to 
        a low value can reduce cache size and network transfers, at the cost of 
        more CPU and a larger dask graph. 
 
        Omit to let dask heuristically decide a good default. A default can 
        also be set globally with the ``split_every`` key in 
        :mod:`dask.config`. 
    name: str, optional 
        Prefix of the keys of the intermediate and output nodes. If omitted it 
        defaults to the function names. 
    out: Array, optional 
        Another dask array whose contents will be replaced. Omit to create a 
        new one. Note that, unlike in numpy, this setting gives no performance 
        benefits whatsoever, but can still be useful  if one needs to preserve 
        the references to a previously existing Array. 
    concatenate: bool, optional 
        If True (the default), the outputs of the ``chunk``/``combine`` 
        functions are concatenated into a single np.array before being passed 
        to the ``combine``/``aggregate`` functions. If False, the input of 
        ``combine`` and ``aggregate`` will be either a list of the raw outputs 
        of the previous step or a single output, and the function will have to 
        concatenate it itself. It can be useful to set this to False if the 
        chunk and/or combine steps do not produce np.arrays. 
    output_size: int &gt;= 1, optional 
        Size of the output of the ``aggregate`` function along the reduced 
        axes. Ignored if keepdims is False. 
    weights : array_like, optional 
        Weights to be used in the reduction of `x`. Will be 
        automatically broadcast to the shape of `x`, and so must have 
        a compatible shape. For instance, if `x` has shape ``(3, 4)`` 
        then acceptable shapes for `weights` are ``(3, 4)``, ``(4,)``, 
        ``(3, 1)``, ``(1, 1)``, ``(1)``, and ``()``. 
 
    Returns 
    ------- 
    dask array 
 
    **Function Parameters** 
 
    x_chunk: numpy.ndarray 
        Individual input chunk. For ``chunk`` functions, it is one of the 
        original chunks of x. For ``combine`` and ``aggregate`` functions, it's 
        the concatenation of the outputs produced by the previous ``chunk`` or 
        ``combine`` functions. If concatenate=False, it's a list of the raw 
        outputs from the previous functions. 
    weights_chunk: numpy.ndarray, optional 
        Only applicable to the ``chunk`` function. Weights, with the 
        same shape as `x_chunk`, to be applied during the reduction of 
        the individual input chunk. If ``weights`` have not been 
        provided then the function may omit this parameter. When 
        `weights_chunk` is included then it must occur immediately 
        after the `x_chunk` parameter, and must also have a default 
        value for cases when ``weights`` are not provided. 
    axis: tuple 
        Normalized list of axes to reduce upon, e.g. ``(0, )`` 
        Scalar, negative, and None axes have been normalized away. 
        Note that some numpy reduction functions cannot reduce along multiple 
        axes at once and strictly require an int in input. Such functions have 
        to be wrapped to cope. 
    keepdims: bool 
        Whether the reduction function should preserve the reduced axes or 
        remove them. 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">axis = tuple(range(x.ndim))</span>
    <span class="s0">if </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Integral):</span>
        <span class="s1">axis = (axis</span><span class="s0">,</span><span class="s1">)</span>
    <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">x.ndim)</span>

    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Must specify dtype&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s2">&quot;dtype&quot; </span><span class="s0">in </span><span class="s1">getargspec(chunk).args:</span>
        <span class="s1">chunk = partial(chunk</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">if </span><span class="s2">&quot;dtype&quot; </span><span class="s0">in </span><span class="s1">getargspec(aggregate).args:</span>
        <span class="s1">aggregate = partial(aggregate</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">if </span><span class="s1">is_series_like(x):</span>
        <span class="s1">x = x.values</span>

    <span class="s5"># Map chunk across all blocks</span>
    <span class="s1">inds = tuple(range(x.ndim))</span>

    <span class="s1">args = (x</span><span class="s0">, </span><span class="s1">inds)</span>
    <span class="s0">if </span><span class="s1">weights </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s5"># Broadcast weights to x and add to args</span>
        <span class="s1">wgt = asanyarray(weights)</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">wgt = broadcast_to(wgt</span><span class="s0">, </span><span class="s1">x.shape)</span>
        <span class="s0">except </span><span class="s1">ValueError:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">f&quot;Weights with shape </span><span class="s0">{</span><span class="s1">wgt.shape</span><span class="s0">} </span><span class="s2">are not broadcastable &quot;</span>
                <span class="s2">f&quot;to x with shape </span><span class="s0">{</span><span class="s1">x.shape</span><span class="s0">}</span><span class="s2">&quot;</span>
            <span class="s1">)</span>

        <span class="s1">args += (wgt</span><span class="s0">, </span><span class="s1">inds)</span>

    <span class="s5"># The dtype of `tmp` doesn't actually matter, and may be incorrect.</span>
    <span class="s1">tmp = blockwise(</span>
        <span class="s1">chunk</span><span class="s0">, </span><span class="s1">inds</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True, </span><span class="s1">token=name</span><span class="s0">, </span><span class="s1">dtype=dtype </span><span class="s0">or </span><span class="s1">float</span>
    <span class="s1">)</span>
    <span class="s1">tmp._chunks = tuple(</span>
        <span class="s1">(output_size</span><span class="s0">,</span><span class="s1">) * len(c) </span><span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s1">c </span><span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">c </span><span class="s0">in </span><span class="s1">enumerate(tmp.chunks)</span>
    <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">meta </span><span class="s0">is None and </span><span class="s1">hasattr(x</span><span class="s0">, </span><span class="s2">&quot;_meta&quot;</span><span class="s1">):</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">reduced_meta = compute_meta(</span>
                <span class="s1">chunk</span><span class="s0">, </span><span class="s1">x.dtype</span><span class="s0">, </span><span class="s1">x._meta</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True, </span><span class="s1">computing_meta=</span><span class="s0">True</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">TypeError:</span>
            <span class="s1">reduced_meta = compute_meta(</span>
                <span class="s1">chunk</span><span class="s0">, </span><span class="s1">x.dtype</span><span class="s0">, </span><span class="s1">x._meta</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">ValueError:</span>
            <span class="s0">pass</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">reduced_meta = </span><span class="s0">None</span>

    <span class="s1">result = _tree_reduce(</span>
        <span class="s1">tmp</span><span class="s0">,</span>
        <span class="s1">aggregate</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">keepdims</span><span class="s0">,</span>
        <span class="s1">dtype</span><span class="s0">,</span>
        <span class="s1">split_every</span><span class="s0">,</span>
        <span class="s1">combine</span><span class="s0">,</span>
        <span class="s1">name=name</span><span class="s0">,</span>
        <span class="s1">concatenate=concatenate</span><span class="s0">,</span>
        <span class="s1">reduced_meta=reduced_meta</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">keepdims </span><span class="s0">and </span><span class="s1">output_size != </span><span class="s3">1</span><span class="s1">:</span>
        <span class="s1">result._chunks = tuple(</span>
            <span class="s1">(output_size</span><span class="s0">,</span><span class="s1">) </span><span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s1">c </span><span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">c </span><span class="s0">in </span><span class="s1">enumerate(tmp.chunks)</span>
        <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">meta </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">result._meta = meta</span>
    <span class="s0">return </span><span class="s1">handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>


<span class="s0">def </span><span class="s1">_tree_reduce(</span>
    <span class="s1">x</span><span class="s0">,</span>
    <span class="s1">aggregate</span><span class="s0">,</span>
    <span class="s1">axis</span><span class="s0">,</span>
    <span class="s1">keepdims</span><span class="s0">,</span>
    <span class="s1">dtype</span><span class="s0">,</span>
    <span class="s1">split_every=</span><span class="s0">None,</span>
    <span class="s1">combine=</span><span class="s0">None,</span>
    <span class="s1">name=</span><span class="s0">None,</span>
    <span class="s1">concatenate=</span><span class="s0">True,</span>
    <span class="s1">reduced_meta=</span><span class="s0">None,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Perform the tree reduction step of a reduction. 
 
    Lower level, users should use ``reduction`` or ``arg_reduction`` directly. 
    &quot;&quot;&quot;</span>
    <span class="s5"># Normalize split_every</span>
    <span class="s1">split_every = split_every </span><span class="s0">or </span><span class="s1">config.get(</span><span class="s2">&quot;split_every&quot;</span><span class="s0">, </span><span class="s3">4</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">isinstance(split_every</span><span class="s0">, </span><span class="s1">dict):</span>
        <span class="s1">split_every = {k: split_every.get(k</span><span class="s0">, </span><span class="s3">2</span><span class="s1">) </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">axis}</span>
    <span class="s0">elif </span><span class="s1">isinstance(split_every</span><span class="s0">, </span><span class="s1">Integral):</span>
        <span class="s1">n = builtins.max(int(split_every ** (</span><span class="s3">1 </span><span class="s1">/ (len(axis) </span><span class="s0">or </span><span class="s3">1</span><span class="s1">)))</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">split_every = dict.fromkeys(axis</span><span class="s0">, </span><span class="s1">n)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;split_every must be a int or a dict&quot;</span><span class="s1">)</span>

    <span class="s5"># Reduce across intermediates</span>
    <span class="s1">depth = </span><span class="s3">1</span>
    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">n </span><span class="s0">in </span><span class="s1">enumerate(x.numblocks):</span>
        <span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">split_every </span><span class="s0">and </span><span class="s1">split_every[i] != </span><span class="s3">1</span><span class="s1">:</span>
            <span class="s1">depth = int(builtins.max(depth</span><span class="s0">, </span><span class="s1">math.ceil(math.log(n</span><span class="s0">, </span><span class="s1">split_every[i]))))</span>
    <span class="s1">func = partial(combine </span><span class="s0">or </span><span class="s1">aggregate</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">concatenate:</span>
        <span class="s1">func = compose(func</span><span class="s0">, </span><span class="s1">partial(_concatenate2</span><span class="s0">, </span><span class="s1">axes=sorted(axis)))</span>
    <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range(depth - </span><span class="s3">1</span><span class="s1">):</span>
        <span class="s1">x = partial_reduce(</span>
            <span class="s1">func</span><span class="s0">,</span>
            <span class="s1">x</span><span class="s0">,</span>
            <span class="s1">split_every</span><span class="s0">,</span>
            <span class="s0">True,</span>
            <span class="s1">dtype=dtype</span><span class="s0">,</span>
            <span class="s1">name=(name </span><span class="s0">or </span><span class="s1">funcname(combine </span><span class="s0">or </span><span class="s1">aggregate)) + </span><span class="s2">&quot;-partial&quot;</span><span class="s0">,</span>
            <span class="s1">reduced_meta=reduced_meta</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s1">func = partial(aggregate</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s0">if </span><span class="s1">concatenate:</span>
        <span class="s1">func = compose(func</span><span class="s0">, </span><span class="s1">partial(_concatenate2</span><span class="s0">, </span><span class="s1">axes=sorted(axis)))</span>
    <span class="s0">return </span><span class="s1">partial_reduce(</span>
        <span class="s1">func</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">split_every</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dtype</span><span class="s0">,</span>
        <span class="s1">name=(name </span><span class="s0">or </span><span class="s1">funcname(aggregate)) + </span><span class="s2">&quot;-aggregate&quot;</span><span class="s0">,</span>
        <span class="s1">reduced_meta=reduced_meta</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">partial_reduce(</span>
    <span class="s1">func</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">split_every</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">name=</span><span class="s0">None, </span><span class="s1">reduced_meta=</span><span class="s0">None</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Partial reduction across multiple axes. 
 
    Parameters 
    ---------- 
    func : function 
    x : Array 
    split_every : dict 
        Maximum reduction block sizes in each dimension. 
 
    Examples 
    -------- 
    Reduce across axis 0 and 2, merging a maximum of 1 block in the 0th 
    dimension, and 3 blocks in the 2nd dimension: 
 
    &gt;&gt;&gt; partial_reduce(np.min, x, {0: 1, 2: 3})    # doctest: +SKIP 
    &quot;&quot;&quot;</span>
    <span class="s1">name = (</span>
        <span class="s1">(name </span><span class="s0">or </span><span class="s1">funcname(func)) + </span><span class="s2">&quot;-&quot; </span><span class="s1">+ tokenize(func</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">split_every</span><span class="s0">, </span><span class="s1">keepdims</span><span class="s0">, </span><span class="s1">dtype)</span>
    <span class="s1">)</span>
    <span class="s1">parts = [</span>
        <span class="s1">list(partition_all(split_every.get(i</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">range(n)))</span>
        <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">n) </span><span class="s0">in </span><span class="s1">enumerate(x.numblocks)</span>
    <span class="s1">]</span>
    <span class="s1">keys = product(*map(range</span><span class="s0">, </span><span class="s1">map(len</span><span class="s0">, </span><span class="s1">parts)))</span>
    <span class="s1">out_chunks = [</span>
        <span class="s1">tuple(</span><span class="s3">1 </span><span class="s0">for </span><span class="s1">p </span><span class="s0">in </span><span class="s1">partition_all(split_every[i]</span><span class="s0">, </span><span class="s1">c)) </span><span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">split_every </span><span class="s0">else </span><span class="s1">c</span>
        <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">c) </span><span class="s0">in </span><span class="s1">enumerate(x.chunks)</span>
    <span class="s1">]</span>
    <span class="s0">if not </span><span class="s1">keepdims:</span>
        <span class="s1">out_axis = [i </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(x.ndim) </span><span class="s0">if </span><span class="s1">i </span><span class="s0">not in </span><span class="s1">split_every]</span>
        <span class="s1">getter = </span><span class="s0">lambda </span><span class="s1">k: get(out_axis</span><span class="s0">, </span><span class="s1">k)</span>
        <span class="s1">keys = map(getter</span><span class="s0">, </span><span class="s1">keys)</span>
        <span class="s1">out_chunks = list(getter(out_chunks))</span>
    <span class="s1">dsk = {}</span>
    <span class="s0">for </span><span class="s1">k</span><span class="s0">, </span><span class="s1">p </span><span class="s0">in </span><span class="s1">zip(keys</span><span class="s0">, </span><span class="s1">product(*parts)):</span>
        <span class="s1">free = {</span>
            <span class="s1">i: j[</span><span class="s3">0</span><span class="s1">] </span><span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">j) </span><span class="s0">in </span><span class="s1">enumerate(p) </span><span class="s0">if </span><span class="s1">len(j) == </span><span class="s3">1 </span><span class="s0">and </span><span class="s1">i </span><span class="s0">not in </span><span class="s1">split_every</span>
        <span class="s1">}</span>
        <span class="s1">dummy = dict(i </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">enumerate(p) </span><span class="s0">if </span><span class="s1">i[</span><span class="s3">0</span><span class="s1">] </span><span class="s0">in </span><span class="s1">split_every)</span>
        <span class="s1">g = lol_tuples((x.name</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">range(x.ndim)</span><span class="s0">, </span><span class="s1">free</span><span class="s0">, </span><span class="s1">dummy)</span>
        <span class="s1">dsk[(name</span><span class="s0">,</span><span class="s1">) + k] = (func</span><span class="s0">, </span><span class="s1">g)</span>
    <span class="s1">graph = HighLevelGraph.from_collections(name</span><span class="s0">, </span><span class="s1">dsk</span><span class="s0">, </span><span class="s1">dependencies=[x])</span>

    <span class="s1">meta = x._meta</span>
    <span class="s0">if </span><span class="s1">reduced_meta </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">meta = func(reduced_meta</span><span class="s0">, </span><span class="s1">computing_meta=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s5"># no meta keyword argument exists for func, and it isn't required</span>
        <span class="s0">except </span><span class="s1">TypeError:</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">meta = func(reduced_meta)</span>
            <span class="s0">except </span><span class="s1">ValueError </span><span class="s0">as </span><span class="s1">e:</span>
                <span class="s5"># min/max functions have no identity, don't apply function to meta</span>
                <span class="s0">if </span><span class="s2">&quot;zero-size array to reduction operation&quot; </span><span class="s0">in </span><span class="s1">str(e):</span>
                    <span class="s1">meta = reduced_meta</span>
        <span class="s5"># when no work can be computed on the empty array (e.g., func is a ufunc)</span>
        <span class="s0">except </span><span class="s1">ValueError:</span>
            <span class="s0">pass</span>

    <span class="s5"># some functions can't compute empty arrays (those for which reduced_meta</span>
    <span class="s5"># fall into the ValueError exception) and we have to rely on reshaping</span>
    <span class="s5"># the array according to len(out_chunks)</span>
    <span class="s0">if </span><span class="s1">is_arraylike(meta) </span><span class="s0">and </span><span class="s1">meta.ndim != len(out_chunks):</span>
        <span class="s0">if </span><span class="s1">len(out_chunks) == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">meta = meta.sum()</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">meta = meta.reshape((</span><span class="s3">0</span><span class="s0">,</span><span class="s1">) * len(out_chunks))</span>

    <span class="s0">if </span><span class="s1">np.isscalar(meta):</span>
        <span class="s0">return </span><span class="s1">Array(graph</span><span class="s0">, </span><span class="s1">name</span><span class="s0">, </span><span class="s1">out_chunks</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">with </span><span class="s1">contextlib.suppress(AttributeError)</span><span class="s0">, </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s0">if </span><span class="s1">name.startswith(</span><span class="s2">&quot;var&quot;</span><span class="s1">) </span><span class="s0">or </span><span class="s1">name.startswith(</span><span class="s2">&quot;moment&quot;</span><span class="s1">):</span>
                <span class="s1">warnings.simplefilter(</span><span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">ComplexWarning)</span>
            <span class="s1">meta = meta.astype(dtype)</span>
        <span class="s0">return </span><span class="s1">Array(graph</span><span class="s0">, </span><span class="s1">name</span><span class="s0">, </span><span class="s1">out_chunks</span><span class="s0">, </span><span class="s1">meta=meta)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">sum(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">dtype = getattr(np.zeros(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=a.dtype).sum()</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s1">result = reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.sum</span><span class="s0">,</span>
        <span class="s1">chunk.sum</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">prod(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.ones((</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype).prod()</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.prod</span><span class="s0">,</span>
        <span class="s1">chunk.prod</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@implements(np.min</span><span class="s0">, </span><span class="s1">np.amin)</span>
<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">min(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk_min</span><span class="s0">,</span>
        <span class="s1">chunk.min</span><span class="s0">,</span>
        <span class="s1">combine=chunk_min</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=a.dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">chunk_min(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Version of np.min which ignores size 0 arrays&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">x.size == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">array_safe([]</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">ndmin=x.ndim</span><span class="s0">, </span><span class="s1">dtype=x.dtype)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">np.min(x</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>


<span class="s1">@implements(np.max</span><span class="s0">, </span><span class="s1">np.amax)</span>
<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">max(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk_max</span><span class="s0">,</span>
        <span class="s1">chunk.max</span><span class="s0">,</span>
        <span class="s1">combine=chunk_max</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=a.dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">chunk_max(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Version of np.max which ignores size 0 arrays&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">x.size == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">array_safe([]</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">ndmin=x.ndim</span><span class="s0">, </span><span class="s1">dtype=x.dtype)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">np.max(x</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">any(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.any</span><span class="s0">,</span>
        <span class="s1">chunk.any</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=</span><span class="s2">&quot;bool&quot;</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">all(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.all</span><span class="s0">,</span>
        <span class="s1">chunk.all</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=</span><span class="s2">&quot;bool&quot;</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nansum(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(chunk.nansum(np.ones((</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.nansum</span><span class="s0">,</span>
        <span class="s1">chunk.sum</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanprod(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(chunk.nansum(np.ones((</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk.nanprod</span><span class="s0">,</span>
        <span class="s1">chunk.prod</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nancumsum(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;sequential&quot;</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Dask added an additional keyword-only argument ``method``. 
 
    method : {'sequential', 'blelloch'}, optional 
        Choose which method to use to perform the cumsum.  Default is 'sequential'. 
 
        * 'sequential' performs the cumsum of each prior block before the current block. 
        * 'blelloch' is a work-efficient parallel cumsum.  It exposes parallelism by 
            first taking the sum of each block and combines the sums via a binary tree. 
            This method may be faster or more memory efficient depending on workload, 
            scheduler, and hardware.  More benchmarking is necessary. 
    &quot;&quot;&quot;</span>
    <span class="s0">return </span><span class="s1">cumreduction(</span>
        <span class="s1">chunk.nancumsum</span><span class="s0">,</span>
        <span class="s1">operator.add</span><span class="s0">,</span>
        <span class="s3">0</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">dtype</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
        <span class="s1">preop=np.nansum</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nancumprod(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">method=</span><span class="s2">&quot;sequential&quot;</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Dask added an additional keyword-only argument ``method``. 
 
    method : {'sequential', 'blelloch'}, optional 
        Choose which method to use to perform the cumprod.  Default is 'sequential'. 
 
        * 'sequential' performs the cumprod of each prior block before the current block. 
        * 'blelloch' is a work-efficient parallel cumprod.  It exposes parallelism by first 
            taking the product of each block and combines the products via a binary tree. 
            This method may be faster or more memory efficient depending on workload, 
            scheduler, and hardware.  More benchmarking is necessary. 
    &quot;&quot;&quot;</span>
    <span class="s0">return </span><span class="s1">cumreduction(</span>
        <span class="s1">chunk.nancumprod</span><span class="s0">,</span>
        <span class="s1">operator.mul</span><span class="s0">,</span>
        <span class="s3">1</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">dtype</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
        <span class="s1">preop=np.nanprod</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanmin(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">np.isnan(a.size):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">f&quot;Arrays chunk sizes are unknown. </span><span class="s0">{</span><span class="s1">unknown_chunk_message</span><span class="s0">}</span><span class="s2">&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">a.size == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span>
            <span class="s2">&quot;zero-size array to reduction operation fmin which has no identity&quot;</span>
        <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">_nanmin_skip</span><span class="s0">,</span>
        <span class="s1">_nanmin_skip</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=a.dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">_nanmin_skip(x_chunk</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">keepdims):</span>
    <span class="s0">if </span><span class="s1">x_chunk.size &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.filterwarnings(</span>
                <span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s2">&quot;All-NaN slice encountered&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning</span>
            <span class="s1">)</span>
            <span class="s0">return </span><span class="s1">np.nanmin(x_chunk</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">asarray_safe(</span>
            <span class="s1">np.array([]</span><span class="s0">, </span><span class="s1">dtype=x_chunk.dtype)</span><span class="s0">, </span><span class="s1">like=meta_from_array(x_chunk)</span>
        <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanmax(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">np.isnan(a.size):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">f&quot;Arrays chunk sizes are unknown. </span><span class="s0">{</span><span class="s1">unknown_chunk_message</span><span class="s0">}</span><span class="s2">&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">a.size == </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span>
            <span class="s2">&quot;zero-size array to reduction operation fmax which has no identity&quot;</span>
        <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">_nanmax_skip</span><span class="s0">,</span>
        <span class="s1">_nanmax_skip</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=a.dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">_nanmax_skip(x_chunk</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">keepdims):</span>
    <span class="s0">if </span><span class="s1">x_chunk.size &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.filterwarnings(</span>
                <span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s2">&quot;All-NaN slice encountered&quot;</span><span class="s0">, </span><span class="s1">RuntimeWarning</span>
            <span class="s1">)</span>
            <span class="s0">return </span><span class="s1">np.nanmax(x_chunk</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">asarray_safe(</span>
            <span class="s1">np.array([]</span><span class="s0">, </span><span class="s1">dtype=x_chunk.dtype)</span><span class="s0">, </span><span class="s1">like=meta_from_array(x_chunk)</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">mean_chunk(</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">sum=chunk.sum</span><span class="s0">, </span><span class="s1">numel=numel</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">, </span><span class="s1">computing_meta=</span><span class="s0">False, </span><span class="s1">**kwargs</span>
<span class="s1">):</span>
    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">x</span>
    <span class="s1">n = numel(x</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s1">total = sum(x</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">return </span><span class="s1">{</span><span class="s2">&quot;n&quot;</span><span class="s1">: n</span><span class="s0">, </span><span class="s2">&quot;total&quot;</span><span class="s1">: total}</span>


<span class="s0">def </span><span class="s1">mean_combine(</span>
    <span class="s1">pairs</span><span class="s0">,</span>
    <span class="s1">sum=chunk.sum</span><span class="s0">,</span>
    <span class="s1">numel=numel</span><span class="s0">,</span>
    <span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s0">None,</span>
    <span class="s1">computing_meta=</span><span class="s0">False,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s0">if not </span><span class="s1">isinstance(pairs</span><span class="s0">, </span><span class="s1">list):</span>
        <span class="s1">pairs = [pairs]</span>

    <span class="s1">ns = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;n&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs) </span><span class="s0">if not </span><span class="s1">computing_meta </span><span class="s0">else </span><span class="s1">pairs</span>
    <span class="s1">n = _concatenate2(ns</span><span class="s0">, </span><span class="s1">axes=axis).sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">n</span>

    <span class="s1">totals = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;total&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span>
    <span class="s1">total = _concatenate2(totals</span><span class="s0">, </span><span class="s1">axes=axis).sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">return </span><span class="s1">{</span><span class="s2">&quot;n&quot;</span><span class="s1">: n</span><span class="s0">, </span><span class="s2">&quot;total&quot;</span><span class="s1">: total}</span>


<span class="s0">def </span><span class="s1">mean_agg(pairs</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">computing_meta=</span><span class="s0">False, </span><span class="s1">**kwargs):</span>
    <span class="s1">ns = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;n&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs) </span><span class="s0">if not </span><span class="s1">computing_meta </span><span class="s0">else </span><span class="s1">pairs</span>
    <span class="s1">n = _concatenate2(ns</span><span class="s0">, </span><span class="s1">axes=axis)</span>
    <span class="s1">n = np.sum(n</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">n</span>

    <span class="s1">totals = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;total&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span>
    <span class="s1">total = _concatenate2(totals</span><span class="s0">, </span><span class="s1">axes=axis).sum(axis=axis</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s2">&quot;ignore&quot;</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">divide(total</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">mean(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">elif </span><span class="s1">a.dtype == object:</span>
        <span class="s1">dt = object</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.mean(np.zeros(shape=(</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">mean_chunk</span><span class="s0">,</span>
        <span class="s1">mean_agg</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">combine=mean_combine</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanmean(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.mean(np.ones(shape=(</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(mean_chunk</span><span class="s0">, </span><span class="s1">sum=chunk.nansum</span><span class="s0">, </span><span class="s1">numel=nannumel)</span><span class="s0">,</span>
        <span class="s1">mean_agg</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
        <span class="s1">combine=partial(mean_combine</span><span class="s0">, </span><span class="s1">sum=chunk.nansum</span><span class="s0">, </span><span class="s1">numel=nannumel)</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">moment_chunk(</span>
    <span class="s1">A</span><span class="s0">,</span>
    <span class="s1">order=</span><span class="s3">2</span><span class="s0">,</span>
    <span class="s1">sum=chunk.sum</span><span class="s0">,</span>
    <span class="s1">numel=numel</span><span class="s0">,</span>
    <span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">,</span>
    <span class="s1">computing_meta=</span><span class="s0">False,</span>
    <span class="s1">implicit_complex_dtype=</span><span class="s0">False,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">A</span>
    <span class="s1">n = numel(A</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s1">n = n.astype(np.int64)</span>
    <span class="s0">if </span><span class="s1">implicit_complex_dtype:</span>
        <span class="s1">total = sum(A</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">total = sum(A</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s2">&quot;ignore&quot;</span><span class="s1">):</span>
        <span class="s1">u = total / n</span>
    <span class="s1">d = A - u</span>
    <span class="s0">if </span><span class="s1">np.issubdtype(A.dtype</span><span class="s0">, </span><span class="s1">np.complexfloating):</span>
        <span class="s1">d = np.abs(d)</span>
    <span class="s1">xs = [sum(d**i</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">**kwargs) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">2</span><span class="s0">, </span><span class="s1">order + </span><span class="s3">1</span><span class="s1">)]</span>
    <span class="s1">M = np.stack(xs</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">{</span><span class="s2">&quot;total&quot;</span><span class="s1">: total</span><span class="s0">, </span><span class="s2">&quot;n&quot;</span><span class="s1">: n</span><span class="s0">, </span><span class="s2">&quot;M&quot;</span><span class="s1">: M}</span>


<span class="s0">def </span><span class="s1">_moment_helper(Ms</span><span class="s0">, </span><span class="s1">ns</span><span class="s0">, </span><span class="s1">inner_term</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">sum</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">kwargs):</span>
    <span class="s1">M = Ms[...</span><span class="s0">, </span><span class="s1">order - </span><span class="s3">2</span><span class="s1">].sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs) + sum(</span>
        <span class="s1">ns * inner_term**order</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">**kwargs</span>
    <span class="s1">)</span>
    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">order - </span><span class="s3">1</span><span class="s1">):</span>
        <span class="s1">coeff = math.factorial(order) / (math.factorial(k) * math.factorial(order - k))</span>
        <span class="s1">M += coeff * sum(Ms[...</span><span class="s0">, </span><span class="s1">order - k - </span><span class="s3">2</span><span class="s1">] * inner_term**k</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s0">return </span><span class="s1">M</span>


<span class="s0">def </span><span class="s1">moment_combine(</span>
    <span class="s1">pairs</span><span class="s0">,</span>
    <span class="s1">order=</span><span class="s3">2</span><span class="s0">,</span>
    <span class="s1">ddof=</span><span class="s3">0</span><span class="s0">,</span>
    <span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">,</span>
    <span class="s1">sum=np.sum</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s0">None,</span>
    <span class="s1">computing_meta=</span><span class="s0">False,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s0">if not </span><span class="s1">isinstance(pairs</span><span class="s0">, </span><span class="s1">list):</span>
        <span class="s1">pairs = [pairs]</span>

    <span class="s1">kwargs[</span><span class="s2">&quot;dtype&quot;</span><span class="s1">] = </span><span class="s0">None</span>
    <span class="s1">kwargs[</span><span class="s2">&quot;keepdims&quot;</span><span class="s1">] = </span><span class="s0">True</span>

    <span class="s1">ns = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;n&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs) </span><span class="s0">if not </span><span class="s1">computing_meta </span><span class="s0">else </span><span class="s1">pairs</span>
    <span class="s1">ns = _concatenate2(ns</span><span class="s0">, </span><span class="s1">axes=axis)</span>
    <span class="s1">n = ns.sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">n</span>

    <span class="s1">totals = _concatenate2(deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;total&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span><span class="s0">, </span><span class="s1">axes=axis)</span>
    <span class="s1">Ms = _concatenate2(deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;M&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span><span class="s0">, </span><span class="s1">axes=axis)</span>

    <span class="s1">total = totals.sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s2">&quot;ignore&quot;</span><span class="s1">):</span>
        <span class="s0">if </span><span class="s1">np.issubdtype(total.dtype</span><span class="s0">, </span><span class="s1">np.complexfloating):</span>
            <span class="s1">mu = divide(total</span><span class="s0">, </span><span class="s1">n)</span>
            <span class="s1">inner_term = np.abs(divide(totals</span><span class="s0">, </span><span class="s1">ns) - mu)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">mu = divide(total</span><span class="s0">, </span><span class="s1">n</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
            <span class="s1">inner_term = divide(totals</span><span class="s0">, </span><span class="s1">ns</span><span class="s0">, </span><span class="s1">dtype=dtype) - mu</span>

    <span class="s1">xs = [</span>
        <span class="s1">_moment_helper(Ms</span><span class="s0">, </span><span class="s1">ns</span><span class="s0">, </span><span class="s1">inner_term</span><span class="s0">, </span><span class="s1">o</span><span class="s0">, </span><span class="s1">sum</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">kwargs)</span>
        <span class="s0">for </span><span class="s1">o </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">2</span><span class="s0">, </span><span class="s1">order + </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">]</span>
    <span class="s1">M = np.stack(xs</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">{</span><span class="s2">&quot;total&quot;</span><span class="s1">: total</span><span class="s0">, </span><span class="s2">&quot;n&quot;</span><span class="s1">: n</span><span class="s0">, </span><span class="s2">&quot;M&quot;</span><span class="s1">: M}</span>


<span class="s0">def </span><span class="s1">moment_agg(</span>
    <span class="s1">pairs</span><span class="s0">,</span>
    <span class="s1">order=</span><span class="s3">2</span><span class="s0">,</span>
    <span class="s1">ddof=</span><span class="s3">0</span><span class="s0">,</span>
    <span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">,</span>
    <span class="s1">sum=np.sum</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s0">None,</span>
    <span class="s1">computing_meta=</span><span class="s0">False,</span>
    <span class="s1">**kwargs</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s0">if not </span><span class="s1">isinstance(pairs</span><span class="s0">, </span><span class="s1">list):</span>
        <span class="s1">pairs = [pairs]</span>

    <span class="s1">kwargs[</span><span class="s2">&quot;dtype&quot;</span><span class="s1">] = dtype</span>
    <span class="s5"># To properly handle ndarrays, the original dimensions need to be kept for</span>
    <span class="s5"># part of the calculation.</span>
    <span class="s1">keepdim_kw = kwargs.copy()</span>
    <span class="s1">keepdim_kw[</span><span class="s2">&quot;keepdims&quot;</span><span class="s1">] = </span><span class="s0">True</span>
    <span class="s1">keepdim_kw[</span><span class="s2">&quot;dtype&quot;</span><span class="s1">] = </span><span class="s0">None</span>

    <span class="s1">ns = deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;n&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs) </span><span class="s0">if not </span><span class="s1">computing_meta </span><span class="s0">else </span><span class="s1">pairs</span>
    <span class="s1">ns = _concatenate2(ns</span><span class="s0">, </span><span class="s1">axes=axis)</span>
    <span class="s1">n = ns.sum(axis=axis</span><span class="s0">, </span><span class="s1">**keepdim_kw)</span>

    <span class="s0">if </span><span class="s1">computing_meta:</span>
        <span class="s0">return </span><span class="s1">n</span>

    <span class="s1">totals = _concatenate2(deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;total&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span><span class="s0">, </span><span class="s1">axes=axis)</span>
    <span class="s1">Ms = _concatenate2(deepmap(</span><span class="s0">lambda </span><span class="s1">pair: pair[</span><span class="s2">&quot;M&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">pairs)</span><span class="s0">, </span><span class="s1">axes=axis)</span>

    <span class="s1">mu = divide(totals.sum(axis=axis</span><span class="s0">, </span><span class="s1">**keepdim_kw)</span><span class="s0">, </span><span class="s1">n)</span>

    <span class="s0">with </span><span class="s1">np.errstate(divide=</span><span class="s2">&quot;ignore&quot;</span><span class="s0">, </span><span class="s1">invalid=</span><span class="s2">&quot;ignore&quot;</span><span class="s1">):</span>
        <span class="s0">if </span><span class="s1">np.issubdtype(totals.dtype</span><span class="s0">, </span><span class="s1">np.complexfloating):</span>
            <span class="s1">inner_term = np.abs(divide(totals</span><span class="s0">, </span><span class="s1">ns) - mu)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">inner_term = divide(totals</span><span class="s0">, </span><span class="s1">ns</span><span class="s0">, </span><span class="s1">dtype=dtype) - mu</span>

    <span class="s1">M = _moment_helper(Ms</span><span class="s0">, </span><span class="s1">ns</span><span class="s0">, </span><span class="s1">inner_term</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">sum</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">kwargs)</span>

    <span class="s1">denominator = n.sum(axis=axis</span><span class="s0">, </span><span class="s1">**kwargs) - ddof</span>

    <span class="s5"># taking care of the edge case with empty or all-nans array with ddof &gt; 0</span>
    <span class="s0">if </span><span class="s1">isinstance(denominator</span><span class="s0">, </span><span class="s1">Number):</span>
        <span class="s0">if </span><span class="s1">denominator &lt; </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s1">denominator = np.nan</span>
    <span class="s0">elif </span><span class="s1">denominator </span><span class="s0">is not </span><span class="s1">np.ma.masked:</span>
        <span class="s1">denominator[denominator &lt; </span><span class="s3">0</span><span class="s1">] = np.nan</span>

    <span class="s0">return </span><span class="s1">divide(M</span><span class="s0">, </span><span class="s1">denominator</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>


<span class="s0">def </span><span class="s1">moment(</span>
    <span class="s1">a</span><span class="s0">, </span><span class="s1">order</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Calculate the nth centralized moment. 
 
    Parameters 
    ---------- 
    a : Array 
        Data over which to compute moment 
    order : int 
        Order of the moment that is returned, must be &gt;= 2. 
    axis : int, optional 
        Axis along which the central moment is computed. The default is to 
        compute the moment of the flattened array. 
    dtype : data-type, optional 
        Type to use in computing the moment. For arrays of integer type the 
        default is float64; for arrays of float types it is the same as the 
        array type. 
    keepdims : bool, optional 
        If this is set to True, the axes which are reduced are left in the 
        result as dimensions with size one. With this option, the result 
        will broadcast correctly against the original array. 
    ddof : int, optional 
        &quot;Delta Degrees of Freedom&quot;: the divisor used in the calculation is 
        N - ddof, where N represents the number of elements. By default 
        ddof is zero. 
 
    Returns 
    ------- 
    moment : Array 
 
    References 
    ---------- 
    .. [1] Pebay, Philippe (2008), &quot;Formulas for Robust, One-Pass Parallel 
        Computation of Covariances and Arbitrary-Order Statistical Moments&quot;, 
        Technical Report SAND2008-6212, Sandia National Laboratories. 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if not </span><span class="s1">isinstance(order</span><span class="s0">, </span><span class="s1">Integral) </span><span class="s0">or </span><span class="s1">order &lt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Order must be an integer &gt;= 0&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">order &lt; </span><span class="s3">2</span><span class="s1">:</span>
        <span class="s1">reduced = a.sum(axis=axis)  </span><span class="s5"># get reduced shape and chunks</span>
        <span class="s0">if </span><span class="s1">order == </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s5"># When order equals 0, the result is 1, by definition.</span>
            <span class="s0">return </span><span class="s1">ones(</span>
                <span class="s1">reduced.shape</span><span class="s0">, </span><span class="s1">chunks=reduced.chunks</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">, </span><span class="s1">meta=reduced._meta</span>
            <span class="s1">)</span>
        <span class="s5"># By definition the first order about the mean is 0.</span>
        <span class="s0">return </span><span class="s1">zeros(</span>
            <span class="s1">reduced.shape</span><span class="s0">, </span><span class="s1">chunks=reduced.chunks</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s2">&quot;f8&quot;</span><span class="s0">, </span><span class="s1">meta=reduced._meta</span>
        <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.var(np.ones(shape=(</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>

    <span class="s1">implicit_complex_dtype = dtype </span><span class="s0">is None and </span><span class="s1">np.iscomplexobj(a)</span>

    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(</span>
            <span class="s1">moment_chunk</span><span class="s0">, </span><span class="s1">order=order</span><span class="s0">, </span><span class="s1">implicit_complex_dtype=implicit_complex_dtype</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">partial(moment_agg</span><span class="s0">, </span><span class="s1">order=order</span><span class="s0">, </span><span class="s1">ddof=ddof)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
        <span class="s1">combine=partial(moment_combine</span><span class="s0">, </span><span class="s1">order=order)</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">var(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.var(np.ones(shape=(</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>

    <span class="s1">implicit_complex_dtype = dtype </span><span class="s0">is None and </span><span class="s1">np.iscomplexobj(a)</span>

    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(moment_chunk</span><span class="s0">, </span><span class="s1">implicit_complex_dtype=implicit_complex_dtype)</span><span class="s0">,</span>
        <span class="s1">partial(moment_agg</span><span class="s0">, </span><span class="s1">ddof=ddof)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">combine=moment_combine</span><span class="s0">,</span>
        <span class="s1">name=</span><span class="s2">&quot;var&quot;</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanvar(</span>
    <span class="s1">a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span>
<span class="s1">):</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">dt = dtype</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">dt = getattr(np.var(np.ones(shape=(</span><span class="s3">1</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=a.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>

    <span class="s1">implicit_complex_dtype = dtype </span><span class="s0">is None and </span><span class="s1">np.iscomplexobj(a)</span>

    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(</span>
            <span class="s1">moment_chunk</span><span class="s0">,</span>
            <span class="s1">sum=chunk.nansum</span><span class="s0">,</span>
            <span class="s1">numel=nannumel</span><span class="s0">,</span>
            <span class="s1">implicit_complex_dtype=implicit_complex_dtype</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">partial(moment_agg</span><span class="s0">, </span><span class="s1">sum=np.nansum</span><span class="s0">, </span><span class="s1">ddof=ddof)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dt</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">combine=partial(moment_combine</span><span class="s0">, </span><span class="s1">sum=np.nansum)</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">_sqrt(a):</span>
    <span class="s1">o = np.sqrt(a)</span>
    <span class="s0">if </span><span class="s1">isinstance(o</span><span class="s0">, </span><span class="s1">np.ma.masked_array) </span><span class="s0">and not </span><span class="s1">o.shape </span><span class="s0">and </span><span class="s1">o.mask.all():</span>
        <span class="s0">return </span><span class="s1">np.ma.masked</span>
    <span class="s0">return </span><span class="s1">o</span>


<span class="s0">def </span><span class="s1">safe_sqrt(a):</span>
    <span class="s4">&quot;&quot;&quot;A version of sqrt that properly handles scalar masked arrays. 
 
    To mimic ``np.ma`` reductions, we need to convert scalar masked arrays that 
    have an active mask to the ``np.ma.masked`` singleton. This is properly 
    handled automatically for reduction code, but not for ufuncs. We implement 
    a simple version here, since calling `np.ma.sqrt` everywhere is 
    significantly more expensive. 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">hasattr(a</span><span class="s0">, </span><span class="s2">&quot;_elemwise&quot;</span><span class="s1">):</span>
        <span class="s0">return </span><span class="s1">a._elemwise(_sqrt</span><span class="s0">, </span><span class="s1">a)</span>
    <span class="s0">return </span><span class="s1">_sqrt(a)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">std(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s1">result = safe_sqrt(</span>
        <span class="s1">var(</span>
            <span class="s1">a</span><span class="s0">,</span>
            <span class="s1">axis=axis</span><span class="s0">,</span>
            <span class="s1">dtype=dtype</span><span class="s0">,</span>
            <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
            <span class="s1">ddof=ddof</span><span class="s0">,</span>
            <span class="s1">split_every=split_every</span><span class="s0">,</span>
            <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">and </span><span class="s1">dtype != result.dtype:</span>
        <span class="s1">result = result.astype(dtype)</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanstd(</span>
    <span class="s1">a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">ddof=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span>
<span class="s1">):</span>
    <span class="s1">result = safe_sqrt(</span>
        <span class="s1">nanvar(</span>
            <span class="s1">a</span><span class="s0">,</span>
            <span class="s1">axis=axis</span><span class="s0">,</span>
            <span class="s1">dtype=dtype</span><span class="s0">,</span>
            <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
            <span class="s1">ddof=ddof</span><span class="s0">,</span>
            <span class="s1">split_every=split_every</span><span class="s0">,</span>
            <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">and </span><span class="s1">dtype != result.dtype:</span>
        <span class="s1">result = result.astype(dtype)</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s0">def </span><span class="s1">_arg_combine(data</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">argfunc</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">False</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Merge intermediate results from ``arg_*`` functions&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">isinstance(data</span><span class="s0">, </span><span class="s1">dict):</span>
        <span class="s5"># Array type doesn't support structured arrays (e.g., CuPy),</span>
        <span class="s5"># therefore `data` is stored in a `dict`.</span>
        <span class="s0">assert </span><span class="s1">data[</span><span class="s2">&quot;vals&quot;</span><span class="s1">].ndim == data[</span><span class="s2">&quot;arg&quot;</span><span class="s1">].ndim</span>
        <span class="s1">axis = (</span>
            <span class="s0">None</span>
            <span class="s0">if </span><span class="s1">len(axis) == data[</span><span class="s2">&quot;vals&quot;</span><span class="s1">].ndim </span><span class="s0">or </span><span class="s1">data[</span><span class="s2">&quot;vals&quot;</span><span class="s1">].ndim == </span><span class="s3">1</span>
            <span class="s0">else </span><span class="s1">axis[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">axis = </span><span class="s0">None if </span><span class="s1">len(axis) == data.ndim </span><span class="s0">or </span><span class="s1">data.ndim == </span><span class="s3">1 </span><span class="s0">else </span><span class="s1">axis[</span><span class="s3">0</span><span class="s1">]</span>

    <span class="s1">vals = data[</span><span class="s2">&quot;vals&quot;</span><span class="s1">]</span>
    <span class="s1">arg = data[</span><span class="s2">&quot;arg&quot;</span><span class="s1">]</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">local_args = argfunc(vals</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>
        <span class="s1">vals = vals.ravel()[local_args]</span>
        <span class="s1">arg = arg.ravel()[local_args]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">local_args = argfunc(vals</span><span class="s0">, </span><span class="s1">axis=axis)</span>
        <span class="s1">inds = np.ogrid[tuple(map(slice</span><span class="s0">, </span><span class="s1">local_args.shape))]</span>
        <span class="s1">inds.insert(axis</span><span class="s0">, </span><span class="s1">local_args)</span>
        <span class="s1">inds = tuple(inds)</span>
        <span class="s1">vals = vals[inds]</span>
        <span class="s1">arg = arg[inds]</span>
        <span class="s0">if </span><span class="s1">keepdims:</span>
            <span class="s1">vals = np.expand_dims(vals</span><span class="s0">, </span><span class="s1">axis)</span>
            <span class="s1">arg = np.expand_dims(arg</span><span class="s0">, </span><span class="s1">axis)</span>
    <span class="s0">return </span><span class="s1">arg</span><span class="s0">, </span><span class="s1">vals</span>


<span class="s0">def </span><span class="s1">arg_chunk(func</span><span class="s0">, </span><span class="s1">argfunc</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">offset_info):</span>
    <span class="s1">arg_axis = </span><span class="s0">None if </span><span class="s1">len(axis) == x.ndim </span><span class="s0">or </span><span class="s1">x.ndim == </span><span class="s3">1 </span><span class="s0">else </span><span class="s1">axis[</span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">vals = func(x</span><span class="s0">, </span><span class="s1">axis=arg_axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">arg = argfunc(x</span><span class="s0">, </span><span class="s1">axis=arg_axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">x.ndim &gt; </span><span class="s3">0</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">arg_axis </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">offset</span><span class="s0">, </span><span class="s1">total_shape = offset_info</span>
            <span class="s1">ind = np.unravel_index(arg.ravel()[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x.shape)</span>
            <span class="s1">total_ind = tuple(o + i </span><span class="s0">for </span><span class="s1">(o</span><span class="s0">, </span><span class="s1">i) </span><span class="s0">in </span><span class="s1">zip(offset</span><span class="s0">, </span><span class="s1">ind))</span>
            <span class="s1">arg[:] = np.ravel_multi_index(total_ind</span><span class="s0">, </span><span class="s1">total_shape)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">arg += offset_info</span>

    <span class="s0">if </span><span class="s1">isinstance(vals</span><span class="s0">, </span><span class="s1">np.ma.masked_array):</span>
        <span class="s0">if </span><span class="s2">&quot;min&quot; </span><span class="s0">in </span><span class="s1">argfunc.__name__:</span>
            <span class="s1">fill_value = np.ma.minimum_fill_value(vals)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">fill_value = np.ma.maximum_fill_value(vals)</span>
        <span class="s1">vals = np.ma.filled(vals</span><span class="s0">, </span><span class="s1">fill_value)</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">result = np.empty_like(</span>
            <span class="s1">vals</span><span class="s0">, </span><span class="s1">shape=vals.shape</span><span class="s0">, </span><span class="s1">dtype=[(</span><span class="s2">&quot;vals&quot;</span><span class="s0">, </span><span class="s1">vals.dtype)</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;arg&quot;</span><span class="s0">, </span><span class="s1">arg.dtype)]</span>
        <span class="s1">)</span>
    <span class="s0">except </span><span class="s1">TypeError:</span>
        <span class="s5"># Array type doesn't support structured arrays (e.g., CuPy)</span>
        <span class="s1">result = dict()</span>

    <span class="s1">result[</span><span class="s2">&quot;vals&quot;</span><span class="s1">] = vals</span>
    <span class="s1">result[</span><span class="s2">&quot;arg&quot;</span><span class="s1">] = arg</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s0">def </span><span class="s1">arg_combine(argfunc</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">**kwargs):</span>
    <span class="s1">arg</span><span class="s0">, </span><span class="s1">vals = _arg_combine(data</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">argfunc</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True</span><span class="s1">)</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">result = np.empty_like(</span>
            <span class="s1">vals</span><span class="s0">, </span><span class="s1">shape=vals.shape</span><span class="s0">, </span><span class="s1">dtype=[(</span><span class="s2">&quot;vals&quot;</span><span class="s0">, </span><span class="s1">vals.dtype)</span><span class="s0">, </span><span class="s1">(</span><span class="s2">&quot;arg&quot;</span><span class="s0">, </span><span class="s1">arg.dtype)]</span>
        <span class="s1">)</span>
    <span class="s0">except </span><span class="s1">TypeError:</span>
        <span class="s5"># Array type doesn't support structured arrays (e.g., CuPy).</span>
        <span class="s1">result = dict()</span>

    <span class="s1">result[</span><span class="s2">&quot;vals&quot;</span><span class="s1">] = vals</span>
    <span class="s1">result[</span><span class="s2">&quot;arg&quot;</span><span class="s1">] = arg</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s0">def </span><span class="s1">arg_agg(argfunc</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">**kwargs):</span>
    <span class="s0">return </span><span class="s1">_arg_combine(data</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">argfunc</span><span class="s0">, </span><span class="s1">keepdims=keepdims)[</span><span class="s3">0</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">nanarg_agg(argfunc</span><span class="s0">, </span><span class="s1">data</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">**kwargs):</span>
    <span class="s1">arg</span><span class="s0">, </span><span class="s1">vals = _arg_combine(data</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">argfunc</span><span class="s0">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s0">if </span><span class="s1">np.any(np.isnan(vals)):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;All NaN slice encountered&quot;</span><span class="s1">)</span>
    <span class="s0">return </span><span class="s1">arg</span>


<span class="s0">def </span><span class="s1">arg_reduction(</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">chunk</span><span class="s0">, </span><span class="s1">combine</span><span class="s0">, </span><span class="s1">agg</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Generic function for argreduction. 
 
    Parameters 
    ---------- 
    x : Array 
    chunk : callable 
        Partialed ``arg_chunk``. 
    combine : callable 
        Partialed ``arg_combine``. 
    agg : callable 
        Partialed ``arg_agg``. 
    axis : int, optional 
    split_every : int or dict, optional 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">axis = tuple(range(x.ndim))</span>
        <span class="s1">ravel = </span><span class="s0">True</span>
    <span class="s0">elif </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Integral):</span>
        <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">x.ndim)</span>
        <span class="s1">axis = (axis</span><span class="s0">,</span><span class="s1">)</span>
        <span class="s1">ravel = x.ndim == </span><span class="s3">1</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s2">f&quot;axis must be either `None` or int, got '</span><span class="s0">{</span><span class="s1">axis</span><span class="s0">}</span><span class="s2">'&quot;</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis:</span>
        <span class="s1">chunks = x.chunks[ax]</span>
        <span class="s0">if </span><span class="s1">len(chunks) &gt; </span><span class="s3">1 </span><span class="s0">and </span><span class="s1">np.isnan(chunks).any():</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">&quot;Arg-reductions do not work with arrays that have &quot;</span>
                <span class="s2">&quot;unknown chunksizes. At some point in your computation &quot;</span>
                <span class="s2">&quot;this array lost chunking information.</span><span class="s0">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;A possible solution is with </span><span class="s0">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;  x.compute_chunk_sizes()&quot;</span>
            <span class="s1">)</span>

    <span class="s5"># Map chunk across all blocks</span>
    <span class="s1">name = </span><span class="s2">f&quot;arg-reduce-</span><span class="s0">{</span><span class="s1">tokenize(axis</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">chunk</span><span class="s0">, </span><span class="s1">combine</span><span class="s0">, </span><span class="s1">split_every)</span><span class="s0">}</span><span class="s2">&quot;</span>
    <span class="s1">old = x.name</span>
    <span class="s1">keys = list(product(*map(range</span><span class="s0">, </span><span class="s1">x.numblocks)))</span>
    <span class="s1">offsets = list(product(*(accumulate(operator.add</span><span class="s0">, </span><span class="s1">bd[:-</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s3">0</span><span class="s1">) </span><span class="s0">for </span><span class="s1">bd </span><span class="s0">in </span><span class="s1">x.chunks)))</span>
    <span class="s0">if </span><span class="s1">ravel:</span>
        <span class="s1">offset_info = zip(offsets</span><span class="s0">, </span><span class="s1">repeat(x.shape))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">offset_info = pluck(axis[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">offsets)</span>

    <span class="s1">chunks = tuple((</span><span class="s3">1</span><span class="s0">,</span><span class="s1">) * len(c) </span><span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s1">c </span><span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">c) </span><span class="s0">in </span><span class="s1">enumerate(x.chunks))</span>
    <span class="s1">dsk = {</span>
        <span class="s1">(name</span><span class="s0">,</span><span class="s1">) + k: (chunk</span><span class="s0">, </span><span class="s1">(old</span><span class="s0">,</span><span class="s1">) + k</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">off)</span>
        <span class="s0">for </span><span class="s1">(k</span><span class="s0">, </span><span class="s1">off) </span><span class="s0">in </span><span class="s1">zip(keys</span><span class="s0">, </span><span class="s1">offset_info)</span>
    <span class="s1">}</span>

    <span class="s1">dtype = np.argmin(asarray_safe([</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">like=meta_from_array(x)))</span>
    <span class="s1">meta = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">is_arraylike(dtype):</span>
        <span class="s5"># This case occurs on non-NumPy types (e.g., CuPy), where the returned</span>
        <span class="s5"># value is an ndarray rather than a scalar.</span>
        <span class="s1">meta = dtype</span>
        <span class="s1">dtype = meta.dtype</span>

    <span class="s1">graph = HighLevelGraph.from_collections(name</span><span class="s0">, </span><span class="s1">dsk</span><span class="s0">, </span><span class="s1">dependencies=[x])</span>
    <span class="s1">tmp = Array(graph</span><span class="s0">, </span><span class="s1">name</span><span class="s0">, </span><span class="s1">chunks</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">meta=meta)</span>

    <span class="s1">result = _tree_reduce(</span>
        <span class="s1">tmp</span><span class="s0">,</span>
        <span class="s1">agg</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">dtype=dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">combine=combine</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>


<span class="s0">def </span><span class="s1">_nanargmin(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">chunk.nanargmin(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s0">except </span><span class="s1">ValueError:</span>
        <span class="s0">return </span><span class="s1">chunk.nanargmin(np.where(np.isnan(x)</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">x)</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s0">def </span><span class="s1">_nanargmax(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">chunk.nanargmax(x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s0">except </span><span class="s1">ValueError:</span>
        <span class="s0">return </span><span class="s1">chunk.nanargmax(np.where(np.isnan(x)</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">x)</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">argmax(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">arg_reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(arg_chunk</span><span class="s0">, </span><span class="s1">chunk.max</span><span class="s0">, </span><span class="s1">chunk.argmax)</span><span class="s0">,</span>
        <span class="s1">partial(arg_combine</span><span class="s0">, </span><span class="s1">chunk.argmax)</span><span class="s0">,</span>
        <span class="s1">partial(arg_agg</span><span class="s0">, </span><span class="s1">chunk.argmax)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">argmin(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">arg_reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(arg_chunk</span><span class="s0">, </span><span class="s1">chunk.min</span><span class="s0">, </span><span class="s1">chunk.argmin)</span><span class="s0">,</span>
        <span class="s1">partial(arg_combine</span><span class="s0">, </span><span class="s1">chunk.argmin)</span><span class="s0">,</span>
        <span class="s1">partial(arg_agg</span><span class="s0">, </span><span class="s1">chunk.argmin)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanargmax(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">arg_reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(arg_chunk</span><span class="s0">, </span><span class="s1">chunk.nanmax</span><span class="s0">, </span><span class="s1">_nanargmax)</span><span class="s0">,</span>
        <span class="s1">partial(arg_combine</span><span class="s0">, </span><span class="s1">_nanargmax)</span><span class="s0">,</span>
        <span class="s1">partial(nanarg_agg</span><span class="s0">, </span><span class="s1">_nanargmax)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanargmin(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">split_every=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">arg_reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">partial(arg_chunk</span><span class="s0">, </span><span class="s1">chunk.nanmin</span><span class="s0">, </span><span class="s1">_nanargmin)</span><span class="s0">,</span>
        <span class="s1">partial(arg_combine</span><span class="s0">, </span><span class="s1">_nanargmin)</span><span class="s0">,</span>
        <span class="s1">partial(nanarg_agg</span><span class="s0">, </span><span class="s1">_nanargmin)</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">_prefixscan_combine(func</span><span class="s0">, </span><span class="s1">binop</span><span class="s0">, </span><span class="s1">pre</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">dtype):</span>
    <span class="s4">&quot;&quot;&quot;Combine results of a parallel prefix scan such as cumsum 
 
    Parameters 
    ---------- 
    func : callable 
        Cumulative function (e.g. ``np.cumsum``) 
    binop : callable 
        Associative function (e.g. ``add``) 
    pre : np.array 
        The value calculated in parallel from ``preop``. 
        For example, the sum of all the previous blocks. 
    x : np.array 
        Current block 
    axis : int 
    dtype : dtype 
 
    Returns 
    ------- 
    np.array 
    &quot;&quot;&quot;</span>
    <span class="s5"># We could compute this in two tasks.</span>
    <span class="s5"># This would allow us to do useful work (i.e., func), while waiting on `pre`.</span>
    <span class="s5"># Using one task may guide the scheduler to do better and reduce scheduling overhead.</span>
    <span class="s0">return </span><span class="s1">binop(pre</span><span class="s0">, </span><span class="s1">func(x</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">dtype=dtype))</span>


<span class="s0">def </span><span class="s1">_prefixscan_first(func</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">dtype):</span>
    <span class="s4">&quot;&quot;&quot;Compute the prefix scan (e.g., cumsum) on the first block 
 
    Parameters 
    ---------- 
    func : callable 
        Cumulative function (e.g. ``np.cumsum``) 
    x : np.array 
        Current block 
    axis : int 
    dtype : dtype 
 
    Returns 
    ------- 
    np.array 
    &quot;&quot;&quot;</span>
    <span class="s0">return </span><span class="s1">func(x</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>


<span class="s0">def </span><span class="s1">prefixscan_blelloch(func</span><span class="s0">, </span><span class="s1">preop</span><span class="s0">, </span><span class="s1">binop</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Generic function to perform parallel cumulative scan (a.k.a prefix scan) 
 
    The Blelloch prefix scan is work-efficient and exposes parallelism. 
    A parallel cumsum works by first taking the sum of each block, then do a binary tree 
    merge followed by a fan-out (i.e., the Brent-Kung pattern).  We then take the cumsum 
    of each block and add the sum of the previous blocks. 
 
    When performing a cumsum across N chunks, this method has 2 * lg(N) levels of dependencies. 
    In contrast, the sequential method has N levels of dependencies. 
 
    Floating point operations should be more accurate with this method compared to sequential. 
 
    Parameters 
    ---------- 
    func : callable 
        Cumulative function (e.g. ``np.cumsum``) 
    preop : callable 
        Function to get the final value of a cumulative function (e.g., ``np.sum``) 
    binop : callable 
        Associative function (e.g. ``add``) 
    x : dask array 
    axis : int 
    dtype : dtype 
 
    Returns 
    ------- 
    dask array 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">x = x.flatten().rechunk(chunks=x.npartitions)</span>
        <span class="s1">axis = </span><span class="s3">0</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">dtype = getattr(func(np.ones((</span><span class="s3">0</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=x.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">assert </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Integral)</span>
    <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">x.ndim)</span>
    <span class="s1">name = </span><span class="s2">f&quot;</span><span class="s0">{</span><span class="s1">func.__name__</span><span class="s0">}</span><span class="s2">-</span><span class="s0">{</span><span class="s1">tokenize(func</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">preop</span><span class="s0">, </span><span class="s1">binop</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">dtype)</span><span class="s0">}</span><span class="s2">&quot;</span>
    <span class="s1">base_key = (name</span><span class="s0">,</span><span class="s1">)</span>

    <span class="s5"># Right now, the metadata for batches is incorrect, but this should be okay</span>
    <span class="s1">batches = x.map_blocks(preop</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">keepdims=</span><span class="s0">True, </span><span class="s1">dtype=dtype)</span>
    <span class="s5"># We don't need the last index until the end</span>
    <span class="s1">*indices</span><span class="s0">, </span><span class="s1">last_index = full_indices = [</span>
        <span class="s1">list(</span>
            <span class="s1">product(</span>
                <span class="s1">*[range(nb) </span><span class="s0">if </span><span class="s1">j != axis </span><span class="s0">else </span><span class="s1">[i] </span><span class="s0">for </span><span class="s1">j</span><span class="s0">, </span><span class="s1">nb </span><span class="s0">in </span><span class="s1">enumerate(x.numblocks)]</span>
            <span class="s1">)</span>
        <span class="s1">)</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(x.numblocks[axis])</span>
    <span class="s1">]</span>
    <span class="s1">prefix_vals = [[(batches.name</span><span class="s0">,</span><span class="s1">) + index </span><span class="s0">for </span><span class="s1">index </span><span class="s0">in </span><span class="s1">vals] </span><span class="s0">for </span><span class="s1">vals </span><span class="s0">in </span><span class="s1">indices]</span>
    <span class="s1">dsk = {}</span>
    <span class="s1">n_vals = len(prefix_vals)</span>
    <span class="s1">level = </span><span class="s3">0</span>
    <span class="s0">if </span><span class="s1">n_vals &gt;= </span><span class="s3">2</span><span class="s1">:</span>
        <span class="s5"># Upsweep</span>
        <span class="s1">stride = </span><span class="s3">1</span>
        <span class="s1">stride2 = </span><span class="s3">2</span>
        <span class="s0">while </span><span class="s1">stride2 &lt;= n_vals:</span>
            <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(stride2 - </span><span class="s3">1</span><span class="s0">, </span><span class="s1">n_vals</span><span class="s0">, </span><span class="s1">stride2):</span>
                <span class="s1">new_vals = []</span>
                <span class="s0">for </span><span class="s1">index</span><span class="s0">, </span><span class="s1">left_val</span><span class="s0">, </span><span class="s1">right_val </span><span class="s0">in </span><span class="s1">zip(</span>
                    <span class="s1">indices[i]</span><span class="s0">, </span><span class="s1">prefix_vals[i - stride]</span><span class="s0">, </span><span class="s1">prefix_vals[i]</span>
                <span class="s1">):</span>
                    <span class="s1">key = base_key + index + (level</span><span class="s0">, </span><span class="s1">i)</span>
                    <span class="s1">dsk[key] = (binop</span><span class="s0">, </span><span class="s1">left_val</span><span class="s0">, </span><span class="s1">right_val)</span>
                    <span class="s1">new_vals.append(key)</span>
                <span class="s1">prefix_vals[i] = new_vals</span>
            <span class="s1">stride = stride2</span>
            <span class="s1">stride2 *= </span><span class="s3">2</span>
            <span class="s1">level += </span><span class="s3">1</span>

        <span class="s5"># Downsweep</span>
        <span class="s5"># With `n_vals == 3`, we would have `stride = 1` and `stride = 0`, but we need</span>
        <span class="s5"># to do a downsweep iteration, so make sure stride2 is at least 2.</span>
        <span class="s1">stride2 = builtins.max(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">2 </span><span class="s1">** math.ceil(math.log2(n_vals // </span><span class="s3">2</span><span class="s1">)))</span>
        <span class="s1">stride = stride2 // </span><span class="s3">2</span>
        <span class="s0">while </span><span class="s1">stride &gt; </span><span class="s3">0</span><span class="s1">:</span>
            <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(stride2 + stride - </span><span class="s3">1</span><span class="s0">, </span><span class="s1">n_vals</span><span class="s0">, </span><span class="s1">stride2):</span>
                <span class="s1">new_vals = []</span>
                <span class="s0">for </span><span class="s1">index</span><span class="s0">, </span><span class="s1">left_val</span><span class="s0">, </span><span class="s1">right_val </span><span class="s0">in </span><span class="s1">zip(</span>
                    <span class="s1">indices[i]</span><span class="s0">, </span><span class="s1">prefix_vals[i - stride]</span><span class="s0">, </span><span class="s1">prefix_vals[i]</span>
                <span class="s1">):</span>
                    <span class="s1">key = base_key + index + (level</span><span class="s0">, </span><span class="s1">i)</span>
                    <span class="s1">dsk[key] = (binop</span><span class="s0">, </span><span class="s1">left_val</span><span class="s0">, </span><span class="s1">right_val)</span>
                    <span class="s1">new_vals.append(key)</span>
                <span class="s1">prefix_vals[i] = new_vals</span>
            <span class="s1">stride2 = stride</span>
            <span class="s1">stride //= </span><span class="s3">2</span>
            <span class="s1">level += </span><span class="s3">1</span>

    <span class="s0">if </span><span class="s1">full_indices:</span>
        <span class="s0">for </span><span class="s1">index </span><span class="s0">in </span><span class="s1">full_indices[</span><span class="s3">0</span><span class="s1">]:</span>
            <span class="s1">dsk[base_key + index] = (</span>
                <span class="s1">_prefixscan_first</span><span class="s0">,</span>
                <span class="s1">func</span><span class="s0">,</span>
                <span class="s1">(x.name</span><span class="s0">,</span><span class="s1">) + index</span><span class="s0">,</span>
                <span class="s1">axis</span><span class="s0">,</span>
                <span class="s1">dtype</span><span class="s0">,</span>
            <span class="s1">)</span>
        <span class="s0">for </span><span class="s1">indexes</span><span class="s0">, </span><span class="s1">vals </span><span class="s0">in </span><span class="s1">zip(drop(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">full_indices)</span><span class="s0">, </span><span class="s1">prefix_vals):</span>
            <span class="s0">for </span><span class="s1">index</span><span class="s0">, </span><span class="s1">val </span><span class="s0">in </span><span class="s1">zip(indexes</span><span class="s0">, </span><span class="s1">vals):</span>
                <span class="s1">dsk[base_key + index] = (</span>
                    <span class="s1">_prefixscan_combine</span><span class="s0">,</span>
                    <span class="s1">func</span><span class="s0">,</span>
                    <span class="s1">binop</span><span class="s0">,</span>
                    <span class="s1">val</span><span class="s0">,</span>
                    <span class="s1">(x.name</span><span class="s0">,</span><span class="s1">) + index</span><span class="s0">,</span>
                    <span class="s1">axis</span><span class="s0">,</span>
                    <span class="s1">dtype</span><span class="s0">,</span>
                <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">len(full_indices) &lt; </span><span class="s3">2</span><span class="s1">:</span>
        <span class="s1">deps = [x]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">deps = [x</span><span class="s0">, </span><span class="s1">batches]</span>
    <span class="s1">graph = HighLevelGraph.from_collections(name</span><span class="s0">, </span><span class="s1">dsk</span><span class="s0">, </span><span class="s1">dependencies=deps)</span>
    <span class="s1">result = Array(graph</span><span class="s0">, </span><span class="s1">name</span><span class="s0">, </span><span class="s1">x.chunks</span><span class="s0">, </span><span class="s1">batches.dtype)</span>
    <span class="s0">return </span><span class="s1">handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>


<span class="s0">def </span><span class="s1">cumreduction(</span>
    <span class="s1">func</span><span class="s0">,</span>
    <span class="s1">binop</span><span class="s0">,</span>
    <span class="s1">ident</span><span class="s0">,</span>
    <span class="s1">x</span><span class="s0">,</span>
    <span class="s1">axis=</span><span class="s0">None,</span>
    <span class="s1">dtype=</span><span class="s0">None,</span>
    <span class="s1">out=</span><span class="s0">None,</span>
    <span class="s1">method=</span><span class="s2">&quot;sequential&quot;</span><span class="s0">,</span>
    <span class="s1">preop=</span><span class="s0">None,</span>
<span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Generic function for cumulative reduction 
 
    Parameters 
    ---------- 
    func: callable 
        Cumulative function like np.cumsum or np.cumprod 
    binop: callable 
        Associated binary operator like ``np.cumsum-&gt;add`` or ``np.cumprod-&gt;mul`` 
    ident: Number 
        Associated identity like ``np.cumsum-&gt;0`` or ``np.cumprod-&gt;1`` 
    x: dask Array 
    axis: int 
    dtype: dtype 
    method : {'sequential', 'blelloch'}, optional 
        Choose which method to use to perform the cumsum.  Default is 'sequential'. 
 
        * 'sequential' performs the scan of each prior block before the current block. 
        * 'blelloch' is a work-efficient parallel scan.  It exposes parallelism by first 
          calling ``preop`` on each block and combines the values via a binary tree. 
          This method may be faster or more memory efficient depending on workload, 
          scheduler, and hardware.  More benchmarking is necessary. 
    preop: callable, optional 
        Function used by 'blelloch' method, 
        like ``np.cumsum-&gt;np.sum`` or ``np.cumprod-&gt;np.prod`` 
 
    Returns 
    ------- 
    dask array 
 
    See also 
    -------- 
    cumsum 
    cumprod 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">method == </span><span class="s2">&quot;blelloch&quot;</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">preop </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">TypeError(</span>
                <span class="s2">'cumreduction with &quot;blelloch&quot; method required `preop=` argument'</span>
            <span class="s1">)</span>
        <span class="s0">return </span><span class="s1">prefixscan_blelloch(func</span><span class="s0">, </span><span class="s1">preop</span><span class="s0">, </span><span class="s1">binop</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">dtype</span><span class="s0">, </span><span class="s1">out=out)</span>
    <span class="s0">elif </span><span class="s1">method != </span><span class="s2">&quot;sequential&quot;</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span>
            <span class="s2">f'Invalid method for cumreduction.  Expected &quot;sequential&quot; or &quot;blelloch&quot;.  Got: </span><span class="s0">{</span><span class="s1">method</span><span class="s0">!r}</span><span class="s2">'</span>
        <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">x = x.flatten().rechunk(chunks=x.npartitions)</span>
        <span class="s1">axis = </span><span class="s3">0</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">dtype = getattr(func(np.ones((</span><span class="s3">0</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=x.dtype))</span><span class="s0">, </span><span class="s2">&quot;dtype&quot;</span><span class="s0">, </span><span class="s1">object)</span>
    <span class="s0">assert </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Integral)</span>
    <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">x.ndim)</span>

    <span class="s1">m = x.map_blocks(func</span><span class="s0">, </span><span class="s1">axis=axis</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>

    <span class="s1">name = </span><span class="s2">f&quot;</span><span class="s0">{</span><span class="s1">func.__name__</span><span class="s0">}</span><span class="s2">-</span><span class="s0">{</span><span class="s1">tokenize(func</span><span class="s0">, </span><span class="s1">axis</span><span class="s0">, </span><span class="s1">binop</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">dtype)</span><span class="s0">}</span><span class="s2">&quot;</span>
    <span class="s1">n = x.numblocks[axis]</span>
    <span class="s1">full = slice(</span><span class="s0">None, None, None</span><span class="s1">)</span>
    <span class="s1">slc = (full</span><span class="s0">,</span><span class="s1">) * axis + (slice(-</span><span class="s3">1</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span><span class="s1">) + (full</span><span class="s0">,</span><span class="s1">) * (x.ndim - axis - </span><span class="s3">1</span><span class="s1">)</span>

    <span class="s1">indices = list(</span>
        <span class="s1">product(*[range(nb) </span><span class="s0">if </span><span class="s1">i != axis </span><span class="s0">else </span><span class="s1">[</span><span class="s3">0</span><span class="s1">] </span><span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">nb </span><span class="s0">in </span><span class="s1">enumerate(x.numblocks)])</span>
    <span class="s1">)</span>
    <span class="s1">dsk = dict()</span>
    <span class="s0">for </span><span class="s1">ind </span><span class="s0">in </span><span class="s1">indices:</span>
        <span class="s1">shape = tuple(x.chunks[i][ii] </span><span class="s0">if </span><span class="s1">i != axis </span><span class="s0">else </span><span class="s3">1 </span><span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">ii </span><span class="s0">in </span><span class="s1">enumerate(ind))</span>
        <span class="s1">dsk[(name</span><span class="s0">, </span><span class="s2">&quot;extra&quot;</span><span class="s1">) + ind] = (</span>
            <span class="s1">apply</span><span class="s0">,</span>
            <span class="s1">np.full_like</span><span class="s0">,</span>
            <span class="s1">(x._meta</span><span class="s0">, </span><span class="s1">ident</span><span class="s0">, </span><span class="s1">m.dtype)</span><span class="s0">,</span>
            <span class="s1">{</span><span class="s2">&quot;shape&quot;</span><span class="s1">: shape}</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">dsk[(name</span><span class="s0">,</span><span class="s1">) + ind] = (m.name</span><span class="s0">,</span><span class="s1">) + ind</span>

    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">n):</span>
        <span class="s1">last_indices = indices</span>
        <span class="s1">indices = list(</span>
            <span class="s1">product(</span>
                <span class="s1">*[range(nb) </span><span class="s0">if </span><span class="s1">ii != axis </span><span class="s0">else </span><span class="s1">[i] </span><span class="s0">for </span><span class="s1">ii</span><span class="s0">, </span><span class="s1">nb </span><span class="s0">in </span><span class="s1">enumerate(x.numblocks)]</span>
            <span class="s1">)</span>
        <span class="s1">)</span>
        <span class="s0">for </span><span class="s1">old</span><span class="s0">, </span><span class="s1">ind </span><span class="s0">in </span><span class="s1">zip(last_indices</span><span class="s0">, </span><span class="s1">indices):</span>
            <span class="s1">this_slice = (name</span><span class="s0">, </span><span class="s2">&quot;extra&quot;</span><span class="s1">) + ind</span>
            <span class="s1">dsk[this_slice] = (</span>
                <span class="s1">binop</span><span class="s0">,</span>
                <span class="s1">(name</span><span class="s0">, </span><span class="s2">&quot;extra&quot;</span><span class="s1">) + old</span><span class="s0">,</span>
                <span class="s1">(operator.getitem</span><span class="s0">, </span><span class="s1">(m.name</span><span class="s0">,</span><span class="s1">) + old</span><span class="s0">, </span><span class="s1">slc)</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">dsk[(name</span><span class="s0">,</span><span class="s1">) + ind] = (binop</span><span class="s0">, </span><span class="s1">this_slice</span><span class="s0">, </span><span class="s1">(m.name</span><span class="s0">,</span><span class="s1">) + ind)</span>

    <span class="s1">graph = HighLevelGraph.from_collections(name</span><span class="s0">, </span><span class="s1">dsk</span><span class="s0">, </span><span class="s1">dependencies=[m])</span>
    <span class="s1">result = Array(graph</span><span class="s0">, </span><span class="s1">name</span><span class="s0">, </span><span class="s1">x.chunks</span><span class="s0">, </span><span class="s1">m.dtype</span><span class="s0">, </span><span class="s1">meta=x._meta)</span>
    <span class="s0">return </span><span class="s1">handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>


<span class="s0">def </span><span class="s1">_cumsum_merge(a</span><span class="s0">, </span><span class="s1">b):</span>
    <span class="s0">if </span><span class="s1">isinstance(a</span><span class="s0">, </span><span class="s1">np.ma.masked_array) </span><span class="s0">or </span><span class="s1">isinstance(b</span><span class="s0">, </span><span class="s1">np.ma.masked_array):</span>
        <span class="s1">values = np.ma.getdata(a) + np.ma.getdata(b)</span>
        <span class="s0">return </span><span class="s1">np.ma.masked_array(values</span><span class="s0">, </span><span class="s1">mask=np.ma.getmaskarray(b))</span>
    <span class="s0">return </span><span class="s1">a + b</span>


<span class="s0">def </span><span class="s1">_cumprod_merge(a</span><span class="s0">, </span><span class="s1">b):</span>
    <span class="s0">if </span><span class="s1">isinstance(a</span><span class="s0">, </span><span class="s1">np.ma.masked_array) </span><span class="s0">or </span><span class="s1">isinstance(b</span><span class="s0">, </span><span class="s1">np.ma.masked_array):</span>
        <span class="s1">values = np.ma.getdata(a) * np.ma.getdata(b)</span>
        <span class="s0">return </span><span class="s1">np.ma.masked_array(values</span><span class="s0">, </span><span class="s1">mask=np.ma.getmaskarray(b))</span>
    <span class="s0">return </span><span class="s1">a * b</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">cumsum(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None, </span><span class="s1">method=</span><span class="s2">&quot;sequential&quot;</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Dask added an additional keyword-only argument ``method``. 
 
    method : {'sequential', 'blelloch'}, optional 
        Choose which method to use to perform the cumsum.  Default is 'sequential'. 
 
        * 'sequential' performs the cumsum of each prior block before the current block. 
        * 'blelloch' is a work-efficient parallel cumsum.  It exposes parallelism by 
          first taking the sum of each block and combines the sums via a binary tree. 
          This method may be faster or more memory efficient depending on workload, 
          scheduler, and hardware.  More benchmarking is necessary. 
    &quot;&quot;&quot;</span>
    <span class="s0">return </span><span class="s1">cumreduction(</span>
        <span class="s1">np.cumsum</span><span class="s0">,</span>
        <span class="s1">_cumsum_merge</span><span class="s0">,</span>
        <span class="s3">0</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">dtype</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
        <span class="s1">preop=np.sum</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">cumprod(x</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">out=</span><span class="s0">None, </span><span class="s1">method=</span><span class="s2">&quot;sequential&quot;</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Dask added an additional keyword-only argument ``method``. 
 
    method : {'sequential', 'blelloch'}, optional 
        Choose which method to use to perform the cumprod.  Default is 'sequential'. 
 
        * 'sequential' performs the cumprod of each prior block before the current block. 
        * 'blelloch' is a work-efficient parallel cumprod.  It exposes parallelism by first 
          taking the product of each block and combines the products via a binary tree. 
          This method may be faster or more memory efficient depending on workload, 
          scheduler, and hardware.  More benchmarking is necessary. 
    &quot;&quot;&quot;</span>
    <span class="s0">return </span><span class="s1">cumreduction(</span>
        <span class="s1">np.cumprod</span><span class="s0">,</span>
        <span class="s1">_cumprod_merge</span><span class="s0">,</span>
        <span class="s3">1</span><span class="s0">,</span>
        <span class="s1">x</span><span class="s0">,</span>
        <span class="s1">axis</span><span class="s0">,</span>
        <span class="s1">dtype</span><span class="s0">,</span>
        <span class="s1">out=out</span><span class="s0">,</span>
        <span class="s1">method=method</span><span class="s0">,</span>
        <span class="s1">preop=np.prod</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">topk(a</span><span class="s0">, </span><span class="s1">k</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Extract the k largest elements from a on the given axis, 
    and return them sorted from largest to smallest. 
    If k is negative, extract the -k smallest elements instead, 
    and return them sorted from smallest to largest. 
 
    This performs best when ``k`` is much smaller than the chunk size. All 
    results will be returned in a single chunk along the given axis. 
 
    Parameters 
    ---------- 
    x: Array 
        Data being sorted 
    k: int 
    axis: int, optional 
    split_every: int &gt;=2, optional 
        See :func:`reduce`. This parameter becomes very important when k is 
        on the same order of magnitude of the chunk size or more, as it 
        prevents getting the whole or a significant portion of the input array 
        in memory all at once, with a negative impact on network transfer 
        too when running on distributed. 
 
    Returns 
    ------- 
    Selection of x with size abs(k) along the given axis. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import dask.array as da 
    &gt;&gt;&gt; x = np.array([5, 1, 3, 6]) 
    &gt;&gt;&gt; d = da.from_array(x, chunks=2) 
    &gt;&gt;&gt; d.topk(2).compute() 
    array([6, 5]) 
    &gt;&gt;&gt; d.topk(-2).compute() 
    array([1, 3]) 
    &quot;&quot;&quot;</span>
    <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">a.ndim)</span>

    <span class="s5"># chunk and combine steps of the reduction, which recursively invoke</span>
    <span class="s5"># np.partition to pick the top/bottom k elements from the previous step.</span>
    <span class="s5"># The selection is not sorted internally.</span>
    <span class="s1">chunk_combine = partial(chunk.topk</span><span class="s0">, </span><span class="s1">k=k)</span>
    <span class="s5"># aggregate step of the reduction. Internally invokes the chunk/combine</span>
    <span class="s5"># function, then sorts the results internally.</span>
    <span class="s1">aggregate = partial(chunk.topk_aggregate</span><span class="s0">, </span><span class="s1">k=k)</span>

    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a</span><span class="s0">,</span>
        <span class="s1">chunk=chunk_combine</span><span class="s0">,</span>
        <span class="s1">combine=chunk_combine</span><span class="s0">,</span>
        <span class="s1">aggregate=aggregate</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=</span><span class="s0">True,</span>
        <span class="s1">dtype=a.dtype</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">output_size=abs(k)</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">argtopk(a</span><span class="s0">, </span><span class="s1">k</span><span class="s0">, </span><span class="s1">axis=-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">split_every=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot;Extract the indices of the k largest elements from a on the given axis, 
    and return them sorted from largest to smallest. If k is negative, extract 
    the indices of the -k smallest elements instead, and return them sorted 
    from smallest to largest. 
 
    This performs best when ``k`` is much smaller than the chunk size. All 
    results will be returned in a single chunk along the given axis. 
 
    Parameters 
    ---------- 
    x: Array 
        Data being sorted 
    k: int 
    axis: int, optional 
    split_every: int &gt;=2, optional 
        See :func:`topk`. The performance considerations for topk also apply 
        here. 
 
    Returns 
    ------- 
    Selection of np.intp indices of x with size abs(k) along the given axis. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import dask.array as da 
    &gt;&gt;&gt; x = np.array([5, 1, 3, 6]) 
    &gt;&gt;&gt; d = da.from_array(x, chunks=2) 
    &gt;&gt;&gt; d.argtopk(2).compute() 
    array([3, 0]) 
    &gt;&gt;&gt; d.argtopk(-2).compute() 
    array([1, 2]) 
    &quot;&quot;&quot;</span>
    <span class="s1">axis = validate_axis(axis</span><span class="s0">, </span><span class="s1">a.ndim)</span>

    <span class="s5"># Generate nodes where every chunk is a tuple of (a, original index of a)</span>
    <span class="s1">idx = arange(a.shape[axis]</span><span class="s0">, </span><span class="s1">chunks=(a.chunks[axis]</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">dtype=np.intp)</span>
    <span class="s1">idx = idx[tuple(slice(</span><span class="s0">None</span><span class="s1">) </span><span class="s0">if </span><span class="s1">i == axis </span><span class="s0">else </span><span class="s1">np.newaxis </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(a.ndim))]</span>
    <span class="s1">a_plus_idx = a.map_blocks(chunk.argtopk_preprocess</span><span class="s0">, </span><span class="s1">idx</span><span class="s0">, </span><span class="s1">dtype=object)</span>

    <span class="s5"># chunk and combine steps of the reduction. They acquire in input a tuple</span>
    <span class="s5"># of (a, original indices of a) and return another tuple containing the top</span>
    <span class="s5"># k elements of a and the matching original indices. The selection is not</span>
    <span class="s5"># sorted internally, as in np.argpartition.</span>
    <span class="s1">chunk_combine = partial(chunk.argtopk</span><span class="s0">, </span><span class="s1">k=k)</span>
    <span class="s5"># aggregate step of the reduction. Internally invokes the chunk/combine</span>
    <span class="s5"># function, then sorts the results internally, drops a and returns the</span>
    <span class="s5"># index only.</span>
    <span class="s1">aggregate = partial(chunk.argtopk_aggregate</span><span class="s0">, </span><span class="s1">k=k)</span>

    <span class="s0">if </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Number):</span>
        <span class="s1">naxis = </span><span class="s3">1</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">naxis = len(axis)</span>

    <span class="s1">meta = a._meta.astype(np.intp).reshape((</span><span class="s3">0</span><span class="s0">,</span><span class="s1">) * (a.ndim - naxis + </span><span class="s3">1</span><span class="s1">))</span>

    <span class="s0">return </span><span class="s1">reduction(</span>
        <span class="s1">a_plus_idx</span><span class="s0">,</span>
        <span class="s1">chunk=chunk_combine</span><span class="s0">,</span>
        <span class="s1">combine=chunk_combine</span><span class="s0">,</span>
        <span class="s1">aggregate=aggregate</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=</span><span class="s0">True,</span>
        <span class="s1">dtype=np.intp</span><span class="s0">,</span>
        <span class="s1">split_every=split_every</span><span class="s0">,</span>
        <span class="s1">concatenate=</span><span class="s0">False,</span>
        <span class="s1">output_size=abs(k)</span><span class="s0">,</span>
        <span class="s1">meta=meta</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">trace(a</span><span class="s0">, </span><span class="s1">offset=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis1=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">axis2=</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">diagonal(a</span><span class="s0">, </span><span class="s1">offset=offset</span><span class="s0">, </span><span class="s1">axis1=axis1</span><span class="s0">, </span><span class="s1">axis2=axis2).sum(-</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">median(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot; 
    This works by automatically chunking the reduced axes to a single chunk if necessary 
    and then calling ``numpy.median`` function across the remaining dimensions 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s2">&quot;The da.median function only works along an axis.  &quot;</span>
            <span class="s2">&quot;The full algorithm is difficult to do in parallel&quot;</span>
        <span class="s1">)</span>

    <span class="s0">if not </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Iterable):</span>
        <span class="s1">axis = (axis</span><span class="s0">,</span><span class="s1">)</span>

    <span class="s1">axis = [ax + a.ndim </span><span class="s0">if </span><span class="s1">ax &lt; </span><span class="s3">0 </span><span class="s0">else </span><span class="s1">ax </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis]</span>

    <span class="s5"># rechunk if reduced axes are not contained in a single chunk</span>
    <span class="s0">if </span><span class="s1">builtins.any(a.numblocks[ax] &gt; </span><span class="s3">1 </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis):</span>
        <span class="s1">a = a.rechunk({ax: -</span><span class="s3">1 </span><span class="s0">if </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s2">&quot;auto&quot; </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">range(a.ndim)})</span>

    <span class="s1">result = a.map_blocks(</span>
        <span class="s1">np.median</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">drop_axis=axis </span><span class="s0">if not </span><span class="s1">keepdims </span><span class="s0">else None,</span>
        <span class="s1">chunks=[</span><span class="s3">1 </span><span class="s0">if </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s1">c </span><span class="s0">for </span><span class="s1">ax</span><span class="s0">, </span><span class="s1">c </span><span class="s0">in </span><span class="s1">enumerate(a.chunks)]</span>
        <span class="s0">if </span><span class="s1">keepdims</span>
        <span class="s0">else None,</span>
    <span class="s1">)</span>

    <span class="s1">result = handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>
    <span class="s0">return </span><span class="s1">result</span>


<span class="s1">@derived_from(np)</span>
<span class="s0">def </span><span class="s1">nanmedian(a</span><span class="s0">, </span><span class="s1">axis=</span><span class="s0">None, </span><span class="s1">keepdims=</span><span class="s0">False, </span><span class="s1">out=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot; 
    This works by automatically chunking the reduced axes to a single chunk 
    and then calling ``numpy.nanmedian`` function across the remaining dimensions 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">axis </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s2">&quot;The da.nanmedian function only works along an axis or a subset of axes.  &quot;</span>
            <span class="s2">&quot;The full algorithm is difficult to do in parallel&quot;</span>
        <span class="s1">)</span>

    <span class="s0">if not </span><span class="s1">isinstance(axis</span><span class="s0">, </span><span class="s1">Iterable):</span>
        <span class="s1">axis = (axis</span><span class="s0">,</span><span class="s1">)</span>

    <span class="s1">axis = [ax + a.ndim </span><span class="s0">if </span><span class="s1">ax &lt; </span><span class="s3">0 </span><span class="s0">else </span><span class="s1">ax </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis]</span>

    <span class="s5"># rechunk if reduced axes are not contained in a single chunk</span>
    <span class="s0">if </span><span class="s1">builtins.any(a.numblocks[ax] &gt; </span><span class="s3">1 </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis):</span>
        <span class="s1">a = a.rechunk({ax: -</span><span class="s3">1 </span><span class="s0">if </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s2">&quot;auto&quot; </span><span class="s0">for </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">range(a.ndim)})</span>

    <span class="s1">result = a.map_blocks(</span>
        <span class="s1">np.nanmedian</span><span class="s0">,</span>
        <span class="s1">axis=axis</span><span class="s0">,</span>
        <span class="s1">keepdims=keepdims</span><span class="s0">,</span>
        <span class="s1">drop_axis=axis </span><span class="s0">if not </span><span class="s1">keepdims </span><span class="s0">else None,</span>
        <span class="s1">chunks=[</span><span class="s3">1 </span><span class="s0">if </span><span class="s1">ax </span><span class="s0">in </span><span class="s1">axis </span><span class="s0">else </span><span class="s1">c </span><span class="s0">for </span><span class="s1">ax</span><span class="s0">, </span><span class="s1">c </span><span class="s0">in </span><span class="s1">enumerate(a.chunks)]</span>
        <span class="s0">if </span><span class="s1">keepdims</span>
        <span class="s0">else None,</span>
    <span class="s1">)</span>

    <span class="s1">result = handle_out(out</span><span class="s0">, </span><span class="s1">result)</span>
    <span class="s0">return </span><span class="s1">result</span>
</pre>
</body>
</html>
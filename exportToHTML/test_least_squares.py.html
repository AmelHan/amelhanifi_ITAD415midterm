<html>
<head>
<title>test_least_squares.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_least_squares.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">product</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">numpy.linalg </span><span class="s0">import </span><span class="s1">norm</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">(assert_</span><span class="s0">, </span><span class="s1">assert_allclose</span><span class="s0">,</span>
                           <span class="s1">assert_equal</span><span class="s0">, </span><span class="s1">suppress_warnings)</span>
<span class="s0">from </span><span class="s1">pytest </span><span class="s0">import </span><span class="s1">raises </span><span class="s0">as </span><span class="s1">assert_raises</span>
<span class="s0">from </span><span class="s1">scipy.sparse </span><span class="s0">import </span><span class="s1">issparse</span><span class="s0">, </span><span class="s1">lil_matrix</span>
<span class="s0">from </span><span class="s1">scipy.sparse.linalg </span><span class="s0">import </span><span class="s1">aslinearoperator</span>

<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">Bounds</span>
<span class="s0">from </span><span class="s1">scipy.optimize._lsq.least_squares </span><span class="s0">import </span><span class="s1">IMPLEMENTED_LOSSES</span>
<span class="s0">from </span><span class="s1">scipy.optimize._lsq.common </span><span class="s0">import </span><span class="s1">EPS</span><span class="s0">, </span><span class="s1">make_strictly_feasible</span>


<span class="s0">def </span><span class="s1">fun_trivial(x</span><span class="s0">, </span><span class="s1">a=</span><span class="s2">0</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">(x - a)**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5.0</span>


<span class="s0">def </span><span class="s1">jac_trivial(x</span><span class="s0">, </span><span class="s1">a=</span><span class="s2">0.0</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s2">2 </span><span class="s1">* (x - a)</span>


<span class="s0">def </span><span class="s1">fun_2d_trivial(x):</span>
    <span class="s0">return </span><span class="s1">np.array([x[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x[</span><span class="s2">1</span><span class="s1">]])</span>


<span class="s0">def </span><span class="s1">jac_2d_trivial(x):</span>
    <span class="s0">return </span><span class="s1">np.identity(</span><span class="s2">2</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">fun_rosenbrock(x):</span>
    <span class="s0">return </span><span class="s1">np.array([</span><span class="s2">10 </span><span class="s1">* (x[</span><span class="s2">1</span><span class="s1">] - x[</span><span class="s2">0</span><span class="s1">]**</span><span class="s2">2</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s2">1 </span><span class="s1">- x[</span><span class="s2">0</span><span class="s1">])])</span>


<span class="s0">def </span><span class="s1">jac_rosenbrock(x):</span>
    <span class="s0">return </span><span class="s1">np.array([</span>
        <span class="s1">[-</span><span class="s2">20 </span><span class="s1">* x[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s2">10</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">])</span>


<span class="s0">def </span><span class="s1">jac_rosenbrock_bad_dim(x):</span>
    <span class="s0">return </span><span class="s1">np.array([</span>
        <span class="s1">[-</span><span class="s2">20 </span><span class="s1">* x[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s2">10</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s2">0.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]</span>
    <span class="s1">])</span>


<span class="s0">def </span><span class="s1">fun_rosenbrock_cropped(x):</span>
    <span class="s0">return </span><span class="s1">fun_rosenbrock(x)[</span><span class="s2">0</span><span class="s1">]</span>


<span class="s0">def </span><span class="s1">jac_rosenbrock_cropped(x):</span>
    <span class="s0">return </span><span class="s1">jac_rosenbrock(x)[</span><span class="s2">0</span><span class="s1">]</span>


<span class="s3"># When x is 1-D array, return is 2-D array.</span>
<span class="s0">def </span><span class="s1">fun_wrong_dimensions(x):</span>
    <span class="s0">return </span><span class="s1">np.array([x</span><span class="s0">, </span><span class="s1">x**</span><span class="s2">2</span><span class="s0">, </span><span class="s1">x**</span><span class="s2">3</span><span class="s1">])</span>


<span class="s0">def </span><span class="s1">jac_wrong_dimensions(x</span><span class="s0">, </span><span class="s1">a=</span><span class="s2">0.0</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">np.atleast_3d(jac_trivial(x</span><span class="s0">, </span><span class="s1">a=a))</span>


<span class="s0">def </span><span class="s1">fun_bvp(x):</span>
    <span class="s1">n = int(np.sqrt(x.shape[</span><span class="s2">0</span><span class="s1">]))</span>
    <span class="s1">u = np.zeros((n + </span><span class="s2">2</span><span class="s0">, </span><span class="s1">n + </span><span class="s2">2</span><span class="s1">))</span>
    <span class="s1">x = x.reshape((n</span><span class="s0">, </span><span class="s1">n))</span>
    <span class="s1">u[</span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s1">] = x</span>
    <span class="s1">y = u[:-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s1">] + u[</span><span class="s2">2</span><span class="s1">:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s1">] + u[</span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s0">, </span><span class="s1">:-</span><span class="s2">2</span><span class="s1">] + u[</span><span class="s2">1</span><span class="s1">:-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:] - </span><span class="s2">4 </span><span class="s1">* x + x**</span><span class="s2">3</span>
    <span class="s0">return </span><span class="s1">y.ravel()</span>


<span class="s0">class </span><span class="s1">BroydenTridiagonal:</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">n=</span><span class="s2">100</span><span class="s0">, </span><span class="s1">mode=</span><span class="s4">'sparse'</span><span class="s1">):</span>
        <span class="s1">np.random.seed(</span><span class="s2">0</span><span class="s1">)</span>

        <span class="s1">self.n = n</span>

        <span class="s1">self.x0 = -np.ones(n)</span>
        <span class="s1">self.lb = np.linspace(-</span><span class="s2">2</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.5</span><span class="s0">, </span><span class="s1">n)</span>
        <span class="s1">self.ub = np.linspace(-</span><span class="s2">0.8</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">n)</span>

        <span class="s1">self.lb += </span><span class="s2">0.1 </span><span class="s1">* np.random.randn(n)</span>
        <span class="s1">self.ub += </span><span class="s2">0.1 </span><span class="s1">* np.random.randn(n)</span>

        <span class="s1">self.x0 += </span><span class="s2">0.1 </span><span class="s1">* np.random.randn(n)</span>
        <span class="s1">self.x0 = make_strictly_feasible(self.x0</span><span class="s0">, </span><span class="s1">self.lb</span><span class="s0">, </span><span class="s1">self.ub)</span>

        <span class="s0">if </span><span class="s1">mode == </span><span class="s4">'sparse'</span><span class="s1">:</span>
            <span class="s1">self.sparsity = lil_matrix((n</span><span class="s0">, </span><span class="s1">n)</span><span class="s0">, </span><span class="s1">dtype=int)</span>
            <span class="s1">i = np.arange(n)</span>
            <span class="s1">self.sparsity[i</span><span class="s0">, </span><span class="s1">i] = </span><span class="s2">1</span>
            <span class="s1">i = np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">n)</span>
            <span class="s1">self.sparsity[i</span><span class="s0">, </span><span class="s1">i - </span><span class="s2">1</span><span class="s1">] = </span><span class="s2">1</span>
            <span class="s1">i = np.arange(n - </span><span class="s2">1</span><span class="s1">)</span>
            <span class="s1">self.sparsity[i</span><span class="s0">, </span><span class="s1">i + </span><span class="s2">1</span><span class="s1">] = </span><span class="s2">1</span>

            <span class="s1">self.jac = self._jac</span>
        <span class="s0">elif </span><span class="s1">mode == </span><span class="s4">'operator'</span><span class="s1">:</span>
            <span class="s1">self.jac = </span><span class="s0">lambda </span><span class="s1">x: aslinearoperator(self._jac(x))</span>
        <span class="s0">elif </span><span class="s1">mode == </span><span class="s4">'dense'</span><span class="s1">:</span>
            <span class="s1">self.sparsity = </span><span class="s0">None</span>
            <span class="s1">self.jac = </span><span class="s0">lambda </span><span class="s1">x: self._jac(x).toarray()</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_(</span><span class="s0">False</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">fun(self</span><span class="s0">, </span><span class="s1">x):</span>
        <span class="s1">f = (</span><span class="s2">3 </span><span class="s1">- x) * x + </span><span class="s2">1</span>
        <span class="s1">f[</span><span class="s2">1</span><span class="s1">:] -= x[:-</span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">f[:-</span><span class="s2">1</span><span class="s1">] -= </span><span class="s2">2 </span><span class="s1">* x[</span><span class="s2">1</span><span class="s1">:]</span>
        <span class="s0">return </span><span class="s1">f</span>

    <span class="s0">def </span><span class="s1">_jac(self</span><span class="s0">, </span><span class="s1">x):</span>
        <span class="s1">J = lil_matrix((self.n</span><span class="s0">, </span><span class="s1">self.n))</span>
        <span class="s1">i = np.arange(self.n)</span>
        <span class="s1">J[i</span><span class="s0">, </span><span class="s1">i] = </span><span class="s2">3 </span><span class="s1">- </span><span class="s2">2 </span><span class="s1">* x</span>
        <span class="s1">i = np.arange(</span><span class="s2">1</span><span class="s0">, </span><span class="s1">self.n)</span>
        <span class="s1">J[i</span><span class="s0">, </span><span class="s1">i - </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">1</span>
        <span class="s1">i = np.arange(self.n - </span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">J[i</span><span class="s0">, </span><span class="s1">i + </span><span class="s2">1</span><span class="s1">] = -</span><span class="s2">2</span>
        <span class="s0">return </span><span class="s1">J</span>


<span class="s0">class </span><span class="s1">ExponentialFittingProblem:</span>
    <span class="s5">&quot;&quot;&quot;Provide data and function for exponential fitting in the form 
    y = a + exp(b * x) + noise.&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">b</span><span class="s0">, </span><span class="s1">noise</span><span class="s0">, </span><span class="s1">n_outliers=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">x_range=(-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span><span class="s0">,</span>
                 <span class="s1">n_points=</span><span class="s2">11</span><span class="s0">, </span><span class="s1">random_seed=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">np.random.seed(random_seed)</span>
        <span class="s1">self.m = n_points</span>
        <span class="s1">self.n = </span><span class="s2">2</span>

        <span class="s1">self.p0 = np.zeros(</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s1">self.x = np.linspace(x_range[</span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x_range[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">n_points)</span>

        <span class="s1">self.y = a + np.exp(b * self.x)</span>
        <span class="s1">self.y += noise * np.random.randn(self.m)</span>

        <span class="s1">outliers = np.random.randint(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">self.m</span><span class="s0">, </span><span class="s1">n_outliers)</span>
        <span class="s1">self.y[outliers] += </span><span class="s2">50 </span><span class="s1">* noise * np.random.rand(n_outliers)</span>

        <span class="s1">self.p_opt = np.array([a</span><span class="s0">, </span><span class="s1">b])</span>

    <span class="s0">def </span><span class="s1">fun(self</span><span class="s0">, </span><span class="s1">p):</span>
        <span class="s0">return </span><span class="s1">p[</span><span class="s2">0</span><span class="s1">] + np.exp(p[</span><span class="s2">1</span><span class="s1">] * self.x) - self.y</span>

    <span class="s0">def </span><span class="s1">jac(self</span><span class="s0">, </span><span class="s1">p):</span>
        <span class="s1">J = np.empty((self.m</span><span class="s0">, </span><span class="s1">self.n))</span>
        <span class="s1">J[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] = </span><span class="s2">1</span>
        <span class="s1">J[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] = self.x * np.exp(p[</span><span class="s2">1</span><span class="s1">] * self.x)</span>
        <span class="s0">return </span><span class="s1">J</span>


<span class="s0">def </span><span class="s1">cubic_soft_l1(z):</span>
    <span class="s1">rho = np.empty((</span><span class="s2">3</span><span class="s0">, </span><span class="s1">z.size))</span>

    <span class="s1">t = </span><span class="s2">1 </span><span class="s1">+ z</span>
    <span class="s1">rho[</span><span class="s2">0</span><span class="s1">] = </span><span class="s2">3 </span><span class="s1">* (t**(</span><span class="s2">1</span><span class="s1">/</span><span class="s2">3</span><span class="s1">) - </span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">rho[</span><span class="s2">1</span><span class="s1">] = t ** (-</span><span class="s2">2</span><span class="s1">/</span><span class="s2">3</span><span class="s1">)</span>
    <span class="s1">rho[</span><span class="s2">2</span><span class="s1">] = -</span><span class="s2">2</span><span class="s1">/</span><span class="s2">3 </span><span class="s1">* t**(-</span><span class="s2">5</span><span class="s1">/</span><span class="s2">3</span><span class="s1">)</span>

    <span class="s0">return </span><span class="s1">rho</span>


<span class="s1">LOSSES = list(IMPLEMENTED_LOSSES.keys()) + [cubic_soft_l1]</span>


<span class="s0">class </span><span class="s1">BaseMixin:</span>
    <span class="s0">def </span><span class="s1">test_basic(self):</span>
        <span class="s3"># Test that the basic calling sequence works.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.fun</span><span class="s0">, </span><span class="s1">fun_trivial(res.x))</span>

    <span class="s0">def </span><span class="s1">test_args_kwargs(self):</span>
        <span class="s3"># Test that args and kwargs are passed correctly to the functions.</span>
        <span class="s1">a = </span><span class="s2">3.0</span>
        <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_trivial]:</span>
            <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
                <span class="s1">sup.filter(UserWarning</span><span class="s0">,</span>
                           <span class="s4">&quot;jac='(3-point|cs)' works equivalently to '2-point' for method='lm'&quot;</span><span class="s1">)</span>
                <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">args=(a</span><span class="s0">,</span><span class="s1">)</span><span class="s0">,</span>
                                    <span class="s1">method=self.method)</span>
                <span class="s1">res1 = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">kwargs={</span><span class="s4">'a'</span><span class="s1">: a}</span><span class="s0">,</span>
                                    <span class="s1">method=self.method)</span>

            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res1.x</span><span class="s0">, </span><span class="s1">a</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

            <span class="s1">assert_raises(TypeError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                          <span class="s1">args=(</span><span class="s2">3</span><span class="s0">, </span><span class="s2">4</span><span class="s0">,</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">assert_raises(TypeError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                          <span class="s1">kwargs={</span><span class="s4">'kaboom'</span><span class="s1">: </span><span class="s2">3</span><span class="s1">}</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_jac_options(self):</span>
        <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_trivial]:</span>
            <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
                <span class="s1">sup.filter(UserWarning</span><span class="s0">,</span>
                           <span class="s4">&quot;jac='(3-point|cs)' works equivalently to '2-point' for method='lm'&quot;</span><span class="s1">)</span>
                <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac=</span><span class="s4">'oops'</span><span class="s0">,</span>
                      <span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_nfev_options(self):</span>
        <span class="s0">for </span><span class="s1">max_nfev </span><span class="s0">in </span><span class="s1">[</span><span class="s0">None, </span><span class="s2">20</span><span class="s1">]:</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">max_nfev=max_nfev</span><span class="s0">,</span>
                                <span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_x_scale_options(self):</span>
        <span class="s0">for </span><span class="s1">x_scale </span><span class="s0">in </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">0.5</span><span class="s1">])</span><span class="s0">, </span><span class="s4">'jac'</span><span class="s1">]:</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">x_scale=x_scale)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">x_scale=</span><span class="s4">'auto'</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">x_scale=-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">x_scale=</span><span class="s0">None, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">x_scale=</span><span class="s2">1.0</span><span class="s1">+</span><span class="s2">2.0j</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_diff_step(self):</span>
        <span class="s3"># res1 and res2 should be equivalent.</span>
        <span class="s3"># res2 and res3 should be different.</span>
        <span class="s1">res1 = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">diff_step=</span><span class="s2">1e-1</span><span class="s0">,</span>
                             <span class="s1">method=self.method)</span>
        <span class="s1">res2 = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">diff_step=-</span><span class="s2">1e-1</span><span class="s0">,</span>
                             <span class="s1">method=self.method)</span>
        <span class="s1">res3 = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                             <span class="s1">diff_step=</span><span class="s0">None, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res1.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res2.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res3.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_equal(res1.x</span><span class="s0">, </span><span class="s1">res2.x)</span>
        <span class="s1">assert_equal(res1.nfev</span><span class="s0">, </span><span class="s1">res2.nfev)</span>

    <span class="s0">def </span><span class="s1">test_incorrect_options_usage(self):</span>
        <span class="s1">assert_raises(TypeError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">options={</span><span class="s4">'no_such_option'</span><span class="s1">: </span><span class="s2">100</span><span class="s1">})</span>
        <span class="s1">assert_raises(TypeError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">options={</span><span class="s4">'max_nfev'</span><span class="s1">: </span><span class="s2">100</span><span class="s1">})</span>

    <span class="s0">def </span><span class="s1">test_full_result(self):</span>
        <span class="s3"># MINPACK doesn't work very well with factor=100 on this problem,</span>
        <span class="s3"># thus using low 'atol'.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">12.5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.fun</span><span class="s0">, </span><span class="s2">5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.grad</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.active_mask</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">self.method == </span><span class="s4">'lm'</span><span class="s1">:</span>
            <span class="s1">assert_(res.nfev &lt; </span><span class="s2">30</span><span class="s1">)</span>
            <span class="s1">assert_(res.njev </span><span class="s0">is None</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">assert_(res.nfev &lt; </span><span class="s2">10</span><span class="s1">)</span>
            <span class="s1">assert_(res.njev &lt; </span><span class="s2">10</span><span class="s1">)</span>
        <span class="s1">assert_(res.status &gt; </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">assert_(res.success)</span>

    <span class="s0">def </span><span class="s1">test_full_result_single_fev(self):</span>
        <span class="s3"># MINPACK checks the number of nfev after the iteration,</span>
        <span class="s3"># so it's hard to tell what he is going to compute.</span>
        <span class="s0">if </span><span class="s1">self.method == </span><span class="s4">'lm'</span><span class="s1">:</span>
            <span class="s0">return</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">method=self.method</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.x</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">2</span><span class="s1">]))</span>
        <span class="s1">assert_equal(res.cost</span><span class="s0">, </span><span class="s2">40.5</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.fun</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">9</span><span class="s1">]))</span>
        <span class="s1">assert_equal(res.jac</span><span class="s0">, </span><span class="s1">np.array([[</span><span class="s2">4</span><span class="s1">]]))</span>
        <span class="s1">assert_equal(res.grad</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">36</span><span class="s1">]))</span>
        <span class="s1">assert_equal(res.optimality</span><span class="s0">, </span><span class="s2">36</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.active_mask</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">0</span><span class="s1">]))</span>
        <span class="s1">assert_equal(res.nfev</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.njev</span><span class="s0">, </span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.status</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.success</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_rosenbrock(self):</span>
        <span class="s1">x0 = [-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">x_opt = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s0">for </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">x_scale</span><span class="s0">, </span><span class="s1">tr_solver </span><span class="s0">in </span><span class="s1">product(</span>
                <span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_rosenbrock]</span><span class="s0">,</span>
                <span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.2</span><span class="s1">])</span><span class="s0">, </span><span class="s4">'jac'</span><span class="s1">]</span><span class="s0">,</span>
                <span class="s1">[</span><span class="s4">'exact'</span><span class="s0">, </span><span class="s4">'lsmr'</span><span class="s1">]):</span>
            <span class="s0">with </span><span class="s1">suppress_warnings() </span><span class="s0">as </span><span class="s1">sup:</span>
                <span class="s1">sup.filter(UserWarning</span><span class="s0">,</span>
                           <span class="s4">&quot;jac='(3-point|cs)' works equivalently to '2-point' for method='lm'&quot;</span><span class="s1">)</span>
                <span class="s1">res = least_squares(fun_rosenbrock</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">x_scale=x_scale</span><span class="s0">,</span>
                                    <span class="s1">tr_solver=tr_solver</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">x_opt)</span>

    <span class="s0">def </span><span class="s1">test_rosenbrock_cropped(self):</span>
        <span class="s1">x0 = [-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s0">if </span><span class="s1">self.method == </span><span class="s4">'lm'</span><span class="s1">:</span>
            <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_rosenbrock_cropped</span><span class="s0">,</span>
                          <span class="s1">x0</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">for </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">x_scale</span><span class="s0">, </span><span class="s1">tr_solver </span><span class="s0">in </span><span class="s1">product(</span>
                    <span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_rosenbrock_cropped]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.2</span><span class="s1">])</span><span class="s0">, </span><span class="s4">'jac'</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">'exact'</span><span class="s0">, </span><span class="s4">'lsmr'</span><span class="s1">]):</span>
                <span class="s1">res = least_squares(</span>
                    <span class="s1">fun_rosenbrock_cropped</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">x_scale=x_scale</span><span class="s0">,</span>
                    <span class="s1">tr_solver=tr_solver</span><span class="s0">, </span><span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-14</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_fun_wrong_dimensions(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_wrong_dimensions</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_jac_wrong_dimensions(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac_wrong_dimensions</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_fun_and_jac_inconsistent_dimensions(self):</span>
        <span class="s1">x0 = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_rosenbrock</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">,</span>
                      <span class="s1">jac_rosenbrock_bad_dim</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_x0_multidimensional(self):</span>
        <span class="s1">x0 = np.ones(</span><span class="s2">4</span><span class="s1">).reshape(</span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">,</span>
                      <span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_x0_complex_scalar(self):</span>
        <span class="s1">x0 = </span><span class="s2">2.0 </span><span class="s1">+ </span><span class="s2">0.0</span><span class="s1">*</span><span class="s2">1j</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">,</span>
                      <span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_x0_complex_array(self):</span>
        <span class="s1">x0 = [</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">2.0 </span><span class="s1">+ </span><span class="s2">0.0</span><span class="s1">*</span><span class="s2">1j</span><span class="s1">]</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">,</span>
                      <span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_bvp(self):</span>
        <span class="s3"># This test was introduced with fix #5556. It turned out that</span>
        <span class="s3"># dogbox solver had a bug with trust-region radius update, which</span>
        <span class="s3"># could block its progress and create an infinite loop. And this</span>
        <span class="s3"># discrete boundary value problem is the one which triggers it.</span>
        <span class="s1">n = </span><span class="s2">10</span>
        <span class="s1">x0 = np.ones(n**</span><span class="s2">2</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">self.method == </span><span class="s4">'lm'</span><span class="s1">:</span>
            <span class="s1">max_nfev = </span><span class="s2">5000  </span><span class="s3"># To account for Jacobian estimation.</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">max_nfev = </span><span class="s2">100</span>
        <span class="s1">res = least_squares(fun_bvp</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">ftol=</span><span class="s2">1e-2</span><span class="s0">, </span><span class="s1">method=self.method</span><span class="s0">,</span>
                            <span class="s1">max_nfev=max_nfev)</span>

        <span class="s1">assert_(res.nfev &lt; max_nfev)</span>
        <span class="s1">assert_(res.cost &lt; </span><span class="s2">0.5</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_error_raised_when_all_tolerances_below_eps(self):</span>
        <span class="s3"># Test that all 0 tolerances are not allowed.</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">ftol=</span><span class="s0">None, </span><span class="s1">xtol=</span><span class="s0">None, </span><span class="s1">gtol=</span><span class="s0">None</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_convergence_with_only_one_tolerance_enabled(self):</span>
        <span class="s0">if </span><span class="s1">self.method == </span><span class="s4">'lm'</span><span class="s1">:</span>
            <span class="s0">return  </span><span class="s3"># should not do test</span>
        <span class="s1">x0 = [-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">x_opt = [</span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s0">for </span><span class="s1">ftol</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">gtol </span><span class="s0">in </span><span class="s1">[(</span><span class="s2">1e-8</span><span class="s0">, None, None</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">(</span><span class="s0">None, </span><span class="s2">1e-8</span><span class="s0">, None</span><span class="s1">)</span><span class="s0">,</span>
                                  <span class="s1">(</span><span class="s0">None, None, </span><span class="s2">1e-8</span><span class="s1">)]:</span>
            <span class="s1">res = least_squares(fun_rosenbrock</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac=jac_rosenbrock</span><span class="s0">,</span>
                                <span class="s1">ftol=ftol</span><span class="s0">, </span><span class="s1">gtol=gtol</span><span class="s0">, </span><span class="s1">xtol=xtol</span><span class="s0">,</span>
                                <span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">x_opt)</span>


<span class="s0">class </span><span class="s1">BoundsMixin:</span>
    <span class="s0">def </span><span class="s1">test_inconsistent(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">bounds=(</span><span class="s2">10.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_infeasible(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">bounds=(</span><span class="s2">3.</span><span class="s0">, </span><span class="s2">4</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_wrong_number(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">,</span>
                      <span class="s1">bounds=(</span><span class="s2">1.</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_inconsistent_shape(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">bounds=(</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">[</span><span class="s2">2.0</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">])</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s3"># 1-D array wont't be broadcasted</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_rosenbrock</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">]</span><span class="s0">,</span>
                      <span class="s1">bounds=([</span><span class="s2">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">3.0</span><span class="s0">, </span><span class="s2">4.0</span><span class="s1">])</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_in_bounds(self):</span>
        <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_trivial]:</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                                <span class="s1">bounds=(-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
            <span class="s1">assert_equal(res.active_mask</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0</span><span class="s1">])</span>
            <span class="s1">assert_(-</span><span class="s2">1 </span><span class="s1">&lt;= res.x &lt;= </span><span class="s2">3</span><span class="s1">)</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                                <span class="s1">bounds=(</span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>
            <span class="s1">assert_equal(res.active_mask</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">1</span><span class="s1">])</span>
            <span class="s1">assert_(</span><span class="s2">0.5 </span><span class="s1">&lt;= res.x &lt;= </span><span class="s2">3</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_bounds_shape(self):</span>
        <span class="s0">def </span><span class="s1">get_bounds_direct(lb</span><span class="s0">, </span><span class="s1">ub):</span>
            <span class="s0">return </span><span class="s1">lb</span><span class="s0">, </span><span class="s1">ub</span>

        <span class="s0">def </span><span class="s1">get_bounds_instances(lb</span><span class="s0">, </span><span class="s1">ub):</span>
            <span class="s0">return </span><span class="s1">Bounds(lb</span><span class="s0">, </span><span class="s1">ub)</span>

        <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_2d_trivial]:</span>
            <span class="s0">for </span><span class="s1">bounds_func </span><span class="s0">in </span><span class="s1">[get_bounds_direct</span><span class="s0">, </span><span class="s1">get_bounds_instances]:</span>
                <span class="s1">x0 = [</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">]</span>
                <span class="s1">res = least_squares(fun_2d_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac=jac)</span>
                <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">])</span>
                <span class="s1">res = least_squares(fun_2d_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                                    <span class="s1">bounds=bounds_func(</span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">[</span><span class="s2">2.0</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">])</span><span class="s0">,</span>
                                    <span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">])</span>
                <span class="s1">res = least_squares(fun_2d_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                                    <span class="s1">bounds=bounds_func([</span><span class="s2">0.3</span><span class="s0">, </span><span class="s2">0.2</span><span class="s1">]</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">)</span><span class="s0">,</span>
                                    <span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.3</span><span class="s0">, </span><span class="s2">0.2</span><span class="s1">])</span>
                <span class="s1">res = least_squares(</span>
                    <span class="s1">fun_2d_trivial</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                    <span class="s1">bounds=bounds_func([-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">])</span><span class="s0">,</span>
                    <span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.0</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_bounds_instances(self):</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">bounds=Bounds())</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">3.0</span><span class="s0">, </span><span class="s1">bounds=Bounds(lb=</span><span class="s2">1.0</span><span class="s1">))</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">0.5</span><span class="s0">, </span><span class="s1">bounds=Bounds(lb=-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">ub=</span><span class="s2">1.0</span><span class="s1">))</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">-</span><span class="s2">3.0</span><span class="s0">, </span><span class="s1">bounds=Bounds(ub=-</span><span class="s2">1.0</span><span class="s1">))</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_2d_trivial</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">,</span>
                            <span class="s1">bounds=Bounds(lb=[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">ub=</span><span class="s2">1.0</span><span class="s1">))</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_2d_trivial</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">,</span>
                            <span class="s1">bounds=Bounds(lb=[</span><span class="s2">0.1</span><span class="s0">, </span><span class="s2">0.1</span><span class="s1">]))</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.1</span><span class="s0">, </span><span class="s2">0.1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_rosenbrock_bounds(self):</span>
        <span class="s1">x0_1 = np.array([-</span><span class="s2">2.0</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">])</span>
        <span class="s1">x0_2 = np.array([</span><span class="s2">2.0</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">])</span>
        <span class="s1">x0_3 = np.array([-</span><span class="s2">2.0</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">])</span>
        <span class="s1">x0_4 = np.array([</span><span class="s2">0.0</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">])</span>
        <span class="s1">x0_5 = np.array([-</span><span class="s2">1.2</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">])</span>
        <span class="s1">problems = [</span>
            <span class="s1">(x0_1</span><span class="s0">, </span><span class="s1">([-np.inf</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.inf))</span><span class="s0">,</span>
            <span class="s1">(x0_2</span><span class="s0">, </span><span class="s1">([-np.inf</span><span class="s0">, </span><span class="s2">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.inf))</span><span class="s0">,</span>
            <span class="s1">(x0_3</span><span class="s0">, </span><span class="s1">([-np.inf</span><span class="s0">, </span><span class="s2">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">np.inf))</span><span class="s0">,</span>
            <span class="s1">(x0_4</span><span class="s0">, </span><span class="s1">([-np.inf</span><span class="s0">, </span><span class="s2">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">np.inf]))</span><span class="s0">,</span>
            <span class="s1">(x0_2</span><span class="s0">, </span><span class="s1">([</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">1.5</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">3.0</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">]))</span><span class="s0">,</span>
            <span class="s1">(x0_5</span><span class="s0">, </span><span class="s1">([-</span><span class="s2">50.0</span><span class="s0">, </span><span class="s2">0.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0.5</span><span class="s0">, </span><span class="s2">100</span><span class="s1">]))</span>
        <span class="s1">]</span>
        <span class="s0">for </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">bounds </span><span class="s0">in </span><span class="s1">problems:</span>
            <span class="s0">for </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">x_scale</span><span class="s0">, </span><span class="s1">tr_solver </span><span class="s0">in </span><span class="s1">product(</span>
                    <span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">jac_rosenbrock]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">[</span><span class="s2">1.0</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">]</span><span class="s0">, </span><span class="s4">'jac'</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s4">'exact'</span><span class="s0">, </span><span class="s4">'lsmr'</span><span class="s1">]):</span>
                <span class="s1">res = least_squares(fun_rosenbrock</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">bounds</span><span class="s0">,</span>
                                    <span class="s1">x_scale=x_scale</span><span class="s0">, </span><span class="s1">tr_solver=tr_solver</span><span class="s0">,</span>
                                    <span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res.optimality</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">SparseMixin:</span>
    <span class="s0">def </span><span class="s1">test_exact_tr_solver(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">tr_solver=</span><span class="s4">'exact'</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">,</span>
                      <span class="s1">tr_solver=</span><span class="s4">'exact'</span><span class="s0">, </span><span class="s1">jac_sparsity=p.sparsity</span><span class="s0">,</span>
                      <span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_equivalence(self):</span>
        <span class="s1">sparse = BroydenTridiagonal(mode=</span><span class="s4">'sparse'</span><span class="s1">)</span>
        <span class="s1">dense = BroydenTridiagonal(mode=</span><span class="s4">'dense'</span><span class="s1">)</span>
        <span class="s1">res_sparse = least_squares(</span>
            <span class="s1">sparse.fun</span><span class="s0">, </span><span class="s1">sparse.x0</span><span class="s0">, </span><span class="s1">jac=sparse.jac</span><span class="s0">,</span>
            <span class="s1">method=self.method)</span>
        <span class="s1">res_dense = least_squares(</span>
            <span class="s1">dense.fun</span><span class="s0">, </span><span class="s1">dense.x0</span><span class="s0">, </span><span class="s1">jac=sparse.jac</span><span class="s0">,</span>
            <span class="s1">method=self.method)</span>
        <span class="s1">assert_equal(res_sparse.nfev</span><span class="s0">, </span><span class="s1">res_dense.nfev)</span>
        <span class="s1">assert_allclose(res_sparse.x</span><span class="s0">, </span><span class="s1">res_dense.x</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res_sparse.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res_dense.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_tr_options(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">res = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">, </span><span class="s1">method=self.method</span><span class="s0">,</span>
                            <span class="s1">tr_options={</span><span class="s4">'btol'</span><span class="s1">: </span><span class="s2">1e-10</span><span class="s1">})</span>
        <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_wrong_parameters(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">tr_solver=</span><span class="s4">'best'</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_raises(TypeError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">tr_solver=</span><span class="s4">'lsmr'</span><span class="s0">, </span><span class="s1">tr_options={</span><span class="s4">'tol'</span><span class="s1">: </span><span class="s2">1e-10</span><span class="s1">})</span>

    <span class="s0">def </span><span class="s1">test_solver_selection(self):</span>
        <span class="s1">sparse = BroydenTridiagonal(mode=</span><span class="s4">'sparse'</span><span class="s1">)</span>
        <span class="s1">dense = BroydenTridiagonal(mode=</span><span class="s4">'dense'</span><span class="s1">)</span>
        <span class="s1">res_sparse = least_squares(sparse.fun</span><span class="s0">, </span><span class="s1">sparse.x0</span><span class="s0">, </span><span class="s1">jac=sparse.jac</span><span class="s0">,</span>
                                   <span class="s1">method=self.method)</span>
        <span class="s1">res_dense = least_squares(dense.fun</span><span class="s0">, </span><span class="s1">dense.x0</span><span class="s0">, </span><span class="s1">jac=dense.jac</span><span class="s0">,</span>
                                  <span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res_sparse.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res_dense.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
        <span class="s1">assert_(issparse(res_sparse.jac))</span>
        <span class="s1">assert_(isinstance(res_dense.jac</span><span class="s0">, </span><span class="s1">np.ndarray))</span>

    <span class="s0">def </span><span class="s1">test_numerical_jac(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s1">]:</span>
            <span class="s1">res_dense = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">method=self.method)</span>
            <span class="s1">res_sparse = least_squares(</span>
                <span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">,</span><span class="s1">method=self.method</span><span class="s0">,</span>
                <span class="s1">jac_sparsity=p.sparsity)</span>
            <span class="s1">assert_equal(res_dense.nfev</span><span class="s0">, </span><span class="s1">res_sparse.nfev)</span>
            <span class="s1">assert_allclose(res_dense.x</span><span class="s0">, </span><span class="s1">res_sparse.x</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res_dense.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res_sparse.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_with_bounds(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s0">for </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">jac_sparsity </span><span class="s0">in </span><span class="s1">product(</span>
                <span class="s1">[p.jac</span><span class="s0">, </span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s0">None, </span><span class="s1">p.sparsity]):</span>
            <span class="s1">res_1 = least_squares(</span>
                <span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">bounds=(p.lb</span><span class="s0">, </span><span class="s1">np.inf)</span><span class="s0">,</span>
                <span class="s1">method=self.method</span><span class="s0">,</span><span class="s1">jac_sparsity=jac_sparsity)</span>
            <span class="s1">res_2 = least_squares(</span>
                <span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">bounds=(-np.inf</span><span class="s0">, </span><span class="s1">p.ub)</span><span class="s0">,</span>
                <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">jac_sparsity=jac_sparsity)</span>
            <span class="s1">res_3 = least_squares(</span>
                <span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">jac</span><span class="s0">, </span><span class="s1">bounds=(p.lb</span><span class="s0">, </span><span class="s1">p.ub)</span><span class="s0">,</span>
                <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">jac_sparsity=jac_sparsity)</span>
            <span class="s1">assert_allclose(res_1.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-10</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res_2.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-10</span><span class="s1">)</span>
            <span class="s1">assert_allclose(res_3.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-10</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_wrong_jac_sparsity(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">sparsity = p.sparsity[:-</span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">,</span>
                      <span class="s1">jac_sparsity=sparsity</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_linear_operator(self):</span>
        <span class="s1">p = BroydenTridiagonal(mode=</span><span class="s4">'operator'</span><span class="s1">)</span>
        <span class="s1">res = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">tr_solver=</span><span class="s4">'exact'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_x_scale_jac_scale(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">res = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">, </span><span class="s1">method=self.method</span><span class="s0">,</span>
                            <span class="s1">x_scale=</span><span class="s4">'jac'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>

        <span class="s1">p = BroydenTridiagonal(mode=</span><span class="s4">'operator'</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">method=self.method</span><span class="s0">, </span><span class="s1">x_scale=</span><span class="s4">'jac'</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">LossFunctionMixin:</span>
    <span class="s0">def </span><span class="s1">test_options(self):</span>
        <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s1">LOSSES:</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">loss=loss</span><span class="s0">,</span>
                                <span class="s1">method=self.method)</span>
            <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-15</span><span class="s1">)</span>

        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">loss=</span><span class="s4">'hinge'</span><span class="s0">, </span><span class="s1">method=self.method)</span>

    <span class="s0">def </span><span class="s1">test_fun(self):</span>
        <span class="s3"># Test that res.fun is actual residuals, and not modified by loss</span>
        <span class="s3"># function stuff.</span>
        <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s1">LOSSES:</span>
            <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">loss=loss</span><span class="s0">,</span>
                                <span class="s1">method=self.method)</span>
            <span class="s1">assert_equal(res.fun</span><span class="s0">, </span><span class="s1">fun_trivial(res.x))</span>

    <span class="s0">def </span><span class="s1">test_grad(self):</span>
        <span class="s3"># Test that res.grad is true gradient of loss function at the</span>
        <span class="s3"># solution. Use max_nfev = 1, to avoid reaching minimum.</span>
        <span class="s1">x = np.array([</span><span class="s2">2.0</span><span class="s1">])  </span><span class="s3"># res.x will be this.</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'linear'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_equal(res.grad</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">))</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'huber'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_equal(res.grad</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x)</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'soft_l1'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.grad</span><span class="s0">,</span>
                        <span class="s2">2 </span><span class="s1">* x * (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">) / (</span><span class="s2">1 </span><span class="s1">+ (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">)**</span><span class="s2">2</span><span class="s1">)**</span><span class="s2">0.5</span><span class="s1">)</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'cauchy'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.grad</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">) / (</span><span class="s2">1 </span><span class="s1">+ (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">)**</span><span class="s2">2</span><span class="s1">))</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'arctan'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.grad</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">) / (</span><span class="s2">1 </span><span class="s1">+ (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">)**</span><span class="s2">4</span><span class="s1">))</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=cubic_soft_l1</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.grad</span><span class="s0">,</span>
                        <span class="s2">2 </span><span class="s1">* x * (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">) / (</span><span class="s2">1 </span><span class="s1">+ (x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5</span><span class="s1">)**</span><span class="s2">2</span><span class="s1">)**(</span><span class="s2">2</span><span class="s1">/</span><span class="s2">3</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">test_jac(self):</span>
        <span class="s3"># Test that res.jac.T.dot(res.jac) gives Gauss-Newton approximation</span>
        <span class="s3"># of Hessian. This approximation is computed by doubly differentiating</span>
        <span class="s3"># the cost function and dropping the part containing second derivative</span>
        <span class="s3"># of f. For a scalar function it is computed as</span>
        <span class="s3"># H = (rho' + 2 * rho'' * f**2) * f'**2, if the expression inside the</span>
        <span class="s3"># brackets is less than EPS it is replaced by EPS. Here, we check</span>
        <span class="s3"># against the root of H.</span>

        <span class="s1">x = </span><span class="s2">2.0  </span><span class="s3"># res.x will be this.</span>
        <span class="s1">f = x**</span><span class="s2">2 </span><span class="s1">+ </span><span class="s2">5  </span><span class="s3"># res.fun will be this.</span>

        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'linear'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_equal(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x)</span>

        <span class="s3"># For `huber` loss the Jacobian correction is identically zero</span>
        <span class="s3"># in outlier region, in such cases it is modified to be equal EPS**0.5.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'huber'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_equal(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * EPS**</span><span class="s2">0.5</span><span class="s1">)</span>

        <span class="s3"># Now, let's apply `loss_scale` to turn the residual into an inlier.</span>
        <span class="s3"># The loss function becomes linear.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'huber'</span><span class="s0">,</span>
                            <span class="s1">f_scale=</span><span class="s2">10</span><span class="s0">, </span><span class="s1">max_nfev=</span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x)</span>

        <span class="s3"># 'soft_l1' always gives a positive scaling.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'soft_l1'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (</span><span class="s2">1 </span><span class="s1">+ f**</span><span class="s2">2</span><span class="s1">)**-</span><span class="s2">0.75</span><span class="s1">)</span>

        <span class="s3"># For 'cauchy' the correction term turns out to be negative, and it</span>
        <span class="s3"># replaced by EPS**0.5.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'cauchy'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * EPS**</span><span class="s2">0.5</span><span class="s1">)</span>

        <span class="s3"># Now use scaling to turn the residual to inlier.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'cauchy'</span><span class="s0">,</span>
                            <span class="s1">f_scale=</span><span class="s2">10</span><span class="s0">, </span><span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">fs = f / </span><span class="s2">10</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (</span><span class="s2">1 </span><span class="s1">- fs**</span><span class="s2">2</span><span class="s1">)**</span><span class="s2">0.5 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ fs**</span><span class="s2">2</span><span class="s1">))</span>

        <span class="s3"># 'arctan' gives an outlier.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'arctan'</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * EPS**</span><span class="s2">0.5</span><span class="s1">)</span>

        <span class="s3"># Turn to inlier.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'arctan'</span><span class="s0">,</span>
                            <span class="s1">f_scale=</span><span class="s2">20.0</span><span class="s0">, </span><span class="s1">max_nfev=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">method=self.method)</span>
        <span class="s1">fs = f / </span><span class="s2">20</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * (</span><span class="s2">1 </span><span class="s1">- </span><span class="s2">3 </span><span class="s1">* fs**</span><span class="s2">4</span><span class="s1">)**</span><span class="s2">0.5 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ fs**</span><span class="s2">4</span><span class="s1">))</span>

        <span class="s3"># cubic_soft_l1 will give an outlier.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">, </span><span class="s1">loss=cubic_soft_l1</span><span class="s0">,</span>
                            <span class="s1">max_nfev=</span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">, </span><span class="s2">2 </span><span class="s1">* x * EPS**</span><span class="s2">0.5</span><span class="s1">)</span>

        <span class="s3"># Turn to inlier.</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">jac_trivial</span><span class="s0">,</span>
                            <span class="s1">loss=cubic_soft_l1</span><span class="s0">, </span><span class="s1">f_scale=</span><span class="s2">6</span><span class="s0">, </span><span class="s1">max_nfev=</span><span class="s2">1</span><span class="s1">)</span>
        <span class="s1">fs = f / </span><span class="s2">6</span>
        <span class="s1">assert_allclose(res.jac</span><span class="s0">,</span>
                        <span class="s2">2 </span><span class="s1">* x * (</span><span class="s2">1 </span><span class="s1">- fs**</span><span class="s2">2 </span><span class="s1">/ </span><span class="s2">3</span><span class="s1">)**</span><span class="s2">0.5 </span><span class="s1">* (</span><span class="s2">1 </span><span class="s1">+ fs**</span><span class="s2">2</span><span class="s1">)**(-</span><span class="s2">5</span><span class="s1">/</span><span class="s2">6</span><span class="s1">))</span>

    <span class="s0">def </span><span class="s1">test_robustness(self):</span>
        <span class="s0">for </span><span class="s1">noise </span><span class="s0">in </span><span class="s1">[</span><span class="s2">0.1</span><span class="s0">, </span><span class="s2">1.0</span><span class="s1">]:</span>
            <span class="s1">p = ExponentialFittingProblem(</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0.1</span><span class="s0">, </span><span class="s1">noise</span><span class="s0">, </span><span class="s1">random_seed=</span><span class="s2">0</span><span class="s1">)</span>

            <span class="s0">for </span><span class="s1">jac </span><span class="s0">in </span><span class="s1">[</span><span class="s4">'2-point'</span><span class="s0">, </span><span class="s4">'3-point'</span><span class="s0">, </span><span class="s4">'cs'</span><span class="s0">, </span><span class="s1">p.jac]:</span>
                <span class="s1">res_lsq = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.p0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">,</span>
                                        <span class="s1">method=self.method)</span>
                <span class="s1">assert_allclose(res_lsq.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s1">)</span>
                <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s1">LOSSES:</span>
                    <span class="s0">if </span><span class="s1">loss == </span><span class="s4">'linear'</span><span class="s1">:</span>
                        <span class="s0">continue</span>
                    <span class="s1">res_robust = least_squares(</span>
                        <span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.p0</span><span class="s0">, </span><span class="s1">jac=jac</span><span class="s0">, </span><span class="s1">loss=loss</span><span class="s0">, </span><span class="s1">f_scale=noise</span><span class="s0">,</span>
                        <span class="s1">method=self.method)</span>
                    <span class="s1">assert_allclose(res_robust.optimality</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-2</span><span class="s1">)</span>
                    <span class="s1">assert_(norm(res_robust.x - p.p_opt) &lt;</span>
                            <span class="s1">norm(res_lsq.x - p.p_opt))</span>


<span class="s0">class </span><span class="s1">TestDogbox(BaseMixin</span><span class="s0">, </span><span class="s1">BoundsMixin</span><span class="s0">, </span><span class="s1">SparseMixin</span><span class="s0">, </span><span class="s1">LossFunctionMixin):</span>
    <span class="s1">method = </span><span class="s4">'dogbox'</span>


<span class="s0">class </span><span class="s1">TestTRF(BaseMixin</span><span class="s0">, </span><span class="s1">BoundsMixin</span><span class="s0">, </span><span class="s1">SparseMixin</span><span class="s0">, </span><span class="s1">LossFunctionMixin):</span>
    <span class="s1">method = </span><span class="s4">'trf'</span>

    <span class="s0">def </span><span class="s1">test_lsmr_regularization(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s0">for </span><span class="s1">regularize </span><span class="s0">in </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">]:</span>
            <span class="s1">res = least_squares(p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'trf'</span><span class="s0">,</span>
                                <span class="s1">tr_options={</span><span class="s4">'regularize'</span><span class="s1">: regularize})</span>
            <span class="s1">assert_allclose(res.cost</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-20</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">TestLM(BaseMixin):</span>
    <span class="s1">method = </span><span class="s4">'lm'</span>

    <span class="s0">def </span><span class="s1">test_bounds_not_supported(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">,</span>
                      <span class="s2">2.0</span><span class="s0">, </span><span class="s1">bounds=(-</span><span class="s2">3.0</span><span class="s0">, </span><span class="s2">3.0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_m_less_n_not_supported(self):</span>
        <span class="s1">x0 = [-</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_rosenbrock_cropped</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">,</span>
                      <span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_sparse_not_supported(self):</span>
        <span class="s1">p = BroydenTridiagonal()</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_jac_sparsity_not_supported(self):</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">jac_sparsity=[</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_LinearOperator_not_supported(self):</span>
        <span class="s1">p = BroydenTridiagonal(mode=</span><span class="s4">&quot;operator&quot;</span><span class="s1">)</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">p.fun</span><span class="s0">, </span><span class="s1">p.x0</span><span class="s0">, </span><span class="s1">p.jac</span><span class="s0">,</span>
                      <span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">test_loss(self):</span>
        <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'linear'</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>
        <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0.0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-4</span><span class="s1">)</span>

        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">,</span>
                      <span class="s1">method=</span><span class="s4">'lm'</span><span class="s0">, </span><span class="s1">loss=</span><span class="s4">'huber'</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_basic():</span>
    <span class="s3"># test that 'method' arg is really optional</span>
    <span class="s1">res = least_squares(fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-10</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_small_tolerances_for_lm():</span>
    <span class="s0">for </span><span class="s1">ftol</span><span class="s0">, </span><span class="s1">xtol</span><span class="s0">, </span><span class="s1">gtol </span><span class="s0">in </span><span class="s1">[(</span><span class="s0">None, </span><span class="s2">1e-13</span><span class="s0">, </span><span class="s2">1e-13</span><span class="s1">)</span><span class="s0">,</span>
                             <span class="s1">(</span><span class="s2">1e-13</span><span class="s0">, None, </span><span class="s2">1e-13</span><span class="s1">)</span><span class="s0">,</span>
                             <span class="s1">(</span><span class="s2">1e-13</span><span class="s0">, </span><span class="s2">1e-13</span><span class="s0">, None</span><span class="s1">)]:</span>
        <span class="s1">assert_raises(ValueError</span><span class="s0">, </span><span class="s1">least_squares</span><span class="s0">, </span><span class="s1">fun_trivial</span><span class="s0">, </span><span class="s2">2.0</span><span class="s0">, </span><span class="s1">xtol=xtol</span><span class="s0">,</span>
                      <span class="s1">ftol=ftol</span><span class="s0">, </span><span class="s1">gtol=gtol</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'lm'</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_fp32_gh12991():</span>
    <span class="s3"># checks that smaller FP sizes can be used in least_squares</span>
    <span class="s3"># this is the minimum working example reported for gh12991</span>
    <span class="s1">np.random.seed(</span><span class="s2">1</span><span class="s1">)</span>

    <span class="s1">x = np.linspace(</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">100</span><span class="s1">).astype(</span><span class="s4">&quot;float32&quot;</span><span class="s1">)</span>
    <span class="s1">y = np.random.random(</span><span class="s2">100</span><span class="s1">).astype(</span><span class="s4">&quot;float32&quot;</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">func(p</span><span class="s0">, </span><span class="s1">x):</span>
        <span class="s0">return </span><span class="s1">p[</span><span class="s2">0</span><span class="s1">] + p[</span><span class="s2">1</span><span class="s1">] * x</span>

    <span class="s0">def </span><span class="s1">err(p</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">y):</span>
        <span class="s0">return </span><span class="s1">func(p</span><span class="s0">, </span><span class="s1">x) - y</span>

    <span class="s1">res = least_squares(err</span><span class="s0">, </span><span class="s1">[-</span><span class="s2">1.0</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">args=(x</span><span class="s0">, </span><span class="s1">y))</span>
    <span class="s3"># previously the initial jacobian calculated for this would be all 0</span>
    <span class="s3"># and the minimize would terminate immediately, with nfev=1, would</span>
    <span class="s3"># report a successful minimization (it shouldn't have done), but be</span>
    <span class="s3"># unchanged from the initial solution.</span>
    <span class="s3"># It was terminating early because the underlying approx_derivative</span>
    <span class="s3"># used a step size for FP64 when the working space was FP32.</span>
    <span class="s0">assert </span><span class="s1">res.nfev &gt; </span><span class="s2">2</span>
    <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">np.array([</span><span class="s2">0.4082241</span><span class="s0">, </span><span class="s2">0.15530563</span><span class="s1">])</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">5e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_gh_18793():</span>
    <span class="s1">answer = </span><span class="s2">1e-12</span>
    <span class="s1">initial_guess = </span><span class="s2">1.1e-12</span>

    <span class="s0">def </span><span class="s1">chi2(x):</span>
        <span class="s0">return </span><span class="s1">(x-answer)**</span><span class="s2">2</span>

    <span class="s1">res = least_squares(chi2</span><span class="s0">, </span><span class="s1">x0=initial_guess</span><span class="s0">, </span><span class="s1">bounds=(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">np.inf))</span>
    <span class="s3"># if we choose an initial condition that is close to the solution</span>
    <span class="s3"># we shouldn't return an answer that is further away from the solution</span>
    <span class="s1">assert_allclose(res.x</span><span class="s0">, </span><span class="s1">answer</span><span class="s0">, </span><span class="s1">atol=initial_guess-answer)</span>


<span class="s0">def </span><span class="s1">test_gh_19103():</span>
    <span class="s3"># Checks that least_squares trf method selects a strictly feasible point,</span>
    <span class="s3"># and thus succeeds instead of failing,</span>
    <span class="s3"># when the initial guess is reported exactly at a boundary point.</span>
    <span class="s3"># This is a reduced example from gh191303</span>

    <span class="s1">ydata = np.array([</span><span class="s2">0.</span><span class="s1">] * </span><span class="s2">66 </span><span class="s1">+ [</span>
        <span class="s2">1.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">,</span>
        <span class="s2">1.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">,</span>
        <span class="s2">0.</span><span class="s0">, </span><span class="s2">3.</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">6.</span><span class="s0">, </span><span class="s2">5.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">0.</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">, </span><span class="s2">8.</span><span class="s0">, </span><span class="s2">4.</span><span class="s0">, </span><span class="s2">4.</span><span class="s0">,</span>
        <span class="s2">6.</span><span class="s0">, </span><span class="s2">9.</span><span class="s0">, </span><span class="s2">7.</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">, </span><span class="s2">7.</span><span class="s0">, </span><span class="s2">8.</span><span class="s0">, </span><span class="s2">2.</span><span class="s0">, </span><span class="s2">13.</span><span class="s0">, </span><span class="s2">9.</span><span class="s0">, </span><span class="s2">8.</span><span class="s0">, </span><span class="s2">11.</span><span class="s0">,</span>
        <span class="s2">10.</span><span class="s0">, </span><span class="s2">13.</span><span class="s0">, </span><span class="s2">14.</span><span class="s0">, </span><span class="s2">19.</span><span class="s0">, </span><span class="s2">11.</span><span class="s0">, </span><span class="s2">15.</span><span class="s0">, </span><span class="s2">18.</span><span class="s0">, </span><span class="s2">26.</span><span class="s0">, </span><span class="s2">19.</span><span class="s0">, </span><span class="s2">32.</span><span class="s0">, </span><span class="s2">29.</span><span class="s0">,</span>
        <span class="s2">28.</span><span class="s0">, </span><span class="s2">36.</span><span class="s0">, </span><span class="s2">32.</span><span class="s0">, </span><span class="s2">35.</span><span class="s0">, </span><span class="s2">36.</span><span class="s0">, </span><span class="s2">43.</span><span class="s0">, </span><span class="s2">52.</span><span class="s0">, </span><span class="s2">32.</span><span class="s0">, </span><span class="s2">58.</span><span class="s0">, </span><span class="s2">56.</span><span class="s0">, </span><span class="s2">52.</span><span class="s0">,</span>
        <span class="s2">67.</span><span class="s0">, </span><span class="s2">53.</span><span class="s0">, </span><span class="s2">72.</span><span class="s0">, </span><span class="s2">88.</span><span class="s0">, </span><span class="s2">77.</span><span class="s0">, </span><span class="s2">95.</span><span class="s0">, </span><span class="s2">94.</span><span class="s0">, </span><span class="s2">84.</span><span class="s0">, </span><span class="s2">86.</span><span class="s0">, </span><span class="s2">101.</span><span class="s0">, </span><span class="s2">107.</span><span class="s0">,</span>
        <span class="s2">108.</span><span class="s0">, </span><span class="s2">118.</span><span class="s0">, </span><span class="s2">96.</span><span class="s0">, </span><span class="s2">115.</span><span class="s0">, </span><span class="s2">138.</span><span class="s0">, </span><span class="s2">137.</span><span class="s0">,</span>
    <span class="s1">])</span>
    <span class="s1">xdata = np.arange(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">ydata.size) * </span><span class="s2">0.1</span>

    <span class="s0">def </span><span class="s1">exponential_wrapped(params):</span>
        <span class="s1">A</span><span class="s0">, </span><span class="s1">B</span><span class="s0">, </span><span class="s1">x0 = params</span>
        <span class="s0">return </span><span class="s1">A * np.exp(B * (xdata - x0)) - ydata</span>

    <span class="s1">x0 = [</span><span class="s2">0.01</span><span class="s0">, </span><span class="s2">1.</span><span class="s0">, </span><span class="s2">5.</span><span class="s1">]</span>
    <span class="s1">bounds = ((</span><span class="s2">0.01</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(np.inf</span><span class="s0">, </span><span class="s2">10</span><span class="s0">, </span><span class="s2">20.9</span><span class="s1">))</span>
    <span class="s1">res = least_squares(exponential_wrapped</span><span class="s0">, </span><span class="s1">x0</span><span class="s0">, </span><span class="s1">method=</span><span class="s4">'trf'</span><span class="s0">, </span><span class="s1">bounds=bounds)</span>
    <span class="s0">assert </span><span class="s1">res.success</span>
</pre>
</body>
</html>
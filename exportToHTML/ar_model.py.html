<html>
<head>
<title>ar_model.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
ar_model.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">from </span><span class="s1">statsmodels.compat.pandas </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Appender</span><span class="s2">,</span>
    <span class="s1">Substitution</span><span class="s2">,</span>
    <span class="s1">call_cached_func</span><span class="s2">,</span>
    <span class="s1">to_numpy</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">collections.abc </span><span class="s2">import </span><span class="s1">Iterable</span>
<span class="s2">import </span><span class="s1">datetime</span>
<span class="s2">import </span><span class="s1">datetime </span><span class="s2">as </span><span class="s1">dt</span>
<span class="s2">from </span><span class="s1">types </span><span class="s2">import </span><span class="s1">SimpleNamespace</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">Any</span><span class="s2">, </span><span class="s1">Literal</span><span class="s2">, </span><span class="s1">Sequence</span><span class="s2">, </span><span class="s1">cast</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">scipy.stats </span><span class="s2">import </span><span class="s1">gaussian_kde</span><span class="s2">, </span><span class="s1">norm</span>

<span class="s2">import </span><span class="s1">statsmodels.base.wrapper </span><span class="s2">as </span><span class="s1">wrap</span>
<span class="s2">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s2">import </span><span class="s1">Summary</span>
<span class="s2">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s2">import </span><span class="s1">OLS</span>
<span class="s2">from </span><span class="s1">statsmodels.tools </span><span class="s2">import </span><span class="s1">eval_measures</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span><span class="s2">, </span><span class="s1">cache_writable</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.docstring </span><span class="s2">import </span><span class="s1">Docstring</span><span class="s2">, </span><span class="s1">remove_parameters</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.sm_exceptions </span><span class="s2">import </span><span class="s1">SpecificationWarning</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ArrayLike</span><span class="s2">,</span>
    <span class="s1">ArrayLike1D</span><span class="s2">,</span>
    <span class="s1">ArrayLike2D</span><span class="s2">,</span>
    <span class="s1">Float64Array</span><span class="s2">,</span>
    <span class="s1">NDArray</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.validation </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">array_like</span><span class="s2">,</span>
    <span class="s1">bool_like</span><span class="s2">,</span>
    <span class="s1">int_like</span><span class="s2">,</span>
    <span class="s1">string_like</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.arima_process </span><span class="s2">import </span><span class="s1">arma2ma</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.base </span><span class="s2">import </span><span class="s1">tsa_model</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.base.prediction </span><span class="s2">import </span><span class="s1">PredictionResults</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.deterministic </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">DeterministicProcess</span><span class="s2">,</span>
    <span class="s1">DeterministicTerm</span><span class="s2">,</span>
    <span class="s1">Seasonality</span><span class="s2">,</span>
    <span class="s1">TimeTrend</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.tsatools </span><span class="s2">import </span><span class="s1">freq_to_period</span><span class="s2">, </span><span class="s1">lagmat</span>

<span class="s1">__all__ = [</span><span class="s3">&quot;AR&quot;</span><span class="s2">, </span><span class="s3">&quot;AutoReg&quot;</span><span class="s1">]</span>

<span class="s1">AR_DEPRECATION_WARN = </span><span class="s3">&quot;&quot;&quot; 
statsmodels.tsa.AR has been deprecated in favor of statsmodels.tsa.AutoReg and 
statsmodels.tsa.SARIMAX. 
 
AutoReg adds the ability to specify exogenous variables, include time trends, 
and add seasonal dummies. The AutoReg API differs from AR since the model is 
treated as immutable, and so the entire specification including the lag 
length must be specified when creating the model. This change is too 
substantial to incorporate into the existing AR api. The function 
ar_select_order performs lag length selection for AutoReg models. 
 
AutoReg only estimates parameters using conditional MLE (OLS). Use SARIMAX to 
estimate ARX and related models using full MLE via the Kalman Filter. 
 
To silence this warning and continue using AR until it is removed, use: 
 
import warnings 
warnings.filterwarnings('ignore', 'statsmodels.tsa.ar_model.AR', FutureWarning) 
&quot;&quot;&quot;</span>

<span class="s1">REPEATED_FIT_ERROR = </span><span class="s3">&quot;&quot;&quot; 
Model has been fit using maxlag={0}, method={1}, ic={2}, trend={3}. These 
cannot be changed in subsequent calls to `fit`. Instead, use a new instance of 
AR. 
&quot;&quot;&quot;</span>


<span class="s2">def </span><span class="s1">sumofsq(x: np.ndarray</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s4">0</span><span class="s1">) -&gt; float | np.ndarray:</span>
    <span class="s5">&quot;&quot;&quot;Helper function to calculate sum of squares along first axis&quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">np.sum(x**</span><span class="s4">2</span><span class="s2">, </span><span class="s1">axis=axis)</span>


<span class="s2">def </span><span class="s1">_get_period(data: pd.DatetimeIndex | pd.PeriodIndex</span><span class="s2">, </span><span class="s1">index_freq) -&gt; int:</span>
    <span class="s5">&quot;&quot;&quot;Shared helper to get period from frequenc or raise&quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">data.freq:</span>
        <span class="s2">return </span><span class="s1">freq_to_period(index_freq)</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span>
        <span class="s3">&quot;freq cannot be inferred from endog and model includes seasonal &quot;</span>
        <span class="s3">&quot;terms.  The number of periods must be explicitly set when the &quot;</span>
        <span class="s3">&quot;endog's index does not contain a frequency.&quot;</span>
    <span class="s1">)</span>


<span class="s2">class </span><span class="s1">AutoReg(tsa_model.TimeSeriesModel):</span>
    <span class="s5">&quot;&quot;&quot; 
    Autoregressive AR-X(p) model 
 
    Estimate an AR-X model using Conditional Maximum Likelihood (OLS). 
 
    Parameters 
    ---------- 
    endog : array_like 
        A 1-d endogenous response variable. The dependent variable. 
    lags : {None, int, list[int]} 
        The number of lags to include in the model if an integer or the 
        list of lag indices to include.  For example, [1, 4] will only 
        include lags 1 and 4 while lags=4 will include lags 1, 2, 3, and 4. 
        None excludes all AR lags, and behave identically to 0. 
    trend : {'n', 'c', 't', 'ct'} 
        The trend to include in the model: 
 
        * 'n' - No trend. 
        * 'c' - Constant only. 
        * 't' - Time trend only. 
        * 'ct' - Constant and time trend. 
 
    seasonal : bool 
        Flag indicating whether to include seasonal dummies in the model. If 
        seasonal is True and trend includes 'c', then the first period 
        is excluded from the seasonal terms. 
    exog : array_like, optional 
        Exogenous variables to include in the model. Must have the same number 
        of observations as endog and should be aligned so that endog[i] is 
        regressed on exog[i]. 
    hold_back : {None, int} 
        Initial observations to exclude from the estimation sample.  If None, 
        then hold_back is equal to the maximum lag in the model.  Set to a 
        non-zero value to produce comparable models with different lag 
        length.  For example, to compare the fit of a model with lags=3 and 
        lags=1, set hold_back=3 which ensures that both models are estimated 
        using observations 3,...,nobs. hold_back must be &gt;= the maximum lag in 
        the model. 
    period : {None, int} 
        The period of the data. Only used if seasonal is True. This parameter 
        can be omitted if using a pandas object for endog that contains a 
        recognized frequency. 
    missing : str 
        Available options are 'none', 'drop', and 'raise'. If 'none', no nan 
        checking is done. If 'drop', any observations with nans are dropped. 
        If 'raise', an error is raised. Default is 'none'. 
    deterministic : DeterministicProcess 
        A deterministic process.  If provided, trend and seasonal are ignored. 
        A warning is raised if trend is not &quot;n&quot; and seasonal is not False. 
    old_names : bool 
        Flag indicating whether to use the v0.11 names or the v0.12+ names. 
 
        .. deprecated:: 0.13.0 
 
           old_names is deprecated and will be removed after 0.14 is 
           released. You must update any code reliant on the old variable 
           names to use the new names. 
 
    See Also 
    -------- 
    statsmodels.tsa.statespace.sarimax.SARIMAX 
        Estimation of SARIMAX models using exact likelihood and the 
        Kalman Filter. 
 
    Notes 
    ----- 
    See the notebook `Autoregressions 
    &lt;../examples/notebooks/generated/autoregressions.html&gt;`__ for an overview. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; from statsmodels.tsa.ar_model import AutoReg 
    &gt;&gt;&gt; data = sm.datasets.sunspots.load_pandas().data['SUNACTIVITY'] 
    &gt;&gt;&gt; out = 'AIC: {0:0.3f}, HQIC: {1:0.3f}, BIC: {2:0.3f}' 
 
    Start by fitting an unrestricted Seasonal AR model 
 
    &gt;&gt;&gt; res = AutoReg(data, lags = [1, 11, 12]).fit() 
    &gt;&gt;&gt; print(out.format(res.aic, res.hqic, res.bic)) 
    AIC: 5.945, HQIC: 5.970, BIC: 6.007 
 
    An alternative used seasonal dummies 
 
    &gt;&gt;&gt; res = AutoReg(data, lags=1, seasonal=True, period=11).fit() 
    &gt;&gt;&gt; print(out.format(res.aic, res.hqic, res.bic)) 
    AIC: 6.017, HQIC: 6.080, BIC: 6.175 
 
    Finally, both the seasonal AR structure and dummies can be included 
 
    &gt;&gt;&gt; res = AutoReg(data, lags=[1, 11, 12], seasonal=True, period=11).fit() 
    &gt;&gt;&gt; print(out.format(res.aic, res.hqic, res.bic)) 
    AIC: 5.884, HQIC: 5.959, BIC: 6.071 
    &quot;&quot;&quot;</span>

    <span class="s1">_y: Float64Array</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">endog: ArrayLike1D</span><span class="s2">,</span>
        <span class="s1">lags: int | Sequence[int] | </span><span class="s2">None,</span>
        <span class="s1">trend: Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;t&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s1">] = </span><span class="s3">&quot;c&quot;</span><span class="s2">,</span>
        <span class="s1">seasonal: bool = </span><span class="s2">False,</span>
        <span class="s1">exog: ArrayLike2D | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">hold_back: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">period: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">missing: str = </span><span class="s3">&quot;none&quot;</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">deterministic: DeterministicProcess | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">old_names: bool = </span><span class="s2">False,</span>
    <span class="s1">):</span>
        <span class="s1">super().__init__(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, None, None, </span><span class="s1">missing=missing)</span>
        <span class="s1">self._trend = cast(</span>
            <span class="s1">Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;t&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">string_like(</span>
                <span class="s1">trend</span><span class="s2">, </span><span class="s3">&quot;trend&quot;</span><span class="s2">, </span><span class="s1">options=(</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;t&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">False</span>
            <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">self._seasonal = bool_like(seasonal</span><span class="s2">, </span><span class="s3">&quot;seasonal&quot;</span><span class="s1">)</span>
        <span class="s1">self._period = int_like(period</span><span class="s2">, </span><span class="s3">&quot;period&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self._period </span><span class="s2">is None and </span><span class="s1">self._seasonal:</span>
            <span class="s1">self._period = _get_period(self.data</span><span class="s2">, </span><span class="s1">self._index_freq)</span>
        <span class="s1">terms: list[DeterministicTerm] = [TimeTrend.from_string(self._trend)]</span>
        <span class="s2">if </span><span class="s1">seasonal:</span>
            <span class="s2">assert </span><span class="s1">isinstance(self._period</span><span class="s2">, </span><span class="s1">int)</span>
            <span class="s1">terms.append(Seasonality(self._period))</span>
        <span class="s2">if </span><span class="s1">hasattr(self.data.orig_endog</span><span class="s2">, </span><span class="s3">&quot;index&quot;</span><span class="s1">):</span>
            <span class="s1">index = self.data.orig_endog.index</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">index = np.arange(self.data.endog.shape[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">self._user_deterministic = </span><span class="s2">False</span>
        <span class="s2">if </span><span class="s1">deterministic </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">isinstance(deterministic</span><span class="s2">, </span><span class="s1">DeterministicProcess):</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s3">&quot;deterministic must be a DeterministicProcess&quot;</span><span class="s1">)</span>
            <span class="s1">self._deterministics = deterministic</span>
            <span class="s1">self._user_deterministic = </span><span class="s2">True</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._deterministics = DeterministicProcess(</span>
                <span class="s1">index</span><span class="s2">, </span><span class="s1">additional_terms=terms</span>
            <span class="s1">)</span>
        <span class="s1">self._exog_names: list[str] = []</span>
        <span class="s1">self._k_ar = </span><span class="s4">0</span>
        <span class="s1">self._old_names = bool_like(old_names</span><span class="s2">, </span><span class="s3">&quot;old_names&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">deterministic </span><span class="s2">is not None and </span><span class="s1">(</span>
            <span class="s1">self._trend != </span><span class="s3">&quot;n&quot; </span><span class="s2">or </span><span class="s1">self._seasonal</span>
        <span class="s1">):</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">'When using deterministic, trend must be &quot;n&quot; and '</span>
                <span class="s3">&quot;seasonal must be False.&quot;</span><span class="s2">,</span>
                <span class="s1">SpecificationWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=</span><span class="s4">2</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self._old_names:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s3">&quot;old_names will be removed after the 0.14 release. You should &quot;</span>
                <span class="s3">&quot;stop setting this parameter and use the new names.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=</span><span class="s4">2</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s1">self._lags</span><span class="s2">, </span><span class="s1">self._hold_back = self._check_lags(</span>
            <span class="s1">lags</span><span class="s2">, </span><span class="s1">int_like(hold_back</span><span class="s2">, </span><span class="s3">&quot;hold_back&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">)</span>
        <span class="s1">self._setup_regressors()</span>
        <span class="s1">self.nobs = self._y.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">self.data.xnames = self.exog_names</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">ar_lags(self) -&gt; list[int] | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The autoregressive lags included in the model&quot;&quot;&quot;</span>
        <span class="s1">lags = list(self._lags)</span>
        <span class="s2">return None if not </span><span class="s1">lags </span><span class="s2">else </span><span class="s1">lags</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">hold_back(self) -&gt; int | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The number of initial obs. excluded from the estimation sample.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._hold_back</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">trend(self) -&gt; Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s2">, </span><span class="s3">&quot;ctt&quot;</span><span class="s1">]:</span>
        <span class="s5">&quot;&quot;&quot;The trend used in the model.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._trend</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">seasonal(self) -&gt; bool:</span>
        <span class="s5">&quot;&quot;&quot;Flag indicating that the model contains a seasonal component.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._seasonal</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">deterministic(self) -&gt; DeterministicProcess | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The deterministic used to construct the model&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._deterministics </span><span class="s2">if </span><span class="s1">self._user_deterministic </span><span class="s2">else None</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">period(self) -&gt; int | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The period of the seasonal component.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._period</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">df_model(self) -&gt; int:</span>
        <span class="s5">&quot;&quot;&quot;The model degrees of freedom.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._x.shape[</span><span class="s4">1</span><span class="s1">]</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">exog_names(self) -&gt; list[str] | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;Names of exogenous variables included in model&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._exog_names</span>

    <span class="s2">def </span><span class="s1">initialize(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;Initialize the model (no-op).&quot;&quot;&quot;</span>
        <span class="s2">pass</span>

    <span class="s2">def </span><span class="s1">_check_lags(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">lags: int | Sequence[int] | </span><span class="s2">None, </span><span class="s1">hold_back: int | </span><span class="s2">None</span>
    <span class="s1">) -&gt; tuple[list[int]</span><span class="s2">, </span><span class="s1">int]:</span>
        <span class="s2">if </span><span class="s1">lags </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">_lags: list[int] = []</span>
            <span class="s1">self._maxlag = </span><span class="s4">0</span>
        <span class="s2">elif </span><span class="s1">isinstance(lags</span><span class="s2">, </span><span class="s1">Iterable):</span>
            <span class="s1">_lags = []</span>
            <span class="s2">for </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">lags:</span>
                <span class="s1">val = int_like(lag</span><span class="s2">, </span><span class="s3">&quot;lags&quot;</span><span class="s1">)</span>
                <span class="s2">assert </span><span class="s1">isinstance(val</span><span class="s2">, </span><span class="s1">int)</span>
                <span class="s1">_lags.append(val)</span>
            <span class="s1">_lags_arr: NDArray = np.array(sorted(_lags))</span>
            <span class="s2">if </span><span class="s1">(</span>
                <span class="s1">np.any(_lags_arr &lt; </span><span class="s4">1</span><span class="s1">)</span>
                <span class="s2">or </span><span class="s1">np.unique(_lags_arr).shape[</span><span class="s4">0</span><span class="s1">] != _lags_arr.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;All values in lags must be positive and distinct.&quot;</span>
                <span class="s1">)</span>
            <span class="s1">self._maxlag = np.max(_lags_arr)</span>
            <span class="s1">_lags = [int(v) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">_lags_arr]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">val = int_like(lags</span><span class="s2">, </span><span class="s3">&quot;lags&quot;</span><span class="s1">)</span>
            <span class="s2">assert </span><span class="s1">isinstance(val</span><span class="s2">, </span><span class="s1">int)</span>
            <span class="s1">self._maxlag = val</span>
            <span class="s2">if </span><span class="s1">self._maxlag &lt; </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;lags must be a non-negative scalar.&quot;</span><span class="s1">)</span>
            <span class="s1">_lags_arr = np.arange(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self._maxlag + </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">_lags = [int(v) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">_lags_arr]</span>

        <span class="s2">if </span><span class="s1">hold_back </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">hold_back = self._maxlag</span>
        <span class="s2">if </span><span class="s1">hold_back &lt; self._maxlag:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;hold_back must be &gt;= lags if lags is an int or&quot;</span>
                <span class="s3">&quot;max(lags) if lags is array_like.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">_lags</span><span class="s2">, </span><span class="s1">int(hold_back)</span>

    <span class="s2">def </span><span class="s1">_setup_regressors(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">maxlag = self._maxlag</span>
        <span class="s1">hold_back = self._hold_back</span>
        <span class="s1">exog_names = []</span>
        <span class="s1">endog_names = self.endog_names</span>
        <span class="s1">x</span><span class="s2">, </span><span class="s1">y = lagmat(self.endog</span><span class="s2">, </span><span class="s1">maxlag</span><span class="s2">, </span><span class="s1">original=</span><span class="s3">&quot;sep&quot;</span><span class="s1">)</span>
        <span class="s1">exog_names.extend(</span>
            <span class="s1">[endog_names + </span><span class="s3">&quot;.L{0}&quot;</span><span class="s1">.format(lag) </span><span class="s2">for </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">self._lags]</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(self._lags) &lt; maxlag:</span>
            <span class="s1">x = x[:</span><span class="s2">, </span><span class="s1">np.asarray(self._lags) - </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">self._k_ar = x.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">deterministic = self._deterministics.in_sample()</span>
        <span class="s2">if </span><span class="s1">deterministic.shape[</span><span class="s4">1</span><span class="s1">]:</span>
            <span class="s1">x = np.c_[to_numpy(deterministic)</span><span class="s2">, </span><span class="s1">x]</span>
            <span class="s2">if </span><span class="s1">self._old_names:</span>
                <span class="s1">deterministic_names = []</span>
                <span class="s2">if </span><span class="s3">&quot;c&quot; </span><span class="s2">in </span><span class="s1">self._trend:</span>
                    <span class="s1">deterministic_names.append(</span><span class="s3">&quot;intercept&quot;</span><span class="s1">)</span>
                <span class="s2">if </span><span class="s3">&quot;t&quot; </span><span class="s2">in </span><span class="s1">self._trend:</span>
                    <span class="s1">deterministic_names.append(</span><span class="s3">&quot;trend&quot;</span><span class="s1">)</span>
                <span class="s2">if </span><span class="s1">self._seasonal:</span>
                    <span class="s1">period = self._period</span>
                    <span class="s2">assert </span><span class="s1">isinstance(period</span><span class="s2">, </span><span class="s1">int)</span>
                    <span class="s1">names = [</span><span class="s3">&quot;seasonal.{0}&quot;</span><span class="s1">.format(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(period)]</span>
                    <span class="s2">if </span><span class="s3">&quot;c&quot; </span><span class="s2">in </span><span class="s1">self._trend:</span>
                        <span class="s1">names = names[</span><span class="s4">1</span><span class="s1">:]</span>
                    <span class="s1">deterministic_names.extend(names)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">deterministic_names = list(deterministic.columns)</span>
            <span class="s1">exog_names = deterministic_names + exog_names</span>
        <span class="s2">if </span><span class="s1">self.exog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">x = np.c_[x</span><span class="s2">, </span><span class="s1">self.exog]</span>
            <span class="s1">exog_names.extend(self.data.param_names)</span>
        <span class="s1">y = y[hold_back:]</span>
        <span class="s1">x = x[hold_back:]</span>
        <span class="s2">if </span><span class="s1">y.shape[</span><span class="s4">0</span><span class="s1">] &lt; x.shape[</span><span class="s4">1</span><span class="s1">]:</span>
            <span class="s1">reg = x.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">period = self._period</span>
            <span class="s1">trend = </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">self._trend == </span><span class="s3">&quot;n&quot; </span><span class="s2">else </span><span class="s1">len(self._trend)</span>
            <span class="s2">if </span><span class="s1">self._seasonal:</span>
                <span class="s2">assert </span><span class="s1">isinstance(period</span><span class="s2">, </span><span class="s1">int)</span>
                <span class="s1">seas = period - int(</span><span class="s3">&quot;c&quot; </span><span class="s2">in </span><span class="s1">self._trend)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">seas = </span><span class="s4">0</span>
            <span class="s1">lags = len(self._lags)</span>
            <span class="s1">nobs = y.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;The model specification cannot be estimated. &quot;</span>
                <span class="s3">f&quot;The model contains </span><span class="s2">{</span><span class="s1">reg</span><span class="s2">} </span><span class="s3">regressors (</span><span class="s2">{</span><span class="s1">trend</span><span class="s2">} </span><span class="s3">trend, &quot;</span>
                <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">seas</span><span class="s2">} </span><span class="s3">seasonal, </span><span class="s2">{</span><span class="s1">lags</span><span class="s2">} </span><span class="s3">lags) but after adjustment &quot;</span>
                <span class="s3">&quot;for hold_back and creation of the lags, there &quot;</span>
                <span class="s3">f&quot;are only </span><span class="s2">{</span><span class="s1">nobs</span><span class="s2">} </span><span class="s3">data points available to estimate &quot;</span>
                <span class="s3">&quot;parameters.&quot;</span>
            <span class="s1">)</span>
        <span class="s1">self._y</span><span class="s2">, </span><span class="s1">self._x = y</span><span class="s2">, </span><span class="s1">x</span>
        <span class="s1">self._exog_names = exog_names</span>

    <span class="s2">def </span><span class="s1">fit(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">cov_type: str = </span><span class="s3">&quot;nonrobust&quot;</span><span class="s2">,</span>
        <span class="s1">cov_kwds: dict[str</span><span class="s2">, </span><span class="s1">Any] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">use_t: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; AutoRegResultsWrapper:</span>
        <span class="s5">&quot;&quot;&quot; 
        Estimate the model parameters. 
 
        Parameters 
        ---------- 
        cov_type : str 
            The covariance estimator to use. The most common choices are listed 
            below.  Supports all covariance estimators that are available 
            in ``OLS.fit``. 
 
            * 'nonrobust' - The class OLS covariance estimator that assumes 
              homoskedasticity. 
            * 'HC0', 'HC1', 'HC2', 'HC3' - Variants of White's 
              (or Eiker-Huber-White) covariance estimator. `HC0` is the 
              standard implementation.  The other make corrections to improve 
              the finite sample performance of the heteroskedasticity robust 
              covariance estimator. 
            * 'HAC' - Heteroskedasticity-autocorrelation robust covariance 
              estimation. Supports cov_kwds. 
 
              - `maxlags` integer (required) : number of lags to use. 
              - `kernel` callable or str (optional) : kernel 
                  currently available kernels are ['bartlett', 'uniform'], 
                  default is Bartlett. 
              - `use_correction` bool (optional) : If true, use small sample 
                  correction. 
        cov_kwds : dict, optional 
            A dictionary of keyword arguments to pass to the covariance 
            estimator. `nonrobust` and `HC#` do not support cov_kwds. 
        use_t : bool, optional 
            A flag indicating that inference should use the Student's t 
            distribution that accounts for model degree of freedom.  If False, 
            uses the normal distribution. If None, defers the choice to 
            the cov_type. It also removes degree of freedom corrections from 
            the covariance estimator when cov_type is 'nonrobust'. 
 
        Returns 
        ------- 
        AutoRegResults 
            Estimation results. 
 
        See Also 
        -------- 
        statsmodels.regression.linear_model.OLS 
            Ordinary Least Squares estimation. 
        statsmodels.regression.linear_model.RegressionResults 
            See ``get_robustcov_results`` for a detailed list of available 
            covariance estimators and options. 
 
        Notes 
        ----- 
        Use ``OLS`` to estimate model parameters and to estimate parameter 
        covariance. 
        &quot;&quot;&quot;</span>
        <span class="s0"># TODO: Determine correction for degree-of-freedom</span>
        <span class="s0"># Special case parameterless model</span>
        <span class="s2">if </span><span class="s1">self._x.shape[</span><span class="s4">1</span><span class="s1">] == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">AutoRegResultsWrapper(</span>
                <span class="s1">AutoRegResults(self</span><span class="s2">, </span><span class="s1">np.empty(</span><span class="s4">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.empty((</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)))</span>
            <span class="s1">)</span>

        <span class="s1">ols_mod = OLS(self._y</span><span class="s2">, </span><span class="s1">self._x)</span>
        <span class="s1">ols_res = ols_mod.fit(</span>
            <span class="s1">cov_type=cov_type</span><span class="s2">, </span><span class="s1">cov_kwds=cov_kwds</span><span class="s2">, </span><span class="s1">use_t=use_t</span>
        <span class="s1">)</span>
        <span class="s1">cov_params = ols_res.cov_params()</span>
        <span class="s1">use_t = ols_res.use_t</span>
        <span class="s2">if </span><span class="s1">cov_type == </span><span class="s3">&quot;nonrobust&quot; </span><span class="s2">and not </span><span class="s1">use_t:</span>
            <span class="s1">nobs = self._y.shape[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s1">k = self._x.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">scale = nobs / (nobs - k)</span>
            <span class="s1">cov_params /= scale</span>
        <span class="s1">res = AutoRegResults(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">ols_res.params</span><span class="s2">,</span>
            <span class="s1">cov_params</span><span class="s2">,</span>
            <span class="s1">ols_res.normalized_cov_params</span><span class="s2">,</span>
            <span class="s1">use_t=use_t</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">AutoRegResultsWrapper(res)</span>

    <span class="s2">def </span><span class="s1">_resid(self</span><span class="s2">, </span><span class="s1">params: ArrayLike) -&gt; np.ndarray:</span>
        <span class="s1">params = array_like(params</span><span class="s2">, </span><span class="s3">&quot;params&quot;</span><span class="s2">, </span><span class="s1">ndim=</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._y.squeeze() - (self._x @ params).squeeze()</span>

    <span class="s2">def </span><span class="s1">loglike(self</span><span class="s2">, </span><span class="s1">params: ArrayLike) -&gt; float:</span>
        <span class="s5">&quot;&quot;&quot; 
        Log-likelihood of model. 
 
        Parameters 
        ---------- 
        params : ndarray 
            The model parameters used to compute the log-likelihood. 
 
        Returns 
        ------- 
        float 
            The log-likelihood value. 
        &quot;&quot;&quot;</span>
        <span class="s1">nobs = self.nobs</span>
        <span class="s1">resid = self._resid(params)</span>
        <span class="s1">ssr = resid @ resid</span>
        <span class="s1">llf = -(nobs / </span><span class="s4">2</span><span class="s1">) * (np.log(</span><span class="s4">2 </span><span class="s1">* np.pi) + np.log(ssr / nobs) + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">llf</span>

    <span class="s2">def </span><span class="s1">score(self</span><span class="s2">, </span><span class="s1">params: ArrayLike) -&gt; np.ndarray:</span>
        <span class="s5">&quot;&quot;&quot; 
        Score vector of model. 
 
        The gradient of logL with respect to each parameter. 
 
        Parameters 
        ---------- 
        params : ndarray 
            The parameters to use when evaluating the Hessian. 
 
        Returns 
        ------- 
        ndarray 
            The score vector evaluated at the parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">resid = self._resid(params)</span>
        <span class="s2">return </span><span class="s1">self._x.T @ resid</span>

    <span class="s2">def </span><span class="s1">information(self</span><span class="s2">, </span><span class="s1">params: ArrayLike) -&gt; np.ndarray:</span>
        <span class="s5">&quot;&quot;&quot; 
        Fisher information matrix of model. 
 
        Returns -1 * Hessian of the log-likelihood evaluated at params. 
 
        Parameters 
        ---------- 
        params : ndarray 
            The model parameters. 
 
        Returns 
        ------- 
        ndarray 
            The information matrix. 
        &quot;&quot;&quot;</span>
        <span class="s1">resid = self._resid(params)</span>
        <span class="s1">sigma2 = resid @ resid / self.nobs</span>
        <span class="s2">return </span><span class="s1">(self._x.T @ self._x) * (</span><span class="s4">1 </span><span class="s1">/ sigma2)</span>

    <span class="s2">def </span><span class="s1">hessian(self</span><span class="s2">, </span><span class="s1">params: ArrayLike) -&gt; np.ndarray:</span>
        <span class="s5">&quot;&quot;&quot; 
        The Hessian matrix of the model. 
 
        Parameters 
        ---------- 
        params : ndarray 
            The parameters to use when evaluating the Hessian. 
 
        Returns 
        ------- 
        ndarray 
            The hessian evaluated at the parameters. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">-self.information(params)</span>

    <span class="s2">def </span><span class="s1">_setup_oos_forecast(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">add_forecasts: int</span><span class="s2">, </span><span class="s1">exog_oos: ArrayLike2D</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s1">x = np.zeros((add_forecasts</span><span class="s2">, </span><span class="s1">self._x.shape[</span><span class="s4">1</span><span class="s1">]))</span>
        <span class="s1">oos_exog = self._deterministics.out_of_sample(steps=add_forecasts)</span>
        <span class="s1">n_deterministic = oos_exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">x[:</span><span class="s2">, </span><span class="s1">:n_deterministic] = to_numpy(oos_exog)</span>
        <span class="s0"># skip the AR columns</span>
        <span class="s1">loc = n_deterministic + len(self._lags)</span>
        <span class="s2">if </span><span class="s1">self.exog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">exog_oos_a = np.asarray(exog_oos)</span>
            <span class="s1">x[:</span><span class="s2">, </span><span class="s1">loc:] = exog_oos_a[:add_forecasts]</span>
        <span class="s2">return </span><span class="s1">x</span>

    <span class="s2">def </span><span class="s1">_wrap_prediction(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">prediction: np.ndarray</span><span class="s2">, </span><span class="s1">start: int</span><span class="s2">, </span><span class="s1">end: int</span><span class="s2">, </span><span class="s1">pad: int</span>
    <span class="s1">) -&gt; pd.Series:</span>
        <span class="s1">prediction = np.hstack([np.full(pad</span><span class="s2">, </span><span class="s1">np.nan)</span><span class="s2">, </span><span class="s1">prediction])</span>
        <span class="s1">n_values = end - start + pad</span>
        <span class="s2">if not </span><span class="s1">isinstance(self.data.orig_endog</span><span class="s2">, </span><span class="s1">(pd.Series</span><span class="s2">, </span><span class="s1">pd.DataFrame)):</span>
            <span class="s2">return </span><span class="s1">prediction[-n_values:]</span>
        <span class="s1">index = self._index</span>
        <span class="s2">if </span><span class="s1">end &gt; self.endog.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s1">freq = getattr(index</span><span class="s2">, </span><span class="s3">&quot;freq&quot;</span><span class="s2">, None</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">freq:</span>
                <span class="s2">if </span><span class="s1">isinstance(index</span><span class="s2">, </span><span class="s1">pd.PeriodIndex):</span>
                    <span class="s1">index = pd.period_range(index[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">freq=freq</span><span class="s2">, </span><span class="s1">periods=end)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">index = pd.date_range(index[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">freq=freq</span><span class="s2">, </span><span class="s1">periods=end)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">index = pd.RangeIndex(end)</span>
        <span class="s1">index = index[start - pad : end]</span>
        <span class="s1">prediction = prediction[-n_values:]</span>
        <span class="s2">return </span><span class="s1">pd.Series(prediction</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s2">def </span><span class="s1">_dynamic_predict(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">params: ArrayLike</span><span class="s2">,</span>
        <span class="s1">start: int</span><span class="s2">,</span>
        <span class="s1">end: int</span><span class="s2">,</span>
        <span class="s1">dynamic: int</span><span class="s2">,</span>
        <span class="s1">num_oos: int</span><span class="s2">,</span>
        <span class="s1">exog: Float64Array | </span><span class="s2">None,</span>
        <span class="s1">exog_oos: Float64Array | </span><span class="s2">None,</span>
    <span class="s1">) -&gt; pd.Series:</span>
        <span class="s5">&quot;&quot;&quot; 
 
        :param params: 
        :param start: 
        :param end: 
        :param dynamic: 
        :param num_oos: 
        :param exog: 
        :param exog_oos: 
        :return: 
        &quot;&quot;&quot;</span>
        <span class="s1">reg = []</span>
        <span class="s1">hold_back = self._hold_back</span>
        <span class="s1">adj = </span><span class="s4">0</span>
        <span class="s2">if </span><span class="s1">start &lt; hold_back:</span>
            <span class="s0"># Adjust start and dynamic</span>
            <span class="s1">adj = hold_back - start</span>
        <span class="s1">start += adj</span>
        <span class="s0"># New offset shifts, but must remain non-negative</span>
        <span class="s1">dynamic = max(dynamic - adj</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">(start - hold_back) &lt;= self.nobs:</span>
            <span class="s0"># _x is missing hold_back observations, which is why</span>
            <span class="s0"># it is shifted by this amount</span>
            <span class="s1">is_loc = slice(start - hold_back</span><span class="s2">, </span><span class="s1">end + </span><span class="s4">1 </span><span class="s1">- hold_back)</span>
            <span class="s1">x = self._x[is_loc]</span>
            <span class="s2">if </span><span class="s1">exog </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">x = x.copy()</span>
                <span class="s0"># Replace final columns</span>
                <span class="s1">x[:</span><span class="s2">, </span><span class="s1">-exog.shape[</span><span class="s4">1</span><span class="s1">] :] = exog[start : end + </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">reg.append(x)</span>
        <span class="s2">if </span><span class="s1">num_oos &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">reg.append(self._setup_oos_forecast(num_oos</span><span class="s2">, </span><span class="s1">exog_oos))</span>
        <span class="s1">_reg = np.vstack(reg)</span>
        <span class="s1">det_col_idx = self._x.shape[</span><span class="s4">1</span><span class="s1">] - len(self._lags)</span>
        <span class="s1">det_col_idx -= </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">self.exog </span><span class="s2">is None else </span><span class="s1">self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s0"># Simple 1-step static forecasts for dynamic observations</span>
        <span class="s1">forecasts = np.empty(_reg.shape[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">forecasts[:dynamic] = _reg[:dynamic] @ params</span>
        <span class="s2">for </span><span class="s1">h </span><span class="s2">in </span><span class="s1">range(dynamic</span><span class="s2">, </span><span class="s1">_reg.shape[</span><span class="s4">0</span><span class="s1">]):</span>
            <span class="s0"># Fill in regressor matrix</span>
            <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">enumerate(self._lags):</span>
                <span class="s1">fcast_loc = h - lag</span>
                <span class="s2">if </span><span class="s1">fcast_loc &gt;= dynamic:</span>
                    <span class="s1">val = forecasts[fcast_loc]</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s0"># If before the start of the forecasts, use actual values</span>
                    <span class="s1">val = self.endog[fcast_loc + start]</span>
                <span class="s1">_reg[h</span><span class="s2">, </span><span class="s1">det_col_idx + j] = val</span>
            <span class="s1">forecasts[h] = np.squeeze(_reg[h : h + </span><span class="s4">1</span><span class="s1">] @ params)</span>
        <span class="s2">return </span><span class="s1">self._wrap_prediction(forecasts</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end + </span><span class="s4">1 </span><span class="s1">+ num_oos</span><span class="s2">, </span><span class="s1">adj)</span>

    <span class="s2">def </span><span class="s1">_static_oos_predict(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">params: ArrayLike</span><span class="s2">, </span><span class="s1">num_oos: int</span><span class="s2">, </span><span class="s1">exog_oos: ArrayLike2D</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s1">new_x = self._setup_oos_forecast(num_oos</span><span class="s2">, </span><span class="s1">exog_oos)</span>
        <span class="s2">if </span><span class="s1">self._maxlag == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">new_x @ params</span>
        <span class="s1">forecasts = np.empty(num_oos)</span>
        <span class="s1">nexog = </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">self.exog </span><span class="s2">is None else </span><span class="s1">self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">ar_offset = self._x.shape[</span><span class="s4">1</span><span class="s1">] - nexog - len(self._lags)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(num_oos):</span>
            <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">enumerate(self._lags):</span>
                <span class="s1">loc = i - lag</span>
                <span class="s1">val = self._y[loc] </span><span class="s2">if </span><span class="s1">loc &lt; </span><span class="s4">0 </span><span class="s2">else </span><span class="s1">forecasts[loc]</span>
                <span class="s1">new_x[i</span><span class="s2">, </span><span class="s1">ar_offset + j] = np.squeeze(val)</span>
            <span class="s1">forecasts[i] = np.squeeze(new_x[i : i + </span><span class="s4">1</span><span class="s1">] @ params)</span>
        <span class="s2">return </span><span class="s1">forecasts</span>

    <span class="s2">def </span><span class="s1">_static_predict(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">params: Float64Array</span><span class="s2">,</span>
        <span class="s1">start: int</span><span class="s2">,</span>
        <span class="s1">end: int</span><span class="s2">,</span>
        <span class="s1">num_oos: int</span><span class="s2">,</span>
        <span class="s1">exog: Float64Array | </span><span class="s2">None,</span>
        <span class="s1">exog_oos: Float64Array | </span><span class="s2">None,</span>
    <span class="s1">) -&gt; pd.Series:</span>
        <span class="s5">&quot;&quot;&quot; 
        Path for static predictions 
 
        Parameters 
        ---------- 
        params : ndarray 
            The model parameters 
        start : int 
            Index of first observation 
        end : int 
            Index of last in-sample observation. Inclusive, so start:end+1 
            in slice notation. 
        num_oos : int 
            Number of out-of-sample observations, so that the returned size is 
            num_oos + (end - start + 1). 
        exog : {ndarray, DataFrame} 
            Array containing replacement exog values 
        exog_oos :  {ndarray, DataFrame} 
            Containing forecast exog values 
        &quot;&quot;&quot;</span>
        <span class="s1">hold_back = self._hold_back</span>
        <span class="s1">nobs = self.endog.shape[</span><span class="s4">0</span><span class="s1">]</span>

        <span class="s1">x = np.empty((</span><span class="s4">0</span><span class="s2">, </span><span class="s1">self._x.shape[</span><span class="s4">1</span><span class="s1">]))</span>

        <span class="s0"># Adjust start to reflect observations lost</span>
        <span class="s1">adj = max(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">hold_back - start)</span>
        <span class="s1">start += adj</span>
        <span class="s2">if </span><span class="s1">start &lt;= nobs:</span>
            <span class="s0"># Use existing regressors</span>
            <span class="s1">is_loc = slice(start - hold_back</span><span class="s2">, </span><span class="s1">end + </span><span class="s4">1 </span><span class="s1">- hold_back)</span>
            <span class="s1">x = self._x[is_loc]</span>
            <span class="s2">if </span><span class="s1">exog </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">exog_a = np.asarray(exog)</span>
                <span class="s1">x = x.copy()</span>
                <span class="s0"># Replace final columns</span>
                <span class="s1">x[:</span><span class="s2">, </span><span class="s1">-exog_a.shape[</span><span class="s4">1</span><span class="s1">] :] = exog_a[start : end + </span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">in_sample = x @ params</span>
        <span class="s2">if </span><span class="s1">num_oos == </span><span class="s4">0</span><span class="s1">:  </span><span class="s0"># No out of sample</span>
            <span class="s2">return </span><span class="s1">self._wrap_prediction(in_sample</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">adj)</span>

        <span class="s1">out_of_sample = self._static_oos_predict(params</span><span class="s2">, </span><span class="s1">num_oos</span><span class="s2">, </span><span class="s1">exog_oos)</span>
        <span class="s1">prediction = np.hstack((in_sample</span><span class="s2">, </span><span class="s1">out_of_sample))</span>
        <span class="s2">return </span><span class="s1">self._wrap_prediction(prediction</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end + </span><span class="s4">1 </span><span class="s1">+ num_oos</span><span class="s2">, </span><span class="s1">adj)</span>

    <span class="s2">def </span><span class="s1">_prepare_prediction(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">params: ArrayLike</span><span class="s2">,</span>
        <span class="s1">exog: ArrayLike2D</span><span class="s2">,</span>
        <span class="s1">exog_oos: ArrayLike2D</span><span class="s2">,</span>
        <span class="s1">start: int | str | datetime.datetime | pd.Timestamp | </span><span class="s2">None,</span>
        <span class="s1">end: int | str | datetime.datetime | pd.Timestamp | </span><span class="s2">None,</span>
    <span class="s1">) -&gt; tuple[</span>
        <span class="s1">np.ndarray</span><span class="s2">,</span>
        <span class="s1">np.ndarray | pd.DataFrame | </span><span class="s2">None,</span>
        <span class="s1">np.ndarray | pd.DataFrame | </span><span class="s2">None,</span>
        <span class="s1">int</span><span class="s2">,</span>
        <span class="s1">int</span><span class="s2">,</span>
        <span class="s1">int</span><span class="s2">,</span>
    <span class="s1">]:</span>
        <span class="s1">params = array_like(params</span><span class="s2">, </span><span class="s3">&quot;params&quot;</span><span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">isinstance(params</span><span class="s2">, </span><span class="s1">np.ndarray)</span>
        <span class="s2">if </span><span class="s1">isinstance(exog</span><span class="s2">, </span><span class="s1">pd.DataFrame):</span>
            <span class="s1">_exog = exog</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">_exog = array_like(exog</span><span class="s2">, </span><span class="s3">&quot;exog&quot;</span><span class="s2">, </span><span class="s1">ndim=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">isinstance(exog_oos</span><span class="s2">, </span><span class="s1">pd.DataFrame):</span>
            <span class="s1">_exog_oos = exog_oos</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">_exog_oos = array_like(exog_oos</span><span class="s2">, </span><span class="s3">&quot;exog_oos&quot;</span><span class="s2">, </span><span class="s1">ndim=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">start = </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">start </span><span class="s2">is None else </span><span class="s1">start</span>
        <span class="s1">end = self._index[-</span><span class="s4">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">end </span><span class="s2">is None else </span><span class="s1">end</span>
        <span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">num_oos</span><span class="s2">, </span><span class="s1">_ = self._get_prediction_index(start</span><span class="s2">, </span><span class="s1">end)</span>
        <span class="s2">return </span><span class="s1">params</span><span class="s2">, </span><span class="s1">_exog</span><span class="s2">, </span><span class="s1">_exog_oos</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">num_oos</span>

    <span class="s2">def </span><span class="s1">_parse_dynamic(self</span><span class="s2">, </span><span class="s1">dynamic</span><span class="s2">, </span><span class="s1">start):</span>
        <span class="s2">if </span><span class="s1">isinstance(</span>
            <span class="s1">dynamic</span><span class="s2">, </span><span class="s1">(str</span><span class="s2">, </span><span class="s1">bytes</span><span class="s2">, </span><span class="s1">pd.Timestamp</span><span class="s2">, </span><span class="s1">dt.datetime</span><span class="s2">, </span><span class="s1">pd.Period)</span>
        <span class="s1">):</span>
            <span class="s1">dynamic_loc</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = self._get_index_loc(dynamic)</span>
            <span class="s0"># Adjust since relative to start</span>
            <span class="s1">dynamic_loc -= start</span>
        <span class="s2">elif </span><span class="s1">dynamic </span><span class="s2">is True</span><span class="s1">:</span>
            <span class="s0"># if True, all forecasts are dynamic</span>
            <span class="s1">dynamic_loc = </span><span class="s4">0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dynamic_loc = int(dynamic)</span>
        <span class="s0"># At this point dynamic is an offset relative to start</span>
        <span class="s0"># and it must be non-negative</span>
        <span class="s2">if </span><span class="s1">dynamic_loc &lt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;Dynamic prediction cannot begin prior to the &quot;</span>
                <span class="s3">&quot;first observation in the sample.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">dynamic_loc</span>

    <span class="s2">def </span><span class="s1">predict(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">params: ArrayLike</span><span class="s2">,</span>
        <span class="s1">start: int | str | datetime.datetime | pd.Timestamp | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">end: int | str | datetime.datetime | pd.Timestamp | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">dynamic: bool | int = </span><span class="s2">False,</span>
        <span class="s1">exog: ArrayLike2D | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">exog_oos: ArrayLike2D | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; pd.Series:</span>
        <span class="s5">&quot;&quot;&quot; 
        In-sample prediction and out-of-sample forecasting. 
 
        Parameters 
        ---------- 
        params : array_like 
            The fitted model parameters. 
        start : int, str, or datetime, optional 
            Zero-indexed observation number at which to start forecasting, 
            i.e., the first forecast is start. Can also be a date string to 
            parse or a datetime type. Default is the the zeroth observation. 
        end : int, str, or datetime, optional 
            Zero-indexed observation number at which to end forecasting, i.e., 
            the last forecast is end. Can also be a date string to 
            parse or a datetime type. However, if the dates index does not 
            have a fixed frequency, end must be an integer index if you 
            want out-of-sample prediction. Default is the last observation in 
            the sample. Unlike standard python slices, end is inclusive so 
            that all the predictions [start, start+1, ..., end-1, end] are 
            returned. 
        dynamic : {bool, int, str, datetime, Timestamp}, optional 
            Integer offset relative to `start` at which to begin dynamic 
            prediction. Prior to this observation, true endogenous values 
            will be used for prediction; starting with this observation and 
            continuing through the end of prediction, forecasted endogenous 
            values will be used instead. Datetime-like objects are not 
            interpreted as offsets. They are instead used to find the index 
            location of `dynamic` which is then used to to compute the offset. 
        exog : array_like 
            A replacement exogenous array.  Must have the same shape as the 
            exogenous data array used when the model was created. 
        exog_oos : array_like 
            An array containing out-of-sample values of the exogenous variable. 
            Must has the same number of columns as the exog used when the 
            model was created, and at least as many rows as the number of 
            out-of-sample forecasts. 
 
        Returns 
        ------- 
        predictions : {ndarray, Series} 
            Array of out of in-sample predictions and / or out-of-sample 
            forecasts. 
        &quot;&quot;&quot;</span>

        <span class="s1">params</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exog_oos</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">num_oos = self._prepare_prediction(</span>
            <span class="s1">params</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exog_oos</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">self.exog </span><span class="s2">is None and </span><span class="s1">(exog </span><span class="s2">is not None or </span><span class="s1">exog_oos </span><span class="s2">is not None</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;exog and exog_oos cannot be used when the model &quot;</span>
                <span class="s3">&quot;does not contains exogenous regressors.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">self.exog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">exog </span><span class="s2">is not None and </span><span class="s1">exog.shape != self.exog.shape:</span>
                <span class="s1">msg = (</span>
                    <span class="s3">&quot;The shape of exog {0} must match the shape of the &quot;</span>
                    <span class="s3">&quot;exog variable used to create the model {1}.&quot;</span>
                <span class="s1">)</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg.format(exog.shape</span><span class="s2">, </span><span class="s1">self.exog.shape))</span>
            <span class="s2">if </span><span class="s1">(</span>
                <span class="s1">exog_oos </span><span class="s2">is not None</span>
                <span class="s2">and </span><span class="s1">exog_oos.shape[</span><span class="s4">1</span><span class="s1">] != self.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">):</span>
                <span class="s1">msg = (</span>
                    <span class="s3">&quot;The number of columns in exog_oos ({0}) must match &quot;</span>
                    <span class="s3">&quot;the number of columns  in the exog variable used to &quot;</span>
                    <span class="s3">&quot;create the model ({1}).&quot;</span>
                <span class="s1">)</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s1">msg.format(exog_oos.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">self.exog.shape[</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">num_oos &gt; </span><span class="s4">0 </span><span class="s2">and </span><span class="s1">exog_oos </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;exog_oos must be provided when producing &quot;</span>
                    <span class="s3">&quot;out-of-sample forecasts.&quot;</span>
                <span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">exog_oos </span><span class="s2">is not None and </span><span class="s1">num_oos &gt; exog_oos.shape[</span><span class="s4">0</span><span class="s1">]:</span>
                <span class="s1">msg = (</span>
                    <span class="s3">&quot;start and end indicate that {0} out-of-sample &quot;</span>
                    <span class="s3">&quot;predictions must be computed. exog_oos has {1} rows &quot;</span>
                    <span class="s3">&quot;but must have at least {0}.&quot;</span>
                <span class="s1">)</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg.format(num_oos</span><span class="s2">, </span><span class="s1">exog_oos.shape[</span><span class="s4">0</span><span class="s1">]))</span>

        <span class="s2">if </span><span class="s1">(isinstance(dynamic</span><span class="s2">, </span><span class="s1">bool) </span><span class="s2">and not </span><span class="s1">dynamic) </span><span class="s2">or </span><span class="s1">self._maxlag == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s0"># If model has no lags, static and dynamic are identical</span>
            <span class="s2">return </span><span class="s1">self._static_predict(</span>
                <span class="s1">params</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">num_oos</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exog_oos</span>
            <span class="s1">)</span>
        <span class="s1">dynamic = self._parse_dynamic(dynamic</span><span class="s2">, </span><span class="s1">start)</span>

        <span class="s2">return </span><span class="s1">self._dynamic_predict(</span>
            <span class="s1">params</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">dynamic</span><span class="s2">, </span><span class="s1">num_oos</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exog_oos</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">AR:</span>
    <span class="s5">&quot;&quot;&quot; 
    The AR class has been removed and replaced with AutoReg 
 
    See Also 
    -------- 
    AutoReg 
        The replacement for AR that improved deterministic modeling 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s3">&quot;AR has been removed from statsmodels and replaced with &quot;</span>
            <span class="s3">&quot;statsmodels.tsa.ar_model.AutoReg.&quot;</span>
        <span class="s1">)</span>


<span class="s2">class </span><span class="s1">ARResults:</span>
    <span class="s5">&quot;&quot;&quot; 
    Removed and replaced by AutoRegResults. 
 
    See Also 
    -------- 
    AutoReg 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
            <span class="s3">&quot;AR and ARResults have been removed and replaced by &quot;</span>
            <span class="s3">&quot;AutoReg And AutoRegResults.&quot;</span>
        <span class="s1">)</span>


<span class="s1">doc = Docstring(AutoReg.predict.__doc__)</span>
<span class="s1">_predict_params = doc.extract_parameters(</span>
    <span class="s1">[</span><span class="s3">&quot;start&quot;</span><span class="s2">, </span><span class="s3">&quot;end&quot;</span><span class="s2">, </span><span class="s3">&quot;dynamic&quot;</span><span class="s2">, </span><span class="s3">&quot;exog&quot;</span><span class="s2">, </span><span class="s3">&quot;exog_oos&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s4">8</span>
<span class="s1">)</span>


<span class="s2">class </span><span class="s1">AutoRegResults(tsa_model.TimeSeriesModelResults):</span>
    <span class="s5">&quot;&quot;&quot; 
    Class to hold results from fitting an AutoReg model. 
 
    Parameters 
    ---------- 
    model : AutoReg 
        Reference to the model that is fit. 
    params : ndarray 
        The fitted parameters from the AR Model. 
    cov_params : ndarray 
        The estimated covariance matrix of the model parameters. 
    normalized_cov_params : ndarray 
        The array inv(dot(x.T,x)) where x contains the regressors in the 
        model. 
    scale : float, optional 
        An estimate of the scale of the model. 
    use_t : bool, optional 
        Whether use_t was set in fit 
    summary_text : str, optional 
        Additional text to append to results summary 
    &quot;&quot;&quot;</span>

    <span class="s1">_cache: dict[str</span><span class="s2">, </span><span class="s1">Any] = {}  </span><span class="s0"># for scale setter</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">model</span><span class="s2">,</span>
        <span class="s1">params</span><span class="s2">,</span>
        <span class="s1">cov_params</span><span class="s2">,</span>
        <span class="s1">normalized_cov_params=</span><span class="s2">None,</span>
        <span class="s1">scale=</span><span class="s4">1.0</span><span class="s2">,</span>
        <span class="s1">use_t=</span><span class="s2">False,</span>
        <span class="s1">summary_text=</span><span class="s3">&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">super().__init__(model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">normalized_cov_params</span><span class="s2">, </span><span class="s1">scale)</span>
        <span class="s1">self._cache = {}</span>
        <span class="s1">self._params = params</span>
        <span class="s1">self._nobs = model.nobs</span>
        <span class="s1">self._n_totobs = model.endog.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">self._df_model = model.df_model</span>
        <span class="s1">self._ar_lags = model.ar_lags</span>
        <span class="s1">self._use_t = use_t</span>
        <span class="s2">if </span><span class="s1">self._ar_lags </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self._max_lag = max(self._ar_lags)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._max_lag = </span><span class="s4">0</span>
        <span class="s1">self._hold_back = self.model.hold_back</span>
        <span class="s1">self.cov_params_default = cov_params</span>
        <span class="s1">self._summary_text = summary_text</span>

    <span class="s2">def </span><span class="s1">initialize(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s5">&quot;&quot;&quot; 
        Initialize (possibly re-initialize) a Results instance. 
 
        Parameters 
        ---------- 
        model : Model 
            The model instance. 
        params : ndarray 
            The model parameters. 
        **kwargs 
            Any additional keyword arguments required to initialize the model. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._params = params</span>
        <span class="s1">self.model = model</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">ar_lags(self):</span>
        <span class="s5">&quot;&quot;&quot;The autoregressive lags included in the model&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._ar_lags</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">params(self):</span>
        <span class="s5">&quot;&quot;&quot;The estimated parameters.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._params</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">df_model(self):</span>
        <span class="s5">&quot;&quot;&quot;The degrees of freedom consumed by the model.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._df_model</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">df_resid(self):</span>
        <span class="s5">&quot;&quot;&quot;The remaining degrees of freedom in the residuals.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.nobs - self._df_model</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">nobs(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        The number of observations after adjusting for losses due to lags. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._nobs</span>

    <span class="s1">@cache_writable()</span>
    <span class="s2">def </span><span class="s1">sigma2(self):</span>
        <span class="s2">return </span><span class="s4">1.0 </span><span class="s1">/ self.nobs * sumofsq(self.resid)</span>

    <span class="s1">@cache_writable()  </span><span class="s0"># for compatability with RegressionResults</span>
    <span class="s2">def </span><span class="s1">scale(self):</span>
        <span class="s2">return </span><span class="s1">self.sigma2</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bse(self):  </span><span class="s0"># allow user to specify?</span>
        <span class="s5">&quot;&quot;&quot; 
        The standard errors of the estimated parameters. 
 
        If `method` is 'cmle', then the standard errors that are returned are 
        the OLS standard errors of the coefficients. If the `method` is 'mle' 
        then they are computed using the numerical Hessian. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">np.sqrt(np.diag(self.cov_params()))</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">aic(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Akaike Information Criterion using Lutkepohl's definition. 
 
        :math:`-2 llf + \ln(nobs) (1 + df_{model})` 
        &quot;&quot;&quot;</span>
        <span class="s0"># This is based on loglike with dropped constant terms ?</span>
        <span class="s0"># Lutkepohl</span>
        <span class="s0"># return np.log(self.sigma2) + 1./self.model.nobs * self.k_ar</span>
        <span class="s0"># Include constant as estimated free parameter and double the loss</span>
        <span class="s0"># Stata defintion</span>
        <span class="s0"># nobs = self.nobs</span>
        <span class="s0"># return -2 * self.llf/nobs + 2 * (self.k_ar+self.k_trend)/nobs</span>
        <span class="s2">return </span><span class="s1">eval_measures.aic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.df_model + </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">hqic(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Hannan-Quinn Information Criterion using Lutkepohl's definition. 
 
        :math:`-2 llf + 2 \ln(\ln(nobs)) (1 + df_{model})` 
        &quot;&quot;&quot;</span>
        <span class="s0"># Lutkepohl</span>
        <span class="s0"># return np.log(self.sigma2)+ 2 * np.log(np.log(nobs))/nobs * self.k_ar</span>
        <span class="s0"># R uses all estimated parameters rather than just lags</span>
        <span class="s0"># Stata</span>
        <span class="s0"># nobs = self.nobs</span>
        <span class="s0"># return -2 * self.llf/nobs + 2 * np.log(np.log(nobs))/nobs * \</span>
        <span class="s0">#        (self.k_ar + self.k_trend)</span>
        <span class="s2">return </span><span class="s1">eval_measures.hqic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.df_model + </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">fpe(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Final prediction error using Ltkepohl's definition. 
 
        :math:`((nobs+df_{model})/(nobs-df_{model})) \sigma^2` 
        &quot;&quot;&quot;</span>
        <span class="s1">nobs = self.nobs</span>
        <span class="s1">df_model = self.df_model</span>
        <span class="s0"># Lutkepohl</span>
        <span class="s2">return </span><span class="s1">self.sigma2 * ((nobs + df_model) / (nobs - df_model))</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">aicc(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Akaike Information Criterion with small sample correction 
 
        :math:`2.0 * df_{model} * nobs / (nobs - df_{model} - 1.0)` 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">eval_measures.aicc(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.df_model + </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">bic(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Bayes Information Criterion 
 
        :math:`-2 llf + \ln(nobs) (1 + df_{model})` 
        &quot;&quot;&quot;</span>
        <span class="s0"># Lutkepohl</span>
        <span class="s0"># np.log(self.sigma2) + np.log(nobs)/nobs * self.k_ar</span>
        <span class="s0"># Include constant as est. free parameter</span>
        <span class="s0"># Stata</span>
        <span class="s0"># -2 * self.llf/nobs + np.log(nobs)/nobs * (self.k_ar + self.k_trend)</span>
        <span class="s2">return </span><span class="s1">eval_measures.bic(self.llf</span><span class="s2">, </span><span class="s1">self.nobs</span><span class="s2">, </span><span class="s1">self.df_model + </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">resid(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        The residuals of the model. 
        &quot;&quot;&quot;</span>
        <span class="s1">model = self.model</span>
        <span class="s1">endog = model.endog.squeeze()</span>
        <span class="s2">return </span><span class="s1">endog[self._hold_back :] - self.fittedvalues</span>

    <span class="s2">def </span><span class="s1">_lag_repr(self):</span>
        <span class="s5">&quot;&quot;&quot;Returns poly repr of an AR, (1  -phi1 L -phi2 L^2-...)&quot;&quot;&quot;</span>
        <span class="s1">ar_lags = self._ar_lags </span><span class="s2">if </span><span class="s1">self._ar_lags </span><span class="s2">is not None else </span><span class="s1">[]</span>
        <span class="s1">k_ar = len(ar_lags)</span>
        <span class="s1">ar_params = np.zeros(self._max_lag + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">ar_params[</span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
        <span class="s1">df_model = self._df_model</span>
        <span class="s1">exog = self.model.exog</span>
        <span class="s1">k_exog = exog.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">exog </span><span class="s2">is not None else </span><span class="s4">0</span>
        <span class="s1">params = self._params[df_model - k_ar - k_exog : df_model - k_exog]</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">enumerate(ar_lags):</span>
            <span class="s1">ar_params[lag] = -params[i]</span>
        <span class="s2">return </span><span class="s1">ar_params</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">roots(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        The roots of the AR process. 
 
        The roots are the solution to 
        (1 - arparams[0]*z - arparams[1]*z**2 -...- arparams[p-1]*z**k_ar) = 0. 
        Stability requires that the roots in modulus lie outside the unit 
        circle. 
        &quot;&quot;&quot;</span>
        <span class="s0"># TODO: Specific to AR</span>
        <span class="s1">lag_repr = self._lag_repr()</span>
        <span class="s2">if </span><span class="s1">lag_repr.shape[</span><span class="s4">0</span><span class="s1">] == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.empty(</span><span class="s4">0</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">np.roots(lag_repr) ** -</span><span class="s4">1</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">arfreq(self):</span>
        <span class="s5">r&quot;&quot;&quot; 
        Returns the frequency of the AR roots. 
 
        This is the solution, x, to z = abs(z)*exp(2j*np.pi*x) where z are the 
        roots. 
        &quot;&quot;&quot;</span>
        <span class="s0"># TODO: Specific to AR</span>
        <span class="s1">z = self.roots</span>
        <span class="s2">return </span><span class="s1">np.arctan2(z.imag</span><span class="s2">, </span><span class="s1">z.real) / (</span><span class="s4">2 </span><span class="s1">* np.pi)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">fittedvalues(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        The in-sample predicted values of the fitted AR model. 
 
        The `k_ar` initial values are computed via the Kalman Filter if the 
        model is fit by `mle`. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.model.predict(self.params)[self._hold_back :]</span>

    <span class="s2">def </span><span class="s1">test_serial_correlation(self</span><span class="s2">, </span><span class="s1">lags=</span><span class="s2">None, </span><span class="s1">model_df=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Ljung-Box test for residual serial correlation 
 
        Parameters 
        ---------- 
        lags : int 
            The maximum number of lags to use in the test. Jointly tests that 
            all autocorrelations up to and including lag j are zero for 
            j = 1, 2, ..., lags. If None, uses min(10, nobs // 5). 
        model_df : int 
            The model degree of freedom to use when adjusting computing the 
            test statistic to account for parameter estimation. If None, uses 
            the number of AR lags included in the model. 
 
        Returns 
        ------- 
        output : DataFrame 
            DataFrame containing three columns: the test statistic, the 
            p-value of the test, and the degree of freedom used in the test. 
 
        Notes 
        ----- 
        Null hypothesis is no serial correlation. 
 
        The the test degree-of-freedom is 0 or negative once accounting for 
        model_df, then the test statistic's p-value is missing. 
 
        See Also 
        -------- 
        statsmodels.stats.diagnostic.acorr_ljungbox 
            Ljung-Box test for serial correlation. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Deferred to prevent circular import</span>
        <span class="s2">from </span><span class="s1">statsmodels.stats.diagnostic </span><span class="s2">import </span><span class="s1">acorr_ljungbox</span>

        <span class="s1">lags = int_like(lags</span><span class="s2">, </span><span class="s3">&quot;lags&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">model_df = int_like(model_df</span><span class="s2">, </span><span class="s3">&quot;df_model&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">model_df = self.df_model </span><span class="s2">if </span><span class="s1">model_df </span><span class="s2">is None else </span><span class="s1">model_df</span>
        <span class="s1">nobs_effective = self.resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">lags </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lags = min(nobs_effective // </span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span><span class="s1">)</span>
        <span class="s1">test_stats = acorr_ljungbox(</span>
            <span class="s1">self.resid</span><span class="s2">,</span>
            <span class="s1">lags=lags</span><span class="s2">,</span>
            <span class="s1">boxpierce=</span><span class="s2">False,</span>
            <span class="s1">model_df=model_df</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">cols = [</span><span class="s3">&quot;Ljung-Box&quot;</span><span class="s2">, </span><span class="s3">&quot;LB P-value&quot;</span><span class="s2">, </span><span class="s3">&quot;DF&quot;</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">lags == </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">df = max(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1 </span><span class="s1">- model_df)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">df = np.clip(np.arange(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">lags + </span><span class="s4">1</span><span class="s1">) - model_df</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">np.inf)</span>
            <span class="s1">df = df.astype(int)</span>
        <span class="s1">test_stats[</span><span class="s3">&quot;df&quot;</span><span class="s1">] = df</span>
        <span class="s1">index = pd.RangeIndex(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">lags + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s3">&quot;Lag&quot;</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">pd.DataFrame(test_stats</span><span class="s2">, </span><span class="s1">columns=cols</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s2">def </span><span class="s1">test_normality(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        Test for normality of standardized residuals. 
 
        Returns 
        ------- 
        Series 
            Series containing four values, the test statistic and its p-value, 
            the skewness and the kurtosis. 
 
        Notes 
        ----- 
        Null hypothesis is normality. 
 
        See Also 
        -------- 
        statsmodels.stats.stattools.jarque_bera 
            The Jarque-Bera test of normality. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Deferred to prevent circular import</span>
        <span class="s2">from </span><span class="s1">statsmodels.stats.stattools </span><span class="s2">import </span><span class="s1">jarque_bera</span>

        <span class="s1">index = [</span><span class="s3">&quot;Jarque-Bera&quot;</span><span class="s2">, </span><span class="s3">&quot;P-value&quot;</span><span class="s2">, </span><span class="s3">&quot;Skewness&quot;</span><span class="s2">, </span><span class="s3">&quot;Kurtosis&quot;</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">pd.Series(jarque_bera(self.resid)</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s2">def </span><span class="s1">test_heteroskedasticity(self</span><span class="s2">, </span><span class="s1">lags=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        ARCH-LM test of residual heteroskedasticity 
 
        Parameters 
        ---------- 
        lags : int 
            The maximum number of lags to use in the test. Jointly tests that 
            all squared autocorrelations up to and including lag j are zero for 
            j = 1, 2, ..., lags. If None, uses lag=12*(nobs/100)^{1/4}. 
 
        Returns 
        ------- 
        Series 
            Series containing the test statistic and its p-values. 
 
        See Also 
        -------- 
        statsmodels.stats.diagnostic.het_arch 
            ARCH-LM test. 
        statsmodels.stats.diagnostic.acorr_lm 
            LM test for autocorrelation. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">statsmodels.stats.diagnostic </span><span class="s2">import </span><span class="s1">het_arch</span>

        <span class="s1">lags = int_like(lags</span><span class="s2">, </span><span class="s3">&quot;lags&quot;</span><span class="s2">, </span><span class="s1">optional=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">nobs_effective = self.resid.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">lags </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lags = min(nobs_effective // </span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span><span class="s1">)</span>
        <span class="s1">out = []</span>
        <span class="s2">for </span><span class="s1">lag </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">lags + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s1">res = het_arch(self.resid</span><span class="s2">, </span><span class="s1">nlags=lag)</span>
            <span class="s1">out.append([res[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">res[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">lag])</span>
        <span class="s1">index = pd.RangeIndex(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">lags + </span><span class="s4">1</span><span class="s2">, </span><span class="s1">name=</span><span class="s3">&quot;Lag&quot;</span><span class="s1">)</span>
        <span class="s1">cols = [</span><span class="s3">&quot;ARCH-LM&quot;</span><span class="s2">, </span><span class="s3">&quot;P-value&quot;</span><span class="s2">, </span><span class="s3">&quot;DF&quot;</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">pd.DataFrame(out</span><span class="s2">, </span><span class="s1">columns=cols</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s2">def </span><span class="s1">diagnostic_summary(self):</span>
        <span class="s5">&quot;&quot;&quot; 
        Returns a summary containing standard model diagnostic tests 
 
        Returns 
        ------- 
        Summary 
            A summary instance with panels for serial correlation tests, 
            normality tests and heteroskedasticity tests. 
 
        See Also 
        -------- 
        test_serial_correlation 
            Test models residuals for serial correlation. 
        test_normality 
            Test models residuals for deviations from normality. 
        test_heteroskedasticity 
            Test models residuals for conditional heteroskedasticity. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">statsmodels.iolib.table </span><span class="s2">import </span><span class="s1">SimpleTable</span>

        <span class="s1">spacer = SimpleTable([</span><span class="s3">&quot;&quot;</span><span class="s1">])</span>
        <span class="s1">smry = Summary()</span>
        <span class="s1">sc = self.test_serial_correlation()</span>
        <span class="s1">sc = sc.loc[sc.DF &gt; </span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">values = [[i + </span><span class="s4">1</span><span class="s1">] + row </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">row </span><span class="s2">in </span><span class="s1">enumerate(sc.values.tolist())]</span>
        <span class="s1">data_fmts = (</span><span class="s3">&quot;%10d&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10d&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">sc.shape[</span><span class="s4">0</span><span class="s1">]:</span>
            <span class="s1">tab = SimpleTable(</span>
                <span class="s1">values</span><span class="s2">,</span>
                <span class="s1">headers=[</span><span class="s3">&quot;Lag&quot;</span><span class="s1">] + list(sc.columns)</span><span class="s2">,</span>
                <span class="s1">title=</span><span class="s3">&quot;Test of No Serial Correlation&quot;</span><span class="s2">,</span>
                <span class="s1">header_align=</span><span class="s3">&quot;r&quot;</span><span class="s2">,</span>
                <span class="s1">data_fmts=data_fmts</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">smry.tables.append(tab)</span>
            <span class="s1">smry.tables.append(spacer)</span>
        <span class="s1">jb = self.test_normality()</span>
        <span class="s1">data_fmts = (</span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s1">)</span>
        <span class="s1">tab = SimpleTable(</span>
            <span class="s1">[jb.values]</span><span class="s2">,</span>
            <span class="s1">headers=list(jb.index)</span><span class="s2">,</span>
            <span class="s1">title=</span><span class="s3">&quot;Test of Normality&quot;</span><span class="s2">,</span>
            <span class="s1">header_align=</span><span class="s3">&quot;r&quot;</span><span class="s2">,</span>
            <span class="s1">data_fmts=data_fmts</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">smry.tables.append(tab)</span>
        <span class="s1">smry.tables.append(spacer)</span>
        <span class="s1">arch_lm = self.test_heteroskedasticity()</span>
        <span class="s1">values = [</span>
            <span class="s1">[i + </span><span class="s4">1</span><span class="s1">] + row </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">row </span><span class="s2">in </span><span class="s1">enumerate(arch_lm.values.tolist())</span>
        <span class="s1">]</span>
        <span class="s1">data_fmts = (</span><span class="s3">&quot;%10d&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10.3f&quot;</span><span class="s2">, </span><span class="s3">&quot;%10d&quot;</span><span class="s1">)</span>
        <span class="s1">tab = SimpleTable(</span>
            <span class="s1">values</span><span class="s2">,</span>
            <span class="s1">headers=[</span><span class="s3">&quot;Lag&quot;</span><span class="s1">] + list(arch_lm.columns)</span><span class="s2">,</span>
            <span class="s1">title=</span><span class="s3">&quot;Test of Conditional Homoskedasticity&quot;</span><span class="s2">,</span>
            <span class="s1">header_align=</span><span class="s3">&quot;r&quot;</span><span class="s2">,</span>
            <span class="s1">data_fmts=data_fmts</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">smry.tables.append(tab)</span>
        <span class="s2">return </span><span class="s1">smry</span>

    <span class="s1">@Appender(remove_parameters(AutoReg.predict.__doc__</span><span class="s2">, </span><span class="s3">&quot;params&quot;</span><span class="s1">))</span>
    <span class="s2">def </span><span class="s1">predict(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">end=</span><span class="s2">None, </span><span class="s1">dynamic=</span><span class="s2">False, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">exog_oos=</span><span class="s2">None</span>
    <span class="s1">):</span>
        <span class="s2">return </span><span class="s1">self.model.predict(</span>
            <span class="s1">self._params</span><span class="s2">,</span>
            <span class="s1">start=start</span><span class="s2">,</span>
            <span class="s1">end=end</span><span class="s2">,</span>
            <span class="s1">dynamic=dynamic</span><span class="s2">,</span>
            <span class="s1">exog=exog</span><span class="s2">,</span>
            <span class="s1">exog_oos=exog_oos</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">get_prediction(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">start=</span><span class="s2">None, </span><span class="s1">end=</span><span class="s2">None, </span><span class="s1">dynamic=</span><span class="s2">False, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">exog_oos=</span><span class="s2">None</span>
    <span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Predictions and prediction intervals 
 
        Parameters 
        ---------- 
        start : int, str, or datetime, optional 
            Zero-indexed observation number at which to start forecasting, 
            i.e., the first forecast is start. Can also be a date string to 
            parse or a datetime type. Default is the the zeroth observation. 
        end : int, str, or datetime, optional 
            Zero-indexed observation number at which to end forecasting, i.e., 
            the last forecast is end. Can also be a date string to 
            parse or a datetime type. However, if the dates index does not 
            have a fixed frequency, end must be an integer index if you 
            want out-of-sample prediction. Default is the last observation in 
            the sample. Unlike standard python slices, end is inclusive so 
            that all the predictions [start, start+1, ..., end-1, end] are 
            returned. 
        dynamic : {bool, int, str, datetime, Timestamp}, optional 
            Integer offset relative to `start` at which to begin dynamic 
            prediction. Prior to this observation, true endogenous values 
            will be used for prediction; starting with this observation and 
            continuing through the end of prediction, forecasted endogenous 
            values will be used instead. Datetime-like objects are not 
            interpreted as offsets. They are instead used to find the index 
            location of `dynamic` which is then used to to compute the offset. 
        exog : array_like 
            A replacement exogenous array.  Must have the same shape as the 
            exogenous data array used when the model was created. 
        exog_oos : array_like 
            An array containing out-of-sample values of the exogenous variable. 
            Must has the same number of columns as the exog used when the 
            model was created, and at least as many rows as the number of 
            out-of-sample forecasts. 
 
        Returns 
        ------- 
        PredictionResults 
            Prediction results with mean and prediction intervals 
        &quot;&quot;&quot;</span>
        <span class="s1">mean = self.predict(</span>
            <span class="s1">start=start</span><span class="s2">, </span><span class="s1">end=end</span><span class="s2">, </span><span class="s1">dynamic=dynamic</span><span class="s2">, </span><span class="s1">exog=exog</span><span class="s2">, </span><span class="s1">exog_oos=exog_oos</span>
        <span class="s1">)</span>
        <span class="s1">mean_var = np.full_like(mean</span><span class="s2">, </span><span class="s1">self.sigma2)</span>
        <span class="s1">mean_var[np.isnan(mean)] = np.nan</span>
        <span class="s1">start = </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">start </span><span class="s2">is None else </span><span class="s1">start</span>
        <span class="s1">end = self.model._index[-</span><span class="s4">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">end </span><span class="s2">is None else </span><span class="s1">end</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">oos</span><span class="s2">, </span><span class="s1">_ = self.model._get_prediction_index(start</span><span class="s2">, </span><span class="s1">end)</span>
        <span class="s2">if </span><span class="s1">oos &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">ar_params = self._lag_repr()</span>
            <span class="s1">ma = arma2ma(ar_params</span><span class="s2">, </span><span class="s1">np.ones(</span><span class="s4">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">lags=oos)</span>
            <span class="s1">mean_var[-oos:] = self.sigma2 * np.cumsum(ma**</span><span class="s4">2</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">isinstance(mean</span><span class="s2">, </span><span class="s1">pd.Series):</span>
            <span class="s1">mean_var = pd.Series(mean_var</span><span class="s2">, </span><span class="s1">index=mean.index)</span>

        <span class="s2">return </span><span class="s1">PredictionResults(mean</span><span class="s2">, </span><span class="s1">mean_var)</span>

    <span class="s2">def </span><span class="s1">forecast(self</span><span class="s2">, </span><span class="s1">steps=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Out-of-sample forecasts 
 
        Parameters 
        ---------- 
        steps : {int, str, datetime}, default 1 
            If an integer, the number of steps to forecast from the end of the 
            sample. Can also be a date string to parse or a datetime type. 
            However, if the dates index does not have a fixed frequency, 
            steps must be an integer. 
        exog : {ndarray, DataFrame} 
            Exogenous values to use out-of-sample. Must have same number of 
            columns as original exog data and at least `steps` rows 
 
        Returns 
        ------- 
        array_like 
            Array of out of in-sample predictions and / or out-of-sample 
            forecasts. 
 
        See Also 
        -------- 
        AutoRegResults.predict 
            In- and out-of-sample predictions 
        AutoRegResults.get_prediction 
            In- and out-of-sample predictions and confidence intervals 
        &quot;&quot;&quot;</span>
        <span class="s1">start = self.model.data.orig_endog.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">isinstance(steps</span><span class="s2">, </span><span class="s1">(int</span><span class="s2">, </span><span class="s1">np.integer)):</span>
            <span class="s1">end = start + steps - </span><span class="s4">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">end = steps</span>
        <span class="s2">return </span><span class="s1">self.predict(start=start</span><span class="s2">, </span><span class="s1">end=end</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s2">False, </span><span class="s1">exog_oos=exog)</span>

    <span class="s2">def </span><span class="s1">_plot_predictions(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">predictions</span><span class="s2">,</span>
        <span class="s1">start</span><span class="s2">,</span>
        <span class="s1">end</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">in_sample</span><span class="s2">,</span>
        <span class="s1">fig</span><span class="s2">,</span>
        <span class="s1">figsize</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot;Shared helper for plotting predictions&quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">statsmodels.graphics.utils </span><span class="s2">import </span><span class="s1">_import_mpl</span><span class="s2">, </span><span class="s1">create_mpl_fig</span>

        <span class="s1">_import_mpl()</span>
        <span class="s1">fig = create_mpl_fig(fig</span><span class="s2">, </span><span class="s1">figsize)</span>
        <span class="s1">start = </span><span class="s4">0 </span><span class="s2">if </span><span class="s1">start </span><span class="s2">is None else </span><span class="s1">start</span>
        <span class="s1">end = self.model._index[-</span><span class="s4">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">end </span><span class="s2">is None else </span><span class="s1">end</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">oos</span><span class="s2">, </span><span class="s1">_ = self.model._get_prediction_index(start</span><span class="s2">, </span><span class="s1">end)</span>

        <span class="s1">ax = fig.add_subplot(</span><span class="s4">111</span><span class="s1">)</span>
        <span class="s1">mean = predictions.predicted_mean</span>
        <span class="s2">if not </span><span class="s1">in_sample </span><span class="s2">and </span><span class="s1">oos:</span>
            <span class="s2">if </span><span class="s1">isinstance(mean</span><span class="s2">, </span><span class="s1">pd.Series):</span>
                <span class="s1">mean = mean.iloc[-oos:]</span>
        <span class="s2">elif not </span><span class="s1">in_sample:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;in_sample is False but there are no&quot;</span>
                <span class="s3">&quot;out-of-sample forecasts to plot.&quot;</span>
            <span class="s1">)</span>
        <span class="s1">ax.plot(mean</span><span class="s2">, </span><span class="s1">zorder=</span><span class="s4">2</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">oos </span><span class="s2">and </span><span class="s1">alpha </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">ci = np.asarray(predictions.conf_int(alpha))</span>
            <span class="s1">lower</span><span class="s2">, </span><span class="s1">upper = ci[-oos:</span><span class="s2">, </span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ci[-oos:</span><span class="s2">, </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s1">label = </span><span class="s3">&quot;{0:.0%} confidence interval&quot;</span><span class="s1">.format(</span><span class="s4">1 </span><span class="s1">- alpha)</span>
            <span class="s1">x = ax.get_lines()[-</span><span class="s4">1</span><span class="s1">].get_xdata()</span>
            <span class="s1">ax.fill_between(</span>
                <span class="s1">x[-oos:]</span><span class="s2">,</span>
                <span class="s1">lower</span><span class="s2">,</span>
                <span class="s1">upper</span><span class="s2">,</span>
                <span class="s1">color=</span><span class="s3">&quot;gray&quot;</span><span class="s2">,</span>
                <span class="s1">alpha=</span><span class="s4">0.5</span><span class="s2">,</span>
                <span class="s1">label=label</span><span class="s2">,</span>
                <span class="s1">zorder=</span><span class="s4">1</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s1">ax.legend(loc=</span><span class="s3">&quot;best&quot;</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>

    <span class="s1">@Substitution(predict_params=_predict_params)</span>
    <span class="s2">def </span><span class="s1">plot_predict(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">start=</span><span class="s2">None,</span>
        <span class="s1">end=</span><span class="s2">None,</span>
        <span class="s1">dynamic=</span><span class="s2">False,</span>
        <span class="s1">exog=</span><span class="s2">None,</span>
        <span class="s1">exog_oos=</span><span class="s2">None,</span>
        <span class="s1">alpha=</span><span class="s4">0.05</span><span class="s2">,</span>
        <span class="s1">in_sample=</span><span class="s2">True,</span>
        <span class="s1">fig=</span><span class="s2">None,</span>
        <span class="s1">figsize=</span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Plot in- and out-of-sample predictions 
 
        Parameters 
        ----------\n%(predict_params)s 
        alpha : {float, None} 
            The tail probability not covered by the confidence interval. Must 
            be in (0, 1). Confidence interval is constructed assuming normally 
            distributed shocks. If None, figure will not show the confidence 
            interval. 
        in_sample : bool 
            Flag indicating whether to include the in-sample period in the 
            plot. 
        fig : Figure 
            An existing figure handle. If not provided, a new figure is 
            created. 
        figsize: tuple[float, float] 
            Tuple containing the figure size values. 
 
        Returns 
        ------- 
        Figure 
            Figure handle containing the plot. 
        &quot;&quot;&quot;</span>
        <span class="s1">predictions = self.get_prediction(</span>
            <span class="s1">start=start</span><span class="s2">, </span><span class="s1">end=end</span><span class="s2">, </span><span class="s1">dynamic=dynamic</span><span class="s2">, </span><span class="s1">exog=exog</span><span class="s2">, </span><span class="s1">exog_oos=exog_oos</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._plot_predictions(</span>
            <span class="s1">predictions</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">end</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">in_sample</span><span class="s2">, </span><span class="s1">fig</span><span class="s2">, </span><span class="s1">figsize</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">plot_diagnostics(self</span><span class="s2">, </span><span class="s1">lags=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">fig=</span><span class="s2">None, </span><span class="s1">figsize=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Diagnostic plots for standardized residuals 
 
        Parameters 
        ---------- 
        lags : int, optional 
            Number of lags to include in the correlogram. Default is 10. 
        fig : Figure, optional 
            If given, subplots are created in this figure instead of in a new 
            figure. Note that the 2x2 grid will be created in the provided 
            figure using `fig.add_subplot()`. 
        figsize : tuple, optional 
            If a figure is created, this argument allows specifying a size. 
            The tuple is (width, height). 
 
        Notes 
        ----- 
        Produces a 2x2 plot grid with the following plots (ordered clockwise 
        from top left): 
 
        1. Standardized residuals over time 
        2. Histogram plus estimated density of standardized residuals, along 
           with a Normal(0,1) density plotted for reference. 
        3. Normal Q-Q plot, with Normal reference line. 
        4. Correlogram 
 
        See Also 
        -------- 
        statsmodels.graphics.gofplots.qqplot 
        statsmodels.graphics.tsaplots.plot_acf 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">statsmodels.graphics.utils </span><span class="s2">import </span><span class="s1">_import_mpl</span><span class="s2">, </span><span class="s1">create_mpl_fig</span>

        <span class="s1">_import_mpl()</span>
        <span class="s1">fig = create_mpl_fig(fig</span><span class="s2">, </span><span class="s1">figsize)</span>
        <span class="s0"># Eliminate residuals associated with burned or diffuse likelihoods</span>
        <span class="s1">resid = self.resid</span>

        <span class="s0"># Top-left: residuals vs time</span>
        <span class="s1">ax = fig.add_subplot(</span><span class="s4">221</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">hasattr(self.model.data</span><span class="s2">, </span><span class="s3">&quot;dates&quot;</span><span class="s1">) </span><span class="s2">and </span><span class="s1">self.data.dates </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">x = self.model.data.dates._mpl_repr()</span>
            <span class="s1">x = x[self.model.hold_back :]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">hold_back = self.model.hold_back</span>
            <span class="s1">x = hold_back + np.arange(self.resid.shape[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">std_resid = resid / np.sqrt(self.sigma2)</span>
        <span class="s1">ax.plot(x</span><span class="s2">, </span><span class="s1">std_resid)</span>
        <span class="s1">ax.hlines(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">x[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x[-</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">0.5</span><span class="s1">)</span>
        <span class="s1">ax.set_xlim(x[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x[-</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">ax.set_title(</span><span class="s3">&quot;Standardized residual&quot;</span><span class="s1">)</span>

        <span class="s0"># Top-right: histogram, Gaussian kernel density, Normal density</span>
        <span class="s0"># Can only do histogram and Gaussian kernel density on the non-null</span>
        <span class="s0"># elements</span>
        <span class="s1">std_resid_nonmissing = std_resid[~(np.isnan(resid))]</span>
        <span class="s1">ax = fig.add_subplot(</span><span class="s4">222</span><span class="s1">)</span>

        <span class="s1">ax.hist(std_resid_nonmissing</span><span class="s2">, </span><span class="s1">density=</span><span class="s2">True, </span><span class="s1">label=</span><span class="s3">&quot;Hist&quot;</span><span class="s1">)</span>

        <span class="s1">kde = gaussian_kde(std_resid)</span>
        <span class="s1">xlim = (-</span><span class="s4">1.96 </span><span class="s1">* </span><span class="s4">2</span><span class="s2">, </span><span class="s4">1.96 </span><span class="s1">* </span><span class="s4">2</span><span class="s1">)</span>
        <span class="s1">x = np.linspace(xlim[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">xlim[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">ax.plot(x</span><span class="s2">, </span><span class="s1">kde(x)</span><span class="s2">, </span><span class="s1">label=</span><span class="s3">&quot;KDE&quot;</span><span class="s1">)</span>
        <span class="s1">ax.plot(x</span><span class="s2">, </span><span class="s1">norm.pdf(x)</span><span class="s2">, </span><span class="s1">label=</span><span class="s3">&quot;N(0,1)&quot;</span><span class="s1">)</span>
        <span class="s1">ax.set_xlim(xlim)</span>
        <span class="s1">ax.legend()</span>
        <span class="s1">ax.set_title(</span><span class="s3">&quot;Histogram plus estimated density&quot;</span><span class="s1">)</span>

        <span class="s0"># Bottom-left: QQ plot</span>
        <span class="s1">ax = fig.add_subplot(</span><span class="s4">223</span><span class="s1">)</span>
        <span class="s2">from </span><span class="s1">statsmodels.graphics.gofplots </span><span class="s2">import </span><span class="s1">qqplot</span>

        <span class="s1">qqplot(std_resid</span><span class="s2">, </span><span class="s1">line=</span><span class="s3">&quot;s&quot;</span><span class="s2">, </span><span class="s1">ax=ax)</span>
        <span class="s1">ax.set_title(</span><span class="s3">&quot;Normal Q-Q&quot;</span><span class="s1">)</span>

        <span class="s0"># Bottom-right: Correlogram</span>
        <span class="s1">ax = fig.add_subplot(</span><span class="s4">224</span><span class="s1">)</span>
        <span class="s2">from </span><span class="s1">statsmodels.graphics.tsaplots </span><span class="s2">import </span><span class="s1">plot_acf</span>

        <span class="s1">plot_acf(resid</span><span class="s2">, </span><span class="s1">ax=ax</span><span class="s2">, </span><span class="s1">lags=lags)</span>
        <span class="s1">ax.set_title(</span><span class="s3">&quot;Correlogram&quot;</span><span class="s1">)</span>

        <span class="s1">ax.set_ylim(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">fig</span>

    <span class="s2">def </span><span class="s1">summary(self</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Summarize the Model 
 
        Parameters 
        ---------- 
        alpha : float, optional 
            Significance level for the confidence intervals. 
 
        Returns 
        ------- 
        smry : Summary instance 
            This holds the summary table and text, which can be printed or 
            converted to various output formats. 
 
        See Also 
        -------- 
        statsmodels.iolib.summary.Summary 
        &quot;&quot;&quot;</span>
        <span class="s1">model = self.model</span>

        <span class="s1">title = model.__class__.__name__ + </span><span class="s3">&quot; Model Results&quot;</span>
        <span class="s1">method = </span><span class="s3">&quot;Conditional MLE&quot;</span>
        <span class="s0"># get sample</span>
        <span class="s1">start = self._hold_back</span>
        <span class="s2">if </span><span class="s1">self.data.dates </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">dates = self.data.dates</span>
            <span class="s1">sample = [dates[start].strftime(</span><span class="s3">&quot;%m-%d-%Y&quot;</span><span class="s1">)]</span>
            <span class="s1">sample += [</span><span class="s3">&quot;- &quot; </span><span class="s1">+ dates[-</span><span class="s4">1</span><span class="s1">].strftime(</span><span class="s3">&quot;%m-%d-%Y&quot;</span><span class="s1">)]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sample = [str(start)</span><span class="s2">, </span><span class="s1">str(len(self.data.orig_endog))]</span>
        <span class="s1">model = model.__class__.__name__</span>
        <span class="s2">if </span><span class="s1">self.model.seasonal:</span>
            <span class="s1">model = </span><span class="s3">&quot;Seas. &quot; </span><span class="s1">+ model</span>
        <span class="s2">if </span><span class="s1">self.ar_lags </span><span class="s2">is not None and </span><span class="s1">len(self.ar_lags) &lt; self._max_lag:</span>
            <span class="s1">model = </span><span class="s3">&quot;Restr. &quot; </span><span class="s1">+ model</span>
        <span class="s2">if </span><span class="s1">self.model.exog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">model += </span><span class="s3">&quot;-X&quot;</span>

        <span class="s1">order = </span><span class="s3">&quot;({0})&quot;</span><span class="s1">.format(self._max_lag)</span>
        <span class="s1">dep_name = str(self.model.endog_names)</span>
        <span class="s1">top_left = [</span>
            <span class="s1">(</span><span class="s3">&quot;Dep. Variable:&quot;</span><span class="s2">, </span><span class="s1">[dep_name])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Model:&quot;</span><span class="s2">, </span><span class="s1">[model + order])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Method:&quot;</span><span class="s2">, </span><span class="s1">[method])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Date:&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Time:&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Sample:&quot;</span><span class="s2">, </span><span class="s1">[sample[</span><span class="s4">0</span><span class="s1">]])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;&quot;</span><span class="s2">, </span><span class="s1">[sample[</span><span class="s4">1</span><span class="s1">]])</span><span class="s2">,</span>
        <span class="s1">]</span>

        <span class="s1">top_right = [</span>
            <span class="s1">(</span><span class="s3">&quot;No. Observations:&quot;</span><span class="s2">, </span><span class="s1">[str(len(self.model.endog))])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;Log Likelihood&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.llf])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;S.D. of innovations&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.sigma2**</span><span class="s4">0.5</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;AIC&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.aic])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;BIC&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.bic])</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s3">&quot;HQIC&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s3">&quot;%#5.3f&quot; </span><span class="s1">% self.hqic])</span><span class="s2">,</span>
        <span class="s1">]</span>

        <span class="s1">smry = Summary()</span>
        <span class="s1">smry.add_table_2cols(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">gleft=top_left</span><span class="s2">, </span><span class="s1">gright=top_right</span><span class="s2">, </span><span class="s1">title=title</span>
        <span class="s1">)</span>
        <span class="s1">smry.add_table_params(self</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">use_t=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s0"># Make the roots table</span>
        <span class="s2">from </span><span class="s1">statsmodels.iolib.table </span><span class="s2">import </span><span class="s1">SimpleTable</span>

        <span class="s2">if </span><span class="s1">self._max_lag:</span>
            <span class="s1">arstubs = [</span><span class="s3">&quot;AR.%d&quot; </span><span class="s1">% i </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">self._max_lag + </span><span class="s4">1</span><span class="s1">)]</span>
            <span class="s1">stubs = arstubs</span>
            <span class="s1">roots = self.roots</span>
            <span class="s1">freq = self.arfreq</span>
            <span class="s1">modulus = np.abs(roots)</span>
            <span class="s1">data = np.column_stack((roots.real</span><span class="s2">, </span><span class="s1">roots.imag</span><span class="s2">, </span><span class="s1">modulus</span><span class="s2">, </span><span class="s1">freq))</span>
            <span class="s1">roots_table = SimpleTable(</span>
                <span class="s1">[</span>
                    <span class="s1">(</span>
                        <span class="s3">&quot;%17.4f&quot; </span><span class="s1">% row[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span>
                        <span class="s3">&quot;%+17.4fj&quot; </span><span class="s1">% row[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">,</span>
                        <span class="s3">&quot;%17.4f&quot; </span><span class="s1">% row[</span><span class="s4">2</span><span class="s1">]</span><span class="s2">,</span>
                        <span class="s3">&quot;%17.4f&quot; </span><span class="s1">% row[</span><span class="s4">3</span><span class="s1">]</span><span class="s2">,</span>
                    <span class="s1">)</span>
                    <span class="s2">for </span><span class="s1">row </span><span class="s2">in </span><span class="s1">data</span>
                <span class="s1">]</span><span class="s2">,</span>
                <span class="s1">headers=[</span>
                    <span class="s3">&quot;            Real&quot;</span><span class="s2">,</span>
                    <span class="s3">&quot;         Imaginary&quot;</span><span class="s2">,</span>
                    <span class="s3">&quot;         Modulus&quot;</span><span class="s2">,</span>
                    <span class="s3">&quot;        Frequency&quot;</span><span class="s2">,</span>
                <span class="s1">]</span><span class="s2">,</span>
                <span class="s1">title=</span><span class="s3">&quot;Roots&quot;</span><span class="s2">,</span>
                <span class="s1">stubs=stubs</span><span class="s2">,</span>
            <span class="s1">)</span>

            <span class="s1">smry.tables.append(roots_table)</span>
        <span class="s2">if </span><span class="s1">self._summary_text:</span>
            <span class="s1">extra_txt = smry.extra_txt </span><span class="s2">if </span><span class="s1">smry.extra_txt </span><span class="s2">is not None else </span><span class="s1">[]</span>
            <span class="s1">smry.add_extra_txt(extra_txt + [self._summary_text])</span>
        <span class="s2">return </span><span class="s1">smry</span>

    <span class="s2">def </span><span class="s1">apply(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">refit=</span><span class="s2">False, </span><span class="s1">fit_kwargs=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Apply the fitted parameters to new data unrelated to the original data 
 
        Creates a new result object using the current fitted parameters, 
        applied to a completely new dataset that is assumed to be unrelated to 
        the model's original data. The new results can then be used for 
        analysis or forecasting. 
 
        Parameters 
        ---------- 
        endog : array_like 
            New observations from the modeled time-series process. 
        exog : array_like, optional 
            New observations of exogenous regressors, if applicable. 
        refit : bool, optional 
            Whether to re-fit the parameters, using the new dataset. 
            Default is False (so parameters from the current results object 
            are used to create the new results object). 
        fit_kwargs : dict, optional 
            Keyword arguments to pass to `fit` (if `refit=True`). 
 
        Returns 
        ------- 
        AutoRegResults 
            Updated results object containing results for the new dataset. 
 
        See Also 
        -------- 
        AutoRegResults.append 
        statsmodels.tsa.statespace.mlemodel.MLEResults.apply 
 
        Notes 
        ----- 
        The `endog` argument to this method should consist of new observations 
        that are not necessarily related to the original model's `endog` 
        dataset. 
 
        Care is needed when using deterministic processes with cyclical 
        components such as seasonal dummies or Fourier series. These 
        deterministic components will align to the first observation 
        in the data and so it is essential that any new data have the 
        same initial period. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; import pandas as pd 
        &gt;&gt;&gt; from statsmodels.tsa.ar_model import AutoReg 
        &gt;&gt;&gt; index = pd.period_range(start='2000', periods=3, freq='A') 
        &gt;&gt;&gt; original_observations = pd.Series([1.2, 1.5, 1.8], index=index) 
        &gt;&gt;&gt; mod = AutoReg(original_observations, lags=1, trend=&quot;n&quot;) 
        &gt;&gt;&gt; res = mod.fit() 
        &gt;&gt;&gt; print(res.params) 
        y.L1    1.219512 
        dtype: float64 
        &gt;&gt;&gt; print(res.fittedvalues) 
        2001    1.463415 
        2002    1.829268 
        Freq: A-DEC, dtype: float64 
        &gt;&gt;&gt; print(res.forecast(1)) 
        2003    2.195122 
        Freq: A-DEC, dtype: float64 
 
        &gt;&gt;&gt; new_index = pd.period_range(start='1980', periods=3, freq='A') 
        &gt;&gt;&gt; new_observations = pd.Series([1.4, 0.3, 1.2], index=new_index) 
        &gt;&gt;&gt; new_res = res.apply(new_observations) 
        &gt;&gt;&gt; print(new_res.params) 
        y.L1    1.219512 
        dtype: float64 
        &gt;&gt;&gt; print(new_res.fittedvalues) 
        1981    1.707317 
        1982    0.365854 
        Freq: A-DEC, dtype: float64 
        &gt;&gt;&gt; print(new_res.forecast(1)) 
        1983    1.463415 
        Freq: A-DEC, dtype: float64 
        &quot;&quot;&quot;</span>
        <span class="s1">existing = self.model</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">deterministic = existing.deterministic</span>
            <span class="s2">if </span><span class="s1">deterministic </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">isinstance(endog</span><span class="s2">, </span><span class="s1">(pd.Series</span><span class="s2">, </span><span class="s1">pd.DataFrame)):</span>
                    <span class="s1">index = endog.index</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">index = np.arange(endog.shape[</span><span class="s4">0</span><span class="s1">])</span>
                <span class="s1">deterministic = deterministic.apply(index)</span>
            <span class="s1">mod = AutoReg(</span>
                <span class="s1">endog</span><span class="s2">,</span>
                <span class="s1">lags=existing.ar_lags</span><span class="s2">,</span>
                <span class="s1">trend=existing.trend</span><span class="s2">,</span>
                <span class="s1">seasonal=existing.seasonal</span><span class="s2">,</span>
                <span class="s1">exog=exog</span><span class="s2">,</span>
                <span class="s1">hold_back=existing.hold_back</span><span class="s2">,</span>
                <span class="s1">period=existing.period</span><span class="s2">,</span>
                <span class="s1">deterministic=deterministic</span><span class="s2">,</span>
                <span class="s1">old_names=</span><span class="s2">False,</span>
            <span class="s1">)</span>
        <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">exc:</span>
            <span class="s1">error = (</span>
                <span class="s3">&quot;An exception occured during the creation of the cloned &quot;</span>
                <span class="s3">&quot;AutoReg instance when applying the existing model &quot;</span>
                <span class="s3">&quot;specification to the new data. The original traceback &quot;</span>
                <span class="s3">&quot;appears below.&quot;</span>
            <span class="s1">)</span>
            <span class="s1">exc.args = (error</span><span class="s2">,</span><span class="s1">) + exc.args</span>
            <span class="s2">raise </span><span class="s1">exc.with_traceback(exc.__traceback__)</span>

        <span class="s2">if </span><span class="s1">(mod.exog </span><span class="s2">is None</span><span class="s1">) != (existing.exog </span><span class="s2">is None</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">existing.exog </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s3">&quot;exog must be provided when the original model contained &quot;</span>
                    <span class="s3">&quot;exog variables&quot;</span>
                <span class="s1">)</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;exog must be None when the original model did not contain &quot;</span>
                <span class="s3">&quot;exog variables&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">(</span>
            <span class="s1">existing.exog </span><span class="s2">is not None</span>
            <span class="s2">and </span><span class="s1">existing.exog.shape[</span><span class="s4">1</span><span class="s1">] != mod.exog.shape[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s3">&quot;The number of exog variables passed must match the original &quot;</span>
                <span class="s3">f&quot;number of exog values (</span><span class="s2">{</span><span class="s1">existing.exog.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">}</span><span class="s3">)&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">refit:</span>
            <span class="s1">fit_kwargs = {} </span><span class="s2">if </span><span class="s1">fit_kwargs </span><span class="s2">is None else </span><span class="s1">fit_kwargs</span>
            <span class="s2">return </span><span class="s1">mod.fit(**fit_kwargs)</span>
        <span class="s1">smry_txt = (</span>
            <span class="s3">&quot;Parameters and standard errors were estimated using a different &quot;</span>
            <span class="s3">&quot;dataset and were then applied to this dataset.&quot;</span>
        <span class="s1">)</span>
        <span class="s1">res = AutoRegResults(</span>
            <span class="s1">mod</span><span class="s2">,</span>
            <span class="s1">self.params</span><span class="s2">,</span>
            <span class="s1">self.cov_params_default</span><span class="s2">,</span>
            <span class="s1">self.normalized_cov_params</span><span class="s2">,</span>
            <span class="s1">use_t=self.use_t</span><span class="s2">,</span>
            <span class="s1">summary_text=smry_txt</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">AutoRegResultsWrapper(res)</span>

    <span class="s2">def </span><span class="s1">append(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None, </span><span class="s1">refit=</span><span class="s2">False, </span><span class="s1">fit_kwargs=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s5">&quot;&quot;&quot; 
        Append observations to the ones used to fit the model 
 
        Creates a new result object using the current fitted parameters 
        where additional observations are appended to the data used 
        to fit the model. The new results can then be used for 
        analysis or forecasting. 
 
        Parameters 
        ---------- 
        endog : array_like 
            New observations from the modeled time-series process. 
        exog : array_like, optional 
            New observations of exogenous regressors, if applicable. 
        refit : bool, optional 
            Whether to re-fit the parameters, using the new dataset. 
            Default is False (so parameters from the current results object 
            are used to create the new results object). 
        fit_kwargs : dict, optional 
            Keyword arguments to pass to `fit` (if `refit=True`). 
 
        Returns 
        ------- 
        AutoRegResults 
            Updated results object containing results for the new dataset. 
 
        See Also 
        -------- 
        AutoRegResults.apply 
        statsmodels.tsa.statespace.mlemodel.MLEResults.append 
 
        Notes 
        ----- 
        The endog and exog arguments to this method must be formatted in the 
        same way (e.g. Pandas Series versus Numpy array) as were the endog 
        and exog arrays passed to the original model. 
 
        The endog argument to this method should consist of new observations 
        that occurred directly after the last element of endog. For any other 
        kind of dataset, see the apply method. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; import pandas as pd 
        &gt;&gt;&gt; from statsmodels.tsa.ar_model import AutoReg 
        &gt;&gt;&gt; index = pd.period_range(start='2000', periods=3, freq='A') 
        &gt;&gt;&gt; original_observations = pd.Series([1.2, 1.4, 1.8], index=index) 
        &gt;&gt;&gt; mod = AutoReg(original_observations, lags=1, trend=&quot;n&quot;) 
        &gt;&gt;&gt; res = mod.fit() 
        &gt;&gt;&gt; print(res.params) 
        y.L1    1.235294 
        dtype: float64 
        &gt;&gt;&gt; print(res.fittedvalues) 
        2001    1.482353 
        2002    1.729412 
        Freq: A-DEC, dtype: float64 
        &gt;&gt;&gt; print(res.forecast(1)) 
        2003    2.223529 
        Freq: A-DEC, dtype: float64 
 
        &gt;&gt;&gt; new_index = pd.period_range(start='2003', periods=3, freq='A') 
        &gt;&gt;&gt; new_observations = pd.Series([2.1, 2.4, 2.7], index=new_index) 
        &gt;&gt;&gt; updated_res = res.append(new_observations) 
        &gt;&gt;&gt; print(updated_res.params) 
        y.L1    1.235294 
        dtype: float64 
        &gt;&gt;&gt; print(updated_res.fittedvalues) 
        dtype: float64 
        2001    1.482353 
        2002    1.729412 
        2003    2.223529 
        2004    2.594118 
        2005    2.964706 
        Freq: A-DEC, dtype: float64 
        &gt;&gt;&gt; print(updated_res.forecast(1)) 
        2006    3.335294 
        Freq: A-DEC, dtype: float64 
        &quot;&quot;&quot;</span>

        <span class="s2">def </span><span class="s1">_check(orig</span><span class="s2">, </span><span class="s1">new</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">use_pandas=</span><span class="s2">True</span><span class="s1">):</span>
            <span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.mlemodel </span><span class="s2">import </span><span class="s1">_check_index</span>

            <span class="s1">typ = type(orig)</span>
            <span class="s2">if not </span><span class="s1">isinstance(new</span><span class="s2">, </span><span class="s1">typ):</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s3">must have the same type as the </span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s3">used to &quot;</span>
                    <span class="s3">f&quot;originally create the model (</span><span class="s2">{</span><span class="s1">typ.__name__</span><span class="s2">}</span><span class="s3">).&quot;</span>
                <span class="s1">)</span>
            <span class="s2">if not </span><span class="s1">use_pandas:</span>
                <span class="s2">return </span><span class="s1">np.concatenate([orig</span><span class="s2">, </span><span class="s1">new])</span>
            <span class="s1">start = len(orig)</span>
            <span class="s1">end = start + len(new) - </span><span class="s4">1</span>
            <span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">append_ix = self.model._get_prediction_index(start</span><span class="s2">, </span><span class="s1">end)</span>
            <span class="s1">_check_index(append_ix</span><span class="s2">, </span><span class="s1">new</span><span class="s2">, </span><span class="s1">title=name)</span>
            <span class="s2">return </span><span class="s1">pd.concat([orig</span><span class="s2">, </span><span class="s1">new]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>

        <span class="s1">existing = self.model</span>
        <span class="s1">no_exog = existing.exog </span><span class="s2">is None</span>
        <span class="s2">if </span><span class="s1">no_exog != (exog </span><span class="s2">is None</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">no_exog:</span>
                <span class="s1">err = (</span>
                    <span class="s3">&quot;Original model does not contain exog data but exog data &quot;</span>
                    <span class="s3">&quot;passed&quot;</span>
                <span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">err = </span><span class="s3">&quot;Original model has exog data but not exog data passed&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(err)</span>
        <span class="s2">if </span><span class="s1">isinstance(existing.data.orig_endog</span><span class="s2">, </span><span class="s1">(pd.Series</span><span class="s2">, </span><span class="s1">pd.DataFrame)):</span>
            <span class="s1">endog = _check(existing.data.orig_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s3">&quot;endog&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">endog = _check(</span>
                <span class="s1">existing.endog</span><span class="s2">, </span><span class="s1">np.asarray(endog)</span><span class="s2">, </span><span class="s3">&quot;endog&quot;</span><span class="s2">, </span><span class="s1">use_pandas=</span><span class="s2">False</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">isinstance(existing.data.orig_exog</span><span class="s2">, </span><span class="s1">(pd.Series</span><span class="s2">, </span><span class="s1">pd.DataFrame)):</span>
            <span class="s1">exog = _check(existing.data.orig_exog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s3">&quot;exog&quot;</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">exog </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">exog = _check(</span>
                <span class="s1">existing.exog</span><span class="s2">, </span><span class="s1">np.asarray(exog)</span><span class="s2">, </span><span class="s3">&quot;endog&quot;</span><span class="s2">, </span><span class="s1">use_pandas=</span><span class="s2">False</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self.apply(endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">refit=refit</span><span class="s2">, </span><span class="s1">fit_kwargs=fit_kwargs)</span>


<span class="s2">class </span><span class="s1">AutoRegResultsWrapper(wrap.ResultsWrapper):</span>
    <span class="s1">_attrs = {}</span>
    <span class="s1">_wrap_attrs = wrap.union_dicts(</span>
        <span class="s1">tsa_model.TimeSeriesResultsWrapper._wrap_attrs</span><span class="s2">, </span><span class="s1">_attrs</span>
    <span class="s1">)</span>
    <span class="s1">_methods = {}</span>
    <span class="s1">_wrap_methods = wrap.union_dicts(</span>
        <span class="s1">tsa_model.TimeSeriesResultsWrapper._wrap_methods</span><span class="s2">, </span><span class="s1">_methods</span>
    <span class="s1">)</span>


<span class="s1">wrap.populate_wrapper(AutoRegResultsWrapper</span><span class="s2">, </span><span class="s1">AutoRegResults)</span>

<span class="s1">doc = Docstring(AutoReg.__doc__)</span>
<span class="s1">_auto_reg_params = doc.extract_parameters(</span>
    <span class="s1">[</span>
        <span class="s3">&quot;trend&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;seasonal&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;exog&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;hold_back&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;period&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;missing&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;old_names&quot;</span><span class="s2">,</span>
    <span class="s1">]</span><span class="s2">,</span>
    <span class="s4">4</span><span class="s2">,</span>
<span class="s1">)</span>


<span class="s1">@Substitution(auto_reg_params=_auto_reg_params)</span>
<span class="s2">def </span><span class="s1">ar_select_order(</span>
    <span class="s1">endog</span><span class="s2">,</span>
    <span class="s1">maxlag</span><span class="s2">,</span>
    <span class="s1">ic=</span><span class="s3">&quot;bic&quot;</span><span class="s2">,</span>
    <span class="s1">glob=</span><span class="s2">False,</span>
    <span class="s1">trend: Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s2">, </span><span class="s3">&quot;ctt&quot;</span><span class="s1">] = </span><span class="s3">&quot;c&quot;</span><span class="s2">,</span>
    <span class="s1">seasonal=</span><span class="s2">False,</span>
    <span class="s1">exog=</span><span class="s2">None,</span>
    <span class="s1">hold_back=</span><span class="s2">None,</span>
    <span class="s1">period=</span><span class="s2">None,</span>
    <span class="s1">missing=</span><span class="s3">&quot;none&quot;</span><span class="s2">,</span>
    <span class="s1">old_names=</span><span class="s2">False,</span>
<span class="s1">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Autoregressive AR-X(p) model order selection. 
 
    Parameters 
    ---------- 
    endog : array_like 
         A 1-d endogenous response variable. The independent variable. 
    maxlag : int 
        The maximum lag to consider. 
    ic : {'aic', 'hqic', 'bic'} 
        The information criterion to use in the selection. 
    glob : bool 
        Flag indicating where to use a global search  across all combinations 
        of lags.  In practice, this option is not computational feasible when 
        maxlag is larger than 15 (or perhaps 20) since the global search 
        requires fitting 2**maxlag models.\n%(auto_reg_params)s 
 
    Returns 
    ------- 
    AROrderSelectionResults 
        A results holder containing the model and the complete set of 
        information criteria for all models fit. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from statsmodels.tsa.ar_model import ar_select_order 
    &gt;&gt;&gt; data = sm.datasets.sunspots.load_pandas().data['SUNACTIVITY'] 
 
    Determine the optimal lag structure 
 
    &gt;&gt;&gt; mod = ar_select_order(data, maxlag=13) 
    &gt;&gt;&gt; mod.ar_lags 
    array([1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
    Determine the optimal lag structure with seasonal terms 
 
    &gt;&gt;&gt; mod = ar_select_order(data, maxlag=13, seasonal=True, period=12) 
    &gt;&gt;&gt; mod.ar_lags 
    array([1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
    Globally determine the optimal lag structure 
 
    &gt;&gt;&gt; mod = ar_select_order(data, maxlag=13, glob=True) 
    &gt;&gt;&gt; mod.ar_lags 
    array([1, 2, 9]) 
    &quot;&quot;&quot;</span>
    <span class="s1">full_mod = AutoReg(</span>
        <span class="s1">endog</span><span class="s2">,</span>
        <span class="s1">maxlag</span><span class="s2">,</span>
        <span class="s1">trend=trend</span><span class="s2">,</span>
        <span class="s1">seasonal=seasonal</span><span class="s2">,</span>
        <span class="s1">exog=exog</span><span class="s2">,</span>
        <span class="s1">hold_back=hold_back</span><span class="s2">,</span>
        <span class="s1">period=period</span><span class="s2">,</span>
        <span class="s1">missing=missing</span><span class="s2">,</span>
        <span class="s1">old_names=old_names</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">nexog = full_mod.exog.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">full_mod.exog </span><span class="s2">is not None else </span><span class="s4">0</span>
    <span class="s1">y</span><span class="s2">, </span><span class="s1">x = full_mod._y</span><span class="s2">, </span><span class="s1">full_mod._x</span>
    <span class="s1">base_col = x.shape[</span><span class="s4">1</span><span class="s1">] - nexog - maxlag</span>
    <span class="s1">sel = np.ones(x.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
    <span class="s1">ics: list[tuple[int | tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">tuple[float</span><span class="s2">, </span><span class="s1">float</span><span class="s2">, </span><span class="s1">float]]] = []</span>

    <span class="s2">def </span><span class="s1">compute_ics(res):</span>
        <span class="s1">nobs = res.nobs</span>
        <span class="s1">df_model = res.df_model</span>
        <span class="s1">sigma2 = </span><span class="s4">1.0 </span><span class="s1">/ nobs * sumofsq(res.resid)</span>
        <span class="s1">llf = -nobs * (np.log(</span><span class="s4">2 </span><span class="s1">* np.pi * sigma2) + </span><span class="s4">1</span><span class="s1">) / </span><span class="s4">2</span>
        <span class="s1">res = SimpleNamespace(</span>
            <span class="s1">nobs=nobs</span><span class="s2">, </span><span class="s1">df_model=df_model</span><span class="s2">, </span><span class="s1">sigma2=sigma2</span><span class="s2">, </span><span class="s1">llf=llf</span>
        <span class="s1">)</span>

        <span class="s1">aic = call_cached_func(AutoRegResults.aic</span><span class="s2">, </span><span class="s1">res)</span>
        <span class="s1">bic = call_cached_func(AutoRegResults.bic</span><span class="s2">, </span><span class="s1">res)</span>
        <span class="s1">hqic = call_cached_func(AutoRegResults.hqic</span><span class="s2">, </span><span class="s1">res)</span>

        <span class="s2">return </span><span class="s1">aic</span><span class="s2">, </span><span class="s1">bic</span><span class="s2">, </span><span class="s1">hqic</span>

    <span class="s2">def </span><span class="s1">ic_no_data():</span>
        <span class="s5">&quot;&quot;&quot;Fake mod and results to handle no regressor case&quot;&quot;&quot;</span>
        <span class="s1">mod = SimpleNamespace(</span>
            <span class="s1">nobs=y.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">endog=y</span><span class="s2">, </span><span class="s1">exog=np.empty((y.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">)</span>
        <span class="s1">llf = OLS.loglike(mod</span><span class="s2">, </span><span class="s1">np.empty(</span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">res = SimpleNamespace(</span>
            <span class="s1">resid=y</span><span class="s2">, </span><span class="s1">nobs=y.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">llf=llf</span><span class="s2">, </span><span class="s1">df_model=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">k_constant=</span><span class="s4">0</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">compute_ics(res)</span>

    <span class="s2">if not </span><span class="s1">glob:</span>
        <span class="s1">sel[base_col : base_col + maxlag] = </span><span class="s2">False</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(maxlag + </span><span class="s4">1</span><span class="s1">):</span>
            <span class="s1">sel[base_col : base_col + i] = </span><span class="s2">True</span>
            <span class="s2">if not </span><span class="s1">np.any(sel):</span>
                <span class="s1">ics.append((</span><span class="s4">0</span><span class="s2">, </span><span class="s1">ic_no_data()))</span>
                <span class="s2">continue</span>
            <span class="s1">res = OLS(y</span><span class="s2">, </span><span class="s1">x[:</span><span class="s2">, </span><span class="s1">sel]).fit()</span>
            <span class="s1">lags = tuple(j </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">i + </span><span class="s4">1</span><span class="s1">))</span>
            <span class="s1">lags = </span><span class="s4">0 </span><span class="s2">if not </span><span class="s1">lags </span><span class="s2">else </span><span class="s1">lags</span>
            <span class="s1">ics.append((lags</span><span class="s2">, </span><span class="s1">compute_ics(res)))</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">bits = np.arange(</span><span class="s4">2</span><span class="s1">**maxlag</span><span class="s2">, </span><span class="s1">dtype=np.int32)[:</span><span class="s2">, None</span><span class="s1">]</span>
        <span class="s1">bits = bits.view(np.uint8)</span>
        <span class="s1">bits = np.unpackbits(bits).reshape(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">32</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">4</span><span class="s1">):</span>
            <span class="s1">bits[:</span><span class="s2">, </span><span class="s4">8 </span><span class="s1">* i : </span><span class="s4">8 </span><span class="s1">* (i + </span><span class="s4">1</span><span class="s1">)] = bits[:</span><span class="s2">, </span><span class="s4">8 </span><span class="s1">* i : </span><span class="s4">8 </span><span class="s1">* (i + </span><span class="s4">1</span><span class="s1">)][</span>
                <span class="s1">:</span><span class="s2">, </span><span class="s1">::-</span><span class="s4">1</span>
            <span class="s1">]</span>
        <span class="s1">masks = bits[:</span><span class="s2">, </span><span class="s1">:maxlag]</span>
        <span class="s2">for </span><span class="s1">mask </span><span class="s2">in </span><span class="s1">masks:</span>
            <span class="s1">sel[base_col : base_col + maxlag] = mask</span>
            <span class="s2">if not </span><span class="s1">np.any(sel):</span>
                <span class="s1">ics.append((</span><span class="s4">0</span><span class="s2">, </span><span class="s1">ic_no_data()))</span>
                <span class="s2">continue</span>
            <span class="s1">res = OLS(y</span><span class="s2">, </span><span class="s1">x[:</span><span class="s2">, </span><span class="s1">sel]).fit()</span>
            <span class="s1">lags = tuple(np.where(mask)[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">lags = </span><span class="s4">0 </span><span class="s2">if not </span><span class="s1">lags </span><span class="s2">else </span><span class="s1">lags</span>
            <span class="s1">ics.append((lags</span><span class="s2">, </span><span class="s1">compute_ics(res)))</span>

    <span class="s1">key_loc = {</span><span class="s3">&quot;aic&quot;</span><span class="s1">: </span><span class="s4">0</span><span class="s2">, </span><span class="s3">&quot;bic&quot;</span><span class="s1">: </span><span class="s4">1</span><span class="s2">, </span><span class="s3">&quot;hqic&quot;</span><span class="s1">: </span><span class="s4">2</span><span class="s1">}[ic]</span>
    <span class="s1">ics = sorted(ics</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">x: x[</span><span class="s4">1</span><span class="s1">][key_loc])</span>
    <span class="s1">selected_model = ics[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s1">mod = AutoReg(</span>
        <span class="s1">endog</span><span class="s2">,</span>
        <span class="s1">selected_model</span><span class="s2">,</span>
        <span class="s1">trend=trend</span><span class="s2">,</span>
        <span class="s1">seasonal=seasonal</span><span class="s2">,</span>
        <span class="s1">exog=exog</span><span class="s2">,</span>
        <span class="s1">hold_back=hold_back</span><span class="s2">,</span>
        <span class="s1">period=period</span><span class="s2">,</span>
        <span class="s1">missing=missing</span><span class="s2">,</span>
        <span class="s1">old_names=old_names</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">AROrderSelectionResults(mod</span><span class="s2">, </span><span class="s1">ics</span><span class="s2">, </span><span class="s1">trend</span><span class="s2">, </span><span class="s1">seasonal</span><span class="s2">, </span><span class="s1">period)</span>


<span class="s2">class </span><span class="s1">AROrderSelectionResults:</span>
    <span class="s5">&quot;&quot;&quot; 
    Results from an AR order selection 
 
    Contains the information criteria for all fitted model orders. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">model: AutoReg</span><span class="s2">,</span>
        <span class="s1">ics: list[tuple[int | tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">tuple[float</span><span class="s2">, </span><span class="s1">float</span><span class="s2">, </span><span class="s1">float]]]</span><span class="s2">,</span>
        <span class="s1">trend: Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s2">, </span><span class="s3">&quot;ctt&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">seasonal: bool</span><span class="s2">,</span>
        <span class="s1">period: int | </span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s1">self._model = model</span>
        <span class="s1">self._ics = ics</span>
        <span class="s1">self._trend = trend</span>
        <span class="s1">self._seasonal = seasonal</span>
        <span class="s1">self._period = period</span>
        <span class="s1">aic = sorted(ics</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">r: r[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">self._aic = dict([(key</span><span class="s2">, </span><span class="s1">val[</span><span class="s4">0</span><span class="s1">]) </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">aic])</span>
        <span class="s1">bic = sorted(ics</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">r: r[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">self._bic = dict([(key</span><span class="s2">, </span><span class="s1">val[</span><span class="s4">1</span><span class="s1">]) </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">bic])</span>
        <span class="s1">hqic = sorted(ics</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">r: r[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">2</span><span class="s1">])</span>
        <span class="s1">self._hqic = dict([(key</span><span class="s2">, </span><span class="s1">val[</span><span class="s4">2</span><span class="s1">]) </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">hqic])</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">model(self) -&gt; AutoReg:</span>
        <span class="s5">&quot;&quot;&quot;The model selected using the chosen information criterion.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._model</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">seasonal(self) -&gt; bool:</span>
        <span class="s5">&quot;&quot;&quot;Flag indicating if a seasonal component is included.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._seasonal</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">trend(self) -&gt; Literal[</span><span class="s3">&quot;n&quot;</span><span class="s2">, </span><span class="s3">&quot;c&quot;</span><span class="s2">, </span><span class="s3">&quot;ct&quot;</span><span class="s2">, </span><span class="s3">&quot;ctt&quot;</span><span class="s1">]:</span>
        <span class="s5">&quot;&quot;&quot;The trend included in the model selection.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._trend</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">period(self) -&gt; int | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The period of the seasonal component.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._period</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">aic(self) -&gt; dict[int | tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">float]:</span>
        <span class="s5">&quot;&quot;&quot; 
        The Akaike information criterion for the models fit. 
 
        Returns 
        ------- 
        dict[tuple, float] 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._aic</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">bic(self) -&gt; dict[int | tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">float]:</span>
        <span class="s5">&quot;&quot;&quot; 
        The Bayesian (Schwarz) information criteria for the models fit. 
 
        Returns 
        ------- 
        dict[tuple, float] 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._bic</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">hqic(self) -&gt; dict[int | tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">float]:</span>
        <span class="s5">&quot;&quot;&quot; 
        The Hannan-Quinn information criteria for the models fit. 
 
        Returns 
        ------- 
        dict[tuple, float] 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._hqic</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">ar_lags(self) -&gt; list[int] | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s5">&quot;&quot;&quot;The lags included in the selected model.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._model.ar_lags</span>
</pre>
</body>
</html>
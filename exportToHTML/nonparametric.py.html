<html>
<head>
<title>nonparametric.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
nonparametric.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Rank based methods for inferential statistics 
 
Created on Sat Aug 15 10:18:53 2020 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>


<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span>
<span class="s3">from </span><span class="s1">scipy.stats </span><span class="s3">import </span><span class="s1">rankdata</span>

<span class="s3">from </span><span class="s1">statsmodels.stats.base </span><span class="s3">import </span><span class="s1">HolderTuple</span>
<span class="s3">from </span><span class="s1">statsmodels.stats.weightstats </span><span class="s3">import </span><span class="s1">(</span>
    <span class="s1">_tconfint_generic</span><span class="s3">,</span>
    <span class="s1">_tstat_generic</span><span class="s3">,</span>
    <span class="s1">_zconfint_generic</span><span class="s3">,</span>
    <span class="s1">_zstat_generic</span><span class="s3">,</span>
<span class="s1">)</span>


<span class="s3">def </span><span class="s1">rankdata_2samp(x1</span><span class="s3">, </span><span class="s1">x2):</span>
    <span class="s2">&quot;&quot;&quot;Compute midranks for two samples 
 
    Parameters 
    ---------- 
    x1, x2 : array_like 
        Original data for two samples that will be converted to midranks. 
 
    Returns 
    ------- 
    rank1 : ndarray 
        Midranks of the first sample in the pooled sample. 
    rank2 : ndarray 
        Midranks of the second sample in the pooled sample. 
    ranki1 : ndarray 
        Internal midranks of the first sample. 
    ranki2 : ndarray 
        Internal midranks of the second sample. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">x1 = np.asarray(x1)</span>
    <span class="s1">x2 = np.asarray(x2)</span>

    <span class="s1">nobs1 = len(x1)</span>
    <span class="s1">nobs2 = len(x2)</span>
    <span class="s3">if </span><span class="s1">nobs1 == </span><span class="s4">0 </span><span class="s3">or </span><span class="s1">nobs2 == </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;one sample has zero length&quot;</span><span class="s1">)</span>

    <span class="s1">x_combined = np.concatenate((x1</span><span class="s3">, </span><span class="s1">x2))</span>
    <span class="s3">if </span><span class="s1">x_combined.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">rank = np.apply_along_axis(rankdata</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">x_combined)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">rank = rankdata(x_combined)  </span><span class="s0"># no axis in older scipy</span>
    <span class="s1">rank1 = rank[:nobs1]</span>
    <span class="s1">rank2 = rank[nobs1:]</span>
    <span class="s3">if </span><span class="s1">x_combined.ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">ranki1 = np.apply_along_axis(rankdata</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">x1)</span>
        <span class="s1">ranki2 = np.apply_along_axis(rankdata</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s1">x2)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">ranki1 = rankdata(x1)</span>
        <span class="s1">ranki2 = rankdata(x2)</span>
    <span class="s3">return </span><span class="s1">rank1</span><span class="s3">, </span><span class="s1">rank2</span><span class="s3">, </span><span class="s1">ranki1</span><span class="s3">, </span><span class="s1">ranki2</span>


<span class="s3">class </span><span class="s1">RankCompareResult(HolderTuple):</span>
    <span class="s2">&quot;&quot;&quot;Results for rank comparison 
 
    This is a subclass of HolderTuple that includes results from intermediate 
    computations, as well as methods for hypothesis tests, confidence intervals 
    and summary. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">conf_int(self</span><span class="s3">, </span><span class="s1">value=</span><span class="s3">None, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Confidence interval for probability that sample 1 has larger values 
 
        Confidence interval is for the shifted probability 
 
            P(x1 &gt; x2) + 0.5 * P(x1 = x2) - value 
 
        Parameters 
        ---------- 
        value : float 
            Value, default 0, shifts the confidence interval, 
            e.g. ``value=0.5`` centers the confidence interval at zero. 
        alpha : float 
            Significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
 
               * 'two-sided' : H1: ``prob - value`` not equal to 0. 
               * 'larger' :   H1: ``prob - value &gt; 0`` 
               * 'smaller' :  H1: ``prob - value &lt; 0`` 
 
        Returns 
        ------- 
        lower : float or ndarray 
            Lower confidence limit. This is -inf for the one-sided alternative 
            &quot;smaller&quot;. 
        upper : float or ndarray 
            Upper confidence limit. This is inf for the one-sided alternative 
            &quot;larger&quot;. 
 
        &quot;&quot;&quot;</span>

        <span class="s1">p0 = value</span>
        <span class="s3">if </span><span class="s1">p0 </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">p0 = </span><span class="s4">0</span>
        <span class="s1">diff = self.prob1 - p0</span>
        <span class="s1">std_diff = np.sqrt(self.var / self.nobs)</span>

        <span class="s3">if </span><span class="s1">self.use_t </span><span class="s3">is False</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">_zconfint_generic(diff</span><span class="s3">, </span><span class="s1">std_diff</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">alternative)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">_tconfint_generic(diff</span><span class="s3">, </span><span class="s1">std_diff</span><span class="s3">, </span><span class="s1">self.df</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">,</span>
                                     <span class="s1">alternative)</span>

    <span class="s3">def </span><span class="s1">test_prob_superior(self</span><span class="s3">, </span><span class="s1">value=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;test for superiority probability 
 
        H0: P(x1 &gt; x2) + 0.5 * P(x1 = x2) = value 
 
        The alternative is that the probability is either not equal, larger 
        or smaller than the null-value depending on the chosen alternative. 
 
        Parameters 
        ---------- 
        value : float 
            Value of the probability under the Null hypothesis. 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
 
               * 'two-sided' : H1: ``prob - value`` not equal to 0. 
               * 'larger' :   H1: ``prob - value &gt; 0`` 
               * 'smaller' :  H1: ``prob - value &lt; 0`` 
 
        Returns 
        ------- 
        res : HolderTuple 
            HolderTuple instance with the following main attributes 
 
            statistic : float 
                Test statistic for z- or t-test 
            pvalue : float 
                Pvalue of the test based on either normal or t distribution. 
 
        &quot;&quot;&quot;</span>

        <span class="s1">p0 = value  </span><span class="s0"># alias</span>
        <span class="s0"># diff = self.prob1 - p0  # for reporting, not used in computation</span>
        <span class="s0"># TODO: use var_prob</span>
        <span class="s1">std_diff = np.sqrt(self.var / self.nobs)</span>

        <span class="s0"># corresponds to a one-sample test and either p0 or diff could be used</span>
        <span class="s3">if not </span><span class="s1">self.use_t:</span>
            <span class="s1">stat</span><span class="s3">, </span><span class="s1">pv = _zstat_generic(self.prob1</span><span class="s3">, </span><span class="s1">p0</span><span class="s3">, </span><span class="s1">std_diff</span><span class="s3">, </span><span class="s1">alternative</span><span class="s3">,</span>
                                      <span class="s1">diff=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">distr = </span><span class="s5">&quot;normal&quot;</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">stat</span><span class="s3">, </span><span class="s1">pv = _tstat_generic(self.prob1</span><span class="s3">, </span><span class="s1">p0</span><span class="s3">, </span><span class="s1">std_diff</span><span class="s3">, </span><span class="s1">self.df</span><span class="s3">,</span>
                                      <span class="s1">alternative</span><span class="s3">, </span><span class="s1">diff=</span><span class="s4">0</span><span class="s1">)</span>
            <span class="s1">distr = </span><span class="s5">&quot;t&quot;</span>

        <span class="s1">res = HolderTuple(statistic=stat</span><span class="s3">,</span>
                          <span class="s1">pvalue=pv</span><span class="s3">,</span>
                          <span class="s1">df=self.df</span><span class="s3">,</span>
                          <span class="s1">distribution=distr</span>
                          <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">tost_prob_superior(self</span><span class="s3">, </span><span class="s1">low</span><span class="s3">, </span><span class="s1">upp):</span>
        <span class="s2">'''test of stochastic (non-)equivalence of p = P(x1 &gt; x2) 
 
        Null hypothesis:  p &lt; low or p &gt; upp 
        Alternative hypothesis:  low &lt; p &lt; upp 
 
        where p is the probability that a random draw from the population of 
        the first sample has a larger value than a random draw from the 
        population of the second sample, specifically 
 
            p = P(x1 &gt; x2) + 0.5 * P(x1 = x2) 
 
        If the pvalue is smaller than a threshold, say 0.05, then we reject the 
        hypothesis that the probability p that distribution 1 is stochastically 
        superior to distribution 2 is outside of the interval given by 
        thresholds low and upp. 
 
        Parameters 
        ---------- 
        low, upp : float 
            equivalence interval low &lt; mean &lt; upp 
 
        Returns 
        ------- 
        res : HolderTuple 
            HolderTuple instance with the following main attributes 
 
            pvalue : float 
                Pvalue of the equivalence test given by the larger pvalue of 
                the two one-sided tests. 
            statistic : float 
                Test statistic of the one-sided test that has the larger 
                pvalue. 
            results_larger : HolderTuple 
                Results instanc with test statistic, pvalue and degrees of 
                freedom for lower threshold test. 
            results_smaller : HolderTuple 
                Results instanc with test statistic, pvalue and degrees of 
                freedom for upper threshold test. 
 
        '''</span>

        <span class="s1">t1 = self.test_prob_superior(low</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'larger'</span><span class="s1">)</span>
        <span class="s1">t2 = self.test_prob_superior(upp</span><span class="s3">, </span><span class="s1">alternative=</span><span class="s5">'smaller'</span><span class="s1">)</span>

        <span class="s0"># idx_max = 1 if t1.pvalue &lt; t2.pvalue else 0</span>
        <span class="s1">idx_max = np.asarray(t1.pvalue &lt; t2.pvalue</span><span class="s3">, </span><span class="s1">int)</span>
        <span class="s1">title = </span><span class="s5">&quot;Equivalence test for Prob(x1 &gt; x2) + 0.5 Prob(x1 = x2) &quot;</span>
        <span class="s1">res = HolderTuple(statistic=np.choose(idx_max</span><span class="s3">,</span>
                                              <span class="s1">[t1.statistic</span><span class="s3">, </span><span class="s1">t2.statistic])</span><span class="s3">,</span>
                          <span class="s0"># pvalue=[t1.pvalue, t2.pvalue][idx_max], # python</span>
                          <span class="s0"># use np.choose for vectorized selection</span>
                          <span class="s1">pvalue=np.choose(idx_max</span><span class="s3">, </span><span class="s1">[t1.pvalue</span><span class="s3">, </span><span class="s1">t2.pvalue])</span><span class="s3">,</span>
                          <span class="s1">results_larger=t1</span><span class="s3">,</span>
                          <span class="s1">results_smaller=t2</span><span class="s3">,</span>
                          <span class="s1">title=title</span>
                          <span class="s1">)</span>
        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">confint_lintransf(self</span><span class="s3">, </span><span class="s1">const=-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">slope=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">,</span>
                          <span class="s1">alternative=</span><span class="s5">&quot;two-sided&quot;</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;confidence interval of a linear transformation of prob1 
 
        This computes the confidence interval for 
 
            d = const + slope * prob1 
 
        Default values correspond to Somers' d. 
 
        Parameters 
        ---------- 
        const, slope : float 
            Constant and slope for linear (affine) transformation. 
        alpha : float 
            Significance level for the confidence interval, coverage is 
            ``1-alpha`` 
        alternative : str 
            The alternative hypothesis, H1, has to be one of the following 
 
               * 'two-sided' : H1: ``prob - value`` not equal to 0. 
               * 'larger' :   H1: ``prob - value &gt; 0`` 
               * 'smaller' :  H1: ``prob - value &lt; 0`` 
 
        Returns 
        ------- 
        lower : float or ndarray 
            Lower confidence limit. This is -inf for the one-sided alternative 
            &quot;smaller&quot;. 
        upper : float or ndarray 
            Upper confidence limit. This is inf for the one-sided alternative 
            &quot;larger&quot;. 
 
        &quot;&quot;&quot;</span>

        <span class="s1">low_p</span><span class="s3">, </span><span class="s1">upp_p = self.conf_int(alpha=alpha</span><span class="s3">, </span><span class="s1">alternative=alternative)</span>
        <span class="s1">low = const + slope * low_p</span>
        <span class="s1">upp = const + slope * upp_p</span>
        <span class="s3">if </span><span class="s1">slope &lt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">low</span><span class="s3">, </span><span class="s1">upp = upp</span><span class="s3">, </span><span class="s1">low</span>
        <span class="s3">return </span><span class="s1">low</span><span class="s3">, </span><span class="s1">upp</span>

    <span class="s3">def </span><span class="s1">effectsize_normal(self</span><span class="s3">, </span><span class="s1">prob=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Cohen's d, standardized mean difference under normality assumption. 
 
        This computes the standardized mean difference, Cohen's d, effect size 
        that is equivalent to the rank based probability ``p`` of being 
        stochastically larger if we assume that the data is normally 
        distributed, given by 
 
            :math: `d = F^{-1}(p) * \\sqrt{2}` 
 
        where :math:`F^{-1}` is the inverse of the cdf of the normal 
        distribution. 
 
        Parameters 
        ---------- 
        prob : float in (0, 1) 
            Probability to be converted to Cohen's d effect size. 
            If prob is None, then the ``prob1`` attribute is used. 
 
        Returns 
        ------- 
        equivalent Cohen's d effect size under normality assumption. 
 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">prob </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">prob = self.prob1</span>
        <span class="s3">return </span><span class="s1">stats.norm.ppf(prob) * np.sqrt(</span><span class="s4">2</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">summary(self</span><span class="s3">, </span><span class="s1">alpha=</span><span class="s4">0.05</span><span class="s3">, </span><span class="s1">xname=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot;summary table for probability that random draw x1 is larger than x2 
 
        Parameters 
        ---------- 
        alpha : float 
            Significance level for confidence intervals. Coverage is 1 - alpha 
        xname : None or list of str 
            If None, then each row has a name column with generic names. 
            If xname is a list of strings, then it will be included as part 
            of those names. 
 
        Returns 
        ------- 
        SimpleTable instance with methods to convert to different output 
        formats. 
        &quot;&quot;&quot;</span>

        <span class="s1">yname = </span><span class="s5">&quot;None&quot;</span>
        <span class="s1">effect = np.atleast_1d(self.prob1)</span>
        <span class="s3">if </span><span class="s1">self.pvalue </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">statistic</span><span class="s3">, </span><span class="s1">pvalue = self.test_prob_superior()</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">pvalue = self.pvalue</span>
            <span class="s1">statistic = self.statistic</span>
        <span class="s1">pvalues = np.atleast_1d(pvalue)</span>
        <span class="s1">ci = np.atleast_2d(self.conf_int(alpha=alpha))</span>
        <span class="s3">if </span><span class="s1">ci.shape[</span><span class="s4">0</span><span class="s1">] &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">ci = ci.T</span>
        <span class="s1">use_t = self.use_t</span>
        <span class="s1">sd = np.atleast_1d(np.sqrt(self.var_prob))</span>
        <span class="s1">statistic = np.atleast_1d(statistic)</span>
        <span class="s3">if </span><span class="s1">xname </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">xname = [</span><span class="s5">'c%d' </span><span class="s1">% ii </span><span class="s3">for </span><span class="s1">ii </span><span class="s3">in </span><span class="s1">range(len(effect))]</span>

        <span class="s1">xname2 = [</span><span class="s5">'prob(x1&gt;x2) %s' </span><span class="s1">% ii </span><span class="s3">for </span><span class="s1">ii </span><span class="s3">in </span><span class="s1">xname]</span>

        <span class="s1">title = </span><span class="s5">&quot;Probability sample 1 is stochastically larger&quot;</span>
        <span class="s3">from </span><span class="s1">statsmodels.iolib.summary </span><span class="s3">import </span><span class="s1">summary_params</span>

        <span class="s1">summ = summary_params((self</span><span class="s3">, </span><span class="s1">effect</span><span class="s3">, </span><span class="s1">sd</span><span class="s3">, </span><span class="s1">statistic</span><span class="s3">,</span>
                               <span class="s1">pvalues</span><span class="s3">, </span><span class="s1">ci)</span><span class="s3">,</span>
                              <span class="s1">yname=yname</span><span class="s3">, </span><span class="s1">xname=xname2</span><span class="s3">, </span><span class="s1">use_t=use_t</span><span class="s3">,</span>
                              <span class="s1">title=title</span><span class="s3">, </span><span class="s1">alpha=alpha)</span>
        <span class="s3">return </span><span class="s1">summ</span>


<span class="s3">def </span><span class="s1">rank_compare_2indep(x1</span><span class="s3">, </span><span class="s1">x2</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Statistics and tests for the probability that x1 has larger values than x2. 
 
    p is the probability that a random draw from the population of 
    the first sample has a larger value than a random draw from the 
    population of the second sample, specifically 
 
            p = P(x1 &gt; x2) + 0.5 * P(x1 = x2) 
 
    This is a measure underlying Wilcoxon-Mann-Whitney's U test, 
    Fligner-Policello test and Brunner-Munzel test, and 
    Inference is based on the asymptotic distribution of the Brunner-Munzel 
    test. The half probability for ties corresponds to the use of midranks 
    and make it valid for discrete variables. 
 
    The Null hypothesis for stochastic equality is p = 0.5, which corresponds 
    to the Brunner-Munzel test. 
 
    Parameters 
    ---------- 
    x1, x2 : array_like 
        Array of samples, should be one-dimensional. 
    use_t : boolean 
        If use_t is true, the t distribution with Welch-Satterthwaite type 
        degrees of freedom is used for p-value and confidence interval. 
        If use_t is false, then the normal distribution is used. 
 
    Returns 
    ------- 
    res : RankCompareResult 
        The results instance contains the results for the Brunner-Munzel test 
        and has methods for hypothesis tests, confidence intervals and summary. 
 
        statistic : float 
            The Brunner-Munzel W statistic. 
        pvalue : float 
            p-value assuming an t distribution. One-sided or 
            two-sided, depending on the choice of `alternative` and `use_t`. 
 
    See Also 
    -------- 
    RankCompareResult 
    scipy.stats.brunnermunzel : Brunner-Munzel test for stochastic equality 
    scipy.stats.mannwhitneyu : Mann-Whitney rank test on two samples. 
 
    Notes 
    ----- 
    Wilcoxon-Mann-Whitney assumes equal variance or equal distribution under 
    the Null hypothesis. Fligner-Policello test allows for unequal variances 
    but assumes continuous distribution, i.e. no ties. 
    Brunner-Munzel extend the test to allow for unequal variance and discrete 
    or ordered categorical random variables. 
 
    Brunner and Munzel recommended to estimate the p-value by t-distribution 
    when the size of data is 50 or less. If the size is lower than 10, it would 
    be better to use permuted Brunner Munzel test (see [2]_) for the test 
    of stochastic equality. 
 
    This measure has been introduced in the literature under many different 
    names relying on a variety of assumptions. 
    In psychology, McGraw and Wong (1992) introduced it as Common Language 
    effect size for the continuous, normal distribution case, 
    Vargha and Delaney (2000) [3]_ extended it to the nonparametric 
    continuous distribution case as in Fligner-Policello. 
 
    WMW and related tests can only be interpreted as test of medians or tests 
    of central location only under very restrictive additional assumptions 
    such as both distribution are identical under the equality null hypothesis 
    (assumed by Mann-Whitney) or both distributions are symmetric (shown by 
    Fligner-Policello). If the distribution of the two samples can differ in 
    an arbitrary way, then the equality Null hypothesis corresponds to p=0.5 
    against an alternative p != 0.5.  see for example Conroy (2012) [4]_ and 
    Divine et al (2018) [5]_ . 
 
    Note: Brunner-Munzel and related literature define the probability that x1 
    is stochastically smaller than x2, while here we use stochastically larger. 
    This equivalent to switching x1 and x2 in the two sample case. 
 
    References 
    ---------- 
    .. [1] Brunner, E. and Munzel, U. &quot;The nonparametric Benhrens-Fisher 
           problem: Asymptotic theory and a small-sample approximation&quot;. 
           Biometrical Journal. Vol. 42(2000): 17-25. 
    .. [2] Neubert, K. and Brunner, E. &quot;A studentized permutation test for the 
           non-parametric Behrens-Fisher problem&quot;. Computational Statistics and 
           Data Analysis. Vol. 51(2007): 5192-5204. 
    .. [3] Vargha, András, and Harold D. Delaney. 2000. “A Critique and 
           Improvement of the CL Common Language Effect Size Statistics of 
           McGraw and Wong.” Journal of Educational and Behavioral Statistics 
           25 (2): 101–32. https://doi.org/10.3102/10769986025002101. 
    .. [4] Conroy, Ronán M. 2012. “What Hypotheses Do ‘Nonparametric’ Two-Group 
           Tests Actually Test?” The Stata Journal: Promoting Communications on 
           Statistics and Stata 12 (2): 182–90. 
           https://doi.org/10.1177/1536867X1201200202. 
    .. [5] Divine, George W., H. James Norton, Anna E. Barón, and Elizabeth 
           Juarez-Colunga. 2018. “The Wilcoxon–Mann–Whitney Procedure Fails as 
           a Test of Medians.” The American Statistician 72 (3): 278–86. 
           https://doi.org/10.1080/00031305.2017.1305291. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">x1 = np.asarray(x1)</span>
    <span class="s1">x2 = np.asarray(x2)</span>

    <span class="s1">nobs1 = len(x1)</span>
    <span class="s1">nobs2 = len(x2)</span>
    <span class="s1">nobs = nobs1 + nobs2</span>
    <span class="s3">if </span><span class="s1">nobs1 == </span><span class="s4">0 </span><span class="s3">or </span><span class="s1">nobs2 == </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;one sample has zero length&quot;</span><span class="s1">)</span>

    <span class="s1">rank1</span><span class="s3">, </span><span class="s1">rank2</span><span class="s3">, </span><span class="s1">ranki1</span><span class="s3">, </span><span class="s1">ranki2 = rankdata_2samp(x1</span><span class="s3">, </span><span class="s1">x2)</span>

    <span class="s1">meanr1 = np.mean(rank1</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">meanr2 = np.mean(rank2</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">meanri1 = np.mean(ranki1</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">meanri2 = np.mean(ranki2</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">S1 = np.sum(np.power(rank1 - ranki1 - meanr1 + meanri1</span><span class="s3">, </span><span class="s4">2.0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">S1 /= nobs1 - </span><span class="s4">1</span>
    <span class="s1">S2 = np.sum(np.power(rank2 - ranki2 - meanr2 + meanri2</span><span class="s3">, </span><span class="s4">2.0</span><span class="s1">)</span><span class="s3">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">S2 /= nobs2 - </span><span class="s4">1</span>

    <span class="s1">wbfn = nobs1 * nobs2 * (meanr1 - meanr2)</span>
    <span class="s1">wbfn /= (nobs1 + nobs2) * np.sqrt(nobs1 * S1 + nobs2 * S2)</span>

    <span class="s0"># Here we only use alternative == &quot;two-sided&quot;</span>
    <span class="s3">if </span><span class="s1">use_t:</span>
        <span class="s1">df_numer = np.power(nobs1 * S1 + nobs2 * S2</span><span class="s3">, </span><span class="s4">2.0</span><span class="s1">)</span>
        <span class="s1">df_denom = np.power(nobs1 * S1</span><span class="s3">, </span><span class="s4">2.0</span><span class="s1">) / (nobs1 - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">df_denom += np.power(nobs2 * S2</span><span class="s3">, </span><span class="s4">2.0</span><span class="s1">) / (nobs2 - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">df = df_numer / df_denom</span>
        <span class="s1">pvalue = </span><span class="s4">2 </span><span class="s1">* stats.t.sf(np.abs(wbfn)</span><span class="s3">, </span><span class="s1">df)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">pvalue = </span><span class="s4">2 </span><span class="s1">* stats.norm.sf(np.abs(wbfn))</span>
        <span class="s1">df = </span><span class="s3">None</span>

    <span class="s0"># other info</span>
    <span class="s1">var1 = S1 / (nobs - nobs1)**</span><span class="s4">2</span>
    <span class="s1">var2 = S2 / (nobs - nobs2)**</span><span class="s4">2</span>
    <span class="s1">var_prob = (var1 / nobs1 + var2 / nobs2)</span>
    <span class="s1">var = nobs * (var1 / nobs1 + var2 / nobs2)</span>
    <span class="s1">prob1 = (meanr1 - (nobs1 + </span><span class="s4">1</span><span class="s1">) / </span><span class="s4">2</span><span class="s1">) / nobs2</span>
    <span class="s1">prob2 = (meanr2 - (nobs2 + </span><span class="s4">1</span><span class="s1">) / </span><span class="s4">2</span><span class="s1">) / nobs1</span>

    <span class="s3">return </span><span class="s1">RankCompareResult(statistic=wbfn</span><span class="s3">, </span><span class="s1">pvalue=pvalue</span><span class="s3">, </span><span class="s1">s1=S1</span><span class="s3">, </span><span class="s1">s2=S2</span><span class="s3">,</span>
                             <span class="s1">var1=var1</span><span class="s3">, </span><span class="s1">var2=var2</span><span class="s3">, </span><span class="s1">var=var</span><span class="s3">,</span>
                             <span class="s1">var_prob=var_prob</span><span class="s3">,</span>
                             <span class="s1">nobs1=nobs1</span><span class="s3">, </span><span class="s1">nobs2=nobs2</span><span class="s3">, </span><span class="s1">nobs=nobs</span><span class="s3">,</span>
                             <span class="s1">mean1=meanr1</span><span class="s3">, </span><span class="s1">mean2=meanr2</span><span class="s3">,</span>
                             <span class="s1">prob1=prob1</span><span class="s3">, </span><span class="s1">prob2=prob2</span><span class="s3">,</span>
                             <span class="s1">somersd1=prob1 * </span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span><span class="s3">, </span><span class="s1">somersd2=prob2 * </span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span><span class="s3">,</span>
                             <span class="s1">df=df</span><span class="s3">, </span><span class="s1">use_t=use_t</span>
                             <span class="s1">)</span>


<span class="s3">def </span><span class="s1">rank_compare_2ordinal(count1</span><span class="s3">, </span><span class="s1">count2</span><span class="s3">, </span><span class="s1">ddof=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">use_t=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot; 
    Stochastically larger probability for 2 independent ordinal samples. 
 
    This is a special case of `rank_compare_2indep` when the data are given as 
    counts of two independent ordinal, i.e. ordered multinomial, samples. 
 
    The statistic of interest is the probability that a random draw from the 
    population of the first sample has a larger value than a random draw from 
    the population of the second sample, specifically 
 
        p = P(x1 &gt; x2) + 0.5 * P(x1 = x2) 
 
    Parameters 
    ---------- 
    count1 : array_like 
        Counts of the first sample, categories are assumed to be ordered. 
    count2 : array_like 
        Counts of the second sample, number of categories and ordering needs 
        to be the same as for sample 1. 
    ddof : scalar 
        Degrees of freedom correction for variance estimation. The default 
        ddof=1 corresponds to `rank_compare_2indep`. 
    use_t : bool 
        If use_t is true, the t distribution with Welch-Satterthwaite type 
        degrees of freedom is used for p-value and confidence interval. 
        If use_t is false, then the normal distribution is used. 
 
    Returns 
    ------- 
    res : RankCompareResult 
        This includes methods for hypothesis tests and confidence intervals 
        for the probability that sample 1 is stochastically larger than 
        sample 2. 
 
    See Also 
    -------- 
    rank_compare_2indep 
    RankCompareResult 
 
    Notes 
    ----- 
    The implementation is based on the appendix of Munzel and Hauschke (2003) 
    with the addition of ``ddof`` so that the results match the general 
    function `rank_compare_2indep`. 
 
    &quot;&quot;&quot;</span>

    <span class="s1">count1 = np.asarray(count1)</span>
    <span class="s1">count2 = np.asarray(count2)</span>
    <span class="s1">nobs1</span><span class="s3">, </span><span class="s1">nobs2 = count1.sum()</span><span class="s3">, </span><span class="s1">count2.sum()</span>
    <span class="s1">freq1 = count1 / nobs1</span>
    <span class="s1">freq2 = count2 / nobs2</span>
    <span class="s1">cdf1 = np.concatenate(([</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">freq1)).cumsum(axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">cdf2 = np.concatenate(([</span><span class="s4">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">freq2)).cumsum(axis=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s0"># mid rank cdf</span>
    <span class="s1">cdfm1 = (cdf1[</span><span class="s4">1</span><span class="s1">:] + cdf1[:-</span><span class="s4">1</span><span class="s1">]) / </span><span class="s4">2</span>
    <span class="s1">cdfm2 = (cdf2[</span><span class="s4">1</span><span class="s1">:] + cdf2[:-</span><span class="s4">1</span><span class="s1">]) / </span><span class="s4">2</span>
    <span class="s1">prob1 = (cdfm2 * freq1).sum()</span>
    <span class="s1">prob2 = (cdfm1 * freq2).sum()</span>

    <span class="s1">var1 = (cdfm2**</span><span class="s4">2 </span><span class="s1">* freq1).sum() - prob1**</span><span class="s4">2</span>
    <span class="s1">var2 = (cdfm1**</span><span class="s4">2 </span><span class="s1">* freq2).sum() - prob2**</span><span class="s4">2</span>

    <span class="s1">var_prob = (var1 / (nobs1 - ddof) + var2 / (nobs2 - ddof))</span>
    <span class="s1">nobs = nobs1 + nobs2</span>
    <span class="s1">var = nobs * var_prob</span>
    <span class="s1">vn1 = var1 * nobs2 * nobs1 / (nobs1 - ddof)</span>
    <span class="s1">vn2 = var2 * nobs1 * nobs2 / (nobs2 - ddof)</span>
    <span class="s1">df = (vn1 + vn2)**</span><span class="s4">2 </span><span class="s1">/ (vn1**</span><span class="s4">2 </span><span class="s1">/ (nobs1 - </span><span class="s4">1</span><span class="s1">) + vn2**</span><span class="s4">2 </span><span class="s1">/ (nobs2 - </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">res = RankCompareResult(statistic=</span><span class="s3">None, </span><span class="s1">pvalue=</span><span class="s3">None, </span><span class="s1">s1=</span><span class="s3">None, </span><span class="s1">s2=</span><span class="s3">None,</span>
                            <span class="s1">var1=var1</span><span class="s3">, </span><span class="s1">var2=var2</span><span class="s3">, </span><span class="s1">var=var</span><span class="s3">,</span>
                            <span class="s1">var_prob=var_prob</span><span class="s3">,</span>
                            <span class="s1">nobs1=nobs1</span><span class="s3">, </span><span class="s1">nobs2=nobs2</span><span class="s3">, </span><span class="s1">nobs=nobs</span><span class="s3">,</span>
                            <span class="s1">mean1=</span><span class="s3">None, </span><span class="s1">mean2=</span><span class="s3">None,</span>
                            <span class="s1">prob1=prob1</span><span class="s3">, </span><span class="s1">prob2=prob2</span><span class="s3">,</span>
                            <span class="s1">somersd1=prob1 * </span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span><span class="s3">, </span><span class="s1">somersd2=prob2 * </span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span><span class="s3">,</span>
                            <span class="s1">df=df</span><span class="s3">, </span><span class="s1">use_t=use_t</span>
                            <span class="s1">)</span>

    <span class="s3">return </span><span class="s1">res</span>


<span class="s3">def </span><span class="s1">prob_larger_continuous(distr1</span><span class="s3">, </span><span class="s1">distr2):</span>
    <span class="s2">&quot;&quot;&quot; 
    Probability indicating that distr1 is stochastically larger than distr2. 
 
    This computes 
 
        p = P(x1 &gt; x2) 
 
    for two continuous distributions, where `distr1` and `distr2` are the 
    distributions of random variables x1 and x2 respectively. 
 
    Parameters 
    ---------- 
    distr1, distr2 : distributions 
        Two instances of scipy.stats.distributions. The required methods are 
        cdf of the second distribution and expect of the first distribution. 
 
    Returns 
    ------- 
    p : probability x1 is larger than x2 
 
 
    Notes 
    ----- 
    This is a one-liner that is added mainly as reference. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; prob_larger_continuous(stats.norm, stats.t(5)) 
    0.4999999999999999 
 
    # which is the same as 
    &gt;&gt;&gt; stats.norm.expect(stats.t(5).cdf) 
    0.4999999999999999 
 
    # distribution 1 with smaller mean (loc) than distribution 2 
    &gt;&gt;&gt; prob_larger_continuous(stats.norm, stats.norm(loc=1)) 
    0.23975006109347669 
 
    &quot;&quot;&quot;</span>

    <span class="s3">return </span><span class="s1">distr1.expect(distr2.cdf)</span>


<span class="s3">def </span><span class="s1">cohensd2problarger(d):</span>
    <span class="s2">&quot;&quot;&quot; 
    Convert Cohen's d effect size to stochastically-larger-probability. 
 
    This assumes observations are normally distributed. 
 
    Computed as 
 
        p = Prob(x1 &gt; x2) = F(d / sqrt(2)) 
 
    where `F` is cdf of normal distribution. Cohen's d is defined as 
 
        d = (mean1 - mean2) / std 
 
    where ``std`` is the pooled within standard deviation. 
 
    Parameters 
    ---------- 
    d : float or array_like 
        Cohen's d effect size for difference mean1 - mean2. 
 
    Returns 
    ------- 
    prob : float or ndarray 
        Prob(x1 &gt; x2) 
    &quot;&quot;&quot;</span>

    <span class="s3">return </span><span class="s1">stats.norm.cdf(d / np.sqrt(</span><span class="s4">2</span><span class="s1">))</span>
</pre>
</body>
</html>
<html>
<head>
<title>_parameter_inference.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_parameter_inference.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
Created on Wed May 30 15:11:09 2018 
 
@author: josef 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">stats</span>


<span class="s0"># this is a copy from stats._diagnostic_other to avoid circular imports</span>
<span class="s3">def </span><span class="s1">_lm_robust(score</span><span class="s3">, </span><span class="s1">constraint_matrix</span><span class="s3">, </span><span class="s1">score_deriv_inv</span><span class="s3">, </span><span class="s1">cov_score</span><span class="s3">,</span>
               <span class="s1">cov_params=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">'''general formula for score/LM test 
 
    generalized score or lagrange multiplier test for implicit constraints 
 
    `r(params) = 0`, with gradient `R = d r / d params` 
 
    linear constraints are given by `R params - q = 0` 
 
    It is assumed that all arrays are evaluated at the constrained estimates. 
 
 
    Parameters 
    ---------- 
    score : ndarray, 1-D 
        derivative of objective function at estimated parameters 
        of constrained model 
    constraint_matrix R : ndarray 
        Linear restriction matrix or Jacobian of nonlinear constraints 
    score_deriv_inv, Ainv : ndarray, symmetric, square 
        inverse of second derivative of objective function 
        TODO: could be inverse of OPG or any other estimator if information 
        matrix equality holds 
    cov_score B :  ndarray, symmetric, square 
        covariance matrix of the score. This is the inner part of a sandwich 
        estimator. 
    cov_params V :  ndarray, symmetric, square 
        covariance of full parameter vector evaluated at constrained parameter 
        estimate. This can be specified instead of cov_score B. 
 
    Returns 
    ------- 
    lm_stat : float 
        score/lagrange multiplier statistic 
    p-value : float 
        p-value of the LM test based on chisquare distribution 
 
    Notes 
    ----- 
 
    '''</span>
    <span class="s0"># shorthand alias</span>
    <span class="s1">R</span><span class="s3">, </span><span class="s1">Ainv</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">V = constraint_matrix</span><span class="s3">, </span><span class="s1">score_deriv_inv</span><span class="s3">, </span><span class="s1">cov_score</span><span class="s3">, </span><span class="s1">cov_params</span>

    <span class="s1">k_constraints = np.linalg.matrix_rank(R)</span>
    <span class="s1">tmp = R.dot(Ainv)</span>
    <span class="s1">wscore = tmp.dot(score)  </span><span class="s0"># C Ainv score</span>

    <span class="s3">if </span><span class="s1">B </span><span class="s3">is None and </span><span class="s1">V </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s0"># only Ainv is given, so we assume information matrix identity holds</span>
        <span class="s0"># computational short cut, should be same if Ainv == inv(B)</span>
        <span class="s1">lm_stat = score.dot(Ainv.dot(score))</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s0"># information matrix identity does not hold</span>
        <span class="s3">if </span><span class="s1">V </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">inner = tmp.dot(B).dot(tmp.T)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">inner = R.dot(V).dot(R.T)</span>

        <span class="s0">#lm_stat2 = wscore.dot(np.linalg.pinv(inner).dot(wscore))</span>
        <span class="s0"># Let's assume inner is invertible, TODO: check if usecase for pinv exists</span>
        <span class="s1">lm_stat = wscore.dot(np.linalg.solve(inner</span><span class="s3">, </span><span class="s1">wscore))</span>
    <span class="s1">pval = stats.chi2.sf(lm_stat</span><span class="s3">, </span><span class="s1">k_constraints)</span>
    <span class="s3">return </span><span class="s1">lm_stat</span><span class="s3">, </span><span class="s1">pval</span><span class="s3">, </span><span class="s1">k_constraints</span>


<span class="s3">def </span><span class="s1">score_test(self</span><span class="s3">, </span><span class="s1">exog_extra=</span><span class="s3">None, </span><span class="s1">params_constrained=</span><span class="s3">None,</span>
               <span class="s1">hypothesis=</span><span class="s4">'joint'</span><span class="s3">, </span><span class="s1">cov_type=</span><span class="s3">None, </span><span class="s1">cov_kwds=</span><span class="s3">None,</span>
               <span class="s1">k_constraints=</span><span class="s3">None, </span><span class="s1">r_matrix=</span><span class="s3">None, </span><span class="s1">scale=</span><span class="s3">None, </span><span class="s1">observed=</span><span class="s3">True</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;score test for restrictions or for omitted variables 
 
    Null Hypothesis : constraints are satisfied 
 
    Alternative Hypothesis : at least one of the constraints does not hold 
 
    This allows to specify restricted and unrestricted model properties in 
    three different ways 
 
    - fit_constrained result: model contains score and hessian function for 
      the full, unrestricted model, but the parameter estimate in the results 
      instance is for the restricted model. This is the case if the model 
      was estimated with fit_constrained. 
    - restricted model with variable addition: If exog_extra is not None, then 
      it is assumed that the current model is a model with zero restrictions 
      and the unrestricted model is given by adding exog_extra as additional 
      explanatory variables. 
    - unrestricted model with restricted parameters explicitly provided. If 
      params_constrained is not None, then the model is assumed to be for the 
      unrestricted model, but the provided parameters are for the restricted 
      model. 
      TODO: This case will currently only work for `nonrobust` cov_type, 
      otherwise we will also need the restriction matrix provided by the user. 
 
 
    Parameters 
    ---------- 
    exog_extra : None or array_like 
        Explanatory variables that are jointly tested for inclusion in the 
        model, i.e. omitted variables. 
    params_constrained : array_like 
        estimated parameter of the restricted model. This can be the 
        parameter estimate for the current when testing for omitted 
        variables. 
    hypothesis : str, 'joint' (default) or 'separate' 
        If hypothesis is 'joint', then the chisquare test results for the 
        joint hypothesis that all constraints hold is returned. 
        If hypothesis is 'joint', then z-test results for each constraint 
        is returned. 
        This is currently only implemented for cov_type=&quot;nonrobust&quot;. 
    cov_type : str 
        Warning: only partially implemented so far, currently only &quot;nonrobust&quot; 
        and &quot;HC0&quot; are supported. 
        If cov_type is None, then the cov_type specified in fit for the Wald 
        tests is used. 
        If the cov_type argument is not None, then it will be used instead of 
        the Wald cov_type given in fit. 
    k_constraints : int or None 
        Number of constraints that were used in the estimation of params 
        restricted relative to the number of exog in the model. 
        This must be provided if no exog_extra are given. If exog_extra is 
        not None, then k_constraints is assumed to be zero if it is None. 
    observed : bool 
        If True, then the observed Hessian is used in calculating the 
        covariance matrix of the score. If false then the expected 
        information matrix is used. This currently only applies to GLM where 
        EIM is available. 
        Warning: This option might still change. 
 
    Returns 
    ------- 
    chi2_stat : float 
        chisquare statistic for the score test 
    p-value : float 
        P-value of the score test based on the chisquare distribution. 
    df : int 
        Degrees of freedom used in the p-value calculation. This is equal 
        to the number of constraints. 
 
    Notes 
    ----- 
    Status: experimental, several options are not implemented yet or are not 
    verified yet. Currently available ptions might also still change. 
 
    cov_type is 'nonrobust': 
 
    The covariance matrix for the score is based on the Hessian, i.e. 
    observed information matrix or optionally on the expected information 
    matrix. 
 
    cov_type is 'HC0' 
 
    The covariance matrix of the score is the simple empirical covariance of 
    score_obs without degrees of freedom correction. 
    &quot;&quot;&quot;</span>
    <span class="s0"># TODO: we are computing unnecessary things for cov_type nonrobust</span>
    <span class="s3">if </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s4">&quot;_results&quot;</span><span class="s1">):</span>
        <span class="s0"># use numpy if we have wrapper, not relevant if method</span>
        <span class="s1">self = self._results</span>
    <span class="s1">model = self.model</span>
    <span class="s1">nobs = model.endog.shape[</span><span class="s5">0</span><span class="s1">]  </span><span class="s0"># model.nobs</span>
    <span class="s0"># discrete Poisson does not have nobs</span>
    <span class="s3">if </span><span class="s1">params_constrained </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">params_constrained = self.params</span>
    <span class="s1">cov_type = cov_type </span><span class="s3">if </span><span class="s1">cov_type </span><span class="s3">is not None else </span><span class="s1">self.cov_type</span>

    <span class="s3">if </span><span class="s1">observed </span><span class="s3">is False</span><span class="s1">:</span>
        <span class="s1">hess_kwd = {</span><span class="s4">'observed'</span><span class="s1">: </span><span class="s3">False</span><span class="s1">}</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">hess_kwd = {}</span>

    <span class="s3">if </span><span class="s1">exog_extra </span><span class="s3">is None</span><span class="s1">:</span>

        <span class="s3">if </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s4">'constraints'</span><span class="s1">):</span>
            <span class="s3">if </span><span class="s1">isinstance(self.constraints</span><span class="s3">, </span><span class="s1">tuple):</span>
                <span class="s1">r_matrix = self.constraints[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">r_matrix = self.constraints.coefs</span>
            <span class="s1">k_constraints = r_matrix.shape[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s3">else</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">k_constraints </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'if exog_extra is None, then k_constraints'</span>
                                 <span class="s4">'needs to be given'</span><span class="s1">)</span>

        <span class="s0"># we need to use results scale as additional parameter</span>
        <span class="s3">if </span><span class="s1">scale </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s0"># we need to use results scale as additional parameter, gh #7840</span>
            <span class="s1">score_kwd = {</span><span class="s4">'scale'</span><span class="s1">: scale}</span>
            <span class="s1">hess_kwd[</span><span class="s4">'scale'</span><span class="s1">] = scale</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">score_kwd = {}</span>

        <span class="s0"># duplicate computation of score, might not be needed</span>
        <span class="s1">score = model.score(params_constrained</span><span class="s3">, </span><span class="s1">**score_kwd)</span>
        <span class="s1">score_obs = model.score_obs(params_constrained</span><span class="s3">, </span><span class="s1">**score_kwd)</span>
        <span class="s1">hessian = model.hessian(params_constrained</span><span class="s3">, </span><span class="s1">**hess_kwd)</span>

    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">if </span><span class="s1">cov_type == </span><span class="s4">'V'</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">'if exog_extra is not None, then cov_type cannot '</span>
                             <span class="s4">'be V'</span><span class="s1">)</span>
        <span class="s3">if </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s4">'constraints'</span><span class="s1">):</span>
            <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s4">'if exog_extra is not None, then self'</span>
                                      <span class="s4">'should not be a constrained fit result'</span><span class="s1">)</span>

        <span class="s3">if </span><span class="s1">isinstance(exog_extra</span><span class="s3">, </span><span class="s1">tuple):</span>
            <span class="s1">sh = _scorehess_extra(self</span><span class="s3">, </span><span class="s1">params_constrained</span><span class="s3">, </span><span class="s1">*exog_extra</span><span class="s3">,</span>
                                  <span class="s1">hess_kwds=hess_kwd)</span>
            <span class="s1">score_obs</span><span class="s3">, </span><span class="s1">hessian</span><span class="s3">, </span><span class="s1">k_constraints</span><span class="s3">, </span><span class="s1">r_matrix = sh</span>
            <span class="s1">score = score_obs.sum(</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">exog_extra = np.asarray(exog_extra)</span>
            <span class="s1">k_constraints = </span><span class="s5">0</span>
            <span class="s1">ex = np.column_stack((model.exog</span><span class="s3">, </span><span class="s1">exog_extra))</span>
            <span class="s0"># this uses shape not matrix rank to determine k_constraints</span>
            <span class="s0"># requires nonsingular (no added perfect collinearity)</span>
            <span class="s1">k_constraints += ex.shape[</span><span class="s5">1</span><span class="s1">] - model.exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
            <span class="s0"># TODO use diag instead of full np.eye</span>
            <span class="s1">r_matrix = np.eye(len(self.params) + k_constraints</span>
                              <span class="s1">)[-k_constraints:]</span>

            <span class="s1">score_factor = model.score_factor(params_constrained)</span>
            <span class="s3">if </span><span class="s1">score_factor.ndim == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">score_obs = (score_factor[:</span><span class="s3">, None</span><span class="s1">] * ex)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">sf = score_factor</span>
                <span class="s1">score_obs = np.column_stack((sf[:</span><span class="s3">, </span><span class="s1">:</span><span class="s5">1</span><span class="s1">] * ex</span><span class="s3">, </span><span class="s1">sf[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">:]))</span>
            <span class="s1">score = score_obs.sum(</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">hessian_factor = model.hessian_factor(params_constrained</span><span class="s3">,</span>
                                                  <span class="s1">**hess_kwd)</span>
            <span class="s0"># see #4714</span>
            <span class="s3">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s3">import </span><span class="s1">GLM</span>
            <span class="s3">if </span><span class="s1">isinstance(model</span><span class="s3">, </span><span class="s1">GLM):</span>
                <span class="s1">hessian_factor *= -</span><span class="s5">1</span>
            <span class="s1">hessian = np.dot(ex.T * hessian_factor</span><span class="s3">, </span><span class="s1">ex)</span>

    <span class="s3">if </span><span class="s1">cov_type == </span><span class="s4">'nonrobust'</span><span class="s1">:</span>
        <span class="s1">cov_score_test = -hessian</span>
    <span class="s3">elif </span><span class="s1">cov_type.upper() == </span><span class="s4">'HC0'</span><span class="s1">:</span>
        <span class="s1">hinv = -np.linalg.inv(hessian)</span>
        <span class="s1">cov_score = nobs * np.cov(score_obs.T)</span>
        <span class="s0"># temporary to try out</span>
        <span class="s1">lm = _lm_robust(score</span><span class="s3">, </span><span class="s1">r_matrix</span><span class="s3">, </span><span class="s1">hinv</span><span class="s3">, </span><span class="s1">cov_score</span><span class="s3">, </span><span class="s1">cov_params=</span><span class="s3">None</span><span class="s1">)</span>
        <span class="s3">return </span><span class="s1">lm</span>
        <span class="s0"># alternative is to use only the center, but it is singular</span>
        <span class="s0"># https://github.com/statsmodels/statsmodels/pull/2096#issuecomment-393646205</span>
        <span class="s0"># cov_score_test_inv = cov_lm_robust(score, r_matrix, hinv,</span>
        <span class="s0">#                                   cov_score, cov_params=None)</span>
    <span class="s3">elif </span><span class="s1">cov_type.upper() == </span><span class="s4">'V'</span><span class="s1">:</span>
        <span class="s0"># TODO: this does not work, V in fit_constrained results is singular</span>
        <span class="s0"># we need cov_params without the zeros in it</span>
        <span class="s1">hinv = -np.linalg.inv(hessian)</span>
        <span class="s1">cov_score = nobs * np.cov(score_obs.T)</span>
        <span class="s1">V = self.cov_params_default</span>
        <span class="s0"># temporary to try out</span>
        <span class="s1">chi2stat = _lm_robust(score</span><span class="s3">, </span><span class="s1">r_matrix</span><span class="s3">, </span><span class="s1">hinv</span><span class="s3">, </span><span class="s1">cov_score</span><span class="s3">, </span><span class="s1">cov_params=V)</span>
        <span class="s1">pval = stats.chi2.sf(chi2stat</span><span class="s3">, </span><span class="s1">k_constraints)</span>
        <span class="s3">return </span><span class="s1">chi2stat</span><span class="s3">, </span><span class="s1">pval</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">msg = </span><span class="s4">'Only cov_type &quot;nonrobust&quot; and &quot;HC0&quot; are available.'</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError(msg)</span>

    <span class="s3">if </span><span class="s1">hypothesis == </span><span class="s4">'joint'</span><span class="s1">:</span>
        <span class="s1">chi2stat = score.dot(np.linalg.solve(cov_score_test</span><span class="s3">, </span><span class="s1">score[:</span><span class="s3">, None</span><span class="s1">]))</span>
        <span class="s1">pval = stats.chi2.sf(chi2stat</span><span class="s3">, </span><span class="s1">k_constraints)</span>
        <span class="s0"># return a stats results instance instead?  Contrast?</span>
        <span class="s3">return </span><span class="s1">chi2stat</span><span class="s3">, </span><span class="s1">pval</span><span class="s3">, </span><span class="s1">k_constraints</span>
    <span class="s3">elif </span><span class="s1">hypothesis == </span><span class="s4">'separate'</span><span class="s1">:</span>
        <span class="s1">diff = score</span>
        <span class="s1">bse = np.sqrt(np.diag(cov_score_test))</span>
        <span class="s1">stat = diff / bse</span>
        <span class="s1">pval = stats.norm.sf(np.abs(stat))*</span><span class="s5">2</span>
        <span class="s3">return </span><span class="s1">stat</span><span class="s3">, </span><span class="s1">pval</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s4">'only hypothesis &quot;joint&quot; is available'</span><span class="s1">)</span>


<span class="s3">def </span><span class="s1">_scorehess_extra(self</span><span class="s3">, </span><span class="s1">params=</span><span class="s3">None, </span><span class="s1">exog_extra=</span><span class="s3">None,</span>
                     <span class="s1">exog2_extra=</span><span class="s3">None, </span><span class="s1">hess_kwds=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Experimental helper function for variable addition score test. 
 
    This uses score and hessian factor at the params which should be the 
    params of the restricted model. 
 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">hess_kwds </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">hess_kwds = {}</span>
    <span class="s0"># this corresponds to a model methods, so we need only the model</span>
    <span class="s1">model = self.model</span>
    <span class="s0"># as long as we have results instance, we can take params from it</span>
    <span class="s3">if </span><span class="s1">params </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s1">params = self.params</span>

    <span class="s0"># get original exog from model, currently only if exactly 2</span>
    <span class="s1">exog_o1</span><span class="s3">, </span><span class="s1">exog_o2 = model._get_exogs()</span>

    <span class="s3">if </span><span class="s1">exog_o2 </span><span class="s3">is None</span><span class="s1">:</span>
        <span class="s0"># if extra params is scalar, as in NB, GPP</span>
        <span class="s1">exog_o2 = np.ones((exog_o1.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s1">k_mean = exog_o1.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">k_prec = exog_o2.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s3">if </span><span class="s1">exog_extra </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">exog = np.column_stack((exog_o1</span><span class="s3">, </span><span class="s1">exog_extra))</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">exog = exog_o1</span>

    <span class="s3">if </span><span class="s1">exog2_extra </span><span class="s3">is not None</span><span class="s1">:</span>
        <span class="s1">exog2 = np.column_stack((exog_o2</span><span class="s3">, </span><span class="s1">exog2_extra))</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">exog2 = exog_o2</span>

    <span class="s1">k_mean_new = exog.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">k_prec_new = exog2.shape[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">k_cm = k_mean_new - k_mean</span>
    <span class="s1">k_cp = k_prec_new - k_prec</span>
    <span class="s1">k_constraints = k_cm + k_cp</span>

    <span class="s1">index_mean = np.arange(k_mean</span><span class="s3">, </span><span class="s1">k_mean_new)</span>
    <span class="s1">index_prec = np.arange(k_mean_new + k_prec</span><span class="s3">, </span><span class="s1">k_mean_new + k_prec_new)</span>

    <span class="s1">r_matrix = np.zeros((k_constraints</span><span class="s3">, </span><span class="s1">len(params) + k_constraints))</span>
    <span class="s0"># print(exog.shape, exog2.shape)</span>
    <span class="s0"># print(r_matrix.shape, k_cm, k_cp, k_mean_new, k_prec_new)</span>
    <span class="s0"># print(index_mean, index_prec)</span>
    <span class="s1">r_matrix[:k_cm</span><span class="s3">, </span><span class="s1">index_mean] = np.eye(k_cm)</span>
    <span class="s1">r_matrix[k_cm: k_cm + k_cp</span><span class="s3">, </span><span class="s1">index_prec] = np.eye(k_cp)</span>

    <span class="s3">if </span><span class="s1">hasattr(model</span><span class="s3">, </span><span class="s4">&quot;score_hessian_factor&quot;</span><span class="s1">):</span>
        <span class="s1">sf</span><span class="s3">, </span><span class="s1">hf = model.score_hessian_factor(params</span><span class="s3">, </span><span class="s1">return_hessian=</span><span class="s3">True,</span>
                                            <span class="s1">**hess_kwds)</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">sf = model.score_factor(params)</span>
        <span class="s1">hf = model.hessian_factor(params</span><span class="s3">, </span><span class="s1">**hess_kwds)</span>

    <span class="s1">sf1</span><span class="s3">, </span><span class="s1">sf2 = sf</span>
    <span class="s1">hf11</span><span class="s3">, </span><span class="s1">hf12</span><span class="s3">, </span><span class="s1">hf22 = hf</span>

    <span class="s0"># elementwise product for each row (observation)</span>
    <span class="s1">d1 = sf1[:</span><span class="s3">, None</span><span class="s1">] * exog</span>
    <span class="s1">d2 = sf2[:</span><span class="s3">, None</span><span class="s1">] * exog2</span>
    <span class="s1">score_obs = np.column_stack((d1</span><span class="s3">, </span><span class="s1">d2))</span>

    <span class="s0"># elementwise product for each row (observation)</span>
    <span class="s1">d11 = (exog.T * hf11).dot(exog)</span>
    <span class="s1">d12 = (exog.T * hf12).dot(exog2)</span>
    <span class="s1">d22 = (exog2.T * hf22).dot(exog2)</span>
    <span class="s1">hessian = np.block([[d11</span><span class="s3">, </span><span class="s1">d12]</span><span class="s3">, </span><span class="s1">[d12.T</span><span class="s3">, </span><span class="s1">d22]])</span>
    <span class="s3">return </span><span class="s1">score_obs</span><span class="s3">, </span><span class="s1">hessian</span><span class="s3">, </span><span class="s1">k_constraints</span><span class="s3">, </span><span class="s1">r_matrix</span>


<span class="s3">def </span><span class="s1">im_ratio(results):</span>
    <span class="s1">res = getattr(results</span><span class="s3">, </span><span class="s4">&quot;_results&quot;</span><span class="s3">, </span><span class="s1">results)  </span><span class="s0"># shortcut</span>
    <span class="s1">hess = res.model.hessian(res.params)</span>
    <span class="s3">if </span><span class="s1">res.cov_type == </span><span class="s4">&quot;nonrobust&quot;</span><span class="s1">:</span>
        <span class="s1">score_obs = res.model.score_obs(res.params)</span>
        <span class="s1">cov_score = score_obs.T @ score_obs</span>
        <span class="s1">hessneg_inv = np.linalg.inv(-hess)</span>
        <span class="s1">im_ratio = hessneg_inv @ cov_score</span>
    <span class="s3">else</span><span class="s1">:</span>
        <span class="s1">im_ratio = res.cov_params() @ (-hess)</span>
    <span class="s3">return </span><span class="s1">im_ratio</span>


<span class="s3">def </span><span class="s1">tic(results):</span>
    <span class="s2">&quot;&quot;&quot;Takeuchi information criterion for misspecified models 
 
    &quot;&quot;&quot;</span>
    <span class="s1">imr = getattr(results</span><span class="s3">, </span><span class="s4">&quot;im_ratio&quot;</span><span class="s3">, </span><span class="s1">im_ratio(results))</span>
    <span class="s1">tic = - </span><span class="s5">2 </span><span class="s1">* results.llf + </span><span class="s5">2 </span><span class="s1">* np.trace(imr)</span>
    <span class="s3">return </span><span class="s1">tic</span>


<span class="s3">def </span><span class="s1">gbic(results</span><span class="s3">, </span><span class="s1">gbicp=</span><span class="s3">False</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;generalized BIC for misspecified models 
 
    References 
    ---------- 
    Lv, Jinchi, and Jun S. Liu. 2014. &quot;Model Selection Principles in 
    Misspecified Models.&quot; Journal of the Royal Statistical Society. 
    Series B (Statistical Methodology) 76 (1): 141â€“67. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">self = getattr(results</span><span class="s3">, </span><span class="s4">&quot;_results&quot;</span><span class="s3">, </span><span class="s1">results)</span>
    <span class="s1">k_params = self.df_model + </span><span class="s5">1</span>
    <span class="s1">nobs = k_params + self.df_resid</span>
    <span class="s1">imr = getattr(results</span><span class="s3">, </span><span class="s4">&quot;im_ratio&quot;</span><span class="s3">, </span><span class="s1">im_ratio(results))</span>
    <span class="s1">imr_logdet = np.linalg.slogdet(imr)[</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">gbic = -</span><span class="s5">2 </span><span class="s1">* self.llf + k_params * np.log(nobs) - imr_logdet  </span><span class="s0"># LL equ. (20)</span>
    <span class="s1">gbicp = gbic + np.trace(imr)  </span><span class="s0"># LL equ. (23)</span>
    <span class="s3">return </span><span class="s1">gbic</span><span class="s3">, </span><span class="s1">gbicp</span>
</pre>
</body>
</html>
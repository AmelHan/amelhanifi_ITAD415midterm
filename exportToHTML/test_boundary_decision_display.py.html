<html>
<head>
<title>test_boundary_decision_display.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_boundary_decision_display.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>

<span class="s0">from </span><span class="s1">sklearn.base </span><span class="s0">import </span><span class="s1">BaseEstimator</span><span class="s0">, </span><span class="s1">ClassifierMixin</span>
<span class="s0">from </span><span class="s1">sklearn.datasets </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">load_iris</span><span class="s0">,</span>
    <span class="s1">make_classification</span><span class="s0">,</span>
    <span class="s1">make_multilabel_classification</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.inspection </span><span class="s0">import </span><span class="s1">DecisionBoundaryDisplay</span>
<span class="s0">from </span><span class="s1">sklearn.inspection._plot.decision_boundary </span><span class="s0">import </span><span class="s1">_check_boundary_response_method</span>
<span class="s0">from </span><span class="s1">sklearn.linear_model </span><span class="s0">import </span><span class="s1">LogisticRegression</span>
<span class="s0">from </span><span class="s1">sklearn.tree </span><span class="s0">import </span><span class="s1">DecisionTreeClassifier</span><span class="s0">, </span><span class="s1">DecisionTreeRegressor</span>

<span class="s2"># TODO: Remove when https://github.com/numpy/numpy/issues/14397 is resolved</span>
<span class="s1">pytestmark = pytest.mark.filterwarnings(</span>
    <span class="s3">&quot;ignore:In future, it will be an error for 'np.bool_':DeprecationWarning:&quot;</span>
    <span class="s3">&quot;matplotlib.*&quot;</span>
<span class="s1">)</span>


<span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(</span>
    <span class="s1">n_informative=</span><span class="s4">1</span><span class="s0">,</span>
    <span class="s1">n_redundant=</span><span class="s4">1</span><span class="s0">,</span>
    <span class="s1">n_clusters_per_class=</span><span class="s4">1</span><span class="s0">,</span>
    <span class="s1">n_features=</span><span class="s4">2</span><span class="s0">,</span>
    <span class="s1">random_state=</span><span class="s4">42</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s1">@pytest.fixture(scope=</span><span class="s3">&quot;module&quot;</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">fitted_clf():</span>
    <span class="s0">return </span><span class="s1">LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>


<span class="s0">def </span><span class="s1">test_input_data_dimension(pyplot):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise an error when `X` does not have exactly 2 features.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_samples=</span><span class="s4">10</span><span class="s0">, </span><span class="s1">n_features=</span><span class="s4">4</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">clf = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s1">msg = </span><span class="s3">&quot;n_features must be equal to 2. Got 4 instead.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(estimator=clf</span><span class="s0">, </span><span class="s1">X=X)</span>


<span class="s0">def </span><span class="s1">test_check_boundary_response_method_auto():</span>
    <span class="s5">&quot;&quot;&quot;Check _check_boundary_response_method behavior with 'auto'.&quot;&quot;&quot;</span>

    <span class="s0">class </span><span class="s1">A:</span>
        <span class="s0">def </span><span class="s1">decision_function(self):</span>
            <span class="s0">pass</span>

    <span class="s1">a_inst = A()</span>
    <span class="s1">method = _check_boundary_response_method(a_inst</span><span class="s0">, </span><span class="s3">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">method == a_inst.decision_function</span>

    <span class="s0">class </span><span class="s1">B:</span>
        <span class="s0">def </span><span class="s1">predict_proba(self):</span>
            <span class="s0">pass</span>

    <span class="s1">b_inst = B()</span>
    <span class="s1">method = _check_boundary_response_method(b_inst</span><span class="s0">, </span><span class="s3">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">method == b_inst.predict_proba</span>

    <span class="s0">class </span><span class="s1">C:</span>
        <span class="s0">def </span><span class="s1">predict_proba(self):</span>
            <span class="s0">pass</span>

        <span class="s0">def </span><span class="s1">decision_function(self):</span>
            <span class="s0">pass</span>

    <span class="s1">c_inst = C()</span>
    <span class="s1">method = _check_boundary_response_method(c_inst</span><span class="s0">, </span><span class="s3">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">method == c_inst.decision_function</span>

    <span class="s0">class </span><span class="s1">D:</span>
        <span class="s0">def </span><span class="s1">predict(self):</span>
            <span class="s0">pass</span>

    <span class="s1">d_inst = D()</span>
    <span class="s1">method = _check_boundary_response_method(d_inst</span><span class="s0">, </span><span class="s3">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">method == d_inst.predict</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;predict_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_multiclass_error(pyplot</span><span class="s0">, </span><span class="s1">response_method):</span>
    <span class="s5">&quot;&quot;&quot;Check multiclass errors.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">n_informative=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">X = X[:</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span>
    <span class="s1">lr = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">msg = (</span>
        <span class="s3">&quot;Multiclass classifiers are only supported when response_method is 'predict' or&quot;</span>
        <span class="s3">&quot; 'auto'&quot;</span>
    <span class="s1">)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">response_method=response_method)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;auto&quot;</span><span class="s0">, </span><span class="s3">&quot;predict&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_multiclass(pyplot</span><span class="s0">, </span><span class="s1">response_method):</span>
    <span class="s5">&quot;&quot;&quot;Check multiclass gives expected results.&quot;&quot;&quot;</span>
    <span class="s1">grid_resolution = </span><span class="s4">10</span>
    <span class="s1">eps = </span><span class="s4">1.0</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_classification(n_classes=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">n_informative=</span><span class="s4">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">X = X[:</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span>
    <span class="s1">lr = LogisticRegression(random_state=</span><span class="s4">0</span><span class="s1">).fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">disp = DecisionBoundaryDisplay.from_estimator(</span>
        <span class="s1">lr</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">response_method=response_method</span><span class="s0">, </span><span class="s1">grid_resolution=grid_resolution</span><span class="s0">, </span><span class="s1">eps=</span><span class="s4">1.0</span>
    <span class="s1">)</span>

    <span class="s1">x0_min</span><span class="s0">, </span><span class="s1">x0_max = X[:</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].min() - eps</span><span class="s0">, </span><span class="s1">X[:</span><span class="s0">, </span><span class="s4">0</span><span class="s1">].max() + eps</span>
    <span class="s1">x1_min</span><span class="s0">, </span><span class="s1">x1_max = X[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].min() - eps</span><span class="s0">, </span><span class="s1">X[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">].max() + eps</span>
    <span class="s1">xx0</span><span class="s0">, </span><span class="s1">xx1 = np.meshgrid(</span>
        <span class="s1">np.linspace(x0_min</span><span class="s0">, </span><span class="s1">x0_max</span><span class="s0">, </span><span class="s1">grid_resolution)</span><span class="s0">,</span>
        <span class="s1">np.linspace(x1_min</span><span class="s0">, </span><span class="s1">x1_max</span><span class="s0">, </span><span class="s1">grid_resolution)</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">response = lr.predict(np.c_[xx0.ravel()</span><span class="s0">, </span><span class="s1">xx1.ravel()])</span>
    <span class="s1">assert_allclose(disp.response</span><span class="s0">, </span><span class="s1">response.reshape(xx0.shape))</span>
    <span class="s1">assert_allclose(disp.xx0</span><span class="s0">, </span><span class="s1">xx0)</span>
    <span class="s1">assert_allclose(disp.xx1</span><span class="s0">, </span><span class="s1">xx1)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;kwargs, error_msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s1">{</span><span class="s3">&quot;plot_method&quot;</span><span class="s1">: </span><span class="s3">&quot;hello_world&quot;</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">r&quot;plot_method must be one of contourf, contour, pcolormesh. Got hello_world&quot;</span>
            <span class="s3">r&quot; instead.&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">{</span><span class="s3">&quot;grid_resolution&quot;</span><span class="s1">: </span><span class="s4">1</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">r&quot;grid_resolution must be greater than 1. Got 1 instead&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s1">{</span><span class="s3">&quot;grid_resolution&quot;</span><span class="s1">: -</span><span class="s4">1</span><span class="s1">}</span><span class="s0">,</span>
            <span class="s3">r&quot;grid_resolution must be greater than 1. Got -1 instead&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">({</span><span class="s3">&quot;eps&quot;</span><span class="s1">: -</span><span class="s4">1.1</span><span class="s1">}</span><span class="s0">, </span><span class="s3">r&quot;eps must be greater than or equal to 0. Got -1.1 instead&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_input_validation_errors(pyplot</span><span class="s0">, </span><span class="s1">kwargs</span><span class="s0">, </span><span class="s1">error_msg</span><span class="s0">, </span><span class="s1">fitted_clf):</span>
    <span class="s5">&quot;&quot;&quot;Check input validation from_estimator.&quot;&quot;&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=error_msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(fitted_clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s0">def </span><span class="s1">test_display_plot_input_error(pyplot</span><span class="s0">, </span><span class="s1">fitted_clf):</span>
    <span class="s5">&quot;&quot;&quot;Check input validation for `plot`.&quot;&quot;&quot;</span>
    <span class="s1">disp = DecisionBoundaryDisplay.from_estimator(fitted_clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">grid_resolution=</span><span class="s4">5</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;plot_method must be 'contourf'&quot;</span><span class="s1">):</span>
        <span class="s1">disp.plot(plot_method=</span><span class="s3">&quot;hello_world&quot;</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;auto&quot;</span><span class="s0">, </span><span class="s3">&quot;predict&quot;</span><span class="s0">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s0">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;plot_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;contourf&quot;</span><span class="s0">, </span><span class="s3">&quot;contour&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_decision_boundary_display(pyplot</span><span class="s0">, </span><span class="s1">fitted_clf</span><span class="s0">, </span><span class="s1">response_method</span><span class="s0">, </span><span class="s1">plot_method):</span>
    <span class="s5">&quot;&quot;&quot;Check that decision boundary is correct.&quot;&quot;&quot;</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">eps = </span><span class="s4">2.0</span>
    <span class="s1">disp = DecisionBoundaryDisplay.from_estimator(</span>
        <span class="s1">fitted_clf</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">5</span><span class="s0">,</span>
        <span class="s1">response_method=response_method</span><span class="s0">,</span>
        <span class="s1">plot_method=plot_method</span><span class="s0">,</span>
        <span class="s1">eps=eps</span><span class="s0">,</span>
        <span class="s1">ax=ax</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">isinstance(disp.surface_</span><span class="s0">, </span><span class="s1">pyplot.matplotlib.contour.QuadContourSet)</span>
    <span class="s0">assert </span><span class="s1">disp.ax_ == ax</span>
    <span class="s0">assert </span><span class="s1">disp.figure_ == fig</span>

    <span class="s1">x0</span><span class="s0">, </span><span class="s1">x1 = X[:</span><span class="s0">, </span><span class="s4">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">X[:</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>

    <span class="s1">x0_min</span><span class="s0">, </span><span class="s1">x0_max = x0.min() - eps</span><span class="s0">, </span><span class="s1">x0.max() + eps</span>
    <span class="s1">x1_min</span><span class="s0">, </span><span class="s1">x1_max = x1.min() - eps</span><span class="s0">, </span><span class="s1">x1.max() + eps</span>

    <span class="s0">assert </span><span class="s1">disp.xx0.min() == pytest.approx(x0_min)</span>
    <span class="s0">assert </span><span class="s1">disp.xx0.max() == pytest.approx(x0_max)</span>
    <span class="s0">assert </span><span class="s1">disp.xx1.min() == pytest.approx(x1_min)</span>
    <span class="s0">assert </span><span class="s1">disp.xx1.max() == pytest.approx(x1_max)</span>

    <span class="s1">fig2</span><span class="s0">, </span><span class="s1">ax2 = pyplot.subplots()</span>
    <span class="s2"># change plotting method for second plot</span>
    <span class="s1">disp.plot(plot_method=</span><span class="s3">&quot;pcolormesh&quot;</span><span class="s0">, </span><span class="s1">ax=ax2</span><span class="s0">, </span><span class="s1">shading=</span><span class="s3">&quot;auto&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">isinstance(disp.surface_</span><span class="s0">, </span><span class="s1">pyplot.matplotlib.collections.QuadMesh)</span>
    <span class="s0">assert </span><span class="s1">disp.ax_ == ax2</span>
    <span class="s0">assert </span><span class="s1">disp.figure_ == fig2</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s3">&quot;response_method, msg&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">(</span>
            <span class="s3">&quot;predict_proba&quot;</span><span class="s0">,</span>
            <span class="s3">&quot;MyClassifier has none of the following attributes: predict_proba&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s3">&quot;decision_function&quot;</span><span class="s0">,</span>
            <span class="s3">&quot;MyClassifier has none of the following attributes: decision_function&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s3">&quot;auto&quot;</span><span class="s0">,</span>
            <span class="s1">(</span>
                <span class="s3">&quot;MyClassifier has none of the following attributes: decision_function, &quot;</span>
                <span class="s3">&quot;predict_proba, predict&quot;</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">(</span>
            <span class="s3">&quot;bad_method&quot;</span><span class="s0">,</span>
            <span class="s3">&quot;MyClassifier has none of the following attributes: bad_method&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_error_bad_response(pyplot</span><span class="s0">, </span><span class="s1">response_method</span><span class="s0">, </span><span class="s1">msg):</span>
    <span class="s5">&quot;&quot;&quot;Check errors for bad response.&quot;&quot;&quot;</span>

    <span class="s0">class </span><span class="s1">MyClassifier(BaseEstimator</span><span class="s0">, </span><span class="s1">ClassifierMixin):</span>
        <span class="s0">def </span><span class="s1">fit(self</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">y):</span>
            <span class="s1">self.fitted_ = </span><span class="s0">True</span>
            <span class="s1">self.classes_ = [</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span>
            <span class="s0">return </span><span class="s1">self</span>

    <span class="s1">clf = MyClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(clf</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">response_method=response_method)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;auto&quot;</span><span class="s0">, </span><span class="s3">&quot;predict&quot;</span><span class="s0">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_multilabel_classifier_error(pyplot</span><span class="s0">, </span><span class="s1">response_method):</span>
    <span class="s5">&quot;&quot;&quot;Check that multilabel classifier raises correct error.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s0">, </span><span class="s1">y = make_multilabel_classification(random_state=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">X = X[:</span><span class="s0">, </span><span class="s1">:</span><span class="s4">2</span><span class="s1">]</span>
    <span class="s1">tree = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s3">&quot;Multi-label and multi-output multi-class classifiers are not supported&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(</span>
            <span class="s1">tree</span><span class="s0">,</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">response_method=response_method</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s3">&quot;response_method&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;auto&quot;</span><span class="s0">, </span><span class="s3">&quot;predict&quot;</span><span class="s0">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_multi_output_multi_class_classifier_error(pyplot</span><span class="s0">, </span><span class="s1">response_method):</span>
    <span class="s5">&quot;&quot;&quot;Check that multi-output multi-class classifier raises correct error.&quot;&quot;&quot;</span>
    <span class="s1">X = np.asarray([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]])</span>
    <span class="s1">y = np.asarray([[</span><span class="s3">&quot;tree&quot;</span><span class="s0">, </span><span class="s3">&quot;cat&quot;</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">&quot;cat&quot;</span><span class="s0">, </span><span class="s3">&quot;tree&quot;</span><span class="s1">]])</span>
    <span class="s1">tree = DecisionTreeClassifier().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s1">msg = </span><span class="s3">&quot;Multi-label and multi-output multi-class classifiers are not supported&quot;</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=msg):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(</span>
            <span class="s1">tree</span><span class="s0">,</span>
            <span class="s1">X</span><span class="s0">,</span>
            <span class="s1">response_method=response_method</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_multioutput_regressor_error(pyplot):</span>
    <span class="s5">&quot;&quot;&quot;Check that multioutput regressor raises correct error.&quot;&quot;&quot;</span>
    <span class="s1">X = np.asarray([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">1</span><span class="s0">, </span><span class="s4">2</span><span class="s1">]])</span>
    <span class="s1">y = np.asarray([[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s4">4</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]])</span>
    <span class="s1">tree = DecisionTreeRegressor().fit(X</span><span class="s0">, </span><span class="s1">y)</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=</span><span class="s3">&quot;Multi-output regressors are not supported&quot;</span><span class="s1">):</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(tree</span><span class="s0">, </span><span class="s1">X)</span>


<span class="s1">@pytest.mark.filterwarnings(</span>
    <span class="s2"># We expect to raise the following warning because the classifier is fit on a</span>
    <span class="s2"># NumPy array</span>
    <span class="s3">&quot;ignore:X has feature names, but LogisticRegression was fitted without&quot;</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_dataframe_labels_used(pyplot</span><span class="s0">, </span><span class="s1">fitted_clf):</span>
    <span class="s5">&quot;&quot;&quot;Check that column names are used for pandas.&quot;&quot;&quot;</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s3">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">df = pd.DataFrame(X</span><span class="s0">, </span><span class="s1">columns=[</span><span class="s3">&quot;col_x&quot;</span><span class="s0">, </span><span class="s3">&quot;col_y&quot;</span><span class="s1">])</span>

    <span class="s2"># pandas column names are used by default</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">disp = DecisionBoundaryDisplay.from_estimator(fitted_clf</span><span class="s0">, </span><span class="s1">df</span><span class="s0">, </span><span class="s1">ax=ax)</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;col_x&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;col_y&quot;</span>

    <span class="s2"># second call to plot will have the names</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">disp.plot(ax=ax)</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;col_x&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;col_y&quot;</span>

    <span class="s2"># axes with a label will not get overridden</span>
    <span class="s1">fig</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">ax.set(xlabel=</span><span class="s3">&quot;hello&quot;</span><span class="s0">, </span><span class="s1">ylabel=</span><span class="s3">&quot;world&quot;</span><span class="s1">)</span>
    <span class="s1">disp.plot(ax=ax)</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;hello&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;world&quot;</span>

    <span class="s2"># labels get overridden only if provided to the `plot` method</span>
    <span class="s1">disp.plot(ax=ax</span><span class="s0">, </span><span class="s1">xlabel=</span><span class="s3">&quot;overwritten_x&quot;</span><span class="s0">, </span><span class="s1">ylabel=</span><span class="s3">&quot;overwritten_y&quot;</span><span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;overwritten_x&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;overwritten_y&quot;</span>

    <span class="s2"># labels do not get inferred if provided to `from_estimator`</span>
    <span class="s1">_</span><span class="s0">, </span><span class="s1">ax = pyplot.subplots()</span>
    <span class="s1">disp = DecisionBoundaryDisplay.from_estimator(</span>
        <span class="s1">fitted_clf</span><span class="s0">, </span><span class="s1">df</span><span class="s0">, </span><span class="s1">ax=ax</span><span class="s0">, </span><span class="s1">xlabel=</span><span class="s3">&quot;overwritten_x&quot;</span><span class="s0">, </span><span class="s1">ylabel=</span><span class="s3">&quot;overwritten_y&quot;</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">ax.get_xlabel() == </span><span class="s3">&quot;overwritten_x&quot;</span>
    <span class="s0">assert </span><span class="s1">ax.get_ylabel() == </span><span class="s3">&quot;overwritten_y&quot;</span>


<span class="s0">def </span><span class="s1">test_string_target(pyplot):</span>
    <span class="s5">&quot;&quot;&quot;Check that decision boundary works with classifiers trained on string labels.&quot;&quot;&quot;</span>
    <span class="s1">iris = load_iris()</span>
    <span class="s1">X = iris.data[:</span><span class="s0">, </span><span class="s1">[</span><span class="s4">0</span><span class="s0">, </span><span class="s4">1</span><span class="s1">]]</span>

    <span class="s2"># Use strings as target</span>
    <span class="s1">y = iris.target_names[iris.target]</span>
    <span class="s1">log_reg = LogisticRegression().fit(X</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s2"># Does not raise</span>
    <span class="s1">DecisionBoundaryDisplay.from_estimator(</span>
        <span class="s1">log_reg</span><span class="s0">,</span>
        <span class="s1">X</span><span class="s0">,</span>
        <span class="s1">grid_resolution=</span><span class="s4">5</span><span class="s0">,</span>
        <span class="s1">response_method=</span><span class="s3">&quot;predict&quot;</span><span class="s0">,</span>
    <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_dataframe_support(pyplot):</span>
    <span class="s5">&quot;&quot;&quot;Check that passing a dataframe at fit and to the Display does not 
    raise warnings. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/23311 
    &quot;&quot;&quot;</span>
    <span class="s1">pd = pytest.importorskip(</span><span class="s3">&quot;pandas&quot;</span><span class="s1">)</span>
    <span class="s1">df = pd.DataFrame(X</span><span class="s0">, </span><span class="s1">columns=[</span><span class="s3">&quot;col_x&quot;</span><span class="s0">, </span><span class="s3">&quot;col_y&quot;</span><span class="s1">])</span>
    <span class="s1">estimator = LogisticRegression().fit(df</span><span class="s0">, </span><span class="s1">y)</span>

    <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s2"># no warnings linked to feature names validation should be raised</span>
        <span class="s1">warnings.simplefilter(</span><span class="s3">&quot;error&quot;</span><span class="s0">, </span><span class="s1">UserWarning)</span>
        <span class="s1">DecisionBoundaryDisplay.from_estimator(estimator</span><span class="s0">, </span><span class="s1">df</span><span class="s0">, </span><span class="s1">response_method=</span><span class="s3">&quot;predict&quot;</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_conditional.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6897bb;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_conditional.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">statsmodels.discrete.conditional_models </span><span class="s0">import </span><span class="s1">(</span>
      <span class="s1">ConditionalLogit</span><span class="s0">, </span><span class="s1">ConditionalPoisson</span><span class="s0">, </span><span class="s1">ConditionalMNLogit)</span>
<span class="s0">from </span><span class="s1">statsmodels.tools.numdiff </span><span class="s0">import </span><span class="s1">approx_fprime</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>
<span class="s0">import </span><span class="s1">pandas </span><span class="s0">as </span><span class="s1">pd</span>


<span class="s0">def </span><span class="s1">test_logit_1d():</span>

    <span class="s1">y = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">g = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span>

    <span class="s1">x = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">x = x[:</span><span class="s0">, None</span><span class="s1">]</span>

    <span class="s1">model = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>

    <span class="s3"># Check the gradient for the denominator of the partial likelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">params = np.r_[x</span><span class="s0">, </span><span class="s1">]</span>
        <span class="s1">_</span><span class="s0">, </span><span class="s1">grad = model._denom_grad(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">params)</span>
        <span class="s1">ngrad = approx_fprime(params</span><span class="s0">, lambda </span><span class="s1">x: model._denom(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">x)).squeeze()</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">ngrad)</span>

    <span class="s3"># Check the gradient for the loglikelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">grad = approx_fprime(np.r_[x</span><span class="s0">, </span><span class="s1">]</span><span class="s0">, </span><span class="s1">model.loglike).squeeze()</span>
        <span class="s1">score = model.score(np.r_[x</span><span class="s0">, </span><span class="s1">])</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">result = model.fit()</span>

    <span class="s3"># From Stata</span>
    <span class="s1">assert_allclose(result.params</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0.9272407</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result.bse</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1.295155</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_logit_2d():</span>

    <span class="s1">y = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">g = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span>

    <span class="s1">x1 = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">x2 = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">x = np.empty((</span><span class="s2">10</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
    <span class="s1">x[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] = x1</span>
    <span class="s1">x[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] = x2</span>

    <span class="s1">model = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>

    <span class="s3"># Check the gradient for the denominator of the partial likelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">params = np.r_[x</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.5</span><span class="s1">*x]</span>
        <span class="s1">_</span><span class="s0">, </span><span class="s1">grad = model._denom_grad(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">params)</span>
        <span class="s1">ngrad = approx_fprime(params</span><span class="s0">, lambda </span><span class="s1">x: model._denom(</span><span class="s2">0</span><span class="s0">, </span><span class="s1">x))</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">ngrad</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s3"># Check the gradient for the loglikelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">params = np.r_[-</span><span class="s2">0.5</span><span class="s1">*x</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">*x]</span>
        <span class="s1">grad = approx_fprime(params</span><span class="s0">, </span><span class="s1">model.loglike)</span>
        <span class="s1">score = model.score(params)</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">result = model.fit()</span>

    <span class="s3"># From Stata</span>
    <span class="s1">assert_allclose(result.params</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1.011074</span><span class="s0">, </span><span class="s2">1.236758</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result.bse</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">1.420784</span><span class="s0">, </span><span class="s2">1.361738</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s1">result.summary()</span>


<span class="s0">def </span><span class="s1">test_formula():</span>

    <span class="s0">for </span><span class="s1">j </span><span class="s0">in </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s1">:</span>

        <span class="s1">np.random.seed(</span><span class="s2">34234</span><span class="s1">)</span>
        <span class="s1">n = </span><span class="s2">200</span>
        <span class="s1">y = np.random.randint(</span><span class="s2">0</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s1">size=n)</span>
        <span class="s1">x1 = np.random.normal(size=n)</span>
        <span class="s1">x2 = np.random.normal(size=n)</span>
        <span class="s1">g = np.random.randint(</span><span class="s2">0</span><span class="s0">, </span><span class="s2">25</span><span class="s0">, </span><span class="s1">size=n)</span>

        <span class="s1">x = np.hstack((x1[:</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x2[:</span><span class="s0">, None</span><span class="s1">]))</span>
        <span class="s0">if </span><span class="s1">j == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">model1 = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">model1 = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>
        <span class="s1">result1 = model1.fit()</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">, </span><span class="s4">&quot;x1&quot;</span><span class="s1">: x1</span><span class="s0">, </span><span class="s4">&quot;x2&quot;</span><span class="s1">: x2</span><span class="s0">, </span><span class="s4">&quot;g&quot;</span><span class="s1">: g})</span>
        <span class="s0">if </span><span class="s1">j == </span><span class="s2">0</span><span class="s1">:</span>
            <span class="s1">model2 = ConditionalLogit.from_formula(</span>
                        <span class="s4">&quot;y ~ 0 + x1 + x2&quot;</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;g&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">model2 = ConditionalPoisson.from_formula(</span>
                        <span class="s4">&quot;y ~ 0 + x1 + x2&quot;</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;g&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
        <span class="s1">result2 = model2.fit()</span>

        <span class="s1">assert_allclose(result1.params</span><span class="s0">, </span><span class="s1">result2.params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(result1.bse</span><span class="s0">, </span><span class="s1">result2.bse</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(result1.cov_params()</span><span class="s0">, </span><span class="s1">result2.cov_params()</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>
        <span class="s1">assert_allclose(result1.tvalues</span><span class="s0">, </span><span class="s1">result2.tvalues</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_poisson_1d():</span>

    <span class="s1">y = np.r_[</span><span class="s2">3</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">4</span><span class="s0">, </span><span class="s2">5</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">6</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span>
    <span class="s1">g = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>

    <span class="s1">x = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">x = x[:</span><span class="s0">, None</span><span class="s1">]</span>

    <span class="s1">model = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>

    <span class="s3"># Check the gradient for the loglikelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">grad = approx_fprime(np.r_[x</span><span class="s0">, </span><span class="s1">]</span><span class="s0">, </span><span class="s1">model.loglike).squeeze()</span>
        <span class="s1">score = model.score(np.r_[x</span><span class="s0">, </span><span class="s1">])</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">result = model.fit()</span>

    <span class="s3"># From Stata</span>
    <span class="s1">assert_allclose(result.params</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0.6466272</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result.bse</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0.4170918</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_poisson_2d():</span>

    <span class="s1">y = np.r_[</span><span class="s2">3</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">4</span><span class="s0">, </span><span class="s2">8</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">5</span><span class="s0">, </span><span class="s2">4</span><span class="s0">, </span><span class="s2">7</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">6</span><span class="s1">]</span>
    <span class="s1">g = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span>

    <span class="s1">x1 = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">x2 = np.r_[</span><span class="s2">2</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">3</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span>
    <span class="s1">x = np.empty((</span><span class="s2">10</span><span class="s0">, </span><span class="s2">2</span><span class="s1">))</span>
    <span class="s1">x[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">] = x1</span>
    <span class="s1">x[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">] = x2</span>

    <span class="s1">model = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=g)</span>

    <span class="s3"># Check the gradient for the loglikelihood</span>
    <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">-</span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">2</span><span class="s1">:</span>
        <span class="s1">params = np.r_[-</span><span class="s2">0.5</span><span class="s1">*x</span><span class="s0">, </span><span class="s2">0.5</span><span class="s1">*x]</span>
        <span class="s1">grad = approx_fprime(params</span><span class="s0">, </span><span class="s1">model.loglike)</span>
        <span class="s1">score = model.score(params)</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">score</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s1">result = model.fit()</span>

    <span class="s3"># From Stata</span>
    <span class="s1">assert_allclose(result.params</span><span class="s0">, </span><span class="s1">np.r_[-</span><span class="s2">.9478957</span><span class="s0">, </span><span class="s1">-</span><span class="s2">.0134279</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result.bse</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">.3874942</span><span class="s0">, </span><span class="s2">.1686712</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s1">result.summary()</span>


<span class="s0">def </span><span class="s1">test_lasso_logistic():</span>

    <span class="s1">np.random.seed(</span><span class="s2">3423948</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s2">200</span>
    <span class="s1">groups = np.arange(</span><span class="s2">10</span><span class="s1">)</span>
    <span class="s1">groups = np.kron(groups</span><span class="s0">, </span><span class="s1">np.ones(n // </span><span class="s2">10</span><span class="s1">))</span>
    <span class="s1">group_effects = np.random.normal(size=</span><span class="s2">10</span><span class="s1">)</span>
    <span class="s1">group_effects = np.kron(group_effects</span><span class="s0">, </span><span class="s1">np.ones(n // </span><span class="s2">10</span><span class="s1">))</span>

    <span class="s1">x = np.random.normal(size=(n</span><span class="s0">, </span><span class="s2">4</span><span class="s1">))</span>
    <span class="s1">params = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">lin_pred = np.dot(x</span><span class="s0">, </span><span class="s1">params) + group_effects</span>

    <span class="s1">mean = </span><span class="s2">1 </span><span class="s1">/ (</span><span class="s2">1 </span><span class="s1">+ np.exp(-lin_pred))</span>
    <span class="s1">y = (np.random.uniform(size=n) &lt; mean).astype(int)</span>

    <span class="s1">model0 = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result0 = model0.fit()</span>

    <span class="s3"># Should be the same as model0</span>
    <span class="s1">model1 = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result1 = model1.fit_regularized(L1_wt=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0</span><span class="s1">)</span>

    <span class="s1">assert_allclose(result0.params</span><span class="s0">, </span><span class="s1">result1.params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s1">)</span>

    <span class="s1">model2 = ConditionalLogit(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result2 = model2.fit_regularized(L1_wt=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0.05</span><span class="s1">)</span>

    <span class="s3"># Rxegression test</span>
    <span class="s1">assert_allclose(result2.params</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0.55235152</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s3"># Test with formula</span>
    <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">, </span><span class="s4">&quot;x1&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;x2&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;x3&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span><span class="s0">,</span>
                       <span class="s4">&quot;x4&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;groups&quot;</span><span class="s1">: groups})</span>
    <span class="s1">fml = </span><span class="s4">&quot;y ~ 0 + x1 + x2 + x3 + x4&quot;</span>
    <span class="s1">model3 = ConditionalLogit.from_formula(fml</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;groups&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
    <span class="s1">result3 = model3.fit_regularized(L1_wt=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0.05</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result2.params</span><span class="s0">, </span><span class="s1">result3.params)</span>


<span class="s0">def </span><span class="s1">test_lasso_poisson():</span>

    <span class="s1">np.random.seed(</span><span class="s2">342394</span><span class="s1">)</span>

    <span class="s1">n = </span><span class="s2">200</span>
    <span class="s1">groups = np.arange(</span><span class="s2">10</span><span class="s1">)</span>
    <span class="s1">groups = np.kron(groups</span><span class="s0">, </span><span class="s1">np.ones(n // </span><span class="s2">10</span><span class="s1">))</span>
    <span class="s1">group_effects = np.random.normal(size=</span><span class="s2">10</span><span class="s1">)</span>
    <span class="s1">group_effects = np.kron(group_effects</span><span class="s0">, </span><span class="s1">np.ones(n // </span><span class="s2">10</span><span class="s1">))</span>

    <span class="s1">x = np.random.normal(size=(n</span><span class="s0">, </span><span class="s2">4</span><span class="s1">))</span>
    <span class="s1">params = np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span>
    <span class="s1">lin_pred = np.dot(x</span><span class="s0">, </span><span class="s1">params) + group_effects</span>

    <span class="s1">mean = np.exp(lin_pred)</span>
    <span class="s1">y = np.random.poisson(mean)</span>

    <span class="s1">model0 = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result0 = model0.fit()</span>

    <span class="s3"># Should be the same as model0</span>
    <span class="s1">model1 = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result1 = model1.fit_regularized(L1_wt=</span><span class="s2">0</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0</span><span class="s1">)</span>

    <span class="s1">assert_allclose(result0.params</span><span class="s0">, </span><span class="s1">result1.params</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-3</span><span class="s1">)</span>

    <span class="s1">model2 = ConditionalPoisson(y</span><span class="s0">, </span><span class="s1">x</span><span class="s0">, </span><span class="s1">groups=groups)</span>
    <span class="s1">result2 = model2.fit_regularized(L1_wt=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0.2</span><span class="s1">)</span>

    <span class="s3"># Regression test</span>
    <span class="s1">assert_allclose(result2.params</span><span class="s0">, </span><span class="s1">np.r_[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">0</span><span class="s0">, </span><span class="s2">0.91697508</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-4</span><span class="s1">)</span>

    <span class="s3"># Test with formula</span>
    <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">, </span><span class="s4">&quot;x1&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;x2&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;x3&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]</span><span class="s0">,</span>
                       <span class="s4">&quot;x4&quot;</span><span class="s1">: x[:</span><span class="s0">, </span><span class="s2">3</span><span class="s1">]</span><span class="s0">, </span><span class="s4">&quot;groups&quot;</span><span class="s1">: groups})</span>
    <span class="s1">fml = </span><span class="s4">&quot;y ~ 0 + x1 + x2 + x3 + x4&quot;</span>
    <span class="s1">model3 = ConditionalPoisson.from_formula(fml</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;groups&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
    <span class="s1">result3 = model3.fit_regularized(L1_wt=</span><span class="s2">1</span><span class="s0">, </span><span class="s1">alpha=</span><span class="s2">0.2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(result2.params</span><span class="s0">, </span><span class="s1">result3.params)</span>


<span class="s0">def </span><span class="s1">gen_mnlogit(n):</span>

    <span class="s1">np.random.seed(</span><span class="s2">235</span><span class="s1">)</span>

    <span class="s1">g = np.kron(np.ones(</span><span class="s2">5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">np.arange(n//</span><span class="s2">5</span><span class="s1">))</span>
    <span class="s1">x1 = np.random.normal(size=n)</span>
    <span class="s1">x2 = np.random.normal(size=n)</span>
    <span class="s1">xm = np.concatenate((x1[:</span><span class="s0">, None</span><span class="s1">]</span><span class="s0">, </span><span class="s1">x2[:</span><span class="s0">, None</span><span class="s1">])</span><span class="s0">, </span><span class="s1">axis=</span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">pa = np.array([[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">1</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s2">0</span><span class="s0">, </span><span class="s2">2</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1</span><span class="s1">]])</span>
    <span class="s1">lpr = np.dot(xm</span><span class="s0">, </span><span class="s1">pa)</span>
    <span class="s1">pr = np.exp(lpr)</span>
    <span class="s1">pr /= pr.sum(</span><span class="s2">1</span><span class="s1">)[:</span><span class="s0">, None</span><span class="s1">]</span>
    <span class="s1">cpr = pr.cumsum(</span><span class="s2">1</span><span class="s1">)</span>
    <span class="s1">y = </span><span class="s2">2 </span><span class="s1">* np.ones(n)</span>
    <span class="s1">u = np.random.uniform(size=n)</span>
    <span class="s1">y[u &lt; cpr[:</span><span class="s0">, </span><span class="s2">2</span><span class="s1">]] = </span><span class="s2">2</span>
    <span class="s1">y[u &lt; cpr[:</span><span class="s0">, </span><span class="s2">1</span><span class="s1">]] = </span><span class="s2">1</span>
    <span class="s1">y[u &lt; cpr[:</span><span class="s0">, </span><span class="s2">0</span><span class="s1">]] = </span><span class="s2">0</span>

    <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;y&quot;</span><span class="s1">: y</span><span class="s0">, </span><span class="s4">&quot;x1&quot;</span><span class="s1">: x1</span><span class="s0">,</span>
                       <span class="s4">&quot;x2&quot;</span><span class="s1">: x2</span><span class="s0">, </span><span class="s4">&quot;g&quot;</span><span class="s1">: g})</span>
    <span class="s0">return </span><span class="s1">df</span>


<span class="s0">def </span><span class="s1">test_conditional_mnlogit_grad():</span>

    <span class="s1">df = gen_mnlogit(</span><span class="s2">90</span><span class="s1">)</span>
    <span class="s1">model = ConditionalMNLogit.from_formula(</span>
                <span class="s4">&quot;y ~ 0 + x1 + x2&quot;</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;g&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>

    <span class="s3"># Compare the gradients to numeric gradients</span>
    <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range(</span><span class="s2">5</span><span class="s1">):</span>
        <span class="s1">za = np.random.normal(size=</span><span class="s2">4</span><span class="s1">)</span>
        <span class="s1">grad = model.score(za)</span>
        <span class="s1">ngrad = approx_fprime(za</span><span class="s0">, </span><span class="s1">model.loglike)</span>
        <span class="s1">assert_allclose(grad</span><span class="s0">, </span><span class="s1">ngrad</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-3</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_conditional_mnlogit_2d():</span>

    <span class="s1">df = gen_mnlogit(</span><span class="s2">90</span><span class="s1">)</span>
    <span class="s1">model = ConditionalMNLogit.from_formula(</span>
                <span class="s4">&quot;y ~ 0 + x1 + x2&quot;</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;g&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
    <span class="s1">result = model.fit()</span>

    <span class="s3"># Regression tests</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">result.params</span><span class="s0">,</span>
        <span class="s1">np.asarray([[</span><span class="s2">0.75592035</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.58565494</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">1.82919869</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.32594231</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">result.bse</span><span class="s0">,</span>
        <span class="s1">np.asarray([[</span><span class="s2">0.68099698</span><span class="s0">, </span><span class="s2">0.70142727</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">0.65190315</span><span class="s0">, </span><span class="s2">0.59653771</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">atol=</span><span class="s2">1e-5</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_conditional_mnlogit_3d():</span>

    <span class="s1">df = gen_mnlogit(</span><span class="s2">90</span><span class="s1">)</span>
    <span class="s1">df[</span><span class="s4">&quot;x3&quot;</span><span class="s1">] = np.random.normal(size=df.shape[</span><span class="s2">0</span><span class="s1">])</span>
    <span class="s1">model = ConditionalMNLogit.from_formula(</span>
                <span class="s4">&quot;y ~ 0 + x1 + x2 + x3&quot;</span><span class="s0">, </span><span class="s1">groups=</span><span class="s4">&quot;g&quot;</span><span class="s0">, </span><span class="s1">data=df)</span>
    <span class="s1">result = model.fit()</span>

    <span class="s3"># Regression tests</span>
    <span class="s1">assert_allclose(</span>
        <span class="s1">result.params</span><span class="s0">,</span>
        <span class="s1">np.asarray([[ </span><span class="s2">0.729629</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.633673</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[ </span><span class="s2">1.879019</span><span class="s0">, </span><span class="s1">-</span><span class="s2">1.327163</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[-</span><span class="s2">0.114124</span><span class="s0">, </span><span class="s1">-</span><span class="s2">0.109378</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s1">assert_allclose(</span>
        <span class="s1">result.bse</span><span class="s0">,</span>
        <span class="s1">np.asarray([[</span><span class="s2">0.682965</span><span class="s0">, </span><span class="s2">0.60472</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">0.672947</span><span class="s0">, </span><span class="s2">0.42401</span><span class="s1">]</span><span class="s0">,</span>
                    <span class="s1">[</span><span class="s2">0.722631</span><span class="s0">, </span><span class="s2">0.33663</span><span class="s1">]])</span><span class="s0">,</span>
        <span class="s1">atol=</span><span class="s2">1e-5</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s2">1e-5</span><span class="s1">)</span>

    <span class="s3"># Smoke test</span>
    <span class="s1">result.summary()</span>
</pre>
</body>
</html>
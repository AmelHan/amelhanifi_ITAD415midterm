<html>
<head>
<title>test_splitting.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #6897bb;}
.s4 { color: #808080;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_splitting.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy.testing </span><span class="s0">import </span><span class="s1">assert_array_equal</span>

<span class="s0">from </span><span class="s1">sklearn.ensemble._hist_gradient_boosting.common </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">G_H_DTYPE</span><span class="s0">,</span>
    <span class="s1">HISTOGRAM_DTYPE</span><span class="s0">,</span>
    <span class="s1">X_BINNED_DTYPE</span><span class="s0">,</span>
    <span class="s1">MonotonicConstraint</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.ensemble._hist_gradient_boosting.histogram </span><span class="s0">import </span><span class="s1">HistogramBuilder</span>
<span class="s0">from </span><span class="s1">sklearn.ensemble._hist_gradient_boosting.splitting </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">Splitter</span><span class="s0">,</span>
    <span class="s1">compute_node_value</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils._openmp_helpers </span><span class="s0">import </span><span class="s1">_openmp_effective_n_threads</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">skip_if_32bit</span>

<span class="s1">n_threads = _openmp_effective_n_threads()</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;n_bins&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s3">3</span><span class="s0">, </span><span class="s3">32</span><span class="s0">, </span><span class="s3">256</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_histogram_split(n_bins):</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">feature_idx = </span><span class="s3">0</span>
    <span class="s1">l2_regularization = </span><span class="s3">0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>
    <span class="s1">X_binned = np.asfortranarray(</span>
        <span class="s1">rng.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_bins - </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=(int(</span><span class="s3">1e4</span><span class="s1">)</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE</span>
    <span class="s1">)</span>
    <span class="s1">binned_feature = X_binned.T[feature_idx]</span>
    <span class="s1">sample_indices = np.arange(binned_feature.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">ordered_hessians = np.ones_like(binned_feature</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">all_hessians = ordered_hessians</span>
    <span class="s1">sum_hessians = all_hessians.sum()</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">False</span>

    <span class="s0">for </span><span class="s1">true_bin </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">n_bins - </span><span class="s3">2</span><span class="s1">):</span>
        <span class="s0">for </span><span class="s1">sign </span><span class="s0">in </span><span class="s1">[-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">]:</span>
            <span class="s1">ordered_gradients = np.full_like(binned_feature</span><span class="s0">, </span><span class="s1">sign</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
            <span class="s1">ordered_gradients[binned_feature &lt;= true_bin] *= -</span><span class="s3">1</span>
            <span class="s1">all_gradients = ordered_gradients</span>
            <span class="s1">sum_gradients = all_gradients.sum()</span>

            <span class="s1">builder = HistogramBuilder(</span>
                <span class="s1">X_binned</span><span class="s0">,</span>
                <span class="s1">n_bins</span><span class="s0">,</span>
                <span class="s1">all_gradients</span><span class="s0">,</span>
                <span class="s1">all_hessians</span><span class="s0">,</span>
                <span class="s1">hessians_are_constant</span><span class="s0">,</span>
                <span class="s1">n_threads</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">n_bins_non_missing = np.array(</span>
                <span class="s1">[n_bins - </span><span class="s3">1</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32</span>
            <span class="s1">)</span>
            <span class="s1">has_missing_values = np.array([</span><span class="s0">False</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
            <span class="s1">monotonic_cst = np.array(</span>
                <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
            <span class="s1">)</span>
            <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
            <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
            <span class="s1">splitter = Splitter(</span>
                <span class="s1">X_binned</span><span class="s0">,</span>
                <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
                <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
                <span class="s1">has_missing_values</span><span class="s0">,</span>
                <span class="s1">is_categorical</span><span class="s0">,</span>
                <span class="s1">monotonic_cst</span><span class="s0">,</span>
                <span class="s1">l2_regularization</span><span class="s0">,</span>
                <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
                <span class="s1">min_samples_leaf</span><span class="s0">,</span>
                <span class="s1">min_gain_to_split</span><span class="s0">,</span>
                <span class="s1">hessians_are_constant</span><span class="s0">,</span>
            <span class="s1">)</span>

            <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
            <span class="s1">value = compute_node_value(</span>
                <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
            <span class="s1">)</span>
            <span class="s1">split_info = splitter.find_node_split(</span>
                <span class="s1">sample_indices.shape[</span><span class="s3">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
            <span class="s1">)</span>

            <span class="s0">assert </span><span class="s1">split_info.bin_idx == true_bin</span>
            <span class="s0">assert </span><span class="s1">split_info.gain &gt;= </span><span class="s3">0</span>
            <span class="s0">assert </span><span class="s1">split_info.feature_idx == feature_idx</span>
            <span class="s0">assert </span><span class="s1">(</span>
                <span class="s1">split_info.n_samples_left + split_info.n_samples_right</span>
                <span class="s1">== sample_indices.shape[</span><span class="s3">0</span><span class="s1">]</span>
            <span class="s1">)</span>
            <span class="s4"># Constant hessian: 1. per sample.</span>
            <span class="s0">assert </span><span class="s1">split_info.n_samples_left == split_info.sum_hessian_left</span>


<span class="s1">@skip_if_32bit</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s2">&quot;constant_hessian&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_gradient_and_hessian_sanity(constant_hessian):</span>
    <span class="s4"># This test checks that the values of gradients and hessians are</span>
    <span class="s4"># consistent in different places:</span>
    <span class="s4"># - in split_info: si.sum_gradient_left + si.sum_gradient_right must be</span>
    <span class="s4">#   equal to the gradient at the node. Same for hessians.</span>
    <span class="s4"># - in the histograms: summing 'sum_gradients' over the bins must be</span>
    <span class="s4">#   constant across all features, and those sums must be equal to the</span>
    <span class="s4">#   node's gradient. Same for hessians.</span>

    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>

    <span class="s1">n_bins = </span><span class="s3">10</span>
    <span class="s1">n_features = </span><span class="s3">20</span>
    <span class="s1">n_samples = </span><span class="s3">500</span>
    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s1">X_binned = rng.randint(</span>
        <span class="s3">0</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">size=(n_samples</span><span class="s0">, </span><span class="s1">n_features)</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE</span>
    <span class="s1">)</span>
    <span class="s1">X_binned = np.asfortranarray(X_binned)</span>
    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_gradients = rng.randn(n_samples).astype(G_H_DTYPE)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s0">if </span><span class="s1">constant_hessian:</span>
        <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
        <span class="s1">sum_hessians = </span><span class="s3">1 </span><span class="s1">* n_samples</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">all_hessians = rng.lognormal(size=n_samples).astype(G_H_DTYPE)</span>
        <span class="s1">sum_hessians = all_hessians.sum()</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">constant_hessian</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>
    <span class="s1">n_bins_non_missing = np.array([n_bins - </span><span class="s3">1</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">has_missing_values = np.array([</span><span class="s0">False</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">constant_hessian</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">hists_parent = builder.compute_histograms_brute(sample_indices)</span>
    <span class="s1">value_parent = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">si_parent = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">hists_parent</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value_parent</span>
    <span class="s1">)</span>
    <span class="s1">sample_indices_left</span><span class="s0">, </span><span class="s1">sample_indices_right</span><span class="s0">, </span><span class="s1">_ = splitter.split_indices(</span>
        <span class="s1">si_parent</span><span class="s0">, </span><span class="s1">sample_indices</span>
    <span class="s1">)</span>

    <span class="s1">hists_left = builder.compute_histograms_brute(sample_indices_left)</span>
    <span class="s1">value_left = compute_node_value(</span>
        <span class="s1">si_parent.sum_gradient_left</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_hessian_left</span><span class="s0">,</span>
        <span class="s1">-np.inf</span><span class="s0">,</span>
        <span class="s1">np.inf</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">hists_right = builder.compute_histograms_brute(sample_indices_right)</span>
    <span class="s1">value_right = compute_node_value(</span>
        <span class="s1">si_parent.sum_gradient_right</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_hessian_right</span><span class="s0">,</span>
        <span class="s1">-np.inf</span><span class="s0">,</span>
        <span class="s1">np.inf</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">si_left = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">,</span>
        <span class="s1">hists_left</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_gradient_left</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_hessian_left</span><span class="s0">,</span>
        <span class="s1">value_left</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s1">si_right = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">,</span>
        <span class="s1">hists_right</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_gradient_right</span><span class="s0">,</span>
        <span class="s1">si_parent.sum_hessian_right</span><span class="s0">,</span>
        <span class="s1">value_right</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s4"># make sure that si.sum_gradient_left + si.sum_gradient_right have their</span>
    <span class="s4"># expected value, same for hessians</span>
    <span class="s0">for </span><span class="s1">si</span><span class="s0">, </span><span class="s1">indices </span><span class="s0">in </span><span class="s1">(</span>
        <span class="s1">(si_parent</span><span class="s0">, </span><span class="s1">sample_indices)</span><span class="s0">,</span>
        <span class="s1">(si_left</span><span class="s0">, </span><span class="s1">sample_indices_left)</span><span class="s0">,</span>
        <span class="s1">(si_right</span><span class="s0">, </span><span class="s1">sample_indices_right)</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s1">gradient = si.sum_gradient_right + si.sum_gradient_left</span>
        <span class="s1">expected_gradient = all_gradients[indices].sum()</span>
        <span class="s1">hessian = si.sum_hessian_right + si.sum_hessian_left</span>
        <span class="s0">if </span><span class="s1">constant_hessian:</span>
            <span class="s1">expected_hessian = indices.shape[</span><span class="s3">0</span><span class="s1">] * all_hessians[</span><span class="s3">0</span><span class="s1">]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">expected_hessian = all_hessians[indices].sum()</span>

        <span class="s0">assert </span><span class="s1">np.isclose(gradient</span><span class="s0">, </span><span class="s1">expected_gradient)</span>
        <span class="s0">assert </span><span class="s1">np.isclose(hessian</span><span class="s0">, </span><span class="s1">expected_hessian)</span>

    <span class="s4"># make sure sum of gradients in histograms are the same for all features,</span>
    <span class="s4"># and make sure they're equal to their expected value</span>
    <span class="s1">hists_parent = np.asarray(hists_parent</span><span class="s0">, </span><span class="s1">dtype=HISTOGRAM_DTYPE)</span>
    <span class="s1">hists_left = np.asarray(hists_left</span><span class="s0">, </span><span class="s1">dtype=HISTOGRAM_DTYPE)</span>
    <span class="s1">hists_right = np.asarray(hists_right</span><span class="s0">, </span><span class="s1">dtype=HISTOGRAM_DTYPE)</span>
    <span class="s0">for </span><span class="s1">hists</span><span class="s0">, </span><span class="s1">indices </span><span class="s0">in </span><span class="s1">(</span>
        <span class="s1">(hists_parent</span><span class="s0">, </span><span class="s1">sample_indices)</span><span class="s0">,</span>
        <span class="s1">(hists_left</span><span class="s0">, </span><span class="s1">sample_indices_left)</span><span class="s0">,</span>
        <span class="s1">(hists_right</span><span class="s0">, </span><span class="s1">sample_indices_right)</span><span class="s0">,</span>
    <span class="s1">):</span>
        <span class="s4"># note: gradients and hessians have shape (n_features,),</span>
        <span class="s4"># we're comparing them to *scalars*. This has the benefit of also</span>
        <span class="s4"># making sure that all the entries are equal across features.</span>
        <span class="s1">gradients = hists[</span><span class="s2">&quot;sum_gradients&quot;</span><span class="s1">].sum(axis=</span><span class="s3">1</span><span class="s1">)  </span><span class="s4"># shape = (n_features,)</span>
        <span class="s1">expected_gradient = all_gradients[indices].sum()  </span><span class="s4"># scalar</span>
        <span class="s1">hessians = hists[</span><span class="s2">&quot;sum_hessians&quot;</span><span class="s1">].sum(axis=</span><span class="s3">1</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">constant_hessian:</span>
            <span class="s4"># 0 is not the actual hessian, but it's not computed in this case</span>
            <span class="s1">expected_hessian = </span><span class="s3">0.0</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">expected_hessian = all_hessians[indices].sum()</span>

        <span class="s0">assert </span><span class="s1">np.allclose(gradients</span><span class="s0">, </span><span class="s1">expected_gradient)</span>
        <span class="s0">assert </span><span class="s1">np.allclose(hessians</span><span class="s0">, </span><span class="s1">expected_hessian)</span>


<span class="s0">def </span><span class="s1">test_split_indices():</span>
    <span class="s4"># Check that split_indices returns the correct splits and that</span>
    <span class="s4"># splitter.partition is consistent with what is returned.</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">421</span><span class="s1">)</span>

    <span class="s1">n_bins = </span><span class="s3">5</span>
    <span class="s1">n_samples = </span><span class="s3">10</span>
    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s4"># split will happen on feature 1 and on bin 3</span>
    <span class="s1">X_binned = [</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span><span class="s0">,</span>
        <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">,</span>
    <span class="s1">]</span>
    <span class="s1">X_binned = np.asfortranarray(X_binned</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE)</span>
    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_gradients = rng.randn(n_samples).astype(G_H_DTYPE)</span>
    <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s1">sum_hessians = </span><span class="s3">1 </span><span class="s1">* n_samples</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">True</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">hessians_are_constant</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>
    <span class="s1">n_bins_non_missing = np.array([n_bins] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">has_missing_values = np.array([</span><span class="s0">False</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">hessians_are_constant</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">np.all(sample_indices == splitter.partition)</span>

    <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
    <span class="s1">value = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">si_root = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
    <span class="s1">)</span>

    <span class="s4"># sanity checks for best split</span>
    <span class="s0">assert </span><span class="s1">si_root.feature_idx == </span><span class="s3">1</span>
    <span class="s0">assert </span><span class="s1">si_root.bin_idx == </span><span class="s3">3</span>

    <span class="s1">samples_left</span><span class="s0">, </span><span class="s1">samples_right</span><span class="s0">, </span><span class="s1">position_right = splitter.split_indices(</span>
        <span class="s1">si_root</span><span class="s0">, </span><span class="s1">splitter.partition</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">set(samples_left) == set([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">8</span><span class="s1">])</span>
    <span class="s0">assert </span><span class="s1">set(samples_right) == set([</span><span class="s3">2</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">9</span><span class="s1">])</span>

    <span class="s0">assert </span><span class="s1">list(samples_left) == list(splitter.partition[:position_right])</span>
    <span class="s0">assert </span><span class="s1">list(samples_right) == list(splitter.partition[position_right:])</span>

    <span class="s4"># Check that the resulting split indices sizes are consistent with the</span>
    <span class="s4"># count statistics anticipated when looking for the best split.</span>
    <span class="s0">assert </span><span class="s1">samples_left.shape[</span><span class="s3">0</span><span class="s1">] == si_root.n_samples_left</span>
    <span class="s0">assert </span><span class="s1">samples_right.shape[</span><span class="s3">0</span><span class="s1">] == si_root.n_samples_right</span>


<span class="s0">def </span><span class="s1">test_min_gain_to_split():</span>
    <span class="s4"># Try to split a pure node (all gradients are equal, same for hessians)</span>
    <span class="s4"># with min_gain_to_split = 0 and make sure that the node is not split (best</span>
    <span class="s4"># possible gain = -1). Note: before the strict inequality comparison, this</span>
    <span class="s4"># test would fail because the node would be split with a gain of 0.</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">l2_regularization = </span><span class="s3">0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">0</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>
    <span class="s1">n_bins = </span><span class="s3">255</span>
    <span class="s1">n_samples = </span><span class="s3">100</span>
    <span class="s1">X_binned = np.asfortranarray(</span>
        <span class="s1">rng.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">size=(n_samples</span><span class="s0">, </span><span class="s3">1</span><span class="s1">))</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE</span>
    <span class="s1">)</span>
    <span class="s1">binned_feature = X_binned[:</span><span class="s0">, </span><span class="s3">0</span><span class="s1">]</span>
    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_hessians = np.ones_like(binned_feature</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">all_gradients = np.ones_like(binned_feature</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s1">sum_hessians = all_hessians.sum()</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">False</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">hessians_are_constant</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>
    <span class="s1">n_bins_non_missing = np.array([n_bins - </span><span class="s3">1</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">has_missing_values = np.array([</span><span class="s0">False</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">hessians_are_constant</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
    <span class="s1">value = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">split_info = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
    <span class="s1">)</span>
    <span class="s0">assert </span><span class="s1">split_info.gain == -</span><span class="s3">1</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s1">(</span>
        <span class="s2">&quot;X_binned, all_gradients, has_missing_values, n_bins_non_missing, &quot;</span>
        <span class="s2">&quot; expected_split_on_nan, expected_bin_idx, expected_go_to_left&quot;</span>
    <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s4"># basic sanity check with no missing values: given the gradient</span>
        <span class="s4"># values, the split must occur on bin_idx=3</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">9</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># gradients</span>
            <span class="s0">False,  </span><span class="s4"># no missing values</span>
            <span class="s3">10</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">False,  </span><span class="s4"># don't split on nans</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># expected_bin_idx</span>
            <span class="s2">&quot;not_applicable&quot;</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s4"># We replace 2 samples by NaNs (bin_idx=8)</span>
        <span class="s4"># These 2 samples were mapped to the left node before, so they should</span>
        <span class="s4"># be mapped to left node again</span>
        <span class="s4"># Notice how the bin_idx threshold changes from 3 to 1.</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">8</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 8 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">8</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">False,  </span><span class="s4"># don't split on nans</span>
            <span class="s3">1</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=1</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to left</span>
        <span class="s4"># same as above, but with non-consecutive missing_values_bin</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">9</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 9 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">8</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">False,  </span><span class="s4"># don't split on nans</span>
            <span class="s3">1</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=1</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to left</span>
        <span class="s4"># this time replacing 2 samples that were on the right.</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 8 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">8</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">False,  </span><span class="s4"># don't split on nans</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=3 (like in first case)</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
        <span class="s4"># same as above, but with non-consecutive missing_values_bin</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 9 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">8</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">False,  </span><span class="s4"># don't split on nans</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=3 (like in first case)</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
        <span class="s4"># For the following cases, split_on_nans is True (we replace all of</span>
        <span class="s4"># the samples with nans, instead of just 2).</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">4</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 4 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">True,  </span><span class="s4"># split on nans</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=3</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
        <span class="s4"># same as above, but with non-consecutive missing_values_bin</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 9 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">True,  </span><span class="s4"># split on nans</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=3</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">6</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 6 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">6</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">True,  </span><span class="s4"># split on nans</span>
            <span class="s3">5</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=5</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
        <span class="s4"># same as above, but with non-consecutive missing_values_bin</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># 9 &lt;=&gt; missing</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">]</span><span class="s0">,</span>
            <span class="s0">True,  </span><span class="s4"># missing values</span>
            <span class="s3">6</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s0">True,  </span><span class="s4"># split on nans</span>
            <span class="s3">5</span><span class="s0">,  </span><span class="s4"># cut on bin_idx=5</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># missing values go to right</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_splitting_missing_values(</span>
    <span class="s1">X_binned</span><span class="s0">,</span>
    <span class="s1">all_gradients</span><span class="s0">,</span>
    <span class="s1">has_missing_values</span><span class="s0">,</span>
    <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
    <span class="s1">expected_split_on_nan</span><span class="s0">,</span>
    <span class="s1">expected_bin_idx</span><span class="s0">,</span>
    <span class="s1">expected_go_to_left</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s4"># Make sure missing values are properly supported.</span>
    <span class="s4"># we build an artificial example with gradients such that the best split</span>
    <span class="s4"># is on bin_idx=3, when there are no missing values.</span>
    <span class="s4"># Then we introduce missing values and:</span>
    <span class="s4">#   - make sure the chosen bin is correct (find_best_bin()): it's</span>
    <span class="s4">#     still the same split, even though the index of the bin may change</span>
    <span class="s4">#   - make sure the missing values are mapped to the correct child</span>
    <span class="s4">#     (split_indices())</span>

    <span class="s1">n_bins = max(X_binned) + </span><span class="s3">1</span>
    <span class="s1">n_samples = len(X_binned)</span>
    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">X_binned = np.array(X_binned</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE).reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">X_binned = np.asfortranarray(X_binned)</span>
    <span class="s1">all_gradients = np.array(all_gradients</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">has_missing_values = np.array([has_missing_values]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s1">sum_hessians = </span><span class="s3">1 </span><span class="s1">* n_samples</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">True</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">hessians_are_constant</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>

    <span class="s1">n_bins_non_missing = np.array([n_bins_non_missing]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">hessians_are_constant</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
    <span class="s1">value = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">split_info = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">split_info.bin_idx == expected_bin_idx</span>
    <span class="s0">if </span><span class="s1">has_missing_values:</span>
        <span class="s0">assert </span><span class="s1">split_info.missing_go_to_left == expected_go_to_left</span>

    <span class="s1">split_on_nan = split_info.bin_idx == n_bins_non_missing[</span><span class="s3">0</span><span class="s1">] - </span><span class="s3">1</span>
    <span class="s0">assert </span><span class="s1">split_on_nan == expected_split_on_nan</span>

    <span class="s4"># Make sure the split is properly computed.</span>
    <span class="s4"># This also make sure missing values are properly assigned to the correct</span>
    <span class="s4"># child in split_indices()</span>
    <span class="s1">samples_left</span><span class="s0">, </span><span class="s1">samples_right</span><span class="s0">, </span><span class="s1">_ = splitter.split_indices(</span>
        <span class="s1">split_info</span><span class="s0">, </span><span class="s1">splitter.partition</span>
    <span class="s1">)</span>

    <span class="s0">if not </span><span class="s1">expected_split_on_nan:</span>
        <span class="s4"># When we don't split on nans, the split should always be the same.</span>
        <span class="s0">assert </span><span class="s1">set(samples_left) == set([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">])</span>
        <span class="s0">assert </span><span class="s1">set(samples_right) == set([</span><span class="s3">4</span><span class="s0">, </span><span class="s3">5</span><span class="s0">, </span><span class="s3">6</span><span class="s0">, </span><span class="s3">7</span><span class="s0">, </span><span class="s3">8</span><span class="s0">, </span><span class="s3">9</span><span class="s1">])</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s4"># When we split on nans, samples with missing values are always mapped</span>
        <span class="s4"># to the right child.</span>
        <span class="s1">missing_samples_indices = np.flatnonzero(</span>
            <span class="s1">np.array(X_binned) == missing_values_bin_idx</span>
        <span class="s1">)</span>
        <span class="s1">non_missing_samples_indices = np.flatnonzero(</span>
            <span class="s1">np.array(X_binned) != missing_values_bin_idx</span>
        <span class="s1">)</span>

        <span class="s0">assert </span><span class="s1">set(samples_right) == set(missing_samples_indices)</span>
        <span class="s0">assert </span><span class="s1">set(samples_left) == set(non_missing_samples_indices)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s2">&quot;X_binned, has_missing_values, n_bins_non_missing, &quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s4"># one category</span>
        <span class="s1">([</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">20</span><span class="s0">, False, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s4"># all categories appear less than MIN_CAT_SUPPORT (hardcoded to 10)</span>
        <span class="s1">([</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">9 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">8</span><span class="s0">, False, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s4"># only one category appears more than MIN_CAT_SUPPORT</span>
        <span class="s1">([</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">12 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">8</span><span class="s0">, False, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s4"># missing values + category appear less than MIN_CAT_SUPPORT</span>
        <span class="s4"># 9 is missing</span>
        <span class="s1">([</span><span class="s3">0</span><span class="s1">] * </span><span class="s3">9 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">8 </span><span class="s1">+ [</span><span class="s3">9</span><span class="s1">] * </span><span class="s3">4</span><span class="s0">, True, </span><span class="s3">2</span><span class="s1">)</span><span class="s0">,</span>
        <span class="s4"># no non-missing category</span>
        <span class="s1">([</span><span class="s3">9</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">, True, </span><span class="s3">0</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_splitting_categorical_cat_smooth(</span>
    <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">has_missing_values</span><span class="s0">, </span><span class="s1">n_bins_non_missing</span>
<span class="s1">):</span>
    <span class="s4"># Checks categorical splits are correct when the MIN_CAT_SUPPORT constraint</span>
    <span class="s4"># isn't respected: there are no splits</span>

    <span class="s1">n_bins = max(X_binned) + </span><span class="s3">1</span>
    <span class="s1">n_samples = len(X_binned)</span>
    <span class="s1">X_binned = np.array([X_binned]</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE).T</span>
    <span class="s1">X_binned = np.asfortranarray(X_binned)</span>

    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_gradients = np.ones(n_samples</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">has_missing_values = np.array([has_missing_values]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s1">sum_hessians = n_samples</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">True</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">hessians_are_constant</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>

    <span class="s1">n_bins_non_missing = np.array([n_bins_non_missing]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.ones_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>

    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">hessians_are_constant</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
    <span class="s1">value = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">split_info = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
    <span class="s1">)</span>

    <span class="s4"># no split found</span>
    <span class="s0">assert </span><span class="s1">split_info.gain == -</span><span class="s3">1</span>


<span class="s0">def </span><span class="s1">_assert_categories_equals_bitset(categories</span><span class="s0">, </span><span class="s1">bitset):</span>
    <span class="s4"># assert that the bitset exactly corresponds to the categories</span>
    <span class="s4"># bitset is assumed to be an array of 8 uint32 elements</span>

    <span class="s4"># form bitset from threshold</span>
    <span class="s1">expected_bitset = np.zeros(</span><span class="s3">8</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s0">for </span><span class="s1">cat </span><span class="s0">in </span><span class="s1">categories:</span>
        <span class="s1">idx = cat // </span><span class="s3">32</span>
        <span class="s1">shift = cat % </span><span class="s3">32</span>
        <span class="s1">expected_bitset[idx] |= </span><span class="s3">1 </span><span class="s1">&lt;&lt; shift</span>

    <span class="s4"># check for equality</span>
    <span class="s1">assert_array_equal(expected_bitset</span><span class="s0">, </span><span class="s1">bitset)</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s1">(</span>
        <span class="s2">&quot;X_binned, all_gradients, expected_categories_left, n_bins_non_missing,&quot;</span>
        <span class="s2">&quot;missing_values_bin_idx, has_missing_values, expected_missing_go_to_left&quot;</span>
    <span class="s1">)</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s4"># 4 categories</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">False,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">None,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left, unchecked</span>
        <span class="s4"># Make sure that the categories that are on the right (second half) of</span>
        <span class="s4"># the sorted categories array can still go in the left child. In this</span>
        <span class="s4"># case, the best split was found when scanning from right to left.</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">3</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">False,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">None,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left, unchecked</span>
        <span class="s4"># categories that don't respect MIN_CAT_SUPPORT (cat 4) are always</span>
        <span class="s4"># mapped to the right child</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">4</span><span class="s1">] * </span><span class="s3">5</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">10</span><span class="s1">] * </span><span class="s3">5</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">3</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">False,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">None,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left, unchecked</span>
        <span class="s4"># categories that don't respect MIN_CAT_SUPPORT are always mapped to</span>
        <span class="s4"># the right child: in this case a more sensible split could have been</span>
        <span class="s4"># 3, 4 - 0, 1, 2</span>
        <span class="s4"># But the split is still 3 - 0, 1, 2, 4. this is because we only scan</span>
        <span class="s4"># up to the middle of the sorted category array (0, 1, 2, 3), and</span>
        <span class="s4"># because we exclude cat 4 in this array.</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">4</span><span class="s1">] * </span><span class="s3">5</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">5</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">3</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">4</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">False,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">None,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left, unchecked</span>
        <span class="s4"># 4 categories with missing values that go to the right</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">9</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">10</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">9</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">True,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">False,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left</span>
        <span class="s4"># 4 categories with missing values that go to the left</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">9</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">11</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">1</span><span class="s0">, </span><span class="s3">9</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">3</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">9</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">True,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left</span>
        <span class="s4"># split is on the missing value</span>
        <span class="s1">(</span>
            <span class="s1">[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s0">, </span><span class="s3">3</span><span class="s0">, </span><span class="s3">4</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">255</span><span class="s1">] * </span><span class="s3">12</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s1">] * </span><span class="s3">11 </span><span class="s1">+ [</span><span class="s3">1</span><span class="s1">] * </span><span class="s3">12</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">[</span><span class="s3">255</span><span class="s1">]</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">5</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">255</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">True,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left</span>
        <span class="s4"># split on even categories</span>
        <span class="s1">(</span>
            <span class="s1">list(range(</span><span class="s3">60</span><span class="s1">)) * </span><span class="s3">12</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] * </span><span class="s3">360</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">list(range(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">60</span><span class="s0">, </span><span class="s3">2</span><span class="s1">))</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">59</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">59</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">True,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left</span>
        <span class="s4"># split on every 8 categories</span>
        <span class="s1">(</span>
            <span class="s1">list(range(</span><span class="s3">256</span><span class="s1">)) * </span><span class="s3">12</span><span class="s0">,  </span><span class="s4"># X_binned</span>
            <span class="s1">[</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] * </span><span class="s3">384</span><span class="s0">,  </span><span class="s4"># all_gradients</span>
            <span class="s1">list(range(</span><span class="s3">7</span><span class="s0">, </span><span class="s3">256</span><span class="s0">, </span><span class="s3">8</span><span class="s1">))</span><span class="s0">,  </span><span class="s4"># expected_categories_left</span>
            <span class="s3">255</span><span class="s0">,  </span><span class="s4"># n_bins_non_missing</span>
            <span class="s3">255</span><span class="s0">,  </span><span class="s4"># missing_values_bin_idx</span>
            <span class="s0">True,  </span><span class="s4"># has_missing_values</span>
            <span class="s0">True,</span>
        <span class="s1">)</span><span class="s0">,  </span><span class="s4"># expected_missing_go_to_left</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_splitting_categorical_sanity(</span>
    <span class="s1">X_binned</span><span class="s0">,</span>
    <span class="s1">all_gradients</span><span class="s0">,</span>
    <span class="s1">expected_categories_left</span><span class="s0">,</span>
    <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
    <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
    <span class="s1">has_missing_values</span><span class="s0">,</span>
    <span class="s1">expected_missing_go_to_left</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s4"># Tests various combinations of categorical splits</span>

    <span class="s1">n_samples = len(X_binned)</span>
    <span class="s1">n_bins = max(X_binned) + </span><span class="s3">1</span>

    <span class="s1">X_binned = np.array(X_binned</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE).reshape(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>
    <span class="s1">X_binned = np.asfortranarray(X_binned)</span>

    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_gradients = np.array(all_gradients</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">has_missing_values = np.array([has_missing_values]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
    <span class="s1">sum_gradients = all_gradients.sum()</span>
    <span class="s1">sum_hessians = n_samples</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">True</span>

    <span class="s1">builder = HistogramBuilder(</span>
        <span class="s1">X_binned</span><span class="s0">, </span><span class="s1">n_bins</span><span class="s0">, </span><span class="s1">all_gradients</span><span class="s0">, </span><span class="s1">all_hessians</span><span class="s0">, </span><span class="s1">hessians_are_constant</span><span class="s0">, </span><span class="s1">n_threads</span>
    <span class="s1">)</span>

    <span class="s1">n_bins_non_missing = np.array([n_bins_non_missing]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">monotonic_cst = np.array(</span>
        <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
    <span class="s1">)</span>
    <span class="s1">is_categorical = np.ones_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>

    <span class="s1">splitter = Splitter(</span>
        <span class="s1">X_binned</span><span class="s0">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
        <span class="s1">has_missing_values</span><span class="s0">,</span>
        <span class="s1">is_categorical</span><span class="s0">,</span>
        <span class="s1">monotonic_cst</span><span class="s0">,</span>
        <span class="s1">l2_regularization</span><span class="s0">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
        <span class="s1">min_samples_leaf</span><span class="s0">,</span>
        <span class="s1">min_gain_to_split</span><span class="s0">,</span>
        <span class="s1">hessians_are_constant</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>

    <span class="s1">value = compute_node_value(</span>
        <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
    <span class="s1">)</span>
    <span class="s1">split_info = splitter.find_node_split(</span>
        <span class="s1">n_samples</span><span class="s0">, </span><span class="s1">histograms</span><span class="s0">, </span><span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">value</span>
    <span class="s1">)</span>

    <span class="s0">assert </span><span class="s1">split_info.is_categorical</span>
    <span class="s0">assert </span><span class="s1">split_info.gain &gt; </span><span class="s3">0</span>
    <span class="s1">_assert_categories_equals_bitset(</span>
        <span class="s1">expected_categories_left</span><span class="s0">, </span><span class="s1">split_info.left_cat_bitset</span>
    <span class="s1">)</span>
    <span class="s0">if </span><span class="s1">has_missing_values:</span>
        <span class="s0">assert </span><span class="s1">split_info.missing_go_to_left == expected_missing_go_to_left</span>
    <span class="s4"># If there is no missing value during training, the flag missing_go_to_left</span>
    <span class="s4"># is set later in the grower.</span>

    <span class="s4"># make sure samples are split correctly</span>
    <span class="s1">samples_left</span><span class="s0">, </span><span class="s1">samples_right</span><span class="s0">, </span><span class="s1">_ = splitter.split_indices(</span>
        <span class="s1">split_info</span><span class="s0">, </span><span class="s1">splitter.partition</span>
    <span class="s1">)</span>

    <span class="s1">left_mask = np.isin(X_binned.ravel()</span><span class="s0">, </span><span class="s1">expected_categories_left)</span>
    <span class="s1">assert_array_equal(sample_indices[left_mask]</span><span class="s0">, </span><span class="s1">samples_left)</span>
    <span class="s1">assert_array_equal(sample_indices[~left_mask]</span><span class="s0">, </span><span class="s1">samples_right)</span>


<span class="s0">def </span><span class="s1">test_split_interaction_constraints():</span>
    <span class="s5">&quot;&quot;&quot;Check that allowed_features are respected.&quot;&quot;&quot;</span>
    <span class="s1">n_features = </span><span class="s3">4</span>
    <span class="s4"># features 1 and 2 are not allowed to be split on</span>
    <span class="s1">allowed_features = np.array([</span><span class="s3">0</span><span class="s0">, </span><span class="s3">3</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">n_bins = </span><span class="s3">5</span>
    <span class="s1">n_samples = </span><span class="s3">10</span>
    <span class="s1">l2_regularization = </span><span class="s3">0.0</span>
    <span class="s1">min_hessian_to_split = </span><span class="s3">1e-3</span>
    <span class="s1">min_samples_leaf = </span><span class="s3">1</span>
    <span class="s1">min_gain_to_split = </span><span class="s3">0.0</span>

    <span class="s1">sample_indices = np.arange(n_samples</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
    <span class="s1">all_hessians = np.ones(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">dtype=G_H_DTYPE)</span>
    <span class="s1">sum_hessians = n_samples</span>
    <span class="s1">hessians_are_constant = </span><span class="s0">True</span>

    <span class="s1">split_features = []</span>

    <span class="s4"># The loop is to ensure that we split at least once on each allowed feature (0, 3).</span>
    <span class="s4"># This is tracked by split_features and checked at the end.</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(</span><span class="s3">10</span><span class="s1">):</span>
        <span class="s1">rng = np.random.RandomState(</span><span class="s3">919 </span><span class="s1">+ i)</span>
        <span class="s1">X_binned = np.asfortranarray(</span>
            <span class="s1">rng.randint(</span><span class="s3">0</span><span class="s0">, </span><span class="s1">n_bins - </span><span class="s3">1</span><span class="s0">, </span><span class="s1">size=(n_samples</span><span class="s0">, </span><span class="s1">n_features))</span><span class="s0">,</span>
            <span class="s1">dtype=X_BINNED_DTYPE</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">X_binned = np.asfortranarray(X_binned</span><span class="s0">, </span><span class="s1">dtype=X_BINNED_DTYPE)</span>

        <span class="s4"># Make feature 1 very important</span>
        <span class="s1">all_gradients = (</span><span class="s3">10 </span><span class="s1">* X_binned[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">] + rng.randn(n_samples)).astype(G_H_DTYPE)</span>
        <span class="s1">sum_gradients = all_gradients.sum()</span>

        <span class="s1">builder = HistogramBuilder(</span>
            <span class="s1">X_binned</span><span class="s0">,</span>
            <span class="s1">n_bins</span><span class="s0">,</span>
            <span class="s1">all_gradients</span><span class="s0">,</span>
            <span class="s1">all_hessians</span><span class="s0">,</span>
            <span class="s1">hessians_are_constant</span><span class="s0">,</span>
            <span class="s1">n_threads</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">n_bins_non_missing = np.array([n_bins] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint32)</span>
        <span class="s1">has_missing_values = np.array([</span><span class="s0">False</span><span class="s1">] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
        <span class="s1">monotonic_cst = np.array(</span>
            <span class="s1">[MonotonicConstraint.NO_CST] * X_binned.shape[</span><span class="s3">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">dtype=np.int8</span>
        <span class="s1">)</span>
        <span class="s1">is_categorical = np.zeros_like(monotonic_cst</span><span class="s0">, </span><span class="s1">dtype=np.uint8)</span>
        <span class="s1">missing_values_bin_idx = n_bins - </span><span class="s3">1</span>
        <span class="s1">splitter = Splitter(</span>
            <span class="s1">X_binned</span><span class="s0">,</span>
            <span class="s1">n_bins_non_missing</span><span class="s0">,</span>
            <span class="s1">missing_values_bin_idx</span><span class="s0">,</span>
            <span class="s1">has_missing_values</span><span class="s0">,</span>
            <span class="s1">is_categorical</span><span class="s0">,</span>
            <span class="s1">monotonic_cst</span><span class="s0">,</span>
            <span class="s1">l2_regularization</span><span class="s0">,</span>
            <span class="s1">min_hessian_to_split</span><span class="s0">,</span>
            <span class="s1">min_samples_leaf</span><span class="s0">,</span>
            <span class="s1">min_gain_to_split</span><span class="s0">,</span>
            <span class="s1">hessians_are_constant</span><span class="s0">,</span>
        <span class="s1">)</span>

        <span class="s0">assert </span><span class="s1">np.all(sample_indices == splitter.partition)</span>

        <span class="s1">histograms = builder.compute_histograms_brute(sample_indices)</span>
        <span class="s1">value = compute_node_value(</span>
            <span class="s1">sum_gradients</span><span class="s0">, </span><span class="s1">sum_hessians</span><span class="s0">, </span><span class="s1">-np.inf</span><span class="s0">, </span><span class="s1">np.inf</span><span class="s0">, </span><span class="s1">l2_regularization</span>
        <span class="s1">)</span>

        <span class="s4"># with all features allowed, feature 1 should be split on as it is the most</span>
        <span class="s4"># important one by construction of the gradients</span>
        <span class="s1">si_root = splitter.find_node_split(</span>
            <span class="s1">n_samples</span><span class="s0">,</span>
            <span class="s1">histograms</span><span class="s0">,</span>
            <span class="s1">sum_gradients</span><span class="s0">,</span>
            <span class="s1">sum_hessians</span><span class="s0">,</span>
            <span class="s1">value</span><span class="s0">,</span>
            <span class="s1">allowed_features=</span><span class="s0">None,</span>
        <span class="s1">)</span>
        <span class="s0">assert </span><span class="s1">si_root.feature_idx == </span><span class="s3">1</span>

        <span class="s4"># only features 0 and 3 are allowed to be split on</span>
        <span class="s1">si_root = splitter.find_node_split(</span>
            <span class="s1">n_samples</span><span class="s0">,</span>
            <span class="s1">histograms</span><span class="s0">,</span>
            <span class="s1">sum_gradients</span><span class="s0">,</span>
            <span class="s1">sum_hessians</span><span class="s0">,</span>
            <span class="s1">value</span><span class="s0">,</span>
            <span class="s1">allowed_features=allowed_features</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">split_features.append(si_root.feature_idx)</span>
        <span class="s0">assert </span><span class="s1">si_root.feature_idx </span><span class="s0">in </span><span class="s1">allowed_features</span>

    <span class="s4"># make sure feature 0 and feature 3 are split on in the constraint setting</span>
    <span class="s0">assert </span><span class="s1">set(allowed_features) == set(split_features)</span>
</pre>
</body>
</html>
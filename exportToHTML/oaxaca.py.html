<html>
<head>
<title>oaxaca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
oaxaca.py</font>
</center></td></tr></table>
<pre><span class="s0"># TODO Non-Linear Regressions can be used</span>
<span class="s0"># TODO Further decomposition of the two_fold parameters i.e.</span>
<span class="s0"># the delta method for further two_fold detail</span>
<span class="s2">&quot;&quot;&quot; 
Author: Austin Adams 
 
This class implements Oaxaca-Blinder Decomposition. It returns 
a OaxacaResults Class: 
 
OaxacaBlinder: 
Two-Fold (two_fold) 
Three-Fold (three_fold) 
 
OaxacaResults: 
Table Summary (summary) 
 
Oaxaca-Blinder is a statistical method that is used to explain 
the differences between two mean values. The idea is to show 
from two mean values what can be explained by the data and 
what cannot by using OLS regression frameworks. 
 
&quot;The original use by Oaxaca's was to explain the wage 
differential between two different groups of workers, 
but the method has since been applied to numerous other 
topics.&quot; (Wikipedia) 
 
The model is designed to accept two endogenous response variables 
and two exogenous explanitory variables. They are then fit using 
the specific type of decomposition that you want. 
 
The method was famously used in Card and Krueger's paper 
&quot;School Quality and Black-White Relative Earnings: A Direct Assessment&quot; (1992) 
 
General reference for Oaxaca-Blinder: 
 
B. Jann &quot;The Blinder-Oaxaca decomposition for linear 
regression models,&quot; The Stata Journal, 2008. 
 
Econometrics references for regression models: 
 
E. M. Kitagawa  &quot;Components of a Difference Between Two Rates&quot; 
Journal of the American Statistical Association, 1955. 
 
A. S. Blinder &quot;Wage Discrimination: Reduced Form and Structural 
Estimates,&quot; The Journal of Human Resources, 1973. 
&quot;&quot;&quot;</span>
<span class="s3">from </span><span class="s1">textwrap </span><span class="s3">import </span><span class="s1">dedent</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.tools </span><span class="s3">import </span><span class="s1">add_constant</span>


<span class="s3">class </span><span class="s1">OaxacaBlinder:</span>
    <span class="s2">&quot;&quot;&quot; 
    Class to perform Oaxaca-Blinder Decomposition. 
 
    Parameters 
    ---------- 
    endog : array_like 
        The endogenous variable or the dependent variable that you are trying 
        to explain. 
    exog : array_like 
        The exogenous variable(s) or the independent variable(s) that you are 
        using to explain the endogenous variable. 
    bifurcate : {int, str} 
        The column of the exogenous variable(s) on which to split. This would 
        generally be the group that you wish to explain the two means for. 
        Int of the column for a NumPy array or int/string for the name of 
        the column in Pandas. 
    hasconst : bool, optional 
        Indicates whether the two exogenous variables include a user-supplied 
        constant. If True, a constant is assumed. If False, a constant is added 
        at the start. If nothing is supplied, then True is assumed. 
    swap : bool, optional 
        Imitates the STATA Oaxaca command by allowing users to choose to swap 
        groups. Unlike STATA, this is assumed to be True instead of False 
    cov_type : str, optional 
        See regression.linear_model.RegressionResults for a description of the 
        available covariance estimators 
    cov_kwds : dict, optional 
        See linear_model.RegressionResults.get_robustcov_results for a 
        description required keywords for alternative covariance estimators 
 
    Notes 
    ----- 
    Please check if your data includes at constant. This will still run, but 
    will return incorrect values if set incorrectly. 
 
    You can access the models by using their code as an attribute, e.g., 
    _t_model for the total model, _f_model for the first model, _s_model for 
    the second model. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; data = sm.datasets.ccards.load() 
 
    '3' is the column of which we want to explain or which indicates 
    the two groups. In this case, it is if you rent. 
 
    &gt;&gt;&gt; model = sm.OaxacaBlinder(df.endog, df.exog, 3, hasconst = False) 
    &gt;&gt;&gt; model.two_fold().summary() 
    Oaxaca-Blinder Two-fold Effects 
    Unexplained Effect: 27.94091 
    Explained Effect: 130.80954 
    Gap: 158.75044 
 
    &gt;&gt;&gt; model.three_fold().summary() 
    Oaxaca-Blinder Three-fold Effects 
    Endowments Effect: 321.74824 
    Coefficient Effect: 75.45371 
    Interaction Effect: -238.45151 
    Gap: 158.75044 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">endog</span><span class="s3">,</span>
        <span class="s1">exog</span><span class="s3">,</span>
        <span class="s1">bifurcate</span><span class="s3">,</span>
        <span class="s1">hasconst=</span><span class="s3">True,</span>
        <span class="s1">swap=</span><span class="s3">True,</span>
        <span class="s1">cov_type=</span><span class="s4">&quot;nonrobust&quot;</span><span class="s3">,</span>
        <span class="s1">cov_kwds=</span><span class="s3">None,</span>
    <span class="s1">):</span>
        <span class="s3">if </span><span class="s1">str(type(exog)).find(</span><span class="s4">&quot;pandas&quot;</span><span class="s1">) != -</span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">bifurcate = exog.columns.get_loc(bifurcate)</span>
            <span class="s1">endog</span><span class="s3">, </span><span class="s1">exog = np.array(endog)</span><span class="s3">, </span><span class="s1">np.array(exog)</span>

        <span class="s1">self.two_fold_type = </span><span class="s3">None</span>
        <span class="s1">self.bifurcate = bifurcate</span>
        <span class="s1">self.cov_type = cov_type</span>
        <span class="s1">self.cov_kwds = cov_kwds</span>
        <span class="s1">self.neumark = np.delete(exog</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">self.exog = exog</span>
        <span class="s1">self.hasconst = hasconst</span>
        <span class="s1">bi_col = exog[:</span><span class="s3">, </span><span class="s1">bifurcate]</span>
        <span class="s1">endog = np.column_stack((bi_col</span><span class="s3">, </span><span class="s1">endog))</span>
        <span class="s1">bi = np.unique(bi_col)</span>
        <span class="s1">self.bi_col = bi_col</span>

        <span class="s0"># split the data along the bifurcate axis, the issue is you need to</span>
        <span class="s0"># delete it after you fit the model for the total model.</span>
        <span class="s1">exog_f = exog[np.where(exog[:</span><span class="s3">, </span><span class="s1">bifurcate] == bi[</span><span class="s5">0</span><span class="s1">])]</span>
        <span class="s1">exog_s = exog[np.where(exog[:</span><span class="s3">, </span><span class="s1">bifurcate] == bi[</span><span class="s5">1</span><span class="s1">])]</span>
        <span class="s1">endog_f = endog[np.where(endog[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">] == bi[</span><span class="s5">0</span><span class="s1">])]</span>
        <span class="s1">endog_s = endog[np.where(endog[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">] == bi[</span><span class="s5">1</span><span class="s1">])]</span>
        <span class="s1">exog_f = np.delete(exog_f</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">exog_s = np.delete(exog_s</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">endog_f = endog_f[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">endog_s = endog_s[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">self.endog = endog[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">self.len_f</span><span class="s3">, </span><span class="s1">self.len_s = len(endog_f)</span><span class="s3">, </span><span class="s1">len(endog_s)</span>
        <span class="s1">self.gap = endog_f.mean() - endog_s.mean()</span>

        <span class="s3">if </span><span class="s1">swap </span><span class="s3">and </span><span class="s1">self.gap &lt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">endog_f</span><span class="s3">, </span><span class="s1">endog_s = endog_s</span><span class="s3">, </span><span class="s1">endog_f</span>
            <span class="s1">exog_f</span><span class="s3">, </span><span class="s1">exog_s = exog_s</span><span class="s3">, </span><span class="s1">exog_f</span>
            <span class="s1">self.gap = endog_f.mean() - endog_s.mean()</span>
            <span class="s1">bi[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">, </span><span class="s1">bi[</span><span class="s5">1</span><span class="s1">] = bi[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">bi[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">self.bi = bi</span>

        <span class="s3">if </span><span class="s1">hasconst </span><span class="s3">is False</span><span class="s1">:</span>
            <span class="s1">exog_f = add_constant(exog_f</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">exog_s = add_constant(exog_s</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">self.exog = add_constant(self.exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
            <span class="s1">self.neumark = add_constant(self.neumark</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>

        <span class="s1">self.exog_f_mean = np.mean(exog_f</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">self.exog_s_mean = np.mean(exog_s</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

        <span class="s1">self._f_model = OLS(endog_f</span><span class="s3">, </span><span class="s1">exog_f).fit(</span>
            <span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span>
        <span class="s1">)</span>
        <span class="s1">self._s_model = OLS(endog_s</span><span class="s3">, </span><span class="s1">exog_s).fit(</span>
            <span class="s1">cov_type=cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=cov_kwds</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">variance(self</span><span class="s3">, </span><span class="s1">decomp_type</span><span class="s3">, </span><span class="s1">n=</span><span class="s5">5000</span><span class="s3">, </span><span class="s1">conf=</span><span class="s5">0.99</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        A helper function to calculate the variance/std. Used to keep 
        the decomposition functions cleaner 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self.submitted_n </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">n = self.submitted_n</span>
        <span class="s3">if </span><span class="s1">self.submitted_conf </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">conf = self.submitted_conf</span>
        <span class="s3">if </span><span class="s1">self.submitted_weight </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">submitted_weight = [</span>
                <span class="s1">self.submitted_weight</span><span class="s3">,</span>
                <span class="s5">1 </span><span class="s1">- self.submitted_weight</span><span class="s3">,</span>
            <span class="s1">]</span>
        <span class="s1">bi = self.bi</span>
        <span class="s1">bifurcate = self.bifurcate</span>
        <span class="s1">endow_eff_list = []</span>
        <span class="s1">coef_eff_list = []</span>
        <span class="s1">int_eff_list = []</span>
        <span class="s1">exp_eff_list = []</span>
        <span class="s1">unexp_eff_list = []</span>
        <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range(</span><span class="s5">0</span><span class="s3">, </span><span class="s1">n):</span>
            <span class="s1">endog = np.column_stack((self.bi_col</span><span class="s3">, </span><span class="s1">self.endog))</span>
            <span class="s1">exog = self.exog</span>
            <span class="s1">amount = len(endog)</span>

            <span class="s1">samples = np.random.randint(</span><span class="s5">0</span><span class="s3">, </span><span class="s1">high=amount</span><span class="s3">, </span><span class="s1">size=amount)</span>
            <span class="s1">endog = endog[samples]</span>
            <span class="s1">exog = exog[samples]</span>
            <span class="s1">neumark = np.delete(exog</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">exog_f = exog[np.where(exog[:</span><span class="s3">, </span><span class="s1">bifurcate] == bi[</span><span class="s5">0</span><span class="s1">])]</span>
            <span class="s1">exog_s = exog[np.where(exog[:</span><span class="s3">, </span><span class="s1">bifurcate] == bi[</span><span class="s5">1</span><span class="s1">])]</span>
            <span class="s1">endog_f = endog[np.where(endog[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">] == bi[</span><span class="s5">0</span><span class="s1">])]</span>
            <span class="s1">endog_s = endog[np.where(endog[:</span><span class="s3">, </span><span class="s5">0</span><span class="s1">] == bi[</span><span class="s5">1</span><span class="s1">])]</span>
            <span class="s1">exog_f = np.delete(exog_f</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">exog_s = np.delete(exog_s</span><span class="s3">, </span><span class="s1">bifurcate</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">endog_f = endog_f[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">endog_s = endog_s[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>
            <span class="s1">endog = endog[:</span><span class="s3">, </span><span class="s5">1</span><span class="s1">]</span>

            <span class="s1">two_fold_type = self.two_fold_type</span>

            <span class="s3">if </span><span class="s1">self.hasconst </span><span class="s3">is False</span><span class="s1">:</span>
                <span class="s1">exog_f = add_constant(exog_f</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
                <span class="s1">exog_s = add_constant(exog_s</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
                <span class="s1">exog = add_constant(exog</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>
                <span class="s1">neumark = add_constant(neumark</span><span class="s3">, </span><span class="s1">prepend=</span><span class="s3">False</span><span class="s1">)</span>

            <span class="s1">_f_model = OLS(endog_f</span><span class="s3">, </span><span class="s1">exog_f).fit(</span>
                <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
            <span class="s1">)</span>
            <span class="s1">_s_model = OLS(endog_s</span><span class="s3">, </span><span class="s1">exog_s).fit(</span>
                <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
            <span class="s1">)</span>
            <span class="s1">exog_f_mean = np.mean(exog_f</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s1">exog_s_mean = np.mean(exog_s</span><span class="s3">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

            <span class="s3">if </span><span class="s1">decomp_type == </span><span class="s5">3</span><span class="s1">:</span>
                <span class="s1">endow_eff = (exog_f_mean - exog_s_mean) @ _s_model.params</span>
                <span class="s1">coef_eff = exog_s_mean @ (_f_model.params - _s_model.params)</span>
                <span class="s1">int_eff = (exog_f_mean - exog_s_mean) @ (</span>
                    <span class="s1">_f_model.params - _s_model.params</span>
                <span class="s1">)</span>

                <span class="s1">endow_eff_list.append(endow_eff)</span>
                <span class="s1">coef_eff_list.append(coef_eff)</span>
                <span class="s1">int_eff_list.append(int_eff)</span>

            <span class="s3">elif </span><span class="s1">decomp_type == </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s1">len_f = len(exog_f)</span>
                <span class="s1">len_s = len(exog_s)</span>

                <span class="s3">if </span><span class="s1">two_fold_type == </span><span class="s4">&quot;cotton&quot;</span><span class="s1">:</span>
                    <span class="s1">t_params = (len_f / (len_f + len_s) * _f_model.params) + (</span>
                        <span class="s1">len_s / (len_f + len_s) * _s_model.params</span>
                    <span class="s1">)</span>

                <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;reimers&quot;</span><span class="s1">:</span>
                    <span class="s1">t_params = </span><span class="s5">0.5 </span><span class="s1">* (_f_model.params + _s_model.params)</span>

                <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;self_submitted&quot;</span><span class="s1">:</span>
                    <span class="s1">t_params = (</span>
                        <span class="s1">submitted_weight[</span><span class="s5">0</span><span class="s1">] * _f_model.params</span>
                        <span class="s1">+ submitted_weight[</span><span class="s5">1</span><span class="s1">] * _s_model.params</span>
                    <span class="s1">)</span>

                <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;nuemark&quot;</span><span class="s1">:</span>
                    <span class="s1">_t_model = OLS(endog</span><span class="s3">, </span><span class="s1">neumark).fit(</span>
                        <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
                    <span class="s1">)</span>
                    <span class="s1">t_params = _t_model.params</span>

                <span class="s3">else</span><span class="s1">:</span>
                    <span class="s1">_t_model = OLS(endog</span><span class="s3">, </span><span class="s1">exog).fit(</span>
                        <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
                    <span class="s1">)</span>
                    <span class="s1">t_params = np.delete(_t_model.params</span><span class="s3">, </span><span class="s1">bifurcate)</span>

                <span class="s1">unexplained = (exog_f_mean @ (_f_model.params - t_params)) + (</span>
                    <span class="s1">exog_s_mean @ (t_params - _s_model.params)</span>
                <span class="s1">)</span>

                <span class="s1">explained = (exog_f_mean - exog_s_mean) @ t_params</span>

                <span class="s1">unexp_eff_list.append(unexplained)</span>
                <span class="s1">exp_eff_list.append(explained)</span>

        <span class="s1">high</span><span class="s3">, </span><span class="s1">low = int(n * conf)</span><span class="s3">, </span><span class="s1">int(n * (</span><span class="s5">1 </span><span class="s1">- conf))</span>
        <span class="s3">if </span><span class="s1">decomp_type == </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">[</span>
                <span class="s1">np.std(np.sort(endow_eff_list)[low:high])</span><span class="s3">,</span>
                <span class="s1">np.std(np.sort(coef_eff_list)[low:high])</span><span class="s3">,</span>
                <span class="s1">np.std(np.sort(int_eff_list)[low:high])</span><span class="s3">,</span>
            <span class="s1">]</span>
        <span class="s3">elif </span><span class="s1">decomp_type == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s3">return </span><span class="s1">[</span>
                <span class="s1">np.std(np.sort(unexp_eff_list)[low:high])</span><span class="s3">,</span>
                <span class="s1">np.std(np.sort(exp_eff_list)[low:high])</span><span class="s3">,</span>
            <span class="s1">]</span>

    <span class="s3">def </span><span class="s1">three_fold(self</span><span class="s3">, </span><span class="s1">std=</span><span class="s3">False, </span><span class="s1">n=</span><span class="s3">None, </span><span class="s1">conf=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Calculates the three-fold Oaxaca Blinder Decompositions 
 
        Parameters 
        ---------- 
        std: boolean, optional 
            If true, bootstrapped standard errors will be calculated. 
        n: int, optional 
            A amount of iterations to calculate the bootstrapped 
            standard errors. This defaults to 5000. 
        conf: float, optional 
            This is the confidence required for the standard error 
            calculation. Defaults to .99, but could be anything less 
            than or equal to one. One is heavy discouraged, due to the 
            extreme outliers inflating the variance. 
 
        Returns 
        ------- 
        OaxacaResults 
            A results container for the three-fold decomposition. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.submitted_n = n</span>
        <span class="s1">self.submitted_conf = conf</span>
        <span class="s1">self.submitted_weight = </span><span class="s3">None</span>
        <span class="s1">std_val = </span><span class="s3">None</span>
        <span class="s1">self.endow_eff = (</span>
            <span class="s1">self.exog_f_mean - self.exog_s_mean</span>
        <span class="s1">) @ self._s_model.params</span>
        <span class="s1">self.coef_eff = self.exog_s_mean @ (</span>
            <span class="s1">self._f_model.params - self._s_model.params</span>
        <span class="s1">)</span>
        <span class="s1">self.int_eff = (self.exog_f_mean - self.exog_s_mean) @ (</span>
            <span class="s1">self._f_model.params - self._s_model.params</span>
        <span class="s1">)</span>

        <span class="s3">if </span><span class="s1">std </span><span class="s3">is True</span><span class="s1">:</span>
            <span class="s1">std_val = self.variance(</span><span class="s5">3</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">OaxacaResults(</span>
            <span class="s1">(self.endow_eff</span><span class="s3">, </span><span class="s1">self.coef_eff</span><span class="s3">, </span><span class="s1">self.int_eff</span><span class="s3">, </span><span class="s1">self.gap)</span><span class="s3">,</span>
            <span class="s5">3</span><span class="s3">,</span>
            <span class="s1">std_val=std_val</span><span class="s3">,</span>
        <span class="s1">)</span>

    <span class="s3">def </span><span class="s1">two_fold(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">std=</span><span class="s3">False,</span>
        <span class="s1">two_fold_type=</span><span class="s4">&quot;pooled&quot;</span><span class="s3">,</span>
        <span class="s1">submitted_weight=</span><span class="s3">None,</span>
        <span class="s1">n=</span><span class="s3">None,</span>
        <span class="s1">conf=</span><span class="s3">None,</span>
    <span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Calculates the two-fold or pooled Oaxaca Blinder Decompositions 
 
        Methods 
        ------- 
        std: boolean, optional 
            If true, bootstrapped standard errors will be calculated. 
 
        two_fold_type: string, optional 
            This method allows for the specific calculation of the 
            non-discriminatory model. There are four different types 
            available at this time. pooled, cotton, reimers, self_submitted. 
            Pooled is assumed and if a non-viable parameter is given, 
            pooled will be ran. 
 
            pooled - This type assumes that the pooled model's parameters 
            (a normal regression) is the non-discriminatory model. 
            This includes the indicator variable. This is generally 
            the best idea. If you have economic justification for 
            using others, then use others. 
 
            nuemark - This is similar to the pooled type, but the regression 
            is not done including the indicator variable. 
 
            cotton - This type uses the adjusted in Cotton (1988), which 
            accounts for the undervaluation of one group causing the 
            overevalution of another. It uses the sample size weights for 
            a linear combination of the two model parameters 
 
            reimers - This type uses a linear combination of the two 
            models with both parameters being 50% of the 
            non-discriminatory model. 
 
            self_submitted - This allows the user to submit their 
            own weights. Please be sure to put the weight of the larger mean 
            group only. This should be submitted in the 
            submitted_weights variable. 
 
        submitted_weight: int/float, required only for self_submitted, 
            This is the submitted weight for the larger mean. If the 
            weight for the larger mean is p, then the weight for the 
            other mean is 1-p. Only submit the first value. 
 
        n: int, optional 
            A amount of iterations to calculate the bootstrapped 
            standard errors. This defaults to 5000. 
        conf: float, optional 
            This is the confidence required for the standard error 
            calculation. Defaults to .99, but could be anything less 
            than or equal to one. One is heavy discouraged, due to the 
            extreme outliers inflating the variance. 
 
        Returns 
        ------- 
        OaxacaResults 
            A results container for the two-fold decomposition. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.submitted_n = n</span>
        <span class="s1">self.submitted_conf = conf</span>
        <span class="s1">std_val = </span><span class="s3">None</span>
        <span class="s1">self.two_fold_type = two_fold_type</span>
        <span class="s1">self.submitted_weight = submitted_weight</span>

        <span class="s3">if </span><span class="s1">two_fold_type == </span><span class="s4">&quot;cotton&quot;</span><span class="s1">:</span>
            <span class="s1">self.t_params = (</span>
                <span class="s1">self.len_f / (self.len_f + self.len_s) * self._f_model.params</span>
            <span class="s1">) + (self.len_s / (self.len_f + self.len_s) * self._s_model.params)</span>

        <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;reimers&quot;</span><span class="s1">:</span>
            <span class="s1">self.t_params = </span><span class="s5">0.5 </span><span class="s1">* (self._f_model.params + self._s_model.params)</span>

        <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;self_submitted&quot;</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">submitted_weight </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Please submit weights&quot;</span><span class="s1">)</span>
            <span class="s1">submitted_weight = [submitted_weight</span><span class="s3">, </span><span class="s5">1 </span><span class="s1">- submitted_weight]</span>
            <span class="s1">self.t_params = (</span>
                <span class="s1">submitted_weight[</span><span class="s5">0</span><span class="s1">] * self._f_model.params</span>
                <span class="s1">+ submitted_weight[</span><span class="s5">1</span><span class="s1">] * self._s_model.params</span>
            <span class="s1">)</span>

        <span class="s3">elif </span><span class="s1">two_fold_type == </span><span class="s4">&quot;nuemark&quot;</span><span class="s1">:</span>
            <span class="s1">self._t_model = OLS(self.endog</span><span class="s3">, </span><span class="s1">self.neumark).fit(</span>
                <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
            <span class="s1">)</span>
            <span class="s1">self.t_params = self._t_model.params</span>

        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self._t_model = OLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog).fit(</span>
                <span class="s1">cov_type=self.cov_type</span><span class="s3">, </span><span class="s1">cov_kwds=self.cov_kwds</span>
            <span class="s1">)</span>
            <span class="s1">self.t_params = np.delete(self._t_model.params</span><span class="s3">, </span><span class="s1">self.bifurcate)</span>

        <span class="s1">self.unexplained = (</span>
            <span class="s1">self.exog_f_mean @ (self._f_model.params - self.t_params)</span>
        <span class="s1">) + (self.exog_s_mean @ (self.t_params - self._s_model.params))</span>
        <span class="s1">self.explained = (self.exog_f_mean - self.exog_s_mean) @ self.t_params</span>

        <span class="s3">if </span><span class="s1">std </span><span class="s3">is True</span><span class="s1">:</span>
            <span class="s1">std_val = self.variance(</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s3">return </span><span class="s1">OaxacaResults(</span>
            <span class="s1">(self.unexplained</span><span class="s3">, </span><span class="s1">self.explained</span><span class="s3">, </span><span class="s1">self.gap)</span><span class="s3">, </span><span class="s5">2</span><span class="s3">, </span><span class="s1">std_val=std_val</span>
        <span class="s1">)</span>


<span class="s3">class </span><span class="s1">OaxacaResults:</span>
    <span class="s2">&quot;&quot;&quot; 
    This class summarizes the fit of the OaxacaBlinder model. 
 
    Use .summary() to get a table of the fitted values or 
    use .params to receive a list of the values 
    use .std to receive a list of the standard errors 
 
    If a two-fold model was fitted, this will return 
    unexplained effect, explained effect, and the 
    mean gap. The list will always be of the following order 
    and type. If standard error was asked for, then standard error 
    calculations will also be included for each variable after each 
    calculated effect. 
 
    unexplained : float 
        This is the effect that cannot be explained by the data at hand. 
        This does not mean it cannot be explained with more. 
    explained : float 
        This is the effect that can be explained using the data. 
    gap : float 
        This is the gap in the mean differences of the two groups. 
 
    If a three-fold model was fitted, this will 
    return characteristic effect, coefficient effect 
    interaction effect, and the mean gap. The list will 
    be of the following order and type. If standard error was asked 
    for, then standard error calculations will also be included for 
    each variable after each calculated effect. 
 
    endowment effect : float 
        This is the effect due to the group differences in 
        predictors 
    coefficient effect : float 
        This is the effect due to differences of the coefficients 
        of the two groups 
    interaction effect : float 
        This is the effect due to differences in both effects 
        existing at the same time between the two groups. 
    gap : float 
        This is the gap in the mean differences of the two groups. 
 
    Attributes 
    ---------- 
    params 
        A list of all values for the fitted models. 
    std 
        A list of standard error calculations. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">results</span><span class="s3">, </span><span class="s1">model_type</span><span class="s3">, </span><span class="s1">std_val=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.params = results</span>
        <span class="s1">self.std = std_val</span>
        <span class="s1">self.model_type = model_type</span>

    <span class="s3">def </span><span class="s1">summary(self):</span>
        <span class="s2">&quot;&quot;&quot; 
        Print a summary table with the Oaxaca-Blinder effects 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self.model_type == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">self.std </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">print(</span>
                    <span class="s1">dedent(</span>
                        <span class="s4">f&quot;&quot;&quot;</span><span class="s3">\ 
                </span><span class="s4">Oaxaca-Blinder Two-fold Effects</span>
                <span class="s4">Unexplained Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Explained Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Gap: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span><span class="s4">&quot;&quot;&quot;</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">print(</span>
                    <span class="s1">dedent(</span>
                        <span class="s4">&quot;&quot;&quot;</span><span class="s3">\ 
                </span><span class="s4">Oaxaca-Blinder Two-fold Effects 
                Unexplained Effect: {:.5f} 
                Unexplained Standard Error: {:.5f} 
                Explained Effect: {:.5f} 
                Explained Standard Error: {:.5f} 
                Gap: {:.5f}&quot;&quot;&quot;</span><span class="s1">.format(</span>
                            <span class="s1">self.params[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">,</span>
                            <span class="s1">self.std[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">,</span>
                            <span class="s1">self.params[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">,</span>
                            <span class="s1">self.std[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">,</span>
                            <span class="s1">self.params[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">,</span>
                        <span class="s1">)</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>
        <span class="s3">if </span><span class="s1">self.model_type == </span><span class="s5">3</span><span class="s1">:</span>
            <span class="s3">if </span><span class="s1">self.std </span><span class="s3">is None</span><span class="s1">:</span>
                <span class="s1">print(</span>
                    <span class="s1">dedent(</span>
                        <span class="s4">f&quot;&quot;&quot;</span><span class="s3">\ 
                </span><span class="s4">Oaxaca-Blinder Three-fold Effects</span>
                <span class="s4">Endowment Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Coefficient Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Interaction Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Gap: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">3</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span><span class="s4">&quot;&quot;&quot;</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>
            <span class="s3">else</span><span class="s1">:</span>
                <span class="s1">print(</span>
                    <span class="s1">dedent(</span>
                        <span class="s4">f&quot;&quot;&quot;</span><span class="s3">\ 
                </span><span class="s4">Oaxaca-Blinder Three-fold Effects</span>
                <span class="s4">Endowment Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Endowment Standard Error: </span><span class="s3">{</span><span class="s1">self.std[</span><span class="s5">0</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Coefficient Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Coefficient Standard Error: </span><span class="s3">{</span><span class="s1">self.std[</span><span class="s5">1</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Interaction Effect: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Interaction Standard Error: </span><span class="s3">{</span><span class="s1">self.std[</span><span class="s5">2</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span>
                <span class="s4">Gap: </span><span class="s3">{</span><span class="s1">self.params[</span><span class="s5">3</span><span class="s1">]</span><span class="s3">:</span><span class="s4">.5f</span><span class="s3">}</span><span class="s4">&quot;&quot;&quot;</span>
                    <span class="s1">)</span>
                <span class="s1">)</span>
</pre>
</body>
</html>
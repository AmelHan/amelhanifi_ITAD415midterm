<html>
<head>
<title>test_mlemodel.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_mlemodel.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for the generic MLEModel 
 
Author: Chad Fulton 
License: Simplified-BSD 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">re</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace </span><span class="s2">import </span><span class="s1">(sarimax</span><span class="s2">, </span><span class="s1">varmax</span><span class="s2">, </span><span class="s1">kalman_filter</span><span class="s2">,</span>
                                        <span class="s1">kalman_smoother)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.mlemodel </span><span class="s2">import </span><span class="s1">MLEModel</span><span class="s2">, </span><span class="s1">MLEResultsWrapper</span>
<span class="s2">from </span><span class="s1">statsmodels.datasets </span><span class="s2">import </span><span class="s1">nile</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">assert_</span><span class="s2">, </span><span class="s1">assert_almost_equal</span><span class="s2">, </span><span class="s1">assert_equal</span><span class="s2">, </span><span class="s1">assert_allclose</span><span class="s2">, </span><span class="s1">assert_raises)</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.tests.results </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">results_sarimax</span><span class="s2">, </span><span class="s1">results_var_misc)</span>

<span class="s1">current_path = os.path.dirname(os.path.abspath(__file__))</span>

<span class="s3"># Basic kwargs</span>
<span class="s1">kwargs = {</span>
    <span class="s4">'k_states'</span><span class="s1">: </span><span class="s5">1</span><span class="s2">, </span><span class="s4">'design'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'transition'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
    <span class="s4">'selection'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'state_cov'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
    <span class="s4">'initialization'</span><span class="s1">: </span><span class="s4">'approximate_diffuse'</span>
<span class="s1">}</span>


<span class="s2">def </span><span class="s1">get_dummy_mod(fit=</span><span class="s2">True, </span><span class="s1">pandas=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s3"># This tests time-varying parameters regression when in fact the parameters</span>
    <span class="s3"># are not time-varying, and in fact the regression fit is perfect</span>
    <span class="s1">endog = np.arange(</span><span class="s5">100</span><span class="s1">)*</span><span class="s5">1.0</span>
    <span class="s1">exog = </span><span class="s5">2</span><span class="s1">*endog</span>

    <span class="s2">if </span><span class="s1">pandas:</span>
        <span class="s1">index = pd.date_range(</span><span class="s4">'1960-01-01'</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'MS'</span><span class="s1">)</span>
        <span class="s1">endog = pd.Series(endog</span><span class="s2">, </span><span class="s1">index=index)</span>
        <span class="s1">exog = pd.Series(exog</span><span class="s2">, </span><span class="s1">index=index)</span>

    <span class="s1">mod = sarimax.SARIMAX(</span>
        <span class="s1">endog</span><span class="s2">, </span><span class="s1">exog=exog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">time_varying_regression=</span><span class="s2">True, </span><span class="s1">mle_regression=</span><span class="s2">False,</span>
        <span class="s1">use_exact_diffuse=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">fit:</span>
        <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
            <span class="s1">res = mod.fit(disp=-</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">res = </span><span class="s2">None</span>

    <span class="s2">return </span><span class="s1">mod</span><span class="s2">, </span><span class="s1">res</span>


<span class="s2">def </span><span class="s1">test_init_matrices_time_invariant():</span>
    <span class="s3"># Test setting state space system matrices in __init__, with time-invariant</span>
    <span class="s3"># matrices</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">k_states = </span><span class="s5">3</span>
    <span class="s1">k_posdef = </span><span class="s5">1</span>

    <span class="s1">endog = np.zeros((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">obs_intercept = np.arange(k_endog) * </span><span class="s5">1.0</span>
    <span class="s1">design = np.reshape(</span>
        <span class="s1">np.arange(k_endog * k_states) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_states))</span>
    <span class="s1">obs_cov = np.reshape(np.arange(k_endog**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_endog))</span>
    <span class="s1">state_intercept = np.arange(k_states) * </span><span class="s5">1.0</span>
    <span class="s1">transition = np.reshape(np.arange(k_states**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_states))</span>
    <span class="s1">selection = np.reshape(</span>
        <span class="s1">np.arange(k_states * k_posdef) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_posdef))</span>
    <span class="s1">state_cov = np.reshape(np.arange(k_posdef**</span><span class="s5">2</span><span class="s1">) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_posdef</span><span class="s2">, </span><span class="s1">k_posdef))</span>

    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">k_posdef=k_posdef</span><span class="s2">,</span>
                   <span class="s1">obs_intercept=obs_intercept</span><span class="s2">, </span><span class="s1">design=design</span><span class="s2">,</span>
                   <span class="s1">obs_cov=obs_cov</span><span class="s2">, </span><span class="s1">state_intercept=state_intercept</span><span class="s2">,</span>
                   <span class="s1">transition=transition</span><span class="s2">, </span><span class="s1">selection=selection</span><span class="s2">,</span>
                   <span class="s1">state_cov=state_cov)</span>

    <span class="s1">assert_allclose(mod[</span><span class="s4">'obs_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'design'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">design)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'obs_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_cov)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'state_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'transition'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transition)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'selection'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">selection)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'state_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_cov)</span>


<span class="s2">def </span><span class="s1">test_init_matrices_time_varying():</span>
    <span class="s3"># Test setting state space system matrices in __init__, with time-varying</span>
    <span class="s3"># matrices</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">k_endog = </span><span class="s5">2</span>
    <span class="s1">k_states = </span><span class="s5">3</span>
    <span class="s1">k_posdef = </span><span class="s5">1</span>

    <span class="s1">endog = np.zeros((</span><span class="s5">10</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s1">obs_intercept = np.reshape(np.arange(k_endog * nobs) * </span><span class="s5">1.0</span><span class="s2">,</span>
                               <span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">design = np.reshape(</span>
        <span class="s1">np.arange(k_endog * k_states * nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">obs_cov = np.reshape(</span>
        <span class="s1">np.arange(k_endog**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">k_endog</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">state_intercept = np.reshape(</span>
        <span class="s1">np.arange(k_states * nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">transition = np.reshape(</span>
        <span class="s1">np.arange(k_states**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_states</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">selection = np.reshape(</span>
        <span class="s1">np.arange(k_states * k_posdef * nobs) * </span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">(k_states</span><span class="s2">, </span><span class="s1">k_posdef</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">state_cov = np.reshape(</span>
        <span class="s1">np.arange(k_posdef**</span><span class="s5">2 </span><span class="s1">* nobs) * </span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">(k_posdef</span><span class="s2">, </span><span class="s1">k_posdef</span><span class="s2">, </span><span class="s1">nobs))</span>

    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">k_states=k_states</span><span class="s2">, </span><span class="s1">k_posdef=k_posdef</span><span class="s2">,</span>
                   <span class="s1">obs_intercept=obs_intercept</span><span class="s2">, </span><span class="s1">design=design</span><span class="s2">,</span>
                   <span class="s1">obs_cov=obs_cov</span><span class="s2">, </span><span class="s1">state_intercept=state_intercept</span><span class="s2">,</span>
                   <span class="s1">transition=transition</span><span class="s2">, </span><span class="s1">selection=selection</span><span class="s2">,</span>
                   <span class="s1">state_cov=state_cov)</span>

    <span class="s1">assert_allclose(mod[</span><span class="s4">'obs_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'design'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">design)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'obs_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">obs_cov)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'state_intercept'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_intercept)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'transition'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transition)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'selection'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">selection)</span>
    <span class="s1">assert_allclose(mod[</span><span class="s4">'state_cov'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">state_cov)</span>


<span class="s2">def </span><span class="s1">test_wrapping():</span>
    <span class="s3"># Test the wrapping of various Representation / KalmanFilter /</span>
    <span class="s3"># KalmanSmoother methods / attributes</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">_ = get_dummy_mod(fit=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s3"># Test that we can get the design matrix</span>
    <span class="s1">assert_equal(mod[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">2.0 </span><span class="s1">* np.arange(</span><span class="s5">100</span><span class="s1">))</span>

    <span class="s3"># Test that we can set individual elements of the design matrix</span>
    <span class="s1">mod[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">:] = </span><span class="s5">2</span>
    <span class="s1">assert_equal(mod.ssm[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">:]</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm[</span><span class="s4">'design'</span><span class="s1">].shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">100</span><span class="s1">))</span>

    <span class="s3"># Test that we can set the entire design matrix</span>
    <span class="s1">mod[</span><span class="s4">'design'</span><span class="s1">] = [[</span><span class="s5">3.</span><span class="s1">]]</span>
    <span class="s1">assert_equal(mod.ssm[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">3.</span><span class="s1">)</span>
    <span class="s3"># (Now it's no longer time-varying, so only 2-dim)</span>
    <span class="s1">assert_equal(mod.ssm[</span><span class="s4">'design'</span><span class="s1">].shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>

    <span class="s3"># Test that we can change the following properties: loglikelihood_burn,</span>
    <span class="s3"># initial_variance, tolerance</span>
    <span class="s1">assert_equal(mod.loglikelihood_burn</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">mod.loglikelihood_burn = </span><span class="s5">1</span>
    <span class="s1">assert_equal(mod.ssm.loglikelihood_burn</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">assert_equal(mod.tolerance</span><span class="s2">, </span><span class="s1">mod.ssm.tolerance)</span>
    <span class="s1">mod.tolerance = </span><span class="s5">0.123</span>
    <span class="s1">assert_equal(mod.ssm.tolerance</span><span class="s2">, </span><span class="s5">0.123</span><span class="s1">)</span>

    <span class="s1">assert_equal(mod.initial_variance</span><span class="s2">, </span><span class="s5">1e10</span><span class="s1">)</span>
    <span class="s1">mod.initial_variance = </span><span class="s5">1e12</span>
    <span class="s1">assert_equal(mod.ssm.initial_variance</span><span class="s2">, </span><span class="s5">1e12</span><span class="s1">)</span>

    <span class="s3"># Test that we can use the following wrappers: initialization,</span>
    <span class="s3"># initialize_known, initialize_stationary, initialize_approximate_diffuse</span>

    <span class="s3"># Initialization starts off as none</span>
    <span class="s1">assert_equal(isinstance(mod.initialization</span><span class="s2">, </span><span class="s1">object)</span><span class="s2">, True</span><span class="s1">)</span>

    <span class="s3"># Since the SARIMAX model may be fully stationary or may have diffuse</span>
    <span class="s3"># elements, it uses a custom initialization by default, but it can be</span>
    <span class="s3"># overridden by users</span>
    <span class="s1">mod.initialize_default()  </span><span class="s3"># no-op here</span>

    <span class="s1">mod.initialize_approximate_diffuse(</span><span class="s5">1e5</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.initialization.initialization_type</span><span class="s2">, </span><span class="s4">'approximate_diffuse'</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.initialization.approximate_diffuse_variance</span><span class="s2">, </span><span class="s5">1e5</span><span class="s1">)</span>

    <span class="s1">mod.initialize_known([</span><span class="s5">5.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[[</span><span class="s5">40</span><span class="s1">]])</span>
    <span class="s1">assert_equal(mod.initialization.initialization_type</span><span class="s2">, </span><span class="s4">'known'</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.initialization.constant</span><span class="s2">, </span><span class="s1">[</span><span class="s5">5.</span><span class="s1">])</span>
    <span class="s1">assert_equal(mod.initialization.stationary_cov</span><span class="s2">, </span><span class="s1">[[</span><span class="s5">40</span><span class="s1">]])</span>

    <span class="s1">mod.initialize_stationary()</span>
    <span class="s1">assert_equal(mod.initialization.initialization_type</span><span class="s2">, </span><span class="s4">'stationary'</span><span class="s1">)</span>

    <span class="s3"># Test that we can use the following wrapper methods: set_filter_method,</span>
    <span class="s3"># set_stability_method, set_conserve_memory, set_smoother_output</span>

    <span class="s3"># The defaults are as follows:</span>
    <span class="s1">assert_equal(mod.ssm.filter_method</span><span class="s2">, </span><span class="s1">kalman_filter.FILTER_CONVENTIONAL)</span>
    <span class="s1">assert_equal(</span>
        <span class="s1">mod.ssm.stability_method</span><span class="s2">,</span>
        <span class="s1">kalman_filter.STABILITY_FORCE_SYMMETRY)</span>
    <span class="s1">assert_equal(mod.ssm.conserve_memory</span><span class="s2">, </span><span class="s1">kalman_filter.MEMORY_STORE_ALL)</span>
    <span class="s1">assert_equal(mod.ssm.smoother_output</span><span class="s2">, </span><span class="s1">kalman_smoother.SMOOTHER_ALL)</span>

    <span class="s3"># Now, create the Cython filter object and assert that they have</span>
    <span class="s3"># transferred correctly</span>
    <span class="s1">mod.ssm._initialize_filter()</span>
    <span class="s1">kf = mod.ssm._kalman_filter</span>
    <span class="s1">assert_equal(kf.filter_method</span><span class="s2">, </span><span class="s1">kalman_filter.FILTER_CONVENTIONAL)</span>
    <span class="s1">assert_equal(kf.stability_method</span><span class="s2">, </span><span class="s1">kalman_filter.STABILITY_FORCE_SYMMETRY)</span>
    <span class="s1">assert_equal(kf.conserve_memory</span><span class="s2">, </span><span class="s1">kalman_filter.MEMORY_STORE_ALL)</span>
    <span class="s3"># (the smoother object is so far not in Cython, so there is no</span>
    <span class="s3"># transferring)</span>

    <span class="s3"># Change the attributes in the model class</span>
    <span class="s1">mod.set_filter_method(</span><span class="s5">100</span><span class="s1">)</span>
    <span class="s1">mod.set_stability_method(</span><span class="s5">101</span><span class="s1">)</span>
    <span class="s1">mod.set_conserve_memory(</span><span class="s5">102</span><span class="s1">)</span>
    <span class="s1">mod.set_smoother_output(</span><span class="s5">103</span><span class="s1">)</span>

    <span class="s3"># Assert that the changes have occurred in the ssm class</span>
    <span class="s1">assert_equal(mod.ssm.filter_method</span><span class="s2">, </span><span class="s5">100</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm.stability_method</span><span class="s2">, </span><span class="s5">101</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm.conserve_memory</span><span class="s2">, </span><span class="s5">102</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm.smoother_output</span><span class="s2">, </span><span class="s5">103</span><span class="s1">)</span>

    <span class="s3"># Assert that the changes have *not yet* occurred in the filter object</span>
    <span class="s1">assert_equal(kf.filter_method</span><span class="s2">, </span><span class="s1">kalman_filter.FILTER_CONVENTIONAL)</span>
    <span class="s1">assert_equal(kf.stability_method</span><span class="s2">, </span><span class="s1">kalman_filter.STABILITY_FORCE_SYMMETRY)</span>
    <span class="s1">assert_equal(kf.conserve_memory</span><span class="s2">, </span><span class="s1">kalman_filter.MEMORY_STORE_ALL)</span>

    <span class="s3"># Now, test the setting of the other two methods by resetting the</span>
    <span class="s3"># filter method to a valid value</span>
    <span class="s1">mod.set_filter_method(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">mod.ssm._initialize_filter()</span>
    <span class="s3"># Retrieve the new kalman filter object (a new object had to be created</span>
    <span class="s3"># due to the changing filter method)</span>
    <span class="s1">kf = mod.ssm._kalman_filter</span>

    <span class="s1">assert_equal(kf.filter_method</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(kf.stability_method</span><span class="s2">, </span><span class="s5">101</span><span class="s1">)</span>
    <span class="s1">assert_equal(kf.conserve_memory</span><span class="s2">, </span><span class="s5">102</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_fit_misc():</span>
    <span class="s1">true = results_sarimax.wpi1_stationary</span>
    <span class="s1">endog = np.diff(true[</span><span class="s4">'data'</span><span class="s1">])[</span><span class="s5">1</span><span class="s1">:]</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">trend=</span><span class="s4">'c'</span><span class="s1">)</span>

    <span class="s3"># Test optim_hessian={'opg','oim','approx'}</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
        <span class="s1">res1 = mod.fit(method=</span><span class="s4">'ncg'</span><span class="s2">, </span><span class="s1">disp=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">optim_hessian=</span><span class="s4">'opg'</span><span class="s2">,</span>
                       <span class="s1">optim_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">res2 = mod.fit(method=</span><span class="s4">'ncg'</span><span class="s2">, </span><span class="s1">disp=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">optim_hessian=</span><span class="s4">'oim'</span><span class="s2">,</span>
                       <span class="s1">optim_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s3"># Check that the Hessians broadly result in the same optimum</span>
    <span class="s1">assert_allclose(res1.llf</span><span class="s2">, </span><span class="s1">res2.llf</span><span class="s2">, </span><span class="s1">rtol=</span><span class="s5">1e-2</span><span class="s1">)</span>

    <span class="s3"># Test return_params=True</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">_ = get_dummy_mod(fit=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
        <span class="s1">res_params = mod.fit(disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">return_params=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s3"># 5 digits necessary to accommodate 32-bit numpy/scipy with OpenBLAS 0.2.18</span>
    <span class="s1">assert_almost_equal(res_params</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span>


<span class="s1">@pytest.mark.smoke</span>
<span class="s2">def </span><span class="s1">test_score_misc():</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">res = get_dummy_mod()</span>

    <span class="s3"># Test that the score function works</span>
    <span class="s1">mod.score(res.params)</span>


<span class="s2">def </span><span class="s1">test_from_formula():</span>
    <span class="s1">assert_raises(NotImplementedError</span><span class="s2">, lambda</span><span class="s1">: MLEModel.from_formula(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">))</span>


<span class="s2">def </span><span class="s1">test_score_analytic_ar1():</span>
    <span class="s3"># Test the score against the analytic score for an AR(1) model with 2</span>
    <span class="s3"># observations</span>
    <span class="s3"># Let endog = [1, 0.5], params=[0, 1]</span>
    <span class="s1">mod = sarimax.SARIMAX([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">partial_phi(phi</span><span class="s2">, </span><span class="s1">sigma2):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">0.5 </span><span class="s1">* (phi**</span><span class="s5">2 </span><span class="s1">+ </span><span class="s5">2</span><span class="s1">*phi*sigma2 - </span><span class="s5">1</span><span class="s1">) / (sigma2 * (</span><span class="s5">1 </span><span class="s1">- phi**</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s2">def </span><span class="s1">partial_sigma2(phi</span><span class="s2">, </span><span class="s1">sigma2):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">0.5 </span><span class="s1">* (</span><span class="s5">2</span><span class="s1">*sigma2 + phi - </span><span class="s5">1.25</span><span class="s1">) / (sigma2**</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s1">params = np.r_[</span><span class="s5">0.</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span>

    <span class="s3"># Compute the analytic score</span>
    <span class="s1">analytic_score = np.r_[</span>
        <span class="s1">partial_phi(params[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[</span><span class="s5">1</span><span class="s1">])</span><span class="s2">,</span>
        <span class="s1">partial_sigma2(params[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[</span><span class="s5">1</span><span class="s1">])]</span>

    <span class="s3"># Check each of the approximations, transformed parameters</span>
    <span class="s1">approx_cs = mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">approx_complex_step=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(approx_cs</span><span class="s2">, </span><span class="s1">analytic_score)</span>

    <span class="s1">approx_fd = mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">approx_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(approx_fd</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s1">approx_fd_centered = (</span>
        <span class="s1">mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">approx_complex_step=</span><span class="s2">False,</span>
                  <span class="s1">approx_centered=</span><span class="s2">True</span><span class="s1">))</span>
    <span class="s1">assert_allclose(approx_fd</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s1">harvey_cs = mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                          <span class="s1">approx_complex_step=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_cs</span><span class="s2">, </span><span class="s1">analytic_score)</span>
    <span class="s1">harvey_fd = mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                          <span class="s1">approx_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_fd</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>
    <span class="s1">harvey_fd_centered = mod.score(params</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                                   <span class="s1">approx_complex_step=</span><span class="s2">False,</span>
                                   <span class="s1">approx_centered=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_fd_centered</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s3"># Check the approximations for untransformed parameters. The analytic</span>
    <span class="s3"># check now comes from chain rule with the analytic derivative of the</span>
    <span class="s3"># transformation</span>
    <span class="s3"># if L* is the likelihood evaluated at untransformed parameters and</span>
    <span class="s3"># L is the likelihood evaluated at transformed parameters, then we have:</span>
    <span class="s3"># L*(u) = L(t(u))</span>
    <span class="s3"># and then</span>
    <span class="s3"># L'*(u) = L'(t(u)) * t'(u)</span>
    <span class="s2">def </span><span class="s1">partial_transform_phi(phi):</span>
        <span class="s2">return </span><span class="s1">-</span><span class="s5">1. </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">+ phi**</span><span class="s5">2</span><span class="s1">)**(</span><span class="s5">3.</span><span class="s1">/</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">partial_transform_sigma2(sigma2):</span>
        <span class="s2">return </span><span class="s5">2. </span><span class="s1">* sigma2</span>

    <span class="s1">uparams = mod.untransform_params(params)</span>

    <span class="s1">analytic_score = np.dot(</span>
        <span class="s1">np.diag(np.r_[partial_transform_phi(uparams[</span><span class="s5">0</span><span class="s1">])</span><span class="s2">,</span>
                      <span class="s1">partial_transform_sigma2(uparams[</span><span class="s5">1</span><span class="s1">])])</span><span class="s2">,</span>
        <span class="s1">np.r_[partial_phi(params[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[</span><span class="s5">1</span><span class="s1">])</span><span class="s2">,</span>
              <span class="s1">partial_sigma2(params[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[</span><span class="s5">1</span><span class="s1">])])</span>

    <span class="s1">approx_cs = mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False, </span><span class="s1">approx_complex_step=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(approx_cs</span><span class="s2">, </span><span class="s1">analytic_score)</span>

    <span class="s1">approx_fd = mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False,</span>
                          <span class="s1">approx_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(approx_fd</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s1">approx_fd_centered = (</span>
        <span class="s1">mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False, </span><span class="s1">approx_complex_step=</span><span class="s2">False,</span>
                  <span class="s1">approx_centered=</span><span class="s2">True</span><span class="s1">))</span>
    <span class="s1">assert_allclose(approx_fd_centered</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s1">harvey_cs = mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                          <span class="s1">approx_complex_step=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_cs</span><span class="s2">, </span><span class="s1">analytic_score)</span>
    <span class="s1">harvey_fd = mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                          <span class="s1">approx_complex_step=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_fd</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>
    <span class="s1">harvey_fd_centered = mod.score(uparams</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False, </span><span class="s1">method=</span><span class="s4">'harvey'</span><span class="s2">,</span>
                                   <span class="s1">approx_complex_step=</span><span class="s2">False,</span>
                                   <span class="s1">approx_centered=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(harvey_fd_centered</span><span class="s2">, </span><span class="s1">analytic_score</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>

    <span class="s3"># Check the Hessian: these approximations are not very good, particularly</span>
    <span class="s3"># when phi is close to 0</span>
    <span class="s1">params = np.r_[</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">]</span>

    <span class="s2">def </span><span class="s1">hessian(phi</span><span class="s2">, </span><span class="s1">sigma2):</span>
        <span class="s1">hessian = np.zeros((</span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
        <span class="s1">hessian[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = (-phi**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">1</span><span class="s1">) / (phi**</span><span class="s5">2 </span><span class="s1">- </span><span class="s5">1</span><span class="s1">)**</span><span class="s5">2</span>
        <span class="s1">hessian[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = hessian[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = -</span><span class="s5">1 </span><span class="s1">/ (</span><span class="s5">2 </span><span class="s1">* sigma2**</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">hessian[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">] = (sigma2 + phi - </span><span class="s5">1.25</span><span class="s1">) / sigma2**</span><span class="s5">3</span>
        <span class="s2">return </span><span class="s1">hessian</span>

    <span class="s1">analytic_hessian = hessian(params[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">params[</span><span class="s5">1</span><span class="s1">])</span>

    <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
        <span class="s1">assert_allclose(mod._hessian_complex_step(params) * </span><span class="s5">2</span><span class="s2">,</span>
                        <span class="s1">analytic_hessian</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-1</span><span class="s1">)</span>
        <span class="s1">assert_allclose(mod._hessian_finite_difference(params) * </span><span class="s5">2</span><span class="s2">,</span>
                        <span class="s1">analytic_hessian</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_cov_params():</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">res = get_dummy_mod()</span>

    <span class="s3"># Smoke test for each of the covariance types</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'none'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Covariance matrix not calculated.'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'approx'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'approx'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Covariance matrix calculated using numerical (complex-step) '</span>
            <span class="s4">'differentiation.'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'oim'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'oim'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Covariance matrix calculated using the observed information '</span>
            <span class="s4">'matrix (complex-step) described in Harvey (1989).'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'opg'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'opg'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Covariance matrix calculated using the outer product of '</span>
            <span class="s4">'gradients (complex-step).'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'robust'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'robust'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Quasi-maximum likelihood covariance matrix used for robustness '</span>
            <span class="s4">'to some misspecifications; calculated using the observed '</span>
            <span class="s4">'information matrix (complex-step) described in Harvey (1989).'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'robust_oim'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'robust_oim'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Quasi-maximum likelihood covariance matrix used for robustness '</span>
            <span class="s4">'to some misspecifications; calculated using the observed '</span>
            <span class="s4">'information matrix (complex-step) described in Harvey (1989).'</span><span class="s1">)</span>

        <span class="s1">res = mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'robust_approx'</span><span class="s1">)</span>
        <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'robust_approx'</span><span class="s1">)</span>
        <span class="s1">assert_equal(</span>
            <span class="s1">res.cov_kwds[</span><span class="s4">'description'</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">'Quasi-maximum likelihood covariance matrix used for robustness '</span>
            <span class="s4">'to some misspecifications; calculated using numerical '</span>
            <span class="s4">'(complex-step) differentiation.'</span><span class="s1">)</span>

        <span class="s2">with </span><span class="s1">pytest.raises(NotImplementedError):</span>
            <span class="s1">mod.fit(res.params</span><span class="s2">, </span><span class="s1">disp=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'invalid_cov_type'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_transform():</span>
    <span class="s3"># The transforms in MLEModel are noops</span>
    <span class="s1">mod = MLEModel([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Test direct transform, untransform</span>
    <span class="s1">assert_allclose(mod.transform_params([</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">, </span><span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span>
    <span class="s1">assert_allclose(mod.untransform_params([</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">, </span><span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span>

    <span class="s3"># Smoke test for transformation in `filter`, `update`, `loglike`,</span>
    <span class="s3"># `loglikeobs`</span>
    <span class="s1">mod.filter([]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">mod.update([]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">mod.loglike([]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">mod.loglikeobs([]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s3"># Note that mod is an SARIMAX instance, and the two parameters are</span>
    <span class="s3"># variances</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">_ = get_dummy_mod(fit=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s3"># Test direct transform, untransform</span>
    <span class="s1">assert_allclose(mod.transform_params([</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">, </span><span class="s1">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">9</span><span class="s1">])</span>
    <span class="s1">assert_allclose(mod.untransform_params([</span><span class="s5">4</span><span class="s2">, </span><span class="s5">9</span><span class="s1">])</span><span class="s2">, </span><span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span>

    <span class="s3"># Test transformation in `filter`</span>
    <span class="s1">res = mod.filter([</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.params</span><span class="s2">, </span><span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span>

    <span class="s1">res = mod.filter([</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">transformed=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.params</span><span class="s2">, </span><span class="s1">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">9</span><span class="s1">])</span>


<span class="s2">def </span><span class="s1">test_filter():</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">])</span>
    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Test return of ssm object</span>
    <span class="s1">res = mod.filter([]</span><span class="s2">, </span><span class="s1">return_ssm=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">assert_equal(isinstance(res</span><span class="s2">, </span><span class="s1">kalman_filter.FilterResults)</span><span class="s2">, True</span><span class="s1">)</span>

    <span class="s3"># Test return of full results object</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_equal(isinstance(res</span><span class="s2">, </span><span class="s1">MLEResultsWrapper)</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'opg'</span><span class="s1">)</span>

    <span class="s3"># Test return of full results object, specific covariance type</span>
    <span class="s1">res = mod.filter([]</span><span class="s2">, </span><span class="s1">cov_type=</span><span class="s4">'oim'</span><span class="s1">)</span>
    <span class="s1">assert_equal(isinstance(res</span><span class="s2">, </span><span class="s1">MLEResultsWrapper)</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(res.cov_type</span><span class="s2">, </span><span class="s4">'oim'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_params():</span>
    <span class="s1">mod = MLEModel([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># By default start_params raises NotImplementedError</span>
    <span class="s1">assert_raises(NotImplementedError</span><span class="s2">, lambda</span><span class="s1">: mod.start_params)</span>
    <span class="s3"># But param names are by default an empty array</span>
    <span class="s1">assert_equal(mod.param_names</span><span class="s2">, </span><span class="s1">[])</span>

    <span class="s3"># We can set them in the object if we want</span>
    <span class="s1">mod._start_params = [</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">mod._param_names = [</span><span class="s4">'a'</span><span class="s1">]</span>

    <span class="s1">assert_equal(mod.start_params</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">assert_equal(mod.param_names</span><span class="s2">, </span><span class="s1">[</span><span class="s4">'a'</span><span class="s1">])</span>


<span class="s2">def </span><span class="s1">check_results(pandas):</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">res = get_dummy_mod(pandas=pandas)</span>

    <span class="s3"># Test fitted values</span>
    <span class="s1">assert_almost_equal(res.fittedvalues[</span><span class="s5">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">mod.endog[</span><span class="s5">2</span><span class="s1">:].squeeze())</span>

    <span class="s3"># Test residuals</span>
    <span class="s1">assert_almost_equal(res.resid[</span><span class="s5">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">np.zeros(mod.nobs-</span><span class="s5">2</span><span class="s1">))</span>

    <span class="s3"># Test loglikelihood_burn</span>
    <span class="s1">assert_equal(res.loglikelihood_burn</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_results(pandas=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s1">check_results(pandas=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">check_results(pandas=</span><span class="s2">True</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_predict():</span>
    <span class="s1">dates = pd.date_range(start=</span><span class="s4">'1980-01-01'</span><span class="s2">, </span><span class="s1">end=</span><span class="s4">'1981-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>

    <span class="s3"># Test that predict with start=None, end=None does prediction with full</span>
    <span class="s3"># dataset</span>
    <span class="s1">predict = res.predict()</span>
    <span class="s1">assert_equal(predict.shape</span><span class="s2">, </span><span class="s1">(mod.nobs</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">assert_allclose(res.get_prediction().predicted_mean</span><span class="s2">, </span><span class="s1">predict)</span>

    <span class="s3"># Test a string value to the dynamic option</span>
    <span class="s1">assert_allclose(res.predict(dynamic=</span><span class="s4">'1981-01-01'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">res.predict())</span>

    <span class="s3"># Test an invalid date string value to the dynamic option</span>
    <span class="s3"># assert_raises(ValueError, res.predict, dynamic='1982-01-01')</span>

    <span class="s3"># Test for passing a string to predict when dates are not set</span>
    <span class="s1">mod = MLEModel([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_raises(KeyError</span><span class="s2">, </span><span class="s1">res.predict</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s4">'string'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_forecast():</span>
    <span class="s3"># Numpy</span>
    <span class="s1">mod = MLEModel([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">forecast = res.forecast(steps=</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">assert_allclose(forecast</span><span class="s2">, </span><span class="s1">np.ones((</span><span class="s5">10</span><span class="s2">,</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.get_forecast(steps=</span><span class="s5">10</span><span class="s1">).predicted_mean</span><span class="s2">, </span><span class="s1">forecast)</span>

    <span class="s3"># Pandas</span>
    <span class="s1">index = pd.date_range(</span><span class="s4">'1960-01-01'</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'MS'</span><span class="s1">)</span>
    <span class="s1">mod = MLEModel(pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=index)</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_allclose(res.forecast(steps=</span><span class="s5">10</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.ones((</span><span class="s5">10</span><span class="s2">,</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.forecast(steps=</span><span class="s4">'1960-12-01'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.ones((</span><span class="s5">10</span><span class="s2">,</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_allclose(res.get_forecast(steps=</span><span class="s5">10</span><span class="s1">).predicted_mean</span><span class="s2">,</span>
                    <span class="s1">np.ones((</span><span class="s5">10</span><span class="s2">,</span><span class="s1">)) * </span><span class="s5">2</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_summary():</span>
    <span class="s1">dates = pd.date_range(start=</span><span class="s4">'1980-01-01'</span><span class="s2">, </span><span class="s1">end=</span><span class="s4">'1984-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">5</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>

    <span class="s3"># Get the summary</span>
    <span class="s1">txt = str(res.summary())</span>

    <span class="s3"># Test res.summary when the model has dates</span>
    <span class="s1">assert_equal(re.search(</span><span class="s4">r'Sample:\s+01-01-1980'</span><span class="s2">, </span><span class="s1">txt) </span><span class="s2">is not None, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(re.search(</span><span class="s4">r'\s+- 01-01-1984'</span><span class="s2">, </span><span class="s1">txt) </span><span class="s2">is not None, True</span><span class="s1">)</span>

    <span class="s3"># Test res.summary when `model_name` was not provided</span>
    <span class="s1">assert_equal(re.search(</span><span class="s4">r'Model:\s+MLEModel'</span><span class="s2">, </span><span class="s1">txt) </span><span class="s2">is not None, True</span><span class="s1">)</span>

    <span class="s3"># Smoke test that summary still works when diagnostic tests fail</span>
    <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
        <span class="s1">warnings.simplefilter(</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>
        <span class="s1">res.filter_results._standardized_forecasts_error[:] = np.nan</span>
        <span class="s1">res.summary()</span>
        <span class="s1">res.filter_results._standardized_forecasts_error = </span><span class="s5">1</span>
        <span class="s1">res.summary()</span>
        <span class="s1">res.filter_results._standardized_forecasts_error = </span><span class="s4">'a'</span>
        <span class="s1">res.summary()</span>


<span class="s2">def </span><span class="s1">check_endog(endog</span><span class="s2">, </span><span class="s1">nobs=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">k_endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">**kwargs):</span>
    <span class="s3"># create the model</span>
    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s3"># the data directly available in the model is the statsmodels version of</span>
    <span class="s3"># the data; it should be 2-dim, C-contiguous, long-shaped:</span>
    <span class="s3"># (nobs, k_endog) == (2, 1)</span>
    <span class="s1">assert_equal(mod.endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.endog.flags[</span><span class="s4">'C_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.endog.shape</span><span class="s2">, </span><span class="s1">(nobs</span><span class="s2">, </span><span class="s1">k_endog))</span>
    <span class="s3"># the data in the `ssm` object is the state space version of the data; it</span>
    <span class="s3"># should be 2-dim, F-contiguous, wide-shaped (k_endog, nobs) == (1, 2)</span>
    <span class="s3"># and it should share data with mod.endog</span>
    <span class="s1">assert_equal(mod.ssm.endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm.endog.flags[</span><span class="s4">'F_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.ssm.endog.shape</span><span class="s2">, </span><span class="s1">(k_endog</span><span class="s2">, </span><span class="s1">nobs))</span>
    <span class="s1">assert_equal(mod.ssm.endog.base </span><span class="s2">is </span><span class="s1">mod.endog</span><span class="s2">, True</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">mod</span>


<span class="s2">def </span><span class="s1">test_basic_endog():</span>
    <span class="s3"># Test various types of basic python endog inputs (e.g. lists, scalars...)</span>

    <span class="s3"># Check cannot call with non-array_like</span>
    <span class="s3"># fails due to checks in statsmodels base classes</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">MLEModel</span><span class="s2">, </span><span class="s1">endog=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">MLEModel</span><span class="s2">, </span><span class="s1">endog=</span><span class="s4">'a'</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">MLEModel</span><span class="s2">, </span><span class="s1">endog=</span><span class="s2">True, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s3"># Check behavior with different types</span>
    <span class="s1">mod = MLEModel([</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_equal(res.filter_results.endog</span><span class="s2">, </span><span class="s1">[[</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s1">mod = MLEModel([</span><span class="s5">1.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_equal(res.filter_results.endog</span><span class="s2">, </span><span class="s1">[[</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s1">mod = MLEModel([</span><span class="s2">True</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">res = mod.filter([])</span>
    <span class="s1">assert_equal(res.filter_results.endog</span><span class="s2">, </span><span class="s1">[[</span><span class="s5">1</span><span class="s1">]])</span>

    <span class="s1">mod = MLEModel([</span><span class="s4">'a'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s3"># raises error due to inability coerce string to numeric</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">mod.filter</span><span class="s2">, </span><span class="s1">[])</span>

    <span class="s3"># Check that a different iterable tpyes give the expected result</span>
    <span class="s1">endog = [</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s1">endog = [[</span><span class="s5">1.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">2.</span><span class="s1">]]</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s1">endog = (</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>


<span class="s2">def </span><span class="s1">test_numpy_endog():</span>
    <span class="s3"># Test various types of numpy endog inputs</span>

    <span class="s3"># Check behavior of the link maintained between passed `endog` and</span>
    <span class="s3"># `mod.endog` arrays</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">])</span>
    <span class="s1">mod = MLEModel(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">assert_equal(mod.endog.base </span><span class="s2">is not </span><span class="s1">mod.data.orig_endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.endog.base </span><span class="s2">is not </span><span class="s1">endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.data.orig_endog.base </span><span class="s2">is not </span><span class="s1">endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">endog[</span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2</span>
    <span class="s3"># there is no link to mod.endog</span>
    <span class="s1">assert_equal(mod.endog</span><span class="s2">, </span><span class="s1">np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">].reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s3"># there remains a link to mod.data.orig_endog</span>
    <span class="s1">assert_equal(mod.data.orig_endog</span><span class="s2">, </span><span class="s1">endog)</span>

    <span class="s3"># Check behavior with different memory layouts / shapes</span>

    <span class="s3"># Example  (failure): 0-dim array</span>
    <span class="s1">endog = np.array(</span><span class="s5">1.</span><span class="s1">)</span>
    <span class="s3"># raises error due to len(endog) failing in statsmodels base classes</span>
    <span class="s1">assert_raises(TypeError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Example : 1-dim array, both C- and F-contiguous, length 2</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">])</span>
    <span class="s1">assert_equal(endog.ndim</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'C_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'F_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example : 2-dim array, C-contiguous, long-shaped: (nobs, k_endog)</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'C_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s3"># On newer numpy (&gt;= 0.10), this array is (rightly) both C and F contiguous</span>
    <span class="s3"># assert_equal(endog.flags['F_CONTIGUOUS'], False)</span>
    <span class="s1">assert_equal(endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example : 2-dim array, C-contiguous, wide-shaped: (k_endog, nobs)</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]).reshape(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'C_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s3"># On newer numpy (&gt;= 0.10), this array is (rightly) both C and F contiguous</span>
    <span class="s3"># assert_equal(endog.flags['F_CONTIGUOUS'], False)</span>
    <span class="s1">assert_equal(endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s3"># raises error because arrays are always interpreted as</span>
    <span class="s3"># (nobs, k_endog), which means that k_endog=2 is incompatibile with shape</span>
    <span class="s3"># of design matrix (1, 1)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Example : 2-dim array, F-contiguous, long-shaped (nobs, k_endog)</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]).reshape(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">).transpose()</span>
    <span class="s1">assert_equal(endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s3"># On newer numpy (&gt;= 0.10), this array is (rightly) both C and F contiguous</span>
    <span class="s3"># assert_equal(endog.flags['C_CONTIGUOUS'], False)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'F_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example : 2-dim array, F-contiguous, wide-shaped (k_endog, nobs)</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">).transpose()</span>
    <span class="s1">assert_equal(endog.ndim</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span>
    <span class="s3"># On newer numpy (&gt;= 0.10), this array is (rightly) both C and F contiguous</span>
    <span class="s3"># assert_equal(endog.flags['C_CONTIGUOUS'], False)</span>
    <span class="s1">assert_equal(endog.flags[</span><span class="s4">'F_CONTIGUOUS'</span><span class="s1">]</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(endog.shape</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">))</span>
    <span class="s3"># raises error because arrays are always interpreted as</span>
    <span class="s3"># (nobs, k_endog), which means that k_endog=2 is incompatibile with shape</span>
    <span class="s3"># of design matrix (1, 1)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Example  (failure): 3-dim array</span>
    <span class="s1">endog = np.array([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]).reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s3"># raises error due to direct ndim check in statsmodels base classes</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Example : np.array with 2 columns</span>
    <span class="s3"># Update kwargs for k_endog=2</span>
    <span class="s1">kwargs2 = {</span>
        <span class="s4">'k_states'</span><span class="s1">: </span><span class="s5">1</span><span class="s2">, </span><span class="s4">'design'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'obs_cov'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
        <span class="s4">'transition'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'selection'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'state_cov'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
        <span class="s4">'initialization'</span><span class="s1">: </span><span class="s4">'approximate_diffuse'</span>
    <span class="s1">}</span>
    <span class="s1">endog = np.array([[</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">3.</span><span class="s2">, </span><span class="s5">4.</span><span class="s1">]])</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">k_endog=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">**kwargs2)</span>
    <span class="s1">mod.filter([])</span>


<span class="s2">def </span><span class="s1">test_pandas_endog():</span>
    <span class="s3"># Test various types of pandas endog inputs (e.g. TimeSeries, etc.)</span>

    <span class="s3"># Example (failure): pandas.Series, no dates</span>
    <span class="s1">endog = pd.Series([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">])</span>
    <span class="s3"># raises error due to no dates</span>
    <span class="s1">warnings.simplefilter(</span><span class="s4">'always'</span><span class="s1">)</span>
    <span class="s3"># assert_raises(ValueError, check_endog, endog, **kwargs)</span>

    <span class="s3"># Example : pandas.Series</span>
    <span class="s1">dates = pd.date_range(start=</span><span class="s4">'1980-01-01'</span><span class="s2">, </span><span class="s1">end=</span><span class="s4">'1981-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example : pandas.Series, string datatype</span>
    <span class="s1">endog = pd.Series([</span><span class="s4">'a'</span><span class="s2">, </span><span class="s4">'b'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s3"># raises error due to direct type casting check in statsmodels base classes</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Example : pandas.Series</span>
    <span class="s1">endog = pd.Series([</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example : pandas.DataFrame with 1 column</span>
    <span class="s1">endog = pd.DataFrame({</span><span class="s4">'a'</span><span class="s1">: [</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod.filter([])</span>

    <span class="s3"># Example (failure): pandas.DataFrame with 2 columns</span>
    <span class="s1">endog = pd.DataFrame({</span><span class="s4">'a'</span><span class="s1">: [</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s4">'b'</span><span class="s1">: [</span><span class="s5">3.</span><span class="s2">, </span><span class="s5">4.</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s3"># raises error because 2-columns means k_endog=2, but the design matrix</span>
    <span class="s3"># set in **kwargs is shaped (1, 1)</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">check_endog</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s3"># Check behavior of the link maintained between passed `endog` and</span>
    <span class="s3"># `mod.endog` arrays</span>
    <span class="s1">endog = pd.DataFrame({</span><span class="s4">'a'</span><span class="s1">: [</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">assert_equal(mod.endog.base </span><span class="s2">is not </span><span class="s1">mod.data.orig_endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.endog.base </span><span class="s2">is not </span><span class="s1">endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">assert_equal(mod.data.orig_endog.values.base </span><span class="s2">is not </span><span class="s1">endog</span><span class="s2">, True</span><span class="s1">)</span>
    <span class="s1">endog.iloc[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">2</span>
    <span class="s3"># there is no link to mod.endog</span>
    <span class="s1">assert_equal(mod.endog</span><span class="s2">, </span><span class="s1">np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">].reshape(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
    <span class="s3"># there remains a link to mod.data.orig_endog</span>
    <span class="s1">assert_allclose(mod.data.orig_endog</span><span class="s2">, </span><span class="s1">endog)</span>

    <span class="s3"># Example : pandas.DataFrame with 2 columns</span>
    <span class="s3"># Update kwargs for k_endog=2</span>
    <span class="s1">kwargs2 = {</span>
        <span class="s4">'k_states'</span><span class="s1">: </span><span class="s5">1</span><span class="s2">, </span><span class="s4">'design'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'obs_cov'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
        <span class="s4">'transition'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'selection'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">, </span><span class="s4">'state_cov'</span><span class="s1">: [[</span><span class="s5">1</span><span class="s1">]]</span><span class="s2">,</span>
        <span class="s4">'initialization'</span><span class="s1">: </span><span class="s4">'approximate_diffuse'</span>
    <span class="s1">}</span>
    <span class="s1">endog = pd.DataFrame({</span><span class="s4">'a'</span><span class="s1">: [</span><span class="s5">1.</span><span class="s2">, </span><span class="s5">2.</span><span class="s1">]</span><span class="s2">, </span><span class="s4">'b'</span><span class="s1">: [</span><span class="s5">3.</span><span class="s2">, </span><span class="s5">4.</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">index=dates)</span>
    <span class="s1">mod = check_endog(endog</span><span class="s2">, </span><span class="s1">k_endog=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">**kwargs2)</span>
    <span class="s1">mod.filter([])</span>


<span class="s2">def </span><span class="s1">test_diagnostics():</span>
    <span class="s1">mod</span><span class="s2">, </span><span class="s1">res = get_dummy_mod()</span>

    <span class="s3"># Override the standardized forecasts errors to get more reasonable values</span>
    <span class="s3"># for the tests to run (not necessary, but prevents some annoying warnings)</span>
    <span class="s1">shape = res.filter_results._standardized_forecasts_error.shape</span>
    <span class="s1">res.filter_results._standardized_forecasts_error = (</span>
        <span class="s1">np.random.normal(size=shape))</span>

    <span class="s3"># Make sure method=None selects the appropriate test</span>
    <span class="s1">actual = res.test_normality(method=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">desired = res.test_normality(method=</span><span class="s4">'jarquebera'</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s1">assert_raises(NotImplementedError</span><span class="s2">, </span><span class="s1">res.test_normality</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'invalid'</span><span class="s1">)</span>

    <span class="s1">actual = res.test_heteroskedasticity(method=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">desired = res.test_heteroskedasticity(method=</span><span class="s4">'breakvar'</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">res.test_heteroskedasticity(method=</span><span class="s2">None, </span><span class="s1">alternative=</span><span class="s4">'invalid'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(NotImplementedError):</span>
        <span class="s1">res.test_heteroskedasticity(method=</span><span class="s4">'invalid'</span><span class="s1">)</span>

    <span class="s1">actual = res.test_serial_correlation(method=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s1">desired = res.test_serial_correlation(method=</span><span class="s4">'ljungbox'</span><span class="s1">)</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired)</span>

    <span class="s2">with </span><span class="s1">pytest.raises(NotImplementedError):</span>
        <span class="s1">res.test_serial_correlation(method=</span><span class="s4">'invalid'</span><span class="s1">)</span>

    <span class="s3"># Smoke tests for other options</span>
    <span class="s1">res.test_heteroskedasticity(method=</span><span class="s2">None, </span><span class="s1">alternative=</span><span class="s4">'d'</span><span class="s2">, </span><span class="s1">use_f=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">res.test_serial_correlation(method=</span><span class="s4">'boxpierce'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_small_sample_serial_correlation_test():</span>
    <span class="s3"># Test the Ljung Box serial correlation test for small samples with df</span>
    <span class="s3"># adjustment using the Nile dataset. Ljung-Box statistic and p-value</span>
    <span class="s3"># are compared to R's Arima() and checkresiduals() functions in forecast</span>
    <span class="s3"># package:</span>
    <span class="s3"># library(forecast)</span>
    <span class="s3"># fit &lt;- Arima(y, order=c(1,0,1), include.constant=FALSE)</span>
    <span class="s3"># checkresiduals(fit, lag=10)</span>
    <span class="s2">from </span><span class="s1">statsmodels.tsa.statespace.sarimax </span><span class="s2">import </span><span class="s1">SARIMAX</span>
    <span class="s1">niledata = nile.data.load_pandas().data</span>
    <span class="s1">niledata.index = pd.date_range(</span><span class="s4">'1871-01-01'</span><span class="s2">, </span><span class="s4">'1970-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>
    <span class="s1">mod = SARIMAX(</span>
        <span class="s1">endog=niledata[</span><span class="s4">'volume'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">trend=</span><span class="s4">'n'</span><span class="s2">,</span>
        <span class="s1">freq=niledata.index.freq)</span>
    <span class="s1">res = mod.fit()</span>

    <span class="s1">actual = res.test_serial_correlation(</span>
        <span class="s1">method=</span><span class="s4">'ljungbox'</span><span class="s2">, </span><span class="s1">lags=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">df_adjust=</span><span class="s2">True</span><span class="s1">)[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">14.116</span><span class="s2">, </span><span class="s5">0.0788</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-3</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_diagnostics_nile_eviews():</span>
    <span class="s3"># Test the diagnostic tests using the Nile dataset. Results are from</span>
    <span class="s3"># &quot;Fitting State Space Models with EViews&quot; (Van den Bossche 2011,</span>
    <span class="s3"># Journal of Statistical Software).</span>
    <span class="s3"># For parameter values, see Figure 2</span>
    <span class="s3"># For Ljung-Box and Jarque-Bera statistics and p-values, see Figure 5</span>
    <span class="s3"># The Heteroskedasticity statistic is not provided in this paper.</span>
    <span class="s1">niledata = nile.data.load_pandas().data</span>
    <span class="s1">niledata.index = pd.date_range(</span><span class="s4">'1871-01-01'</span><span class="s2">, </span><span class="s4">'1970-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>

    <span class="s1">mod = MLEModel(</span>
        <span class="s1">niledata[</span><span class="s4">'volume'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">initialization=</span><span class="s4">'approximate_diffuse'</span><span class="s2">, </span><span class="s1">initial_variance=</span><span class="s5">1e15</span><span class="s2">,</span>
        <span class="s1">loglikelihood_burn=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">mod.ssm[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'obs_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = np.exp(</span><span class="s5">9.600350</span><span class="s1">)</span>
    <span class="s1">mod.ssm[</span><span class="s4">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = np.exp(</span><span class="s5">7.348705</span><span class="s1">)</span>
    <span class="s1">res = mod.filter([])</span>

    <span class="s3"># Test Ljung-Box</span>
    <span class="s3"># Note: only 3 digits provided in the reference paper</span>
    <span class="s1">actual = res.test_serial_correlation(method=</span><span class="s4">'ljungbox'</span><span class="s2">, </span><span class="s1">lags=</span><span class="s5">10</span><span class="s1">)[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">13.117</span><span class="s2">, </span><span class="s5">0.217</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-3</span><span class="s1">)</span>

    <span class="s3"># Test Jarque-Bera</span>
    <span class="s1">actual = res.test_normality(method=</span><span class="s4">'jarquebera'</span><span class="s1">)[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">:</span><span class="s5">2</span><span class="s1">]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.041686</span><span class="s2">, </span><span class="s5">0.979373</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-5</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_diagnostics_nile_durbinkoopman():</span>
    <span class="s3"># Test the diagnostic tests using the Nile dataset. Results are from</span>
    <span class="s3"># Durbin and Koopman (2012); parameter values reported on page 37; test</span>
    <span class="s3"># statistics on page 40</span>
    <span class="s1">niledata = nile.data.load_pandas().data</span>
    <span class="s1">niledata.index = pd.date_range(</span><span class="s4">'1871-01-01'</span><span class="s2">, </span><span class="s4">'1970-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>

    <span class="s1">mod = MLEModel(</span>
        <span class="s1">niledata[</span><span class="s4">'volume'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">k_states=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">initialization=</span><span class="s4">'approximate_diffuse'</span><span class="s2">, </span><span class="s1">initial_variance=</span><span class="s5">1e15</span><span class="s2">,</span>
        <span class="s1">loglikelihood_burn=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">mod.ssm[</span><span class="s4">'design'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'obs_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">15099.</span>
    <span class="s1">mod.ssm[</span><span class="s4">'transition'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'selection'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">mod.ssm[</span><span class="s4">'state_cov'</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">1469.1</span>
    <span class="s1">res = mod.filter([])</span>

    <span class="s3"># Test Ljung-Box</span>
    <span class="s3"># Note: only 3 digits provided in the reference paper</span>
    <span class="s1">actual = res.test_serial_correlation(method=</span><span class="s4">'ljungbox'</span><span class="s2">, </span><span class="s1">lags=</span><span class="s5">9</span><span class="s1">)[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">8.84</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-2</span><span class="s1">)</span>

    <span class="s3"># Test Jarque-Bera</span>
    <span class="s3"># Note: The book reports 0.09 for Kurtosis, because it is reporting the</span>
    <span class="s3"># statistic less the mean of the Kurtosis distribution (which is 3).</span>
    <span class="s1">norm = res.test_normality(method=</span><span class="s4">'jarquebera'</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">actual = [norm[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">norm[</span><span class="s5">2</span><span class="s1">]</span><span class="s2">, </span><span class="s1">norm[</span><span class="s5">3</span><span class="s1">]]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.05</span><span class="s2">, </span><span class="s1">-</span><span class="s5">0.03</span><span class="s2">, </span><span class="s5">3.09</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-2</span><span class="s1">)</span>

    <span class="s3"># Test Heteroskedasticity</span>
    <span class="s3"># Note: only 2 digits provided in the book</span>
    <span class="s1">actual = res.test_heteroskedasticity(method=</span><span class="s4">'breakvar'</span><span class="s1">)[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
    <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">[</span><span class="s5">0.61</span><span class="s1">]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s5">1e-2</span><span class="s1">)</span>


<span class="s1">@pytest.mark.smoke</span>
<span class="s2">def </span><span class="s1">test_prediction_results():</span>
    <span class="s3"># Just smoke tests for the PredictionResults class, which is copied from</span>
    <span class="s3"># elsewhere in statsmodels</span>

    <span class="s1">mod</span><span class="s2">, </span><span class="s1">res = get_dummy_mod()</span>
    <span class="s1">predict = res.get_prediction()</span>
    <span class="s1">predict.summary_frame()</span>


<span class="s2">def </span><span class="s1">test_lutkepohl_information_criteria():</span>
    <span class="s3"># Setup dataset, use Lutkepohl data</span>
    <span class="s1">dta = pd.DataFrame(</span>
        <span class="s1">results_var_misc.lutkepohl_data</span><span class="s2">, </span><span class="s1">columns=[</span><span class="s4">'inv'</span><span class="s2">, </span><span class="s4">'inc'</span><span class="s2">, </span><span class="s4">'consump'</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">index=pd.date_range(</span><span class="s4">'1960-01-01'</span><span class="s2">, </span><span class="s4">'1982-10-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'QS'</span><span class="s1">))</span>

    <span class="s1">dta[</span><span class="s4">'dln_inv'</span><span class="s1">] = np.log(dta[</span><span class="s4">'inv'</span><span class="s1">]).diff()</span>
    <span class="s1">dta[</span><span class="s4">'dln_inc'</span><span class="s1">] = np.log(dta[</span><span class="s4">'inc'</span><span class="s1">]).diff()</span>
    <span class="s1">dta[</span><span class="s4">'dln_consump'</span><span class="s1">] = np.log(dta[</span><span class="s4">'consump'</span><span class="s1">]).diff()</span>

    <span class="s1">endog = dta.loc[</span><span class="s4">'1960-04-01'</span><span class="s1">:</span><span class="s4">'1978-10-01'</span><span class="s2">,</span>
                    <span class="s1">[</span><span class="s4">'dln_inv'</span><span class="s2">, </span><span class="s4">'dln_inc'</span><span class="s2">, </span><span class="s4">'dln_consump'</span><span class="s1">]]</span>

    <span class="s3"># AR model - SARIMAX</span>
    <span class="s3"># (use loglikelihood_burn=1 to mimic conditional MLE used by Stata's var</span>
    <span class="s3"># command).</span>
    <span class="s1">true = results_var_misc.lutkepohl_ar1_lustats</span>
    <span class="s1">mod = sarimax.SARIMAX(endog[</span><span class="s4">'dln_inv'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">trend=</span><span class="s4">'c'</span><span class="s2">,</span>
                          <span class="s1">loglikelihood_burn=</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">res = mod.filter(true[</span><span class="s4">'params'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(res.llf</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'loglike'</span><span class="s1">])</span>
    <span class="s3"># Test the Lutkepohl ICs</span>
    <span class="s3"># Note: for the Lutkepohl ICs, Stata only counts the AR coefficients as</span>
    <span class="s3"># estimated parameters for the purposes of information criteria, whereas we</span>
    <span class="s3"># count all parameters including scale and constant, so we need to adjust</span>
    <span class="s3"># for that</span>
    <span class="s1">aic = (res.info_criteria(</span><span class="s4">'aic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
           <span class="s5">2 </span><span class="s1">* </span><span class="s5">2 </span><span class="s1">/ res.nobs_effective)</span>
    <span class="s1">bic = (res.info_criteria(</span><span class="s4">'bic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
           <span class="s5">2 </span><span class="s1">* np.log(res.nobs_effective) / res.nobs_effective)</span>
    <span class="s1">hqic = (res.info_criteria(</span><span class="s4">'hqic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
            <span class="s5">2 </span><span class="s1">* </span><span class="s5">2 </span><span class="s1">* np.log(np.log(res.nobs_effective)) / res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'bic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(hqic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'hqic'</span><span class="s1">])</span>

    <span class="s3"># Test the non-Lutkepohl ICs</span>
    <span class="s3"># Note: for the non-Lutkepohl ICs, Stata does not count the scale as an</span>
    <span class="s3"># estimated parameter, but does count the constant term, for the</span>
    <span class="s3"># purposes of information criteria, whereas we count both, so we need to</span>
    <span class="s3"># adjust for that</span>
    <span class="s1">true = results_var_misc.lutkepohl_ar1</span>
    <span class="s1">aic = res.aic - </span><span class="s5">2</span>
    <span class="s1">bic = res.bic - np.log(res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_bic'</span><span class="s1">])</span>
    <span class="s1">aic = res.info_criteria(</span><span class="s4">'aic'</span><span class="s1">) - </span><span class="s5">2</span>
    <span class="s1">bic = res.info_criteria(</span><span class="s4">'bic'</span><span class="s1">) - np.log(res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_bic'</span><span class="s1">])</span>

    <span class="s3"># Note: could also test the &quot;dfk&quot; (degree of freedom corrections), but not</span>
    <span class="s3"># really necessary since they just rescale things a bit</span>

    <span class="s3"># VAR model - VARMAX</span>
    <span class="s3"># (use loglikelihood_burn=1 to mimic conditional MLE used by Stata's var</span>
    <span class="s3"># command).</span>
    <span class="s1">true = results_var_misc.lutkepohl_var1_lustats</span>
    <span class="s1">mod = varmax.VARMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">trend=</span><span class="s4">'n'</span><span class="s2">,</span>
                        <span class="s1">error_cov_type=</span><span class="s4">'unstructured'</span><span class="s2">, </span><span class="s1">loglikelihood_burn=</span><span class="s5">1</span><span class="s2">,</span><span class="s1">)</span>
    <span class="s1">res = mod.filter(true[</span><span class="s4">'params'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(res.llf</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'loglike'</span><span class="s1">])</span>

    <span class="s3"># Test the Lutkepohl ICs</span>
    <span class="s3"># Note: for the Lutkepohl ICs, Stata only counts the AR coefficients as</span>
    <span class="s3"># estimated parameters for the purposes of information criteria, whereas we</span>
    <span class="s3"># count all parameters including the elements of the covariance matrix, so</span>
    <span class="s3"># we need to adjust for that</span>
    <span class="s1">aic = (res.info_criteria(</span><span class="s4">'aic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
           <span class="s5">2 </span><span class="s1">* </span><span class="s5">6 </span><span class="s1">/ res.nobs_effective)</span>
    <span class="s1">bic = (res.info_criteria(</span><span class="s4">'bic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
           <span class="s5">6 </span><span class="s1">* np.log(res.nobs_effective) / res.nobs_effective)</span>
    <span class="s1">hqic = (res.info_criteria(</span><span class="s4">'hqic'</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">'lutkepohl'</span><span class="s1">) -</span>
            <span class="s5">2 </span><span class="s1">* </span><span class="s5">6 </span><span class="s1">* np.log(np.log(res.nobs_effective)) / res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'bic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(hqic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'hqic'</span><span class="s1">])</span>

    <span class="s3"># Test the non-Lutkepohl ICs</span>
    <span class="s3"># Note: for the non-Lutkepohl ICs, Stata does not count the elements of the</span>
    <span class="s3"># covariance matrix as estimated parameters for the purposes of information</span>
    <span class="s3"># criteria, whereas we count both, so we need to adjust for that</span>
    <span class="s1">true = results_var_misc.lutkepohl_var1</span>
    <span class="s1">aic = res.aic - </span><span class="s5">2 </span><span class="s1">* </span><span class="s5">6</span>
    <span class="s1">bic = res.bic - </span><span class="s5">6 </span><span class="s1">* np.log(res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_bic'</span><span class="s1">])</span>
    <span class="s1">aic = res.info_criteria(</span><span class="s4">'aic'</span><span class="s1">) - </span><span class="s5">2 </span><span class="s1">* </span><span class="s5">6</span>
    <span class="s1">bic = res.info_criteria(</span><span class="s4">'bic'</span><span class="s1">) - </span><span class="s5">6 </span><span class="s1">* np.log(res.nobs_effective)</span>
    <span class="s1">assert_allclose(aic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_aic'</span><span class="s1">])</span>
    <span class="s1">assert_allclose(bic</span><span class="s2">, </span><span class="s1">true[</span><span class="s4">'estat_bic'</span><span class="s1">])</span>


<span class="s2">def </span><span class="s1">test_append_extend_apply_invalid():</span>
    <span class="s3"># Test for invalid options to append, extend, and apply</span>
    <span class="s1">niledata = nile.data.load_pandas().data[</span><span class="s4">'volume'</span><span class="s1">]</span>
    <span class="s1">niledata.index = pd.date_range(</span><span class="s4">'1871-01-01'</span><span class="s2">, </span><span class="s4">'1970-01-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'AS'</span><span class="s1">)</span>

    <span class="s1">endog1 = niledata.iloc[:</span><span class="s5">20</span><span class="s1">]</span>
    <span class="s1">endog2 = niledata.iloc[</span><span class="s5">20</span><span class="s1">:</span><span class="s5">40</span><span class="s1">]</span>

    <span class="s1">mod = sarimax.SARIMAX(endog1</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">concentrate_scale=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">res1 = mod.smooth([</span><span class="s5">0.5</span><span class="s1">])</span>

    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.append</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">,</span>
                  <span class="s1">fit_kwargs={</span><span class="s4">'cov_type'</span><span class="s1">: </span><span class="s4">'approx'</span><span class="s1">})</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.extend</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">,</span>
                  <span class="s1">fit_kwargs={</span><span class="s4">'cov_type'</span><span class="s1">: </span><span class="s4">'approx'</span><span class="s1">})</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.apply</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">,</span>
                  <span class="s1">fit_kwargs={</span><span class="s4">'cov_type'</span><span class="s1">: </span><span class="s4">'approx'</span><span class="s1">})</span>

    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.append</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">, </span><span class="s1">fit_kwargs={</span><span class="s4">'cov_kwds'</span><span class="s1">: {}})</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.extend</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">, </span><span class="s1">fit_kwargs={</span><span class="s4">'cov_kwds'</span><span class="s1">: {}})</span>
    <span class="s1">assert_raises(ValueError</span><span class="s2">, </span><span class="s1">res1.apply</span><span class="s2">, </span><span class="s1">endog2</span><span class="s2">, </span><span class="s1">fit_kwargs={</span><span class="s4">'cov_kwds'</span><span class="s1">: {}})</span>

    <span class="s3"># Test for exception when given a different frequency</span>
    <span class="s1">wrong_freq = niledata.iloc[</span><span class="s5">20</span><span class="s1">:</span><span class="s5">40</span><span class="s1">]</span>
    <span class="s1">wrong_freq.index = pd.date_range(</span>
        <span class="s1">start=niledata.index[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">periods=len(wrong_freq)</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'MS'</span><span class="s1">)</span>
    <span class="s1">message = (</span><span class="s4">'Given `endog` does not have an index that extends the index of'</span>
               <span class="s4">' the model. Expected index frequency is'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.append(wrong_freq)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.extend(wrong_freq)</span>
    <span class="s1">message = (</span><span class="s4">'Given `exog` does not have an index that extends the index of'</span>
               <span class="s4">' the model. Expected index frequency is'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.append(endog2</span><span class="s2">, </span><span class="s1">exog=wrong_freq)</span>
    <span class="s1">message = </span><span class="s4">'The indices for endog and exog are not aligned'</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.extend(endog2</span><span class="s2">, </span><span class="s1">exog=wrong_freq)</span>

    <span class="s3"># Test for exception when given the same frequency but not right after the</span>
    <span class="s3"># end of model</span>
    <span class="s1">not_cts = niledata.iloc[</span><span class="s5">21</span><span class="s1">:</span><span class="s5">41</span><span class="s1">]</span>
    <span class="s1">message = (</span><span class="s4">'Given `endog` does not have an index that extends the index of'</span>
               <span class="s4">' the model.$'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.append(not_cts)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.extend(not_cts)</span>
    <span class="s1">message = (</span><span class="s4">'Given `exog` does not have an index that extends the index of'</span>
               <span class="s4">' the model.$'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.append(endog2</span><span class="s2">, </span><span class="s1">exog=not_cts)</span>
    <span class="s1">message = </span><span class="s4">'The indices for endog and exog are not aligned'</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res1.extend(endog2</span><span class="s2">, </span><span class="s1">exog=not_cts)</span>

    <span class="s3"># # Test for problems with non-date indexes</span>
    <span class="s1">endog3 = pd.Series(niledata.iloc[:</span><span class="s5">20</span><span class="s1">].values)</span>
    <span class="s1">endog4 = pd.Series(niledata.iloc[:</span><span class="s5">40</span><span class="s1">].values)[</span><span class="s5">20</span><span class="s1">:]</span>
    <span class="s1">mod2 = sarimax.SARIMAX(endog3</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">exog=endog3</span><span class="s2">,</span>
                           <span class="s1">concentrate_scale=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">res2 = mod2.smooth([</span><span class="s5">0.2</span><span class="s2">, </span><span class="s5">0.5</span><span class="s1">])</span>

    <span class="s3"># Test for exception when given the same frequency but not right after the</span>
    <span class="s3"># end of model</span>
    <span class="s1">not_cts = pd.Series(niledata[:</span><span class="s5">41</span><span class="s1">].values)[</span><span class="s5">21</span><span class="s1">:]</span>
    <span class="s1">message = (</span><span class="s4">'Given `endog` does not have an index that extends the index of'</span>
               <span class="s4">' the model.$'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res2.append(not_cts)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res2.extend(not_cts)</span>
    <span class="s1">message = (</span><span class="s4">'Given `exog` does not have an index that extends the index of'</span>
               <span class="s4">' the model.$'</span><span class="s1">)</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res2.append(endog4</span><span class="s2">, </span><span class="s1">exog=not_cts)</span>
    <span class="s1">message = </span><span class="s4">'The indices for endog and exog are not aligned'</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=message):</span>
        <span class="s1">res2.extend(endog4</span><span class="s2">, </span><span class="s1">exog=not_cts)</span>


<span class="s2">def </span><span class="s1">test_integer_params():</span>
    <span class="s3"># See GH#6335</span>
    <span class="s1">mod = sarimax.SARIMAX([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">exog=[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">,</span>
                          <span class="s1">concentrate_scale=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">res = mod.filter([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s1">])</span>
    <span class="s1">p = res.predict(end=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s2">True, </span><span class="s1">exog=[</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">])</span>
    <span class="s1">assert_equal(p.dtype</span><span class="s2">, </span><span class="s1">np.float64)</span>


<span class="s2">def </span><span class="s1">check_states_index(states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols):</span>
    <span class="s1">predicted_cov_ix = pd.MultiIndex.from_product(</span>
        <span class="s1">[predicted_ix</span><span class="s2">, </span><span class="s1">cols]).swaplevel()</span>
    <span class="s1">filtered_cov_ix = pd.MultiIndex.from_product([ix</span><span class="s2">, </span><span class="s1">cols]).swaplevel()</span>
    <span class="s1">smoothed_cov_ix = pd.MultiIndex.from_product([ix</span><span class="s2">, </span><span class="s1">cols]).swaplevel()</span>

    <span class="s3"># Predicted</span>
    <span class="s1">assert_(states.predicted.index.equals(predicted_ix))</span>
    <span class="s1">assert_(states.predicted.columns.equals(cols))</span>

    <span class="s1">assert_(states.predicted_cov.index.equals(predicted_cov_ix))</span>
    <span class="s1">assert_(states.predicted.columns.equals(cols))</span>

    <span class="s3"># Filtered</span>
    <span class="s1">assert_(states.filtered.index.equals(ix))</span>
    <span class="s1">assert_(states.filtered.columns.equals(cols))</span>

    <span class="s1">assert_(states.filtered_cov.index.equals(filtered_cov_ix))</span>
    <span class="s1">assert_(states.filtered.columns.equals(cols))</span>

    <span class="s3"># Smoothed</span>
    <span class="s1">assert_(states.smoothed.index.equals(ix))</span>
    <span class="s1">assert_(states.smoothed.columns.equals(cols))</span>

    <span class="s1">assert_(states.smoothed_cov.index.equals(smoothed_cov_ix))</span>
    <span class="s1">assert_(states.smoothed.columns.equals(cols))</span>


<span class="s2">def </span><span class="s1">test_states_index_periodindex():</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">ix = pd.period_range(start=</span><span class="s4">'2000'</span><span class="s2">, </span><span class="s1">periods=nobs</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'M'</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series(np.zeros(nobs)</span><span class="s2">, </span><span class="s1">index=ix)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">res = mod.smooth([</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">])</span>

    <span class="s1">predicted_ix = pd.period_range(start=ix[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">periods=nobs + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'M'</span><span class="s1">)</span>
    <span class="s1">cols = pd.Index([</span><span class="s4">'state.0'</span><span class="s2">, </span><span class="s4">'state.1'</span><span class="s1">])</span>

    <span class="s1">check_states_index(res.states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols)</span>


<span class="s2">def </span><span class="s1">test_states_index_dateindex():</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">ix = pd.date_range(start=</span><span class="s4">'2000'</span><span class="s2">, </span><span class="s1">periods=nobs</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'M'</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series(np.zeros(nobs)</span><span class="s2">, </span><span class="s1">index=ix)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">res = mod.smooth([</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">])</span>

    <span class="s1">predicted_ix = pd.date_range(start=ix[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">periods=nobs + </span><span class="s5">1</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">'M'</span><span class="s1">)</span>
    <span class="s1">cols = pd.Index([</span><span class="s4">'state.0'</span><span class="s2">, </span><span class="s4">'state.1'</span><span class="s1">])</span>

    <span class="s1">check_states_index(res.states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols)</span>


<span class="s2">def </span><span class="s1">test_states_index_int64index():</span>
    <span class="s1">nobs = </span><span class="s5">10</span>
    <span class="s1">ix = pd.Index(np.arange(</span><span class="s5">10</span><span class="s1">))</span>
    <span class="s1">endog = pd.Series(np.zeros(nobs)</span><span class="s2">, </span><span class="s1">index=ix)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">res = mod.smooth([</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">])</span>

    <span class="s1">predicted_ix = pd.Index(np.arange(</span><span class="s5">11</span><span class="s1">))</span>
    <span class="s1">cols = pd.Index([</span><span class="s4">'state.0'</span><span class="s2">, </span><span class="s4">'state.1'</span><span class="s1">])</span>

    <span class="s1">check_states_index(res.states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols)</span>


<span class="s2">def </span><span class="s1">test_states_index_rangeindex():</span>
    <span class="s1">nobs = </span><span class="s5">10</span>

    <span class="s3"># Basic range index</span>
    <span class="s1">ix = pd.RangeIndex(</span><span class="s5">10</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series(np.zeros(nobs)</span><span class="s2">, </span><span class="s1">index=ix)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">res = mod.smooth([</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">])</span>

    <span class="s1">predicted_ix = pd.RangeIndex(</span><span class="s5">11</span><span class="s1">)</span>
    <span class="s1">cols = pd.Index([</span><span class="s4">'state.0'</span><span class="s2">, </span><span class="s4">'state.1'</span><span class="s1">])</span>

    <span class="s1">check_states_index(res.states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols)</span>

    <span class="s3"># More complex range index</span>
    <span class="s1">ix = pd.RangeIndex(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">32</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span>
    <span class="s1">endog = pd.Series(np.zeros(nobs)</span><span class="s2">, </span><span class="s1">index=ix)</span>

    <span class="s1">mod = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">order=(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">))</span>
    <span class="s1">res = mod.smooth([</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1.0</span><span class="s1">])</span>

    <span class="s1">predicted_ix = pd.RangeIndex(</span><span class="s5">2</span><span class="s2">, </span><span class="s5">35</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span>
    <span class="s1">cols = pd.Index([</span><span class="s4">'state.0'</span><span class="s2">, </span><span class="s4">'state.1'</span><span class="s1">])</span>

    <span class="s1">check_states_index(res.states</span><span class="s2">, </span><span class="s1">ix</span><span class="s2">, </span><span class="s1">predicted_ix</span><span class="s2">, </span><span class="s1">cols)</span>


<span class="s2">def </span><span class="s1">test_invalid_kwargs():</span>
    <span class="s1">endog = [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">]</span>
    <span class="s3"># Make sure we can create basic SARIMAX</span>
    <span class="s1">sarimax.SARIMAX(endog)</span>
    <span class="s3"># Now check that it raises a warning if we add an invalid keyword argument</span>
    <span class="s2">with </span><span class="s1">pytest.warns(FutureWarning):</span>
        <span class="s1">sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">invalid_kwarg=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s3"># (Note: once deprectation is completed in v0.15, switch to checking for</span>
    <span class="s3"># a TypeError, as below)</span>
    <span class="s3"># assert_raises(TypeError, sarimax.SARIMAX, endog, invalid_kwarg=True)</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_concentrated.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_concentrated.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for concentrating the scale out of the loglikelihood function 
 
Note: the univariate cases is well tested in test_sarimax.py 
 
Author: Chad Fulton 
License: Simplified-BSD 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.tools </span><span class="s2">import </span><span class="s1">Bunch</span>
<span class="s2">from </span><span class="s1">.results </span><span class="s2">import </span><span class="s1">results_varmax</span>
<span class="s2">from </span><span class="s1">statsmodels.tsa.statespace </span><span class="s2">import </span><span class="s1">sarimax</span><span class="s2">, </span><span class="s1">varmax</span>
<span class="s2">from </span><span class="s1">numpy.testing </span><span class="s2">import </span><span class="s1">assert_raises</span><span class="s2">, </span><span class="s1">assert_allclose</span>


<span class="s2">def </span><span class="s1">get_sarimax_models(endog</span><span class="s2">, </span><span class="s1">filter_univariate=</span><span class="s2">False, </span><span class="s1">**kwargs):</span>
    <span class="s1">kwargs.setdefault(</span><span class="s3">'tolerance'</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s5"># Construct a concentrated version of the given SARIMAX model, and get</span>
    <span class="s5"># the estimate of the scale</span>
    <span class="s1">mod_conc = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod_conc.ssm.filter_concentrated = </span><span class="s2">True</span>
    <span class="s1">mod_conc.ssm.filter_univariate = filter_univariate</span>
    <span class="s1">params_conc = mod_conc.start_params</span>
    <span class="s1">params_conc[-</span><span class="s4">1</span><span class="s1">] = </span><span class="s4">1</span>
    <span class="s1">res_conc = mod_conc.smooth(params_conc)</span>
    <span class="s1">scale = res_conc.scale</span>

    <span class="s5"># Construct the non-concentrated version</span>
    <span class="s1">mod_orig = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod_orig.ssm.filter_univariate = filter_univariate</span>
    <span class="s1">params_orig = params_conc.copy()</span>
    <span class="s1">k_vars = </span><span class="s4">1 </span><span class="s1">+ kwargs.get(</span><span class="s3">'measurement_error'</span><span class="s2">, False</span><span class="s1">)</span>
    <span class="s1">params_orig[-k_vars:] = scale * params_conc[-k_vars:]</span>
    <span class="s1">res_orig = mod_orig.smooth(params_orig)</span>

    <span class="s2">return </span><span class="s1">Bunch(**{</span><span class="s3">'mod_conc'</span><span class="s1">: mod_conc</span><span class="s2">, </span><span class="s3">'params_conc'</span><span class="s1">: params_conc</span><span class="s2">,</span>
                    <span class="s3">'mod_orig'</span><span class="s1">: mod_orig</span><span class="s2">, </span><span class="s3">'params_orig'</span><span class="s1">: params_orig</span><span class="s2">,</span>
                    <span class="s3">'res_conc'</span><span class="s1">: res_conc</span><span class="s2">, </span><span class="s3">'res_orig'</span><span class="s1">: res_orig</span><span class="s2">,</span>
                    <span class="s3">'scale'</span><span class="s1">: scale})</span>


<span class="s2">def </span><span class="s1">test_concentrated_loglike_sarimax():</span>
    <span class="s5"># Note: we will not use the &quot;concentrate_scale&quot; option to SARIMAX for this</span>
    <span class="s5"># test, which is a lower-level test of the Kalman filter using the SARIMAX</span>
    <span class="s5"># model as an example</span>
    <span class="s1">nobs = </span><span class="s4">30</span>
    <span class="s1">np.random.seed(</span><span class="s4">28953</span><span class="s1">)</span>
    <span class="s1">endog = np.random.normal(size=nobs)</span>
    <span class="s1">kwargs = {}</span>

    <span class="s5"># Typical model</span>
    <span class="s1">out = get_sarimax_models(endog)</span>
    <span class="s1">assert_allclose(out.res_conc.llf</span><span class="s2">, </span><span class="s1">out.res_orig.llf)</span>
    <span class="s1">assert_allclose(out.res_conc.llf_obs</span><span class="s2">, </span><span class="s1">out.res_orig.llf_obs)</span>
    <span class="s1">assert_allclose(out.mod_conc.loglike(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglike(out.params_orig))</span>
    <span class="s1">assert_allclose(out.mod_conc.loglikeobs(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglikeobs(out.params_orig))</span>

    <span class="s5"># Add missing entries</span>
    <span class="s1">endog[</span><span class="s4">2</span><span class="s1">:</span><span class="s4">10</span><span class="s1">] = np.nan</span>
    <span class="s1">out = get_sarimax_models(endog)</span>
    <span class="s1">assert_allclose(out.res_conc.llf</span><span class="s2">, </span><span class="s1">out.res_orig.llf)</span>
    <span class="s1">assert_allclose(out.res_conc.llf_obs</span><span class="s2">, </span><span class="s1">out.res_orig.llf_obs)</span>
    <span class="s1">assert_allclose(out.mod_conc.loglike(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglike(out.params_orig))</span>
    <span class="s1">assert_allclose(out.mod_conc.loglikeobs(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglikeobs(out.params_orig))</span>

    <span class="s5"># Add seasonal differencing</span>
    <span class="s5"># Note: now, due to differences in approximate diffuse initialization,</span>
    <span class="s5"># we may have differences in the first 2 observations (but notice that</span>
    <span class="s5"># this does not affect the computed joint log-likelihood because those</span>
    <span class="s5"># observations are not included there)</span>
    <span class="s1">kwargs[</span><span class="s3">'seasonal_order'</span><span class="s1">] = (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s1">)</span>
    <span class="s1">out = get_sarimax_models(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">assert_allclose(out.res_conc.llf</span><span class="s2">, </span><span class="s1">out.res_orig.llf)</span>
    <span class="s1">assert_allclose(out.res_conc.llf_obs[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">out.res_orig.llf_obs[</span><span class="s4">2</span><span class="s1">:])</span>
    <span class="s1">assert_allclose(out.mod_conc.loglike(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglike(out.params_orig))</span>
    <span class="s1">assert_allclose(out.mod_conc.loglikeobs(out.params_conc)[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglikeobs(out.params_orig)[</span><span class="s4">2</span><span class="s1">:])</span>

    <span class="s5"># Add loglikelihood burn, trend, and exog</span>
    <span class="s1">kwargs[</span><span class="s3">'loglikelihood_burn'</span><span class="s1">] = </span><span class="s4">5</span>
    <span class="s1">kwargs[</span><span class="s3">'trend'</span><span class="s1">] = </span><span class="s3">'c'</span>
    <span class="s1">kwargs[</span><span class="s3">'exog'</span><span class="s1">] = np.arange(nobs)</span>
    <span class="s1">out = get_sarimax_models(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">assert_allclose(out.res_conc.llf</span><span class="s2">, </span><span class="s1">out.res_orig.llf)</span>
    <span class="s1">assert_allclose(out.res_conc.llf_obs[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">out.res_orig.llf_obs[</span><span class="s4">2</span><span class="s1">:])</span>
    <span class="s1">assert_allclose(out.mod_conc.loglike(out.params_conc)</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglike(out.params_orig))</span>
    <span class="s1">assert_allclose(out.mod_conc.loglikeobs(out.params_conc)[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">,</span>
                    <span class="s1">out.mod_orig.loglikeobs(out.params_orig)[</span><span class="s4">2</span><span class="s1">:])</span>


<span class="s2">def </span><span class="s1">test_concentrated_predict_sarimax():</span>
    <span class="s5"># Note: we will not use the &quot;concentrate_scale&quot; option to SARIMAX for this</span>
    <span class="s5"># test, which is a lower-level test of the Kalman filter using the SARIMAX</span>
    <span class="s5"># model as an example</span>
    <span class="s1">nobs = </span><span class="s4">30</span>
    <span class="s1">np.random.seed(</span><span class="s4">28953</span><span class="s1">)</span>
    <span class="s1">endog = np.random.normal(size=nobs)</span>

    <span class="s5"># Typical model</span>
    <span class="s1">out = get_sarimax_models(endog)</span>
    <span class="s1">assert_allclose(out.res_conc.predict()</span><span class="s2">, </span><span class="s1">out.res_orig.predict())</span>
    <span class="s1">assert_allclose(out.res_conc.forecast(</span><span class="s4">5</span><span class="s1">)</span><span class="s2">, </span><span class="s1">out.res_orig.forecast(</span><span class="s4">5</span><span class="s1">))</span>
    <span class="s1">assert_allclose(out.res_conc.predict(start=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">end=</span><span class="s4">45</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s4">10</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">out.res_orig.predict(start=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">end=</span><span class="s4">45</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s4">10</span><span class="s1">))</span>


<span class="s2">def </span><span class="s1">test_fixed_scale_sarimax():</span>
    <span class="s5"># Test that the fixed_scale context manager works</span>
    <span class="s1">nobs = </span><span class="s4">30</span>
    <span class="s1">np.random.seed(</span><span class="s4">28953</span><span class="s1">)</span>
    <span class="s1">endog = np.random.normal(size=nobs)</span>
    <span class="s1">kwargs = {</span>
        <span class="s3">'seasonal_order'</span><span class="s1">: (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s3">'trend'</span><span class="s1">: </span><span class="s3">'ct'</span><span class="s2">,</span>
        <span class="s3">'exog'</span><span class="s1">: np.sin(np.arange(nobs))</span>
    <span class="s1">}</span>

    <span class="s5"># Construct a concentrated version of the given SARIMAX model</span>
    <span class="s1">mod_conc = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">concentrate_scale=</span><span class="s2">True, </span><span class="s1">**kwargs)</span>

    <span class="s5"># Construct the non-concentrated version</span>
    <span class="s1">mod_orig = sarimax.SARIMAX(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s5"># Modify the scale parameter</span>
    <span class="s1">params = mod_orig.start_params</span>
    <span class="s1">params[-</span><span class="s4">1</span><span class="s1">] *= </span><span class="s4">1.2</span>

    <span class="s5"># Test that these are not equal in the default computation</span>
    <span class="s1">assert_raises(AssertionError</span><span class="s2">, </span><span class="s1">assert_allclose</span><span class="s2">,</span>
                  <span class="s1">mod_conc.loglike(params[:-</span><span class="s4">1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">mod_orig.loglike(params))</span>

    <span class="s5"># Now test that the llf is equal when we use the fixed_scale decorator</span>
    <span class="s2">with </span><span class="s1">mod_conc.ssm.fixed_scale(params[-</span><span class="s4">1</span><span class="s1">]):</span>
        <span class="s1">res1 = mod_conc.smooth(params[:-</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">llf1 = mod_conc.loglike(params[:-</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">llf_obs1 = mod_conc.loglikeobs(params[:-</span><span class="s4">1</span><span class="s1">])</span>

    <span class="s1">res2 = mod_orig.smooth(params)</span>
    <span class="s1">llf2 = mod_orig.loglike(params)</span>
    <span class="s1">llf_obs2 = mod_orig.loglikeobs(params)</span>

    <span class="s1">assert_allclose(res1.llf</span><span class="s2">, </span><span class="s1">res2.llf)</span>
    <span class="s1">assert_allclose(res1.llf_obs[</span><span class="s4">2</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">res2.llf_obs[</span><span class="s4">2</span><span class="s1">:])</span>
    <span class="s1">assert_allclose(llf1</span><span class="s2">, </span><span class="s1">llf2)</span>
    <span class="s1">assert_allclose(llf_obs1</span><span class="s2">, </span><span class="s1">llf_obs2)</span>


<span class="s2">def </span><span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False, </span><span class="s1">missing=</span><span class="s2">False, </span><span class="s1">**kwargs):</span>
    <span class="s5"># Test that concentrating the scale out of the likelihood function works</span>
    <span class="s1">index = pd.date_range(</span><span class="s3">'1960-01-01'</span><span class="s2">, </span><span class="s3">'1982-10-01'</span><span class="s2">, </span><span class="s1">freq=</span><span class="s3">'QS'</span><span class="s1">)</span>
    <span class="s1">dta = pd.DataFrame(results_varmax.lutkepohl_data</span><span class="s2">,</span>
                       <span class="s1">columns=[</span><span class="s3">'inv'</span><span class="s2">, </span><span class="s3">'inc'</span><span class="s2">, </span><span class="s3">'consump'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">index=index)</span>
    <span class="s1">dta[</span><span class="s3">'dln_inv'</span><span class="s1">] = np.log(dta[</span><span class="s3">'inv'</span><span class="s1">]).diff()</span>
    <span class="s1">dta[</span><span class="s3">'dln_inc'</span><span class="s1">] = np.log(dta[</span><span class="s3">'inc'</span><span class="s1">]).diff()</span>
    <span class="s1">dta[</span><span class="s3">'dln_consump'</span><span class="s1">] = np.log(dta[</span><span class="s3">'consump'</span><span class="s1">]).diff()</span>

    <span class="s1">endog = dta.loc[</span><span class="s3">'1960-04-01'</span><span class="s1">:</span><span class="s3">'1978-10-01'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">'dln_inv'</span><span class="s2">, </span><span class="s3">'dln_inc'</span><span class="s1">]]</span>

    <span class="s5"># Optionally add some missing observations</span>
    <span class="s2">if </span><span class="s1">missing:</span>
        <span class="s1">endog.iloc[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s1">] = np.nan</span>
        <span class="s1">endog.iloc[</span><span class="s4">3</span><span class="s1">:</span><span class="s4">5</span><span class="s2">, </span><span class="s1">:] = np.nan</span>
        <span class="s1">endog.iloc[</span><span class="s4">8</span><span class="s2">, </span><span class="s4">1</span><span class="s1">] = np.nan</span>

    <span class="s5"># Sometimes we can have slight differences if the Kalman filters</span>
    <span class="s5"># converge at different observations, so disable convergence.</span>
    <span class="s1">kwargs.update({</span><span class="s3">'tolerance'</span><span class="s1">: </span><span class="s4">0</span><span class="s1">})</span>

    <span class="s1">mod_orig = varmax.VARMAX(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod_conc = varmax.VARMAX(endog</span><span class="s2">, </span><span class="s1">**kwargs)</span>
    <span class="s1">mod_conc.ssm.filter_concentrated = </span><span class="s2">True</span>

    <span class="s1">mod_orig.ssm.filter_univariate = filter_univariate</span>
    <span class="s1">mod_conc.ssm.filter_univariate = filter_univariate</span>

    <span class="s5"># Since VARMAX does not explicitly allow concentrating out the scale, for</span>
    <span class="s5"># now we will simulate it by setting the first variance to be 1.</span>
    <span class="s5"># Note that start_scale will not be the scale used for the non-concentrated</span>
    <span class="s5"># model, because we need to use the MLE scale estimated by the</span>
    <span class="s5"># concentrated model.</span>
    <span class="s1">conc_params = mod_conc.start_params</span>
    <span class="s1">start_scale = conc_params[mod_conc._params_state_cov][</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s2">if </span><span class="s1">kwargs.get(</span><span class="s3">'error_cov_type'</span><span class="s2">, </span><span class="s3">'unstructured'</span><span class="s1">) == </span><span class="s3">'diagonal'</span><span class="s1">:</span>
        <span class="s1">conc_params[mod_conc._params_state_cov] /= start_scale</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">conc_params[mod_conc._params_state_cov] /= start_scale**</span><span class="s4">0.5</span>

    <span class="s5"># Concentrated model smoothing</span>
    <span class="s1">res_conc = mod_conc.smooth(conc_params)</span>
    <span class="s1">scale = res_conc.scale</span>

    <span class="s5"># Map the concentrated parameters to the non-concentrated model</span>
    <span class="s1">orig_params = conc_params.copy()</span>
    <span class="s2">if </span><span class="s1">kwargs.get(</span><span class="s3">'error_cov_type'</span><span class="s2">, </span><span class="s3">'unstructured'</span><span class="s1">) == </span><span class="s3">'diagonal'</span><span class="s1">:</span>
        <span class="s1">orig_params[mod_orig._params_state_cov] *= scale</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">orig_params[mod_orig._params_state_cov] *= scale**</span><span class="s4">0.5</span>

    <span class="s5"># Measurement error variances also get rescaled</span>
    <span class="s1">orig_params[mod_orig._params_obs_cov] *= scale</span>

    <span class="s5"># Non-oncentrated model smoothing</span>
    <span class="s1">res_orig = mod_orig.smooth(orig_params)</span>

    <span class="s5"># Test loglike</span>
    <span class="s5"># Need to reduce the tolerance when we have measurement error.</span>
    <span class="s1">assert_allclose(res_conc.llf</span><span class="s2">, </span><span class="s1">res_orig.llf)</span>

    <span class="s5"># Test state space representation matrices</span>
    <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">mod_conc.ssm.shapes:</span>
        <span class="s2">if </span><span class="s1">name == </span><span class="s3">'obs'</span><span class="s1">:</span>
            <span class="s2">continue</span>
        <span class="s1">assert_allclose(getattr(res_conc.filter_results</span><span class="s2">, </span><span class="s1">name)</span><span class="s2">,</span>
                        <span class="s1">getattr(res_orig.filter_results</span><span class="s2">, </span><span class="s1">name))</span>

    <span class="s5"># Test filter / smoother output</span>
    <span class="s1">scale = res_conc.scale</span>
    <span class="s1">d = res_conc.loglikelihood_burn</span>

    <span class="s1">filter_attr = [</span><span class="s3">'predicted_state'</span><span class="s2">, </span><span class="s3">'filtered_state'</span><span class="s2">, </span><span class="s3">'forecasts'</span><span class="s2">,</span>
                   <span class="s3">'forecasts_error'</span><span class="s2">, </span><span class="s3">'kalman_gain'</span><span class="s1">]</span>

    <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">filter_attr:</span>
        <span class="s1">actual = getattr(res_conc.filter_results</span><span class="s2">, </span><span class="s1">name)</span>
        <span class="s1">desired = getattr(res_orig.filter_results</span><span class="s2">, </span><span class="s1">name)</span>
        <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-7</span><span class="s1">)</span>

    <span class="s5"># Note: do not want to compare the elements from any diffuse</span>
    <span class="s5"># initialization for things like covariances, so only compare for</span>
    <span class="s5"># periods past the loglikelihood_burn period</span>
    <span class="s1">filter_attr_burn = [</span><span class="s3">'standardized_forecasts_error'</span><span class="s2">,</span>
                        <span class="s3">'predicted_state_cov'</span><span class="s2">, </span><span class="s3">'filtered_state_cov'</span><span class="s2">,</span>
                        <span class="s3">'tmp1'</span><span class="s2">, </span><span class="s3">'tmp2'</span><span class="s2">, </span><span class="s3">'tmp3'</span><span class="s2">, </span><span class="s3">'tmp4'</span><span class="s1">]</span>

    <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">filter_attr_burn:</span>
        <span class="s1">actual = getattr(res_conc.filter_results</span><span class="s2">, </span><span class="s1">name)[...</span><span class="s2">, </span><span class="s1">d:]</span>
        <span class="s1">desired = getattr(res_orig.filter_results</span><span class="s2">, </span><span class="s1">name)[...</span><span class="s2">, </span><span class="s1">d:]</span>
        <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-7</span><span class="s1">)</span>

    <span class="s1">smoothed_attr = [</span><span class="s3">'smoothed_state'</span><span class="s2">, </span><span class="s3">'smoothed_state_cov'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_state_autocov'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_state_disturbance'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_state_disturbance_cov'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_measurement_disturbance'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_measurement_disturbance_cov'</span><span class="s2">,</span>
                     <span class="s3">'scaled_smoothed_estimator'</span><span class="s2">,</span>
                     <span class="s3">'scaled_smoothed_estimator_cov'</span><span class="s2">, </span><span class="s3">'smoothing_error'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_forecasts'</span><span class="s2">, </span><span class="s3">'smoothed_forecasts_error'</span><span class="s2">,</span>
                     <span class="s3">'smoothed_forecasts_error_cov'</span><span class="s1">]</span>

    <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">smoothed_attr:</span>
        <span class="s1">actual = getattr(res_conc.filter_results</span><span class="s2">, </span><span class="s1">name)</span>
        <span class="s1">desired = getattr(res_orig.filter_results</span><span class="s2">, </span><span class="s1">name)</span>
        <span class="s1">assert_allclose(actual</span><span class="s2">, </span><span class="s1">desired</span><span class="s2">, </span><span class="s1">atol=</span><span class="s4">1e-7</span><span class="s1">)</span>

    <span class="s5"># Test prediction output</span>
    <span class="s1">nobs = mod_conc.nobs</span>
    <span class="s1">pred_conc = res_conc.get_prediction(start=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">end=nobs + </span><span class="s4">50</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s4">40</span><span class="s1">)</span>
    <span class="s1">pred_orig = res_conc.get_prediction(start=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">end=nobs + </span><span class="s4">50</span><span class="s2">, </span><span class="s1">dynamic=</span><span class="s4">40</span><span class="s1">)</span>

    <span class="s1">assert_allclose(pred_conc.predicted_mean</span><span class="s2">, </span><span class="s1">pred_orig.predicted_mean)</span>
    <span class="s1">assert_allclose(pred_conc.se_mean</span><span class="s2">, </span><span class="s1">pred_orig.se_mean)</span>


<span class="s2">def </span><span class="s1">test_concentrated_scale_conventional():</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False, </span><span class="s1">measurement_error=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False,</span>
                             <span class="s1">error_cov_type=</span><span class="s3">'diagonal'</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False, </span><span class="s1">missing=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">False, </span><span class="s1">missing=</span><span class="s2">True,</span>
                             <span class="s1">loglikelihood_burn=</span><span class="s4">10</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_concentrated_scale_univariate():</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">True, </span><span class="s1">measurement_error=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">True, </span><span class="s1">error_cov_type=</span><span class="s3">'diagonal'</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">True, </span><span class="s1">missing=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">check_concentrated_scale(filter_univariate=</span><span class="s2">True, </span><span class="s1">missing=</span><span class="s2">True,</span>
                             <span class="s1">loglikelihood_burn=</span><span class="s4">10</span><span class="s1">)</span>
</pre>
</body>
</html>
<html>
<head>
<title>_dask.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_dask.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">print_function</span><span class="s0">, </span><span class="s1">division</span><span class="s0">, </span><span class="s1">absolute_import</span>

<span class="s0">import </span><span class="s1">asyncio</span>
<span class="s0">import </span><span class="s1">concurrent.futures</span>
<span class="s0">import </span><span class="s1">contextlib</span>

<span class="s0">import </span><span class="s1">time</span>
<span class="s0">from </span><span class="s1">uuid </span><span class="s0">import </span><span class="s1">uuid4</span>
<span class="s0">import </span><span class="s1">weakref</span>

<span class="s0">from </span><span class="s1">.parallel </span><span class="s0">import </span><span class="s1">parallel_config</span>
<span class="s0">from </span><span class="s1">.parallel </span><span class="s0">import </span><span class="s1">AutoBatchingMixin</span><span class="s0">, </span><span class="s1">ParallelBackendBase</span>

<span class="s0">try</span><span class="s1">:</span>
    <span class="s0">import </span><span class="s1">dask</span>
    <span class="s0">import </span><span class="s1">distributed</span>
<span class="s0">except </span><span class="s1">ImportError:</span>
    <span class="s1">dask = </span><span class="s0">None</span>
    <span class="s1">distributed = </span><span class="s0">None</span>

<span class="s0">if </span><span class="s1">dask </span><span class="s0">is not None and </span><span class="s1">distributed </span><span class="s0">is not None</span><span class="s1">:</span>
    <span class="s0">from </span><span class="s1">dask.utils </span><span class="s0">import </span><span class="s1">funcname</span>
    <span class="s0">from </span><span class="s1">dask.sizeof </span><span class="s0">import </span><span class="s1">sizeof</span>
    <span class="s0">from </span><span class="s1">dask.distributed </span><span class="s0">import </span><span class="s1">(</span>
        <span class="s1">Client</span><span class="s0">,</span>
        <span class="s1">as_completed</span><span class="s0">,</span>
        <span class="s1">get_client</span><span class="s0">,</span>
        <span class="s1">secede</span><span class="s0">,</span>
        <span class="s1">rejoin</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">from </span><span class="s1">distributed.utils </span><span class="s0">import </span><span class="s1">thread_state</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s2"># asyncio.TimeoutError, Python3-only error thrown by recent versions of</span>
        <span class="s2"># distributed</span>
        <span class="s0">from </span><span class="s1">distributed.utils </span><span class="s0">import </span><span class="s1">TimeoutError </span><span class="s0">as </span><span class="s1">_TimeoutError</span>
    <span class="s0">except </span><span class="s1">ImportError:</span>
        <span class="s0">from </span><span class="s1">tornado.gen </span><span class="s0">import </span><span class="s1">TimeoutError </span><span class="s0">as </span><span class="s1">_TimeoutError</span>


<span class="s0">def </span><span class="s1">is_weakrefable(obj):</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">weakref.ref(obj)</span>
        <span class="s0">return True</span>
    <span class="s0">except </span><span class="s1">TypeError:</span>
        <span class="s0">return False</span>


<span class="s0">class </span><span class="s1">_WeakKeyDictionary:</span>
    <span class="s3">&quot;&quot;&quot;A variant of weakref.WeakKeyDictionary for unhashable objects. 
 
    This datastructure is used to store futures for broadcasted data objects 
    such as large numpy arrays or pandas dataframes that are not hashable and 
    therefore cannot be used as keys of traditional python dicts. 
 
    Furthermore using a dict with id(array) as key is not safe because the 
    Python is likely to reuse id of recently collected arrays. 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(self):</span>
        <span class="s1">self._data = {}</span>

    <span class="s0">def </span><span class="s1">__getitem__(self</span><span class="s0">, </span><span class="s1">obj):</span>
        <span class="s1">ref</span><span class="s0">, </span><span class="s1">val = self._data[id(obj)]</span>
        <span class="s0">if </span><span class="s1">ref() </span><span class="s0">is not </span><span class="s1">obj:</span>
            <span class="s2"># In case of a race condition with on_destroy.</span>
            <span class="s0">raise </span><span class="s1">KeyError(obj)</span>
        <span class="s0">return </span><span class="s1">val</span>

    <span class="s0">def </span><span class="s1">__setitem__(self</span><span class="s0">, </span><span class="s1">obj</span><span class="s0">, </span><span class="s1">value):</span>
        <span class="s1">key = id(obj)</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">ref</span><span class="s0">, </span><span class="s1">_ = self._data[key]</span>
            <span class="s0">if </span><span class="s1">ref() </span><span class="s0">is not </span><span class="s1">obj:</span>
                <span class="s2"># In case of race condition with on_destroy.</span>
                <span class="s0">raise </span><span class="s1">KeyError(obj)</span>
        <span class="s0">except </span><span class="s1">KeyError:</span>
            <span class="s2"># Insert the new entry in the mapping along with a weakref</span>
            <span class="s2"># callback to automatically delete the entry from the mapping</span>
            <span class="s2"># as soon as the object used as key is garbage collected.</span>
            <span class="s0">def </span><span class="s1">on_destroy(_):</span>
                <span class="s0">del </span><span class="s1">self._data[key]</span>
            <span class="s1">ref = weakref.ref(obj</span><span class="s0">, </span><span class="s1">on_destroy)</span>
        <span class="s1">self._data[key] = ref</span><span class="s0">, </span><span class="s1">value</span>

    <span class="s0">def </span><span class="s1">__len__(self):</span>
        <span class="s0">return </span><span class="s1">len(self._data)</span>

    <span class="s0">def </span><span class="s1">clear(self):</span>
        <span class="s1">self._data.clear()</span>


<span class="s0">def </span><span class="s1">_funcname(x):</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">isinstance(x</span><span class="s0">, </span><span class="s1">list):</span>
            <span class="s1">x = x[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">except </span><span class="s1">Exception:</span>
        <span class="s0">pass</span>
    <span class="s0">return </span><span class="s1">funcname(x)</span>


<span class="s0">def </span><span class="s1">_make_tasks_summary(tasks):</span>
    <span class="s3">&quot;&quot;&quot;Summarize of list of (func, args, kwargs) function calls&quot;&quot;&quot;</span>
    <span class="s1">unique_funcs = {func </span><span class="s0">for </span><span class="s1">func</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwargs </span><span class="s0">in </span><span class="s1">tasks}</span>

    <span class="s0">if </span><span class="s1">len(unique_funcs) == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">mixed = </span><span class="s0">False</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">mixed = </span><span class="s0">True</span>
    <span class="s0">return </span><span class="s1">len(tasks)</span><span class="s0">, </span><span class="s1">mixed</span><span class="s0">, </span><span class="s1">_funcname(tasks)</span>


<span class="s0">class </span><span class="s1">Batch:</span>
    <span class="s3">&quot;&quot;&quot;dask-compatible wrapper that executes a batch of tasks&quot;&quot;&quot;</span>
    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">tasks):</span>
        <span class="s2"># collect some metadata from the tasks to ease Batch calls</span>
        <span class="s2"># introspection when debugging</span>
        <span class="s1">self._num_tasks</span><span class="s0">, </span><span class="s1">self._mixed</span><span class="s0">, </span><span class="s1">self._funcname = _make_tasks_summary(</span>
            <span class="s1">tasks</span>
        <span class="s1">)</span>

    <span class="s0">def </span><span class="s1">__call__(self</span><span class="s0">, </span><span class="s1">tasks=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">results = []</span>
        <span class="s0">with </span><span class="s1">parallel_config(backend=</span><span class="s5">'dask'</span><span class="s1">):</span>
            <span class="s0">for </span><span class="s1">func</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwargs </span><span class="s0">in </span><span class="s1">tasks:</span>
                <span class="s1">results.append(func(*args</span><span class="s0">, </span><span class="s1">**kwargs))</span>
            <span class="s0">return </span><span class="s1">results</span>

    <span class="s0">def </span><span class="s1">__repr__(self):</span>
        <span class="s1">descr = </span><span class="s5">f&quot;batch_of_</span><span class="s0">{</span><span class="s1">self._funcname</span><span class="s0">}</span><span class="s5">_</span><span class="s0">{</span><span class="s1">self._num_tasks</span><span class="s0">}</span><span class="s5">_calls&quot;</span>
        <span class="s0">if </span><span class="s1">self._mixed:</span>
            <span class="s1">descr = </span><span class="s5">&quot;mixed_&quot; </span><span class="s1">+ descr</span>
        <span class="s0">return </span><span class="s1">descr</span>


<span class="s0">def </span><span class="s1">_joblib_probe_task():</span>
    <span class="s2"># Noop used by the joblib connector to probe when workers are ready.</span>
    <span class="s0">pass</span>


<span class="s0">class </span><span class="s1">DaskDistributedBackend(AutoBatchingMixin</span><span class="s0">, </span><span class="s1">ParallelBackendBase):</span>
    <span class="s1">MIN_IDEAL_BATCH_DURATION = </span><span class="s4">0.2</span>
    <span class="s1">MAX_IDEAL_BATCH_DURATION = </span><span class="s4">1.0</span>
    <span class="s1">supports_timeout = </span><span class="s0">True</span>
    <span class="s1">default_n_jobs = -</span><span class="s4">1</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">scheduler_host=</span><span class="s0">None, </span><span class="s1">scatter=</span><span class="s0">None,</span>
                 <span class="s1">client=</span><span class="s0">None, </span><span class="s1">loop=</span><span class="s0">None, </span><span class="s1">wait_for_workers_timeout=</span><span class="s4">10</span><span class="s0">,</span>
                 <span class="s1">**submit_kwargs):</span>
        <span class="s1">super().__init__()</span>

        <span class="s0">if </span><span class="s1">distributed </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">msg = (</span><span class="s5">&quot;You are trying to use 'dask' as a joblib parallel backend &quot;</span>
                   <span class="s5">&quot;but dask is not installed. Please install dask &quot;</span>
                   <span class="s5">&quot;to fix this error.&quot;</span><span class="s1">)</span>
            <span class="s0">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s0">if </span><span class="s1">client </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">if </span><span class="s1">scheduler_host:</span>
                <span class="s1">client = Client(scheduler_host</span><span class="s0">, </span><span class="s1">loop=loop</span><span class="s0">,</span>
                                <span class="s1">set_as_default=</span><span class="s0">False</span><span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">client = get_client()</span>
                <span class="s0">except </span><span class="s1">ValueError </span><span class="s0">as </span><span class="s1">e:</span>
                    <span class="s1">msg = (</span><span class="s5">&quot;To use Joblib with Dask first create a Dask Client&quot;</span>
                           <span class="s5">&quot;</span><span class="s0">\n\n</span><span class="s5">&quot;</span>
                           <span class="s5">&quot;    from dask.distributed import Client</span><span class="s0">\n</span><span class="s5">&quot;</span>
                           <span class="s5">&quot;    client = Client()</span><span class="s0">\n</span><span class="s5">&quot;</span>
                           <span class="s5">&quot;or</span><span class="s0">\n</span><span class="s5">&quot;</span>
                           <span class="s5">&quot;    client = Client('scheduler-address:8786')&quot;</span><span class="s1">)</span>
                    <span class="s0">raise </span><span class="s1">ValueError(msg) </span><span class="s0">from </span><span class="s1">e</span>

        <span class="s1">self.client = client</span>

        <span class="s0">if </span><span class="s1">scatter </span><span class="s0">is not None and not </span><span class="s1">isinstance(scatter</span><span class="s0">, </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple)):</span>
            <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s5">&quot;scatter must be a list/tuple, got &quot;</span>
                            <span class="s5">&quot;`%s`&quot; </span><span class="s1">% type(scatter).__name__)</span>

        <span class="s0">if </span><span class="s1">scatter </span><span class="s0">is not None and </span><span class="s1">len(scatter) &gt; </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s2"># Keep a reference to the scattered data to keep the ids the same</span>
            <span class="s1">self._scatter = list(scatter)</span>
            <span class="s1">scattered = self.client.scatter(scatter</span><span class="s0">, </span><span class="s1">broadcast=</span><span class="s0">True</span><span class="s1">)</span>
            <span class="s1">self.data_futures = {id(x): f </span><span class="s0">for </span><span class="s1">x</span><span class="s0">, </span><span class="s1">f </span><span class="s0">in </span><span class="s1">zip(scatter</span><span class="s0">, </span><span class="s1">scattered)}</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">self._scatter = []</span>
            <span class="s1">self.data_futures = {}</span>
        <span class="s1">self.wait_for_workers_timeout = wait_for_workers_timeout</span>
        <span class="s1">self.submit_kwargs = submit_kwargs</span>
        <span class="s1">self.waiting_futures = as_completed(</span>
            <span class="s1">[]</span><span class="s0">,</span>
            <span class="s1">loop=client.loop</span><span class="s0">,</span>
            <span class="s1">with_results=</span><span class="s0">True,</span>
            <span class="s1">raise_errors=</span><span class="s0">False</span>
        <span class="s1">)</span>
        <span class="s1">self._results = {}</span>
        <span class="s1">self._callbacks = {}</span>

    <span class="s0">async def </span><span class="s1">_collect(self):</span>
        <span class="s0">while </span><span class="s1">self._continue:</span>
            <span class="s0">async for </span><span class="s1">future</span><span class="s0">, </span><span class="s1">result </span><span class="s0">in </span><span class="s1">self.waiting_futures:</span>
                <span class="s1">cf_future = self._results.pop(future)</span>
                <span class="s1">callback = self._callbacks.pop(future)</span>
                <span class="s0">if </span><span class="s1">future.status == </span><span class="s5">&quot;error&quot;</span><span class="s1">:</span>
                    <span class="s1">typ</span><span class="s0">, </span><span class="s1">exc</span><span class="s0">, </span><span class="s1">tb = result</span>
                    <span class="s1">cf_future.set_exception(exc)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">cf_future.set_result(result)</span>
                    <span class="s1">callback(result)</span>
            <span class="s0">await </span><span class="s1">asyncio.sleep(</span><span class="s4">0.01</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">__reduce__(self):</span>
        <span class="s0">return </span><span class="s1">(DaskDistributedBackend</span><span class="s0">, </span><span class="s1">())</span>

    <span class="s0">def </span><span class="s1">get_nested_backend(self):</span>
        <span class="s0">return </span><span class="s1">DaskDistributedBackend(client=self.client)</span><span class="s0">, </span><span class="s1">-</span><span class="s4">1</span>

    <span class="s0">def </span><span class="s1">configure(self</span><span class="s0">, </span><span class="s1">n_jobs=</span><span class="s4">1</span><span class="s0">, </span><span class="s1">parallel=</span><span class="s0">None, </span><span class="s1">**backend_args):</span>
        <span class="s1">self.parallel = parallel</span>
        <span class="s0">return </span><span class="s1">self.effective_n_jobs(n_jobs)</span>

    <span class="s0">def </span><span class="s1">start_call(self):</span>
        <span class="s1">self._continue = </span><span class="s0">True</span>
        <span class="s1">self.client.loop.add_callback(self._collect)</span>
        <span class="s1">self.call_data_futures = _WeakKeyDictionary()</span>

    <span class="s0">def </span><span class="s1">stop_call(self):</span>
        <span class="s2"># The explicit call to clear is required to break a cycling reference</span>
        <span class="s2"># to the futures.</span>
        <span class="s1">self._continue = </span><span class="s0">False</span>
        <span class="s2"># wait for the future collection routine (self._backend._collect) to</span>
        <span class="s2"># finish in order to limit asyncio warnings due to aborting _collect</span>
        <span class="s2"># during a following backend termination call</span>
        <span class="s1">time.sleep(</span><span class="s4">0.01</span><span class="s1">)</span>
        <span class="s1">self.call_data_futures.clear()</span>

    <span class="s0">def </span><span class="s1">effective_n_jobs(self</span><span class="s0">, </span><span class="s1">n_jobs):</span>
        <span class="s1">effective_n_jobs = sum(self.client.ncores().values())</span>
        <span class="s0">if </span><span class="s1">effective_n_jobs != </span><span class="s4">0 </span><span class="s0">or not </span><span class="s1">self.wait_for_workers_timeout:</span>
            <span class="s0">return </span><span class="s1">effective_n_jobs</span>

        <span class="s2"># If there is no worker, schedule a probe task to wait for the workers</span>
        <span class="s2"># to come up and be available. If the dask cluster is in adaptive mode</span>
        <span class="s2"># task might cause the cluster to provision some workers.</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">self.client.submit(_joblib_probe_task).result(</span>
                <span class="s1">timeout=self.wait_for_workers_timeout</span>
            <span class="s1">)</span>
        <span class="s0">except </span><span class="s1">_TimeoutError </span><span class="s0">as </span><span class="s1">e:</span>
            <span class="s1">error_msg = (</span>
                <span class="s5">&quot;DaskDistributedBackend has no worker after {} seconds. &quot;</span>
                <span class="s5">&quot;Make sure that workers are started and can properly connect &quot;</span>
                <span class="s5">&quot;to the scheduler and increase the joblib/dask connection &quot;</span>
                <span class="s5">&quot;timeout with:</span><span class="s0">\n\n</span><span class="s5">&quot;</span>
                <span class="s5">&quot;parallel_config(backend='dask', wait_for_workers_timeout={})&quot;</span>
            <span class="s1">).format(self.wait_for_workers_timeout</span><span class="s0">,</span>
                     <span class="s1">max(</span><span class="s4">10</span><span class="s0">, </span><span class="s4">2 </span><span class="s1">* self.wait_for_workers_timeout))</span>
            <span class="s0">raise </span><span class="s1">TimeoutError(error_msg) </span><span class="s0">from </span><span class="s1">e</span>
        <span class="s0">return </span><span class="s1">sum(self.client.ncores().values())</span>

    <span class="s0">async def </span><span class="s1">_to_func_args(self</span><span class="s0">, </span><span class="s1">func):</span>
        <span class="s1">itemgetters = dict()</span>

        <span class="s2"># Futures that are dynamically generated during a single call to</span>
        <span class="s2"># Parallel.__call__.</span>
        <span class="s1">call_data_futures = getattr(self</span><span class="s0">, </span><span class="s5">'call_data_futures'</span><span class="s0">, None</span><span class="s1">)</span>

        <span class="s0">async def </span><span class="s1">maybe_to_futures(args):</span>
            <span class="s1">out = []</span>
            <span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args:</span>
                <span class="s1">arg_id = id(arg)</span>
                <span class="s0">if </span><span class="s1">arg_id </span><span class="s0">in </span><span class="s1">itemgetters:</span>
                    <span class="s1">out.append(itemgetters[arg_id])</span>
                    <span class="s0">continue</span>

                <span class="s1">f = self.data_futures.get(arg_id</span><span class="s0">, None</span><span class="s1">)</span>
                <span class="s0">if </span><span class="s1">f </span><span class="s0">is None and </span><span class="s1">call_data_futures </span><span class="s0">is not None</span><span class="s1">:</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s1">f = </span><span class="s0">await </span><span class="s1">call_data_futures[arg]</span>
                    <span class="s0">except </span><span class="s1">KeyError:</span>
                        <span class="s0">pass</span>
                    <span class="s0">if </span><span class="s1">f </span><span class="s0">is None</span><span class="s1">:</span>
                        <span class="s0">if </span><span class="s1">is_weakrefable(arg) </span><span class="s0">and </span><span class="s1">sizeof(arg) &gt; </span><span class="s4">1e3</span><span class="s1">:</span>
                            <span class="s2"># Automatically scatter large objects to some of</span>
                            <span class="s2"># the workers to avoid duplicated data transfers.</span>
                            <span class="s2"># Rely on automated inter-worker data stealing if</span>
                            <span class="s2"># more workers need to reuse this data</span>
                            <span class="s2"># concurrently.</span>
                            <span class="s2"># set hash=False - nested scatter calls (i.e</span>
                            <span class="s2"># calling client.scatter inside a dask worker)</span>
                            <span class="s2"># using hash=True often raise CancelledError,</span>
                            <span class="s2"># see dask/distributed#3703</span>
                            <span class="s1">_coro = self.client.scatter(</span>
                                <span class="s1">arg</span><span class="s0">,</span>
                                <span class="s1">asynchronous=</span><span class="s0">True,</span>
                                <span class="s1">hash=</span><span class="s0">False</span>
                            <span class="s1">)</span>
                            <span class="s2"># Centralize the scattering of identical arguments</span>
                            <span class="s2"># between concurrent apply_async callbacks by</span>
                            <span class="s2"># exposing the running coroutine in</span>
                            <span class="s2"># call_data_futures before it completes.</span>
                            <span class="s1">t = asyncio.Task(_coro)</span>
                            <span class="s1">call_data_futures[arg] = t</span>

                            <span class="s1">f = </span><span class="s0">await </span><span class="s1">t</span>

                <span class="s0">if </span><span class="s1">f </span><span class="s0">is not None</span><span class="s1">:</span>
                    <span class="s1">out.append(f)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">out.append(arg)</span>
            <span class="s0">return </span><span class="s1">out</span>

        <span class="s1">tasks = []</span>
        <span class="s0">for </span><span class="s1">f</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwargs </span><span class="s0">in </span><span class="s1">func.items:</span>
            <span class="s1">args = list(</span><span class="s0">await </span><span class="s1">maybe_to_futures(args))</span>
            <span class="s1">kwargs = dict(zip(kwargs.keys()</span><span class="s0">,</span>
                              <span class="s0">await </span><span class="s1">maybe_to_futures(kwargs.values())))</span>
            <span class="s1">tasks.append((f</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwargs))</span>

        <span class="s0">return </span><span class="s1">(Batch(tasks)</span><span class="s0">, </span><span class="s1">tasks)</span>

    <span class="s0">def </span><span class="s1">apply_async(self</span><span class="s0">, </span><span class="s1">func</span><span class="s0">, </span><span class="s1">callback=</span><span class="s0">None</span><span class="s1">):</span>

        <span class="s1">cf_future = concurrent.futures.Future()</span>
        <span class="s1">cf_future.get = cf_future.result  </span><span class="s2"># achieve AsyncResult API</span>

        <span class="s0">async def </span><span class="s1">f(func</span><span class="s0">, </span><span class="s1">callback):</span>
            <span class="s1">batch</span><span class="s0">, </span><span class="s1">tasks = </span><span class="s0">await </span><span class="s1">self._to_func_args(func)</span>
            <span class="s1">key = </span><span class="s5">f'</span><span class="s0">{</span><span class="s1">repr(batch)</span><span class="s0">}</span><span class="s5">-</span><span class="s0">{</span><span class="s1">uuid4().hex</span><span class="s0">}</span><span class="s5">'</span>

            <span class="s1">dask_future = self.client.submit(</span>
                <span class="s1">batch</span><span class="s0">, </span><span class="s1">tasks=tasks</span><span class="s0">, </span><span class="s1">key=key</span><span class="s0">, </span><span class="s1">**self.submit_kwargs</span>
            <span class="s1">)</span>
            <span class="s1">self.waiting_futures.add(dask_future)</span>
            <span class="s1">self._callbacks[dask_future] = callback</span>
            <span class="s1">self._results[dask_future] = cf_future</span>

        <span class="s1">self.client.loop.add_callback(f</span><span class="s0">, </span><span class="s1">func</span><span class="s0">, </span><span class="s1">callback)</span>

        <span class="s0">return </span><span class="s1">cf_future</span>

    <span class="s0">def </span><span class="s1">abort_everything(self</span><span class="s0">, </span><span class="s1">ensure_ready=</span><span class="s0">True</span><span class="s1">):</span>
        <span class="s3">&quot;&quot;&quot; Tell the client to cancel any task submitted via this instance 
 
        joblib.Parallel will never access those results 
        &quot;&quot;&quot;</span>
        <span class="s0">with </span><span class="s1">self.waiting_futures.lock:</span>
            <span class="s1">self.waiting_futures.futures.clear()</span>
            <span class="s0">while not </span><span class="s1">self.waiting_futures.queue.empty():</span>
                <span class="s1">self.waiting_futures.queue.get()</span>

    <span class="s1">@contextlib.contextmanager</span>
    <span class="s0">def </span><span class="s1">retrieval_context(self):</span>
        <span class="s3">&quot;&quot;&quot;Override ParallelBackendBase.retrieval_context to avoid deadlocks. 
 
        This removes thread from the worker's thread pool (using 'secede'). 
        Seceding avoids deadlock in nested parallelism settings. 
        &quot;&quot;&quot;</span>
        <span class="s2"># See 'joblib.Parallel.__call__' and 'joblib.Parallel.retrieve' for how</span>
        <span class="s2"># this is used.</span>
        <span class="s0">if </span><span class="s1">hasattr(thread_state</span><span class="s0">, </span><span class="s5">'execution_state'</span><span class="s1">):</span>
            <span class="s2"># we are in a worker. Secede to avoid deadlock.</span>
            <span class="s1">secede()</span>

        <span class="s0">yield</span>

        <span class="s0">if </span><span class="s1">hasattr(thread_state</span><span class="s0">, </span><span class="s5">'execution_state'</span><span class="s1">):</span>
            <span class="s1">rejoin()</span>
</pre>
</body>
</html>
<html>
<head>
<title>panel_short.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
panel_short.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot;Panel data analysis for short T and large N 
 
Created on Sat Dec 17 19:32:00 2011 
 
Author: Josef Perktold 
License: BSD-3 
 
 
starting from scratch before looking at references again 
just a stub to get the basic structure for group handling 
target outsource as much as possible for reuse 
 
Notes 
----- 
 
this is the basic version using a loop over individuals which will be more 
widely applicable. Depending on the special cases, there will be faster 
implementations possible (sparse, kroneker, ...) 
 
the only two group specific methods or get_within_cov and whiten 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">GLS</span>
<span class="s3">from </span><span class="s1">statsmodels.tools.grouputils </span><span class="s3">import </span><span class="s1">GroupSorted</span>


<span class="s3">def </span><span class="s1">sum_outer_product_loop(x</span><span class="s3">, </span><span class="s1">group_iter):</span>
    <span class="s2">'''sum outerproduct dot(x_i, x_i.T) over individuals 
 
    loop version 
 
    '''</span>

    <span class="s1">mom = </span><span class="s4">0</span>
    <span class="s3">for </span><span class="s1">g </span><span class="s3">in </span><span class="s1">group_iter():</span>
        <span class="s1">x_g = x[g]</span>
        <span class="s0">#print 'x_g.shape', x_g.shape</span>
        <span class="s1">mom += np.outer(x_g</span><span class="s3">, </span><span class="s1">x_g)</span>

    <span class="s3">return </span><span class="s1">mom</span>

<span class="s3">def </span><span class="s1">sum_outer_product_balanced(x</span><span class="s3">, </span><span class="s1">n_groups):</span>
    <span class="s2">'''sum outerproduct dot(x_i, x_i.T) over individuals 
 
    where x_i is (nobs_i, 1), and result is (nobs_i, nobs_i) 
 
    reshape-dot version, for x.ndim=1 only 
 
    '''</span>
    <span class="s1">xrs = x.reshape(-</span><span class="s4">1</span><span class="s3">, </span><span class="s1">n_groups</span><span class="s3">, </span><span class="s1">order=</span><span class="s5">'F'</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">np.dot(xrs</span><span class="s3">, </span><span class="s1">xrs.T)  </span><span class="s0">#should be (nobs_i, nobs_i)</span>

    <span class="s0">#x.reshape(n_groups, nobs_i,  k_vars) #, order='F')</span>
    <span class="s0">#... ? this is getting 3-dimensional  dot, tensordot?</span>
    <span class="s0">#needs (n_groups, k_vars, k_vars) array with sum over groups</span>
    <span class="s0">#NOT</span>
    <span class="s0">#I only need this for x is 1d, i.e. residual</span>


<span class="s3">def </span><span class="s1">whiten_individuals_loop(x</span><span class="s3">, </span><span class="s1">transform</span><span class="s3">, </span><span class="s1">group_iter):</span>
    <span class="s2">'''apply linear transform for each individual 
 
    loop version 
    '''</span>

    <span class="s0">#Note: figure out dimension of transformed variable</span>
    <span class="s0">#so we can pre-allocate</span>
    <span class="s1">x_new = []</span>
    <span class="s3">for </span><span class="s1">g </span><span class="s3">in </span><span class="s1">group_iter():</span>
        <span class="s1">x_g = x[g]</span>
        <span class="s1">x_new.append(np.dot(transform</span><span class="s3">, </span><span class="s1">x_g))</span>

    <span class="s3">return </span><span class="s1">np.concatenate(x_new) </span><span class="s0">#np.vstack(x_new)  #or np.array(x_new) #check shape</span>



<span class="s3">class </span><span class="s1">ShortPanelGLS2:</span>
    <span class="s2">'''Short Panel with general intertemporal within correlation 
 
    assumes data is stacked by individuals, panel is balanced and 
    within correlation structure is identical across individuals. 
 
    It looks like this can just inherit GLS and overwrite whiten 
    '''</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">group):</span>
        <span class="s1">self.endog = endog</span>
        <span class="s1">self.exog = exog</span>
        <span class="s1">self.group = GroupSorted(group)</span>
        <span class="s1">self.n_groups = self.group.n_groups</span>
        <span class="s0">#self.nobs_group =   #list for unbalanced?</span>

    <span class="s3">def </span><span class="s1">fit_ols(self):</span>
        <span class="s1">self.res_pooled = OLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog).fit()</span>
        <span class="s3">return </span><span class="s1">self.res_pooled  </span><span class="s0">#return or not</span>

    <span class="s3">def </span><span class="s1">get_within_cov(self</span><span class="s3">, </span><span class="s1">resid):</span>
        <span class="s0">#central moment or not?</span>
        <span class="s1">mom = sum_outer_product_loop(resid</span><span class="s3">, </span><span class="s1">self.group.group_iter)</span>
        <span class="s3">return </span><span class="s1">mom / self.n_groups   </span><span class="s0">#df correction ?</span>

    <span class="s3">def </span><span class="s1">whiten_groups(self</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">cholsigmainv_i):</span>
        <span class="s0">#from scipy import sparse #use sparse</span>
        <span class="s1">wx = whiten_individuals_loop(x</span><span class="s3">, </span><span class="s1">cholsigmainv_i</span><span class="s3">, </span><span class="s1">self.group.group_iter)</span>
        <span class="s3">return </span><span class="s1">wx</span>

    <span class="s3">def </span><span class="s1">fit(self):</span>
        <span class="s1">res_pooled = self.fit_ols() </span><span class="s0">#get starting estimate</span>
        <span class="s1">sigma_i = self.get_within_cov(res_pooled.resid)</span>
        <span class="s1">self.cholsigmainv_i = np.linalg.cholesky(np.linalg.pinv(sigma_i)).T</span>
        <span class="s1">wendog = self.whiten_groups(self.endog</span><span class="s3">, </span><span class="s1">self.cholsigmainv_i)</span>
        <span class="s1">wexog = self.whiten_groups(self.exog</span><span class="s3">, </span><span class="s1">self.cholsigmainv_i)</span>
        <span class="s0">#print wendog.shape, wexog.shape</span>
        <span class="s1">self.res1 = OLS(wendog</span><span class="s3">, </span><span class="s1">wexog).fit()</span>
        <span class="s3">return </span><span class="s1">self.res1</span>

<span class="s3">class </span><span class="s1">ShortPanelGLS(GLS):</span>
    <span class="s2">'''Short Panel with general intertemporal within correlation 
 
    assumes data is stacked by individuals, panel is balanced and 
    within correlation structure is identical across individuals. 
 
    It looks like this can just inherit GLS and overwrite whiten 
    '''</span>

    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">group</span><span class="s3">, </span><span class="s1">sigma_i=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.group = GroupSorted(group)</span>
        <span class="s1">self.n_groups = self.group.n_groups</span>
        <span class="s0">#self.nobs_group =   #list for unbalanced?</span>
        <span class="s1">nobs_i = len(endog) / self.n_groups </span><span class="s0">#endog might later not be an ndarray</span>
        <span class="s0">#balanced only for now,</span>
        <span class="s0">#which is a requirement anyway in this case (full cov)</span>
        <span class="s0">#needs to change for parametrized sigma_i</span>

        <span class="s0">#</span>
        <span class="s3">if </span><span class="s1">sigma_i </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">sigma_i = np.eye(int(nobs_i))</span>
        <span class="s1">self.cholsigmainv_i = np.linalg.cholesky(np.linalg.pinv(sigma_i)).T</span>

        <span class="s0">#super is taking care of endog, exog and sigma</span>
        <span class="s1">super(self.__class__</span><span class="s3">, </span><span class="s1">self).__init__(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s3">None</span><span class="s1">)</span>

    <span class="s3">def </span><span class="s1">get_within_cov(self</span><span class="s3">, </span><span class="s1">resid):</span>
        <span class="s0">#central moment or not?</span>
        <span class="s1">mom = sum_outer_product_loop(resid</span><span class="s3">, </span><span class="s1">self.group.group_iter)</span>
        <span class="s3">return </span><span class="s1">mom / self.n_groups   </span><span class="s0">#df correction ?</span>

    <span class="s3">def </span><span class="s1">whiten_groups(self</span><span class="s3">, </span><span class="s1">x</span><span class="s3">, </span><span class="s1">cholsigmainv_i):</span>
        <span class="s0">#from scipy import sparse #use sparse</span>
        <span class="s1">wx = whiten_individuals_loop(x</span><span class="s3">, </span><span class="s1">cholsigmainv_i</span><span class="s3">, </span><span class="s1">self.group.group_iter)</span>
        <span class="s3">return </span><span class="s1">wx</span>

    <span class="s3">def </span><span class="s1">_fit_ols(self):</span>
        <span class="s0">#used as starting estimate in old explicity version</span>
        <span class="s1">self.res_pooled = OLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog).fit()</span>
        <span class="s3">return </span><span class="s1">self.res_pooled  </span><span class="s0">#return or not</span>

    <span class="s3">def </span><span class="s1">_fit_old(self):</span>
        <span class="s0">#old explicit version</span>
        <span class="s1">res_pooled = self._fit_ols() </span><span class="s0">#get starting estimate</span>
        <span class="s1">sigma_i = self.get_within_cov(res_pooled.resid)</span>
        <span class="s1">self.cholsigmainv_i = np.linalg.cholesky(np.linalg.pinv(sigma_i)).T</span>
        <span class="s1">wendog = self.whiten_groups(self.endog</span><span class="s3">, </span><span class="s1">self.cholsigmainv_i)</span>
        <span class="s1">wexog = self.whiten_groups(self.exog</span><span class="s3">, </span><span class="s1">self.cholsigmainv_i)</span>
        <span class="s1">self.res1 = OLS(wendog</span><span class="s3">, </span><span class="s1">wexog).fit()</span>
        <span class="s3">return </span><span class="s1">self.res1</span>

    <span class="s3">def </span><span class="s1">whiten(self</span><span class="s3">, </span><span class="s1">x):</span>
        <span class="s0">#whiten x by groups, will be applied to endog and exog</span>
        <span class="s1">wx = whiten_individuals_loop(x</span><span class="s3">, </span><span class="s1">self.cholsigmainv_i</span><span class="s3">, </span><span class="s1">self.group.group_iter)</span>
        <span class="s3">return </span><span class="s1">wx</span>

    <span class="s0">#copied from GLSHet and adjusted (boiler plate?)</span>
    <span class="s3">def </span><span class="s1">fit_iterative(self</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">3</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Perform an iterative two-step procedure to estimate the GLS model. 
 
        Parameters 
        ---------- 
        maxiter : int, optional 
            the number of iterations 
 
        Notes 
        ----- 
        maxiter=1: returns the estimated based on given weights 
        maxiter=2: performs a second estimation with the updated weights, 
                   this is 2-step estimation 
        maxiter&gt;2: iteratively estimate and update the weights 
 
        TODO: possible extension stop iteration if change in parameter 
            estimates is smaller than x_tol 
 
        Repeated calls to fit_iterative, will do one redundant pinv_wexog 
        calculation. Calling fit_iterative(maxiter) once does not do any 
        redundant recalculations (whitening or calculating pinv_wexog). 
        &quot;&quot;&quot;</span>
        <span class="s0">#Note: in contrast to GLSHet, we do not have an auxiliary regression here</span>
        <span class="s0">#      might be needed if there is more structure in cov_i</span>

        <span class="s0">#because we only have the loop we are not attaching the ols_pooled</span>
        <span class="s0">#initial estimate anymore compared to original version</span>

        <span class="s3">if </span><span class="s1">maxiter &lt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">'maxiter needs to be at least 1'</span><span class="s1">)</span>

        <span class="s3">import </span><span class="s1">collections</span>
        <span class="s1">self.history = collections.defaultdict(list) </span><span class="s0">#not really necessary</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(maxiter):</span>
            <span class="s0">#pinv_wexog is cached, delete it to force recalculation</span>
            <span class="s3">if </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s5">'pinv_wexog'</span><span class="s1">):</span>
                <span class="s3">del </span><span class="s1">self.pinv_wexog</span>

            <span class="s0">#fit with current cov, GLS, i.e. OLS on whitened endog, exog</span>
            <span class="s1">results = self.fit()</span>
            <span class="s1">self.history[</span><span class="s5">'self_params'</span><span class="s1">].append(results.params)</span>

            <span class="s3">if not </span><span class="s1">i == maxiter-</span><span class="s4">1</span><span class="s1">:  </span><span class="s0">#skip for last iteration, could break instead</span>
                <span class="s0">#print 'ols',</span>
                <span class="s1">self.results_old = results </span><span class="s0">#store previous results for debugging</span>

                <span class="s0">#get cov from residuals of previous regression</span>
                <span class="s1">sigma_i = self.get_within_cov(results.resid)</span>
                <span class="s1">self.cholsigmainv_i = np.linalg.cholesky(np.linalg.pinv(sigma_i)).T</span>

                <span class="s0">#calculate new whitened endog and exog</span>
                <span class="s1">self.initialize()</span>

        <span class="s0">#note results is the wrapper, results._results is the results instance</span>
        <span class="s0">#results._results.results_residual_regression = res_resid</span>
        <span class="s3">return </span><span class="s1">results</span>
</pre>
</body>
</html>
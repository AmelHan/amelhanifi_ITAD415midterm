<html>
<head>
<title>_onenormest.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_onenormest.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Sparse block 1-norm estimator. 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy.sparse.linalg </span><span class="s2">import </span><span class="s1">aslinearoperator</span>


<span class="s1">__all__ = [</span><span class="s3">'onenormest'</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">onenormest(A</span><span class="s2">, </span><span class="s1">t=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">itmax=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">compute_v=</span><span class="s2">False, </span><span class="s1">compute_w=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Compute a lower bound of the 1-norm of a sparse matrix. 
 
    Parameters 
    ---------- 
    A : ndarray or other linear operator 
        A linear operator that can be transposed and that can 
        produce matrix products. 
    t : int, optional 
        A positive parameter controlling the tradeoff between 
        accuracy versus time and memory usage. 
        Larger values take longer and use more memory 
        but give more accurate output. 
    itmax : int, optional 
        Use at most this many iterations. 
    compute_v : bool, optional 
        Request a norm-maximizing linear operator input vector if True. 
    compute_w : bool, optional 
        Request a norm-maximizing linear operator output vector if True. 
 
    Returns 
    ------- 
    est : float 
        An underestimate of the 1-norm of the sparse matrix. 
    v : ndarray, optional 
        The vector such that ||Av||_1 == est*||v||_1. 
        It can be thought of as an input to the linear operator 
        that gives an output with particularly large norm. 
    w : ndarray, optional 
        The vector Av which has relatively large 1-norm. 
        It can be thought of as an output of the linear operator 
        that is relatively large in norm compared to the input. 
 
    Notes 
    ----- 
    This is algorithm 2.4 of [1]. 
 
    In [2] it is described as follows. 
    &quot;This algorithm typically requires the evaluation of 
    about 4t matrix-vector products and almost invariably 
    produces a norm estimate (which is, in fact, a lower 
    bound on the norm) correct to within a factor 3.&quot; 
 
    .. versionadded:: 0.13.0 
 
    References 
    ---------- 
    .. [1] Nicholas J. Higham and Francoise Tisseur (2000), 
           &quot;A Block Algorithm for Matrix 1-Norm Estimation, 
           with an Application to 1-Norm Pseudospectra.&quot; 
           SIAM J. Matrix Anal. Appl. Vol. 21, No. 4, pp. 1185-1201. 
 
    .. [2] Awad H. Al-Mohy and Nicholas J. Higham (2009), 
           &quot;A new scaling and squaring algorithm for the matrix exponential.&quot; 
           SIAM J. Matrix Anal. Appl. Vol. 31, No. 3, pp. 970-989. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.sparse import csc_matrix 
    &gt;&gt;&gt; from scipy.sparse.linalg import onenormest 
    &gt;&gt;&gt; A = csc_matrix([[1., 0., 0.], [5., 8., 2.], [0., -1., 0.]], dtype=float) 
    &gt;&gt;&gt; A.toarray() 
    array([[ 1.,  0.,  0.], 
           [ 5.,  8.,  2.], 
           [ 0., -1.,  0.]]) 
    &gt;&gt;&gt; onenormest(A) 
    9.0 
    &gt;&gt;&gt; np.linalg.norm(A.toarray(), ord=1) 
    9.0 
    &quot;&quot;&quot;</span>

    <span class="s5"># Check the input.</span>
    <span class="s1">A = aslinearoperator(A)</span>
    <span class="s2">if </span><span class="s1">A.shape[</span><span class="s4">0</span><span class="s1">] != A.shape[</span><span class="s4">1</span><span class="s1">]:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'expected the operator to act like a square matrix'</span><span class="s1">)</span>

    <span class="s5"># If the operator size is small compared to t,</span>
    <span class="s5"># then it is easier to compute the exact norm.</span>
    <span class="s5"># Otherwise estimate the norm.</span>
    <span class="s1">n = A.shape[</span><span class="s4">1</span><span class="s1">]</span>
    <span class="s2">if </span><span class="s1">t &gt;= n:</span>
        <span class="s1">A_explicit = np.asarray(aslinearoperator(A).matmat(np.identity(n)))</span>
        <span class="s2">if </span><span class="s1">A_explicit.shape != (n</span><span class="s2">, </span><span class="s1">n):</span>
            <span class="s2">raise </span><span class="s1">Exception(</span><span class="s3">'internal error: '</span><span class="s2">,</span>
                    <span class="s3">'unexpected shape ' </span><span class="s1">+ str(A_explicit.shape))</span>
        <span class="s1">col_abs_sums = abs(A_explicit).sum(axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">col_abs_sums.shape != (n</span><span class="s2">, </span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">Exception(</span><span class="s3">'internal error: '</span><span class="s2">,</span>
                    <span class="s3">'unexpected shape ' </span><span class="s1">+ str(col_abs_sums.shape))</span>
        <span class="s1">argmax_j = np.argmax(col_abs_sums)</span>
        <span class="s1">v = elementary_vector(n</span><span class="s2">, </span><span class="s1">argmax_j)</span>
        <span class="s1">w = A_explicit[:</span><span class="s2">, </span><span class="s1">argmax_j]</span>
        <span class="s1">est = col_abs_sums[argmax_j]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">est</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">w</span><span class="s2">, </span><span class="s1">nmults</span><span class="s2">, </span><span class="s1">nresamples = _onenormest_core(A</span><span class="s2">, </span><span class="s1">A.H</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">itmax)</span>

    <span class="s5"># Report the norm estimate along with some certificates of the estimate.</span>
    <span class="s2">if </span><span class="s1">compute_v </span><span class="s2">or </span><span class="s1">compute_w:</span>
        <span class="s1">result = (est</span><span class="s2">,</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">compute_v:</span>
            <span class="s1">result += (v</span><span class="s2">,</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">compute_w:</span>
            <span class="s1">result += (w</span><span class="s2">,</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">est</span>


<span class="s2">def </span><span class="s1">_blocked_elementwise(func):</span>
    <span class="s0">&quot;&quot;&quot; 
    Decorator for an elementwise function, to apply it blockwise along 
    first dimension, to avoid excessive memory usage in temporaries. 
    &quot;&quot;&quot;</span>
    <span class="s1">block_size = </span><span class="s4">2</span><span class="s1">**</span><span class="s4">20</span>

    <span class="s2">def </span><span class="s1">wrapper(x):</span>
        <span class="s2">if </span><span class="s1">x.shape[</span><span class="s4">0</span><span class="s1">] &lt; block_size:</span>
            <span class="s2">return </span><span class="s1">func(x)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">y0 = func(x[:block_size])</span>
            <span class="s1">y = np.zeros((x.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">) + y0.shape[</span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">dtype=y0.dtype)</span>
            <span class="s1">y[:block_size] = y0</span>
            <span class="s2">del </span><span class="s1">y0</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(block_size</span><span class="s2">, </span><span class="s1">x.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">block_size):</span>
                <span class="s1">y[j:j+block_size] = func(x[j:j+block_size])</span>
            <span class="s2">return </span><span class="s1">y</span>
    <span class="s2">return </span><span class="s1">wrapper</span>


<span class="s1">@_blocked_elementwise</span>
<span class="s2">def </span><span class="s1">sign_round_up(X):</span>
    <span class="s0">&quot;&quot;&quot; 
    This should do the right thing for both real and complex matrices. 
 
    From Higham and Tisseur: 
    &quot;Everything in this section remains valid for complex matrices 
    provided that sign(A) is redefined as the matrix (aij / |aij|) 
    (and sign(0) = 1) transposes are replaced by conjugate transposes.&quot; 
 
    &quot;&quot;&quot;</span>
    <span class="s1">Y = X.copy()</span>
    <span class="s1">Y[Y == </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">1</span>
    <span class="s1">Y /= np.abs(Y)</span>
    <span class="s2">return </span><span class="s1">Y</span>


<span class="s1">@_blocked_elementwise</span>
<span class="s2">def </span><span class="s1">_max_abs_axis1(X):</span>
    <span class="s2">return </span><span class="s1">np.max(np.abs(X)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_sum_abs_axis0(X):</span>
    <span class="s1">block_size = </span><span class="s4">2</span><span class="s1">**</span><span class="s4">20</span>
    <span class="s1">r = </span><span class="s2">None</span>
    <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">X.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">block_size):</span>
        <span class="s1">y = np.sum(np.abs(X[j:j+block_size])</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">r </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">r = y</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">r += y</span>
    <span class="s2">return </span><span class="s1">r</span>


<span class="s2">def </span><span class="s1">elementary_vector(n</span><span class="s2">, </span><span class="s1">i):</span>
    <span class="s1">v = np.zeros(n</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s1">v[i] = </span><span class="s4">1</span>
    <span class="s2">return </span><span class="s1">v</span>


<span class="s2">def </span><span class="s1">vectors_are_parallel(v</span><span class="s2">, </span><span class="s1">w):</span>
    <span class="s5"># Columns are considered parallel when they are equal or negative.</span>
    <span class="s5"># Entries are required to be in {-1, 1},</span>
    <span class="s5"># which guarantees that the magnitudes of the vectors are identical.</span>
    <span class="s2">if </span><span class="s1">v.ndim != </span><span class="s4">1 </span><span class="s2">or </span><span class="s1">v.shape != w.shape:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'expected conformant vectors with entries in {-1,1}'</span><span class="s1">)</span>
    <span class="s1">n = v.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s2">return </span><span class="s1">np.dot(v</span><span class="s2">, </span><span class="s1">w) == n</span>


<span class="s2">def </span><span class="s1">every_col_of_X_is_parallel_to_a_col_of_Y(X</span><span class="s2">, </span><span class="s1">Y):</span>
    <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">X.T:</span>
        <span class="s2">if not </span><span class="s1">any(vectors_are_parallel(v</span><span class="s2">, </span><span class="s1">w) </span><span class="s2">for </span><span class="s1">w </span><span class="s2">in </span><span class="s1">Y.T):</span>
            <span class="s2">return False</span>
    <span class="s2">return True</span>


<span class="s2">def </span><span class="s1">column_needs_resampling(i</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s5"># column i of X needs resampling if either</span>
    <span class="s5"># it is parallel to a previous column of X or</span>
    <span class="s5"># it is parallel to a column of Y</span>
    <span class="s1">n</span><span class="s2">, </span><span class="s1">t = X.shape</span>
    <span class="s1">v = X[:</span><span class="s2">, </span><span class="s1">i]</span>
    <span class="s2">if </span><span class="s1">any(vectors_are_parallel(v</span><span class="s2">, </span><span class="s1">X[:</span><span class="s2">, </span><span class="s1">j]) </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(i)):</span>
        <span class="s2">return True</span>
    <span class="s2">if </span><span class="s1">Y </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">any(vectors_are_parallel(v</span><span class="s2">, </span><span class="s1">w) </span><span class="s2">for </span><span class="s1">w </span><span class="s2">in </span><span class="s1">Y.T):</span>
            <span class="s2">return True</span>
    <span class="s2">return False</span>


<span class="s2">def </span><span class="s1">resample_column(i</span><span class="s2">, </span><span class="s1">X):</span>
    <span class="s1">X[:</span><span class="s2">, </span><span class="s1">i] = np.random.randint(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">size=X.shape[</span><span class="s4">0</span><span class="s1">])*</span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span>


<span class="s2">def </span><span class="s1">less_than_or_close(a</span><span class="s2">, </span><span class="s1">b):</span>
    <span class="s2">return </span><span class="s1">np.allclose(a</span><span class="s2">, </span><span class="s1">b) </span><span class="s2">or </span><span class="s1">(a &lt; b)</span>


<span class="s2">def </span><span class="s1">_algorithm_2_2(A</span><span class="s2">, </span><span class="s1">AT</span><span class="s2">, </span><span class="s1">t):</span>
    <span class="s0">&quot;&quot;&quot; 
    This is Algorithm 2.2. 
 
    Parameters 
    ---------- 
    A : ndarray or other linear operator 
        A linear operator that can produce matrix products. 
    AT : ndarray or other linear operator 
        The transpose of A. 
    t : int, optional 
        A positive parameter controlling the tradeoff between 
        accuracy versus time and memory usage. 
 
    Returns 
    ------- 
    g : sequence 
        A non-negative decreasing vector 
        such that g[j] is a lower bound for the 1-norm 
        of the column of A of jth largest 1-norm. 
        The first entry of this vector is therefore a lower bound 
        on the 1-norm of the linear operator A. 
        This sequence has length t. 
    ind : sequence 
        The ith entry of ind is the index of the column A whose 1-norm 
        is given by g[i]. 
        This sequence of indices has length t, and its entries are 
        chosen from range(n), possibly with repetition, 
        where n is the order of the operator A. 
 
    Notes 
    ----- 
    This algorithm is mainly for testing. 
    It uses the 'ind' array in a way that is similar to 
    its usage in algorithm 2.4. This algorithm 2.2 may be easier to test, 
    so it gives a chance of uncovering bugs related to indexing 
    which could have propagated less noticeably to algorithm 2.4. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">A_linear_operator = aslinearoperator(A)</span>
    <span class="s1">AT_linear_operator = aslinearoperator(AT)</span>
    <span class="s1">n = A_linear_operator.shape[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s5"># Initialize the X block with columns of unit 1-norm.</span>
    <span class="s1">X = np.ones((n</span><span class="s2">, </span><span class="s1">t))</span>
    <span class="s2">if </span><span class="s1">t &gt; </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">X[:</span><span class="s2">, </span><span class="s4">1</span><span class="s1">:] = np.random.randint(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">size=(n</span><span class="s2">, </span><span class="s1">t-</span><span class="s4">1</span><span class="s1">))*</span><span class="s4">2 </span><span class="s1">- </span><span class="s4">1</span>
    <span class="s1">X /= float(n)</span>

    <span class="s5"># Iteratively improve the lower bounds.</span>
    <span class="s5"># Track extra things, to assert invariants for debugging.</span>
    <span class="s1">g_prev = </span><span class="s2">None</span>
    <span class="s1">h_prev = </span><span class="s2">None</span>
    <span class="s1">k = </span><span class="s4">1</span>
    <span class="s1">ind = range(t)</span>
    <span class="s2">while True</span><span class="s1">:</span>
        <span class="s1">Y = np.asarray(A_linear_operator.matmat(X))</span>
        <span class="s1">g = _sum_abs_axis0(Y)</span>
        <span class="s1">best_j = np.argmax(g)</span>
        <span class="s1">g.sort()</span>
        <span class="s1">g = g[::-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">S = sign_round_up(Y)</span>
        <span class="s1">Z = np.asarray(AT_linear_operator.matmat(S))</span>
        <span class="s1">h = _max_abs_axis1(Z)</span>

        <span class="s5"># If this algorithm runs for fewer than two iterations,</span>
        <span class="s5"># then its return values do not have the properties indicated</span>
        <span class="s5"># in the description of the algorithm.</span>
        <span class="s5"># In particular, the entries of g are not 1-norms of any</span>
        <span class="s5"># column of A until the second iteration.</span>
        <span class="s5"># Therefore we will require the algorithm to run for at least</span>
        <span class="s5"># two iterations, even though this requirement is not stated</span>
        <span class="s5"># in the description of the algorithm.</span>
        <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">less_than_or_close(max(h)</span><span class="s2">, </span><span class="s1">np.dot(Z[:</span><span class="s2">, </span><span class="s1">best_j]</span><span class="s2">, </span><span class="s1">X[:</span><span class="s2">, </span><span class="s1">best_j])):</span>
                <span class="s2">break</span>
        <span class="s1">ind = np.argsort(h)[::-</span><span class="s4">1</span><span class="s1">][:t]</span>
        <span class="s1">h = h[ind]</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(t):</span>
            <span class="s1">X[:</span><span class="s2">, </span><span class="s1">j] = elementary_vector(n</span><span class="s2">, </span><span class="s1">ind[j])</span>

        <span class="s5"># Check invariant (2.2).</span>
        <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">less_than_or_close(g_prev[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">h_prev[</span><span class="s4">0</span><span class="s1">]):</span>
                <span class="s2">raise </span><span class="s1">Exception(</span><span class="s3">'invariant (2.2) is violated'</span><span class="s1">)</span>
            <span class="s2">if not </span><span class="s1">less_than_or_close(h_prev[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">g[</span><span class="s4">0</span><span class="s1">]):</span>
                <span class="s2">raise </span><span class="s1">Exception(</span><span class="s3">'invariant (2.2) is violated'</span><span class="s1">)</span>

        <span class="s5"># Check invariant (2.3).</span>
        <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">3</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(t):</span>
                <span class="s2">if not </span><span class="s1">less_than_or_close(g[j]</span><span class="s2">, </span><span class="s1">g_prev[j]):</span>
                    <span class="s2">raise </span><span class="s1">Exception(</span><span class="s3">'invariant (2.3) is violated'</span><span class="s1">)</span>

        <span class="s5"># Update for the next iteration.</span>
        <span class="s1">g_prev = g</span>
        <span class="s1">h_prev = h</span>
        <span class="s1">k += </span><span class="s4">1</span>

    <span class="s5"># Return the lower bounds and the corresponding column indices.</span>
    <span class="s2">return </span><span class="s1">g</span><span class="s2">, </span><span class="s1">ind</span>


<span class="s2">def </span><span class="s1">_onenormest_core(A</span><span class="s2">, </span><span class="s1">AT</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">itmax):</span>
    <span class="s0">&quot;&quot;&quot; 
    Compute a lower bound of the 1-norm of a sparse matrix. 
 
    Parameters 
    ---------- 
    A : ndarray or other linear operator 
        A linear operator that can produce matrix products. 
    AT : ndarray or other linear operator 
        The transpose of A. 
    t : int, optional 
        A positive parameter controlling the tradeoff between 
        accuracy versus time and memory usage. 
    itmax : int, optional 
        Use at most this many iterations. 
 
    Returns 
    ------- 
    est : float 
        An underestimate of the 1-norm of the sparse matrix. 
    v : ndarray, optional 
        The vector such that ||Av||_1 == est*||v||_1. 
        It can be thought of as an input to the linear operator 
        that gives an output with particularly large norm. 
    w : ndarray, optional 
        The vector Av which has relatively large 1-norm. 
        It can be thought of as an output of the linear operator 
        that is relatively large in norm compared to the input. 
    nmults : int, optional 
        The number of matrix products that were computed. 
    nresamples : int, optional 
        The number of times a parallel column was observed, 
        necessitating a re-randomization of the column. 
 
    Notes 
    ----- 
    This is algorithm 2.4. 
 
    &quot;&quot;&quot;</span>
    <span class="s5"># This function is a more or less direct translation</span>
    <span class="s5"># of Algorithm 2.4 from the Higham and Tisseur (2000) paper.</span>
    <span class="s1">A_linear_operator = aslinearoperator(A)</span>
    <span class="s1">AT_linear_operator = aslinearoperator(AT)</span>
    <span class="s2">if </span><span class="s1">itmax &lt; </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'at least two iterations are required'</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">t &lt; </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'at least one column is required'</span><span class="s1">)</span>
    <span class="s1">n = A.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s2">if </span><span class="s1">t &gt;= n:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'t should be smaller than the order of A'</span><span class="s1">)</span>
    <span class="s5"># Track the number of big*small matrix multiplications</span>
    <span class="s5"># and the number of resamplings.</span>
    <span class="s1">nmults = </span><span class="s4">0</span>
    <span class="s1">nresamples = </span><span class="s4">0</span>
    <span class="s5"># &quot;We now explain our choice of starting matrix.  We take the first</span>
    <span class="s5"># column of X to be the vector of 1s [...] This has the advantage that</span>
    <span class="s5"># for a matrix with nonnegative elements the algorithm converges</span>
    <span class="s5"># with an exact estimate on the second iteration, and such matrices</span>
    <span class="s5"># arise in applications [...]&quot;</span>
    <span class="s1">X = np.ones((n</span><span class="s2">, </span><span class="s1">t)</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s5"># &quot;The remaining columns are chosen as rand{-1,1},</span>
    <span class="s5"># with a check for and correction of parallel columns,</span>
    <span class="s5"># exactly as for S in the body of the algorithm.&quot;</span>
    <span class="s2">if </span><span class="s1">t &gt; </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">t):</span>
            <span class="s5"># These are technically initial samples, not resamples,</span>
            <span class="s5"># so the resampling count is not incremented.</span>
            <span class="s1">resample_column(i</span><span class="s2">, </span><span class="s1">X)</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(t):</span>
            <span class="s2">while </span><span class="s1">column_needs_resampling(i</span><span class="s2">, </span><span class="s1">X):</span>
                <span class="s1">resample_column(i</span><span class="s2">, </span><span class="s1">X)</span>
                <span class="s1">nresamples += </span><span class="s4">1</span>
    <span class="s5"># &quot;Choose starting matrix X with columns of unit 1-norm.&quot;</span>
    <span class="s1">X /= float(n)</span>
    <span class="s5"># &quot;indices of used unit vectors e_j&quot;</span>
    <span class="s1">ind_hist = np.zeros(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">dtype=np.intp)</span>
    <span class="s1">est_old = </span><span class="s4">0</span>
    <span class="s1">S = np.zeros((n</span><span class="s2">, </span><span class="s1">t)</span><span class="s2">, </span><span class="s1">dtype=float)</span>
    <span class="s1">k = </span><span class="s4">1</span>
    <span class="s1">ind = </span><span class="s2">None</span>
    <span class="s2">while True</span><span class="s1">:</span>
        <span class="s1">Y = np.asarray(A_linear_operator.matmat(X))</span>
        <span class="s1">nmults += </span><span class="s4">1</span>
        <span class="s1">mags = _sum_abs_axis0(Y)</span>
        <span class="s1">est = np.max(mags)</span>
        <span class="s1">best_j = np.argmax(mags)</span>
        <span class="s2">if </span><span class="s1">est &gt; est_old </span><span class="s2">or </span><span class="s1">k == </span><span class="s4">2</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">2</span><span class="s1">:</span>
                <span class="s1">ind_best = ind[best_j]</span>
            <span class="s1">w = Y[:</span><span class="s2">, </span><span class="s1">best_j]</span>
        <span class="s5"># (1)</span>
        <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">2 </span><span class="s2">and </span><span class="s1">est &lt;= est_old:</span>
            <span class="s1">est = est_old</span>
            <span class="s2">break</span>
        <span class="s1">est_old = est</span>
        <span class="s1">S_old = S</span>
        <span class="s2">if </span><span class="s1">k &gt; itmax:</span>
            <span class="s2">break</span>
        <span class="s1">S = sign_round_up(Y)</span>
        <span class="s2">del </span><span class="s1">Y</span>
        <span class="s5"># (2)</span>
        <span class="s2">if </span><span class="s1">every_col_of_X_is_parallel_to_a_col_of_Y(S</span><span class="s2">, </span><span class="s1">S_old):</span>
            <span class="s2">break</span>
        <span class="s2">if </span><span class="s1">t &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s5"># &quot;Ensure that no column of S is parallel to another column of S</span>
            <span class="s5"># or to a column of S_old by replacing columns of S by rand{-1,1}.&quot;</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(t):</span>
                <span class="s2">while </span><span class="s1">column_needs_resampling(i</span><span class="s2">, </span><span class="s1">S</span><span class="s2">, </span><span class="s1">S_old):</span>
                    <span class="s1">resample_column(i</span><span class="s2">, </span><span class="s1">S)</span>
                    <span class="s1">nresamples += </span><span class="s4">1</span>
        <span class="s2">del </span><span class="s1">S_old</span>
        <span class="s5"># (3)</span>
        <span class="s1">Z = np.asarray(AT_linear_operator.matmat(S))</span>
        <span class="s1">nmults += </span><span class="s4">1</span>
        <span class="s1">h = _max_abs_axis1(Z)</span>
        <span class="s2">del </span><span class="s1">Z</span>
        <span class="s5"># (4)</span>
        <span class="s2">if </span><span class="s1">k &gt;= </span><span class="s4">2 </span><span class="s2">and </span><span class="s1">max(h) == h[ind_best]:</span>
            <span class="s2">break</span>
        <span class="s5"># &quot;Sort h so that h_first &gt;= ... &gt;= h_last</span>
        <span class="s5"># and re-order ind correspondingly.&quot;</span>
        <span class="s5">#</span>
        <span class="s5"># Later on, we will need at most t+len(ind_hist) largest</span>
        <span class="s5"># entries, so drop the rest</span>
        <span class="s1">ind = np.argsort(h)[::-</span><span class="s4">1</span><span class="s1">][:t+len(ind_hist)].copy()</span>
        <span class="s2">del </span><span class="s1">h</span>
        <span class="s2">if </span><span class="s1">t &gt; </span><span class="s4">1</span><span class="s1">:</span>
            <span class="s5"># (5)</span>
            <span class="s5"># Break if the most promising t vectors have been visited already.</span>
            <span class="s2">if </span><span class="s1">np.in1d(ind[:t]</span><span class="s2">, </span><span class="s1">ind_hist).all():</span>
                <span class="s2">break</span>
            <span class="s5"># Put the most promising unvisited vectors at the front of the list</span>
            <span class="s5"># and put the visited vectors at the end of the list.</span>
            <span class="s5"># Preserve the order of the indices induced by the ordering of h.</span>
            <span class="s1">seen = np.in1d(ind</span><span class="s2">, </span><span class="s1">ind_hist)</span>
            <span class="s1">ind = np.concatenate((ind[~seen]</span><span class="s2">, </span><span class="s1">ind[seen]))</span>
        <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(t):</span>
            <span class="s1">X[:</span><span class="s2">, </span><span class="s1">j] = elementary_vector(n</span><span class="s2">, </span><span class="s1">ind[j])</span>

        <span class="s1">new_ind = ind[:t][~np.in1d(ind[:t]</span><span class="s2">, </span><span class="s1">ind_hist)]</span>
        <span class="s1">ind_hist = np.concatenate((ind_hist</span><span class="s2">, </span><span class="s1">new_ind))</span>
        <span class="s1">k += </span><span class="s4">1</span>
    <span class="s1">v = elementary_vector(n</span><span class="s2">, </span><span class="s1">ind_best)</span>
    <span class="s2">return </span><span class="s1">est</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, </span><span class="s1">w</span><span class="s2">, </span><span class="s1">nmults</span><span class="s2">, </span><span class="s1">nresamples</span>
</pre>
</body>
</html>
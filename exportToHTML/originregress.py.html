<html>
<head>
<title>originregress.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
originregress.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
This module implements empirical likelihood regression that is forced through 
the origin. 
 
This is different than regression not forced through the origin because the 
maximum empirical likelihood estimate is calculated with a vector of ones in 
the exogenous matrix but restricts the intercept parameter to be 0.  This 
results in significantly more narrow confidence intervals and different 
parameter estimates. 
 
For notes on regression not forced through the origin, see empirical likelihood 
methods in the OLSResults class. 
 
General References 
------------------ 
Owen, A.B. (2001). Empirical Likelihood.  Chapman and Hall. p. 82. 
 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">optimize</span>
<span class="s2">from </span><span class="s1">scipy.stats </span><span class="s2">import </span><span class="s1">chi2</span>

<span class="s2">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s2">import </span><span class="s1">OLS</span><span class="s2">, </span><span class="s1">RegressionResults</span>
<span class="s3"># When descriptive merged, this will be changed</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.tools </span><span class="s2">import </span><span class="s1">add_constant</span>


<span class="s2">class </span><span class="s1">ELOriginRegress:</span>
    <span class="s0">&quot;&quot;&quot; 
    Empirical Likelihood inference and estimation for linear regression 
    through the origin. 
 
    Parameters 
    ---------- 
    endog: nx1 array 
        Array of response variables. 
 
    exog: nxk array 
        Array of exogenous variables.  Assumes no array of ones 
 
    Attributes 
    ---------- 
    endog : nx1 array 
        Array of response variables 
 
    exog : nxk array 
        Array of exogenous variables.  Assumes no array of ones. 
 
    nobs : float 
        Number of observations. 
 
    nvar : float 
        Number of exogenous regressors. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog):</span>
        <span class="s1">self.endog = endog</span>
        <span class="s1">self.exog = exog</span>
        <span class="s1">self.nobs = self.exog.shape[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">self.nvar = float(exog.shape[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s2">except </span><span class="s1">IndexError:</span>
            <span class="s1">self.nvar = </span><span class="s4">1.</span>

    <span class="s2">def </span><span class="s1">fit(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fits the model and provides regression results. 
 
        Returns 
        ------- 
        Results : class 
            Empirical likelihood regression class. 
        &quot;&quot;&quot;</span>
        <span class="s1">exog_with = add_constant(self.exog</span><span class="s2">, </span><span class="s1">prepend=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">restricted_model = OLS(self.endog</span><span class="s2">, </span><span class="s1">exog_with)</span>
        <span class="s1">restricted_fit = restricted_model.fit()</span>
        <span class="s1">restricted_el = restricted_fit.el_test(</span>
        <span class="s1">np.array([</span><span class="s4">0</span><span class="s1">])</span><span class="s2">, </span><span class="s1">np.array([</span><span class="s4">0</span><span class="s1">])</span><span class="s2">, </span><span class="s1">ret_params=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">params = np.squeeze(restricted_el[</span><span class="s4">3</span><span class="s1">])</span>
        <span class="s1">beta_hat_llr = restricted_el[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">llf = np.sum(np.log(restricted_el[</span><span class="s4">2</span><span class="s1">]))</span>
        <span class="s2">return </span><span class="s1">OriginResults(restricted_model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">beta_hat_llr</span><span class="s2">, </span><span class="s1">llf)</span>

    <span class="s2">def </span><span class="s1">predict(self</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">exog=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s1">exog </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exog = self.exog</span>
        <span class="s2">return </span><span class="s1">np.dot(add_constant(exog</span><span class="s2">, </span><span class="s1">prepend=</span><span class="s2">True</span><span class="s1">)</span><span class="s2">, </span><span class="s1">params)</span>


<span class="s2">class </span><span class="s1">OriginResults(RegressionResults):</span>
    <span class="s0">&quot;&quot;&quot; 
    A Results class for empirical likelihood regression through the origin. 
 
    Parameters 
    ---------- 
    model : class 
        An OLS model with an intercept. 
 
    params : 1darray 
        Fitted parameters. 
 
    est_llr : float 
        The log likelihood ratio of the model with the intercept restricted to 
        0 at the maximum likelihood estimates of the parameters. 
        llr_restricted/llr_unrestricted 
 
    llf_el : float 
        The log likelihood of the fitted model with the intercept restricted to 0. 
 
    Attributes 
    ---------- 
    model : class 
        An OLS model with an intercept. 
 
    params : 1darray 
        Fitted parameter. 
 
    llr : float 
        The log likelihood ratio of the maximum empirical likelihood estimate. 
 
    llf_el : float 
        The log likelihood of the fitted model with the intercept restricted to 0. 
 
    Notes 
    ----- 
    IMPORTANT.  Since EL estimation does not drop the intercept parameter but 
    instead estimates the slope parameters conditional on the slope parameter 
    being 0, the first element for params will be the intercept, which is 
    restricted to 0. 
 
    IMPORTANT.  This class inherits from RegressionResults but inference is 
    conducted via empirical likelihood.  Therefore, any methods that 
    require an estimate of the covariance matrix will not function.  Instead 
    use el_test and conf_int_el to conduct inference. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; data = sm.datasets.bc.load() 
    &gt;&gt;&gt; model = sm.emplike.ELOriginRegress(data.endog, data.exog) 
    &gt;&gt;&gt; fitted = model.fit() 
    &gt;&gt;&gt; fitted.params #  0 is the intercept term. 
    array([ 0.        ,  0.00351813]) 
 
    &gt;&gt;&gt; fitted.el_test(np.array([.0034]), np.array([1])) 
    (3.6696503297979302, 0.055411808127497755) 
    &gt;&gt;&gt; fitted.conf_int_el(1) 
    (0.0033971871114706867, 0.0036373150174892847) 
 
    # No covariance matrix so normal inference is not valid 
    &gt;&gt;&gt; fitted.conf_int() 
    TypeError: unsupported operand type(s) for *: 'instancemethod' and 'float' 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">est_llr</span><span class="s2">, </span><span class="s1">llf_el):</span>
        <span class="s1">self.model = model</span>
        <span class="s1">self.params = np.squeeze(params)</span>
        <span class="s1">self.llr = est_llr</span>
        <span class="s1">self.llf_el = llf_el</span>
    <span class="s2">def </span><span class="s1">el_test(self</span><span class="s2">, </span><span class="s1">b0_vals</span><span class="s2">, </span><span class="s1">param_nums</span><span class="s2">, </span><span class="s1">method=</span><span class="s5">'nm'</span><span class="s2">,</span>
                            <span class="s1">stochastic_exog=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">return_weights=</span><span class="s4">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the llr and p-value for a hypothesized parameter value 
        for a regression that goes through the origin. 
 
        Parameters 
        ---------- 
        b0_vals : 1darray 
            The hypothesized value to be tested. 
 
        param_num : 1darray 
            Which parameters to test.  Note this uses python 
            indexing but the '0' parameter refers to the intercept term, 
            which is assumed 0.  Therefore, param_num should be &gt; 0. 
 
        return_weights : bool 
            If true, returns the weights that optimize the likelihood 
            ratio at b0_vals.  Default is False. 
 
        method : str 
            Can either be 'nm' for Nelder-Mead or 'powell' for Powell.  The 
            optimization method that optimizes over nuisance parameters. 
            Default is 'nm'. 
 
        stochastic_exog : bool 
            When TRUE, the exogenous variables are assumed to be stochastic. 
            When the regressors are nonstochastic, moment conditions are 
            placed on the exogenous variables.  Confidence intervals for 
            stochastic regressors are at least as large as non-stochastic 
            regressors.  Default is TRUE. 
 
        Returns 
        ------- 
        res : tuple 
            pvalue and likelihood ratio. 
        &quot;&quot;&quot;</span>
        <span class="s1">b0_vals = np.hstack((</span><span class="s4">0</span><span class="s2">, </span><span class="s1">b0_vals))</span>
        <span class="s1">param_nums = np.hstack((</span><span class="s4">0</span><span class="s2">, </span><span class="s1">param_nums))</span>
        <span class="s1">test_res = self.model.fit().el_test(b0_vals</span><span class="s2">, </span><span class="s1">param_nums</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">,</span>
                                  <span class="s1">stochastic_exog=stochastic_exog</span><span class="s2">,</span>
                                  <span class="s1">return_weights=return_weights)</span>
        <span class="s1">llr_test = test_res[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">llr_res = llr_test - self.llr</span>
        <span class="s1">pval = chi2.sf(llr_res</span><span class="s2">, </span><span class="s1">self.model.exog.shape[</span><span class="s4">1</span><span class="s1">] - </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">return_weights:</span>
            <span class="s2">return </span><span class="s1">llr_res</span><span class="s2">, </span><span class="s1">pval</span><span class="s2">, </span><span class="s1">test_res[</span><span class="s4">2</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">llr_res</span><span class="s2">, </span><span class="s1">pval</span>

    <span class="s2">def </span><span class="s1">conf_int_el(self</span><span class="s2">, </span><span class="s1">param_num</span><span class="s2">, </span><span class="s1">upper_bound=</span><span class="s2">None,</span>
                       <span class="s1">lower_bound=</span><span class="s2">None, </span><span class="s1">sig=</span><span class="s4">.05</span><span class="s2">, </span><span class="s1">method=</span><span class="s5">'nm'</span><span class="s2">,</span>
                       <span class="s1">stochastic_exog=</span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the confidence interval for a regression parameter when the 
        regression is forced through the origin. 
 
        Parameters 
        ---------- 
        param_num : int 
            The parameter number to be tested.  Note this uses python 
            indexing but the '0' parameter refers to the intercept term. 
 
        upper_bound : float 
            The maximum value the upper confidence limit can be.  The 
            closer this is to the confidence limit, the quicker the 
            computation.  Default is .00001 confidence limit under normality. 
 
        lower_bound : float 
            The minimum value the lower confidence limit can be. 
            Default is .00001 confidence limit under normality. 
 
        sig : float, optional 
            The significance level.  Default .05. 
 
        method : str, optional 
             Algorithm to optimize of nuisance params.  Can be 'nm' or 
            'powell'.  Default is 'nm'. 
 
        Returns 
        ------- 
        ci: tuple 
            The confidence interval for the parameter 'param_num'. 
        &quot;&quot;&quot;</span>
        <span class="s1">r0 = chi2.ppf(</span><span class="s4">1 </span><span class="s1">- sig</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">param_num = np.array([param_num])</span>
        <span class="s2">if </span><span class="s1">upper_bound </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">upper_bound = (np.squeeze(self.model.fit().</span>
                                      <span class="s1">conf_int(</span><span class="s4">.0001</span><span class="s1">)[param_num])[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s2">if </span><span class="s1">lower_bound </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lower_bound = (np.squeeze(self.model.fit().conf_int(</span><span class="s4">.00001</span><span class="s1">)</span>
                                      <span class="s1">[param_num])[</span><span class="s4">0</span><span class="s1">])</span>
        <span class="s1">f = </span><span class="s2">lambda </span><span class="s1">b0:  self.el_test(np.array([b0])</span><span class="s2">, </span><span class="s1">param_num</span><span class="s2">,</span>
                                     <span class="s1">method=method</span><span class="s2">,</span>
                                 <span class="s1">stochastic_exog=stochastic_exog)[</span><span class="s4">0</span><span class="s1">] - r0</span>
        <span class="s1">_param = np.squeeze(self.params[param_num])</span>
        <span class="s1">lowerl = optimize.brentq(f</span><span class="s2">, </span><span class="s1">np.squeeze(lower_bound)</span><span class="s2">, </span><span class="s1">_param)</span>
        <span class="s1">upperl = optimize.brentq(f</span><span class="s2">, </span><span class="s1">_param</span><span class="s2">, </span><span class="s1">np.squeeze(upper_bound))</span>
        <span class="s2">return </span><span class="s1">(lowerl</span><span class="s2">, </span><span class="s1">upperl)</span>
</pre>
</body>
</html>
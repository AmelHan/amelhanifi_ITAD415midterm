<html>
<head>
<title>multivariate_tools.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
multivariate_tools.py</font>
</center></td></tr></table>
<pre><span class="s0">'''Tools for multivariate analysis 
 
 
Author : Josef Perktold 
License : BSD-3 
 
 
 
TODO: 
 
- names of functions, currently just &quot;working titles&quot; 
 
'''</span>



<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">statsmodels.tools.tools </span><span class="s2">import </span><span class="s1">Bunch</span>

<span class="s2">def </span><span class="s1">partial_project(endog</span><span class="s2">, </span><span class="s1">exog):</span>
    <span class="s0">'''helper function to get linear projection or partialling out of variables 
 
    endog variables are projected on exog variables 
 
    Parameters 
    ---------- 
    endog : ndarray 
        array of variables where the effect of exog is partialled out. 
    exog : ndarray 
        array of variables on which the endog variables are projected. 
 
    Returns 
    ------- 
    res : instance of Bunch with 
 
        - params : OLS parameter estimates from projection of endog on exog 
        - fittedvalues : predicted values of endog given exog 
        - resid : residual of the regression, values of endog with effect of 
          exog partialled out 
 
    Notes 
    ----- 
    This is no-frills mainly for internal calculations, no error checking or 
    array conversion is performed, at least for now. 
 
    '''</span>
    <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2 = endog</span><span class="s2">, </span><span class="s1">exog</span>
    <span class="s1">params = np.linalg.pinv(x2).dot(x1)</span>
    <span class="s1">predicted = x2.dot(params)</span>
    <span class="s1">residual = x1 - predicted</span>
    <span class="s1">res = Bunch(params=params</span><span class="s2">,</span>
                <span class="s1">fittedvalues=predicted</span><span class="s2">,</span>
                <span class="s1">resid=residual)</span>

    <span class="s2">return </span><span class="s1">res</span>



<span class="s2">def </span><span class="s1">cancorr(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">demean=</span><span class="s2">True, </span><span class="s1">standardize=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">'''canonical correlation coefficient beween 2 arrays 
 
    Parameters 
    ---------- 
    x1, x2 : ndarrays, 2_D 
        two 2-dimensional data arrays, observations in rows, variables in columns 
    demean : bool 
         If demean is true, then the mean is subtracted from each variable 
    standardize : bool 
         If standardize is true, then each variable is demeaned and divided by 
         its standard deviation. Rescaling does not change the canonical 
         correlation coefficients. 
 
    Returns 
    ------- 
    ccorr : ndarray, 1d 
        canonical correlation coefficients, sorted from largest to smallest. 
        Note, that these are the square root of the eigenvalues. 
 
    Notes 
    ----- 
    This is a helper function for other statistical functions. It only 
    calculates the canonical correlation coefficients and does not do a full 
    canoncial correlation analysis 
 
    The canonical correlation coefficient is calculated with the generalized 
    matrix inverse and does not raise an exception if one of the data arrays 
    have less than full column rank. 
 
    See Also 
    -------- 
    cc_ranktest 
    cc_stats 
    CCA not yet 
 
    '''</span>
    <span class="s3">#x, y = x1, x2</span>
    <span class="s2">if </span><span class="s1">demean </span><span class="s2">or </span><span class="s1">standardize:</span>
        <span class="s1">x1 = (x1 - x1.mean(</span><span class="s4">0</span><span class="s1">))</span>
        <span class="s1">x2 = (x2 - x2.mean(</span><span class="s4">0</span><span class="s1">))</span>

    <span class="s2">if </span><span class="s1">standardize:</span>
        <span class="s3">#std does not make a difference to canonical correlation coefficients</span>
        <span class="s1">x1 /= x1.std(</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">x2 /= x2.std(</span><span class="s4">0</span><span class="s1">)</span>

    <span class="s1">t1 = np.linalg.pinv(x1).dot(x2)</span>
    <span class="s1">t2 = np.linalg.pinv(x2).dot(x1)</span>
    <span class="s1">m = t1.dot(t2)</span>
    <span class="s1">cc = np.sqrt(np.linalg.eigvals(m))</span>
    <span class="s1">cc.sort()</span>
    <span class="s2">return </span><span class="s1">cc[::-</span><span class="s4">1</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">cc_ranktest(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">demean=</span><span class="s2">True, </span><span class="s1">fullrank=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">'''rank tests based on smallest canonical correlation coefficients 
 
    Anderson canonical correlations test (LM test) and 
    Cragg-Donald test (Wald test) 
    Assumes homoskedasticity and independent observations, overrejects if 
    there is heteroscedasticity or autocorrelation. 
 
    The Null Hypothesis is that the rank is k - 1, the alternative hypothesis 
    is that the rank is at least k. 
 
 
    Parameters 
    ---------- 
    x1, x2 : ndarrays, 2_D 
        two 2-dimensional data arrays, observations in rows, variables in columns 
    demean : bool 
         If demean is true, then the mean is subtracted from each variable. 
    fullrank : bool 
         If true, then only the test that the matrix has full rank is returned. 
         If false, the test for all possible ranks are returned. However, no 
         the p-values are not corrected for the multiplicity of tests. 
 
    Returns 
    ------- 
    value : float 
        value of the test statistic 
    p-value : float 
        p-value for the test Null Hypothesis tha the smallest canonical 
        correlation coefficient is zero. based on chi-square distribution 
    df : int 
        degrees of freedom for thechi-square distribution in the hypothesis test 
    ccorr : ndarray, 1d 
        All canonical correlation coefficients sorted from largest to smallest. 
 
    Notes 
    ----- 
    Degrees of freedom for the distribution of the test statistic are based on 
    number of columns of x1 and x2 and not on their matrix rank. 
    (I'm not sure yet what the interpretation of the test is if x1 or x2 are of 
    reduced rank.) 
 
    See Also 
    -------- 
    cancorr 
    cc_stats 
 
    '''</span>

    <span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">stats</span>

    <span class="s1">nobs1</span><span class="s2">, </span><span class="s1">k1 = x1.shape</span>
    <span class="s1">nobs2</span><span class="s2">, </span><span class="s1">k2 = x2.shape</span>

    <span class="s1">cc = cancorr(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">demean=demean)</span>
    <span class="s1">cc2 = cc * cc</span>
    <span class="s2">if </span><span class="s1">fullrank:</span>
        <span class="s1">df = np.abs(k1 - k2) + </span><span class="s4">1</span>
        <span class="s1">value = nobs1 * cc2[-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">w_value = nobs1 * (cc2[-</span><span class="s4">1</span><span class="s1">] / (</span><span class="s4">1. </span><span class="s1">- cc2[-</span><span class="s4">1</span><span class="s1">]))</span>
        <span class="s2">return </span><span class="s1">value</span><span class="s2">, </span><span class="s1">stats.chi2.sf(value</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">cc</span><span class="s2">, </span><span class="s1">w_value</span><span class="s2">, </span><span class="s1">stats.chi2.sf(w_value</span><span class="s2">, </span><span class="s1">df)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">r = np.arange(min(k1</span><span class="s2">, </span><span class="s1">k2))[::-</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s1">df = (k1 - r) * (k2 - r)</span>
        <span class="s1">values = nobs1 * cc2[::-</span><span class="s4">1</span><span class="s1">].cumsum()</span>
        <span class="s1">w_values = nobs1 * (cc2 / (</span><span class="s4">1. </span><span class="s1">- cc2))[::-</span><span class="s4">1</span><span class="s1">].cumsum()</span>
        <span class="s2">return </span><span class="s1">values</span><span class="s2">, </span><span class="s1">stats.chi2.sf(values</span><span class="s2">, </span><span class="s1">df)</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">cc</span><span class="s2">, </span><span class="s1">w_values</span><span class="s2">, </span><span class="s1">stats.chi2.sf(w_values</span><span class="s2">, </span><span class="s1">df)</span>


<span class="s2">def </span><span class="s1">cc_stats(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">demean=</span><span class="s2">True</span><span class="s1">):</span>
    <span class="s0">'''MANOVA statistics based on canonical correlation coefficient 
 
    Calculates Pillai's Trace, Wilk's Lambda, Hotelling's Trace and 
    Roy's Largest Root. 
 
    Parameters 
    ---------- 
    x1, x2 : ndarrays, 2_D 
        two 2-dimensional data arrays, observations in rows, variables in columns 
    demean : bool 
         If demean is true, then the mean is subtracted from each variable. 
 
    Returns 
    ------- 
    res : dict 
        Dictionary containing the test statistics. 
 
    Notes 
    ----- 
 
    same as `canon` in Stata 
 
    missing: F-statistics and p-values 
 
    TODO: should return a results class instead 
    produces nans sometimes, singular, perfect correlation of x1, x2 ? 
 
    '''</span>

    <span class="s1">nobs1</span><span class="s2">, </span><span class="s1">k1 = x1.shape  </span><span class="s3"># endogenous ?</span>
    <span class="s1">nobs2</span><span class="s2">, </span><span class="s1">k2 = x2.shape</span>
    <span class="s1">cc = cancorr(x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">demean=demean)</span>
    <span class="s1">cc2 = cc**</span><span class="s4">2</span>
    <span class="s1">lam = (cc2 / (</span><span class="s4">1 </span><span class="s1">- cc2))  </span><span class="s3"># what if max cc2 is 1 ?</span>
    <span class="s3"># Problem: ccr might not care if x1 or x2 are reduced rank,</span>
    <span class="s3">#          but df will depend on rank</span>
    <span class="s1">df_model = k1 * k2  </span><span class="s3"># df_hypothesis (we do not include mean in x1, x2)</span>
    <span class="s1">df_resid = k1 * (nobs1 - k2 - demean)</span>
    <span class="s1">s = min(df_model</span><span class="s2">, </span><span class="s1">k1)</span>
    <span class="s1">m = </span><span class="s4">0.5 </span><span class="s1">* (df_model - k1)</span>
    <span class="s1">n = </span><span class="s4">0.5 </span><span class="s1">* (df_resid - k1 - </span><span class="s4">1</span><span class="s1">)</span>

    <span class="s1">df1 = k1 * df_model</span>
    <span class="s1">df2 = k2</span>


    <span class="s1">pt_value = cc2.sum()    </span><span class="s3"># Pillai's trace</span>
    <span class="s1">wl_value = np.product(</span><span class="s4">1 </span><span class="s1">/ (</span><span class="s4">1 </span><span class="s1">+ lam))   </span><span class="s3"># Wilk's Lambda</span>
    <span class="s1">ht_value = lam.sum()    </span><span class="s3"># Hotelling's Trace</span>
    <span class="s1">rm_value = lam.max()    </span><span class="s3"># Roy's largest root</span>
    <span class="s3">#from scipy import stats</span>
    <span class="s3"># what's the distribution, the test statistic ?</span>
    <span class="s1">res = {}</span>
    <span class="s1">res[</span><span class="s5">'canonical correlation coefficient'</span><span class="s1">] = cc</span>
    <span class="s1">res[</span><span class="s5">'eigenvalues'</span><span class="s1">] = lam</span>
    <span class="s1">res[</span><span class="s5">&quot;Pillai's Trace&quot;</span><span class="s1">] = pt_value</span>
    <span class="s1">res[</span><span class="s5">&quot;Wilk's Lambda&quot;</span><span class="s1">] = wl_value</span>
    <span class="s1">res[</span><span class="s5">&quot;Hotelling's Trace&quot;</span><span class="s1">] = ht_value</span>
    <span class="s1">res[</span><span class="s5">&quot;Roy's Largest Root&quot;</span><span class="s1">] = rm_value</span>
    <span class="s1">res[</span><span class="s5">'df_resid'</span><span class="s1">] = df_resid</span>
    <span class="s1">res[</span><span class="s5">'df_m'</span><span class="s1">] = m</span>
    <span class="s2">return </span><span class="s1">res</span>
</pre>
</body>
</html>
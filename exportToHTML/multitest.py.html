<html>
<head>
<title>multitest.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
multitest.py</font>
</center></td></tr></table>
<pre><span class="s0">'''Multiple Testing and P-Value Correction 
 
 
Author: Josef Perktold 
License: BSD-3 
 
'''</span>


<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">statsmodels.stats._knockoff </span><span class="s2">import </span><span class="s1">RegressionFDR</span>

<span class="s1">__all__ = [</span><span class="s3">'fdrcorrection'</span><span class="s2">, </span><span class="s3">'fdrcorrection_twostage'</span><span class="s2">, </span><span class="s3">'local_fdr'</span><span class="s2">,</span>
           <span class="s3">'multipletests'</span><span class="s2">, </span><span class="s3">'NullDistribution'</span><span class="s2">, </span><span class="s3">'RegressionFDR'</span><span class="s1">]</span>

<span class="s4"># ==============================================</span>
<span class="s4">#</span>
<span class="s4"># Part 1: Multiple Tests and P-Value Correction</span>
<span class="s4">#</span>
<span class="s4"># ==============================================</span>


<span class="s2">def </span><span class="s1">_ecdf(x):</span>
    <span class="s0">'''no frills empirical cdf used in fdrcorrection 
    '''</span>
    <span class="s1">nobs = len(x)</span>
    <span class="s2">return </span><span class="s1">np.arange(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">nobs+</span><span class="s5">1</span><span class="s1">)/float(nobs)</span>

<span class="s1">multitest_methods_names = {</span><span class="s3">'b'</span><span class="s1">: </span><span class="s3">'Bonferroni'</span><span class="s2">,</span>
                           <span class="s3">'s'</span><span class="s1">: </span><span class="s3">'Sidak'</span><span class="s2">,</span>
                           <span class="s3">'h'</span><span class="s1">: </span><span class="s3">'Holm'</span><span class="s2">,</span>
                           <span class="s3">'hs'</span><span class="s1">: </span><span class="s3">'Holm-Sidak'</span><span class="s2">,</span>
                           <span class="s3">'sh'</span><span class="s1">: </span><span class="s3">'Simes-Hochberg'</span><span class="s2">,</span>
                           <span class="s3">'ho'</span><span class="s1">: </span><span class="s3">'Hommel'</span><span class="s2">,</span>
                           <span class="s3">'fdr_bh'</span><span class="s1">: </span><span class="s3">'FDR Benjamini-Hochberg'</span><span class="s2">,</span>
                           <span class="s3">'fdr_by'</span><span class="s1">: </span><span class="s3">'FDR Benjamini-Yekutieli'</span><span class="s2">,</span>
                           <span class="s3">'fdr_tsbh'</span><span class="s1">: </span><span class="s3">'FDR 2-stage Benjamini-Hochberg'</span><span class="s2">,</span>
                           <span class="s3">'fdr_tsbky'</span><span class="s1">: </span><span class="s3">'FDR 2-stage Benjamini-Krieger-Yekutieli'</span><span class="s2">,</span>
                           <span class="s3">'fdr_gbs'</span><span class="s1">: </span><span class="s3">'FDR adaptive Gavrilov-Benjamini-Sarkar'</span>
                           <span class="s1">}</span>

<span class="s1">_alias_list = [[</span><span class="s3">'b'</span><span class="s2">, </span><span class="s3">'bonf'</span><span class="s2">, </span><span class="s3">'bonferroni'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'s'</span><span class="s2">, </span><span class="s3">'sidak'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'h'</span><span class="s2">, </span><span class="s3">'holm'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'hs'</span><span class="s2">, </span><span class="s3">'holm-sidak'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'sh'</span><span class="s2">, </span><span class="s3">'simes-hochberg'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'ho'</span><span class="s2">, </span><span class="s3">'hommel'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'fdr_bh'</span><span class="s2">, </span><span class="s3">'fdr_i'</span><span class="s2">, </span><span class="s3">'fdr_p'</span><span class="s2">, </span><span class="s3">'fdri'</span><span class="s2">, </span><span class="s3">'fdrp'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'fdr_by'</span><span class="s2">, </span><span class="s3">'fdr_n'</span><span class="s2">, </span><span class="s3">'fdr_c'</span><span class="s2">, </span><span class="s3">'fdrn'</span><span class="s2">, </span><span class="s3">'fdrcorr'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'fdr_tsbh'</span><span class="s2">, </span><span class="s3">'fdr_2sbh'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'fdr_tsbky'</span><span class="s2">, </span><span class="s3">'fdr_2sbky'</span><span class="s2">, </span><span class="s3">'fdr_twostage'</span><span class="s1">]</span><span class="s2">,</span>
               <span class="s1">[</span><span class="s3">'fdr_gbs'</span><span class="s1">]</span>
               <span class="s1">]</span>


<span class="s1">multitest_alias = {}</span>
<span class="s2">for </span><span class="s1">m </span><span class="s2">in </span><span class="s1">_alias_list:</span>
    <span class="s1">multitest_alias[m[</span><span class="s5">0</span><span class="s1">]] = m[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s2">for </span><span class="s1">a </span><span class="s2">in </span><span class="s1">m[</span><span class="s5">1</span><span class="s1">:]:</span>
        <span class="s1">multitest_alias[a] = m[</span><span class="s5">0</span><span class="s1">]</span>

<span class="s2">def </span><span class="s1">multipletests(pvals</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'hs'</span><span class="s2">,</span>
                  <span class="s1">maxiter=</span><span class="s5">1</span><span class="s2">,</span>
                  <span class="s1">is_sorted=</span><span class="s2">False,</span>
                  <span class="s1">returnsorted=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Test results and p-value correction for multiple tests 
 
    Parameters 
    ---------- 
    pvals : array_like, 1-d 
        uncorrected p-values.   Must be 1-dimensional. 
    alpha : float 
        FWER, family-wise error rate, e.g. 0.1 
    method : str 
        Method used for testing and adjustment of pvalues. Can be either the 
        full name or initial letters. Available methods are: 
 
        - `bonferroni` : one-step correction 
        - `sidak` : one-step correction 
        - `holm-sidak` : step down method using Sidak adjustments 
        - `holm` : step-down method using Bonferroni adjustments 
        - `simes-hochberg` : step-up method  (independent) 
        - `hommel` : closed method based on Simes tests (non-negative) 
        - `fdr_bh` : Benjamini/Hochberg  (non-negative) 
        - `fdr_by` : Benjamini/Yekutieli (negative) 
        - `fdr_tsbh` : two stage fdr correction (non-negative) 
        - `fdr_tsbky` : two stage fdr correction (non-negative) 
 
    maxiter : int or bool 
        Maximum number of iterations for two-stage fdr, `fdr_tsbh` and 
        `fdr_tsbky`. It is ignored by all other methods. 
        maxiter=1 (default) corresponds to the two stage method. 
        maxiter=-1 corresponds to full iterations which is maxiter=len(pvals). 
        maxiter=0 uses only a single stage fdr correction using a 'bh' or 'bky' 
        prior fraction of assumed true hypotheses. 
    is_sorted : bool 
        If False (default), the p_values will be sorted, but the corrected 
        pvalues are in the original order. If True, then it assumed that the 
        pvalues are already sorted in ascending order. 
    returnsorted : bool 
         not tested, return sorted p-values instead of original sequence 
 
    Returns 
    ------- 
    reject : ndarray, boolean 
        true for hypothesis that can be rejected for given alpha 
    pvals_corrected : ndarray 
        p-values corrected for multiple tests 
    alphacSidak : float 
        corrected alpha for Sidak method 
    alphacBonf : float 
        corrected alpha for Bonferroni method 
 
    Notes 
    ----- 
    There may be API changes for this function in the future. 
 
    Except for 'fdr_twostage', the p-value correction is independent of the 
    alpha specified as argument. In these cases the corrected p-values 
    can also be compared with a different alpha. In the case of 'fdr_twostage', 
    the corrected p-values are specific to the given alpha, see 
    ``fdrcorrection_twostage``. 
 
    The 'fdr_gbs' procedure is not verified against another package, p-values 
    are derived from scratch and are not derived in the reference. In Monte 
    Carlo experiments the method worked correctly and maintained the false 
    discovery rate. 
 
    All procedures that are included, control FWER or FDR in the independent 
    case, and most are robust in the positively correlated case. 
 
    `fdr_gbs`: high power, fdr control for independent case and only small 
    violation in positively correlated case 
 
    **Timing**: 
 
    Most of the time with large arrays is spent in `argsort`. When 
    we want to calculate the p-value for several methods, then it is more 
    efficient to presort the pvalues, and put the results back into the 
    original order outside of the function. 
 
    Method='hommel' is very slow for large arrays, since it requires the 
    evaluation of n partitions, where n is the number of p-values. 
    &quot;&quot;&quot;</span>
    <span class="s2">import </span><span class="s1">gc</span>
    <span class="s1">pvals = np.asarray(pvals)</span>
    <span class="s1">alphaf = alpha  </span><span class="s4"># Notation ?</span>

    <span class="s2">if not </span><span class="s1">is_sorted:</span>
        <span class="s1">sortind = np.argsort(pvals)</span>
        <span class="s1">pvals = np.take(pvals</span><span class="s2">, </span><span class="s1">sortind)</span>

    <span class="s1">ntests = len(pvals)</span>
    <span class="s1">alphacSidak = </span><span class="s5">1 </span><span class="s1">- np.power((</span><span class="s5">1. </span><span class="s1">- alphaf)</span><span class="s2">, </span><span class="s5">1.</span><span class="s1">/ntests)</span>
    <span class="s1">alphacBonf = alphaf / float(ntests)</span>
    <span class="s2">if </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'b'</span><span class="s2">, </span><span class="s3">'bonf'</span><span class="s2">, </span><span class="s3">'bonferroni'</span><span class="s1">]:</span>
        <span class="s1">reject = pvals &lt;= alphacBonf</span>
        <span class="s1">pvals_corrected = pvals * float(ntests)</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'s'</span><span class="s2">, </span><span class="s3">'sidak'</span><span class="s1">]:</span>
        <span class="s1">reject = pvals &lt;= alphacSidak</span>
        <span class="s1">pvals_corrected = -np.expm1(ntests * np.log1p(-pvals))</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'hs'</span><span class="s2">, </span><span class="s3">'holm-sidak'</span><span class="s1">]:</span>
        <span class="s1">alphacSidak_all = </span><span class="s5">1 </span><span class="s1">- np.power((</span><span class="s5">1. </span><span class="s1">- alphaf)</span><span class="s2">,</span>
                                       <span class="s5">1.</span><span class="s1">/np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">notreject = pvals &gt; alphacSidak_all</span>
        <span class="s2">del </span><span class="s1">alphacSidak_all</span>

        <span class="s1">nr_index = np.nonzero(notreject)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">nr_index.size == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># nonreject is empty, all rejected</span>
            <span class="s1">notrejectmin = len(pvals)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">notrejectmin = np.min(nr_index)</span>
        <span class="s1">notreject[notrejectmin:] = </span><span class="s2">True</span>
        <span class="s1">reject = ~notreject</span>
        <span class="s2">del </span><span class="s1">notreject</span>

        <span class="s4"># It's eqivalent to 1 - np.power((1. - pvals),</span>
        <span class="s4">#                           np.arange(ntests, 0, -1))</span>
        <span class="s4"># but prevents the issue of the floating point precision</span>
        <span class="s1">pvals_corrected_raw = -np.expm1(np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">) *</span>
                                        <span class="s1">np.log1p(-pvals))</span>
        <span class="s1">pvals_corrected = np.maximum.accumulate(pvals_corrected_raw)</span>
        <span class="s2">del </span><span class="s1">pvals_corrected_raw</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'h'</span><span class="s2">, </span><span class="s3">'holm'</span><span class="s1">]:</span>
        <span class="s1">notreject = pvals &gt; alphaf / np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">nr_index = np.nonzero(notreject)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">nr_index.size == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s4"># nonreject is empty, all rejected</span>
            <span class="s1">notrejectmin = len(pvals)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">notrejectmin = np.min(nr_index)</span>
        <span class="s1">notreject[notrejectmin:] = </span><span class="s2">True</span>
        <span class="s1">reject = ~notreject</span>
        <span class="s1">pvals_corrected_raw = pvals * np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">pvals_corrected = np.maximum.accumulate(pvals_corrected_raw)</span>
        <span class="s2">del </span><span class="s1">pvals_corrected_raw</span>
        <span class="s1">gc.collect()</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'sh'</span><span class="s2">, </span><span class="s3">'simes-hochberg'</span><span class="s1">]:</span>
        <span class="s1">alphash = alphaf / np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">reject = pvals &lt;= alphash</span>
        <span class="s1">rejind = np.nonzero(reject)</span>
        <span class="s2">if </span><span class="s1">rejind[</span><span class="s5">0</span><span class="s1">].size &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">rejectmax = np.max(np.nonzero(reject))</span>
            <span class="s1">reject[:rejectmax] = </span><span class="s2">True</span>
        <span class="s1">pvals_corrected_raw = np.arange(ntests</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">) * pvals</span>
        <span class="s1">pvals_corrected = np.minimum.accumulate(pvals_corrected_raw[::-</span><span class="s5">1</span><span class="s1">])[::-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s2">del </span><span class="s1">pvals_corrected_raw</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'ho'</span><span class="s2">, </span><span class="s3">'hommel'</span><span class="s1">]:</span>
        <span class="s4"># we need a copy because we overwrite it in a loop</span>
        <span class="s1">a = pvals.copy()</span>
        <span class="s2">for </span><span class="s1">m </span><span class="s2">in </span><span class="s1">range(ntests</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">):</span>
            <span class="s1">cim = np.min(m * pvals[-m:] / np.arange(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">m+</span><span class="s5">1.</span><span class="s1">))</span>
            <span class="s1">a[-m:] = np.maximum(a[-m:]</span><span class="s2">, </span><span class="s1">cim)</span>
            <span class="s1">a[:-m] = np.maximum(a[:-m]</span><span class="s2">, </span><span class="s1">np.minimum(m * pvals[:-m]</span><span class="s2">, </span><span class="s1">cim))</span>
        <span class="s1">pvals_corrected = a</span>
        <span class="s1">reject = a &lt;= alphaf</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'fdr_bh'</span><span class="s2">, </span><span class="s3">'fdr_i'</span><span class="s2">, </span><span class="s3">'fdr_p'</span><span class="s2">, </span><span class="s3">'fdri'</span><span class="s2">, </span><span class="s3">'fdrp'</span><span class="s1">]:</span>
        <span class="s4"># delegate, call with sorted pvals</span>
        <span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected = fdrcorrection(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">,</span>
                                                 <span class="s1">method=</span><span class="s3">'indep'</span><span class="s2">,</span>
                                                 <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'fdr_by'</span><span class="s2">, </span><span class="s3">'fdr_n'</span><span class="s2">, </span><span class="s3">'fdr_c'</span><span class="s2">, </span><span class="s3">'fdrn'</span><span class="s2">, </span><span class="s3">'fdrcorr'</span><span class="s1">]:</span>
        <span class="s4"># delegate, call with sorted pvals</span>
        <span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected = fdrcorrection(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">,</span>
                                                 <span class="s1">method=</span><span class="s3">'n'</span><span class="s2">,</span>
                                                 <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'fdr_tsbky'</span><span class="s2">, </span><span class="s3">'fdr_2sbky'</span><span class="s2">, </span><span class="s3">'fdr_twostage'</span><span class="s1">]:</span>
        <span class="s4"># delegate, call with sorted pvals</span>
        <span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected = fdrcorrection_twostage(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">,</span>
                                                         <span class="s1">method=</span><span class="s3">'bky'</span><span class="s2">,</span>
                                                         <span class="s1">maxiter=maxiter</span><span class="s2">,</span>
                                                         <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)[:</span><span class="s5">2</span><span class="s1">]</span>
    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'fdr_tsbh'</span><span class="s2">, </span><span class="s3">'fdr_2sbh'</span><span class="s1">]:</span>
        <span class="s4"># delegate, call with sorted pvals</span>
        <span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected = fdrcorrection_twostage(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">,</span>
                                                         <span class="s1">method=</span><span class="s3">'bh'</span><span class="s2">,</span>
                                                         <span class="s1">maxiter=maxiter</span><span class="s2">,</span>
                                                         <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)[:</span><span class="s5">2</span><span class="s1">]</span>

    <span class="s2">elif </span><span class="s1">method.lower() </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'fdr_gbs'</span><span class="s1">]:</span>
        <span class="s4">#adaptive stepdown in Gavrilov, Benjamini, Sarkar, Annals of Statistics 2009</span>
<span class="s4">##        notreject = pvals &gt; alphaf / np.arange(ntests, 0, -1) #alphacSidak</span>
<span class="s4">##        notrejectmin = np.min(np.nonzero(notreject))</span>
<span class="s4">##        notreject[notrejectmin:] = True</span>
<span class="s4">##        reject = ~notreject</span>

        <span class="s1">ii = np.arange(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">ntests + </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">q = (ntests + </span><span class="s5">1. </span><span class="s1">- ii)/ii * pvals / (</span><span class="s5">1. </span><span class="s1">- pvals)</span>
        <span class="s1">pvals_corrected_raw = np.maximum.accumulate(q) </span><span class="s4">#up requirementd</span>

        <span class="s1">pvals_corrected = np.minimum.accumulate(pvals_corrected_raw[::-</span><span class="s5">1</span><span class="s1">])[::-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s2">del </span><span class="s1">pvals_corrected_raw</span>
        <span class="s1">reject = pvals_corrected &lt;= alpha</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'method not recognized'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">pvals_corrected </span><span class="s2">is not None</span><span class="s1">: </span><span class="s4">#not necessary anymore</span>
        <span class="s1">pvals_corrected[pvals_corrected&gt;</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s2">if </span><span class="s1">is_sorted </span><span class="s2">or </span><span class="s1">returnsorted:</span>
        <span class="s2">return </span><span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected</span><span class="s2">, </span><span class="s1">alphacSidak</span><span class="s2">, </span><span class="s1">alphacBonf</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">pvals_corrected_ = np.empty_like(pvals_corrected)</span>
        <span class="s1">pvals_corrected_[sortind] = pvals_corrected</span>
        <span class="s2">del </span><span class="s1">pvals_corrected</span>
        <span class="s1">reject_ = np.empty_like(reject)</span>
        <span class="s1">reject_[sortind] = reject</span>
        <span class="s2">return </span><span class="s1">reject_</span><span class="s2">, </span><span class="s1">pvals_corrected_</span><span class="s2">, </span><span class="s1">alphacSidak</span><span class="s2">, </span><span class="s1">alphacBonf</span>


<span class="s2">def </span><span class="s1">fdrcorrection(pvals</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'indep'</span><span class="s2">, </span><span class="s1">is_sorted=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">''' 
    pvalue correction for false discovery rate. 
 
    This covers Benjamini/Hochberg for independent or positively correlated and 
    Benjamini/Yekutieli for general or negatively correlated tests. 
 
    Parameters 
    ---------- 
    pvals : array_like, 1d 
        Set of p-values of the individual tests. 
    alpha : float, optional 
        Family-wise error rate. Defaults to ``0.05``. 
    method : {'i', 'indep', 'p', 'poscorr', 'n', 'negcorr'}, optional 
        Which method to use for FDR correction. 
        ``{'i', 'indep', 'p', 'poscorr'}`` all refer to ``fdr_bh`` 
        (Benjamini/Hochberg for independent or positively 
        correlated tests). ``{'n', 'negcorr'}`` both refer to ``fdr_by`` 
        (Benjamini/Yekutieli for general or negatively correlated tests). 
        Defaults to ``'indep'``. 
    is_sorted : bool, optional 
        If False (default), the p_values will be sorted, but the corrected 
        pvalues are in the original order. If True, then it assumed that the 
        pvalues are already sorted in ascending order. 
 
    Returns 
    ------- 
    rejected : ndarray, bool 
        True if a hypothesis is rejected, False if not 
    pvalue-corrected : ndarray 
        pvalues adjusted for multiple hypothesis testing to limit FDR 
 
    Notes 
    ----- 
    If there is prior information on the fraction of true hypothesis, then alpha 
    should be set to ``alpha * m/m_0`` where m is the number of tests, 
    given by the p-values, and m_0 is an estimate of the true hypothesis. 
    (see Benjamini, Krieger and Yekuteli) 
 
    The two-step method of Benjamini, Krieger and Yekutiel that estimates the number 
    of false hypotheses will be available (soon). 
 
    Both methods exposed via this function (Benjamini/Hochberg, Benjamini/Yekutieli) 
    are also available in the function ``multipletests``, as ``method=&quot;fdr_bh&quot;`` and 
    ``method=&quot;fdr_by&quot;``, respectively. 
 
    See also 
    -------- 
    multipletests 
 
    '''</span>
    <span class="s1">pvals = np.asarray(pvals)</span>
    <span class="s2">assert </span><span class="s1">pvals.ndim == </span><span class="s5">1</span><span class="s2">, </span><span class="s3">&quot;pvals must be 1-dimensional, that is of shape (n,)&quot;</span>

    <span class="s2">if not </span><span class="s1">is_sorted:</span>
        <span class="s1">pvals_sortind = np.argsort(pvals)</span>
        <span class="s1">pvals_sorted = np.take(pvals</span><span class="s2">, </span><span class="s1">pvals_sortind)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">pvals_sorted = pvals  </span><span class="s4"># alias</span>

    <span class="s2">if </span><span class="s1">method </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'i'</span><span class="s2">, </span><span class="s3">'indep'</span><span class="s2">, </span><span class="s3">'p'</span><span class="s2">, </span><span class="s3">'poscorr'</span><span class="s1">]:</span>
        <span class="s1">ecdffactor = _ecdf(pvals_sorted)</span>
    <span class="s2">elif </span><span class="s1">method </span><span class="s2">in </span><span class="s1">[</span><span class="s3">'n'</span><span class="s2">, </span><span class="s3">'negcorr'</span><span class="s1">]:</span>
        <span class="s1">cm = np.sum(</span><span class="s5">1.</span><span class="s1">/np.arange(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">len(pvals_sorted)+</span><span class="s5">1</span><span class="s1">))   </span><span class="s4">#corrected this</span>
        <span class="s1">ecdffactor = _ecdf(pvals_sorted) / cm</span>
<span class="s4">##    elif method in ['n', 'negcorr']:</span>
<span class="s4">##        cm = np.sum(np.arange(len(pvals)))</span>
<span class="s4">##        ecdffactor = ecdf(pvals_sorted)/cm</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'only indep and negcorr implemented'</span><span class="s1">)</span>
    <span class="s1">reject = pvals_sorted &lt;= ecdffactor*alpha</span>
    <span class="s2">if </span><span class="s1">reject.any():</span>
        <span class="s1">rejectmax = max(np.nonzero(reject)[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">reject[:rejectmax] = </span><span class="s2">True</span>

    <span class="s1">pvals_corrected_raw = pvals_sorted / ecdffactor</span>
    <span class="s1">pvals_corrected = np.minimum.accumulate(pvals_corrected_raw[::-</span><span class="s5">1</span><span class="s1">])[::-</span><span class="s5">1</span><span class="s1">]</span>
    <span class="s2">del </span><span class="s1">pvals_corrected_raw</span>
    <span class="s1">pvals_corrected[pvals_corrected&gt;</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s2">if not </span><span class="s1">is_sorted:</span>
        <span class="s1">pvals_corrected_ = np.empty_like(pvals_corrected)</span>
        <span class="s1">pvals_corrected_[pvals_sortind] = pvals_corrected</span>
        <span class="s2">del </span><span class="s1">pvals_corrected</span>
        <span class="s1">reject_ = np.empty_like(reject)</span>
        <span class="s1">reject_[pvals_sortind] = reject</span>
        <span class="s2">return </span><span class="s1">reject_</span><span class="s2">, </span><span class="s1">pvals_corrected_</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">reject</span><span class="s2">, </span><span class="s1">pvals_corrected</span>


<span class="s2">def </span><span class="s1">fdrcorrection_twostage(pvals</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">0.05</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'bky'</span><span class="s2">,</span>
                           <span class="s1">maxiter=</span><span class="s5">1</span><span class="s2">,</span>
                           <span class="s1">iter=</span><span class="s2">None,</span>
                           <span class="s1">is_sorted=</span><span class="s2">False</span><span class="s1">):</span>
    <span class="s0">'''(iterated) two stage linear step-up procedure with estimation of number of true 
    hypotheses 
 
    Benjamini, Krieger and Yekuteli, procedure in Definition 6 
 
    Parameters 
    ---------- 
    pvals : array_like 
        set of p-values of the individual tests. 
    alpha : float 
        error rate 
    method : {'bky', 'bh') 
        see Notes for details 
 
        * 'bky' - implements the procedure in Definition 6 of Benjamini, Krieger 
           and Yekuteli 2006 
        * 'bh' - the two stage method of Benjamini and Hochberg 
 
    maxiter : int or bool 
        Maximum number of iterations. 
        maxiter=1 (default) corresponds to the two stage method. 
        maxiter=-1 corresponds to full iterations which is maxiter=len(pvals). 
        maxiter=0 uses only a single stage fdr correction using a 'bh' or 'bky' 
        prior fraction of assumed true hypotheses. 
        Boolean maxiter is allowed for backwards compatibility with the 
        deprecated ``iter`` keyword. 
        maxiter=False is two-stage fdr (maxiter=1) 
        maxiter=True is full iteration (maxiter=-1 or maxiter=len(pvals)) 
 
        .. versionadded:: 0.14 
 
            Replacement for ``iter`` with additional features. 
 
    iter : bool 
        ``iter`` is deprecated use ``maxiter`` instead. 
        If iter is True, then only one iteration step is used, this is the 
        two-step method. 
        If iter is False, then iterations are stopped at convergence which 
        occurs in a finite number of steps (at most len(pvals) steps). 
 
        .. deprecated:: 0.14 
 
            Use ``maxiter`` instead of ``iter``. 
 
    Returns 
    ------- 
    rejected : ndarray, bool 
        True if a hypothesis is rejected, False if not 
    pvalue-corrected : ndarray 
        pvalues adjusted for multiple hypotheses testing to limit FDR 
    m0 : int 
        ntest - rej, estimated number of true (not rejected) hypotheses 
    alpha_stages : list of floats 
        A list of alphas that have been used at each stage 
 
    Notes 
    ----- 
    The returned corrected p-values are specific to the given alpha, they 
    cannot be used for a different alpha. 
 
    The returned corrected p-values are from the last stage of the fdr_bh 
    linear step-up procedure (fdrcorrection0 with method='indep') corrected 
    for the estimated fraction of true hypotheses. 
    This means that the rejection decision can be obtained with 
    ``pval_corrected &lt;= alpha``, where ``alpha`` is the original significance 
    level. 
    (Note: This has changed from earlier versions (&lt;0.5.0) of statsmodels.) 
 
    BKY described several other multi-stage methods, which would be easy to implement. 
    However, in their simulation the simple two-stage method (with iter=False) was the 
    most robust to the presence of positive correlation 
 
    TODO: What should be returned? 
 
    '''</span>
    <span class="s1">pvals = np.asarray(pvals)</span>

    <span class="s2">if </span><span class="s1">iter </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">import </span><span class="s1">warnings</span>
        <span class="s1">msg = </span><span class="s3">&quot;iter keyword is deprecated, use maxiter keyword instead.&quot;</span>
        <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">FutureWarning)</span>

    <span class="s2">if </span><span class="s1">iter </span><span class="s2">is False</span><span class="s1">:</span>
        <span class="s1">maxiter = </span><span class="s5">1</span>
    <span class="s2">elif </span><span class="s1">iter </span><span class="s2">is True or </span><span class="s1">maxiter </span><span class="s2">in </span><span class="s1">[-</span><span class="s5">1</span><span class="s2">, None</span><span class="s1">] :</span>
        <span class="s1">maxiter = len(pvals)</span>
    <span class="s4"># otherwise we use maxiter</span>


    <span class="s2">if not </span><span class="s1">is_sorted:</span>
        <span class="s1">pvals_sortind = np.argsort(pvals)</span>
        <span class="s1">pvals = np.take(pvals</span><span class="s2">, </span><span class="s1">pvals_sortind)</span>

    <span class="s1">ntests = len(pvals)</span>
    <span class="s2">if </span><span class="s1">method == </span><span class="s3">'bky'</span><span class="s1">:</span>
        <span class="s1">fact = (</span><span class="s5">1.</span><span class="s1">+alpha)</span>
        <span class="s1">alpha_prime = alpha / fact</span>
    <span class="s2">elif </span><span class="s1">method == </span><span class="s3">'bh'</span><span class="s1">:</span>
        <span class="s1">fact = </span><span class="s5">1.</span>
        <span class="s1">alpha_prime = alpha</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;only 'bky' and 'bh' are available as method&quot;</span><span class="s1">)</span>

    <span class="s1">alpha_stages = [alpha_prime]</span>
    <span class="s1">rej</span><span class="s2">, </span><span class="s1">pvalscorr = fdrcorrection(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha_prime</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'indep'</span><span class="s2">,</span>
                                   <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">r1 = rej.sum()</span>
    <span class="s2">if </span><span class="s1">(r1 == </span><span class="s5">0</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(r1 == ntests):</span>
        <span class="s4"># return rej, pvalscorr * fact, ntests - r1, alpha_stages</span>
        <span class="s1">reject = rej</span>
        <span class="s1">pvalscorr *= fact</span>
        <span class="s1">ri = r1</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">ri_old = ri = r1</span>
        <span class="s1">ntests0 = ntests </span><span class="s4"># needed if maxiter=0</span>
        <span class="s4"># while True:</span>
        <span class="s2">for </span><span class="s1">it </span><span class="s2">in </span><span class="s1">range(maxiter):</span>
            <span class="s1">ntests0 = </span><span class="s5">1.0 </span><span class="s1">* ntests - ri_old</span>
            <span class="s1">alpha_star = alpha_prime * ntests / ntests0</span>
            <span class="s1">alpha_stages.append(alpha_star)</span>
            <span class="s4">#print ntests0, alpha_star</span>
            <span class="s1">rej</span><span class="s2">, </span><span class="s1">pvalscorr = fdrcorrection(pvals</span><span class="s2">, </span><span class="s1">alpha=alpha_star</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'indep'</span><span class="s2">,</span>
                                           <span class="s1">is_sorted=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">ri = rej.sum()</span>
            <span class="s2">if </span><span class="s1">(it &gt;= maxiter - </span><span class="s5">1</span><span class="s1">) </span><span class="s2">or </span><span class="s1">ri == ri_old:</span>
                <span class="s2">break</span>
            <span class="s2">elif </span><span class="s1">ri &lt; ri_old:</span>
                <span class="s4"># prevent cycles and endless loops</span>
                <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot; oops - should not be here&quot;</span><span class="s1">)</span>
            <span class="s1">ri_old = ri</span>

        <span class="s4"># make adjustment to pvalscorr to reflect estimated number of Non-Null cases</span>
        <span class="s4"># decision is then pvalscorr &lt; alpha  (or &lt;=)</span>
        <span class="s1">pvalscorr *= ntests0 * </span><span class="s5">1.0 </span><span class="s1">/  ntests</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s3">'bky'</span><span class="s1">:</span>
            <span class="s1">pvalscorr *= (</span><span class="s5">1. </span><span class="s1">+ alpha)</span>

    <span class="s1">pvalscorr[pvalscorr&gt;</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s2">if not </span><span class="s1">is_sorted:</span>
        <span class="s1">pvalscorr_ = np.empty_like(pvalscorr)</span>
        <span class="s1">pvalscorr_[pvals_sortind] = pvalscorr</span>
        <span class="s2">del </span><span class="s1">pvalscorr</span>
        <span class="s1">reject = np.empty_like(rej)</span>
        <span class="s1">reject[pvals_sortind] = rej</span>
        <span class="s2">return </span><span class="s1">reject</span><span class="s2">, </span><span class="s1">pvalscorr_</span><span class="s2">, </span><span class="s1">ntests - ri</span><span class="s2">, </span><span class="s1">alpha_stages</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">rej</span><span class="s2">, </span><span class="s1">pvalscorr</span><span class="s2">, </span><span class="s1">ntests - ri</span><span class="s2">, </span><span class="s1">alpha_stages</span>


<span class="s2">def </span><span class="s1">local_fdr(zscores</span><span class="s2">, </span><span class="s1">null_proportion=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">null_pdf=</span><span class="s2">None, </span><span class="s1">deg=</span><span class="s5">7</span><span class="s2">,</span>
              <span class="s1">nbins=</span><span class="s5">30</span><span class="s2">, </span><span class="s1">alpha=</span><span class="s5">0</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Calculate local FDR values for a list of Z-scores. 
 
    Parameters 
    ---------- 
    zscores : array_like 
        A vector of Z-scores 
    null_proportion : float 
        The assumed proportion of true null hypotheses 
    null_pdf : function mapping reals to positive reals 
        The density of null Z-scores; if None, use standard normal 
    deg : int 
        The maximum exponent in the polynomial expansion of the 
        density of non-null Z-scores 
    nbins : int 
        The number of bins for estimating the marginal density 
        of Z-scores. 
    alpha : float 
        Use Poisson ridge regression with parameter alpha to estimate 
        the density of non-null Z-scores. 
 
    Returns 
    ------- 
    fdr : array_like 
        A vector of FDR values 
 
    References 
    ---------- 
    B Efron (2008).  Microarrays, Empirical Bayes, and the Two-Groups 
    Model.  Statistical Science 23:1, 1-22. 
 
    Examples 
    -------- 
    Basic use (the null Z-scores are taken to be standard normal): 
 
    &gt;&gt;&gt; from statsmodels.stats.multitest import local_fdr 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; zscores = np.random.randn(30) 
    &gt;&gt;&gt; fdr = local_fdr(zscores) 
 
    Use a Gaussian null distribution estimated from the data: 
 
    &gt;&gt;&gt; null = EmpiricalNull(zscores) 
    &gt;&gt;&gt; fdr = local_fdr(zscores, null_pdf=null.pdf) 
    &quot;&quot;&quot;</span>

    <span class="s2">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s2">import </span><span class="s1">GLM</span>
    <span class="s2">from </span><span class="s1">statsmodels.genmod.generalized_linear_model </span><span class="s2">import </span><span class="s1">families</span>
    <span class="s2">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s2">import </span><span class="s1">OLS</span>

    <span class="s4"># Bins for Poisson modeling of the marginal Z-score density</span>
    <span class="s1">minz = min(zscores)</span>
    <span class="s1">maxz = max(zscores)</span>
    <span class="s1">bins = np.linspace(minz</span><span class="s2">, </span><span class="s1">maxz</span><span class="s2">, </span><span class="s1">nbins)</span>

    <span class="s4"># Bin counts</span>
    <span class="s1">zhist = np.histogram(zscores</span><span class="s2">, </span><span class="s1">bins)[</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s4"># Bin centers</span>
    <span class="s1">zbins = (bins[:-</span><span class="s5">1</span><span class="s1">] + bins[</span><span class="s5">1</span><span class="s1">:]) / </span><span class="s5">2</span>

    <span class="s4"># The design matrix at bin centers</span>
    <span class="s1">dmat = np.vander(zbins</span><span class="s2">, </span><span class="s1">deg + </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Rescale the design matrix</span>
    <span class="s1">sd = dmat.std(</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">ii = sd &gt;</span><span class="s5">1e-8</span>
    <span class="s1">dmat[:</span><span class="s2">, </span><span class="s1">ii] /= sd[ii]</span>

    <span class="s1">start = OLS(np.log(</span><span class="s5">1 </span><span class="s1">+ zhist)</span><span class="s2">, </span><span class="s1">dmat).fit().params</span>

    <span class="s4"># Poisson regression</span>
    <span class="s2">if </span><span class="s1">alpha &gt; </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">md = GLM(zhist</span><span class="s2">, </span><span class="s1">dmat</span><span class="s2">, </span><span class="s1">family=families.Poisson()).fit_regularized(L1_wt=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">alpha=alpha</span><span class="s2">, </span><span class="s1">start_params=start)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">md = GLM(zhist</span><span class="s2">, </span><span class="s1">dmat</span><span class="s2">, </span><span class="s1">family=families.Poisson()).fit(start_params=start)</span>

    <span class="s4"># The design matrix for all Z-scores</span>
    <span class="s1">dmat_full = np.vander(zscores</span><span class="s2">, </span><span class="s1">deg + </span><span class="s5">1</span><span class="s1">)</span>
    <span class="s1">dmat_full[:</span><span class="s2">, </span><span class="s1">ii] /= sd[ii]</span>

    <span class="s4"># The height of the estimated marginal density of Z-scores,</span>
    <span class="s4"># evaluated at every observed Z-score.</span>
    <span class="s1">fz = md.predict(dmat_full) / (len(zscores) * (bins[</span><span class="s5">1</span><span class="s1">] - bins[</span><span class="s5">0</span><span class="s1">]))</span>

    <span class="s4"># The null density.</span>
    <span class="s2">if </span><span class="s1">null_pdf </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">f0 = np.exp(-</span><span class="s5">0.5 </span><span class="s1">* zscores**</span><span class="s5">2</span><span class="s1">) / np.sqrt(</span><span class="s5">2 </span><span class="s1">* np.pi)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">f0 = null_pdf(zscores)</span>

    <span class="s4"># The local FDR values</span>
    <span class="s1">fdr = null_proportion * f0 / fz</span>

    <span class="s1">fdr = np.clip(fdr</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">fdr</span>


<span class="s2">class </span><span class="s1">NullDistribution:</span>
    <span class="s0">&quot;&quot;&quot; 
    Estimate a Gaussian distribution for the null Z-scores. 
 
    The observed Z-scores consist of both null and non-null values. 
    The fitted distribution of null Z-scores is Gaussian, but may have 
    non-zero mean and/or non-unit scale. 
 
    Parameters 
    ---------- 
    zscores : array_like 
        The observed Z-scores. 
    null_lb : float 
        Z-scores between `null_lb` and `null_ub` are all considered to be 
        true null hypotheses. 
    null_ub : float 
        See `null_lb`. 
    estimate_mean : bool 
        If True, estimate the mean of the distribution.  If False, the 
        mean is fixed at zero. 
    estimate_scale : bool 
        If True, estimate the scale of the distribution.  If False, the 
        scale parameter is fixed at 1. 
    estimate_null_proportion : bool 
        If True, estimate the proportion of true null hypotheses (i.e. 
        the proportion of z-scores with expected value zero).  If False, 
        this parameter is fixed at 1. 
 
    Attributes 
    ---------- 
    mean : float 
        The estimated mean of the empirical null distribution 
    sd : float 
        The estimated standard deviation of the empirical null distribution 
    null_proportion : float 
        The estimated proportion of true null hypotheses among all hypotheses 
 
    References 
    ---------- 
    B Efron (2008).  Microarrays, Empirical Bayes, and the Two-Groups 
    Model.  Statistical Science 23:1, 1-22. 
 
    Notes 
    ----- 
    See also: 
 
    http://nipy.org/nipy/labs/enn.html#nipy.algorithms.statistics.empirical_pvalue.NormalEmpiricalNull.fdr 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">zscores</span><span class="s2">, </span><span class="s1">null_lb=-</span><span class="s5">1</span><span class="s2">, </span><span class="s1">null_ub=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">estimate_mean=</span><span class="s2">True,</span>
                 <span class="s1">estimate_scale=</span><span class="s2">True, </span><span class="s1">estimate_null_proportion=</span><span class="s2">False</span><span class="s1">):</span>

        <span class="s4"># Extract the null z-scores</span>
        <span class="s1">ii = np.flatnonzero((zscores &gt;= null_lb) &amp; (zscores &lt;= null_ub))</span>
        <span class="s2">if </span><span class="s1">len(ii) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">RuntimeError(</span><span class="s3">&quot;No Z-scores fall between null_lb and null_ub&quot;</span><span class="s1">)</span>
        <span class="s1">zscores0 = zscores[ii]</span>

        <span class="s4"># Number of Z-scores, and null Z-scores</span>
        <span class="s1">n_zs</span><span class="s2">, </span><span class="s1">n_zs0 = len(zscores)</span><span class="s2">, </span><span class="s1">len(zscores0)</span>

        <span class="s4"># Unpack and transform the parameters to the natural scale, hold</span>
        <span class="s4"># parameters fixed as specified.</span>
        <span class="s2">def </span><span class="s1">xform(params):</span>

            <span class="s1">mean = </span><span class="s5">0.</span>
            <span class="s1">sd = </span><span class="s5">1.</span>
            <span class="s1">prob = </span><span class="s5">1.</span>

            <span class="s1">ii = </span><span class="s5">0</span>
            <span class="s2">if </span><span class="s1">estimate_mean:</span>
                <span class="s1">mean = params[ii]</span>
                <span class="s1">ii += </span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">estimate_scale:</span>
                <span class="s1">sd = np.exp(params[ii])</span>
                <span class="s1">ii += </span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">estimate_null_proportion:</span>
                <span class="s1">prob = </span><span class="s5">1 </span><span class="s1">/ (</span><span class="s5">1 </span><span class="s1">+ np.exp(-params[ii]))</span>

            <span class="s2">return </span><span class="s1">mean</span><span class="s2">, </span><span class="s1">sd</span><span class="s2">, </span><span class="s1">prob</span>


        <span class="s2">from </span><span class="s1">scipy.stats.distributions </span><span class="s2">import </span><span class="s1">norm</span>


        <span class="s2">def </span><span class="s1">fun(params):</span>
            <span class="s0">&quot;&quot;&quot; 
            Negative log-likelihood of z-scores. 
 
            The function has three arguments, packed into a vector: 
 
            mean : location parameter 
            logscale : log of the scale parameter 
            logitprop : logit of the proportion of true nulls 
 
            The implementation follows section 4 from Efron 2008. 
            &quot;&quot;&quot;</span>

            <span class="s1">d</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">p = xform(params)</span>

            <span class="s4"># Mass within the central region</span>
            <span class="s1">central_mass = (norm.cdf((null_ub - d) / s) -</span>
                            <span class="s1">norm.cdf((null_lb - d) / s))</span>

            <span class="s4"># Probability that a Z-score is null and is in the central region</span>
            <span class="s1">cp = p * central_mass</span>

            <span class="s4"># Binomial term</span>
            <span class="s1">rval = n_zs0 * np.log(cp) + (n_zs - n_zs0) * np.log(</span><span class="s5">1 </span><span class="s1">- cp)</span>

            <span class="s4"># Truncated Gaussian term for null Z-scores</span>
            <span class="s1">zv = (zscores0 - d) / s</span>
            <span class="s1">rval += np.sum(-zv**</span><span class="s5">2 </span><span class="s1">/ </span><span class="s5">2</span><span class="s1">) - n_zs0 * np.log(s)</span>
            <span class="s1">rval -= n_zs0 * np.log(central_mass)</span>

            <span class="s2">return </span><span class="s1">-rval</span>


        <span class="s4"># Estimate the parameters</span>
        <span class="s2">from </span><span class="s1">scipy.optimize </span><span class="s2">import </span><span class="s1">minimize</span>
        <span class="s4"># starting values are mean = 0, scale = 1, p0 ~ 1</span>
        <span class="s1">mz = minimize(fun</span><span class="s2">, </span><span class="s1">np.r_[</span><span class="s5">0.</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">&quot;Nelder-Mead&quot;</span><span class="s1">)</span>
        <span class="s1">mean</span><span class="s2">, </span><span class="s1">sd</span><span class="s2">, </span><span class="s1">prob = xform(mz[</span><span class="s3">'x'</span><span class="s1">])</span>

        <span class="s1">self.mean = mean</span>
        <span class="s1">self.sd = sd</span>
        <span class="s1">self.null_proportion = prob</span>


    <span class="s4"># The fitted null density function</span>
    <span class="s2">def </span><span class="s1">pdf(self</span><span class="s2">, </span><span class="s1">zscores):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evaluates the fitted empirical null Z-score density. 
 
        Parameters 
        ---------- 
        zscores : scalar or array_like 
            The point or points at which the density is to be 
            evaluated. 
 
        Returns 
        ------- 
        The empirical null Z-score density evaluated at the given 
        points. 
        &quot;&quot;&quot;</span>

        <span class="s1">zval = (zscores - self.mean) / self.sd</span>
        <span class="s2">return </span><span class="s1">np.exp(-</span><span class="s5">0.5</span><span class="s1">*zval**</span><span class="s5">2 </span><span class="s1">- np.log(self.sd) - </span><span class="s5">0.5</span><span class="s1">*np.log(</span><span class="s5">2</span><span class="s1">*np.pi))</span>
</pre>
</body>
</html>
<html>
<head>
<title>test_random_projection.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_random_projection.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">functools</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">typing </span><span class="s0">import </span><span class="s1">Any</span><span class="s0">, </span><span class="s1">List</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">scipy.sparse </span><span class="s0">as </span><span class="s1">sp</span>

<span class="s0">from </span><span class="s1">sklearn.exceptions </span><span class="s0">import </span><span class="s1">DataDimensionalityWarning</span>
<span class="s0">from </span><span class="s1">sklearn.metrics </span><span class="s0">import </span><span class="s1">euclidean_distances</span>
<span class="s0">from </span><span class="s1">sklearn.random_projection </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">GaussianRandomProjection</span><span class="s0">,</span>
    <span class="s1">SparseRandomProjection</span><span class="s0">,</span>
    <span class="s1">_gaussian_random_matrix</span><span class="s0">,</span>
    <span class="s1">_sparse_random_matrix</span><span class="s0">,</span>
    <span class="s1">johnson_lindenstrauss_min_dim</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">from </span><span class="s1">sklearn.utils._testing </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">assert_allclose</span><span class="s0">,</span>
    <span class="s1">assert_allclose_dense_sparse</span><span class="s0">,</span>
    <span class="s1">assert_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s0">,</span>
    <span class="s1">assert_array_equal</span><span class="s0">,</span>
<span class="s1">)</span>

<span class="s1">all_sparse_random_matrix: List[Any] = [_sparse_random_matrix]</span>
<span class="s1">all_dense_random_matrix: List[Any] = [_gaussian_random_matrix]</span>
<span class="s1">all_random_matrix = all_sparse_random_matrix + all_dense_random_matrix</span>

<span class="s1">all_SparseRandomProjection: List[Any] = [SparseRandomProjection]</span>
<span class="s1">all_DenseRandomProjection: List[Any] = [GaussianRandomProjection]</span>
<span class="s1">all_RandomProjection = all_SparseRandomProjection + all_DenseRandomProjection</span>


<span class="s2"># Make some random data with uniformly located non zero entries with</span>
<span class="s2"># Gaussian distributed values</span>
<span class="s0">def </span><span class="s1">make_sparse_random_data(n_samples</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">n_nonzeros</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">):</span>
    <span class="s1">rng = np.random.RandomState(random_state)</span>
    <span class="s1">data_coo = sp.coo_matrix(</span>
        <span class="s1">(</span>
            <span class="s1">rng.randn(n_nonzeros)</span><span class="s0">,</span>
            <span class="s1">(</span>
                <span class="s1">rng.randint(n_samples</span><span class="s0">, </span><span class="s1">size=n_nonzeros)</span><span class="s0">,</span>
                <span class="s1">rng.randint(n_features</span><span class="s0">, </span><span class="s1">size=n_nonzeros)</span><span class="s0">,</span>
            <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">)</span><span class="s0">,</span>
        <span class="s1">shape=(n_samples</span><span class="s0">, </span><span class="s1">n_features)</span><span class="s0">,</span>
    <span class="s1">)</span>
    <span class="s0">return </span><span class="s1">data_coo.toarray()</span><span class="s0">, </span><span class="s1">data_coo.tocsr()</span>


<span class="s0">def </span><span class="s1">densify(matrix):</span>
    <span class="s0">if not </span><span class="s1">sp.issparse(matrix):</span>
        <span class="s0">return </span><span class="s1">matrix</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">matrix.toarray()</span>


<span class="s1">n_samples</span><span class="s0">, </span><span class="s1">n_features = (</span><span class="s3">10</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">)</span>
<span class="s1">n_nonzeros = int(n_samples * n_features / </span><span class="s3">100.0</span><span class="s1">)</span>
<span class="s1">data</span><span class="s0">, </span><span class="s1">data_csr = make_sparse_random_data(n_samples</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">n_nonzeros)</span>


<span class="s2">###############################################################################</span>
<span class="s2"># test on JL lemma</span>
<span class="s2">###############################################################################</span>


<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;n_samples, eps&quot;</span><span class="s0">,</span>
    <span class="s1">[</span>
        <span class="s1">([</span><span class="s3">100</span><span class="s0">, </span><span class="s3">110</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.9</span><span class="s0">, </span><span class="s3">1.1</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s3">90</span><span class="s0">, </span><span class="s3">100</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.0</span><span class="s1">])</span><span class="s0">,</span>
        <span class="s1">([</span><span class="s3">50</span><span class="s0">, </span><span class="s1">-</span><span class="s3">40</span><span class="s1">]</span><span class="s0">, </span><span class="s1">[</span><span class="s3">0.1</span><span class="s0">, </span><span class="s3">0.2</span><span class="s1">])</span><span class="s0">,</span>
    <span class="s1">]</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_invalid_jl_domain(n_samples</span><span class="s0">, </span><span class="s1">eps):</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">johnson_lindenstrauss_min_dim(n_samples</span><span class="s0">, </span><span class="s1">eps=eps)</span>


<span class="s0">def </span><span class="s1">test_input_size_jl_min_dim():</span>
    <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
        <span class="s1">johnson_lindenstrauss_min_dim(</span><span class="s3">3 </span><span class="s1">* [</span><span class="s3">100</span><span class="s1">]</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">2 </span><span class="s1">* [</span><span class="s3">0.9</span><span class="s1">])</span>

    <span class="s1">johnson_lindenstrauss_min_dim(</span>
        <span class="s1">np.random.randint(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s1">size=(</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s1">))</span><span class="s0">, </span><span class="s1">eps=np.full((</span><span class="s3">10</span><span class="s0">, </span><span class="s3">10</span><span class="s1">)</span><span class="s0">, </span><span class="s3">0.5</span><span class="s1">)</span>
    <span class="s1">)</span>


<span class="s2">###############################################################################</span>
<span class="s2"># tests random matrix generation</span>
<span class="s2">###############################################################################</span>
<span class="s0">def </span><span class="s1">check_input_size_random_matrix(random_matrix):</span>
    <span class="s1">inputs = [(</span><span class="s3">0</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s1">-</span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(-</span><span class="s3">1</span><span class="s0">, </span><span class="s3">0</span><span class="s1">)]</span>
    <span class="s0">for </span><span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features </span><span class="s0">in </span><span class="s1">inputs:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">random_matrix(n_components</span><span class="s0">, </span><span class="s1">n_features)</span>


<span class="s0">def </span><span class="s1">check_size_generated(random_matrix):</span>
    <span class="s1">inputs = [(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">5</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">5</span><span class="s0">, </span><span class="s3">5</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)]</span>
    <span class="s0">for </span><span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features </span><span class="s0">in </span><span class="s1">inputs:</span>
        <span class="s0">assert </span><span class="s1">random_matrix(n_components</span><span class="s0">, </span><span class="s1">n_features).shape == (</span>
            <span class="s1">n_components</span><span class="s0">,</span>
            <span class="s1">n_features</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">check_zero_mean_and_unit_norm(random_matrix):</span>
    <span class="s2"># All random matrix should produce a transformation matrix</span>
    <span class="s2"># with zero mean and unit norm for each columns</span>

    <span class="s1">A = densify(random_matrix(</span><span class="s3">10000</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">))</span>

    <span class="s1">assert_array_almost_equal(</span><span class="s3">0</span><span class="s0">, </span><span class="s1">np.mean(A)</span><span class="s0">, </span><span class="s3">3</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(</span><span class="s3">1.0</span><span class="s0">, </span><span class="s1">np.linalg.norm(A)</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">check_input_with_sparse_random_matrix(random_matrix):</span>
    <span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features = </span><span class="s3">5</span><span class="s0">, </span><span class="s3">10</span>

    <span class="s0">for </span><span class="s1">density </span><span class="s0">in </span><span class="s1">[-</span><span class="s3">1.0</span><span class="s0">, </span><span class="s3">0.0</span><span class="s0">, </span><span class="s3">1.1</span><span class="s1">]:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">random_matrix(n_components</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">density=density)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_matrix&quot;</span><span class="s0">, </span><span class="s1">all_random_matrix)</span>
<span class="s0">def </span><span class="s1">test_basic_property_of_random_matrix(random_matrix):</span>
    <span class="s2"># Check basic properties of random matrix generation</span>
    <span class="s1">check_input_size_random_matrix(random_matrix)</span>
    <span class="s1">check_size_generated(random_matrix)</span>
    <span class="s1">check_zero_mean_and_unit_norm(random_matrix)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_matrix&quot;</span><span class="s0">, </span><span class="s1">all_sparse_random_matrix)</span>
<span class="s0">def </span><span class="s1">test_basic_property_of_sparse_random_matrix(random_matrix):</span>
    <span class="s1">check_input_with_sparse_random_matrix(random_matrix)</span>

    <span class="s1">random_matrix_dense = functools.partial(random_matrix</span><span class="s0">, </span><span class="s1">density=</span><span class="s3">1.0</span><span class="s1">)</span>

    <span class="s1">check_zero_mean_and_unit_norm(random_matrix_dense)</span>


<span class="s0">def </span><span class="s1">test_gaussian_random_matrix():</span>
    <span class="s2"># Check some statical properties of Gaussian random matrix</span>
    <span class="s2"># Check that the random matrix follow the proper distribution.</span>
    <span class="s2"># Let's say that each element of a_{ij} of A is taken from</span>
    <span class="s2">#   a_ij ~ N(0.0, 1 / n_components).</span>
    <span class="s2">#</span>
    <span class="s1">n_components = </span><span class="s3">100</span>
    <span class="s1">n_features = </span><span class="s3">1000</span>
    <span class="s1">A = _gaussian_random_matrix(n_components</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">assert_array_almost_equal(</span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">np.mean(A)</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">assert_array_almost_equal(np.var(A</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">/ n_components</span><span class="s0">, </span><span class="s3">1</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_sparse_random_matrix():</span>
    <span class="s2"># Check some statical properties of sparse random matrix</span>
    <span class="s1">n_components = </span><span class="s3">100</span>
    <span class="s1">n_features = </span><span class="s3">500</span>

    <span class="s0">for </span><span class="s1">density </span><span class="s0">in </span><span class="s1">[</span><span class="s3">0.3</span><span class="s0">, </span><span class="s3">1.0</span><span class="s1">]:</span>
        <span class="s1">s = </span><span class="s3">1 </span><span class="s1">/ density</span>

        <span class="s1">A = _sparse_random_matrix(</span>
            <span class="s1">n_components</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">density=density</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span>
        <span class="s1">)</span>
        <span class="s1">A = densify(A)</span>

        <span class="s2"># Check possible values</span>
        <span class="s1">values = np.unique(A)</span>
        <span class="s0">assert </span><span class="s1">np.sqrt(s) / np.sqrt(n_components) </span><span class="s0">in </span><span class="s1">values</span>
        <span class="s0">assert </span><span class="s1">-np.sqrt(s) / np.sqrt(n_components) </span><span class="s0">in </span><span class="s1">values</span>

        <span class="s0">if </span><span class="s1">density == </span><span class="s3">1.0</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s1">np.size(values) == </span><span class="s3">2</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">assert </span><span class="s3">0.0 </span><span class="s0">in </span><span class="s1">values</span>
            <span class="s0">assert </span><span class="s1">np.size(values) == </span><span class="s3">3</span>

        <span class="s2"># Check that the random matrix follow the proper distribution.</span>
        <span class="s2"># Let's say that each element of a_{ij} of A is taken from</span>
        <span class="s2">#</span>
        <span class="s2"># - -sqrt(s) / sqrt(n_components)   with probability 1 / 2s</span>
        <span class="s2"># -  0                              with probability 1 - 1 / s</span>
        <span class="s2"># - +sqrt(s) / sqrt(n_components)   with probability 1 / 2s</span>
        <span class="s2">#</span>
        <span class="s1">assert_almost_equal(np.mean(A == </span><span class="s3">0.0</span><span class="s1">)</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">- </span><span class="s3">1 </span><span class="s1">/ s</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">np.mean(A == np.sqrt(s) / np.sqrt(n_components))</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">np.mean(A == -np.sqrt(s) / np.sqrt(n_components))</span><span class="s0">, </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span>
        <span class="s1">)</span>

        <span class="s1">assert_almost_equal(np.var(A == </span><span class="s3">0.0</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">, </span><span class="s1">(</span><span class="s3">1 </span><span class="s1">- </span><span class="s3">1 </span><span class="s1">/ s) * </span><span class="s3">1 </span><span class="s1">/ s</span><span class="s0">, </span><span class="s1">decimal=</span><span class="s3">2</span><span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">np.var(A == np.sqrt(s) / np.sqrt(n_components)</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
            <span class="s1">(</span><span class="s3">1 </span><span class="s1">- </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)) * </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)</span><span class="s0">,</span>
            <span class="s1">decimal=</span><span class="s3">2</span><span class="s0">,</span>
        <span class="s1">)</span>
        <span class="s1">assert_almost_equal(</span>
            <span class="s1">np.var(A == -np.sqrt(s) / np.sqrt(n_components)</span><span class="s0">, </span><span class="s1">ddof=</span><span class="s3">1</span><span class="s1">)</span><span class="s0">,</span>
            <span class="s1">(</span><span class="s3">1 </span><span class="s1">- </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)) * </span><span class="s3">1 </span><span class="s1">/ (</span><span class="s3">2 </span><span class="s1">* s)</span><span class="s0">,</span>
            <span class="s1">decimal=</span><span class="s3">2</span><span class="s0">,</span>
        <span class="s1">)</span>


<span class="s2">###############################################################################</span>
<span class="s2"># tests on random projection transformer</span>
<span class="s2">###############################################################################</span>


<span class="s0">def </span><span class="s1">test_random_projection_transformer_invalid_input():</span>
    <span class="s1">n_components = </span><span class="s4">&quot;auto&quot;</span>
    <span class="s1">fit_data = [[</span><span class="s3">0</span><span class="s0">, </span><span class="s3">1</span><span class="s0">, </span><span class="s3">2</span><span class="s1">]]</span>
    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">RandomProjection(n_components=n_components).fit(fit_data)</span>


<span class="s0">def </span><span class="s1">test_try_to_transform_before_fit():</span>
    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">RandomProjection(n_components=</span><span class="s4">&quot;auto&quot;</span><span class="s1">).transform(data)</span>


<span class="s0">def </span><span class="s1">test_too_many_samples_to_find_a_safe_embedding():</span>
    <span class="s1">data</span><span class="s0">, </span><span class="s1">_ = make_sparse_random_data(</span><span class="s3">1000</span><span class="s0">, </span><span class="s3">100</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">)</span>

    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s1">rp = RandomProjection(n_components=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">0.1</span><span class="s1">)</span>
        <span class="s1">expected_msg = (</span>
            <span class="s4">&quot;eps=0.100000 and n_samples=1000 lead to a target dimension&quot;</span>
            <span class="s4">&quot; of 5920 which is larger than the original space with&quot;</span>
            <span class="s4">&quot; n_features=100&quot;</span>
        <span class="s1">)</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError</span><span class="s0">, </span><span class="s1">match=expected_msg):</span>
            <span class="s1">rp.fit(data)</span>


<span class="s0">def </span><span class="s1">test_random_projection_embedding_quality():</span>
    <span class="s1">data</span><span class="s0">, </span><span class="s1">_ = make_sparse_random_data(</span><span class="s3">8</span><span class="s0">, </span><span class="s3">5000</span><span class="s0">, </span><span class="s3">15000</span><span class="s1">)</span>
    <span class="s1">eps = </span><span class="s3">0.2</span>

    <span class="s1">original_distances = euclidean_distances(data</span><span class="s0">, </span><span class="s1">squared=</span><span class="s0">True</span><span class="s1">)</span>
    <span class="s1">original_distances = original_distances.ravel()</span>
    <span class="s1">non_identical = original_distances != </span><span class="s3">0.0</span>

    <span class="s2"># remove 0 distances to avoid division by 0</span>
    <span class="s1">original_distances = original_distances[non_identical]</span>

    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s1">rp = RandomProjection(n_components=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">eps=eps</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">projected = rp.fit_transform(data)</span>

        <span class="s1">projected_distances = euclidean_distances(projected</span><span class="s0">, </span><span class="s1">squared=</span><span class="s0">True</span><span class="s1">)</span>
        <span class="s1">projected_distances = projected_distances.ravel()</span>

        <span class="s2"># remove 0 distances to avoid division by 0</span>
        <span class="s1">projected_distances = projected_distances[non_identical]</span>

        <span class="s1">distances_ratio = projected_distances / original_distances</span>

        <span class="s2"># check that the automatically tuned values for the density respect the</span>
        <span class="s2"># contract for eps: pairwise distances are preserved according to the</span>
        <span class="s2"># Johnson-Lindenstrauss lemma</span>
        <span class="s0">assert </span><span class="s1">distances_ratio.max() &lt; </span><span class="s3">1 </span><span class="s1">+ eps</span>
        <span class="s0">assert </span><span class="s3">1 </span><span class="s1">- eps &lt; distances_ratio.min()</span>


<span class="s0">def </span><span class="s1">test_SparseRandomProj_output_representation():</span>
    <span class="s0">for </span><span class="s1">SparseRandomProj </span><span class="s0">in </span><span class="s1">all_SparseRandomProjection:</span>
        <span class="s2"># when using sparse input, the projected data can be forced to be a</span>
        <span class="s2"># dense numpy array</span>
        <span class="s1">rp = SparseRandomProj(n_components=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">dense_output=</span><span class="s0">True, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">rp.fit(data)</span>
        <span class="s0">assert </span><span class="s1">isinstance(rp.transform(data)</span><span class="s0">, </span><span class="s1">np.ndarray)</span>

        <span class="s1">sparse_data = sp.csr_matrix(data)</span>
        <span class="s0">assert </span><span class="s1">isinstance(rp.transform(sparse_data)</span><span class="s0">, </span><span class="s1">np.ndarray)</span>

        <span class="s2"># the output can be left to a sparse matrix instead</span>
        <span class="s1">rp = SparseRandomProj(n_components=</span><span class="s3">10</span><span class="s0">, </span><span class="s1">dense_output=</span><span class="s0">False, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
        <span class="s1">rp = rp.fit(data)</span>
        <span class="s2"># output for dense input will stay dense:</span>
        <span class="s0">assert </span><span class="s1">isinstance(rp.transform(data)</span><span class="s0">, </span><span class="s1">np.ndarray)</span>

        <span class="s2"># output for sparse output will be sparse:</span>
        <span class="s0">assert </span><span class="s1">sp.issparse(rp.transform(sparse_data))</span>


<span class="s0">def </span><span class="s1">test_correct_RandomProjection_dimensions_embedding():</span>
    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s1">rp = RandomProjection(n_components=</span><span class="s4">&quot;auto&quot;</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">0.5</span><span class="s1">).fit(data)</span>

        <span class="s2"># the number of components is adjusted from the shape of the training</span>
        <span class="s2"># set</span>
        <span class="s0">assert </span><span class="s1">rp.n_components == </span><span class="s4">&quot;auto&quot;</span>
        <span class="s0">assert </span><span class="s1">rp.n_components_ == </span><span class="s3">110</span>

        <span class="s0">if </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_SparseRandomProjection:</span>
            <span class="s0">assert </span><span class="s1">rp.density == </span><span class="s4">&quot;auto&quot;</span>
            <span class="s1">assert_almost_equal(rp.density_</span><span class="s0">, </span><span class="s3">0.03</span><span class="s0">, </span><span class="s3">2</span><span class="s1">)</span>

        <span class="s0">assert </span><span class="s1">rp.components_.shape == (</span><span class="s3">110</span><span class="s0">, </span><span class="s1">n_features)</span>

        <span class="s1">projected_1 = rp.transform(data)</span>
        <span class="s0">assert </span><span class="s1">projected_1.shape == (n_samples</span><span class="s0">, </span><span class="s3">110</span><span class="s1">)</span>

        <span class="s2"># once the RP is 'fitted' the projection is always the same</span>
        <span class="s1">projected_2 = rp.transform(data)</span>
        <span class="s1">assert_array_equal(projected_1</span><span class="s0">, </span><span class="s1">projected_2)</span>

        <span class="s2"># fit transform with same random seed will lead to the same results</span>
        <span class="s1">rp2 = RandomProjection(random_state=</span><span class="s3">0</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">0.5</span><span class="s1">)</span>
        <span class="s1">projected_3 = rp2.fit_transform(data)</span>
        <span class="s1">assert_array_equal(projected_1</span><span class="s0">, </span><span class="s1">projected_3)</span>

        <span class="s2"># Try to transform with an input X of size different from fitted.</span>
        <span class="s0">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">rp.transform(data[:</span><span class="s0">, </span><span class="s3">1</span><span class="s1">:</span><span class="s3">5</span><span class="s1">])</span>

        <span class="s2"># it is also possible to fix the number of components and the density</span>
        <span class="s2"># level</span>
        <span class="s0">if </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_SparseRandomProjection:</span>
            <span class="s1">rp = RandomProjection(n_components=</span><span class="s3">100</span><span class="s0">, </span><span class="s1">density=</span><span class="s3">0.001</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">0</span><span class="s1">)</span>
            <span class="s1">projected = rp.fit_transform(data)</span>
            <span class="s0">assert </span><span class="s1">projected.shape == (n_samples</span><span class="s0">, </span><span class="s3">100</span><span class="s1">)</span>
            <span class="s0">assert </span><span class="s1">rp.components_.shape == (</span><span class="s3">100</span><span class="s0">, </span><span class="s1">n_features)</span>
            <span class="s0">assert </span><span class="s1">rp.components_.nnz &lt; </span><span class="s3">115  </span><span class="s2"># close to 1% density</span>
            <span class="s0">assert </span><span class="s3">85 </span><span class="s1">&lt; rp.components_.nnz  </span><span class="s2"># close to 1% density</span>


<span class="s0">def </span><span class="s1">test_warning_n_components_greater_than_n_features():</span>
    <span class="s1">n_features = </span><span class="s3">20</span>
    <span class="s1">data</span><span class="s0">, </span><span class="s1">_ = make_sparse_random_data(</span><span class="s3">5</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">int(n_features / </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s0">with </span><span class="s1">pytest.warns(DataDimensionalityWarning):</span>
            <span class="s1">RandomProjection(n_components=n_features + </span><span class="s3">1</span><span class="s1">).fit(data)</span>


<span class="s0">def </span><span class="s1">test_works_with_sparse_data():</span>
    <span class="s1">n_features = </span><span class="s3">20</span>
    <span class="s1">data</span><span class="s0">, </span><span class="s1">_ = make_sparse_random_data(</span><span class="s3">5</span><span class="s0">, </span><span class="s1">n_features</span><span class="s0">, </span><span class="s1">int(n_features / </span><span class="s3">4</span><span class="s1">))</span>

    <span class="s0">for </span><span class="s1">RandomProjection </span><span class="s0">in </span><span class="s1">all_RandomProjection:</span>
        <span class="s1">rp_dense = RandomProjection(n_components=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s1">).fit(data)</span>
        <span class="s1">rp_sparse = RandomProjection(n_components=</span><span class="s3">3</span><span class="s0">, </span><span class="s1">random_state=</span><span class="s3">1</span><span class="s1">).fit(</span>
            <span class="s1">sp.csr_matrix(data)</span>
        <span class="s1">)</span>
        <span class="s1">assert_array_almost_equal(</span>
            <span class="s1">densify(rp_dense.components_)</span><span class="s0">, </span><span class="s1">densify(rp_sparse.components_)</span>
        <span class="s1">)</span>


<span class="s0">def </span><span class="s1">test_johnson_lindenstrauss_min_dim():</span>
    <span class="s5">&quot;&quot;&quot;Test Johnson-Lindenstrauss for small eps. 
 
    Regression test for #17111: before #19374, 32-bit systems would fail. 
    &quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">johnson_lindenstrauss_min_dim(</span><span class="s3">100</span><span class="s0">, </span><span class="s1">eps=</span><span class="s3">1e-5</span><span class="s1">) == </span><span class="s3">368416070986</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_projection_cls&quot;</span><span class="s0">, </span><span class="s1">all_RandomProjection)</span>
<span class="s0">def </span><span class="s1">test_random_projection_feature_names_out(random_projection_cls):</span>
    <span class="s1">random_projection = random_projection_cls(n_components=</span><span class="s3">2</span><span class="s1">)</span>
    <span class="s1">random_projection.fit(data)</span>
    <span class="s1">names_out = random_projection.get_feature_names_out()</span>
    <span class="s1">class_name_lower = random_projection_cls.__name__.lower()</span>
    <span class="s1">expected_names_out = np.array(</span>
        <span class="s1">[</span><span class="s4">f&quot;</span><span class="s0">{</span><span class="s1">class_name_lower</span><span class="s0">}{</span><span class="s1">i</span><span class="s0">}</span><span class="s4">&quot; </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(random_projection.n_components_)]</span><span class="s0">,</span>
        <span class="s1">dtype=object</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">assert_array_equal(names_out</span><span class="s0">, </span><span class="s1">expected_names_out)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;n_samples&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;n_features&quot;</span><span class="s0">, </span><span class="s1">(</span><span class="s3">2</span><span class="s0">, </span><span class="s3">9</span><span class="s0">, </span><span class="s3">10</span><span class="s0">, </span><span class="s3">11</span><span class="s0">, </span><span class="s3">1000</span><span class="s1">))</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_projection_cls&quot;</span><span class="s0">, </span><span class="s1">all_RandomProjection)</span>
<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;compute_inverse_components&quot;</span><span class="s0">, </span><span class="s1">[</span><span class="s0">True, False</span><span class="s1">])</span>
<span class="s0">def </span><span class="s1">test_inverse_transform(</span>
    <span class="s1">n_samples</span><span class="s0">,</span>
    <span class="s1">n_features</span><span class="s0">,</span>
    <span class="s1">random_projection_cls</span><span class="s0">,</span>
    <span class="s1">compute_inverse_components</span><span class="s0">,</span>
    <span class="s1">global_random_seed</span><span class="s0">,</span>
<span class="s1">):</span>
    <span class="s1">n_components = </span><span class="s3">10</span>

    <span class="s1">random_projection = random_projection_cls(</span>
        <span class="s1">n_components=n_components</span><span class="s0">,</span>
        <span class="s1">compute_inverse_components=compute_inverse_components</span><span class="s0">,</span>
        <span class="s1">random_state=global_random_seed</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s1">X_dense</span><span class="s0">, </span><span class="s1">X_csr = make_sparse_random_data(</span>
        <span class="s1">n_samples</span><span class="s0">,</span>
        <span class="s1">n_features</span><span class="s0">,</span>
        <span class="s1">n_samples * n_features // </span><span class="s3">100 </span><span class="s1">+ </span><span class="s3">1</span><span class="s0">,</span>
        <span class="s1">random_state=global_random_seed</span><span class="s0">,</span>
    <span class="s1">)</span>

    <span class="s0">for </span><span class="s1">X </span><span class="s0">in </span><span class="s1">[X_dense</span><span class="s0">, </span><span class="s1">X_csr]:</span>
        <span class="s0">with </span><span class="s1">warnings.catch_warnings():</span>
            <span class="s1">warnings.filterwarnings(</span>
                <span class="s4">&quot;ignore&quot;</span><span class="s0">,</span>
                <span class="s1">message=(</span>
                    <span class="s4">&quot;The number of components is higher than the number of features&quot;</span>
                <span class="s1">)</span><span class="s0">,</span>
                <span class="s1">category=DataDimensionalityWarning</span><span class="s0">,</span>
            <span class="s1">)</span>
            <span class="s1">projected = random_projection.fit_transform(X)</span>

        <span class="s0">if </span><span class="s1">compute_inverse_components:</span>
            <span class="s0">assert </span><span class="s1">hasattr(random_projection</span><span class="s0">, </span><span class="s4">&quot;inverse_components_&quot;</span><span class="s1">)</span>
            <span class="s1">inv_components = random_projection.inverse_components_</span>
            <span class="s0">assert </span><span class="s1">inv_components.shape == (n_features</span><span class="s0">, </span><span class="s1">n_components)</span>

        <span class="s1">projected_back = random_projection.inverse_transform(projected)</span>
        <span class="s0">assert </span><span class="s1">projected_back.shape == X.shape</span>

        <span class="s1">projected_again = random_projection.transform(projected_back)</span>
        <span class="s0">if </span><span class="s1">hasattr(projected</span><span class="s0">, </span><span class="s4">&quot;toarray&quot;</span><span class="s1">):</span>
            <span class="s1">projected = projected.toarray()</span>
        <span class="s1">assert_allclose(projected</span><span class="s0">, </span><span class="s1">projected_again</span><span class="s0">, </span><span class="s1">rtol=</span><span class="s3">1e-7</span><span class="s0">, </span><span class="s1">atol=</span><span class="s3">1e-10</span><span class="s1">)</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_projection_cls&quot;</span><span class="s0">, </span><span class="s1">all_RandomProjection)</span>
<span class="s1">@pytest.mark.parametrize(</span>
    <span class="s4">&quot;input_dtype, expected_dtype&quot;</span><span class="s0">,</span>
    <span class="s1">(</span>
        <span class="s1">(np.float32</span><span class="s0">, </span><span class="s1">np.float32)</span><span class="s0">,</span>
        <span class="s1">(np.float64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int32</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
        <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.float64)</span><span class="s0">,</span>
    <span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>
<span class="s0">def </span><span class="s1">test_random_projection_dtype_match(</span>
    <span class="s1">random_projection_cls</span><span class="s0">, </span><span class="s1">input_dtype</span><span class="s0">, </span><span class="s1">expected_dtype</span>
<span class="s1">):</span>
    <span class="s2"># Verify output matrix dtype</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X = rng.rand(</span><span class="s3">25</span><span class="s0">, </span><span class="s3">3000</span><span class="s1">)</span>
    <span class="s1">rp = random_projection_cls(random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">transformed = rp.fit_transform(X.astype(input_dtype))</span>

    <span class="s0">assert </span><span class="s1">rp.components_.dtype == expected_dtype</span>
    <span class="s0">assert </span><span class="s1">transformed.dtype == expected_dtype</span>


<span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;random_projection_cls&quot;</span><span class="s0">, </span><span class="s1">all_RandomProjection)</span>
<span class="s0">def </span><span class="s1">test_random_projection_numerical_consistency(random_projection_cls):</span>
    <span class="s2"># Verify numerical consistency among np.float32 and np.float64</span>
    <span class="s1">atol = </span><span class="s3">1e-5</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">42</span><span class="s1">)</span>
    <span class="s1">X = rng.rand(</span><span class="s3">25</span><span class="s0">, </span><span class="s3">3000</span><span class="s1">)</span>
    <span class="s1">rp_32 = random_projection_cls(random_state=</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">rp_64 = random_projection_cls(random_state=</span><span class="s3">0</span><span class="s1">)</span>

    <span class="s1">projection_32 = rp_32.fit_transform(X.astype(np.float32))</span>
    <span class="s1">projection_64 = rp_64.fit_transform(X.astype(np.float64))</span>

    <span class="s1">assert_allclose(projection_64</span><span class="s0">, </span><span class="s1">projection_32</span><span class="s0">, </span><span class="s1">atol=atol)</span>

    <span class="s1">assert_allclose_dense_sparse(rp_32.components_</span><span class="s0">, </span><span class="s1">rp_64.components_)</span>
</pre>
</body>
</html>
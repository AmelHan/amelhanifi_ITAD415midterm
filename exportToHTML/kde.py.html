<html>
<head>
<title>kde.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
kde.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Univariate Kernel Density Estimators 
 
References 
---------- 
Racine, Jeff. (2008) &quot;Nonparametric Econometrics: A Primer,&quot; Foundation and 
    Trends in Econometrics: Vol 3: No 1, pp1-88. 
    http://dx.doi.org/10.1561/0800000009 
 
https://en.wikipedia.org/wiki/Kernel_%28statistics%29 
 
Silverman, B.W.  Density Estimation for Statistics and Data Analysis. 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">integrate</span><span class="s2">, </span><span class="s1">stats</span>

<span class="s2">from </span><span class="s1">statsmodels.sandbox.nonparametric </span><span class="s2">import </span><span class="s1">kernels</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.decorators </span><span class="s2">import </span><span class="s1">cache_readonly</span>
<span class="s2">from </span><span class="s1">statsmodels.tools.validation </span><span class="s2">import </span><span class="s1">array_like</span><span class="s2">, </span><span class="s1">float_like</span>

<span class="s2">from </span><span class="s1">. </span><span class="s2">import </span><span class="s1">bandwidths</span>
<span class="s2">from </span><span class="s1">.kdetools </span><span class="s2">import </span><span class="s1">forrt</span><span class="s2">, </span><span class="s1">revrt</span><span class="s2">, </span><span class="s1">silverman_transform</span>
<span class="s2">from </span><span class="s1">.linbin </span><span class="s2">import </span><span class="s1">fast_linbin</span>

<span class="s3"># Kernels Switch for estimators</span>

<span class="s1">kernel_switch = dict(</span>
    <span class="s1">gau=kernels.Gaussian</span><span class="s2">,</span>
    <span class="s1">epa=kernels.Epanechnikov</span><span class="s2">,</span>
    <span class="s1">uni=kernels.Uniform</span><span class="s2">,</span>
    <span class="s1">tri=kernels.Triangular</span><span class="s2">,</span>
    <span class="s1">biw=kernels.Biweight</span><span class="s2">,</span>
    <span class="s1">triw=kernels.Triweight</span><span class="s2">,</span>
    <span class="s1">cos=kernels.Cosine</span><span class="s2">,</span>
    <span class="s1">cos2=kernels.Cosine2</span><span class="s2">,</span>
    <span class="s1">tric=kernels.Tricube</span>
<span class="s1">)</span>


<span class="s2">def </span><span class="s1">_checkisfit(self):</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">self.density</span>
    <span class="s2">except </span><span class="s1">Exception:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Call fit to fit the density first&quot;</span><span class="s1">)</span>


<span class="s3"># Kernel Density Estimator Class</span>
<span class="s2">class </span><span class="s1">KDEUnivariate:</span>
    <span class="s0">&quot;&quot;&quot; 
    Univariate Kernel Density Estimator. 
 
    Parameters 
    ---------- 
    endog : array_like 
        The variable for which the density estimate is desired. 
 
    Notes 
    ----- 
    If cdf, sf, cumhazard, or entropy are computed, they are computed based on 
    the definition of the kernel rather than the FFT approximation, even if 
    the density is fit with FFT = True. 
 
    `KDEUnivariate` is much faster than `KDEMultivariate`, due to its FFT-based 
    implementation.  It should be preferred for univariate, continuous data. 
    `KDEMultivariate` also supports mixed data. 
 
    See Also 
    -------- 
    KDEMultivariate 
    kdensity, kdensityfft 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import statsmodels.api as sm 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
 
    &gt;&gt;&gt; nobs = 300 
    &gt;&gt;&gt; np.random.seed(1234)  # Seed random generator 
    &gt;&gt;&gt; dens = sm.nonparametric.KDEUnivariate(np.random.normal(size=nobs)) 
    &gt;&gt;&gt; dens.fit() 
    &gt;&gt;&gt; plt.plot(dens.cdf) 
    &gt;&gt;&gt; plt.show() 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog):</span>
        <span class="s1">self.endog = array_like(endog</span><span class="s2">, </span><span class="s4">&quot;endog&quot;</span><span class="s2">, </span><span class="s1">ndim=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">contiguous=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">fit(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">kernel=</span><span class="s4">&quot;gau&quot;</span><span class="s2">,</span>
        <span class="s1">bw=</span><span class="s4">&quot;normal_reference&quot;</span><span class="s2">,</span>
        <span class="s1">fft=</span><span class="s2">True,</span>
        <span class="s1">weights=</span><span class="s2">None,</span>
        <span class="s1">gridsize=</span><span class="s2">None,</span>
        <span class="s1">adjust=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">cut=</span><span class="s5">3</span><span class="s2">,</span>
        <span class="s1">clip=(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Attach the density estimate to the KDEUnivariate class. 
 
        Parameters 
        ---------- 
        kernel : str 
            The Kernel to be used. Choices are: 
 
            - &quot;biw&quot; for biweight 
            - &quot;cos&quot; for cosine 
            - &quot;epa&quot; for Epanechnikov 
            - &quot;gau&quot; for Gaussian. 
            - &quot;tri&quot; for triangular 
            - &quot;triw&quot; for triweight 
            - &quot;uni&quot; for uniform 
 
        bw : str, float, callable 
            The bandwidth to use. Choices are: 
 
            - &quot;scott&quot; - 1.059 * A * nobs ** (-1/5.), where A is 
              `min(std(x),IQR/1.34)` 
            - &quot;silverman&quot; - .9 * A * nobs ** (-1/5.), where A is 
              `min(std(x),IQR/1.34)` 
            - &quot;normal_reference&quot; - C * A * nobs ** (-1/5.), where C is 
              calculated from the kernel. Equivalent (up to 2 dp) to the 
              &quot;scott&quot; bandwidth for gaussian kernels. See bandwidths.py 
            - If a float is given, its value is used as the bandwidth. 
            - If a callable is given, it's return value is used. 
              The callable should take exactly two parameters, i.e., 
              fn(x, kern), and return a float, where: 
 
              * x - the clipped input data 
              * kern - the kernel instance used 
 
        fft : bool 
            Whether or not to use FFT. FFT implementation is more 
            computationally efficient. However, only the Gaussian kernel 
            is implemented. If FFT is False, then a 'nobs' x 'gridsize' 
            intermediate array is created. 
        gridsize : int 
            If gridsize is None, max(len(x), 50) is used. 
        cut : float 
            Defines the length of the grid past the lowest and highest values 
            of x so that the kernel goes to zero. The end points are 
            ``min(x) - cut * adjust * bw`` and ``max(x) + cut * adjust * bw``. 
        adjust : float 
            An adjustment factor for the bw. Bandwidth becomes bw * adjust. 
 
        Returns 
        ------- 
        KDEUnivariate 
            The instance fit, 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(bw</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">self.bw_method = bw</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.bw_method = </span><span class="s4">&quot;user-given&quot;</span>
            <span class="s2">if not </span><span class="s1">callable(bw):</span>
                <span class="s1">bw = float_like(bw</span><span class="s2">, </span><span class="s4">&quot;bw&quot;</span><span class="s1">)</span>

        <span class="s1">endog = self.endog</span>

        <span class="s2">if </span><span class="s1">fft:</span>
            <span class="s2">if </span><span class="s1">kernel != </span><span class="s4">&quot;gau&quot;</span><span class="s1">:</span>
                <span class="s1">msg = </span><span class="s4">&quot;Only gaussian kernel is available for fft&quot;</span>
                <span class="s2">raise </span><span class="s1">NotImplementedError(msg)</span>
            <span class="s2">if </span><span class="s1">weights </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">msg = </span><span class="s4">&quot;Weights are not implemented for fft&quot;</span>
                <span class="s2">raise </span><span class="s1">NotImplementedError(msg)</span>
            <span class="s1">density</span><span class="s2">, </span><span class="s1">grid</span><span class="s2">, </span><span class="s1">bw = kdensityfft(</span>
                <span class="s1">endog</span><span class="s2">,</span>
                <span class="s1">kernel=kernel</span><span class="s2">,</span>
                <span class="s1">bw=bw</span><span class="s2">,</span>
                <span class="s1">adjust=adjust</span><span class="s2">,</span>
                <span class="s1">weights=weights</span><span class="s2">,</span>
                <span class="s1">gridsize=gridsize</span><span class="s2">,</span>
                <span class="s1">clip=clip</span><span class="s2">,</span>
                <span class="s1">cut=cut</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">density</span><span class="s2">, </span><span class="s1">grid</span><span class="s2">, </span><span class="s1">bw = kdensity(</span>
                <span class="s1">endog</span><span class="s2">,</span>
                <span class="s1">kernel=kernel</span><span class="s2">,</span>
                <span class="s1">bw=bw</span><span class="s2">,</span>
                <span class="s1">adjust=adjust</span><span class="s2">,</span>
                <span class="s1">weights=weights</span><span class="s2">,</span>
                <span class="s1">gridsize=gridsize</span><span class="s2">,</span>
                <span class="s1">clip=clip</span><span class="s2">,</span>
                <span class="s1">cut=cut</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s1">self.density = density</span>
        <span class="s1">self.support = grid</span>
        <span class="s1">self.bw = bw</span>
        <span class="s1">self.kernel = kernel_switch[kernel](h=bw)  </span><span class="s3"># we instantiate twice,</span>
        <span class="s3"># should this passed to funcs?</span>
        <span class="s3"># put here to ensure empty cache after re-fit with new options</span>
        <span class="s1">self.kernel.weights = weights</span>
        <span class="s2">if </span><span class="s1">weights </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.kernel.weights /= weights.sum()</span>
        <span class="s1">self._cache = {}</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cdf(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the cumulative distribution function evaluated at the support. 
 
        Notes 
        ----- 
        Will not work if fit has not been called. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>
        <span class="s1">kern = self.kernel</span>
        <span class="s2">if </span><span class="s1">kern.domain </span><span class="s2">is None</span><span class="s1">:  </span><span class="s3"># TODO: test for grid point at domain bound</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = -np.inf</span><span class="s2">, </span><span class="s1">np.inf</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = kern.domain</span>

        <span class="s2">def </span><span class="s1">func(x</span><span class="s2">, </span><span class="s1">s):</span>
            <span class="s2">return </span><span class="s1">np.squeeze(kern.density(s</span><span class="s2">, </span><span class="s1">x))</span>

        <span class="s1">support = self.support</span>
        <span class="s1">support = np.r_[a</span><span class="s2">, </span><span class="s1">support]</span>
        <span class="s1">gridsize = len(support)</span>
        <span class="s1">endog = self.endog</span>
        <span class="s1">probs = [</span>
            <span class="s1">integrate.quad(func</span><span class="s2">, </span><span class="s1">support[i - </span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">support[i]</span><span class="s2">, </span><span class="s1">args=endog)[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">gridsize)</span>
        <span class="s1">]</span>
        <span class="s2">return </span><span class="s1">np.cumsum(probs)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">cumhazard(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the hazard function evaluated at the support. 
 
        Notes 
        ----- 
        Will not work if fit has not been called. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>
        <span class="s2">return </span><span class="s1">-np.log(self.sf)</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">sf(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the survival function evaluated at the support. 
 
        Notes 
        ----- 
        Will not work if fit has not been called. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>
        <span class="s2">return </span><span class="s5">1 </span><span class="s1">- self.cdf</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">entropy(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the differential entropy evaluated at the support 
 
        Notes 
        ----- 
        Will not work if fit has not been called. 1e-12 is added to each 
        probability to ensure that log(0) is not called. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>

        <span class="s2">def </span><span class="s1">entr(x</span><span class="s2">, </span><span class="s1">s):</span>
            <span class="s1">pdf = kern.density(s</span><span class="s2">, </span><span class="s1">x)</span>
            <span class="s2">return </span><span class="s1">pdf * np.log(pdf + </span><span class="s5">1e-12</span><span class="s1">)</span>

        <span class="s1">kern = self.kernel</span>

        <span class="s2">if </span><span class="s1">kern.domain </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = self.domain</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">a</span><span class="s2">, </span><span class="s1">b = -np.inf</span><span class="s2">, </span><span class="s1">np.inf</span>
        <span class="s1">endog = self.endog</span>
        <span class="s3"># TODO: below could run into integr problems, cf. stats.dist._entropy</span>
        <span class="s2">return </span><span class="s1">-integrate.quad(entr</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">args=(endog</span><span class="s2">,</span><span class="s1">))[</span><span class="s5">0</span><span class="s1">]</span>

    <span class="s1">@cache_readonly</span>
    <span class="s2">def </span><span class="s1">icdf(self):</span>
        <span class="s0">&quot;&quot;&quot; 
        Inverse Cumulative Distribution (Quantile) Function 
 
        Notes 
        ----- 
        Will not work if fit has not been called. Uses 
        `scipy.stats.mstats.mquantiles`. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>
        <span class="s1">gridsize = len(self.density)</span>
        <span class="s2">return </span><span class="s1">stats.mstats.mquantiles(self.endog</span><span class="s2">, </span><span class="s1">np.linspace(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">gridsize))</span>

    <span class="s2">def </span><span class="s1">evaluate(self</span><span class="s2">, </span><span class="s1">point):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evaluate density at a point or points. 
 
        Parameters 
        ---------- 
        point : {float, ndarray} 
            Point(s) at which to evaluate the density. 
        &quot;&quot;&quot;</span>
        <span class="s1">_checkisfit(self)</span>
        <span class="s2">return </span><span class="s1">self.kernel.density(self.endog</span><span class="s2">, </span><span class="s1">point)</span>


<span class="s3"># Kernel Density Estimator Functions</span>
<span class="s2">def </span><span class="s1">kdensity(</span>
    <span class="s1">x</span><span class="s2">,</span>
    <span class="s1">kernel=</span><span class="s4">&quot;gau&quot;</span><span class="s2">,</span>
    <span class="s1">bw=</span><span class="s4">&quot;normal_reference&quot;</span><span class="s2">,</span>
    <span class="s1">weights=</span><span class="s2">None,</span>
    <span class="s1">gridsize=</span><span class="s2">None,</span>
    <span class="s1">adjust=</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">clip=(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">,</span>
    <span class="s1">cut=</span><span class="s5">3</span><span class="s2">,</span>
    <span class="s1">retgrid=</span><span class="s2">True,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Rosenblatt-Parzen univariate kernel density estimator. 
 
    Parameters 
    ---------- 
    x : array_like 
        The variable for which the density estimate is desired. 
    kernel : str 
        The Kernel to be used. Choices are 
        - &quot;biw&quot; for biweight 
        - &quot;cos&quot; for cosine 
        - &quot;epa&quot; for Epanechnikov 
        - &quot;gau&quot; for Gaussian. 
        - &quot;tri&quot; for triangular 
        - &quot;triw&quot; for triweight 
        - &quot;uni&quot; for uniform 
    bw : str, float, callable 
        The bandwidth to use. Choices are: 
 
        - &quot;scott&quot; - 1.059 * A * nobs ** (-1/5.), where A is 
          `min(std(x),IQR/1.34)` 
        - &quot;silverman&quot; - .9 * A * nobs ** (-1/5.), where A is 
          `min(std(x),IQR/1.34)` 
        - &quot;normal_reference&quot; - C * A * nobs ** (-1/5.), where C is 
          calculated from the kernel. Equivalent (up to 2 dp) to the 
          &quot;scott&quot; bandwidth for gaussian kernels. See bandwidths.py 
        - If a float is given, its value is used as the bandwidth. 
        - If a callable is given, it's return value is used. 
          The callable should take exactly two parameters, i.e., 
          fn(x, kern), and return a float, where: 
 
          * x - the clipped input data 
          * kern - the kernel instance used 
 
    weights : array or None 
        Optional  weights. If the x value is clipped, then this weight is 
        also dropped. 
    gridsize : int 
        If gridsize is None, max(len(x), 50) is used. 
    adjust : float 
        An adjustment factor for the bw. Bandwidth becomes bw * adjust. 
    clip : tuple 
        Observations in x that are outside of the range given by clip are 
        dropped. The number of observations in x is then shortened. 
    cut : float 
        Defines the length of the grid past the lowest and highest values of x 
        so that the kernel goes to zero. The end points are 
        -/+ cut*bw*{min(x) or max(x)} 
    retgrid : bool 
        Whether or not to return the grid over which the density is estimated. 
 
    Returns 
    ------- 
    density : ndarray 
        The densities estimated at the grid points. 
    grid : ndarray, optional 
        The grid points at which the density is estimated. 
 
    Notes 
    ----- 
    Creates an intermediate (`gridsize` x `nobs`) array. Use FFT for a more 
    computationally efficient version. 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.asarray(x)</span>
    <span class="s2">if </span><span class="s1">x.ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">x = x[:</span><span class="s2">, None</span><span class="s1">]</span>
    <span class="s1">clip_x = np.logical_and(x &gt; clip[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x &lt; clip[</span><span class="s5">1</span><span class="s1">])</span>
    <span class="s1">x = x[clip_x]</span>

    <span class="s1">nobs = len(x)  </span><span class="s3"># after trim</span>

    <span class="s2">if </span><span class="s1">gridsize </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">gridsize = max(nobs</span><span class="s2">, </span><span class="s5">50</span><span class="s1">)  </span><span class="s3"># do not need to resize if no FFT</span>

        <span class="s3"># handle weights</span>
    <span class="s2">if </span><span class="s1">weights </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">weights = np.ones(nobs)</span>
        <span class="s1">q = nobs</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s3"># ensure weights is a numpy array</span>
        <span class="s1">weights = np.asarray(weights)</span>

        <span class="s2">if </span><span class="s1">len(weights) != len(clip_x):</span>
            <span class="s1">msg = </span><span class="s4">&quot;The length of the weights must be the same as the given x.&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
        <span class="s1">weights = weights[clip_x.squeeze()]</span>
        <span class="s1">q = weights.sum()</span>

    <span class="s3"># Get kernel object corresponding to selection</span>
    <span class="s1">kern = kernel_switch[kernel]()</span>

    <span class="s2">if </span><span class="s1">callable(bw):</span>
        <span class="s1">bw = float(bw(x</span><span class="s2">, </span><span class="s1">kern))</span>
        <span class="s3"># user passed a callable custom bandwidth function</span>
    <span class="s2">elif </span><span class="s1">isinstance(bw</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s1">bw = bandwidths.select_bandwidth(x</span><span class="s2">, </span><span class="s1">bw</span><span class="s2">, </span><span class="s1">kern)</span>
        <span class="s3"># will cross-val fit this pattern?</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">bw = float_like(bw</span><span class="s2">, </span><span class="s4">&quot;bw&quot;</span><span class="s1">)</span>

    <span class="s1">bw *= adjust</span>

    <span class="s1">a = np.min(x</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">) - cut * bw</span>
    <span class="s1">b = np.max(x</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">) + cut * bw</span>
    <span class="s1">grid = np.linspace(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">gridsize)</span>

    <span class="s1">k = (</span>
        <span class="s1">x.T - grid[:</span><span class="s2">, None</span><span class="s1">]</span>
    <span class="s1">) / bw  </span><span class="s3"># uses broadcasting to make a gridsize x nobs</span>

    <span class="s3"># set kernel bandwidth</span>
    <span class="s1">kern.seth(bw)</span>

    <span class="s3"># truncate to domain</span>
    <span class="s2">if </span><span class="s1">(</span>
        <span class="s1">kern.domain </span><span class="s2">is not None</span>
    <span class="s1">):  </span><span class="s3"># will not work for piecewise kernels like parzen</span>
        <span class="s1">z_lo</span><span class="s2">, </span><span class="s1">z_high = kern.domain</span>
        <span class="s1">domain_mask = (k &lt; z_lo) | (k &gt; z_high)</span>
        <span class="s1">k = kern(k)  </span><span class="s3"># estimate density</span>
        <span class="s1">k[domain_mask] = </span><span class="s5">0</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">k = kern(k)  </span><span class="s3"># estimate density</span>

    <span class="s1">k[k &lt; </span><span class="s5">0</span><span class="s1">] = </span><span class="s5">0  </span><span class="s3"># get rid of any negative values, do we need this?</span>

    <span class="s1">dens = np.dot(k</span><span class="s2">, </span><span class="s1">weights) / (q * bw)</span>

    <span class="s2">if </span><span class="s1">retgrid:</span>
        <span class="s2">return </span><span class="s1">dens</span><span class="s2">, </span><span class="s1">grid</span><span class="s2">, </span><span class="s1">bw</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">dens</span><span class="s2">, </span><span class="s1">bw</span>


<span class="s2">def </span><span class="s1">kdensityfft(</span>
    <span class="s1">x</span><span class="s2">,</span>
    <span class="s1">kernel=</span><span class="s4">&quot;gau&quot;</span><span class="s2">,</span>
    <span class="s1">bw=</span><span class="s4">&quot;normal_reference&quot;</span><span class="s2">,</span>
    <span class="s1">weights=</span><span class="s2">None,</span>
    <span class="s1">gridsize=</span><span class="s2">None,</span>
    <span class="s1">adjust=</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">clip=(-np.inf</span><span class="s2">, </span><span class="s1">np.inf)</span><span class="s2">,</span>
    <span class="s1">cut=</span><span class="s5">3</span><span class="s2">,</span>
    <span class="s1">retgrid=</span><span class="s2">True,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Rosenblatt-Parzen univariate kernel density estimator 
 
    Parameters 
    ---------- 
    x : array_like 
        The variable for which the density estimate is desired. 
    kernel : str 
        ONLY GAUSSIAN IS CURRENTLY IMPLEMENTED. 
        &quot;bi&quot; for biweight 
        &quot;cos&quot; for cosine 
        &quot;epa&quot; for Epanechnikov, default 
        &quot;epa2&quot; for alternative Epanechnikov 
        &quot;gau&quot; for Gaussian. 
        &quot;par&quot; for Parzen 
        &quot;rect&quot; for rectangular 
        &quot;tri&quot; for triangular 
    bw : str, float, callable 
        The bandwidth to use. Choices are: 
 
        - &quot;scott&quot; - 1.059 * A * nobs ** (-1/5.), where A is 
          `min(std(x),IQR/1.34)` 
        - &quot;silverman&quot; - .9 * A * nobs ** (-1/5.), where A is 
          `min(std(x),IQR/1.34)` 
        - &quot;normal_reference&quot; - C * A * nobs ** (-1/5.), where C is 
          calculated from the kernel. Equivalent (up to 2 dp) to the 
          &quot;scott&quot; bandwidth for gaussian kernels. See bandwidths.py 
        - If a float is given, its value is used as the bandwidth. 
        - If a callable is given, it's return value is used. 
          The callable should take exactly two parameters, i.e., 
          fn(x, kern), and return a float, where: 
 
          * x - the clipped input data 
          * kern - the kernel instance used 
 
    weights : array or None 
        WEIGHTS ARE NOT CURRENTLY IMPLEMENTED. 
        Optional  weights. If the x value is clipped, then this weight is 
        also dropped. 
    gridsize : int 
        If gridsize is None, min(len(x), 512) is used. Note that the provided 
        number is rounded up to the next highest power of 2. 
    adjust : float 
        An adjustment factor for the bw. Bandwidth becomes bw * adjust. 
        clip : tuple 
        Observations in x that are outside of the range given by clip are 
        dropped. The number of observations in x is then shortened. 
    cut : float 
        Defines the length of the grid past the lowest and highest values of x 
        so that the kernel goes to zero. The end points are 
        -/+ cut*bw*{x.min() or x.max()} 
    retgrid : bool 
        Whether or not to return the grid over which the density is estimated. 
 
    Returns 
    ------- 
    density : ndarray 
        The densities estimated at the grid points. 
    grid : ndarray, optional 
        The grid points at which the density is estimated. 
 
    Notes 
    ----- 
    Only the default kernel is implemented. Weights are not implemented yet. 
    This follows Silverman (1982) with changes suggested by Jones and Lotwick 
    (1984). However, the discretization step is replaced by linear binning 
    of Fan and Marron (1994). This should be extended to accept the parts 
    that are dependent only on the data to speed things up for 
    cross-validation. 
 
    References 
    ---------- 
    Fan, J. and J.S. Marron. (1994) `Fast implementations of nonparametric 
        curve estimators`. Journal of Computational and Graphical Statistics. 
        3.1, 35-56. 
    Jones, M.C. and H.W. Lotwick. (1984) `Remark AS R50: A Remark on Algorithm 
        AS 176. Kernal Density Estimation Using the Fast Fourier Transform`. 
        Journal of the Royal Statistical Society. Series C. 33.1, 120-2. 
    Silverman, B.W. (1982) `Algorithm AS 176. Kernel density estimation using 
        the Fast Fourier Transform. Journal of the Royal Statistical Society. 
        Series C. 31.2, 93-9. 
    &quot;&quot;&quot;</span>
    <span class="s1">x = np.asarray(x)</span>
    <span class="s3"># will not work for two columns.</span>
    <span class="s1">x = x[np.logical_and(x &gt; clip[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x &lt; clip[</span><span class="s5">1</span><span class="s1">])]</span>

    <span class="s3"># Get kernel object corresponding to selection</span>
    <span class="s1">kern = kernel_switch[kernel]()</span>

    <span class="s2">if </span><span class="s1">callable(bw):</span>
        <span class="s1">bw = float(bw(x</span><span class="s2">, </span><span class="s1">kern))</span>
        <span class="s3"># user passed a callable custom bandwidth function</span>
    <span class="s2">elif </span><span class="s1">isinstance(bw</span><span class="s2">, </span><span class="s1">str):</span>
        <span class="s3"># if bw is None, select optimal bandwidth for kernel</span>
        <span class="s1">bw = bandwidths.select_bandwidth(x</span><span class="s2">, </span><span class="s1">bw</span><span class="s2">, </span><span class="s1">kern)</span>
        <span class="s3"># will cross-val fit this pattern?</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">bw = float_like(bw</span><span class="s2">, </span><span class="s4">&quot;bw&quot;</span><span class="s1">)</span>

    <span class="s1">bw *= adjust</span>

    <span class="s1">nobs = len(x)  </span><span class="s3"># after trim</span>

    <span class="s3"># 1 Make grid and discretize the data</span>
    <span class="s2">if </span><span class="s1">gridsize </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">gridsize = np.max((nobs</span><span class="s2">, </span><span class="s5">512.0</span><span class="s1">))</span>
    <span class="s1">gridsize = </span><span class="s5">2 </span><span class="s1">** np.ceil(np.log2(gridsize))  </span><span class="s3"># round to next power of 2</span>

    <span class="s1">a = np.min(x) - cut * bw</span>
    <span class="s1">b = np.max(x) + cut * bw</span>
    <span class="s1">grid</span><span class="s2">, </span><span class="s1">delta = np.linspace(a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">int(gridsize)</span><span class="s2">, </span><span class="s1">retstep=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">RANGE = b - a</span>

    <span class="s3"># TODO: Fix this?</span>
    <span class="s3"># This is the Silverman binning function, but I believe it's buggy (SS)</span>
    <span class="s3"># weighting according to Silverman</span>
    <span class="s3">#    count = counts(x,grid)</span>
    <span class="s3">#    binned = np.zeros_like(grid)    #xi_{k} in Silverman</span>
    <span class="s3">#    j = 0</span>
    <span class="s3">#    for k in range(int(gridsize-1)):</span>
    <span class="s3">#        if count[k]&gt;0: # there are points of x in the grid here</span>
    <span class="s3">#            Xingrid = x[j:j+count[k]] # get all these points</span>
    <span class="s3">#            # get weights at grid[k],grid[k+1]</span>
    <span class="s3">#            binned[k] += np.sum(grid[k+1]-Xingrid)</span>
    <span class="s3">#            binned[k+1] += np.sum(Xingrid-grid[k])</span>
    <span class="s3">#            j += count[k]</span>
    <span class="s3">#    binned /= (nobs)*delta**2 # normalize binned to sum to 1/delta</span>

    <span class="s3"># NOTE: THE ABOVE IS WRONG, JUST TRY WITH LINEAR BINNING</span>
    <span class="s1">binned = fast_linbin(x</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">b</span><span class="s2">, </span><span class="s1">gridsize) / (delta * nobs)</span>

    <span class="s3"># step 2 compute FFT of the weights, using Munro (1976) FFT convention</span>
    <span class="s1">y = forrt(binned)</span>

    <span class="s3"># step 3 and 4 for optimal bw compute zstar and the density estimate f</span>
    <span class="s3"># do not have to redo the above if just changing bw, ie., for cross val</span>

    <span class="s3"># NOTE: silverman_transform is the closed form solution of the FFT of the</span>
    <span class="s3"># gaussian kernel. Not yet sure how to generalize it.</span>
    <span class="s1">zstar = silverman_transform(bw</span><span class="s2">, </span><span class="s1">gridsize</span><span class="s2">, </span><span class="s1">RANGE) * y</span>
    <span class="s3"># 3.49 in Silverman</span>
    <span class="s3"># 3.50 w Gaussian kernel</span>
    <span class="s1">f = revrt(zstar)</span>
    <span class="s2">if </span><span class="s1">retgrid:</span>
        <span class="s2">return </span><span class="s1">f</span><span class="s2">, </span><span class="s1">grid</span><span class="s2">, </span><span class="s1">bw</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">f</span><span class="s2">, </span><span class="s1">bw</span>
</pre>
</body>
</html>
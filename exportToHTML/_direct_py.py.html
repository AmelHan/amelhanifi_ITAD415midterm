<html>
<head>
<title>_direct_py.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #808080;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_direct_py.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">__future__ </span><span class="s0">import </span><span class="s1">annotations</span>
<span class="s0">from </span><span class="s1">typing </span><span class="s0">import </span><span class="s1">(  </span><span class="s2"># noqa: UP035</span>
    <span class="s1">Any</span><span class="s0">, </span><span class="s1">Callable</span><span class="s0">, </span><span class="s1">Iterable</span><span class="s0">, </span><span class="s1">TYPE_CHECKING</span>
<span class="s1">)</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">scipy.optimize </span><span class="s0">import </span><span class="s1">OptimizeResult</span>
<span class="s0">from </span><span class="s1">._constraints </span><span class="s0">import </span><span class="s1">old_bound_to_new</span><span class="s0">, </span><span class="s1">Bounds</span>
<span class="s0">from </span><span class="s1">._direct </span><span class="s0">import </span><span class="s1">direct </span><span class="s0">as </span><span class="s1">_direct  </span><span class="s2"># type: ignore</span>

<span class="s0">if </span><span class="s1">TYPE_CHECKING:</span>
    <span class="s0">import </span><span class="s1">numpy.typing </span><span class="s0">as </span><span class="s1">npt</span>

<span class="s1">__all__ = [</span><span class="s3">'direct'</span><span class="s1">]</span>

<span class="s1">ERROR_MESSAGES = (</span>
    <span class="s3">&quot;Number of function evaluations done is larger than maxfun={}&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Number of iterations is larger than maxiter={}&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;u[i] &lt; l[i] for some i&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;maxfun is too large&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Initialization failed&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;There was an error in the creation of the sample points&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;An error occurred while the function was sampled&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Maximum number of levels has been reached.&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Forced stop&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Invalid arguments&quot;</span><span class="s0">,</span>
    <span class="s3">&quot;Out of memory&quot;</span><span class="s0">,</span>
<span class="s1">)</span>

<span class="s1">SUCCESS_MESSAGES = (</span>
    <span class="s1">(</span><span class="s3">&quot;The best function value found is within a relative error={} &quot;</span>
     <span class="s3">&quot;of the (known) global optimum f_min&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s3">&quot;The volume of the hyperrectangle containing the lowest function value &quot;</span>
     <span class="s3">&quot;found is below vol_tol={}&quot;</span><span class="s1">)</span><span class="s0">,</span>
    <span class="s1">(</span><span class="s3">&quot;The side length measure of the hyperrectangle containing the lowest &quot;</span>
     <span class="s3">&quot;function value found is below len_tol={}&quot;</span><span class="s1">)</span><span class="s0">,</span>
<span class="s1">)</span>


<span class="s0">def </span><span class="s1">direct(</span>
    <span class="s1">func: Callable[[npt.ArrayLike</span><span class="s0">, </span><span class="s1">tuple[Any]]</span><span class="s0">, </span><span class="s1">float]</span><span class="s0">,</span>
    <span class="s1">bounds: Iterable | Bounds</span><span class="s0">,</span>
    <span class="s1">*</span><span class="s0">,</span>
    <span class="s1">args: tuple = ()</span><span class="s0">,</span>
    <span class="s1">eps: float = </span><span class="s4">1e-4</span><span class="s0">,</span>
    <span class="s1">maxfun: int | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None,</span>
    <span class="s1">maxiter: int = </span><span class="s4">1000</span><span class="s0">,</span>
    <span class="s1">locally_biased: bool = </span><span class="s0">True,</span>
    <span class="s1">f_min: float = -np.inf</span><span class="s0">,</span>
    <span class="s1">f_min_rtol: float = </span><span class="s4">1e-4</span><span class="s0">,</span>
    <span class="s1">vol_tol: float = </span><span class="s4">1e-16</span><span class="s0">,</span>
    <span class="s1">len_tol: float = </span><span class="s4">1e-6</span><span class="s0">,</span>
    <span class="s1">callback: Callable[[npt.ArrayLike]</span><span class="s0">, None</span><span class="s1">] | </span><span class="s0">None </span><span class="s1">= </span><span class="s0">None</span>
<span class="s1">) -&gt; OptimizeResult:</span>
    <span class="s5">&quot;&quot;&quot; 
    Finds the global minimum of a function using the 
    DIRECT algorithm. 
 
    Parameters 
    ---------- 
    func : callable 
        The objective function to be minimized. 
        ``func(x, *args) -&gt; float`` 
        where ``x`` is an 1-D array with shape (n,) and ``args`` is a tuple of 
        the fixed parameters needed to completely specify the function. 
    bounds : sequence or `Bounds` 
        Bounds for variables. There are two ways to specify the bounds: 
 
        1. Instance of `Bounds` class. 
        2. ``(min, max)`` pairs for each element in ``x``. 
 
    args : tuple, optional 
        Any additional fixed parameters needed to 
        completely specify the objective function. 
    eps : float, optional 
        Minimal required difference of the objective function values 
        between the current best hyperrectangle and the next potentially 
        optimal hyperrectangle to be divided. In consequence, `eps` serves as a 
        tradeoff between local and global search: the smaller, the more local 
        the search becomes. Default is 1e-4. 
    maxfun : int or None, optional 
        Approximate upper bound on objective function evaluations. 
        If `None`, will be automatically set to ``1000 * N`` where ``N`` 
        represents the number of dimensions. Will be capped if necessary to 
        limit DIRECT's RAM usage to app. 1GiB. This will only occur for very 
        high dimensional problems and excessive `max_fun`. Default is `None`. 
    maxiter : int, optional 
        Maximum number of iterations. Default is 1000. 
    locally_biased : bool, optional 
        If `True` (default), use the locally biased variant of the 
        algorithm known as DIRECT_L. If `False`, use the original unbiased 
        DIRECT algorithm. For hard problems with many local minima, 
        `False` is recommended. 
    f_min : float, optional 
        Function value of the global optimum. Set this value only if the 
        global optimum is known. Default is ``-np.inf``, so that this 
        termination criterion is deactivated. 
    f_min_rtol : float, optional 
        Terminate the optimization once the relative error between the 
        current best minimum `f` and the supplied global minimum `f_min` 
        is smaller than `f_min_rtol`. This parameter is only used if 
        `f_min` is also set. Must lie between 0 and 1. Default is 1e-4. 
    vol_tol : float, optional 
        Terminate the optimization once the volume of the hyperrectangle 
        containing the lowest function value is smaller than `vol_tol` 
        of the complete search space. Must lie between 0 and 1. 
        Default is 1e-16. 
    len_tol : float, optional 
        If `locally_biased=True`, terminate the optimization once half of 
        the normalized maximal side length of the hyperrectangle containing 
        the lowest function value is smaller than `len_tol`. 
        If `locally_biased=False`, terminate the optimization once half of 
        the normalized diagonal of the hyperrectangle containing the lowest 
        function value is smaller than `len_tol`. Must lie between 0 and 1. 
        Default is 1e-6. 
    callback : callable, optional 
        A callback function with signature ``callback(xk)`` where ``xk`` 
        represents the best function value found so far. 
 
    Returns 
    ------- 
    res : OptimizeResult 
        The optimization result represented as a ``OptimizeResult`` object. 
        Important attributes are: ``x`` the solution array, ``success`` a 
        Boolean flag indicating if the optimizer exited successfully and 
        ``message`` which describes the cause of the termination. See 
        `OptimizeResult` for a description of other attributes. 
 
    Notes 
    ----- 
    DIviding RECTangles (DIRECT) is a deterministic global 
    optimization algorithm capable of minimizing a black box function with 
    its variables subject to lower and upper bound constraints by sampling 
    potential solutions in the search space [1]_. The algorithm starts by 
    normalising the search space to an n-dimensional unit hypercube. 
    It samples the function at the center of this hypercube and at 2n 
    (n is the number of variables) more points, 2 in each coordinate 
    direction. Using these function values, DIRECT then divides the 
    domain into hyperrectangles, each having exactly one of the sampling 
    points as its center. In each iteration, DIRECT chooses, using the `eps` 
    parameter which defaults to 1e-4, some of the existing hyperrectangles 
    to be further divided. This division process continues until either the 
    maximum number of iterations or maximum function evaluations allowed 
    are exceeded, or the hyperrectangle containing the minimal value found 
    so far becomes small enough. If `f_min` is specified, the optimization 
    will stop once this function value is reached within a relative tolerance. 
    The locally biased variant of DIRECT (originally called DIRECT_L) [2]_ is 
    used by default. It makes the search more locally biased and more 
    efficient for cases with only a few local minima. 
 
    A note about termination criteria: `vol_tol` refers to the volume of the 
    hyperrectangle containing the lowest function value found so far. This 
    volume decreases exponentially with increasing dimensionality of the 
    problem. Therefore `vol_tol` should be decreased to avoid premature 
    termination of the algorithm for higher dimensions. This does not hold 
    for `len_tol`: it refers either to half of the maximal side length 
    (for ``locally_biased=True``) or half of the diagonal of the 
    hyperrectangle (for ``locally_biased=False``). 
 
    This code is based on the DIRECT 2.0.4 Fortran code by Gablonsky et al. at 
    https://ctk.math.ncsu.edu/SOFTWARE/DIRECTv204.tar.gz . 
    This original version was initially converted via f2c and then cleaned up 
    and reorganized by Steven G. Johnson, August 2007, for the NLopt project. 
    The `direct` function wraps the C implementation. 
 
    .. versionadded:: 1.9.0 
 
    References 
    ---------- 
    .. [1] Jones, D.R., Perttunen, C.D. &amp; Stuckman, B.E. Lipschitzian 
        optimization without the Lipschitz constant. J Optim Theory Appl 
        79, 157-181 (1993). 
    .. [2] Gablonsky, J., Kelley, C. A Locally-Biased form of the DIRECT 
        Algorithm. Journal of Global Optimization 21, 27-37 (2001). 
 
    Examples 
    -------- 
    The following example is a 2-D problem with four local minima: minimizing 
    the Styblinski-Tang function 
    (https://en.wikipedia.org/wiki/Test_functions_for_optimization). 
 
    &gt;&gt;&gt; from scipy.optimize import direct, Bounds 
    &gt;&gt;&gt; def styblinski_tang(pos): 
    ...     x, y = pos 
    ...     return 0.5 * (x**4 - 16*x**2 + 5*x + y**4 - 16*y**2 + 5*y) 
    &gt;&gt;&gt; bounds = Bounds([-4., -4.], [4., 4.]) 
    &gt;&gt;&gt; result = direct(styblinski_tang, bounds) 
    &gt;&gt;&gt; result.x, result.fun, result.nfev 
    array([-2.90321597, -2.90321597]), -78.3323279095383, 2011 
 
    The correct global minimum was found but with a huge number of function 
    evaluations (2011). Loosening the termination tolerances `vol_tol` and 
    `len_tol` can be used to stop DIRECT earlier. 
 
    &gt;&gt;&gt; result = direct(styblinski_tang, bounds, len_tol=1e-3) 
    &gt;&gt;&gt; result.x, result.fun, result.nfev 
    array([-2.9044353, -2.9044353]), -78.33230330754142, 207 
 
    &quot;&quot;&quot;</span>
    <span class="s2"># convert bounds to new Bounds class if necessary</span>
    <span class="s0">if not </span><span class="s1">isinstance(bounds</span><span class="s0">, </span><span class="s1">Bounds):</span>
        <span class="s0">if </span><span class="s1">isinstance(bounds</span><span class="s0">, </span><span class="s1">list) </span><span class="s0">or </span><span class="s1">isinstance(bounds</span><span class="s0">, </span><span class="s1">tuple):</span>
            <span class="s1">lb</span><span class="s0">, </span><span class="s1">ub = old_bound_to_new(bounds)</span>
            <span class="s1">bounds = Bounds(lb</span><span class="s0">, </span><span class="s1">ub)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">message = (</span><span class="s3">&quot;bounds must be a sequence or &quot;</span>
                       <span class="s3">&quot;instance of Bounds class&quot;</span><span class="s1">)</span>
            <span class="s0">raise </span><span class="s1">ValueError(message)</span>

    <span class="s1">lb = np.ascontiguousarray(bounds.lb</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>
    <span class="s1">ub = np.ascontiguousarray(bounds.ub</span><span class="s0">, </span><span class="s1">dtype=np.float64)</span>

    <span class="s2"># validate bounds</span>
    <span class="s2"># check that lower bounds are smaller than upper bounds</span>
    <span class="s0">if not </span><span class="s1">np.all(lb &lt; ub):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">'Bounds are not consistent min &lt; max'</span><span class="s1">)</span>
    <span class="s2"># check for infs</span>
    <span class="s0">if </span><span class="s1">(np.any(np.isinf(lb)) </span><span class="s0">or </span><span class="s1">np.any(np.isinf(ub))):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Bounds must not be inf.&quot;</span><span class="s1">)</span>

    <span class="s2"># validate tolerances</span>
    <span class="s0">if </span><span class="s1">(vol_tol &lt; </span><span class="s4">0 </span><span class="s0">or </span><span class="s1">vol_tol &gt; </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;vol_tol must be between 0 and 1.&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">(len_tol &lt; </span><span class="s4">0 </span><span class="s0">or </span><span class="s1">len_tol &gt; </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;len_tol must be between 0 and 1.&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">(f_min_rtol &lt; </span><span class="s4">0 </span><span class="s0">or </span><span class="s1">f_min_rtol &gt; </span><span class="s4">1</span><span class="s1">):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;f_min_rtol must be between 0 and 1.&quot;</span><span class="s1">)</span>

    <span class="s2"># validate maxfun and maxiter</span>
    <span class="s0">if </span><span class="s1">maxfun </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">maxfun = </span><span class="s4">1000 </span><span class="s1">* lb.shape[</span><span class="s4">0</span><span class="s1">]</span>
    <span class="s0">if not </span><span class="s1">isinstance(maxfun</span><span class="s0">, </span><span class="s1">int):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;maxfun must be of type int.&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">maxfun &lt; </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;maxfun must be &gt; 0.&quot;</span><span class="s1">)</span>
    <span class="s0">if not </span><span class="s1">isinstance(maxiter</span><span class="s0">, </span><span class="s1">int):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;maxiter must be of type int.&quot;</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">maxiter &lt; </span><span class="s4">0</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;maxiter must be &gt; 0.&quot;</span><span class="s1">)</span>

    <span class="s2"># validate boolean parameters</span>
    <span class="s0">if not </span><span class="s1">isinstance(locally_biased</span><span class="s0">, </span><span class="s1">bool):</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;locally_biased must be True or False.&quot;</span><span class="s1">)</span>

    <span class="s0">def </span><span class="s1">_func_wrap(x</span><span class="s0">, </span><span class="s1">args=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s1">x = np.asarray(x)</span>
        <span class="s0">if </span><span class="s1">args </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">f = func(x)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">f = func(x</span><span class="s0">, </span><span class="s1">*args)</span>
        <span class="s2"># always return a float</span>
        <span class="s0">return </span><span class="s1">np.asarray(f).item()</span>

    <span class="s2"># TODO: fix disp argument</span>
    <span class="s1">x</span><span class="s0">, </span><span class="s1">fun</span><span class="s0">, </span><span class="s1">ret_code</span><span class="s0">, </span><span class="s1">nfev</span><span class="s0">, </span><span class="s1">nit = _direct(</span>
        <span class="s1">_func_wrap</span><span class="s0">,</span>
        <span class="s1">np.asarray(lb)</span><span class="s0">, </span><span class="s1">np.asarray(ub)</span><span class="s0">,</span>
        <span class="s1">args</span><span class="s0">,</span>
        <span class="s0">False, </span><span class="s1">eps</span><span class="s0">, </span><span class="s1">maxfun</span><span class="s0">, </span><span class="s1">maxiter</span><span class="s0">,</span>
        <span class="s1">locally_biased</span><span class="s0">,</span>
        <span class="s1">f_min</span><span class="s0">, </span><span class="s1">f_min_rtol</span><span class="s0">,</span>
        <span class="s1">vol_tol</span><span class="s0">, </span><span class="s1">len_tol</span><span class="s0">, </span><span class="s1">callback</span>
    <span class="s1">)</span>

    <span class="s1">format_val = (maxfun</span><span class="s0">, </span><span class="s1">maxiter</span><span class="s0">, </span><span class="s1">f_min_rtol</span><span class="s0">, </span><span class="s1">vol_tol</span><span class="s0">, </span><span class="s1">len_tol)</span>
    <span class="s0">if </span><span class="s1">ret_code &gt; </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s1">message = SUCCESS_MESSAGES[ret_code - </span><span class="s4">3</span><span class="s1">].format(</span>
                    <span class="s1">format_val[ret_code - </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">elif </span><span class="s4">0 </span><span class="s1">&lt; ret_code &lt;= </span><span class="s4">2</span><span class="s1">:</span>
        <span class="s1">message = ERROR_MESSAGES[ret_code - </span><span class="s4">1</span><span class="s1">].format(format_val[ret_code - </span><span class="s4">1</span><span class="s1">])</span>
    <span class="s0">elif </span><span class="s4">0 </span><span class="s1">&gt; ret_code &gt; -</span><span class="s4">100</span><span class="s1">:</span>
        <span class="s1">message = ERROR_MESSAGES[abs(ret_code) + </span><span class="s4">1</span><span class="s1">]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">message = ERROR_MESSAGES[ret_code + </span><span class="s4">99</span><span class="s1">]</span>

    <span class="s0">return </span><span class="s1">OptimizeResult(x=np.asarray(x)</span><span class="s0">, </span><span class="s1">fun=fun</span><span class="s0">, </span><span class="s1">status=ret_code</span><span class="s0">,</span>
                          <span class="s1">success=ret_code &gt; </span><span class="s4">2</span><span class="s0">, </span><span class="s1">message=message</span><span class="s0">,</span>
                          <span class="s1">nfev=nfev</span><span class="s0">, </span><span class="s1">nit=nit)</span>
</pre>
</body>
</html>
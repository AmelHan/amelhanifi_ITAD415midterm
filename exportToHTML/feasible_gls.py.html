<html>
<head>
<title>feasible_gls.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
feasible_gls.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s2">&quot;&quot;&quot; 
 
Created on Tue Dec 20 20:24:20 2011 
 
Author: Josef Perktold 
License: BSD-3 
 
&quot;&quot;&quot;</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">statsmodels.regression.linear_model </span><span class="s3">import </span><span class="s1">OLS</span><span class="s3">, </span><span class="s1">GLS</span><span class="s3">, </span><span class="s1">WLS</span>


<span class="s3">def </span><span class="s1">atleast_2dcols(x):</span>
    <span class="s1">x = np.asarray(x)</span>
    <span class="s3">if </span><span class="s1">x.ndim == </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">x = x[:</span><span class="s3">,None</span><span class="s1">]</span>
    <span class="s3">return </span><span class="s1">x</span>


<span class="s3">class </span><span class="s1">GLSHet2(GLS):</span>
    <span class="s2">'''WLS with heteroscedasticity that depends on explanatory variables 
 
    note: mixing GLS sigma and weights for heteroscedasticity might not make 
    sense 
 
    I think rewriting following the pattern of GLSAR is better 
    stopping criteria: improve in GLSAR also, e.g. change in rho 
 
    '''</span>


    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">exog_var</span><span class="s3">, </span><span class="s1">sigma=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.exog_var = atleast_2dcols(exog_var)</span>
        <span class="s1">super(self.__class__</span><span class="s3">, </span><span class="s1">self).__init__(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">sigma=sigma)</span>


    <span class="s3">def </span><span class="s1">fit(self</span><span class="s3">, </span><span class="s1">lambd=</span><span class="s4">1.</span><span class="s1">):</span>
        <span class="s0">#maybe iterate</span>
        <span class="s0">#preliminary estimate</span>
        <span class="s1">res_gls = GLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">sigma=self.sigma).fit()</span>
        <span class="s1">res_resid = OLS(res_gls.resid**</span><span class="s4">2</span><span class="s3">, </span><span class="s1">self.exog_var).fit()</span>
        <span class="s0">#or  log-link</span>
        <span class="s0">#res_resid = OLS(np.log(res_gls.resid**2), self.exog_var).fit()</span>
        <span class="s0">#here I could use whiten and current instance instead of delegating</span>
        <span class="s0">#but this is easier</span>
        <span class="s0">#see pattern of GLSAR, calls self.initialize and self.fit</span>
        <span class="s1">res_wls = WLS(self.endog</span><span class="s3">, </span><span class="s1">self.exog</span><span class="s3">, </span><span class="s1">weights=</span><span class="s4">1.</span><span class="s1">/res_resid.fittedvalues).fit()</span>

        <span class="s1">res_wls._results.results_residual_regression = res_resid</span>
        <span class="s3">return </span><span class="s1">res_wls</span>


<span class="s3">class </span><span class="s1">GLSHet(WLS):</span>
    <span class="s2">&quot;&quot;&quot; 
    A regression model with an estimated heteroscedasticity. 
 
    A subclass of WLS, that additionally estimates the weight matrix as a 
    function of additional explanatory variables. 
 
    Parameters 
    ---------- 
    endog : array_like 
    exog : array_like 
    exog_var : array_like, 1d or 2d 
        regressors, explanatory variables for the variance 
    weights : array_like or None 
        If weights are given, then they are used in the first step estimation. 
    link : link function or None 
        If None, then the variance is assumed to be a linear combination of 
        the exog_var. If given, then ...  not tested yet 
 
    *extra attributes* 
 
    history : dict 
       contains the parameter estimates in both regression for each iteration 
 
    result instance has 
 
    results_residual_regression : OLS result instance 
        result of heteroscedasticity estimation 
 
    except for fit_iterative all methods are inherited from WLS. 
 
    Notes 
    ----- 
    GLSHet is considered to be experimental. 
 
    `fit` is just standard WLS fit for fixed weights 
    `fit_iterative` updates the estimate for weights, see its docstring 
 
    The two alternative for handling heteroscedasticity in the data are to 
    use heteroscedasticity robust standard errors or estimating the 
    heteroscedasticity 
    Estimating heteroscedasticity and using weighted least squares produces 
    smaller confidence intervals for the estimated parameters then the 
    heteroscedasticity robust standard errors if the heteroscedasticity is 
    correctly specified. If the heteroscedasticity is incorrectly specified 
    then the estimated covariance is inconsistent. 
 
    Stock and Watson for example argue in favor of using OLS with 
    heteroscedasticity robust standard errors instead of GLSHet sind we are 
    seldom sure enough about the correct specification (in economics). 
 
    GLSHet has asymptotically the same distribution as WLS if the true 
    weights are know. In both cases the asymptotic distribution of the 
    parameter estimates is the normal distribution. 
 
    The assumption of the model: 
 
    y = X*beta + u, 
    with E(u) = 0, E(X*u)=0, var(u_i) = z_i*gamma 
    or for vector of all observations Sigma = diag(Z*gamma) 
 
    where 
    y : endog (nobs) 
    X : exog  (nobs, k_vars) 
    Z : exog_var (nobs, k_vars2) 
    beta, gamma estimated parameters 
 
    If a link is specified, then the heteroscedasticity is 
 
    var(u_i) = link.inverse(z_i*gamma), or 
    link(var(u_i)) = z_i*gamma 
 
    for example for log-linkg 
    var(u_i) = exp(z_i*gamma) 
 
 
    Usage : see example .... 
 
    TODO: test link option 
    &quot;&quot;&quot;</span>
    <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">exog_var=</span><span class="s3">None, </span><span class="s1">weights=</span><span class="s3">None, </span><span class="s1">link=</span><span class="s3">None</span><span class="s1">):</span>
        <span class="s1">self.exog_var = atleast_2dcols(exog_var)</span>
        <span class="s3">if </span><span class="s1">weights </span><span class="s3">is None</span><span class="s1">:</span>
            <span class="s1">weights = np.ones(endog.shape)</span>
        <span class="s3">if </span><span class="s1">link </span><span class="s3">is not None</span><span class="s1">:</span>
            <span class="s1">self.link = link</span>
            <span class="s1">self.linkinv = link.inverse   </span><span class="s0">#as defined in families.links</span>
        <span class="s3">else</span><span class="s1">:</span>
            <span class="s1">self.link = </span><span class="s3">lambda </span><span class="s1">x: x  </span><span class="s0">#no transformation</span>
            <span class="s1">self.linkinv = </span><span class="s3">lambda </span><span class="s1">x: x</span>

        <span class="s1">super(self.__class__</span><span class="s3">, </span><span class="s1">self).__init__(endog</span><span class="s3">, </span><span class="s1">exog</span><span class="s3">, </span><span class="s1">weights=weights)</span>

    <span class="s3">def </span><span class="s1">iterative_fit(self</span><span class="s3">, </span><span class="s1">maxiter=</span><span class="s4">3</span><span class="s1">):</span>
        <span class="s2">&quot;&quot;&quot; 
        Perform an iterative two-step procedure to estimate a WLS model. 
 
        The model is assumed to have heteroskedastic errors. 
        The variance is estimated by OLS regression of the link transformed 
        squared residuals on Z, i.e.:: 
 
           link(sigma_i) = x_i*gamma. 
 
        Parameters 
        ---------- 
        maxiter : int, optional 
            the number of iterations 
 
        Notes 
        ----- 
        maxiter=1: returns the estimated based on given weights 
        maxiter=2: performs a second estimation with the updated weights, 
                   this is 2-step estimation 
        maxiter&gt;2: iteratively estimate and update the weights 
 
        TODO: possible extension stop iteration if change in parameter 
            estimates is smaller than x_tol 
 
        Repeated calls to fit_iterative, will do one redundant pinv_wexog 
        calculation. Calling fit_iterative(maxiter) ones does not do any 
        redundant recalculations (whitening or calculating pinv_wexog). 
        &quot;&quot;&quot;</span>

        <span class="s3">import </span><span class="s1">collections</span>
        <span class="s1">self.history = collections.defaultdict(list) </span><span class="s0">#not really necessary</span>
        <span class="s1">res_resid = </span><span class="s3">None  </span><span class="s0">#if maxiter &lt; 2 no updating</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range(maxiter):</span>
            <span class="s0">#pinv_wexog is cached</span>
            <span class="s3">if </span><span class="s1">hasattr(self</span><span class="s3">, </span><span class="s5">'pinv_wexog'</span><span class="s1">):</span>
                <span class="s3">del </span><span class="s1">self.pinv_wexog</span>
            <span class="s0">#self.initialize()</span>
            <span class="s0">#print 'wls self',</span>
            <span class="s1">results = self.fit()</span>
            <span class="s1">self.history[</span><span class="s5">'self_params'</span><span class="s1">].append(results.params)</span>
            <span class="s3">if not </span><span class="s1">i == maxiter-</span><span class="s4">1</span><span class="s1">:  </span><span class="s0">#skip for last iteration, could break instead</span>
                <span class="s0">#print 'ols',</span>
                <span class="s1">self.results_old = results </span><span class="s0">#for debugging</span>
                <span class="s0">#estimate heteroscedasticity</span>
                <span class="s1">res_resid = OLS(self.link(results.resid**</span><span class="s4">2</span><span class="s1">)</span><span class="s3">, </span><span class="s1">self.exog_var).fit()</span>
                <span class="s1">self.history[</span><span class="s5">'ols_params'</span><span class="s1">].append(res_resid.params)</span>
                <span class="s0">#update weights</span>
                <span class="s1">self.weights = </span><span class="s4">1.</span><span class="s1">/self.linkinv(res_resid.fittedvalues)</span>
                <span class="s1">self.weights /= self.weights.max()  </span><span class="s0">#not required</span>
                <span class="s1">self.weights[self.weights &lt; </span><span class="s4">1e-14</span><span class="s1">] = </span><span class="s4">1e-14  </span><span class="s0">#clip</span>
                <span class="s0">#print 'in iter', i, self.weights.var() #debug, do weights change</span>
                <span class="s1">self.initialize()</span>

        <span class="s0">#note results is the wrapper, results._results is the results instance</span>
        <span class="s1">results._results.results_residual_regression = res_resid</span>
        <span class="s3">return </span><span class="s1">results</span>
</pre>
</body>
</html>
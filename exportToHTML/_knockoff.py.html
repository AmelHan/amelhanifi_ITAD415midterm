<html>
<head>
<title>_knockoff.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #808080;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_knockoff.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
The RegressionFDR class implements the 'Knockoff' approach for 
controlling false discovery rates (FDR) in regression analysis. 
 
The knockoff approach does not require standard errors.  Thus one 
application is to provide inference for parameter estimates that are 
not smooth functions of the data.  For example, the knockoff approach 
can be used to do inference for parameter estimates obtained from the 
LASSO, of from stepwise variable selection. 
 
The knockoff approach controls FDR for parameter estimates that may be 
dependent, such as coefficient estimates in a multiple regression 
model. 
 
The knockoff approach is applicable whenever the test statistic can be 
computed entirely from x'y and x'x, where x is the design matrix and y 
is the vector of responses. 
 
Reference 
--------- 
Rina Foygel Barber, Emmanuel Candes (2015).  Controlling the False 
Discovery Rate via Knockoffs.  Annals of Statistics 43:5. 
https://candes.su.domains/publications/downloads/FDR_regression.pdf 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">statsmodels.iolib </span><span class="s2">import </span><span class="s1">summary2</span>


<span class="s2">class </span><span class="s1">RegressionFDR:</span>
    <span class="s0">&quot;&quot;&quot; 
    Control FDR in a regression procedure. 
 
    Parameters 
    ---------- 
    endog : array_like 
        The dependent variable of the regression 
    exog : array_like 
        The independent variables of the regression 
    regeffects : RegressionEffects instance 
        An instance of a RegressionEffects class that can compute 
        effect sizes for the regression coefficients. 
    method : str 
        The approach used to assess and control FDR, currently 
        must be 'knockoff'. 
 
    Returns 
    ------- 
    Returns an instance of the RegressionFDR class.  The `fdr` attribute 
    holds the estimated false discovery rates. 
 
    Notes 
    ----- 
    This class Implements the knockoff method of Barber and Candes. 
    This is an approach for controlling the FDR of a variety of 
    regression estimation procedures, including correlation 
    coefficients, OLS regression, OLS with forward selection, and 
    LASSO regression. 
 
    For other approaches to FDR control in regression, see the 
    statsmodels.stats.multitest module.  Methods provided in that 
    module use Z-scores or p-values, and therefore require standard 
    errors for the coefficient estimates to be available. 
 
    The default method for constructing the augmented design matrix is 
    the 'equivariant' approach, set `design_method='sdp'` to use an 
    alternative approach involving semidefinite programming.  See 
    Barber and Candes for more information about both approaches.  The 
    sdp approach requires that the cvxopt package be installed. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">endog</span><span class="s2">, </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">regeffects</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">&quot;knockoff&quot;</span><span class="s2">,</span>
                 <span class="s1">**kwargs):</span>

        <span class="s2">if </span><span class="s1">hasattr(exog</span><span class="s2">, </span><span class="s3">&quot;columns&quot;</span><span class="s1">):</span>
            <span class="s1">self.xnames = exog.columns</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.xnames = [</span><span class="s3">&quot;x%d&quot; </span><span class="s1">% j </span><span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range(exog.shape[</span><span class="s4">1</span><span class="s1">])]</span>

        <span class="s1">exog = np.asarray(exog)</span>
        <span class="s1">endog = np.asarray(endog)</span>

        <span class="s2">if </span><span class="s3">&quot;design_method&quot; </span><span class="s2">not in </span><span class="s1">kwargs:</span>
            <span class="s1">kwargs[</span><span class="s3">&quot;design_method&quot;</span><span class="s1">] = </span><span class="s3">&quot;equi&quot;</span>

        <span class="s1">nobs</span><span class="s2">, </span><span class="s1">nvar = exog.shape</span>

        <span class="s2">if </span><span class="s1">kwargs[</span><span class="s3">&quot;design_method&quot;</span><span class="s1">] == </span><span class="s3">&quot;equi&quot;</span><span class="s1">:</span>
            <span class="s1">exog1</span><span class="s2">, </span><span class="s1">exog2</span><span class="s2">, </span><span class="s1">_ = _design_knockoff_equi(exog)</span>
        <span class="s2">elif </span><span class="s1">kwargs[</span><span class="s3">&quot;design_method&quot;</span><span class="s1">] == </span><span class="s3">&quot;sdp&quot;</span><span class="s1">:</span>
            <span class="s1">exog1</span><span class="s2">, </span><span class="s1">exog2</span><span class="s2">, </span><span class="s1">_ = _design_knockoff_sdp(exog)</span>
        <span class="s1">endog = endog - np.mean(endog)</span>

        <span class="s1">self.endog = endog</span>
        <span class="s1">self.exog = np.concatenate((exog1</span><span class="s2">, </span><span class="s1">exog2)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">self.exog1 = exog1</span>
        <span class="s1">self.exog2 = exog2</span>

        <span class="s1">self.stats = regeffects.stats(self)</span>

        <span class="s1">unq</span><span class="s2">, </span><span class="s1">inv</span><span class="s2">, </span><span class="s1">cnt = np.unique(self.stats</span><span class="s2">, </span><span class="s1">return_inverse=</span><span class="s2">True,</span>
                                  <span class="s1">return_counts=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s5"># The denominator of the FDR</span>
        <span class="s1">cc = np.cumsum(cnt)</span>
        <span class="s1">denom = len(self.stats) - cc + cnt</span>
        <span class="s1">denom[denom &lt; </span><span class="s4">1</span><span class="s1">] = </span><span class="s4">1</span>

        <span class="s5"># The numerator of the FDR</span>
        <span class="s1">ii = np.searchsorted(unq</span><span class="s2">, </span><span class="s1">-unq</span><span class="s2">, </span><span class="s1">side=</span><span class="s3">'right'</span><span class="s1">) - </span><span class="s4">1</span>
        <span class="s1">numer = cc[ii]</span>
        <span class="s1">numer[ii &lt; </span><span class="s4">0</span><span class="s1">] = </span><span class="s4">0</span>

        <span class="s5"># The knockoff+ estimated FDR</span>
        <span class="s1">fdrp = (</span><span class="s4">1 </span><span class="s1">+ numer) / denom</span>

        <span class="s5"># The knockoff estimated FDR</span>
        <span class="s1">fdr = numer / denom</span>

        <span class="s1">self.fdr = fdr[inv]</span>
        <span class="s1">self.fdrp = fdrp[inv]</span>
        <span class="s1">self._ufdr = fdr</span>
        <span class="s1">self._unq = unq</span>

        <span class="s1">df = pd.DataFrame(index=self.xnames)</span>
        <span class="s1">df[</span><span class="s3">&quot;Stat&quot;</span><span class="s1">] = self.stats</span>
        <span class="s1">df[</span><span class="s3">&quot;FDR+&quot;</span><span class="s1">] = self.fdrp</span>
        <span class="s1">df[</span><span class="s3">&quot;FDR&quot;</span><span class="s1">] = self.fdr</span>
        <span class="s1">self.fdr_df = df</span>

    <span class="s2">def </span><span class="s1">threshold(self</span><span class="s2">, </span><span class="s1">tfdr):</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns the threshold statistic for a given target FDR. 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">np.min(self._ufdr) &lt;= tfdr:</span>
            <span class="s2">return </span><span class="s1">self._unq[self._ufdr &lt;= tfdr][</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">np.inf</span>

    <span class="s2">def </span><span class="s1">summary(self):</span>

        <span class="s1">summ = summary2.Summary()</span>
        <span class="s1">summ.add_title(</span><span class="s3">&quot;Regression FDR results&quot;</span><span class="s1">)</span>
        <span class="s1">summ.add_df(self.fdr_df)</span>

        <span class="s2">return </span><span class="s1">summ</span>


<span class="s2">def </span><span class="s1">_design_knockoff_sdp(exog):</span>
    <span class="s0">&quot;&quot;&quot; 
    Use semidefinite programming to construct a knockoff design 
    matrix. 
 
    Requires cvxopt to be installed. 
    &quot;&quot;&quot;</span>

    <span class="s2">try</span><span class="s1">:</span>
        <span class="s2">from </span><span class="s1">cvxopt </span><span class="s2">import </span><span class="s1">solvers</span><span class="s2">, </span><span class="s1">matrix</span>
    <span class="s2">except </span><span class="s1">ImportError:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;SDP knockoff designs require installation of cvxopt&quot;</span><span class="s1">)</span>

    <span class="s1">nobs</span><span class="s2">, </span><span class="s1">nvar = exog.shape</span>

    <span class="s5"># Standardize exog</span>
    <span class="s1">xnm = np.sum(exog**</span><span class="s4">2</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">xnm = np.sqrt(xnm)</span>
    <span class="s1">exog = exog / xnm</span>

    <span class="s1">Sigma = np.dot(exog.T</span><span class="s2">, </span><span class="s1">exog)</span>

    <span class="s1">c = matrix(-np.ones(nvar))</span>

    <span class="s1">h0 = np.concatenate((np.zeros(nvar)</span><span class="s2">, </span><span class="s1">np.ones(nvar)))</span>
    <span class="s1">h0 = matrix(h0)</span>
    <span class="s1">G0 = np.concatenate((-np.eye(nvar)</span><span class="s2">, </span><span class="s1">np.eye(nvar))</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">G0 = matrix(G0)</span>

    <span class="s1">h1 = </span><span class="s4">2 </span><span class="s1">* Sigma</span>
    <span class="s1">h1 = matrix(h1)</span>
    <span class="s1">i</span><span class="s2">, </span><span class="s1">j = np.diag_indices(nvar)</span>
    <span class="s1">G1 = np.zeros((nvar*nvar</span><span class="s2">, </span><span class="s1">nvar))</span>
    <span class="s1">G1[i*nvar + j</span><span class="s2">, </span><span class="s1">i] = </span><span class="s4">1</span>
    <span class="s1">G1 = matrix(G1)</span>

    <span class="s1">solvers.options[</span><span class="s3">'show_progress'</span><span class="s1">] = </span><span class="s2">False</span>
    <span class="s1">sol = solvers.sdp(c</span><span class="s2">, </span><span class="s1">G0</span><span class="s2">, </span><span class="s1">h0</span><span class="s2">, </span><span class="s1">[G1]</span><span class="s2">, </span><span class="s1">[h1])</span>
    <span class="s1">sl = np.asarray(sol[</span><span class="s3">'x'</span><span class="s1">]).ravel()</span>

    <span class="s1">xcov = np.dot(exog.T</span><span class="s2">, </span><span class="s1">exog)</span>
    <span class="s1">exogn = _get_knmat(exog</span><span class="s2">, </span><span class="s1">xcov</span><span class="s2">, </span><span class="s1">sl)</span>

    <span class="s2">return </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exogn</span><span class="s2">, </span><span class="s1">sl</span>


<span class="s2">def </span><span class="s1">_design_knockoff_equi(exog):</span>
    <span class="s0">&quot;&quot;&quot; 
    Construct an equivariant design matrix for knockoff analysis. 
 
    Follows the 'equi-correlated knockoff approach of equation 2.4 in 
    Barber and Candes. 
 
    Constructs a pair of design matrices exogs, exogn such that exogs 
    is a scaled/centered version of the input matrix exog, exogn is 
    another matrix of the same shape with cov(exogn) = cov(exogs), and 
    the covariances between corresponding columns of exogn and exogs 
    are as small as possible. 
    &quot;&quot;&quot;</span>

    <span class="s1">nobs</span><span class="s2">, </span><span class="s1">nvar = exog.shape</span>

    <span class="s2">if </span><span class="s1">nobs &lt; </span><span class="s4">2</span><span class="s1">*nvar:</span>
        <span class="s1">msg = </span><span class="s3">&quot;The equivariant knockoff can ony be used when n &gt;= 2*p&quot;</span>
        <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

    <span class="s5"># Standardize exog</span>
    <span class="s1">xnm = np.sum(exog**</span><span class="s4">2</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">xnm = np.sqrt(xnm)</span>
    <span class="s1">exog = exog / xnm</span>

    <span class="s1">xcov = np.dot(exog.T</span><span class="s2">, </span><span class="s1">exog)</span>
    <span class="s1">ev</span><span class="s2">, </span><span class="s1">_ = np.linalg.eig(xcov)</span>
    <span class="s1">evmin = np.min(ev)</span>

    <span class="s1">sl = min(</span><span class="s4">2</span><span class="s1">*evmin</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">sl = sl * np.ones(nvar)</span>

    <span class="s1">exogn = _get_knmat(exog</span><span class="s2">, </span><span class="s1">xcov</span><span class="s2">, </span><span class="s1">sl)</span>

    <span class="s2">return </span><span class="s1">exog</span><span class="s2">, </span><span class="s1">exogn</span><span class="s2">, </span><span class="s1">sl</span>


<span class="s2">def </span><span class="s1">_get_knmat(exog</span><span class="s2">, </span><span class="s1">xcov</span><span class="s2">, </span><span class="s1">sl):</span>
    <span class="s5"># Utility function, see equation 2.2 of Barber &amp; Candes.</span>

    <span class="s1">nobs</span><span class="s2">, </span><span class="s1">nvar = exog.shape</span>

    <span class="s1">ash = np.linalg.inv(xcov)</span>
    <span class="s1">ash *= -np.outer(sl</span><span class="s2">, </span><span class="s1">sl)</span>
    <span class="s1">i</span><span class="s2">, </span><span class="s1">j = np.diag_indices(nvar)</span>
    <span class="s1">ash[i</span><span class="s2">, </span><span class="s1">j] += </span><span class="s4">2 </span><span class="s1">* sl</span>

    <span class="s1">umat = np.random.normal(size=(nobs</span><span class="s2">, </span><span class="s1">nvar))</span>
    <span class="s1">u</span><span class="s2">, </span><span class="s1">_ = np.linalg.qr(exog)</span>
    <span class="s1">umat -= np.dot(u</span><span class="s2">, </span><span class="s1">np.dot(u.T</span><span class="s2">, </span><span class="s1">umat))</span>
    <span class="s1">umat</span><span class="s2">, </span><span class="s1">_ = np.linalg.qr(umat)</span>

    <span class="s1">ashr</span><span class="s2">, </span><span class="s1">xc</span><span class="s2">, </span><span class="s1">_ = np.linalg.svd(ash</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">ashr *= np.sqrt(xc)</span>
    <span class="s1">ashr = ashr.T</span>

    <span class="s1">ex = (sl[:</span><span class="s2">, None</span><span class="s1">] * np.linalg.solve(xcov</span><span class="s2">, </span><span class="s1">exog.T)).T</span>
    <span class="s1">exogn = exog - ex + np.dot(umat</span><span class="s2">, </span><span class="s1">ashr)</span>

    <span class="s2">return </span><span class="s1">exogn</span>
</pre>
</body>
</html>
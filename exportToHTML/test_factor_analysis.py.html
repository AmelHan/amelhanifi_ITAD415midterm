<html>
<head>
<title>test_factor_analysis.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6897bb;}
.s4 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_factor_analysis.py</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Christian Osendorfer &lt;osendorf@gmail.com&gt;</span>
<span class="s0">#         Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="s0"># License: BSD3</span>

<span class="s2">from </span><span class="s1">itertools </span><span class="s2">import </span><span class="s1">combinations</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">sklearn.decomposition </span><span class="s2">import </span><span class="s1">FactorAnalysis</span>
<span class="s2">from </span><span class="s1">sklearn.decomposition._factor_analysis </span><span class="s2">import </span><span class="s1">_ortho_rotation</span>
<span class="s2">from </span><span class="s1">sklearn.exceptions </span><span class="s2">import </span><span class="s1">ConvergenceWarning</span>
<span class="s2">from </span><span class="s1">sklearn.utils._testing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">assert_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">,</span>
    <span class="s1">ignore_warnings</span><span class="s2">,</span>
<span class="s1">)</span>


<span class="s0"># Ignore warnings from switching to more power iterations in randomized_svd</span>
<span class="s1">@ignore_warnings</span>
<span class="s2">def </span><span class="s1">test_factor_analysis():</span>
    <span class="s0"># Test FactorAnalysis ability to recover the data covariance structure</span>
    <span class="s1">rng = np.random.RandomState(</span><span class="s3">0</span><span class="s1">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_components = </span><span class="s3">20</span><span class="s2">, </span><span class="s3">5</span><span class="s2">, </span><span class="s3">3</span>

    <span class="s0"># Some random settings for the generative model</span>
    <span class="s1">W = rng.randn(n_components</span><span class="s2">, </span><span class="s1">n_features)</span>
    <span class="s0"># latent variable of dim 3, 20 of it</span>
    <span class="s1">h = rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_components)</span>
    <span class="s0"># using gamma to model different noise variance</span>
    <span class="s0"># per component</span>
    <span class="s1">noise = rng.gamma(</span><span class="s3">1</span><span class="s2">, </span><span class="s1">size=n_features) * rng.randn(n_samples</span><span class="s2">, </span><span class="s1">n_features)</span>

    <span class="s0"># generate observations</span>
    <span class="s0"># wlog, mean is 0</span>
    <span class="s1">X = np.dot(h</span><span class="s2">, </span><span class="s1">W) + noise</span>

    <span class="s1">fas = []</span>
    <span class="s2">for </span><span class="s1">method </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;randomized&quot;</span><span class="s2">, </span><span class="s4">&quot;lapack&quot;</span><span class="s1">]:</span>
        <span class="s1">fa = FactorAnalysis(n_components=n_components</span><span class="s2">, </span><span class="s1">svd_method=method)</span>
        <span class="s1">fa.fit(X)</span>
        <span class="s1">fas.append(fa)</span>

        <span class="s1">X_t = fa.transform(X)</span>
        <span class="s2">assert </span><span class="s1">X_t.shape == (n_samples</span><span class="s2">, </span><span class="s1">n_components)</span>

        <span class="s1">assert_almost_equal(fa.loglike_[-</span><span class="s3">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">fa.score_samples(X).sum())</span>
        <span class="s1">assert_almost_equal(fa.score_samples(X).mean()</span><span class="s2">, </span><span class="s1">fa.score(X))</span>

        <span class="s1">diff = np.all(np.diff(fa.loglike_))</span>
        <span class="s2">assert </span><span class="s1">diff &gt; </span><span class="s3">0.0</span><span class="s2">, </span><span class="s4">&quot;Log likelihood dif not increase&quot;</span>

        <span class="s0"># Sample Covariance</span>
        <span class="s1">scov = np.cov(X</span><span class="s2">, </span><span class="s1">rowvar=</span><span class="s3">0.0</span><span class="s2">, </span><span class="s1">bias=</span><span class="s3">1.0</span><span class="s1">)</span>

        <span class="s0"># Model Covariance</span>
        <span class="s1">mcov = fa.get_covariance()</span>
        <span class="s1">diff = np.sum(np.abs(scov - mcov)) / W.size</span>
        <span class="s2">assert </span><span class="s1">diff &lt; </span><span class="s3">0.1</span><span class="s2">, </span><span class="s4">&quot;Mean absolute difference is %f&quot; </span><span class="s1">% diff</span>
        <span class="s1">fa = FactorAnalysis(</span>
            <span class="s1">n_components=n_components</span><span class="s2">, </span><span class="s1">noise_variance_init=np.ones(n_features)</span>
        <span class="s1">)</span>
        <span class="s2">with </span><span class="s1">pytest.raises(ValueError):</span>
            <span class="s1">fa.fit(X[:</span><span class="s2">, </span><span class="s1">:</span><span class="s3">2</span><span class="s1">])</span>

    <span class="s2">def </span><span class="s1">f(x</span><span class="s2">, </span><span class="s1">y):</span>
        <span class="s2">return </span><span class="s1">np.abs(getattr(x</span><span class="s2">, </span><span class="s1">y))  </span><span class="s0"># sign will not be equal</span>

    <span class="s1">fa1</span><span class="s2">, </span><span class="s1">fa2 = fas</span>
    <span class="s2">for </span><span class="s1">attr </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;loglike_&quot;</span><span class="s2">, </span><span class="s4">&quot;components_&quot;</span><span class="s2">, </span><span class="s4">&quot;noise_variance_&quot;</span><span class="s1">]:</span>
        <span class="s1">assert_almost_equal(f(fa1</span><span class="s2">, </span><span class="s1">attr)</span><span class="s2">, </span><span class="s1">f(fa2</span><span class="s2">, </span><span class="s1">attr))</span>

    <span class="s1">fa1.max_iter = </span><span class="s3">1</span>
    <span class="s1">fa1.verbose = </span><span class="s2">True</span>
    <span class="s2">with </span><span class="s1">pytest.warns(ConvergenceWarning):</span>
        <span class="s1">fa1.fit(X)</span>

    <span class="s0"># Test get_covariance and get_precision with n_components == n_features</span>
    <span class="s0"># with n_components &lt; n_features and with n_components == 0</span>
    <span class="s2">for </span><span class="s1">n_components </span><span class="s2">in </span><span class="s1">[</span><span class="s3">0</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span class="s1">X.shape[</span><span class="s3">1</span><span class="s1">]]:</span>
        <span class="s1">fa.n_components = n_components</span>
        <span class="s1">fa.fit(X)</span>
        <span class="s1">cov = fa.get_covariance()</span>
        <span class="s1">precision = fa.get_precision()</span>
        <span class="s1">assert_array_almost_equal(np.dot(cov</span><span class="s2">, </span><span class="s1">precision)</span><span class="s2">, </span><span class="s1">np.eye(X.shape[</span><span class="s3">1</span><span class="s1">])</span><span class="s2">, </span><span class="s3">12</span><span class="s1">)</span>

    <span class="s0"># test rotation</span>
    <span class="s1">n_components = </span><span class="s3">2</span>

    <span class="s1">results</span><span class="s2">, </span><span class="s1">projections = {}</span><span class="s2">, </span><span class="s1">{}</span>
    <span class="s2">for </span><span class="s1">method </span><span class="s2">in </span><span class="s1">(</span><span class="s2">None, </span><span class="s4">&quot;varimax&quot;</span><span class="s2">, </span><span class="s4">&quot;quartimax&quot;</span><span class="s1">):</span>
        <span class="s1">fa_var = FactorAnalysis(n_components=n_components</span><span class="s2">, </span><span class="s1">rotation=method)</span>
        <span class="s1">results[method] = fa_var.fit_transform(X)</span>
        <span class="s1">projections[method] = fa_var.get_covariance()</span>
    <span class="s2">for </span><span class="s1">rot1</span><span class="s2">, </span><span class="s1">rot2 </span><span class="s2">in </span><span class="s1">combinations([</span><span class="s2">None, </span><span class="s4">&quot;varimax&quot;</span><span class="s2">, </span><span class="s4">&quot;quartimax&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s3">2</span><span class="s1">):</span>
        <span class="s2">assert not </span><span class="s1">np.allclose(results[rot1]</span><span class="s2">, </span><span class="s1">results[rot2])</span>
        <span class="s2">assert </span><span class="s1">np.allclose(projections[rot1]</span><span class="s2">, </span><span class="s1">projections[rot2]</span><span class="s2">, </span><span class="s1">atol=</span><span class="s3">3</span><span class="s1">)</span>

    <span class="s0"># test against R's psych::principal with rotate=&quot;varimax&quot;</span>
    <span class="s0"># (i.e., the values below stem from rotating the components in R)</span>
    <span class="s0"># R's factor analysis returns quite different values; therefore, we only</span>
    <span class="s0"># test the rotation itself</span>
    <span class="s1">factors = np.array(</span>
        <span class="s1">[</span>
            <span class="s1">[</span><span class="s3">0.89421016</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.35854928</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.27770122</span><span class="s2">, </span><span class="s3">0.03773647</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[-</span><span class="s3">0.45081822</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.89132754</span><span class="s2">, </span><span class="s3">0.0932195</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.01787973</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s3">0.99500666</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.02031465</span><span class="s2">, </span><span class="s3">0.05426497</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.11539407</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s3">0.96822861</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.06299656</span><span class="s2">, </span><span class="s3">0.24411001</span><span class="s2">, </span><span class="s3">0.07540887</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s1">r_solution = np.array(</span>
        <span class="s1">[[</span><span class="s3">0.962</span><span class="s2">, </span><span class="s3">0.052</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[-</span><span class="s3">0.141</span><span class="s2">, </span><span class="s3">0.989</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0.949</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.300</span><span class="s1">]</span><span class="s2">, </span><span class="s1">[</span><span class="s3">0.937</span><span class="s2">, </span><span class="s1">-</span><span class="s3">0.251</span><span class="s1">]]</span>
    <span class="s1">)</span>
    <span class="s1">rotated = _ortho_rotation(factors[:</span><span class="s2">, </span><span class="s1">:n_components]</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;varimax&quot;</span><span class="s1">).T</span>
    <span class="s1">assert_array_almost_equal(np.abs(rotated)</span><span class="s2">, </span><span class="s1">np.abs(r_solution)</span><span class="s2">, </span><span class="s1">decimal=</span><span class="s3">3</span><span class="s1">)</span>
</pre>
</body>
</html>